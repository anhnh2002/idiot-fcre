#############params############
cuda
Task=Tacred, 5-shot
Encoding model: bert
pattern=hybridprompt
mem=1, margin=0.3, gen=0, gen_num=2
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 127.4410230CurrentTrain: epoch  0, batch     1 | loss: 91.0480700CurrentTrain: epoch  0, batch     2 | loss: 78.5039682CurrentTrain: epoch  0, batch     3 | loss: 88.2306910CurrentTrain: epoch  0, batch     4 | loss: 87.3597513CurrentTrain: epoch  0, batch     5 | loss: 87.4418091CurrentTrain: epoch  0, batch     6 | loss: 101.8835287CurrentTrain: epoch  0, batch     7 | loss: 100.6150611CurrentTrain: epoch  0, batch     8 | loss: 86.3544628CurrentTrain: epoch  0, batch     9 | loss: 86.4705513CurrentTrain: epoch  0, batch    10 | loss: 77.2608740CurrentTrain: epoch  0, batch    11 | loss: 100.9790722CurrentTrain: epoch  0, batch    12 | loss: 99.3914943CurrentTrain: epoch  0, batch    13 | loss: 193.1445742CurrentTrain: epoch  0, batch    14 | loss: 100.3338364CurrentTrain: epoch  0, batch    15 | loss: 86.2700722CurrentTrain: epoch  0, batch    16 | loss: 86.6955689CurrentTrain: epoch  0, batch    17 | loss: 118.3794258CurrentTrain: epoch  0, batch    18 | loss: 99.9756678CurrentTrain: epoch  0, batch    19 | loss: 86.3320767CurrentTrain: epoch  0, batch    20 | loss: 146.9150817CurrentTrain: epoch  0, batch    21 | loss: 146.1959342CurrentTrain: epoch  0, batch    22 | loss: 193.1894195CurrentTrain: epoch  0, batch    23 | loss: 145.9490238CurrentTrain: epoch  0, batch    24 | loss: 99.6026530CurrentTrain: epoch  0, batch    25 | loss: 192.7196244CurrentTrain: epoch  0, batch    26 | loss: 86.0092776CurrentTrain: epoch  0, batch    27 | loss: 117.8975299CurrentTrain: epoch  0, batch    28 | loss: 145.6390192CurrentTrain: epoch  0, batch    29 | loss: 98.7139077CurrentTrain: epoch  0, batch    30 | loss: 145.6671623CurrentTrain: epoch  0, batch    31 | loss: 145.4222380CurrentTrain: epoch  0, batch    32 | loss: 117.6100639CurrentTrain: epoch  0, batch    33 | loss: 85.5126644CurrentTrain: epoch  0, batch    34 | loss: 146.5690565CurrentTrain: epoch  0, batch    35 | loss: 84.9825595CurrentTrain: epoch  0, batch    36 | loss: 84.7571527CurrentTrain: epoch  0, batch    37 | loss: 98.5992710CurrentTrain: epoch  0, batch    38 | loss: 98.1671784CurrentTrain: epoch  0, batch    39 | loss: 85.1203110CurrentTrain: epoch  0, batch    40 | loss: 117.5720920CurrentTrain: epoch  0, batch    41 | loss: 85.5919577CurrentTrain: epoch  0, batch    42 | loss: 84.6573954CurrentTrain: epoch  0, batch    43 | loss: 74.3712639CurrentTrain: epoch  0, batch    44 | loss: 98.0891050CurrentTrain: epoch  0, batch    45 | loss: 82.7940821CurrentTrain: epoch  0, batch    46 | loss: 115.0650167CurrentTrain: epoch  0, batch    47 | loss: 83.8726932CurrentTrain: epoch  0, batch    48 | loss: 97.4309193CurrentTrain: epoch  0, batch    49 | loss: 97.1130939CurrentTrain: epoch  0, batch    50 | loss: 96.9793131CurrentTrain: epoch  0, batch    51 | loss: 97.8810438CurrentTrain: epoch  0, batch    52 | loss: 96.9075258CurrentTrain: epoch  0, batch    53 | loss: 142.9276334CurrentTrain: epoch  0, batch    54 | loss: 116.0490714CurrentTrain: epoch  0, batch    55 | loss: 82.5294288CurrentTrain: epoch  0, batch    56 | loss: 83.6886005CurrentTrain: epoch  0, batch    57 | loss: 95.5699823CurrentTrain: epoch  0, batch    58 | loss: 94.7212865CurrentTrain: epoch  0, batch    59 | loss: 95.2854462CurrentTrain: epoch  0, batch    60 | loss: 93.6369534CurrentTrain: epoch  0, batch    61 | loss: 95.9668130CurrentTrain: epoch  0, batch    62 | loss: 83.0474007CurrentTrain: epoch  0, batch    63 | loss: 111.9088133CurrentTrain: epoch  0, batch    64 | loss: 95.4962377CurrentTrain: epoch  0, batch    65 | loss: 71.6006318CurrentTrain: epoch  0, batch    66 | loss: 91.0208193CurrentTrain: epoch  0, batch    67 | loss: 94.6509443CurrentTrain: epoch  0, batch    68 | loss: 82.4460175CurrentTrain: epoch  0, batch    69 | loss: 141.7931879CurrentTrain: epoch  0, batch    70 | loss: 117.3976795CurrentTrain: epoch  0, batch    71 | loss: 82.6429037CurrentTrain: epoch  0, batch    72 | loss: 96.9215286CurrentTrain: epoch  0, batch    73 | loss: 112.8935665CurrentTrain: epoch  0, batch    74 | loss: 142.3137850CurrentTrain: epoch  0, batch    75 | loss: 95.0093906CurrentTrain: epoch  0, batch    76 | loss: 110.2806831CurrentTrain: epoch  0, batch    77 | loss: 92.8881405CurrentTrain: epoch  0, batch    78 | loss: 112.6259929CurrentTrain: epoch  0, batch    79 | loss: 111.0747890CurrentTrain: epoch  0, batch    80 | loss: 79.2325549CurrentTrain: epoch  0, batch    81 | loss: 92.2656294CurrentTrain: epoch  0, batch    82 | loss: 111.3827890CurrentTrain: epoch  0, batch    83 | loss: 93.8524872CurrentTrain: epoch  0, batch    84 | loss: 107.6148636CurrentTrain: epoch  0, batch    85 | loss: 79.7293064CurrentTrain: epoch  0, batch    86 | loss: 137.4133676CurrentTrain: epoch  0, batch    87 | loss: 81.6693868CurrentTrain: epoch  0, batch    88 | loss: 80.0372843CurrentTrain: epoch  0, batch    89 | loss: 66.0136528CurrentTrain: epoch  0, batch    90 | loss: 93.0794947CurrentTrain: epoch  0, batch    91 | loss: 80.1684487CurrentTrain: epoch  0, batch    92 | loss: 90.4279159CurrentTrain: epoch  0, batch    93 | loss: 135.2179701CurrentTrain: epoch  0, batch    94 | loss: 80.2209610CurrentTrain: epoch  0, batch    95 | loss: 93.3847682CurrentTrain: epoch  1, batch     0 | loss: 79.2731747CurrentTrain: epoch  1, batch     1 | loss: 93.0305624CurrentTrain: epoch  1, batch     2 | loss: 78.2924860CurrentTrain: epoch  1, batch     3 | loss: 79.3196894CurrentTrain: epoch  1, batch     4 | loss: 88.3923489CurrentTrain: epoch  1, batch     5 | loss: 75.7498863CurrentTrain: epoch  1, batch     6 | loss: 94.6736979CurrentTrain: epoch  1, batch     7 | loss: 137.9167703CurrentTrain: epoch  1, batch     8 | loss: 69.9167885CurrentTrain: epoch  1, batch     9 | loss: 107.1252431CurrentTrain: epoch  1, batch    10 | loss: 90.3771372CurrentTrain: epoch  1, batch    11 | loss: 77.4832794CurrentTrain: epoch  1, batch    12 | loss: 75.7594618CurrentTrain: epoch  1, batch    13 | loss: 109.9826618CurrentTrain: epoch  1, batch    14 | loss: 105.4590849CurrentTrain: epoch  1, batch    15 | loss: 93.1283803CurrentTrain: epoch  1, batch    16 | loss: 135.2773398CurrentTrain: epoch  1, batch    17 | loss: 76.2209645CurrentTrain: epoch  1, batch    18 | loss: 86.6363578CurrentTrain: epoch  1, batch    19 | loss: 110.0455275CurrentTrain: epoch  1, batch    20 | loss: 140.5807215CurrentTrain: epoch  1, batch    21 | loss: 79.2359260CurrentTrain: epoch  1, batch    22 | loss: 75.2222260CurrentTrain: epoch  1, batch    23 | loss: 89.5570312CurrentTrain: epoch  1, batch    24 | loss: 135.0164095CurrentTrain: epoch  1, batch    25 | loss: 91.0068620CurrentTrain: epoch  1, batch    26 | loss: 65.5059333CurrentTrain: epoch  1, batch    27 | loss: 75.5025897CurrentTrain: epoch  1, batch    28 | loss: 65.5450608CurrentTrain: epoch  1, batch    29 | loss: 66.7410771CurrentTrain: epoch  1, batch    30 | loss: 92.2867289CurrentTrain: epoch  1, batch    31 | loss: 89.8156154CurrentTrain: epoch  1, batch    32 | loss: 110.5913209CurrentTrain: epoch  1, batch    33 | loss: 93.6476509CurrentTrain: epoch  1, batch    34 | loss: 102.9301412CurrentTrain: epoch  1, batch    35 | loss: 137.7852367CurrentTrain: epoch  1, batch    36 | loss: 77.8870520CurrentTrain: epoch  1, batch    37 | loss: 88.9539746CurrentTrain: epoch  1, batch    38 | loss: 93.0017128CurrentTrain: epoch  1, batch    39 | loss: 65.6789405CurrentTrain: epoch  1, batch    40 | loss: 72.7117838CurrentTrain: epoch  1, batch    41 | loss: 74.2114984CurrentTrain: epoch  1, batch    42 | loss: 80.7905707CurrentTrain: epoch  1, batch    43 | loss: 89.1067885CurrentTrain: epoch  1, batch    44 | loss: 135.1759597CurrentTrain: epoch  1, batch    45 | loss: 89.8770850CurrentTrain: epoch  1, batch    46 | loss: 109.1201833CurrentTrain: epoch  1, batch    47 | loss: 72.6396539CurrentTrain: epoch  1, batch    48 | loss: 90.9544480CurrentTrain: epoch  1, batch    49 | loss: 91.6906317CurrentTrain: epoch  1, batch    50 | loss: 88.0424145CurrentTrain: epoch  1, batch    51 | loss: 113.0778987CurrentTrain: epoch  1, batch    52 | loss: 111.5028630CurrentTrain: epoch  1, batch    53 | loss: 135.5812074CurrentTrain: epoch  1, batch    54 | loss: 78.8930255CurrentTrain: epoch  1, batch    55 | loss: 90.9670416CurrentTrain: epoch  1, batch    56 | loss: 88.6030334CurrentTrain: epoch  1, batch    57 | loss: 107.3992212CurrentTrain: epoch  1, batch    58 | loss: 91.3898529CurrentTrain: epoch  1, batch    59 | loss: 74.9852433CurrentTrain: epoch  1, batch    60 | loss: 87.2601028CurrentTrain: epoch  1, batch    61 | loss: 133.8989591CurrentTrain: epoch  1, batch    62 | loss: 140.6456160CurrentTrain: epoch  1, batch    63 | loss: 73.6870411CurrentTrain: epoch  1, batch    64 | loss: 88.9374005CurrentTrain: epoch  1, batch    65 | loss: 109.4748078CurrentTrain: epoch  1, batch    66 | loss: 66.5595051CurrentTrain: epoch  1, batch    67 | loss: 136.0609080CurrentTrain: epoch  1, batch    68 | loss: 72.8028531CurrentTrain: epoch  1, batch    69 | loss: 81.0227116CurrentTrain: epoch  1, batch    70 | loss: 72.4734712CurrentTrain: epoch  1, batch    71 | loss: 87.2175823CurrentTrain: epoch  1, batch    72 | loss: 108.0751850CurrentTrain: epoch  1, batch    73 | loss: 100.9566707CurrentTrain: epoch  1, batch    74 | loss: 105.3580134CurrentTrain: epoch  1, batch    75 | loss: 86.4147624CurrentTrain: epoch  1, batch    76 | loss: 92.6486245CurrentTrain: epoch  1, batch    77 | loss: 91.1797280CurrentTrain: epoch  1, batch    78 | loss: 86.0920149CurrentTrain: epoch  1, batch    79 | loss: 89.7242693CurrentTrain: epoch  1, batch    80 | loss: 67.1529600CurrentTrain: epoch  1, batch    81 | loss: 103.4795334CurrentTrain: epoch  1, batch    82 | loss: 75.6835877CurrentTrain: epoch  1, batch    83 | loss: 184.3876974CurrentTrain: epoch  1, batch    84 | loss: 106.1153472CurrentTrain: epoch  1, batch    85 | loss: 72.3428410CurrentTrain: epoch  1, batch    86 | loss: 66.0492672CurrentTrain: epoch  1, batch    87 | loss: 77.2135334CurrentTrain: epoch  1, batch    88 | loss: 109.0449549CurrentTrain: epoch  1, batch    89 | loss: 87.2057957CurrentTrain: epoch  1, batch    90 | loss: 75.9403251CurrentTrain: epoch  1, batch    91 | loss: 88.2388825CurrentTrain: epoch  1, batch    92 | loss: 88.8474997CurrentTrain: epoch  1, batch    93 | loss: 136.8480256CurrentTrain: epoch  1, batch    94 | loss: 92.4356289CurrentTrain: epoch  1, batch    95 | loss: 69.4548275CurrentTrain: epoch  2, batch     0 | loss: 63.4179919CurrentTrain: epoch  2, batch     1 | loss: 105.3412329CurrentTrain: epoch  2, batch     2 | loss: 88.3243163CurrentTrain: epoch  2, batch     3 | loss: 91.0623958CurrentTrain: epoch  2, batch     4 | loss: 137.3153779CurrentTrain: epoch  2, batch     5 | loss: 72.6298831CurrentTrain: epoch  2, batch     6 | loss: 130.1664093CurrentTrain: epoch  2, batch     7 | loss: 83.5210488CurrentTrain: epoch  2, batch     8 | loss: 107.4258483CurrentTrain: epoch  2, batch     9 | loss: 62.5708276CurrentTrain: epoch  2, batch    10 | loss: 101.7330300CurrentTrain: epoch  2, batch    11 | loss: 61.9300909CurrentTrain: epoch  2, batch    12 | loss: 65.8920099CurrentTrain: epoch  2, batch    13 | loss: 103.9706789CurrentTrain: epoch  2, batch    14 | loss: 107.3455627CurrentTrain: epoch  2, batch    15 | loss: 109.2078491CurrentTrain: epoch  2, batch    16 | loss: 82.9385119CurrentTrain: epoch  2, batch    17 | loss: 89.2849051CurrentTrain: epoch  2, batch    18 | loss: 85.0826932CurrentTrain: epoch  2, batch    19 | loss: 104.1198872CurrentTrain: epoch  2, batch    20 | loss: 74.7663970CurrentTrain: epoch  2, batch    21 | loss: 103.3830726CurrentTrain: epoch  2, batch    22 | loss: 75.5686216CurrentTrain: epoch  2, batch    23 | loss: 85.4081056CurrentTrain: epoch  2, batch    24 | loss: 83.1861537CurrentTrain: epoch  2, batch    25 | loss: 84.1530047CurrentTrain: epoch  2, batch    26 | loss: 88.6894539CurrentTrain: epoch  2, batch    27 | loss: 80.8255949CurrentTrain: epoch  2, batch    28 | loss: 106.1210026CurrentTrain: epoch  2, batch    29 | loss: 102.5406908CurrentTrain: epoch  2, batch    30 | loss: 88.8561999CurrentTrain: epoch  2, batch    31 | loss: 85.4906884CurrentTrain: epoch  2, batch    32 | loss: 77.2799920CurrentTrain: epoch  2, batch    33 | loss: 109.4484495CurrentTrain: epoch  2, batch    34 | loss: 106.6219284CurrentTrain: epoch  2, batch    35 | loss: 103.6409224CurrentTrain: epoch  2, batch    36 | loss: 87.7884528CurrentTrain: epoch  2, batch    37 | loss: 102.3755579CurrentTrain: epoch  2, batch    38 | loss: 73.4799887CurrentTrain: epoch  2, batch    39 | loss: 106.1769631CurrentTrain: epoch  2, batch    40 | loss: 61.8865371CurrentTrain: epoch  2, batch    41 | loss: 108.1907111CurrentTrain: epoch  2, batch    42 | loss: 103.3865278CurrentTrain: epoch  2, batch    43 | loss: 75.6592408CurrentTrain: epoch  2, batch    44 | loss: 84.4646692CurrentTrain: epoch  2, batch    45 | loss: 74.6728297CurrentTrain: epoch  2, batch    46 | loss: 89.0068021CurrentTrain: epoch  2, batch    47 | loss: 76.2878906CurrentTrain: epoch  2, batch    48 | loss: 133.6648888CurrentTrain: epoch  2, batch    49 | loss: 134.4517165CurrentTrain: epoch  2, batch    50 | loss: 70.4502967CurrentTrain: epoch  2, batch    51 | loss: 137.5350594CurrentTrain: epoch  2, batch    52 | loss: 73.9044927CurrentTrain: epoch  2, batch    53 | loss: 89.7699520CurrentTrain: epoch  2, batch    54 | loss: 107.3909924CurrentTrain: epoch  2, batch    55 | loss: 86.7622580CurrentTrain: epoch  2, batch    56 | loss: 84.9023193CurrentTrain: epoch  2, batch    57 | loss: 70.3326004CurrentTrain: epoch  2, batch    58 | loss: 76.3343635CurrentTrain: epoch  2, batch    59 | loss: 73.5174947CurrentTrain: epoch  2, batch    60 | loss: 86.2920110CurrentTrain: epoch  2, batch    61 | loss: 69.7017907CurrentTrain: epoch  2, batch    62 | loss: 84.0696971CurrentTrain: epoch  2, batch    63 | loss: 71.4451823CurrentTrain: epoch  2, batch    64 | loss: 70.5004314CurrentTrain: epoch  2, batch    65 | loss: 85.4816932CurrentTrain: epoch  2, batch    66 | loss: 136.1844781CurrentTrain: epoch  2, batch    67 | loss: 106.6325354CurrentTrain: epoch  2, batch    68 | loss: 72.3551157CurrentTrain: epoch  2, batch    69 | loss: 70.4267502CurrentTrain: epoch  2, batch    70 | loss: 89.8599383CurrentTrain: epoch  2, batch    71 | loss: 72.9918836CurrentTrain: epoch  2, batch    72 | loss: 183.4414795CurrentTrain: epoch  2, batch    73 | loss: 86.6637856CurrentTrain: epoch  2, batch    74 | loss: 84.8372033CurrentTrain: epoch  2, batch    75 | loss: 84.5903745CurrentTrain: epoch  2, batch    76 | loss: 103.2660769CurrentTrain: epoch  2, batch    77 | loss: 63.5318322CurrentTrain: epoch  2, batch    78 | loss: 89.7297141CurrentTrain: epoch  2, batch    79 | loss: 84.7980599CurrentTrain: epoch  2, batch    80 | loss: 70.9325428CurrentTrain: epoch  2, batch    81 | loss: 87.9199839CurrentTrain: epoch  2, batch    82 | loss: 107.5052893CurrentTrain: epoch  2, batch    83 | loss: 107.0566054CurrentTrain: epoch  2, batch    84 | loss: 74.9873386CurrentTrain: epoch  2, batch    85 | loss: 135.4106780CurrentTrain: epoch  2, batch    86 | loss: 62.3271610CurrentTrain: epoch  2, batch    87 | loss: 63.3485352CurrentTrain: epoch  2, batch    88 | loss: 65.4891245CurrentTrain: epoch  2, batch    89 | loss: 100.9759242CurrentTrain: epoch  2, batch    90 | loss: 85.8036974CurrentTrain: epoch  2, batch    91 | loss: 75.8567062CurrentTrain: epoch  2, batch    92 | loss: 74.4626134CurrentTrain: epoch  2, batch    93 | loss: 87.9881775CurrentTrain: epoch  2, batch    94 | loss: 86.3258672CurrentTrain: epoch  2, batch    95 | loss: 72.6346423CurrentTrain: epoch  3, batch     0 | loss: 85.4345908CurrentTrain: epoch  3, batch     1 | loss: 102.4067955CurrentTrain: epoch  3, batch     2 | loss: 86.6896994CurrentTrain: epoch  3, batch     3 | loss: 89.0392953CurrentTrain: epoch  3, batch     4 | loss: 82.2052503CurrentTrain: epoch  3, batch     5 | loss: 100.2888207CurrentTrain: epoch  3, batch     6 | loss: 81.8916888CurrentTrain: epoch  3, batch     7 | loss: 62.7705242CurrentTrain: epoch  3, batch     8 | loss: 73.7004653CurrentTrain: epoch  3, batch     9 | loss: 126.1661371CurrentTrain: epoch  3, batch    10 | loss: 75.3918465CurrentTrain: epoch  3, batch    11 | loss: 81.2288000CurrentTrain: epoch  3, batch    12 | loss: 104.1574157CurrentTrain: epoch  3, batch    13 | loss: 104.1145559CurrentTrain: epoch  3, batch    14 | loss: 84.6820450CurrentTrain: epoch  3, batch    15 | loss: 104.5152450CurrentTrain: epoch  3, batch    16 | loss: 100.2433379CurrentTrain: epoch  3, batch    17 | loss: 68.4632025CurrentTrain: epoch  3, batch    18 | loss: 72.6714697CurrentTrain: epoch  3, batch    19 | loss: 74.2209258CurrentTrain: epoch  3, batch    20 | loss: 105.8653697CurrentTrain: epoch  3, batch    21 | loss: 81.2738641CurrentTrain: epoch  3, batch    22 | loss: 106.8984357CurrentTrain: epoch  3, batch    23 | loss: 87.0227552CurrentTrain: epoch  3, batch    24 | loss: 71.6706807CurrentTrain: epoch  3, batch    25 | loss: 86.0789212CurrentTrain: epoch  3, batch    26 | loss: 104.3589262CurrentTrain: epoch  3, batch    27 | loss: 106.7962740CurrentTrain: epoch  3, batch    28 | loss: 104.3768388CurrentTrain: epoch  3, batch    29 | loss: 74.4693645CurrentTrain: epoch  3, batch    30 | loss: 90.0149718CurrentTrain: epoch  3, batch    31 | loss: 82.6896702CurrentTrain: epoch  3, batch    32 | loss: 83.4133992CurrentTrain: epoch  3, batch    33 | loss: 131.6053776CurrentTrain: epoch  3, batch    34 | loss: 85.6067765CurrentTrain: epoch  3, batch    35 | loss: 126.0182715CurrentTrain: epoch  3, batch    36 | loss: 60.7419322CurrentTrain: epoch  3, batch    37 | loss: 129.7861460CurrentTrain: epoch  3, batch    38 | loss: 67.2142303CurrentTrain: epoch  3, batch    39 | loss: 87.6949364CurrentTrain: epoch  3, batch    40 | loss: 82.6831287CurrentTrain: epoch  3, batch    41 | loss: 82.2010751CurrentTrain: epoch  3, batch    42 | loss: 86.8612140CurrentTrain: epoch  3, batch    43 | loss: 70.3809975CurrentTrain: epoch  3, batch    44 | loss: 65.9713190CurrentTrain: epoch  3, batch    45 | loss: 72.2163749CurrentTrain: epoch  3, batch    46 | loss: 103.7812792CurrentTrain: epoch  3, batch    47 | loss: 87.8174404CurrentTrain: epoch  3, batch    48 | loss: 131.4693257CurrentTrain: epoch  3, batch    49 | loss: 62.4608085CurrentTrain: epoch  3, batch    50 | loss: 73.5455477CurrentTrain: epoch  3, batch    51 | loss: 76.0261660CurrentTrain: epoch  3, batch    52 | loss: 134.0221814CurrentTrain: epoch  3, batch    53 | loss: 74.4642142CurrentTrain: epoch  3, batch    54 | loss: 104.0403481CurrentTrain: epoch  3, batch    55 | loss: 79.5389515CurrentTrain: epoch  3, batch    56 | loss: 72.0734643CurrentTrain: epoch  3, batch    57 | loss: 74.2107424CurrentTrain: epoch  3, batch    58 | loss: 84.2443936CurrentTrain: epoch  3, batch    59 | loss: 128.8055280CurrentTrain: epoch  3, batch    60 | loss: 85.9526256CurrentTrain: epoch  3, batch    61 | loss: 70.6475245CurrentTrain: epoch  3, batch    62 | loss: 80.0757656CurrentTrain: epoch  3, batch    63 | loss: 103.4006459CurrentTrain: epoch  3, batch    64 | loss: 81.3206019CurrentTrain: epoch  3, batch    65 | loss: 104.0162811CurrentTrain: epoch  3, batch    66 | loss: 105.2332903CurrentTrain: epoch  3, batch    67 | loss: 71.5006605CurrentTrain: epoch  3, batch    68 | loss: 84.5661620CurrentTrain: epoch  3, batch    69 | loss: 68.6888129CurrentTrain: epoch  3, batch    70 | loss: 83.6784174CurrentTrain: epoch  3, batch    71 | loss: 59.7391673CurrentTrain: epoch  3, batch    72 | loss: 73.8539291CurrentTrain: epoch  3, batch    73 | loss: 57.9349392CurrentTrain: epoch  3, batch    74 | loss: 86.7301418CurrentTrain: epoch  3, batch    75 | loss: 107.0455632CurrentTrain: epoch  3, batch    76 | loss: 97.2101129CurrentTrain: epoch  3, batch    77 | loss: 85.5041418CurrentTrain: epoch  3, batch    78 | loss: 127.8492361CurrentTrain: epoch  3, batch    79 | loss: 80.8536111CurrentTrain: epoch  3, batch    80 | loss: 103.8694342CurrentTrain: epoch  3, batch    81 | loss: 61.9792038CurrentTrain: epoch  3, batch    82 | loss: 108.9887492CurrentTrain: epoch  3, batch    83 | loss: 81.6742814CurrentTrain: epoch  3, batch    84 | loss: 71.5581730CurrentTrain: epoch  3, batch    85 | loss: 109.0960668CurrentTrain: epoch  3, batch    86 | loss: 72.1665372CurrentTrain: epoch  3, batch    87 | loss: 85.2290824CurrentTrain: epoch  3, batch    88 | loss: 68.2081834CurrentTrain: epoch  3, batch    89 | loss: 70.0068698CurrentTrain: epoch  3, batch    90 | loss: 96.6839500CurrentTrain: epoch  3, batch    91 | loss: 100.5480913CurrentTrain: epoch  3, batch    92 | loss: 75.4001199CurrentTrain: epoch  3, batch    93 | loss: 84.9038277CurrentTrain: epoch  3, batch    94 | loss: 106.4513007CurrentTrain: epoch  3, batch    95 | loss: 54.9325027CurrentTrain: epoch  4, batch     0 | loss: 81.1067645CurrentTrain: epoch  4, batch     1 | loss: 104.3861671CurrentTrain: epoch  4, batch     2 | loss: 98.6472896CurrentTrain: epoch  4, batch     3 | loss: 76.2860548CurrentTrain: epoch  4, batch     4 | loss: 131.8534710CurrentTrain: epoch  4, batch     5 | loss: 97.1338891CurrentTrain: epoch  4, batch     6 | loss: 71.1869576CurrentTrain: epoch  4, batch     7 | loss: 66.9419358CurrentTrain: epoch  4, batch     8 | loss: 103.4183356CurrentTrain: epoch  4, batch     9 | loss: 130.5160799CurrentTrain: epoch  4, batch    10 | loss: 103.2169919CurrentTrain: epoch  4, batch    11 | loss: 70.2957007CurrentTrain: epoch  4, batch    12 | loss: 82.2184693CurrentTrain: epoch  4, batch    13 | loss: 71.6156626CurrentTrain: epoch  4, batch    14 | loss: 80.7891469CurrentTrain: epoch  4, batch    15 | loss: 102.4055871CurrentTrain: epoch  4, batch    16 | loss: 99.8233813CurrentTrain: epoch  4, batch    17 | loss: 128.7796464CurrentTrain: epoch  4, batch    18 | loss: 80.6476332CurrentTrain: epoch  4, batch    19 | loss: 81.4350176CurrentTrain: epoch  4, batch    20 | loss: 77.6983381CurrentTrain: epoch  4, batch    21 | loss: 70.8343552CurrentTrain: epoch  4, batch    22 | loss: 104.6203406CurrentTrain: epoch  4, batch    23 | loss: 74.4442403CurrentTrain: epoch  4, batch    24 | loss: 94.2287410CurrentTrain: epoch  4, batch    25 | loss: 104.1736310CurrentTrain: epoch  4, batch    26 | loss: 84.8932074CurrentTrain: epoch  4, batch    27 | loss: 63.3367270CurrentTrain: epoch  4, batch    28 | loss: 96.6286482CurrentTrain: epoch  4, batch    29 | loss: 83.4299986CurrentTrain: epoch  4, batch    30 | loss: 86.3519376CurrentTrain: epoch  4, batch    31 | loss: 72.6042557CurrentTrain: epoch  4, batch    32 | loss: 95.7772228CurrentTrain: epoch  4, batch    33 | loss: 57.7661126CurrentTrain: epoch  4, batch    34 | loss: 101.5214088CurrentTrain: epoch  4, batch    35 | loss: 84.0063952CurrentTrain: epoch  4, batch    36 | loss: 71.3843043CurrentTrain: epoch  4, batch    37 | loss: 61.9402637CurrentTrain: epoch  4, batch    38 | loss: 84.1438285CurrentTrain: epoch  4, batch    39 | loss: 72.7941118CurrentTrain: epoch  4, batch    40 | loss: 83.1670254CurrentTrain: epoch  4, batch    41 | loss: 70.3498027CurrentTrain: epoch  4, batch    42 | loss: 86.0497096CurrentTrain: epoch  4, batch    43 | loss: 60.3477335CurrentTrain: epoch  4, batch    44 | loss: 68.0686116CurrentTrain: epoch  4, batch    45 | loss: 84.5939716CurrentTrain: epoch  4, batch    46 | loss: 72.1800875CurrentTrain: epoch  4, batch    47 | loss: 99.6068116CurrentTrain: epoch  4, batch    48 | loss: 75.0622142CurrentTrain: epoch  4, batch    49 | loss: 83.4121321CurrentTrain: epoch  4, batch    50 | loss: 78.2632444CurrentTrain: epoch  4, batch    51 | loss: 72.3722235CurrentTrain: epoch  4, batch    52 | loss: 81.8615752CurrentTrain: epoch  4, batch    53 | loss: 126.3470091CurrentTrain: epoch  4, batch    54 | loss: 82.8321973CurrentTrain: epoch  4, batch    55 | loss: 103.1597227CurrentTrain: epoch  4, batch    56 | loss: 131.2159988CurrentTrain: epoch  4, batch    57 | loss: 72.0740988CurrentTrain: epoch  4, batch    58 | loss: 127.2452136CurrentTrain: epoch  4, batch    59 | loss: 100.9895417CurrentTrain: epoch  4, batch    60 | loss: 83.4778181CurrentTrain: epoch  4, batch    61 | loss: 59.7416938CurrentTrain: epoch  4, batch    62 | loss: 58.4163576CurrentTrain: epoch  4, batch    63 | loss: 69.2934526CurrentTrain: epoch  4, batch    64 | loss: 85.0279966CurrentTrain: epoch  4, batch    65 | loss: 126.1825924CurrentTrain: epoch  4, batch    66 | loss: 73.6599082CurrentTrain: epoch  4, batch    67 | loss: 71.3354621CurrentTrain: epoch  4, batch    68 | loss: 102.1689717CurrentTrain: epoch  4, batch    69 | loss: 70.9268782CurrentTrain: epoch  4, batch    70 | loss: 92.7532242CurrentTrain: epoch  4, batch    71 | loss: 103.2601298CurrentTrain: epoch  4, batch    72 | loss: 67.3307435CurrentTrain: epoch  4, batch    73 | loss: 74.1509096CurrentTrain: epoch  4, batch    74 | loss: 131.7394278CurrentTrain: epoch  4, batch    75 | loss: 82.8579905CurrentTrain: epoch  4, batch    76 | loss: 132.2811052CurrentTrain: epoch  4, batch    77 | loss: 100.6201203CurrentTrain: epoch  4, batch    78 | loss: 69.8349118CurrentTrain: epoch  4, batch    79 | loss: 98.8026074CurrentTrain: epoch  4, batch    80 | loss: 72.3245782CurrentTrain: epoch  4, batch    81 | loss: 131.0829773CurrentTrain: epoch  4, batch    82 | loss: 79.9423775CurrentTrain: epoch  4, batch    83 | loss: 71.7482852CurrentTrain: epoch  4, batch    84 | loss: 75.9193322CurrentTrain: epoch  4, batch    85 | loss: 84.2641555CurrentTrain: epoch  4, batch    86 | loss: 109.4590146CurrentTrain: epoch  4, batch    87 | loss: 124.9256907CurrentTrain: epoch  4, batch    88 | loss: 101.9260820CurrentTrain: epoch  4, batch    89 | loss: 71.3338159CurrentTrain: epoch  4, batch    90 | loss: 120.7043484CurrentTrain: epoch  4, batch    91 | loss: 96.4153992CurrentTrain: epoch  4, batch    92 | loss: 85.6477248CurrentTrain: epoch  4, batch    93 | loss: 80.0703346CurrentTrain: epoch  4, batch    94 | loss: 89.7889828CurrentTrain: epoch  4, batch    95 | loss: 60.0235350CurrentTrain: epoch  5, batch     0 | loss: 80.6608153CurrentTrain: epoch  5, batch     1 | loss: 82.3898790CurrentTrain: epoch  5, batch     2 | loss: 98.5728908CurrentTrain: epoch  5, batch     3 | loss: 84.2219624CurrentTrain: epoch  5, batch     4 | loss: 79.6589105CurrentTrain: epoch  5, batch     5 | loss: 68.1178830CurrentTrain: epoch  5, batch     6 | loss: 127.6138403CurrentTrain: epoch  5, batch     7 | loss: 79.5686997CurrentTrain: epoch  5, batch     8 | loss: 81.1203848CurrentTrain: epoch  5, batch     9 | loss: 79.0475527CurrentTrain: epoch  5, batch    10 | loss: 70.9278638CurrentTrain: epoch  5, batch    11 | loss: 102.5709273CurrentTrain: epoch  5, batch    12 | loss: 131.8062483CurrentTrain: epoch  5, batch    13 | loss: 67.2445907CurrentTrain: epoch  5, batch    14 | loss: 97.1515044CurrentTrain: epoch  5, batch    15 | loss: 65.9366591CurrentTrain: epoch  5, batch    16 | loss: 82.4703617CurrentTrain: epoch  5, batch    17 | loss: 67.5182426CurrentTrain: epoch  5, batch    18 | loss: 83.2127579