#############params############
cuda
Task=Tacred, 5-shot
Encoding model: bert
pattern=hybridprompt
mem=1, margin=0.3, gen=0, gen_num=2
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
#############params############
cuda
Task=Tacred, 5-shot
Encoding model: bert
pattern=hybridprompt
mem=1, margin=0.3, gen=0, gen_num=2
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 127.4410230CurrentTrain: epoch  0, batch     1 | loss: 91.0480700CurrentTrain: epoch  0, batch     2 | loss: 78.5039682CurrentTrain: epoch  0, batch     3 | loss: 88.2306910CurrentTrain: epoch  0, batch     4 | loss: 87.3597513CurrentTrain: epoch  0, batch     5 | loss: 87.4418091CurrentTrain: epoch  0, batch     6 | loss: 101.8835287CurrentTrain: epoch  0, batch     7 | loss: 100.6150611CurrentTrain: epoch  0, batch     8 | loss: 86.3544628CurrentTrain: epoch  0, batch     9 | loss: 86.4705513CurrentTrain: epoch  0, batch    10 | loss: 77.2608740CurrentTrain: epoch  0, batch    11 | loss: 100.9790722CurrentTrain: epoch  0, batch    12 | loss: 99.3914943CurrentTrain: epoch  0, batch    13 | loss: 193.1445742CurrentTrain: epoch  0, batch    14 | loss: 100.3338364CurrentTrain: epoch  0, batch    15 | loss: 86.2700722CurrentTrain: epoch  0, batch    16 | loss: 86.6955689CurrentTrain: epoch  0, batch    17 | loss: 118.3794258CurrentTrain: epoch  0, batch    18 | loss: 99.9756678CurrentTrain: epoch  0, batch    19 | loss: 86.3320767CurrentTrain: epoch  0, batch    20 | loss: 146.9150817CurrentTrain: epoch  0, batch    21 | loss: 146.1959342CurrentTrain: epoch  0, batch    22 | loss: 193.1894195CurrentTrain: epoch  0, batch    23 | loss: 145.9490238CurrentTrain: epoch  0, batch    24 | loss: 99.6026530CurrentTrain: epoch  0, batch    25 | loss: 192.7196244CurrentTrain: epoch  0, batch    26 | loss: 86.0092776CurrentTrain: epoch  0, batch    27 | loss: 117.8975299CurrentTrain: epoch  0, batch    28 | loss: 145.6390192CurrentTrain: epoch  0, batch    29 | loss: 98.7139077CurrentTrain: epoch  0, batch    30 | loss: 145.6671623CurrentTrain: epoch  0, batch    31 | loss: 145.4222380CurrentTrain: epoch  0, batch    32 | loss: 117.6100639CurrentTrain: epoch  0, batch    33 | loss: 85.5126644CurrentTrain: epoch  0, batch    34 | loss: 146.5690565CurrentTrain: epoch  0, batch    35 | loss: 84.9825595CurrentTrain: epoch  0, batch    36 | loss: 84.7571527CurrentTrain: epoch  0, batch    37 | loss: 98.5992710CurrentTrain: epoch  0, batch    38 | loss: 98.1671784CurrentTrain: epoch  0, batch    39 | loss: 85.1203110CurrentTrain: epoch  0, batch    40 | loss: 117.5720920CurrentTrain: epoch  0, batch    41 | loss: 85.5919577CurrentTrain: epoch  0, batch    42 | loss: 84.6573954CurrentTrain: epoch  0, batch    43 | loss: 74.3712639CurrentTrain: epoch  0, batch    44 | loss: 98.0891050CurrentTrain: epoch  0, batch    45 | loss: 82.7940821CurrentTrain: epoch  0, batch    46 | loss: 115.0650167CurrentTrain: epoch  0, batch    47 | loss: 83.8726932CurrentTrain: epoch  0, batch    48 | loss: 97.4309193CurrentTrain: epoch  0, batch    49 | loss: 97.1130939CurrentTrain: epoch  0, batch    50 | loss: 96.9793131CurrentTrain: epoch  0, batch    51 | loss: 97.8810438CurrentTrain: epoch  0, batch    52 | loss: 96.9075258CurrentTrain: epoch  0, batch    53 | loss: 142.9276334CurrentTrain: epoch  0, batch    54 | loss: 116.0490714CurrentTrain: epoch  0, batch    55 | loss: 82.5294288CurrentTrain: epoch  0, batch    56 | loss: 83.6886005CurrentTrain: epoch  0, batch    57 | loss: 95.5699823CurrentTrain: epoch  0, batch    58 | loss: 94.7212865CurrentTrain: epoch  0, batch    59 | loss: 95.2854462CurrentTrain: epoch  0, batch    60 | loss: 93.6369534CurrentTrain: epoch  0, batch    61 | loss: 95.9668130CurrentTrain: epoch  0, batch    62 | loss: 83.0474007CurrentTrain: epoch  0, batch    63 | loss: 111.9088113CurrentTrain: epoch  0, batch    64 | loss: 95.4962419CurrentTrain: epoch  0, batch    65 | loss: 71.6006295CurrentTrain: epoch  0, batch    66 | loss: 91.0208241CurrentTrain: epoch  0, batch    67 | loss: 94.6509428CurrentTrain: epoch  0, batch    68 | loss: 82.4460170CurrentTrain: epoch  0, batch    69 | loss: 141.7931871CurrentTrain: epoch  0, batch    70 | loss: 117.3976788CurrentTrain: epoch  0, batch    71 | loss: 82.6429040CurrentTrain: epoch  0, batch    72 | loss: 96.9215303CurrentTrain: epoch  0, batch    73 | loss: 112.8935680CurrentTrain: epoch  0, batch    74 | loss: 142.3137826CurrentTrain: epoch  0, batch    75 | loss: 95.0093896CurrentTrain: epoch  0, batch    76 | loss: 110.2806840CurrentTrain: epoch  0, batch    77 | loss: 92.8881420CurrentTrain: epoch  0, batch    78 | loss: 112.6259908CurrentTrain: epoch  0, batch    79 | loss: 111.0747893CurrentTrain: epoch  0, batch    80 | loss: 79.2325594CurrentTrain: epoch  0, batch    81 | loss: 92.2656268CurrentTrain: epoch  0, batch    82 | loss: 111.3827867CurrentTrain: epoch  0, batch    83 | loss: 93.8524811CurrentTrain: epoch  0, batch    84 | loss: 107.6148623CurrentTrain: epoch  0, batch    85 | loss: 79.7292917CurrentTrain: epoch  0, batch    86 | loss: 137.4133697CurrentTrain: epoch  0, batch    87 | loss: 81.6693731CurrentTrain: epoch  0, batch    88 | loss: 80.0372756CurrentTrain: epoch  0, batch    89 | loss: 66.0136631CurrentTrain: epoch  0, batch    90 | loss: 93.0795031CurrentTrain: epoch  0, batch    91 | loss: 80.1683889CurrentTrain: epoch  0, batch    92 | loss: 90.4279237CurrentTrain: epoch  0, batch    93 | loss: 135.2179367CurrentTrain: epoch  0, batch    94 | loss: 80.2209518CurrentTrain: epoch  0, batch    95 | loss: 93.3847882CurrentTrain: epoch  1, batch     0 | loss: 79.2728474CurrentTrain: epoch  1, batch     1 | loss: 93.0304749CurrentTrain: epoch  1, batch     2 | loss: 78.2925054CurrentTrain: epoch  1, batch     3 | loss: 79.3197106CurrentTrain: epoch  1, batch     4 | loss: 88.3923469CurrentTrain: epoch  1, batch     5 | loss: 75.7498483CurrentTrain: epoch  1, batch     6 | loss: 94.6735150CurrentTrain: epoch  1, batch     7 | loss: 137.9167320CurrentTrain: epoch  1, batch     8 | loss: 69.9168658CurrentTrain: epoch  1, batch     9 | loss: 107.1252333CurrentTrain: epoch  1, batch    10 | loss: 90.3770987CurrentTrain: epoch  1, batch    11 | loss: 77.4831686CurrentTrain: epoch  1, batch    12 | loss: 75.7594529CurrentTrain: epoch  1, batch    13 | loss: 109.9826580CurrentTrain: epoch  1, batch    14 | loss: 105.4587419CurrentTrain: epoch  1, batch    15 | loss: 93.1282293CurrentTrain: epoch  1, batch    16 | loss: 135.2772798CurrentTrain: epoch  1, batch    17 | loss: 76.2209803CurrentTrain: epoch  1, batch    18 | loss: 86.6365119CurrentTrain: epoch  1, batch    19 | loss: 110.0454511CurrentTrain: epoch  1, batch    20 | loss: 140.5806177CurrentTrain: epoch  1, batch    21 | loss: 79.2360952CurrentTrain: epoch  1, batch    22 | loss: 75.2222301CurrentTrain: epoch  1, batch    23 | loss: 89.5573302CurrentTrain: epoch  1, batch    24 | loss: 135.0166943CurrentTrain: epoch  1, batch    25 | loss: 91.0070666CurrentTrain: epoch  1, batch    26 | loss: 65.5059814CurrentTrain: epoch  1, batch    27 | loss: 75.5030567CurrentTrain: epoch  1, batch    28 | loss: 65.5448904CurrentTrain: epoch  1, batch    29 | loss: 66.7413551CurrentTrain: epoch  1, batch    30 | loss: 92.2867099CurrentTrain: epoch  1, batch    31 | loss: 89.8149591CurrentTrain: epoch  1, batch    32 | loss: 110.5912834CurrentTrain: epoch  1, batch    33 | loss: 93.6483349CurrentTrain: epoch  1, batch    34 | loss: 102.9321325CurrentTrain: epoch  1, batch    35 | loss: 137.7852846CurrentTrain: epoch  1, batch    36 | loss: 77.8865162CurrentTrain: epoch  1, batch    37 | loss: 88.9547066CurrentTrain: epoch  1, batch    38 | loss: 93.0016176CurrentTrain: epoch  1, batch    39 | loss: 65.6787689CurrentTrain: epoch  1, batch    40 | loss: 72.7116115CurrentTrain: epoch  1, batch    41 | loss: 74.2121072CurrentTrain: epoch  1, batch    42 | loss: 80.7923512CurrentTrain: epoch  1, batch    43 | loss: 89.1075067CurrentTrain: epoch  1, batch    44 | loss: 135.1768822CurrentTrain: epoch  1, batch    45 | loss: 89.8748217CurrentTrain: epoch  1, batch    46 | loss: 109.1175136CurrentTrain: epoch  1, batch    47 | loss: 72.6402242CurrentTrain: epoch  1, batch    48 | loss: 90.9530771CurrentTrain: epoch  1, batch    49 | loss: 91.6938125CurrentTrain: epoch  1, batch    50 | loss: 88.0385463CurrentTrain: epoch  1, batch    51 | loss: 113.0821216CurrentTrain: epoch  1, batch    52 | loss: 111.4875992CurrentTrain: epoch  1, batch    53 | loss: 135.5846528CurrentTrain: epoch  1, batch    54 | loss: 78.8999400CurrentTrain: epoch  1, batch    55 | loss: 90.9987463CurrentTrain: epoch  1, batch    56 | loss: 88.5948102CurrentTrain: epoch  1, batch    57 | loss: 107.3849005CurrentTrain: epoch  1, batch    58 | loss: 91.4185134CurrentTrain: epoch  1, batch    59 | loss: 75.0004885CurrentTrain: epoch  1, batch    60 | loss: 87.2501229CurrentTrain: epoch  1, batch    61 | loss: 133.9730345CurrentTrain: epoch  1, batch    62 | loss: 140.6135645CurrentTrain: epoch  1, batch    63 | loss: 73.7124995CurrentTrain: epoch  1, batch    64 | loss: 88.9688862CurrentTrain: epoch  1, batch    65 | loss: 109.4250656CurrentTrain: epoch  1, batch    66 | loss: 66.5575663CurrentTrain: epoch  1, batch    67 | loss: 136.0537203CurrentTrain: epoch  1, batch    68 | loss: 72.8357402CurrentTrain: epoch  1, batch    69 | loss: 81.0275248CurrentTrain: epoch  1, batch    70 | loss: 72.4596581CurrentTrain: epoch  1, batch    71 | loss: 87.2322013CurrentTrain: epoch  1, batch    72 | loss: 108.1030312CurrentTrain: epoch  1, batch    73 | loss: 100.9953653CurrentTrain: epoch  1, batch    74 | loss: 105.3776373CurrentTrain: epoch  1, batch    75 | loss: 86.3964810CurrentTrain: epoch  1, batch    76 | loss: 92.6446889CurrentTrain: epoch  1, batch    77 | loss: 91.2157069CurrentTrain: epoch  1, batch    78 | loss: 86.1054693CurrentTrain: epoch  1, batch    79 | loss: 89.6693580CurrentTrain: epoch  1, batch    80 | loss: 67.1202136CurrentTrain: epoch  1, batch    81 | loss: 103.4576568CurrentTrain: epoch  1, batch    82 | loss: 75.6830029CurrentTrain: epoch  1, batch    83 | loss: 184.3111734CurrentTrain: epoch  1, batch    84 | loss: 106.1459651CurrentTrain: epoch  1, batch    85 | loss: 72.3522016CurrentTrain: epoch  1, batch    86 | loss: 66.0591958CurrentTrain: epoch  1, batch    87 | loss: 77.1540494CurrentTrain: epoch  1, batch    88 | loss: 109.1633552CurrentTrain: epoch  1, batch    89 | loss: 87.1920705CurrentTrain: epoch  1, batch    90 | loss: 76.0022430CurrentTrain: epoch  1, batch    91 | loss: 88.2524557CurrentTrain: epoch  1, batch    92 | loss: 88.8480240CurrentTrain: epoch  1, batch    93 | loss: 136.8714356CurrentTrain: epoch  1, batch    94 | loss: 92.5170508CurrentTrain: epoch  1, batch    95 | loss: 69.4140804CurrentTrain: epoch  2, batch     0 | loss: 63.4056458CurrentTrain: epoch  2, batch     1 | loss: 105.3520281CurrentTrain: epoch  2, batch     2 | loss: 88.3421670CurrentTrain: epoch  2, batch     3 | loss: 91.0163752CurrentTrain: epoch  2, batch     4 | loss: 137.3287484CurrentTrain: epoch  2, batch     5 | loss: 72.6328121CurrentTrain: epoch  2, batch     6 | loss: 130.3061298CurrentTrain: epoch  2, batch     7 | loss: 83.5595040CurrentTrain: epoch  2, batch     8 | loss: 107.5579583CurrentTrain: epoch  2, batch     9 | loss: 62.5845740CurrentTrain: epoch  2, batch    10 | loss: 101.7652269CurrentTrain: epoch  2, batch    11 | loss: 61.9068414CurrentTrain: epoch  2, batch    12 | loss: 65.9102006CurrentTrain: epoch  2, batch    13 | loss: 103.9335822CurrentTrain: epoch  2, batch    14 | loss: 107.2925308CurrentTrain: epoch  2, batch    15 | loss: 109.2510681CurrentTrain: epoch  2, batch    16 | loss: 82.9419828CurrentTrain: epoch  2, batch    17 | loss: 89.2575924CurrentTrain: epoch  2, batch    18 | loss: 85.0520646CurrentTrain: epoch  2, batch    19 | loss: 104.2110754CurrentTrain: epoch  2, batch    20 | loss: 74.7460494CurrentTrain: epoch  2, batch    21 | loss: 103.3393380CurrentTrain: epoch  2, batch    22 | loss: 75.6036419CurrentTrain: epoch  2, batch    23 | loss: 85.5554022CurrentTrain: epoch  2, batch    24 | loss: 83.2479047CurrentTrain: epoch  2, batch    25 | loss: 84.2816080CurrentTrain: epoch  2, batch    26 | loss: 88.6967407CurrentTrain: epoch  2, batch    27 | loss: 80.8377542CurrentTrain: epoch  2, batch    28 | loss: 106.2200746CurrentTrain: epoch  2, batch    29 | loss: 102.5229403CurrentTrain: epoch  2, batch    30 | loss: 88.8964284CurrentTrain: epoch  2, batch    31 | loss: 85.5496288CurrentTrain: epoch  2, batch    32 | loss: 77.2054249CurrentTrain: epoch  2, batch    33 | loss: 109.4034101CurrentTrain: epoch  2, batch    34 | loss: 106.5382777CurrentTrain: epoch  2, batch    35 | loss: 103.5296833CurrentTrain: epoch  2, batch    36 | loss: 87.7873101CurrentTrain: epoch  2, batch    37 | loss: 102.2643017CurrentTrain: epoch  2, batch    38 | loss: 73.3929591CurrentTrain: epoch  2, batch    39 | loss: 106.1104252CurrentTrain: epoch  2, batch    40 | loss: 61.8184054CurrentTrain: epoch  2, batch    41 | loss: 108.2426005CurrentTrain: epoch  2, batch    42 | loss: 103.3167684CurrentTrain: epoch  2, batch    43 | loss: 75.6061731CurrentTrain: epoch  2, batch    44 | loss: 84.5055919CurrentTrain: epoch  2, batch    45 | loss: 74.5283724CurrentTrain: epoch  2, batch    46 | loss: 88.9609792CurrentTrain: epoch  2, batch    47 | loss: 76.2361181CurrentTrain: epoch  2, batch    48 | loss: 133.9734178CurrentTrain: epoch  2, batch    49 | loss: 134.5009364CurrentTrain: epoch  2, batch    50 | loss: 70.5059971CurrentTrain: epoch  2, batch    51 | loss: 137.6178950CurrentTrain: epoch  2, batch    52 | loss: 73.8667120CurrentTrain: epoch  2, batch    53 | loss: 89.9136464CurrentTrain: epoch  2, batch    54 | loss: 107.4933509CurrentTrain: epoch  2, batch    55 | loss: 86.7570440CurrentTrain: epoch  2, batch    56 | loss: 84.9106009CurrentTrain: epoch  2, batch    57 | loss: 70.4483350CurrentTrain: epoch  2, batch    58 | loss: 76.3383016CurrentTrain: epoch  2, batch    59 | loss: 73.5555043CurrentTrain: epoch  2, batch    60 | loss: 86.2922158CurrentTrain: epoch  2, batch    61 | loss: 69.6463464CurrentTrain: epoch  2, batch    62 | loss: 83.9023282CurrentTrain: epoch  2, batch    63 | loss: 71.5344291CurrentTrain: epoch  2, batch    64 | loss: 70.5662998CurrentTrain: epoch  2, batch    65 | loss: 85.4703774CurrentTrain: epoch  2, batch    66 | loss: 136.0955584CurrentTrain: epoch  2, batch    67 | loss: 106.4880379CurrentTrain: epoch  2, batch    68 | loss: 72.4420971CurrentTrain: epoch  2, batch    69 | loss: 70.4241465CurrentTrain: epoch  2, batch    70 | loss: 89.7751146CurrentTrain: epoch  2, batch    71 | loss: 72.9809866CurrentTrain: epoch  2, batch    72 | loss: 183.5888420CurrentTrain: epoch  2, batch    73 | loss: 86.6840652CurrentTrain: epoch  2, batch    74 | loss: 84.8704567CurrentTrain: epoch  2, batch    75 | loss: 84.7124235CurrentTrain: epoch  2, batch    76 | loss: 103.2380506CurrentTrain: epoch  2, batch    77 | loss: 63.6539768CurrentTrain: epoch  2, batch    78 | loss: 89.9128740CurrentTrain: epoch  2, batch    79 | loss: 84.7383824CurrentTrain: epoch  2, batch    80 | loss: 70.9956362CurrentTrain: epoch  2, batch    81 | loss: 87.8466749CurrentTrain: epoch  2, batch    82 | loss: 107.5792885CurrentTrain: epoch  2, batch    83 | loss: 107.2396399CurrentTrain: epoch  2, batch    84 | loss: 74.8796231CurrentTrain: epoch  2, batch    85 | loss: 135.4531346CurrentTrain: epoch  2, batch    86 | loss: 62.2726977CurrentTrain: epoch  2, batch    87 | loss: 63.2888234CurrentTrain: epoch  2, batch    88 | loss: 65.3783679CurrentTrain: epoch  2, batch    89 | loss: 100.9262547CurrentTrain: epoch  2, batch    90 | loss: 85.9162470CurrentTrain: epoch  2, batch    91 | loss: 75.8334300CurrentTrain: epoch  2, batch    92 | loss: 74.5804191CurrentTrain: epoch  2, batch    93 | loss: 87.9638507CurrentTrain: epoch  2, batch    94 | loss: 86.3273272CurrentTrain: epoch  2, batch    95 | loss: 72.7957899CurrentTrain: epoch  3, batch     0 | loss: 85.3939705CurrentTrain: epoch  3, batch     1 | loss: 102.4640394CurrentTrain: epoch  3, batch     2 | loss: 86.7047952CurrentTrain: epoch  3, batch     3 | loss: 88.9325856CurrentTrain: epoch  3, batch     4 | loss: 82.2873892CurrentTrain: epoch  3, batch     5 | loss: 100.2424287CurrentTrain: epoch  3, batch     6 | loss: 81.9667278CurrentTrain: epoch  3, batch     7 | loss: 62.7319800CurrentTrain: epoch  3, batch     8 | loss: 73.8021738CurrentTrain: epoch  3, batch     9 | loss: 126.3405603CurrentTrain: epoch  3, batch    10 | loss: 75.4639497CurrentTrain: epoch  3, batch    11 | loss: 81.2767438CurrentTrain: epoch  3, batch    12 | loss: 104.1204664CurrentTrain: epoch  3, batch    13 | loss: 104.1947179CurrentTrain: epoch  3, batch    14 | loss: 84.7171179CurrentTrain: epoch  3, batch    15 | loss: 104.5131549CurrentTrain: epoch  3, batch    16 | loss: 100.0974534CurrentTrain: epoch  3, batch    17 | loss: 68.3390971CurrentTrain: epoch  3, batch    18 | loss: 72.6541416CurrentTrain: epoch  3, batch    19 | loss: 74.1527673CurrentTrain: epoch  3, batch    20 | loss: 105.9427192CurrentTrain: epoch  3, batch    21 | loss: 81.1645033CurrentTrain: epoch  3, batch    22 | loss: 106.9451680CurrentTrain: epoch  3, batch    23 | loss: 87.0602763CurrentTrain: epoch  3, batch    24 | loss: 71.6951006CurrentTrain: epoch  3, batch    25 | loss: 86.1839101CurrentTrain: epoch  3, batch    26 | loss: 104.3368520CurrentTrain: epoch  3, batch    27 | loss: 106.8019270CurrentTrain: epoch  3, batch    28 | loss: 104.3201058CurrentTrain: epoch  3, batch    29 | loss: 74.2098387CurrentTrain: epoch  3, batch    30 | loss: 90.0713555CurrentTrain: epoch  3, batch    31 | loss: 82.5896310CurrentTrain: epoch  3, batch    32 | loss: 83.4836141CurrentTrain: epoch  3, batch    33 | loss: 131.4185821CurrentTrain: epoch  3, batch    34 | loss: 85.5910486CurrentTrain: epoch  3, batch    35 | loss: 125.9972711CurrentTrain: epoch  3, batch    36 | loss: 60.7398556CurrentTrain: epoch  3, batch    37 | loss: 129.8088081CurrentTrain: epoch  3, batch    38 | loss: 67.2275801CurrentTrain: epoch  3, batch    39 | loss: 87.8148069CurrentTrain: epoch  3, batch    40 | loss: 82.6100215CurrentTrain: epoch  3, batch    41 | loss: 82.2105741CurrentTrain: epoch  3, batch    42 | loss: 86.8390938CurrentTrain: epoch  3, batch    43 | loss: 70.3454115CurrentTrain: epoch  3, batch    44 | loss: 65.9109505CurrentTrain: epoch  3, batch    45 | loss: 72.1089957CurrentTrain: epoch  3, batch    46 | loss: 103.8358899CurrentTrain: epoch  3, batch    47 | loss: 87.6527173CurrentTrain: epoch  3, batch    48 | loss: 131.5253383CurrentTrain: epoch  3, batch    49 | loss: 62.5739440CurrentTrain: epoch  3, batch    50 | loss: 73.5689502CurrentTrain: epoch  3, batch    51 | loss: 75.7767471CurrentTrain: epoch  3, batch    52 | loss: 133.9974552CurrentTrain: epoch  3, batch    53 | loss: 74.4786219CurrentTrain: epoch  3, batch    54 | loss: 103.9383419CurrentTrain: epoch  3, batch    55 | loss: 79.6069087CurrentTrain: epoch  3, batch    56 | loss: 72.0299087CurrentTrain: epoch  3, batch    57 | loss: 74.2450633CurrentTrain: epoch  3, batch    58 | loss: 84.3385157CurrentTrain: epoch  3, batch    59 | loss: 128.6633463CurrentTrain: epoch  3, batch    60 | loss: 86.1584548CurrentTrain: epoch  3, batch    61 | loss: 70.6427174CurrentTrain: epoch  3, batch    62 | loss: 80.0066789CurrentTrain: epoch  3, batch    63 | loss: 103.3575499CurrentTrain: epoch  3, batch    64 | loss: 81.4609157CurrentTrain: epoch  3, batch    65 | loss: 103.8943795CurrentTrain: epoch  3, batch    66 | loss: 105.3806666CurrentTrain: epoch  3, batch    67 | loss: 71.4560343CurrentTrain: epoch  3, batch    68 | loss: 84.7506084CurrentTrain: epoch  3, batch    69 | loss: 68.6901724CurrentTrain: epoch  3, batch    70 | loss: 83.6934546CurrentTrain: epoch  3, batch    71 | loss: 59.7711252CurrentTrain: epoch  3, batch    72 | loss: 73.8884520CurrentTrain: epoch  3, batch    73 | loss: 57.9900619CurrentTrain: epoch  3, batch    74 | loss: 86.5795768CurrentTrain: epoch  3, batch    75 | loss: 107.0407211CurrentTrain: epoch  3, batch    76 | loss: 97.1842094CurrentTrain: epoch  3, batch    77 | loss: 85.5460918CurrentTrain: epoch  3, batch    78 | loss: 127.8909468CurrentTrain: epoch  3, batch    79 | loss: 80.6790582CurrentTrain: epoch  3, batch    80 | loss: 103.7246382CurrentTrain: epoch  3, batch    81 | loss: 62.0503554CurrentTrain: epoch  3, batch    82 | loss: 108.9312336CurrentTrain: epoch  3, batch    83 | loss: 81.7092871CurrentTrain: epoch  3, batch    84 | loss: 71.6571690CurrentTrain: epoch  3, batch    85 | loss: 108.7364122CurrentTrain: epoch  3, batch    86 | loss: 72.3122040CurrentTrain: epoch  3, batch    87 | loss: 85.3159602CurrentTrain: epoch  3, batch    88 | loss: 68.0930881CurrentTrain: epoch  3, batch    89 | loss: 69.9964967CurrentTrain: epoch  3, batch    90 | loss: 96.7781011CurrentTrain: epoch  3, batch    91 | loss: 100.3077044CurrentTrain: epoch  3, batch    92 | loss: 75.4475552CurrentTrain: epoch  3, batch    93 | loss: 84.9785055CurrentTrain: epoch  3, batch    94 | loss: 106.4603327CurrentTrain: epoch  3, batch    95 | loss: 54.9065943CurrentTrain: epoch  4, batch     0 | loss: 81.1125034CurrentTrain: epoch  4, batch     1 | loss: 104.5346277CurrentTrain: epoch  4, batch     2 | loss: 98.5733928CurrentTrain: epoch  4, batch     3 | loss: 76.2837770CurrentTrain: epoch  4, batch     4 | loss: 132.0177386CurrentTrain: epoch  4, batch     5 | loss: 96.9606187CurrentTrain: epoch  4, batch     6 | loss: 71.3038986CurrentTrain: epoch  4, batch     7 | loss: 66.9514652CurrentTrain: epoch  4, batch     8 | loss: 103.6496978CurrentTrain: epoch  4, batch     9 | loss: 130.4480404CurrentTrain: epoch  4, batch    10 | loss: 103.2990859CurrentTrain: epoch  4, batch    11 | loss: 70.1574310CurrentTrain: epoch  4, batch    12 | loss: 82.2485366CurrentTrain: epoch  4, batch    13 | loss: 71.6566895CurrentTrain: epoch  4, batch    14 | loss: 80.8980505CurrentTrain: epoch  4, batch    15 | loss: 102.5369231CurrentTrain: epoch  4, batch    16 | loss: 99.8477191CurrentTrain: epoch  4, batch    17 | loss: 128.8918317CurrentTrain: epoch  4, batch    18 | loss: 80.5896511CurrentTrain: epoch  4, batch    19 | loss: 81.6750526CurrentTrain: epoch  4, batch    20 | loss: 77.7621849CurrentTrain: epoch  4, batch    21 | loss: 70.8375064CurrentTrain: epoch  4, batch    22 | loss: 104.6932653CurrentTrain: epoch  4, batch    23 | loss: 74.4672001CurrentTrain: epoch  4, batch    24 | loss: 94.2900409CurrentTrain: epoch  4, batch    25 | loss: 104.0182678CurrentTrain: epoch  4, batch    26 | loss: 84.9922465CurrentTrain: epoch  4, batch    27 | loss: 63.4229382CurrentTrain: epoch  4, batch    28 | loss: 96.6357423CurrentTrain: epoch  4, batch    29 | loss: 83.6845634CurrentTrain: epoch  4, batch    30 | loss: 86.2833215CurrentTrain: epoch  4, batch    31 | loss: 72.4984875CurrentTrain: epoch  4, batch    32 | loss: 95.9985797CurrentTrain: epoch  4, batch    33 | loss: 57.8524676CurrentTrain: epoch  4, batch    34 | loss: 101.5051592CurrentTrain: epoch  4, batch    35 | loss: 83.9844794CurrentTrain: epoch  4, batch    36 | loss: 71.4447904CurrentTrain: epoch  4, batch    37 | loss: 61.8759981CurrentTrain: epoch  4, batch    38 | loss: 84.1465626CurrentTrain: epoch  4, batch    39 | loss: 72.8406416CurrentTrain: epoch  4, batch    40 | loss: 83.2791579CurrentTrain: epoch  4, batch    41 | loss: 70.4069375CurrentTrain: epoch  4, batch    42 | loss: 86.1541117CurrentTrain: epoch  4, batch    43 | loss: 60.2468222CurrentTrain: epoch  4, batch    44 | loss: 67.9680489CurrentTrain: epoch  4, batch    45 | loss: 84.7123077CurrentTrain: epoch  4, batch    46 | loss: 72.0736060CurrentTrain: epoch  4, batch    47 | loss: 99.7172243CurrentTrain: epoch  4, batch    48 | loss: 75.2406435CurrentTrain: epoch  4, batch    49 | loss: 83.4147684CurrentTrain: epoch  4, batch    50 | loss: 78.2643608CurrentTrain: epoch  4, batch    51 | loss: 72.3392544CurrentTrain: epoch  4, batch    52 | loss: 81.8993594CurrentTrain: epoch  4, batch    53 | loss: 126.1421854CurrentTrain: epoch  4, batch    54 | loss: 82.8702565CurrentTrain: epoch  4, batch    55 | loss: 103.2652312CurrentTrain: epoch  4, batch    56 | loss: 131.2110442CurrentTrain: epoch  4, batch    57 | loss: 72.2133949CurrentTrain: epoch  4, batch    58 | loss: 127.3037777CurrentTrain: epoch  4, batch    59 | loss: 101.0748331CurrentTrain: epoch  4, batch    60 | loss: 83.4865238CurrentTrain: epoch  4, batch    61 | loss: 59.6596515CurrentTrain: epoch  4, batch    62 | loss: 58.2999729CurrentTrain: epoch  4, batch    63 | loss: 69.2541023CurrentTrain: epoch  4, batch    64 | loss: 84.8777816CurrentTrain: epoch  4, batch    65 | loss: 126.1875332CurrentTrain: epoch  4, batch    66 | loss: 73.9522981CurrentTrain: epoch  4, batch    67 | loss: 71.3360059CurrentTrain: epoch  4, batch    68 | loss: 102.1037457CurrentTrain: epoch  4, batch    69 | loss: 70.9273487CurrentTrain: epoch  4, batch    70 | loss: 92.8879591CurrentTrain: epoch  4, batch    71 | loss: 103.1055175CurrentTrain: epoch  4, batch    72 | loss: 67.3714290CurrentTrain: epoch  4, batch    73 | loss: 74.1985099CurrentTrain: epoch  4, batch    74 | loss: 131.5276002CurrentTrain: epoch  4, batch    75 | loss: 82.8071625CurrentTrain: epoch  4, batch    76 | loss: 132.2435090CurrentTrain: epoch  4, batch    77 | loss: 100.3464381CurrentTrain: epoch  4, batch    78 | loss: 69.7143855CurrentTrain: epoch  4, batch    79 | loss: 98.6092294CurrentTrain: epoch  4, batch    80 | loss: 72.2730183CurrentTrain: epoch  4, batch    81 | loss: 131.1905770CurrentTrain: epoch  4, batch    82 | loss: 79.8744785CurrentTrain: epoch  4, batch    83 | loss: 71.7471676CurrentTrain: epoch  4, batch    84 | loss: 75.8920566CurrentTrain: epoch  4, batch    85 | loss: 84.2558916CurrentTrain: epoch  4, batch    86 | loss: 109.1981214CurrentTrain: epoch  4, batch    87 | loss: 124.9855363CurrentTrain: epoch  4, batch    88 | loss: 102.1385712CurrentTrain: epoch  4, batch    89 | loss: 71.2385918CurrentTrain: epoch  4, batch    90 | loss: 120.9123642CurrentTrain: epoch  4, batch    91 | loss: 96.2811594CurrentTrain: epoch  4, batch    92 | loss: 85.4279636CurrentTrain: epoch  4, batch    93 | loss: 80.1148899CurrentTrain: epoch  4, batch    94 | loss: 89.8042856CurrentTrain: epoch  4, batch    95 | loss: 59.8834101CurrentTrain: epoch  5, batch     0 | loss: 80.6153417CurrentTrain: epoch  5, batch     1 | loss: 82.3518936CurrentTrain: epoch  5, batch     2 | loss: 98.6279777CurrentTrain: epoch  5, batch     3 | loss: 84.1687321CurrentTrain: epoch  5, batch     4 | loss: 79.6540179CurrentTrain: epoch  5, batch     5 | loss: 68.0268085CurrentTrain: epoch  5, batch     6 | loss: 127.5643579CurrentTrain: epoch  5, batch     7 | loss: 79.4804254CurrentTrain: epoch  5, batch     8 | loss: 81.1191803CurrentTrain: epoch  5, batch     9 | loss: 79.1900852CurrentTrain: epoch  5, batch    10 | loss: 70.7546920CurrentTrain: epoch  5, batch    11 | loss: 102.7064142CurrentTrain: epoch  5, batch    12 | loss: 131.7216159CurrentTrain: epoch  5, batch    13 | loss: 67.2169679CurrentTrain: epoch  5, batch    14 | loss: 97.1682995CurrentTrain: epoch  5, batch    15 | loss: 66.0734224CurrentTrain: epoch  5, batch    16 | loss: 82.2994226CurrentTrain: epoch  5, batch    17 | loss: 67.5889239CurrentTrain: epoch  5, batch    18 | loss: 83.3098567CurrentTrain: epoch  5, batch    19 | loss: 99.1910532CurrentTrain: epoch  5, batch    20 | loss: 80.9083001CurrentTrain: epoch  5, batch    21 | loss: 65.7969563CurrentTrain: epoch  5, batch    22 | loss: 82.9765762CurrentTrain: epoch  5, batch    23 | loss: 95.2226632CurrentTrain: epoch  5, batch    24 | loss: 59.6804666CurrentTrain: epoch  5, batch    25 | loss: 83.2188732CurrentTrain: epoch  5, batch    26 | loss: 101.7492106CurrentTrain: epoch  5, batch    27 | loss: 95.9022122CurrentTrain: epoch  5, batch    28 | loss: 128.8566294CurrentTrain: epoch  5, batch    29 | loss: 271.6787761CurrentTrain: epoch  5, batch    30 | loss: 72.6184965CurrentTrain: epoch  5, batch    31 | loss: 168.9636151CurrentTrain: epoch  5, batch    32 | loss: 67.2290980CurrentTrain: epoch  5, batch    33 | loss: 75.3803559CurrentTrain: epoch  5, batch    34 | loss: 80.4941876CurrentTrain: epoch  5, batch    35 | loss: 62.8553767CurrentTrain: epoch  5, batch    36 | loss: 127.3517859CurrentTrain: epoch  5, batch    37 | loss: 80.9331739CurrentTrain: epoch  5, batch    38 | loss: 93.7547149CurrentTrain: epoch  5, batch    39 | loss: 101.0688304CurrentTrain: epoch  5, batch    40 | loss: 79.5355759CurrentTrain: epoch  5, batch    41 | loss: 102.3591474CurrentTrain: epoch  5, batch    42 | loss: 131.4338568CurrentTrain: epoch  5, batch    43 | loss: 71.1178977CurrentTrain: epoch  5, batch    44 | loss: 68.5534638CurrentTrain: epoch  5, batch    45 | loss: 83.7374101CurrentTrain: epoch  5, batch    46 | loss: 84.0963278CurrentTrain: epoch  5, batch    47 | loss: 67.7759785CurrentTrain: epoch  5, batch    48 | loss: 63.4993423CurrentTrain: epoch  5, batch    49 | loss: 72.3698492CurrentTrain: epoch  5, batch    50 | loss: 60.6464365CurrentTrain: epoch  5, batch    51 | loss: 81.5561365CurrentTrain: epoch  5, batch    52 | loss: 84.4512111CurrentTrain: epoch  5, batch    53 | loss: 75.8679772CurrentTrain: epoch  5, batch    54 | loss: 85.8282912CurrentTrain: epoch  5, batch    55 | loss: 103.1942356CurrentTrain: epoch  5, batch    56 | loss: 129.6626806CurrentTrain: epoch  5, batch    57 | loss: 83.7784438CurrentTrain: epoch  5, batch    58 | loss: 84.8943416CurrentTrain: epoch  5, batch    59 | loss: 129.0482086CurrentTrain: epoch  5, batch    60 | loss: 101.1923402CurrentTrain: epoch  5, batch    61 | loss: 80.7547320CurrentTrain: epoch  5, batch    62 | loss: 101.0838165CurrentTrain: epoch  5, batch    63 | loss: 85.0270710CurrentTrain: epoch  5, batch    64 | loss: 56.1770033CurrentTrain: epoch  5, batch    65 | loss: 77.0770430CurrentTrain: epoch  5, batch    66 | loss: 79.3003393CurrentTrain: epoch  5, batch    67 | loss: 80.6379254CurrentTrain: epoch  5, batch    68 | loss: 64.5172652CurrentTrain: epoch  5, batch    69 | loss: 80.7021874CurrentTrain: epoch  5, batch    70 | loss: 99.9574568CurrentTrain: epoch  5, batch    71 | loss: 101.4624139CurrentTrain: epoch  5, batch    72 | loss: 99.9219246CurrentTrain: epoch  5, batch    73 | loss: 80.0840108CurrentTrain: epoch  5, batch    74 | loss: 64.0051805CurrentTrain: epoch  5, batch    75 | loss: 68.7083808CurrentTrain: epoch  5, batch    76 | loss: 128.1476239CurrentTrain: epoch  5, batch    77 | loss: 84.3730821CurrentTrain: epoch  5, batch    78 | loss: 78.7932601CurrentTrain: epoch  5, batch    79 | loss: 81.7227997CurrentTrain: epoch  5, batch    80 | loss: 96.7217146CurrentTrain: epoch  5, batch    81 | loss: 100.0186334CurrentTrain: epoch  5, batch    82 | loss: 81.5330387CurrentTrain: epoch  5, batch    83 | loss: 102.1438674CurrentTrain: epoch  5, batch    84 | loss: 97.1725999CurrentTrain: epoch  5, batch    85 | loss: 84.3618617CurrentTrain: epoch  5, batch    86 | loss: 101.7467418CurrentTrain: epoch  5, batch    87 | loss: 66.3349824CurrentTrain: epoch  5, batch    88 | loss: 104.3805592CurrentTrain: epoch  5, batch    89 | loss: 79.5764540CurrentTrain: epoch  5, batch    90 | loss: 80.7435037CurrentTrain: epoch  5, batch    91 | loss: 86.1650811CurrentTrain: epoch  5, batch    92 | loss: 82.0720357CurrentTrain: epoch  5, batch    93 | loss: 68.9857332CurrentTrain: epoch  5, batch    94 | loss: 125.4239012CurrentTrain: epoch  5, batch    95 | loss: 60.7267956CurrentTrain: epoch  6, batch     0 | loss: 57.9482808CurrentTrain: epoch  6, batch     1 | loss: 81.0256794CurrentTrain: epoch  6, batch     2 | loss: 77.3823194CurrentTrain: epoch  6, batch     3 | loss: 100.5033190CurrentTrain: epoch  6, batch     4 | loss: 128.5249894CurrentTrain: epoch  6, batch     5 | loss: 173.4647389CurrentTrain: epoch  6, batch     6 | loss: 81.6951048CurrentTrain: epoch  6, batch     7 | loss: 84.2663975CurrentTrain: epoch  6, batch     8 | loss: 98.9699721CurrentTrain: epoch  6, batch     9 | loss: 83.2787447CurrentTrain: epoch  6, batch    10 | loss: 123.7221054CurrentTrain: epoch  6, batch    11 | loss: 82.3418878CurrentTrain: epoch  6, batch    12 | loss: 101.2148549CurrentTrain: epoch  6, batch    13 | loss: 99.4265083CurrentTrain: epoch  6, batch    14 | loss: 60.3207035CurrentTrain: epoch  6, batch    15 | loss: 77.3832332CurrentTrain: epoch  6, batch    16 | loss: 67.3708384CurrentTrain: epoch  6, batch    17 | loss: 82.1224335CurrentTrain: epoch  6, batch    18 | loss: 66.6639816CurrentTrain: epoch  6, batch    19 | loss: 65.9964839CurrentTrain: epoch  6, batch    20 | loss: 67.8832892CurrentTrain: epoch  6, batch    21 | loss: 82.7320878CurrentTrain: epoch  6, batch    22 | loss: 84.0346086CurrentTrain: epoch  6, batch    23 | loss: 96.2839927CurrentTrain: epoch  6, batch    24 | loss: 100.0540401CurrentTrain: epoch  6, batch    25 | loss: 67.0703200CurrentTrain: epoch  6, batch    26 | loss: 67.5066332CurrentTrain: epoch  6, batch    27 | loss: 69.2637191CurrentTrain: epoch  6, batch    28 | loss: 71.4145235CurrentTrain: epoch  6, batch    29 | loss: 94.5050481CurrentTrain: epoch  6, batch    30 | loss: 99.7727785CurrentTrain: epoch  6, batch    31 | loss: 56.7620351CurrentTrain: epoch  6, batch    32 | loss: 98.3304297CurrentTrain: epoch  6, batch    33 | loss: 84.1638701CurrentTrain: epoch  6, batch    34 | loss: 97.2671725CurrentTrain: epoch  6, batch    35 | loss: 66.7047881CurrentTrain: epoch  6, batch    36 | loss: 68.3051194CurrentTrain: epoch  6, batch    37 | loss: 72.0646825CurrentTrain: epoch  6, batch    38 | loss: 100.9727283CurrentTrain: epoch  6, batch    39 | loss: 78.7941042CurrentTrain: epoch  6, batch    40 | loss: 66.7056400CurrentTrain: epoch  6, batch    41 | loss: 96.8463330CurrentTrain: epoch  6, batch    42 | loss: 77.2406165CurrentTrain: epoch  6, batch    43 | loss: 58.7099117CurrentTrain: epoch  6, batch    44 | loss: 56.6808723CurrentTrain: epoch  6, batch    45 | loss: 81.3675228CurrentTrain: epoch  6, batch    46 | loss: 77.7185107CurrentTrain: epoch  6, batch    47 | loss: 131.1544548CurrentTrain: epoch  6, batch    48 | loss: 70.4955728CurrentTrain: epoch  6, batch    49 | loss: 67.1509203CurrentTrain: epoch  6, batch    50 | loss: 100.1818764CurrentTrain: epoch  6, batch    51 | loss: 96.3444247CurrentTrain: epoch  6, batch    52 | loss: 124.5952996CurrentTrain: epoch  6, batch    53 | loss: 100.5823221CurrentTrain: epoch  6, batch    54 | loss: 82.9778738CurrentTrain: epoch  6, batch    55 | loss: 81.8967115CurrentTrain: epoch  6, batch    56 | loss: 102.9505211CurrentTrain: epoch  6, batch    57 | loss: 62.4440054CurrentTrain: epoch  6, batch    58 | loss: 100.7441093CurrentTrain: epoch  6, batch    59 | loss: 58.5263445CurrentTrain: epoch  6, batch    60 | loss: 77.7663932CurrentTrain: epoch  6, batch    61 | loss: 83.5274644CurrentTrain: epoch  6, batch    62 | loss: 100.3492866CurrentTrain: epoch  6, batch    63 | loss: 81.5295783CurrentTrain: epoch  6, batch    64 | loss: 78.3174796CurrentTrain: epoch  6, batch    65 | loss: 100.9328079CurrentTrain: epoch  6, batch    66 | loss: 82.3515534CurrentTrain: epoch  6, batch    67 | loss: 79.8245217CurrentTrain: epoch  6, batch    68 | loss: 99.9778375CurrentTrain: epoch  6, batch    69 | loss: 78.7328089CurrentTrain: epoch  6, batch    70 | loss: 100.0901289CurrentTrain: epoch  6, batch    71 | loss: 56.4887285CurrentTrain: epoch  6, batch    72 | loss: 69.9770186CurrentTrain: epoch  6, batch    73 | loss: 63.3886178CurrentTrain: epoch  6, batch    74 | loss: 102.6006922CurrentTrain: epoch  6, batch    75 | loss: 100.5143422CurrentTrain: epoch  6, batch    76 | loss: 55.0005633CurrentTrain: epoch  6, batch    77 | loss: 58.4186678CurrentTrain: epoch  6, batch    78 | loss: 97.3877095CurrentTrain: epoch  6, batch    79 | loss: 97.0368108CurrentTrain: epoch  6, batch    80 | loss: 80.6242404CurrentTrain: epoch  6, batch    81 | loss: 59.5799681CurrentTrain: epoch  6, batch    82 | loss: 72.1578663CurrentTrain: epoch  6, batch    83 | loss: 96.1714910CurrentTrain: epoch  6, batch    84 | loss: 81.9022395CurrentTrain: epoch  6, batch    85 | loss: 59.6662252CurrentTrain: epoch  6, batch    86 | loss: 80.5856182CurrentTrain: epoch  6, batch    87 | loss: 97.8458937CurrentTrain: epoch  6, batch    88 | loss: 89.2910965CurrentTrain: epoch  6, batch    89 | loss: 102.3711286CurrentTrain: epoch  6, batch    90 | loss: 97.1867776CurrentTrain: epoch  6, batch    91 | loss: 60.2167405CurrentTrain: epoch  6, batch    92 | loss: 80.9161099CurrentTrain: epoch  6, batch    93 | loss: 79.7682014CurrentTrain: epoch  6, batch    94 | loss: 69.5473714CurrentTrain: epoch  6, batch    95 | loss: 101.2044641CurrentTrain: epoch  7, batch     0 | loss: 79.2726593CurrentTrain: epoch  7, batch     1 | loss: 97.1874883CurrentTrain: epoch  7, batch     2 | loss: 82.3570244CurrentTrain: epoch  7, batch     3 | loss: 79.3703447CurrentTrain: epoch  7, batch     4 | loss: 79.8846200CurrentTrain: epoch  7, batch     5 | loss: 96.4519833CurrentTrain: epoch  7, batch     6 | loss: 81.9766063CurrentTrain: epoch  7, batch     7 | loss: 80.6716605CurrentTrain: epoch  7, batch     8 | loss: 67.2684971CurrentTrain: epoch  7, batch     9 | loss: 64.6737588CurrentTrain: epoch  7, batch    10 | loss: 65.3373119CurrentTrain: epoch  7, batch    11 | loss: 69.0256226CurrentTrain: epoch  7, batch    12 | loss: 98.3994006CurrentTrain: epoch  7, batch    13 | loss: 80.8315106CurrentTrain: epoch  7, batch    14 | loss: 80.5049130CurrentTrain: epoch  7, batch    15 | loss: 68.1027653CurrentTrain: epoch  7, batch    16 | loss: 101.5363727CurrentTrain: epoch  7, batch    17 | loss: 74.2499306CurrentTrain: epoch  7, batch    18 | loss: 67.7928576CurrentTrain: epoch  7, batch    19 | loss: 64.1645957CurrentTrain: epoch  7, batch    20 | loss: 75.5665234CurrentTrain: epoch  7, batch    21 | loss: 76.5587598CurrentTrain: epoch  7, batch    22 | loss: 99.5568373CurrentTrain: epoch  7, batch    23 | loss: 95.8931237CurrentTrain: epoch  7, batch    24 | loss: 66.5441221CurrentTrain: epoch  7, batch    25 | loss: 56.9221289CurrentTrain: epoch  7, batch    26 | loss: 80.3119468CurrentTrain: epoch  7, batch    27 | loss: 98.8133942CurrentTrain: epoch  7, batch    28 | loss: 66.8510672CurrentTrain: epoch  7, batch    29 | loss: 101.9625935CurrentTrain: epoch  7, batch    30 | loss: 80.2863077CurrentTrain: epoch  7, batch    31 | loss: 83.1136681CurrentTrain: epoch  7, batch    32 | loss: 120.8066028CurrentTrain: epoch  7, batch    33 | loss: 82.4364313CurrentTrain: epoch  7, batch    34 | loss: 83.8468817CurrentTrain: epoch  7, batch    35 | loss: 97.6210603CurrentTrain: epoch  7, batch    36 | loss: 79.5424640CurrentTrain: epoch  7, batch    37 | loss: 82.6123373CurrentTrain: epoch  7, batch    38 | loss: 80.6481285CurrentTrain: epoch  7, batch    39 | loss: 102.4841005CurrentTrain: epoch  7, batch    40 | loss: 80.7610761CurrentTrain: epoch  7, batch    41 | loss: 64.1042676CurrentTrain: epoch  7, batch    42 | loss: 95.4895668CurrentTrain: epoch  7, batch    43 | loss: 65.6201222CurrentTrain: epoch  7, batch    44 | loss: 77.8667161CurrentTrain: epoch  7, batch    45 | loss: 98.0347565CurrentTrain: epoch  7, batch    46 | loss: 71.7929308CurrentTrain: epoch  7, batch    47 | loss: 75.8265901CurrentTrain: epoch  7, batch    48 | loss: 121.5012800CurrentTrain: epoch  7, batch    49 | loss: 57.3435338CurrentTrain: epoch  7, batch    50 | loss: 92.1472556CurrentTrain: epoch  7, batch    51 | loss: 75.1277629CurrentTrain: epoch  7, batch    52 | loss: 68.8145493CurrentTrain: epoch  7, batch    53 | loss: 99.0746344CurrentTrain: epoch  7, batch    54 | loss: 65.6393305CurrentTrain: epoch  7, batch    55 | loss: 100.2024664CurrentTrain: epoch  7, batch    56 | loss: 93.6905493CurrentTrain: epoch  7, batch    57 | loss: 81.6144845CurrentTrain: epoch  7, batch    58 | loss: 78.6284179CurrentTrain: epoch  7, batch    59 | loss: 126.0846233CurrentTrain: epoch  7, batch    60 | loss: 66.1353975CurrentTrain: epoch  7, batch    61 | loss: 67.3454128CurrentTrain: epoch  7, batch    62 | loss: 120.0626389CurrentTrain: epoch  7, batch    63 | loss: 80.6191301CurrentTrain: epoch  7, batch    64 | loss: 62.6648903CurrentTrain: epoch  7, batch    65 | loss: 74.2096088CurrentTrain: epoch  7, batch    66 | loss: 78.6412767CurrentTrain: epoch  7, batch    67 | loss: 80.8295070CurrentTrain: epoch  7, batch    68 | loss: 63.4286286CurrentTrain: epoch  7, batch    69 | loss: 79.8175373CurrentTrain: epoch  7, batch    70 | loss: 69.9824706CurrentTrain: epoch  7, batch    71 | loss: 97.7949284CurrentTrain: epoch  7, batch    72 | loss: 66.4558071CurrentTrain: epoch  7, batch    73 | loss: 78.3661388CurrentTrain: epoch  7, batch    74 | loss: 55.4986111CurrentTrain: epoch  7, batch    75 | loss: 64.7931265CurrentTrain: epoch  7, batch    76 | loss: 69.0813449CurrentTrain: epoch  7, batch    77 | loss: 98.0837364CurrentTrain: epoch  7, batch    78 | loss: 85.5270142CurrentTrain: epoch  7, batch    79 | loss: 126.8500123CurrentTrain: epoch  7, batch    80 | loss: 69.4111865CurrentTrain: epoch  7, batch    81 | loss: 66.8844572CurrentTrain: epoch  7, batch    82 | loss: 78.5718922CurrentTrain: epoch  7, batch    83 | loss: 65.0329115CurrentTrain: epoch  7, batch    84 | loss: 78.4652388CurrentTrain: epoch  7, batch    85 | loss: 83.4059313CurrentTrain: epoch  7, batch    86 | loss: 65.8111399CurrentTrain: epoch  7, batch    87 | loss: 99.2126774CurrentTrain: epoch  7, batch    88 | loss: 94.3003091CurrentTrain: epoch  7, batch    89 | loss: 126.3739207CurrentTrain: epoch  7, batch    90 | loss: 80.5179053CurrentTrain: epoch  7, batch    91 | loss: 81.9353188CurrentTrain: epoch  7, batch    92 | loss: 102.0174514CurrentTrain: epoch  7, batch    93 | loss: 57.7006863CurrentTrain: epoch  7, batch    94 | loss: 59.9360288CurrentTrain: epoch  7, batch    95 | loss: 83.2642514CurrentTrain: epoch  8, batch     0 | loss: 68.9966898CurrentTrain: epoch  8, batch     1 | loss: 64.5871163CurrentTrain: epoch  8, batch     2 | loss: 93.8686556CurrentTrain: epoch  8, batch     3 | loss: 127.3753810CurrentTrain: epoch  8, batch     4 | loss: 78.6778623CurrentTrain: epoch  8, batch     5 | loss: 68.7710182CurrentTrain: epoch  8, batch     6 | loss: 82.0633756CurrentTrain: epoch  8, batch     7 | loss: 76.1946960CurrentTrain: epoch  8, batch     8 | loss: 66.9916511CurrentTrain: epoch  8, batch     9 | loss: 96.8283780CurrentTrain: epoch  8, batch    10 | loss: 75.7515122CurrentTrain: epoch  8, batch    11 | loss: 77.8722549CurrentTrain: epoch  8, batch    12 | loss: 77.4024850CurrentTrain: epoch  8, batch    13 | loss: 91.6078005CurrentTrain: epoch  8, batch    14 | loss: 78.0910914CurrentTrain: epoch  8, batch    15 | loss: 78.6508839CurrentTrain: epoch  8, batch    16 | loss: 94.7223478CurrentTrain: epoch  8, batch    17 | loss: 78.8925145CurrentTrain: epoch  8, batch    18 | loss: 97.9514101CurrentTrain: epoch  8, batch    19 | loss: 65.6938979CurrentTrain: epoch  8, batch    20 | loss: 76.4738241CurrentTrain: epoch  8, batch    21 | loss: 75.2524942CurrentTrain: epoch  8, batch    22 | loss: 92.2440954CurrentTrain: epoch  8, batch    23 | loss: 66.7811700CurrentTrain: epoch  8, batch    24 | loss: 63.8378659CurrentTrain: epoch  8, batch    25 | loss: 94.4766360CurrentTrain: epoch  8, batch    26 | loss: 65.1618019CurrentTrain: epoch  8, batch    27 | loss: 76.0015417CurrentTrain: epoch  8, batch    28 | loss: 66.0292713CurrentTrain: epoch  8, batch    29 | loss: 68.3755425CurrentTrain: epoch  8, batch    30 | loss: 101.6021654CurrentTrain: epoch  8, batch    31 | loss: 54.0622219CurrentTrain: epoch  8, batch    32 | loss: 168.8025003CurrentTrain: epoch  8, batch    33 | loss: 95.4264274CurrentTrain: epoch  8, batch    34 | loss: 94.4009143CurrentTrain: epoch  8, batch    35 | loss: 65.8529977CurrentTrain: epoch  8, batch    36 | loss: 95.2508864CurrentTrain: epoch  8, batch    37 | loss: 67.2926159CurrentTrain: epoch  8, batch    38 | loss: 77.3421394CurrentTrain: epoch  8, batch    39 | loss: 80.6427972CurrentTrain: epoch  8, batch    40 | loss: 80.3358730CurrentTrain: epoch  8, batch    41 | loss: 97.2885358CurrentTrain: epoch  8, batch    42 | loss: 80.1077598CurrentTrain: epoch  8, batch    43 | loss: 102.3457201CurrentTrain: epoch  8, batch    44 | loss: 123.4849041CurrentTrain: epoch  8, batch    45 | loss: 81.5019359CurrentTrain: epoch  8, batch    46 | loss: 65.8019239CurrentTrain: epoch  8, batch    47 | loss: 80.7344168CurrentTrain: epoch  8, batch    48 | loss: 63.9856535CurrentTrain: epoch  8, batch    49 | loss: 75.6429198CurrentTrain: epoch  8, batch    50 | loss: 94.6534213CurrentTrain: epoch  8, batch    51 | loss: 62.3753438CurrentTrain: epoch  8, batch    52 | loss: 78.4095491CurrentTrain: epoch  8, batch    53 | loss: 83.7942397CurrentTrain: epoch  8, batch    54 | loss: 98.0791139CurrentTrain: epoch  8, batch    55 | loss: 94.9059679CurrentTrain: epoch  8, batch    56 | loss: 68.8017066CurrentTrain: epoch  8, batch    57 | loss: 65.0025788CurrentTrain: epoch  8, batch    58 | loss: 78.6586041CurrentTrain: epoch  8, batch    59 | loss: 54.8829079CurrentTrain: epoch  8, batch    60 | loss: 122.1065441CurrentTrain: epoch  8, batch    61 | loss: 95.8380200CurrentTrain: epoch  8, batch    62 | loss: 56.3970812CurrentTrain: epoch  8, batch    63 | loss: 80.2873741CurrentTrain: epoch  8, batch    64 | loss: 80.2840308CurrentTrain: epoch  8, batch    65 | loss: 80.0177817CurrentTrain: epoch  8, batch    66 | loss: 73.8357913CurrentTrain: epoch  8, batch    67 | loss: 92.0090712CurrentTrain: epoch  8, batch    68 | loss: 94.7089746CurrentTrain: epoch  8, batch    69 | loss: 82.3782140CurrentTrain: epoch  8, batch    70 | loss: 96.5432394CurrentTrain: epoch  8, batch    71 | loss: 122.3547251CurrentTrain: epoch  8, batch    72 | loss: 76.4428440CurrentTrain: epoch  8, batch    73 | loss: 77.9514798CurrentTrain: epoch  8, batch    74 | loss: 96.8420787CurrentTrain: epoch  8, batch    75 | loss: 78.3488327CurrentTrain: epoch  8, batch    76 | loss: 58.2396548CurrentTrain: epoch  8, batch    77 | loss: 121.2349316CurrentTrain: epoch  8, batch    78 | loss: 64.2396414CurrentTrain: epoch  8, batch    79 | loss: 69.3726559CurrentTrain: epoch  8, batch    80 | loss: 93.0264373CurrentTrain: epoch  8, batch    81 | loss: 78.3367412CurrentTrain: epoch  8, batch    82 | loss: 67.9296025CurrentTrain: epoch  8, batch    83 | loss: 64.8667332CurrentTrain: epoch  8, batch    84 | loss: 125.2710002CurrentTrain: epoch  8, batch    85 | loss: 119.1489486CurrentTrain: epoch  8, batch    86 | loss: 96.7695352CurrentTrain: epoch  8, batch    87 | loss: 78.9086514CurrentTrain: epoch  8, batch    88 | loss: 51.9081911CurrentTrain: epoch  8, batch    89 | loss: 76.9698529CurrentTrain: epoch  8, batch    90 | loss: 76.7902298CurrentTrain: epoch  8, batch    91 | loss: 83.4807954CurrentTrain: epoch  8, batch    92 | loss: 79.3248173CurrentTrain: epoch  8, batch    93 | loss: 77.4483045CurrentTrain: epoch  8, batch    94 | loss: 99.1545581CurrentTrain: epoch  8, batch    95 | loss: 102.1255903CurrentTrain: epoch  9, batch     0 | loss: 66.2933590CurrentTrain: epoch  9, batch     1 | loss: 117.2931954CurrentTrain: epoch  9, batch     2 | loss: 75.3099897CurrentTrain: epoch  9, batch     3 | loss: 66.3603605CurrentTrain: epoch  9, batch     4 | loss: 77.5364937CurrentTrain: epoch  9, batch     5 | loss: 53.2806960CurrentTrain: epoch  9, batch     6 | loss: 101.0981159CurrentTrain: epoch  9, batch     7 | loss: 75.1266927CurrentTrain: epoch  9, batch     8 | loss: 97.3134746CurrentTrain: epoch  9, batch     9 | loss: 64.4851686CurrentTrain: epoch  9, batch    10 | loss: 101.7321180CurrentTrain: epoch  9, batch    11 | loss: 67.6928396CurrentTrain: epoch  9, batch    12 | loss: 93.8900775CurrentTrain: epoch  9, batch    13 | loss: 97.5515752CurrentTrain: epoch  9, batch    14 | loss: 95.7930062CurrentTrain: epoch  9, batch    15 | loss: 74.4899486CurrentTrain: epoch  9, batch    16 | loss: 126.2662905CurrentTrain: epoch  9, batch    17 | loss: 78.3173719CurrentTrain: epoch  9, batch    18 | loss: 79.1768116CurrentTrain: epoch  9, batch    19 | loss: 80.4948104CurrentTrain: epoch  9, batch    20 | loss: 64.3586197CurrentTrain: epoch  9, batch    21 | loss: 96.1157789CurrentTrain: epoch  9, batch    22 | loss: 66.5198664CurrentTrain: epoch  9, batch    23 | loss: 66.7936031CurrentTrain: epoch  9, batch    24 | loss: 122.3334622CurrentTrain: epoch  9, batch    25 | loss: 93.4099727CurrentTrain: epoch  9, batch    26 | loss: 61.7796012CurrentTrain: epoch  9, batch    27 | loss: 120.1562922CurrentTrain: epoch  9, batch    28 | loss: 64.5488835CurrentTrain: epoch  9, batch    29 | loss: 67.4458553CurrentTrain: epoch  9, batch    30 | loss: 63.8873470CurrentTrain: epoch  9, batch    31 | loss: 82.2191712CurrentTrain: epoch  9, batch    32 | loss: 94.0391642CurrentTrain: epoch  9, batch    33 | loss: 69.9564644CurrentTrain: epoch  9, batch    34 | loss: 61.3317133CurrentTrain: epoch  9, batch    35 | loss: 119.7669964CurrentTrain: epoch  9, batch    36 | loss: 81.7951987CurrentTrain: epoch  9, batch    37 | loss: 79.2764701CurrentTrain: epoch  9, batch    38 | loss: 80.4014671CurrentTrain: epoch  9, batch    39 | loss: 65.9953135CurrentTrain: epoch  9, batch    40 | loss: 62.2421796CurrentTrain: epoch  9, batch    41 | loss: 80.3000895CurrentTrain: epoch  9, batch    42 | loss: 62.6869168CurrentTrain: epoch  9, batch    43 | loss: 63.2807081CurrentTrain: epoch  9, batch    44 | loss: 124.9582230CurrentTrain: epoch  9, batch    45 | loss: 67.5153381CurrentTrain: epoch  9, batch    46 | loss: 80.5945444CurrentTrain: epoch  9, batch    47 | loss: 95.6814629CurrentTrain: epoch  9, batch    48 | loss: 77.4649011CurrentTrain: epoch  9, batch    49 | loss: 65.0969719CurrentTrain: epoch  9, batch    50 | loss: 75.0804738CurrentTrain: epoch  9, batch    51 | loss: 78.0241255CurrentTrain: epoch  9, batch    52 | loss: 67.4809707CurrentTrain: epoch  9, batch    53 | loss: 81.1000080CurrentTrain: epoch  9, batch    54 | loss: 66.0652830CurrentTrain: epoch  9, batch    55 | loss: 63.5982260CurrentTrain: epoch  9, batch    56 | loss: 84.2756393CurrentTrain: epoch  9, batch    57 | loss: 52.9058996CurrentTrain: epoch  9, batch    58 | loss: 93.5450576CurrentTrain: epoch  9, batch    59 | loss: 96.1956118CurrentTrain: epoch  9, batch    60 | loss: 71.9798771CurrentTrain: epoch  9, batch    61 | loss: 55.1414427CurrentTrain: epoch  9, batch    62 | loss: 94.8897933CurrentTrain: epoch  9, batch    63 | loss: 63.6748791CurrentTrain: epoch  9, batch    64 | loss: 58.1984148CurrentTrain: epoch  9, batch    65 | loss: 93.9610919CurrentTrain: epoch  9, batch    66 | loss: 94.0960920CurrentTrain: epoch  9, batch    67 | loss: 75.1607595CurrentTrain: epoch  9, batch    68 | loss: 124.3496303CurrentTrain: epoch  9, batch    69 | loss: 97.6030684CurrentTrain: epoch  9, batch    70 | loss: 75.9732990CurrentTrain: epoch  9, batch    71 | loss: 94.5420829CurrentTrain: epoch  9, batch    72 | loss: 65.2655545CurrentTrain: epoch  9, batch    73 | loss: 95.5938993CurrentTrain: epoch  9, batch    74 | loss: 128.1500726CurrentTrain: epoch  9, batch    75 | loss: 100.7139292CurrentTrain: epoch  9, batch    76 | loss: 94.3243316CurrentTrain: epoch  9, batch    77 | loss: 64.8462750CurrentTrain: epoch  9, batch    78 | loss: 123.5571210CurrentTrain: epoch  9, batch    79 | loss: 79.1567975CurrentTrain: epoch  9, batch    80 | loss: 56.2170777CurrentTrain: epoch  9, batch    81 | loss: 55.2066855CurrentTrain: epoch  9, batch    82 | loss: 99.1500895CurrentTrain: epoch  9, batch    83 | loss: 124.1638616CurrentTrain: epoch  9, batch    84 | loss: 122.9671970CurrentTrain: epoch  9, batch    85 | loss: 66.0259780CurrentTrain: epoch  9, batch    86 | loss: 77.5001581CurrentTrain: epoch  9, batch    87 | loss: 65.4008208CurrentTrain: epoch  9, batch    88 | loss: 127.8197451CurrentTrain: epoch  9, batch    89 | loss: 57.4086438CurrentTrain: epoch  9, batch    90 | loss: 79.3653327CurrentTrain: epoch  9, batch    91 | loss: 78.2752602CurrentTrain: epoch  9, batch    92 | loss: 55.0927974CurrentTrain: epoch  9, batch    93 | loss: 67.1023953CurrentTrain: epoch  9, batch    94 | loss: 92.0286661CurrentTrain: epoch  9, batch    95 | loss: 65.4797382

F1 score per class: {32: np.float64(0.5056179775280899), 6: np.float64(0.84), 19: np.float64(0.37209302325581395), 24: np.float64(0.73224043715847), 26: np.float64(0.9128205128205128), 29: np.float64(0.7947598253275109)}
Micro-average F1 score: 0.7470817120622568
Weighted-average F1 score: 0.7505067652900725
F1 score per class: {32: np.float64(0.6415094339622641), 6: np.float64(0.8), 19: np.float64(0.25), 24: np.float64(0.7076923076923077), 26: np.float64(0.93), 29: np.float64(0.8229665071770335)}
Micro-average F1 score: 0.7457322551662174
Weighted-average F1 score: 0.7315683615409067
F1 score per class: {32: np.float64(0.6368159203980099), 6: np.float64(0.8), 19: np.float64(0.3157894736842105), 24: np.float64(0.711340206185567), 26: np.float64(0.9246231155778895), 29: np.float64(0.8075117370892019)}
Micro-average F1 score: 0.7527675276752768
Weighted-average F1 score: 0.74608956103996

F1 score per class: {32: np.float64(0.5056179775280899), 6: np.float64(0.84), 19: np.float64(0.37209302325581395), 24: np.float64(0.73224043715847), 26: np.float64(0.9128205128205128), 29: np.float64(0.7947598253275109)}
Micro-average F1 score: 0.7470817120622568
Weighted-average F1 score: 0.7505067652900725
F1 score per class: {32: np.float64(0.6415094339622641), 6: np.float64(0.8), 19: np.float64(0.25), 24: np.float64(0.7076923076923077), 26: np.float64(0.93), 29: np.float64(0.8229665071770335)}
Micro-average F1 score: 0.7457322551662174
Weighted-average F1 score: 0.7315683615409067
F1 score per class: {32: np.float64(0.6368159203980099), 6: np.float64(0.8), 19: np.float64(0.3157894736842105), 24: np.float64(0.711340206185567), 26: np.float64(0.9246231155778895), 29: np.float64(0.8075117370892019)}
Micro-average F1 score: 0.7527675276752768
Weighted-average F1 score: 0.74608956103996

F1 score per class: {32: np.float64(0.3879310344827586), 6: np.float64(0.8), 19: np.float64(0.22857142857142856), 24: np.float64(0.6767676767676768), 26: np.float64(0.8356807511737089), 29: np.float64(0.5870967741935483)}
Micro-average F1 score: 0.6228710462287105
Weighted-average F1 score: 0.6085847421313917
F1 score per class: {32: np.float64(0.4473684210526316), 6: np.float64(0.7407407407407407), 19: np.float64(0.144), 24: np.float64(0.6301369863013698), 26: np.float64(0.8340807174887892), 29: np.float64(0.6515151515151515)}
Micro-average F1 score: 0.602322206095791
Weighted-average F1 score: 0.5779346491745717
F1 score per class: {32: np.float64(0.4507042253521127), 6: np.float64(0.7457627118644068), 19: np.float64(0.18947368421052632), 24: np.float64(0.6330275229357798), 26: np.float64(0.832579185520362), 29: np.float64(0.6370370370370371)}
Micro-average F1 score: 0.6163141993957704
Weighted-average F1 score: 0.5988565823985617

F1 score per class: {32: np.float64(0.3879310344827586), 6: np.float64(0.8), 19: np.float64(0.22857142857142856), 24: np.float64(0.6767676767676768), 26: np.float64(0.8356807511737089), 29: np.float64(0.5870967741935483)}
Micro-average F1 score: 0.6228710462287105
Weighted-average F1 score: 0.6085847421313917
F1 score per class: {32: np.float64(0.4473684210526316), 6: np.float64(0.7407407407407407), 19: np.float64(0.144), 24: np.float64(0.6301369863013698), 26: np.float64(0.8340807174887892), 29: np.float64(0.6515151515151515)}
Micro-average F1 score: 0.602322206095791
Weighted-average F1 score: 0.5779346491745717
F1 score per class: {32: np.float64(0.4507042253521127), 6: np.float64(0.7457627118644068), 19: np.float64(0.18947368421052632), 24: np.float64(0.6330275229357798), 26: np.float64(0.832579185520362), 29: np.float64(0.6370370370370371)}
Micro-average F1 score: 0.6163141993957704
Weighted-average F1 score: 0.5988565823985617
cur_acc_wo_na:  ['0.7471']
his_acc_wo_na:  ['0.7471']
cur_acc des_wo_na:  ['0.7457']
his_acc des_wo_na:  ['0.7457']
cur_acc rrf_wo_na:  ['0.7528']
his_acc rrf_wo_na:  ['0.7528']
cur_acc_w_na:  ['0.6229']
his_acc_w_na:  ['0.6229']
cur_acc des_w_na:  ['0.6023']
his_acc des_w_na:  ['0.6023']
cur_acc rrf_w_na:  ['0.6163']
his_acc rrf_w_na:  ['0.6163']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 82.8636297CurrentTrain: epoch  0, batch     1 | loss: 149.6902223CurrentTrain: epoch  0, batch     2 | loss: 112.4095211CurrentTrain: epoch  0, batch     3 | loss: 113.5312164CurrentTrain: epoch  0, batch     4 | loss: 23.0601196CurrentTrain: epoch  1, batch     0 | loss: 111.0390112CurrentTrain: epoch  1, batch     1 | loss: 88.4316372CurrentTrain: epoch  1, batch     2 | loss: 109.5100006CurrentTrain: epoch  1, batch     3 | loss: 86.5394714CurrentTrain: epoch  1, batch     4 | loss: 26.9655135CurrentTrain: epoch  2, batch     0 | loss: 133.5610529CurrentTrain: epoch  2, batch     1 | loss: 75.5835000CurrentTrain: epoch  2, batch     2 | loss: 86.8568046CurrentTrain: epoch  2, batch     3 | loss: 85.2598343CurrentTrain: epoch  2, batch     4 | loss: 19.5256712CurrentTrain: epoch  3, batch     0 | loss: 85.1695173CurrentTrain: epoch  3, batch     1 | loss: 84.7320423CurrentTrain: epoch  3, batch     2 | loss: 84.5530456CurrentTrain: epoch  3, batch     3 | loss: 103.8722984CurrentTrain: epoch  3, batch     4 | loss: 25.8608559CurrentTrain: epoch  4, batch     0 | loss: 86.5605584CurrentTrain: epoch  4, batch     1 | loss: 102.4999453CurrentTrain: epoch  4, batch     2 | loss: 69.3788625CurrentTrain: epoch  4, batch     3 | loss: 98.9519899CurrentTrain: epoch  4, batch     4 | loss: 14.0187831CurrentTrain: epoch  5, batch     0 | loss: 80.2333814CurrentTrain: epoch  5, batch     1 | loss: 80.5815602CurrentTrain: epoch  5, batch     2 | loss: 78.4301321CurrentTrain: epoch  5, batch     3 | loss: 128.3449442CurrentTrain: epoch  5, batch     4 | loss: 16.0914298CurrentTrain: epoch  6, batch     0 | loss: 79.4395566CurrentTrain: epoch  6, batch     1 | loss: 100.2102557CurrentTrain: epoch  6, batch     2 | loss: 79.3528565CurrentTrain: epoch  6, batch     3 | loss: 96.0142808CurrentTrain: epoch  6, batch     4 | loss: 25.5882001CurrentTrain: epoch  7, batch     0 | loss: 120.0389805CurrentTrain: epoch  7, batch     1 | loss: 91.1290010CurrentTrain: epoch  7, batch     2 | loss: 97.9989863CurrentTrain: epoch  7, batch     3 | loss: 79.3138734CurrentTrain: epoch  7, batch     4 | loss: 15.6831366CurrentTrain: epoch  8, batch     0 | loss: 93.4568103CurrentTrain: epoch  8, batch     1 | loss: 65.6281829CurrentTrain: epoch  8, batch     2 | loss: 80.0644693CurrentTrain: epoch  8, batch     3 | loss: 120.7986205CurrentTrain: epoch  8, batch     4 | loss: 15.2450412CurrentTrain: epoch  9, batch     0 | loss: 80.3071951CurrentTrain: epoch  9, batch     1 | loss: 76.0279411CurrentTrain: epoch  9, batch     2 | loss: 76.0681953CurrentTrain: epoch  9, batch     3 | loss: 65.2313777CurrentTrain: epoch  9, batch     4 | loss: 40.4600119
MemoryTrain:  epoch  0, batch     0 | loss: 1.8150978MemoryTrain:  epoch  1, batch     0 | loss: 1.5849085MemoryTrain:  epoch  2, batch     0 | loss: 1.2358490MemoryTrain:  epoch  3, batch     0 | loss: 1.0596165MemoryTrain:  epoch  4, batch     0 | loss: 0.8347907MemoryTrain:  epoch  5, batch     0 | loss: 0.6576298MemoryTrain:  epoch  6, batch     0 | loss: 0.5101281MemoryTrain:  epoch  7, batch     0 | loss: 0.4972284MemoryTrain:  epoch  8, batch     0 | loss: 0.4449639MemoryTrain:  epoch  9, batch     0 | loss: 0.3580687

F1 score per class: {32: np.float64(0.6), 2: np.float64(0.0), 6: np.float64(0.5987261146496815), 39: np.float64(0.49333333333333335), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.2857142857142857), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.38095238095238093)}
Micro-average F1 score: 0.4841075794621027
Weighted-average F1 score: 0.4366301103076161
F1 score per class: {32: np.float64(0.64), 2: np.float64(0.0), 6: np.float64(0.3826086956521739), 39: np.float64(0.6120218579234973), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.30303030303030304), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.36363636363636365)}
Micro-average F1 score: 0.4460093896713615
Weighted-average F1 score: 0.3954255916671858
F1 score per class: {32: np.float64(0.6666666666666666), 2: np.float64(0.0), 6: np.float64(0.41025641025641024), 39: np.float64(0.6285714285714286), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.3076923076923077), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.34782608695652173)}
Micro-average F1 score: 0.4682926829268293
Weighted-average F1 score: 0.41732559875059305

F1 score per class: {32: np.float64(0.5454545454545454), 2: np.float64(0.625), 6: np.float64(0.47474747474747475), 39: np.float64(0.4088397790055249), 11: np.float64(0.8246445497630331), 12: np.float64(0.4), 19: np.float64(0.7472527472527473), 24: np.float64(0.17857142857142858), 26: np.float64(0.8911917098445595), 28: np.float64(0.801762114537445), 29: np.float64(0.34782608695652173)}
Micro-average F1 score: 0.6538214515093128
Weighted-average F1 score: 0.643836469057119
F1 score per class: {32: np.float64(0.5517241379310345), 2: np.float64(0.6065573770491803), 6: np.float64(0.34375), 39: np.float64(0.41947565543071164), 11: np.float64(0.8019323671497585), 12: np.float64(0.2535211267605634), 19: np.float64(0.7407407407407407), 24: np.float64(0.20833333333333334), 26: np.float64(0.8969072164948454), 28: np.float64(0.7530364372469636), 29: np.float64(0.32)}
Micro-average F1 score: 0.6197695573074591
Weighted-average F1 score: 0.607685807455092
F1 score per class: {32: np.float64(0.6086956521739131), 2: np.float64(0.6026200873362445), 6: np.float64(0.36363636363636365), 39: np.float64(0.43824701195219123), 11: np.float64(0.8019323671497585), 12: np.float64(0.3404255319148936), 19: np.float64(0.7419354838709677), 24: np.float64(0.19672131147540983), 26: np.float64(0.8969072164948454), 28: np.float64(0.7763713080168776), 29: np.float64(0.2857142857142857)}
Micro-average F1 score: 0.631974921630094
Weighted-average F1 score: 0.6212342209581294

F1 score per class: {32: np.float64(0.3870967741935484), 2: np.float64(0.0), 6: np.float64(0.46078431372549017), 39: np.float64(0.43529411764705883), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.13513513513513514), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.2962962962962963)}
Micro-average F1 score: 0.34554973821989526
Weighted-average F1 score: 0.29719906336293733
F1 score per class: {32: np.float64(0.38095238095238093), 2: np.float64(0.0), 6: np.float64(0.3076923076923077), 39: np.float64(0.5067873303167421), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.14925373134328357), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.25)}
Micro-average F1 score: 0.30844155844155846
Weighted-average F1 score: 0.2622713919699874
F1 score per class: {32: np.float64(0.4), 2: np.float64(0.0), 6: np.float64(0.3287671232876712), 39: np.float64(0.5288461538461539), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.15), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.22857142857142856)}
Micro-average F1 score: 0.3287671232876712
Weighted-average F1 score: 0.27995582949608094

F1 score per class: {32: np.float64(0.35294117647058826), 2: np.float64(0.3954802259887006), 6: np.float64(0.36015325670498083), 39: np.float64(0.2890625), 11: np.float64(0.7837837837837838), 12: np.float64(0.26666666666666666), 19: np.float64(0.6868686868686869), 24: np.float64(0.09259259259259259), 26: np.float64(0.8113207547169812), 28: np.float64(0.5928338762214984), 29: np.float64(0.2)}
Micro-average F1 score: 0.49610136452241715
Weighted-average F1 score: 0.4706116496753008
F1 score per class: {32: np.float64(0.3018867924528302), 2: np.float64(0.36633663366336633), 6: np.float64(0.275), 39: np.float64(0.2679425837320574), 11: np.float64(0.7614678899082569), 12: np.float64(0.15), 19: np.float64(0.6542056074766355), 24: np.float64(0.10869565217391304), 26: np.float64(0.8018433179723502), 28: np.float64(0.5585585585585585), 29: np.float64(0.19047619047619047)}
Micro-average F1 score: 0.45002201673271686
Weighted-average F1 score: 0.4223020390174342
F1 score per class: {32: np.float64(0.34146341463414637), 2: np.float64(0.3812154696132597), 6: np.float64(0.2909090909090909), 39: np.float64(0.2857142857142857), 11: np.float64(0.7614678899082569), 12: np.float64(0.21052631578947367), 19: np.float64(0.6602870813397129), 24: np.float64(0.1), 26: np.float64(0.8018433179723502), 28: np.float64(0.575), 29: np.float64(0.16)}
Micro-average F1 score: 0.46601941747572817
Weighted-average F1 score: 0.4389512981271358
cur_acc_wo_na:  ['0.7471', '0.4841']
his_acc_wo_na:  ['0.7471', '0.6538']
cur_acc des_wo_na:  ['0.7457', '0.4460']
his_acc des_wo_na:  ['0.7457', '0.6198']
cur_acc rrf_wo_na:  ['0.7528', '0.4683']
his_acc rrf_wo_na:  ['0.7528', '0.6320']
cur_acc_w_na:  ['0.6229', '0.3455']
his_acc_w_na:  ['0.6229', '0.4961']
cur_acc des_w_na:  ['0.6023', '0.3084']
his_acc des_w_na:  ['0.6023', '0.4500']
cur_acc rrf_w_na:  ['0.6163', '0.3288']
his_acc rrf_w_na:  ['0.6163', '0.4660']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 117.2458747CurrentTrain: epoch  0, batch     1 | loss: 81.1507655CurrentTrain: epoch  0, batch     2 | loss: 116.8590246CurrentTrain: epoch  0, batch     3 | loss: 9.8236620CurrentTrain: epoch  1, batch     0 | loss: 74.7637659CurrentTrain: epoch  1, batch     1 | loss: 73.9313730CurrentTrain: epoch  1, batch     2 | loss: 86.1297308CurrentTrain: epoch  1, batch     3 | loss: 12.1034741CurrentTrain: epoch  2, batch     0 | loss: 70.0658201CurrentTrain: epoch  2, batch     1 | loss: 84.7144495CurrentTrain: epoch  2, batch     2 | loss: 73.2457972CurrentTrain: epoch  2, batch     3 | loss: 12.5248223CurrentTrain: epoch  3, batch     0 | loss: 124.7250350CurrentTrain: epoch  3, batch     1 | loss: 81.7111659CurrentTrain: epoch  3, batch     2 | loss: 64.1427341CurrentTrain: epoch  3, batch     3 | loss: 17.8104597CurrentTrain: epoch  4, batch     0 | loss: 126.0950689CurrentTrain: epoch  4, batch     1 | loss: 64.3294326CurrentTrain: epoch  4, batch     2 | loss: 66.2033113CurrentTrain: epoch  4, batch     3 | loss: 6.1867118CurrentTrain: epoch  5, batch     0 | loss: 65.4005099CurrentTrain: epoch  5, batch     1 | loss: 94.7416254CurrentTrain: epoch  5, batch     2 | loss: 77.5409073CurrentTrain: epoch  5, batch     3 | loss: 9.9339939CurrentTrain: epoch  6, batch     0 | loss: 67.0373032CurrentTrain: epoch  6, batch     1 | loss: 92.1068118CurrentTrain: epoch  6, batch     2 | loss: 74.9276065CurrentTrain: epoch  6, batch     3 | loss: 19.1326269CurrentTrain: epoch  7, batch     0 | loss: 71.4394094CurrentTrain: epoch  7, batch     1 | loss: 91.8224745CurrentTrain: epoch  7, batch     2 | loss: 73.6694942CurrentTrain: epoch  7, batch     3 | loss: 9.6286993CurrentTrain: epoch  8, batch     0 | loss: 96.0749974CurrentTrain: epoch  8, batch     1 | loss: 75.1724661CurrentTrain: epoch  8, batch     2 | loss: 58.1851432CurrentTrain: epoch  8, batch     3 | loss: 9.1773956CurrentTrain: epoch  9, batch     0 | loss: 63.6595425CurrentTrain: epoch  9, batch     1 | loss: 91.8272564CurrentTrain: epoch  9, batch     2 | loss: 60.8430606CurrentTrain: epoch  9, batch     3 | loss: 9.3244852
MemoryTrain:  epoch  0, batch     0 | loss: 1.1756485MemoryTrain:  epoch  1, batch     0 | loss: 0.9640379MemoryTrain:  epoch  2, batch     0 | loss: 0.7789200MemoryTrain:  epoch  3, batch     0 | loss: 0.6608379MemoryTrain:  epoch  4, batch     0 | loss: 0.6027999MemoryTrain:  epoch  5, batch     0 | loss: 0.4446754MemoryTrain:  epoch  6, batch     0 | loss: 0.3582092MemoryTrain:  epoch  7, batch     0 | loss: 0.3206353MemoryTrain:  epoch  8, batch     0 | loss: 0.2781380MemoryTrain:  epoch  9, batch     0 | loss: 0.2453915

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.75), 7: np.float64(0.8846153846153846), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.2222222222222222), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.36220472440944884)}
Micro-average F1 score: 0.3923076923076923
Weighted-average F1 score: 0.32692595788540135
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.75), 7: np.float64(0.7384615384615385), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.375), 26: np.float64(0.3333333333333333), 27: np.float64(0.0), 31: np.float64(0.39344262295081966)}
Micro-average F1 score: 0.39285714285714285
Weighted-average F1 score: 0.32984478899203373
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.75), 7: np.float64(0.7868852459016393), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.47058823529411764), 26: np.float64(0.4), 27: np.float64(0.0), 31: np.float64(0.3870967741935484)}
Micro-average F1 score: 0.4132841328413284
Weighted-average F1 score: 0.3474570439654303

F1 score per class: {32: np.float64(0.5263157894736842), 2: np.float64(0.32116788321167883), 6: np.float64(0.06451612903225806), 7: np.float64(0.8846153846153846), 40: np.float64(0.5161290322580645), 11: np.float64(0.15748031496062992), 12: np.float64(0.652542372881356), 39: np.float64(0.18181818181818182), 9: np.float64(0.7167630057803468), 19: np.float64(0.18181818181818182), 24: np.float64(0.2692307692307692), 26: np.float64(0.8736842105263158), 27: np.float64(0.0), 28: np.float64(0.8285714285714286), 29: np.float64(0.23529411764705882), 31: np.float64(0.19742489270386265)}
Micro-average F1 score: 0.5128792215226102
Weighted-average F1 score: 0.4944096882550882
F1 score per class: {32: np.float64(0.5161290322580645), 2: np.float64(0.2900763358778626), 6: np.float64(0.061224489795918366), 7: np.float64(0.7164179104477612), 40: np.float64(0.3492063492063492), 11: np.float64(0.2485207100591716), 12: np.float64(0.6403162055335968), 39: np.float64(0.24242424242424243), 9: np.float64(0.75), 19: np.float64(0.2608695652173913), 24: np.float64(0.16129032258064516), 26: np.float64(0.8783068783068783), 27: np.float64(0.125), 28: np.float64(0.7981651376146789), 29: np.float64(0.18181818181818182), 31: np.float64(0.23300970873786409)}
Micro-average F1 score: 0.4989059080962801
Weighted-average F1 score: 0.4805197411340241
F1 score per class: {32: np.float64(0.6666666666666666), 2: np.float64(0.2962962962962963), 6: np.float64(0.06521739130434782), 7: np.float64(0.7619047619047619), 40: np.float64(0.38461538461538464), 11: np.float64(0.24285714285714285), 12: np.float64(0.6374501992031872), 39: np.float64(0.3076923076923077), 9: np.float64(0.7403314917127072), 19: np.float64(0.32), 24: np.float64(0.14925373134328357), 26: np.float64(0.8783068783068783), 27: np.float64(0.18181818181818182), 28: np.float64(0.8075117370892019), 29: np.float64(0.19047619047619047), 31: np.float64(0.21621621621621623)}
Micro-average F1 score: 0.5058757694459989
Weighted-average F1 score: 0.4862364996998351

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6666666666666666), 7: np.float64(0.8214285714285714), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.21052631578947367), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.3382352941176471)}
Micro-average F1 score: 0.35789473684210527
Weighted-average F1 score: 0.3015946298494775
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6666666666666666), 7: np.float64(0.6857142857142857), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.35294117647058826), 26: np.float64(0.0), 27: np.float64(0.2), 28: np.float64(0.0), 31: np.float64(0.37209302325581395)}
Micro-average F1 score: 0.3492063492063492
Weighted-average F1 score: 0.29128126548548383
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6666666666666666), 7: np.float64(0.7384615384615385), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.4444444444444444), 26: np.float64(0.0), 27: np.float64(0.2222222222222222), 28: np.float64(0.0), 31: np.float64(0.3582089552238806)}
Micro-average F1 score: 0.37209302325581395
Weighted-average F1 score: 0.31489965502256984

F1 score per class: {32: np.float64(0.35714285714285715), 2: np.float64(0.22), 6: np.float64(0.03773584905660377), 7: np.float64(0.8214285714285714), 40: np.float64(0.4166666666666667), 11: np.float64(0.14084507042253522), 12: np.float64(0.6184738955823293), 39: np.float64(0.15384615384615385), 9: np.float64(0.6631016042780749), 19: np.float64(0.16), 24: np.float64(0.13333333333333333), 26: np.float64(0.7942583732057417), 27: np.float64(0.0), 28: np.float64(0.6877470355731226), 29: np.float64(0.125), 31: np.float64(0.16727272727272727)}
Micro-average F1 score: 0.4157772621809745
Weighted-average F1 score: 0.385805356380367
F1 score per class: {32: np.float64(0.3018867924528302), 2: np.float64(0.20765027322404372), 6: np.float64(0.033707865168539325), 7: np.float64(0.6486486486486487), 40: np.float64(0.2857142857142857), 39: np.float64(0.19090909090909092), 12: np.float64(0.6044776119402985), 11: np.float64(0.16666666666666666), 9: np.float64(0.6699029126213593), 19: np.float64(0.20689655172413793), 24: np.float64(0.07575757575757576), 26: np.float64(0.8097560975609757), 27: np.float64(0.06451612903225806), 28: np.float64(0.6373626373626373), 29: np.float64(0.0975609756097561), 31: np.float64(0.20253164556962025)}
Micro-average F1 score: 0.3910806174957118
Weighted-average F1 score: 0.36025532854740694
F1 score per class: {32: np.float64(0.4375), 2: np.float64(0.2127659574468085), 6: np.float64(0.03636363636363636), 7: np.float64(0.7058823529411765), 40: np.float64(0.31446540880503143), 11: np.float64(0.19540229885057472), 12: np.float64(0.6037735849056604), 39: np.float64(0.25), 9: np.float64(0.6767676767676768), 19: np.float64(0.25), 24: np.float64(0.06993006993006994), 26: np.float64(0.8058252427184466), 27: np.float64(0.08333333333333333), 28: np.float64(0.6590038314176245), 29: np.float64(0.1111111111111111), 31: np.float64(0.1839080459770115)}
Micro-average F1 score: 0.4028520499108734
Weighted-average F1 score: 0.37039735502375437
cur_acc_wo_na:  ['0.7471', '0.4841', '0.3923']
his_acc_wo_na:  ['0.7471', '0.6538', '0.5129']
cur_acc des_wo_na:  ['0.7457', '0.4460', '0.3929']
his_acc des_wo_na:  ['0.7457', '0.6198', '0.4989']
cur_acc rrf_wo_na:  ['0.7528', '0.4683', '0.4133']
his_acc rrf_wo_na:  ['0.7528', '0.6320', '0.5059']
cur_acc_w_na:  ['0.6229', '0.3455', '0.3579']
his_acc_w_na:  ['0.6229', '0.4961', '0.4158']
cur_acc des_w_na:  ['0.6023', '0.3084', '0.3492']
his_acc des_w_na:  ['0.6023', '0.4500', '0.3911']
cur_acc rrf_w_na:  ['0.6163', '0.3288', '0.3721']
his_acc rrf_w_na:  ['0.6163', '0.4660', '0.4029']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 88.2147187CurrentTrain: epoch  0, batch     1 | loss: 92.5903840CurrentTrain: epoch  0, batch     2 | loss: 121.2346473CurrentTrain: epoch  0, batch     3 | loss: 131.5089330CurrentTrain: epoch  1, batch     0 | loss: 76.1633264CurrentTrain: epoch  1, batch     1 | loss: 109.0189368CurrentTrain: epoch  1, batch     2 | loss: 84.9454684CurrentTrain: epoch  1, batch     3 | loss: 74.9757989CurrentTrain: epoch  2, batch     0 | loss: 87.3918342CurrentTrain: epoch  2, batch     1 | loss: 73.6092505CurrentTrain: epoch  2, batch     2 | loss: 70.8013109CurrentTrain: epoch  2, batch     3 | loss: 89.7445293CurrentTrain: epoch  3, batch     0 | loss: 104.3644092CurrentTrain: epoch  3, batch     1 | loss: 82.6572671CurrentTrain: epoch  3, batch     2 | loss: 84.0304169CurrentTrain: epoch  3, batch     3 | loss: 57.6568766CurrentTrain: epoch  4, batch     0 | loss: 82.0993467CurrentTrain: epoch  4, batch     1 | loss: 98.1021220CurrentTrain: epoch  4, batch     2 | loss: 126.1589829CurrentTrain: epoch  4, batch     3 | loss: 51.5191752CurrentTrain: epoch  5, batch     0 | loss: 98.8071993CurrentTrain: epoch  5, batch     1 | loss: 76.4501987CurrentTrain: epoch  5, batch     2 | loss: 100.0830095CurrentTrain: epoch  5, batch     3 | loss: 44.4222848CurrentTrain: epoch  6, batch     0 | loss: 126.4921342CurrentTrain: epoch  6, batch     1 | loss: 88.7620818CurrentTrain: epoch  6, batch     2 | loss: 79.2703502CurrentTrain: epoch  6, batch     3 | loss: 63.1412237CurrentTrain: epoch  7, batch     0 | loss: 80.0438119CurrentTrain: epoch  7, batch     1 | loss: 63.6038291CurrentTrain: epoch  7, batch     2 | loss: 80.5328732CurrentTrain: epoch  7, batch     3 | loss: 52.4222107CurrentTrain: epoch  8, batch     0 | loss: 96.2923872CurrentTrain: epoch  8, batch     1 | loss: 66.1394804CurrentTrain: epoch  8, batch     2 | loss: 76.1389097CurrentTrain: epoch  8, batch     3 | loss: 63.8477879CurrentTrain: epoch  9, batch     0 | loss: 77.8182103CurrentTrain: epoch  9, batch     1 | loss: 93.3323877CurrentTrain: epoch  9, batch     2 | loss: 62.8108620CurrentTrain: epoch  9, batch     3 | loss: 80.9215334
MemoryTrain:  epoch  0, batch     0 | loss: 1.0382261MemoryTrain:  epoch  1, batch     0 | loss: 0.9297001MemoryTrain:  epoch  2, batch     0 | loss: 0.7480367MemoryTrain:  epoch  3, batch     0 | loss: 0.6406517MemoryTrain:  epoch  4, batch     0 | loss: 0.5047945MemoryTrain:  epoch  5, batch     0 | loss: 0.4176835MemoryTrain:  epoch  6, batch     0 | loss: 0.3759391MemoryTrain:  epoch  7, batch     0 | loss: 0.2985383MemoryTrain:  epoch  8, batch     0 | loss: 0.2917476MemoryTrain:  epoch  9, batch     0 | loss: 0.2471093

F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.8333333333333334), 19: np.float64(0.0), 25: np.float64(0.4857142857142857), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.7708333333333334), 37: np.float64(0.6050420168067226), 38: np.float64(0.55), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5285714285714286
Weighted-average F1 score: 0.4447237570827418
F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.64), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.7555555555555555), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.780952380952381), 37: np.float64(0.4954128440366973), 38: np.float64(0.6938775510204082), 40: np.float64(0.0)}
Micro-average F1 score: 0.5049701789264414
Weighted-average F1 score: 0.3951297934164451
F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.5625), 19: np.float64(0.0), 25: np.float64(0.691358024691358), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.780952380952381), 37: np.float64(0.4915254237288136), 38: np.float64(0.6363636363636364), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5
Weighted-average F1 score: 0.4003042545779764

F1 score per class: {2: np.float64(0.6086956521739131), 6: np.float64(0.31654676258992803), 7: np.float64(0.05504587155963303), 9: np.float64(0.8771929824561403), 11: np.float64(0.39759036144578314), 12: np.float64(0.15151515151515152), 15: np.float64(0.47619047619047616), 19: np.float64(0.6332046332046332), 24: np.float64(0.1), 25: np.float64(0.4857142857142857), 26: np.float64(0.7444444444444445), 27: np.float64(0.34146341463414637), 28: np.float64(0.1917808219178082), 29: np.float64(0.8677248677248677), 31: np.float64(0.16666666666666666), 32: np.float64(0.7665198237885462), 35: np.float64(0.5068493150684932), 37: np.float64(0.2926829268292683), 38: np.float64(0.39285714285714285), 39: np.float64(0.125), 40: np.float64(0.22564102564102564)}
Micro-average F1 score: 0.4737281067556297
Weighted-average F1 score: 0.45678041586551593
F1 score per class: {2: np.float64(0.34782608695652173), 6: np.float64(0.4406779661016949), 7: np.float64(0.0380952380952381), 9: np.float64(0.5747126436781609), 11: np.float64(0.47342995169082125), 12: np.float64(0.29245283018867924), 15: np.float64(0.3076923076923077), 19: np.float64(0.5878136200716846), 24: np.float64(0.2857142857142857), 25: np.float64(0.7555555555555555), 26: np.float64(0.7351351351351352), 27: np.float64(0.2702702702702703), 28: np.float64(0.11382113821138211), 29: np.float64(0.8865979381443299), 31: np.float64(0.0), 32: np.float64(0.7317073170731707), 35: np.float64(0.4880952380952381), 37: np.float64(0.2608695652173913), 38: np.float64(0.40963855421686746), 39: np.float64(0.13333333333333333), 40: np.float64(0.18811881188118812)}
Micro-average F1 score: 0.4654178674351585
Weighted-average F1 score: 0.4327319232567211
F1 score per class: {2: np.float64(0.4375), 6: np.float64(0.4260355029585799), 7: np.float64(0.0380952380952381), 9: np.float64(0.7352941176470589), 11: np.float64(0.44776119402985076), 12: np.float64(0.25316455696202533), 15: np.float64(0.2608695652173913), 19: np.float64(0.5857142857142857), 24: np.float64(0.17391304347826086), 25: np.float64(0.691358024691358), 26: np.float64(0.7472527472527473), 27: np.float64(0.3111111111111111), 28: np.float64(0.12173913043478261), 29: np.float64(0.875), 31: np.float64(0.0), 32: np.float64(0.7639484978540773), 35: np.float64(0.4659090909090909), 37: np.float64(0.2457627118644068), 38: np.float64(0.4117647058823529), 39: np.float64(0.125), 40: np.float64(0.17592592592592593)}
Micro-average F1 score: 0.45912653975363943
Weighted-average F1 score: 0.4251888299442835

F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.6666666666666666), 19: np.float64(0.0), 25: np.float64(0.4358974358974359), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6434782608695652), 37: np.float64(0.496551724137931), 38: np.float64(0.4888888888888889), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4014466546112116
Weighted-average F1 score: 0.3305888722305514
F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.5161290322580645), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.6732673267326733), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6307692307692307), 37: np.float64(0.432), 38: np.float64(0.5230769230769231), 40: np.float64(0.0)}
Micro-average F1 score: 0.3675832127351664
Weighted-average F1 score: 0.28794576341211375
F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.45), 19: np.float64(0.0), 25: np.float64(0.6153846153846154), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.640625), 37: np.float64(0.4233576642335766), 38: np.float64(0.56), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.37753510140405616
Weighted-average F1 score: 0.2994242389681486

F1 score per class: {2: np.float64(0.4117647058823529), 6: np.float64(0.23036649214659685), 7: np.float64(0.028846153846153848), 9: np.float64(0.8064516129032258), 11: np.float64(0.3333333333333333), 12: np.float64(0.125), 15: np.float64(0.29850746268656714), 19: np.float64(0.5942028985507246), 24: np.float64(0.09090909090909091), 25: np.float64(0.4358974358974359), 26: np.float64(0.6733668341708543), 27: np.float64(0.24561403508771928), 28: np.float64(0.09929078014184398), 29: np.float64(0.7627906976744186), 31: np.float64(0.07692307692307693), 32: np.float64(0.5958904109589042), 35: np.float64(0.32456140350877194), 37: np.float64(0.16981132075471697), 38: np.float64(0.29333333333333333), 39: np.float64(0.1111111111111111), 40: np.float64(0.18333333333333332)}
Micro-average F1 score: 0.3537838679539084
Weighted-average F1 score: 0.3257438407123936
F1 score per class: {2: np.float64(0.19753086419753085), 6: np.float64(0.2988505747126437), 7: np.float64(0.0196078431372549), 9: np.float64(0.4716981132075472), 11: np.float64(0.3656716417910448), 12: np.float64(0.18674698795180722), 15: np.float64(0.19047619047619047), 19: np.float64(0.543046357615894), 24: np.float64(0.1891891891891892), 25: np.float64(0.6732673267326733), 26: np.float64(0.6296296296296297), 27: np.float64(0.17857142857142858), 28: np.float64(0.059574468085106386), 29: np.float64(0.7678571428571429), 31: np.float64(0.0), 32: np.float64(0.5625), 35: np.float64(0.311787072243346), 37: np.float64(0.15083798882681565), 38: np.float64(0.23129251700680273), 39: np.float64(0.13333333333333333), 40: np.float64(0.152)}
Micro-average F1 score: 0.329171974522293
Weighted-average F1 score: 0.2993628571303737
F1 score per class: {2: np.float64(0.30434782608695654), 6: np.float64(0.2926829268292683), 7: np.float64(0.019230769230769232), 9: np.float64(0.6666666666666666), 11: np.float64(0.3515625), 12: np.float64(0.18779342723004694), 15: np.float64(0.1592920353982301), 19: np.float64(0.543046357615894), 24: np.float64(0.14285714285714285), 25: np.float64(0.6086956521739131), 26: np.float64(0.6601941747572816), 27: np.float64(0.2028985507246377), 28: np.float64(0.0625), 29: np.float64(0.7567567567567568), 31: np.float64(0.0), 32: np.float64(0.5836065573770491), 35: np.float64(0.3025830258302583), 37: np.float64(0.14427860696517414), 38: np.float64(0.27450980392156865), 39: np.float64(0.1111111111111111), 40: np.float64(0.13818181818181818)}
Micro-average F1 score: 0.3321631109910883
Weighted-average F1 score: 0.29981328324943385
cur_acc_wo_na:  ['0.7471', '0.4841', '0.3923', '0.5286']
his_acc_wo_na:  ['0.7471', '0.6538', '0.5129', '0.4737']
cur_acc des_wo_na:  ['0.7457', '0.4460', '0.3929', '0.5050']
his_acc des_wo_na:  ['0.7457', '0.6198', '0.4989', '0.4654']
cur_acc rrf_wo_na:  ['0.7528', '0.4683', '0.4133', '0.5000']
his_acc rrf_wo_na:  ['0.7528', '0.6320', '0.5059', '0.4591']
cur_acc_w_na:  ['0.6229', '0.3455', '0.3579', '0.4014']
his_acc_w_na:  ['0.6229', '0.4961', '0.4158', '0.3538']
cur_acc des_w_na:  ['0.6023', '0.3084', '0.3492', '0.3676']
his_acc des_w_na:  ['0.6023', '0.4500', '0.3911', '0.3292']
cur_acc rrf_w_na:  ['0.6163', '0.3288', '0.3721', '0.3775']
his_acc rrf_w_na:  ['0.6163', '0.4660', '0.4029', '0.3322']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 143.1619363CurrentTrain: epoch  0, batch     1 | loss: 99.7049003CurrentTrain: epoch  0, batch     2 | loss: 103.5970192CurrentTrain: epoch  0, batch     3 | loss: 114.0479588CurrentTrain: epoch  0, batch     4 | loss: 79.7086259CurrentTrain: epoch  1, batch     0 | loss: 90.1861482CurrentTrain: epoch  1, batch     1 | loss: 112.6484844CurrentTrain: epoch  1, batch     2 | loss: 76.8043984CurrentTrain: epoch  1, batch     3 | loss: 106.3370554CurrentTrain: epoch  1, batch     4 | loss: 105.3641300CurrentTrain: epoch  2, batch     0 | loss: 87.5824351CurrentTrain: epoch  2, batch     1 | loss: 89.5164220CurrentTrain: epoch  2, batch     2 | loss: 76.5859797CurrentTrain: epoch  2, batch     3 | loss: 86.9584498CurrentTrain: epoch  2, batch     4 | loss: 101.0029436CurrentTrain: epoch  3, batch     0 | loss: 69.4860727CurrentTrain: epoch  3, batch     1 | loss: 103.1770502CurrentTrain: epoch  3, batch     2 | loss: 87.6272607CurrentTrain: epoch  3, batch     3 | loss: 105.0186127CurrentTrain: epoch  3, batch     4 | loss: 150.8659002CurrentTrain: epoch  4, batch     0 | loss: 81.4748708CurrentTrain: epoch  4, batch     1 | loss: 104.0651989CurrentTrain: epoch  4, batch     2 | loss: 84.2299205CurrentTrain: epoch  4, batch     3 | loss: 82.4967876CurrentTrain: epoch  4, batch     4 | loss: 70.9852026CurrentTrain: epoch  5, batch     0 | loss: 127.2624180CurrentTrain: epoch  5, batch     1 | loss: 67.4255233CurrentTrain: epoch  5, batch     2 | loss: 98.2223081CurrentTrain: epoch  5, batch     3 | loss: 97.3744951CurrentTrain: epoch  5, batch     4 | loss: 69.9752103CurrentTrain: epoch  6, batch     0 | loss: 98.0091310CurrentTrain: epoch  6, batch     1 | loss: 70.2128628CurrentTrain: epoch  6, batch     2 | loss: 99.1218630CurrentTrain: epoch  6, batch     3 | loss: 99.1988192CurrentTrain: epoch  6, batch     4 | loss: 36.3916490CurrentTrain: epoch  7, batch     0 | loss: 95.0553167CurrentTrain: epoch  7, batch     1 | loss: 79.9938422CurrentTrain: epoch  7, batch     2 | loss: 78.3666586CurrentTrain: epoch  7, batch     3 | loss: 98.3914256CurrentTrain: epoch  7, batch     4 | loss: 53.5287245CurrentTrain: epoch  8, batch     0 | loss: 95.8883101CurrentTrain: epoch  8, batch     1 | loss: 66.3455284CurrentTrain: epoch  8, batch     2 | loss: 95.9553723CurrentTrain: epoch  8, batch     3 | loss: 76.0827391CurrentTrain: epoch  8, batch     4 | loss: 52.6579052CurrentTrain: epoch  9, batch     0 | loss: 76.5369723CurrentTrain: epoch  9, batch     1 | loss: 63.4434867CurrentTrain: epoch  9, batch     2 | loss: 80.6227995CurrentTrain: epoch  9, batch     3 | loss: 120.6860757CurrentTrain: epoch  9, batch     4 | loss: 70.3166552
MemoryTrain:  epoch  0, batch     0 | loss: 1.3808093MemoryTrain:  epoch  1, batch     0 | loss: 1.2275994MemoryTrain:  epoch  2, batch     0 | loss: 0.9961095MemoryTrain:  epoch  3, batch     0 | loss: 0.8549667MemoryTrain:  epoch  4, batch     0 | loss: 0.7271066MemoryTrain:  epoch  5, batch     0 | loss: 0.6904108MemoryTrain:  epoch  6, batch     0 | loss: 0.5468059MemoryTrain:  epoch  7, batch     0 | loss: 0.4110648MemoryTrain:  epoch  8, batch     0 | loss: 0.3412694MemoryTrain:  epoch  9, batch     0 | loss: 0.3085765

F1 score per class: {1: np.float64(0.21301775147928995), 3: np.float64(0.7450980392156863), 6: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 14: np.float64(0.10126582278481013), 19: np.float64(0.0), 22: np.float64(0.5327868852459017), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6455696202531646), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.40498442367601245
Weighted-average F1 score: 0.3620414210775041
F1 score per class: {1: np.float64(0.23391812865497075), 2: np.float64(0.0), 3: np.float64(0.5964912280701754), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.05555555555555555), 15: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.5223880597014925), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6938775510204082), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.32967032967032966
Weighted-average F1 score: 0.28208191180560804
F1 score per class: {1: np.float64(0.23668639053254437), 3: np.float64(0.6033519553072626), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.11650485436893204), 19: np.float64(0.0), 22: np.float64(0.5255474452554745), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6623376623376623), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.35645302897278314
Weighted-average F1 score: 0.3139501527090199

F1 score per class: {1: np.float64(0.16901408450704225), 2: np.float64(0.5555555555555556), 3: np.float64(0.5112107623318386), 6: np.float64(0.3724137931034483), 7: np.float64(0.0425531914893617), 9: np.float64(0.8135593220338984), 11: np.float64(0.14285714285714285), 12: np.float64(0.05084745762711865), 14: np.float64(0.0898876404494382), 15: np.float64(0.6956521739130435), 19: np.float64(0.5494505494505495), 22: np.float64(0.46099290780141844), 24: np.float64(0.0), 25: np.float64(0.3939393939393939), 26: np.float64(0.7486033519553073), 27: np.float64(0.0), 28: np.float64(0.1794871794871795), 29: np.float64(0.8615384615384616), 31: np.float64(0.0), 32: np.float64(0.6666666666666666), 34: np.float64(0.21030927835051547), 35: np.float64(0.1875), 37: np.float64(0.22429906542056074), 38: np.float64(0.3283582089552239), 39: np.float64(0.125), 40: np.float64(0.2485207100591716)}
Micro-average F1 score: 0.3829660512209649
Weighted-average F1 score: 0.37176507810361803
F1 score per class: {1: np.float64(0.17316017316017315), 2: np.float64(0.3181818181818182), 3: np.float64(0.3923076923076923), 6: np.float64(0.38596491228070173), 7: np.float64(0.039603960396039604), 9: np.float64(0.5681818181818182), 11: np.float64(0.11538461538461539), 12: np.float64(0.25), 14: np.float64(0.039473684210526314), 15: np.float64(0.36363636363636365), 19: np.float64(0.5369127516778524), 22: np.float64(0.43613707165109034), 24: np.float64(0.07692307692307693), 25: np.float64(0.7529411764705882), 26: np.float64(0.7301587301587301), 27: np.float64(0.0), 28: np.float64(0.109375), 29: np.float64(0.8527918781725888), 31: np.float64(0.0), 32: np.float64(0.5487364620938628), 34: np.float64(0.2518518518518518), 35: np.float64(0.24561403508771928), 37: np.float64(0.16993464052287582), 38: np.float64(0.37623762376237624), 39: np.float64(0.0), 40: np.float64(0.21505376344086022)}
Micro-average F1 score: 0.36212958312405824
Weighted-average F1 score: 0.3443851825842766
F1 score per class: {1: np.float64(0.17937219730941703), 2: np.float64(0.6363636363636364), 3: np.float64(0.38162544169611307), 6: np.float64(0.39751552795031053), 7: np.float64(0.039603960396039604), 9: np.float64(0.7352941176470589), 11: np.float64(0.12), 12: np.float64(0.2097902097902098), 14: np.float64(0.08571428571428572), 15: np.float64(0.48), 19: np.float64(0.5369127516778524), 22: np.float64(0.4298507462686567), 24: np.float64(0.0), 25: np.float64(0.6052631578947368), 26: np.float64(0.745945945945946), 27: np.float64(0.0), 28: np.float64(0.11864406779661017), 29: np.float64(0.8527918781725888), 31: np.float64(0.0), 32: np.float64(0.5703422053231939), 34: np.float64(0.22666666666666666), 35: np.float64(0.23448275862068965), 37: np.float64(0.18181818181818182), 38: np.float64(0.3291139240506329), 39: np.float64(0.0), 40: np.float64(0.20408163265306123)}
Micro-average F1 score: 0.3648259617901073
Weighted-average F1 score: 0.3478698389826581

F1 score per class: {1: np.float64(0.12203389830508475), 2: np.float64(0.0), 3: np.float64(0.6031746031746031), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 14: np.float64(0.09195402298850575), 19: np.float64(0.0), 22: np.float64(0.4126984126984127), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.44155844155844154), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.27956989247311825
Weighted-average F1 score: 0.2508683327313839
F1 score per class: {1: np.float64(0.12987012987012986), 2: np.float64(0.0), 3: np.float64(0.4180327868852459), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.046153846153846156), 15: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.3954802259887006), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.5), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.21678710394663703
Weighted-average F1 score: 0.19237463234939262
F1 score per class: {1: np.float64(0.13071895424836602), 2: np.float64(0.0), 3: np.float64(0.416988416988417), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.10084033613445378), 15: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.3988919667590028), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.4594594594594595), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2365967365967366
Weighted-average F1 score: 0.21459850548690096

F1 score per class: {1: np.float64(0.09498680738786279), 2: np.float64(0.3333333333333333), 3: np.float64(0.36538461538461536), 6: np.float64(0.27), 7: np.float64(0.021164021164021163), 9: np.float64(0.7384615384615385), 11: np.float64(0.13861386138613863), 12: np.float64(0.044444444444444446), 14: np.float64(0.07692307692307693), 15: np.float64(0.5333333333333333), 19: np.float64(0.5), 22: np.float64(0.3394255874673629), 24: np.float64(0.0), 25: np.float64(0.3611111111111111), 26: np.float64(0.67), 27: np.float64(0.0), 28: np.float64(0.10071942446043165), 29: np.float64(0.7304347826086957), 31: np.float64(0.0), 32: np.float64(0.5), 34: np.float64(0.12927756653992395), 35: np.float64(0.140625), 37: np.float64(0.13043478260869565), 38: np.float64(0.25287356321839083), 39: np.float64(0.1111111111111111), 40: np.float64(0.2131979695431472)}
Micro-average F1 score: 0.27835497835497836
Weighted-average F1 score: 0.25953392806409226
F1 score per class: {1: np.float64(0.0947867298578199), 2: np.float64(0.18666666666666668), 3: np.float64(0.24938875305623473), 6: np.float64(0.23826714801444043), 7: np.float64(0.0213903743315508), 9: np.float64(0.42016806722689076), 11: np.float64(0.10619469026548672), 12: np.float64(0.17667844522968199), 14: np.float64(0.02912621359223301), 15: np.float64(0.26666666666666666), 19: np.float64(0.47761194029850745), 22: np.float64(0.3036876355748373), 24: np.float64(0.07407407407407407), 25: np.float64(0.6736842105263158), 26: np.float64(0.6301369863013698), 27: np.float64(0.0), 28: np.float64(0.059322033898305086), 29: np.float64(0.721030042918455), 31: np.float64(0.0), 32: np.float64(0.3989501312335958), 34: np.float64(0.1574074074074074), 35: np.float64(0.15730337078651685), 37: np.float64(0.12322274881516587), 38: np.float64(0.2159090909090909), 39: np.float64(0.0), 40: np.float64(0.18604651162790697)}
Micro-average F1 score: 0.25170186769069647
Weighted-average F1 score: 0.23456506155324897
F1 score per class: {1: np.float64(0.0954653937947494), 2: np.float64(0.358974358974359), 3: np.float64(0.23893805309734514), 6: np.float64(0.25296442687747034), 7: np.float64(0.02127659574468085), 9: np.float64(0.6578947368421053), 11: np.float64(0.11009174311926606), 12: np.float64(0.1694915254237288), 14: np.float64(0.06629834254143646), 15: np.float64(0.3333333333333333), 19: np.float64(0.47904191616766467), 22: np.float64(0.3031578947368421), 24: np.float64(0.0), 25: np.float64(0.5476190476190477), 26: np.float64(0.6509433962264151), 27: np.float64(0.0), 28: np.float64(0.0603448275862069), 29: np.float64(0.721030042918455), 31: np.float64(0.0), 32: np.float64(0.42134831460674155), 34: np.float64(0.14206128133704735), 35: np.float64(0.1511111111111111), 37: np.float64(0.12935323383084577), 38: np.float64(0.2184873949579832), 39: np.float64(0.0), 40: np.float64(0.17167381974248927)}
Micro-average F1 score: 0.2563442442074292
Weighted-average F1 score: 0.23814070843984267
cur_acc_wo_na:  ['0.7471', '0.4841', '0.3923', '0.5286', '0.4050']
his_acc_wo_na:  ['0.7471', '0.6538', '0.5129', '0.4737', '0.3830']
cur_acc des_wo_na:  ['0.7457', '0.4460', '0.3929', '0.5050', '0.3297']
his_acc des_wo_na:  ['0.7457', '0.6198', '0.4989', '0.4654', '0.3621']
cur_acc rrf_wo_na:  ['0.7528', '0.4683', '0.4133', '0.5000', '0.3565']
his_acc rrf_wo_na:  ['0.7528', '0.6320', '0.5059', '0.4591', '0.3648']
cur_acc_w_na:  ['0.6229', '0.3455', '0.3579', '0.4014', '0.2796']
his_acc_w_na:  ['0.6229', '0.4961', '0.4158', '0.3538', '0.2784']
cur_acc des_w_na:  ['0.6023', '0.3084', '0.3492', '0.3676', '0.2168']
his_acc des_w_na:  ['0.6023', '0.4500', '0.3911', '0.3292', '0.2517']
cur_acc rrf_w_na:  ['0.6163', '0.3288', '0.3721', '0.3775', '0.2366']
his_acc rrf_w_na:  ['0.6163', '0.4660', '0.4029', '0.3322', '0.2563']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 86.1526078CurrentTrain: epoch  0, batch     1 | loss: 86.1489931CurrentTrain: epoch  0, batch     2 | loss: 146.6859841CurrentTrain: epoch  0, batch     3 | loss: 82.1840416CurrentTrain: epoch  1, batch     0 | loss: 130.6428392CurrentTrain: epoch  1, batch     1 | loss: 80.1973427CurrentTrain: epoch  1, batch     2 | loss: 88.0365282CurrentTrain: epoch  1, batch     3 | loss: 113.7111152CurrentTrain: epoch  2, batch     0 | loss: 107.0262193CurrentTrain: epoch  2, batch     1 | loss: 105.3506336CurrentTrain: epoch  2, batch     2 | loss: 73.1864872CurrentTrain: epoch  2, batch     3 | loss: 70.6256138CurrentTrain: epoch  3, batch     0 | loss: 84.7482727CurrentTrain: epoch  3, batch     1 | loss: 176.3192503CurrentTrain: epoch  3, batch     2 | loss: 70.5292472CurrentTrain: epoch  3, batch     3 | loss: 66.1527086CurrentTrain: epoch  4, batch     0 | loss: 100.3173592CurrentTrain: epoch  4, batch     1 | loss: 79.4641377CurrentTrain: epoch  4, batch     2 | loss: 83.9970706CurrentTrain: epoch  4, batch     3 | loss: 69.0163199CurrentTrain: epoch  5, batch     0 | loss: 78.8044064CurrentTrain: epoch  5, batch     1 | loss: 102.3756960CurrentTrain: epoch  5, batch     2 | loss: 81.5055275CurrentTrain: epoch  5, batch     3 | loss: 63.0855979CurrentTrain: epoch  6, batch     0 | loss: 124.0893646CurrentTrain: epoch  6, batch     1 | loss: 75.5472384CurrentTrain: epoch  6, batch     2 | loss: 80.9773380CurrentTrain: epoch  6, batch     3 | loss: 65.4445993CurrentTrain: epoch  7, batch     0 | loss: 68.0342521CurrentTrain: epoch  7, batch     1 | loss: 80.5525677CurrentTrain: epoch  7, batch     2 | loss: 80.0034308CurrentTrain: epoch  7, batch     3 | loss: 63.3931973CurrentTrain: epoch  8, batch     0 | loss: 66.4414874CurrentTrain: epoch  8, batch     1 | loss: 65.1378970CurrentTrain: epoch  8, batch     2 | loss: 77.0413924CurrentTrain: epoch  8, batch     3 | loss: 137.0763464CurrentTrain: epoch  9, batch     0 | loss: 64.2686723CurrentTrain: epoch  9, batch     1 | loss: 65.0331181CurrentTrain: epoch  9, batch     2 | loss: 79.6405042CurrentTrain: epoch  9, batch     3 | loss: 65.0188808
MemoryTrain:  epoch  0, batch     0 | loss: 1.1059404MemoryTrain:  epoch  1, batch     0 | loss: 0.9470033MemoryTrain:  epoch  2, batch     0 | loss: 0.8035052MemoryTrain:  epoch  3, batch     0 | loss: 0.6365174MemoryTrain:  epoch  4, batch     0 | loss: 0.6367360MemoryTrain:  epoch  5, batch     0 | loss: 0.4429821MemoryTrain:  epoch  6, batch     0 | loss: 0.4012370MemoryTrain:  epoch  7, batch     0 | loss: 0.3745592MemoryTrain:  epoch  8, batch     0 | loss: 0.3167315MemoryTrain:  epoch  9, batch     0 | loss: 0.3150046

F1 score per class: {0: np.float64(0.8780487804878049), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.6013986013986014), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.4), 14: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.08695652173913043), 22: np.float64(0.0), 23: np.float64(0.8089887640449438), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.45607476635514016
Weighted-average F1 score: 0.3449340028510022
F1 score per class: {0: np.float64(0.7272727272727273), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7411764705882353), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.4), 14: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.4722222222222222), 22: np.float64(0.0), 23: np.float64(0.7640449438202247), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.46504559270516715
Weighted-average F1 score: 0.3480005953964523
F1 score per class: {0: np.float64(0.7422680412371134), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7169811320754716), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.35294117647058826), 14: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.40625), 22: np.float64(0.0), 23: np.float64(0.7727272727272727), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.45396825396825397
Weighted-average F1 score: 0.3321008086979143

F1 score per class: {0: np.float64(0.43636363636363634), 1: np.float64(0.18326693227091634), 2: np.float64(0.46153846153846156), 3: np.float64(0.5069124423963134), 4: np.float64(0.6013986013986014), 6: np.float64(0.2733812949640288), 7: np.float64(0.05309734513274336), 9: np.float64(0.78125), 11: np.float64(0.16981132075471697), 12: np.float64(0.0), 13: np.float64(0.08), 14: np.float64(0.024691358024691357), 15: np.float64(0.6666666666666666), 19: np.float64(0.5357142857142857), 21: np.float64(0.05128205128205128), 22: np.float64(0.4697508896797153), 23: np.float64(0.7346938775510204), 24: np.float64(0.0), 25: np.float64(0.4411764705882353), 26: np.float64(0.7023809523809523), 27: np.float64(0.0), 28: np.float64(0.2222222222222222), 29: np.float64(0.8205128205128205), 31: np.float64(0.125), 32: np.float64(0.6416666666666667), 34: np.float64(0.24210526315789474), 35: np.float64(0.17647058823529413), 37: np.float64(0.27906976744186046), 38: np.float64(0.3673469387755102), 39: np.float64(0.125), 40: np.float64(0.23170731707317074)}
Micro-average F1 score: 0.38461538461538464
Weighted-average F1 score: 0.37327790936247407
F1 score per class: {0: np.float64(0.2823529411764706), 1: np.float64(0.18181818181818182), 2: np.float64(0.2153846153846154), 3: np.float64(0.35344827586206895), 4: np.float64(0.7283236994219653), 6: np.float64(0.3894736842105263), 7: np.float64(0.04040404040404041), 9: np.float64(0.4672897196261682), 11: np.float64(0.17699115044247787), 12: np.float64(0.21649484536082475), 13: np.float64(0.0821917808219178), 14: np.float64(0.0392156862745098), 15: np.float64(0.631578947368421), 19: np.float64(0.5107692307692308), 21: np.float64(0.19767441860465115), 22: np.float64(0.4128113879003559), 23: np.float64(0.6868686868686869), 24: np.float64(0.0), 25: np.float64(0.65), 26: np.float64(0.6951871657754011), 27: np.float64(0.0), 28: np.float64(0.10619469026548672), 29: np.float64(0.8282828282828283), 31: np.float64(0.07407407407407407), 32: np.float64(0.5551839464882943), 34: np.float64(0.31125827814569534), 35: np.float64(0.25663716814159293), 37: np.float64(0.25), 38: np.float64(0.45977011494252873), 39: np.float64(0.13333333333333333), 40: np.float64(0.2598870056497175)}
Micro-average F1 score: 0.37124463519313305
Weighted-average F1 score: 0.3478047484551749
F1 score per class: {0: np.float64(0.2987551867219917), 1: np.float64(0.17692307692307693), 2: np.float64(0.2857142857142857), 3: np.float64(0.3271375464684015), 4: np.float64(0.7169811320754716), 6: np.float64(0.3954802259887006), 7: np.float64(0.0392156862745098), 9: np.float64(0.6944444444444444), 11: np.float64(0.1834862385321101), 12: np.float64(0.1643835616438356), 13: np.float64(0.06315789473684211), 14: np.float64(0.047619047619047616), 15: np.float64(0.631578947368421), 19: np.float64(0.5236593059936908), 21: np.float64(0.15028901734104047), 22: np.float64(0.4217687074829932), 23: np.float64(0.6938775510204082), 24: np.float64(0.0), 25: np.float64(0.5405405405405406), 26: np.float64(0.6994535519125683), 27: np.float64(0.0), 28: np.float64(0.1111111111111111), 29: np.float64(0.8383838383838383), 31: np.float64(0.09523809523809523), 32: np.float64(0.5616438356164384), 34: np.float64(0.2883435582822086), 35: np.float64(0.2155688622754491), 37: np.float64(0.26804123711340205), 38: np.float64(0.4375), 39: np.float64(0.13333333333333333), 40: np.float64(0.25136612021857924)}
Micro-average F1 score: 0.3704866562009419
Weighted-average F1 score: 0.34704757882020687

F1 score per class: {0: np.float64(0.8275862068965517), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.581081081081081), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.23809523809523808), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.07692307692307693), 22: np.float64(0.0), 23: np.float64(0.7422680412371134), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.34560906515580736
Weighted-average F1 score: 0.24034879161210612
F1 score per class: {0: np.float64(0.631578947368421), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7078651685393258), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.20689655172413793), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3469387755102041), 22: np.float64(0.0), 23: np.float64(0.6476190476190476), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.345372460496614
Weighted-average F1 score: 0.25468075383769306
F1 score per class: {0: np.float64(0.6792452830188679), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.6909090909090909), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.18181818181818182), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3170731707317073), 22: np.float64(0.0), 23: np.float64(0.6601941747572816), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3404761904761905
Weighted-average F1 score: 0.2419508548742367

F1 score per class: {0: np.float64(0.3025210084033613), 1: np.float64(0.09935205183585313), 2: np.float64(0.27906976744186046), 3: np.float64(0.36789297658862874), 4: np.float64(0.5733333333333334), 6: np.float64(0.2), 7: np.float64(0.028037383177570093), 9: np.float64(0.6944444444444444), 11: np.float64(0.16071428571428573), 12: np.float64(0.0), 13: np.float64(0.0390625), 14: np.float64(0.021739130434782608), 15: np.float64(0.5217391304347826), 19: np.float64(0.48859934853420195), 21: np.float64(0.03773584905660377), 22: np.float64(0.33), 23: np.float64(0.6486486486486487), 24: np.float64(0.0), 25: np.float64(0.40540540540540543), 26: np.float64(0.6344086021505376), 27: np.float64(0.0), 28: np.float64(0.21052631578947367), 29: np.float64(0.6866952789699571), 31: np.float64(0.058823529411764705), 32: np.float64(0.45427728613569324), 34: np.float64(0.155668358714044), 35: np.float64(0.11764705882352941), 37: np.float64(0.21428571428571427), 38: np.float64(0.28125), 39: np.float64(0.125), 40: np.float64(0.20765027322404372)}
Micro-average F1 score: 0.2819047619047619
Weighted-average F1 score: 0.26140921825693664
F1 score per class: {0: np.float64(0.19148936170212766), 1: np.float64(0.0989247311827957), 2: np.float64(0.15053763440860216), 3: np.float64(0.22527472527472528), 4: np.float64(0.6666666666666666), 6: np.float64(0.24262295081967214), 7: np.float64(0.0223463687150838), 9: np.float64(0.37037037037037035), 11: np.float64(0.16129032258064516), 12: np.float64(0.15498154981549817), 13: np.float64(0.03821656050955414), 14: np.float64(0.029556650246305417), 15: np.float64(0.5), 19: np.float64(0.45108695652173914), 21: np.float64(0.13991769547325103), 22: np.float64(0.2966751918158568), 23: np.float64(0.5714285714285714), 24: np.float64(0.0), 25: np.float64(0.5714285714285714), 26: np.float64(0.6132075471698113), 27: np.float64(0.0), 28: np.float64(0.06382978723404255), 29: np.float64(0.6861924686192469), 31: np.float64(0.03571428571428571), 32: np.float64(0.3905882352941176), 34: np.float64(0.2), 35: np.float64(0.16477272727272727), 37: np.float64(0.19696969696969696), 38: np.float64(0.2777777777777778), 39: np.float64(0.13333333333333333), 40: np.float64(0.22439024390243903)}
Micro-average F1 score: 0.2629578963368293
Weighted-average F1 score: 0.24173220420489339
F1 score per class: {0: np.float64(0.2028169014084507), 1: np.float64(0.09643605870020965), 2: np.float64(0.1917808219178082), 3: np.float64(0.21256038647342995), 4: np.float64(0.6785714285714286), 6: np.float64(0.2491103202846975), 7: np.float64(0.021621621621621623), 9: np.float64(0.6172839506172839), 11: np.float64(0.16666666666666666), 12: np.float64(0.12972972972972974), 13: np.float64(0.0273972602739726), 14: np.float64(0.03592814371257485), 15: np.float64(0.48), 19: np.float64(0.4585635359116022), 21: np.float64(0.11158798283261803), 22: np.float64(0.2980769230769231), 23: np.float64(0.5714285714285714), 24: np.float64(0.0), 25: np.float64(0.47058823529411764), 26: np.float64(0.6274509803921569), 27: np.float64(0.0), 28: np.float64(0.08130081300813008), 29: np.float64(0.6974789915966386), 31: np.float64(0.046511627906976744), 32: np.float64(0.3961352657004831), 34: np.float64(0.18687872763419483), 35: np.float64(0.13584905660377358), 37: np.float64(0.208), 38: np.float64(0.2978723404255319), 39: np.float64(0.13333333333333333), 40: np.float64(0.215962441314554)}
Micro-average F1 score: 0.2644469345285737
Weighted-average F1 score: 0.2416853722611152
cur_acc_wo_na:  ['0.7471', '0.4841', '0.3923', '0.5286', '0.4050', '0.4561']
his_acc_wo_na:  ['0.7471', '0.6538', '0.5129', '0.4737', '0.3830', '0.3846']
cur_acc des_wo_na:  ['0.7457', '0.4460', '0.3929', '0.5050', '0.3297', '0.4650']
his_acc des_wo_na:  ['0.7457', '0.6198', '0.4989', '0.4654', '0.3621', '0.3712']
cur_acc rrf_wo_na:  ['0.7528', '0.4683', '0.4133', '0.5000', '0.3565', '0.4540']
his_acc rrf_wo_na:  ['0.7528', '0.6320', '0.5059', '0.4591', '0.3648', '0.3705']
cur_acc_w_na:  ['0.6229', '0.3455', '0.3579', '0.4014', '0.2796', '0.3456']
his_acc_w_na:  ['0.6229', '0.4961', '0.4158', '0.3538', '0.2784', '0.2819']
cur_acc des_w_na:  ['0.6023', '0.3084', '0.3492', '0.3676', '0.2168', '0.3454']
his_acc des_w_na:  ['0.6023', '0.4500', '0.3911', '0.3292', '0.2517', '0.2630']
cur_acc rrf_w_na:  ['0.6163', '0.3288', '0.3721', '0.3775', '0.2366', '0.3405']
his_acc rrf_w_na:  ['0.6163', '0.4660', '0.4029', '0.3322', '0.2563', '0.2644']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 111.2415213CurrentTrain: epoch  0, batch     1 | loss: 93.6321188CurrentTrain: epoch  0, batch     2 | loss: 91.9700675CurrentTrain: epoch  0, batch     3 | loss: 85.9551245CurrentTrain: epoch  1, batch     0 | loss: 108.6805923CurrentTrain: epoch  1, batch     1 | loss: 89.9080141CurrentTrain: epoch  1, batch     2 | loss: 75.5401401CurrentTrain: epoch  1, batch     3 | loss: 51.6371234CurrentTrain: epoch  2, batch     0 | loss: 73.2803683CurrentTrain: epoch  2, batch     1 | loss: 82.8586743CurrentTrain: epoch  2, batch     2 | loss: 85.3641819CurrentTrain: epoch  2, batch     3 | loss: 59.3747566CurrentTrain: epoch  3, batch     0 | loss: 68.3885396CurrentTrain: epoch  3, batch     1 | loss: 82.9559162CurrentTrain: epoch  3, batch     2 | loss: 68.9201610CurrentTrain: epoch  3, batch     3 | loss: 59.7643192CurrentTrain: epoch  4, batch     0 | loss: 125.0245528CurrentTrain: epoch  4, batch     1 | loss: 81.6400650CurrentTrain: epoch  4, batch     2 | loss: 67.5514147CurrentTrain: epoch  4, batch     3 | loss: 47.2932661CurrentTrain: epoch  5, batch     0 | loss: 98.3742711CurrentTrain: epoch  5, batch     1 | loss: 70.0724801CurrentTrain: epoch  5, batch     2 | loss: 92.8873324CurrentTrain: epoch  5, batch     3 | loss: 45.1866620CurrentTrain: epoch  6, batch     0 | loss: 64.7832639CurrentTrain: epoch  6, batch     1 | loss: 99.9008490CurrentTrain: epoch  6, batch     2 | loss: 92.8714819CurrentTrain: epoch  6, batch     3 | loss: 55.8716401CurrentTrain: epoch  7, batch     0 | loss: 64.2730431CurrentTrain: epoch  7, batch     1 | loss: 75.5330968CurrentTrain: epoch  7, batch     2 | loss: 80.6074331CurrentTrain: epoch  7, batch     3 | loss: 46.7556280CurrentTrain: epoch  8, batch     0 | loss: 77.5097359CurrentTrain: epoch  8, batch     1 | loss: 75.1941875CurrentTrain: epoch  8, batch     2 | loss: 77.5698428CurrentTrain: epoch  8, batch     3 | loss: 56.3632825CurrentTrain: epoch  9, batch     0 | loss: 75.8142177CurrentTrain: epoch  9, batch     1 | loss: 74.0460035CurrentTrain: epoch  9, batch     2 | loss: 63.0528962CurrentTrain: epoch  9, batch     3 | loss: 72.5399770
MemoryTrain:  epoch  0, batch     0 | loss: 0.7130610MemoryTrain:  epoch  1, batch     0 | loss: 0.5884926MemoryTrain:  epoch  2, batch     0 | loss: 0.4772125MemoryTrain:  epoch  3, batch     0 | loss: 0.4175697MemoryTrain:  epoch  4, batch     0 | loss: 0.3449282MemoryTrain:  epoch  5, batch     0 | loss: 0.3216592MemoryTrain:  epoch  6, batch     0 | loss: 0.2854174MemoryTrain:  epoch  7, batch     0 | loss: 0.2216425MemoryTrain:  epoch  8, batch     0 | loss: 0.2054281MemoryTrain:  epoch  9, batch     0 | loss: 0.2169945

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.6347305389221557), 11: np.float64(0.0), 13: np.float64(0.0), 20: np.float64(0.8), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8), 32: np.float64(0.0), 33: np.float64(0.5), 34: np.float64(0.0), 36: np.float64(0.6605504587155964), 37: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5864077669902913
Weighted-average F1 score: 0.5038397749016762
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.7058823529411765), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.7184466019417476), 22: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8571428571428571), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.2857142857142857), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.6929133858267716), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5364238410596026
Weighted-average F1 score: 0.4366395657205683
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.7052023121387283), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.7547169811320755), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.9), 32: np.float64(0.0), 33: np.float64(0.3333333333333333), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.7433628318584071), 37: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5734265734265734
Weighted-average F1 score: 0.47007414125017416

F1 score per class: {0: np.float64(0.44871794871794873), 1: np.float64(0.18972332015810275), 2: np.float64(0.48), 3: np.float64(0.4656084656084656), 4: np.float64(0.717948717948718), 6: np.float64(0.176), 7: np.float64(0.03278688524590164), 8: np.float64(0.2425629290617849), 9: np.float64(0.7575757575757576), 11: np.float64(0.1724137931034483), 12: np.float64(0.018018018018018018), 13: np.float64(0.03076923076923077), 14: np.float64(0.05063291139240506), 15: np.float64(0.6666666666666666), 19: np.float64(0.5165562913907285), 20: np.float64(0.5028571428571429), 21: np.float64(0.07766990291262135), 22: np.float64(0.49808429118773945), 23: np.float64(0.717391304347826), 24: np.float64(0.0), 25: np.float64(0.3225806451612903), 26: np.float64(0.6931818181818182), 27: np.float64(0.0), 28: np.float64(0.3333333333333333), 29: np.float64(0.797979797979798), 30: np.float64(0.8), 31: np.float64(0.10526315789473684), 32: np.float64(0.61003861003861), 33: np.float64(0.12903225806451613), 34: np.float64(0.29310344827586204), 35: np.float64(0.1984732824427481), 36: np.float64(0.48322147651006714), 37: np.float64(0.24691358024691357), 38: np.float64(0.43243243243243246), 39: np.float64(0.0), 40: np.float64(0.21656050955414013)}
Micro-average F1 score: 0.3887020847343645
Weighted-average F1 score: 0.3823302582020627
F1 score per class: {0: np.float64(0.225), 1: np.float64(0.19491525423728814), 2: np.float64(0.1728395061728395), 3: np.float64(0.37545126353790614), 4: np.float64(0.7771428571428571), 6: np.float64(0.3978494623655914), 7: np.float64(0.028985507246376812), 8: np.float64(0.2823529411764706), 9: np.float64(0.44642857142857145), 11: np.float64(0.2), 12: np.float64(0.21875), 13: np.float64(0.044444444444444446), 14: np.float64(0.049586776859504134), 15: np.float64(0.631578947368421), 19: np.float64(0.455026455026455), 20: np.float64(0.46540880503144655), 21: np.float64(0.13986013986013987), 22: np.float64(0.4358974358974359), 23: np.float64(0.7128712871287128), 24: np.float64(0.0), 25: np.float64(0.4444444444444444), 26: np.float64(0.6808510638297872), 27: np.float64(0.0), 28: np.float64(0.21052631578947367), 29: np.float64(0.8), 30: np.float64(0.5142857142857142), 31: np.float64(0.0625), 32: np.float64(0.5103857566765578), 33: np.float64(0.07228915662650602), 34: np.float64(0.3524229074889868), 35: np.float64(0.2755102040816326), 36: np.float64(0.4656084656084656), 37: np.float64(0.17647058823529413), 38: np.float64(0.5357142857142857), 39: np.float64(0.11764705882352941), 40: np.float64(0.18181818181818182)}
Micro-average F1 score: 0.36985802693847836
Weighted-average F1 score: 0.35392210123314255
F1 score per class: {0: np.float64(0.3090128755364807), 1: np.float64(0.19834710743801653), 2: np.float64(0.30434782608695654), 3: np.float64(0.3968253968253968), 4: np.float64(0.8390804597701149), 6: np.float64(0.3742690058479532), 7: np.float64(0.028985507246376812), 8: np.float64(0.2824074074074074), 9: np.float64(0.684931506849315), 11: np.float64(0.1896551724137931), 12: np.float64(0.2054794520547945), 13: np.float64(0.03389830508474576), 14: np.float64(0.05263157894736842), 15: np.float64(0.631578947368421), 19: np.float64(0.47191011235955055), 20: np.float64(0.45714285714285713), 21: np.float64(0.12422360248447205), 22: np.float64(0.4610169491525424), 23: np.float64(0.72), 24: np.float64(0.0), 25: np.float64(0.36923076923076925), 26: np.float64(0.6951871657754011), 27: np.float64(0.0), 28: np.float64(0.3), 29: np.float64(0.8058252427184466), 30: np.float64(0.6), 31: np.float64(0.08333333333333333), 32: np.float64(0.5171339563862928), 33: np.float64(0.07792207792207792), 34: np.float64(0.321285140562249), 35: np.float64(0.21052631578947367), 36: np.float64(0.5153374233128835), 37: np.float64(0.23404255319148937), 38: np.float64(0.5581395348837209), 39: np.float64(0.0), 40: np.float64(0.16666666666666666)}
Micro-average F1 score: 0.3840341019182329
Weighted-average F1 score: 0.3687722229120312

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.45689655172413796), 11: np.float64(0.0), 13: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5945945945945946), 21: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7567567567567568), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.4), 34: np.float64(0.0), 36: np.float64(0.5106382978723404), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3994708994708995
Weighted-average F1 score: 0.34362431459863596
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.4979253112033195), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5401459854014599), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.20689655172413793), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.5789473684210527), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3564356435643564
Weighted-average F1 score: 0.2932356610561907
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.49795918367346936), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5594405594405595), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8571428571428571), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.24), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.6268656716417911), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.38588235294117645
Weighted-average F1 score: 0.3185083478167791

F1 score per class: {0: np.float64(0.3111111111111111), 1: np.float64(0.1038961038961039), 2: np.float64(0.2727272727272727), 3: np.float64(0.32116788321167883), 4: np.float64(0.691358024691358), 6: np.float64(0.125), 7: np.float64(0.019801980198019802), 8: np.float64(0.12771084337349398), 9: np.float64(0.6756756756756757), 11: np.float64(0.17094017094017094), 12: np.float64(0.017543859649122806), 13: np.float64(0.014814814814814815), 14: np.float64(0.044444444444444446), 15: np.float64(0.5454545454545454), 19: np.float64(0.45481049562682213), 20: np.float64(0.27936507936507937), 21: np.float64(0.057971014492753624), 22: np.float64(0.3551912568306011), 23: np.float64(0.6470588235294118), 24: np.float64(0.0), 25: np.float64(0.3076923076923077), 26: np.float64(0.6256410256410256), 27: np.float64(0.0), 28: np.float64(0.2857142857142857), 29: np.float64(0.6502057613168725), 30: np.float64(0.7), 31: np.float64(0.05), 32: np.float64(0.42133333333333334), 33: np.float64(0.08695652173913043), 34: np.float64(0.20606060606060606), 35: np.float64(0.13612565445026178), 36: np.float64(0.33962264150943394), 37: np.float64(0.21052631578947367), 38: np.float64(0.3018867924528302), 39: np.float64(0.0), 40: np.float64(0.17894736842105263)}
Micro-average F1 score: 0.27576335877862596
Weighted-average F1 score: 0.2588474165055398
F1 score per class: {0: np.float64(0.14663951120162932), 1: np.float64(0.10430839002267574), 2: np.float64(0.12173913043478261), 3: np.float64(0.23476297968397292), 4: np.float64(0.7272727272727273), 6: np.float64(0.24749163879598662), 7: np.float64(0.01680672268907563), 8: np.float64(0.15444015444015444), 9: np.float64(0.3597122302158273), 11: np.float64(0.19298245614035087), 12: np.float64(0.14840989399293286), 13: np.float64(0.02197802197802198), 14: np.float64(0.04054054054054054), 15: np.float64(0.5), 19: np.float64(0.3954022988505747), 20: np.float64(0.2642857142857143), 21: np.float64(0.10309278350515463), 22: np.float64(0.3090909090909091), 23: np.float64(0.5538461538461539), 24: np.float64(0.0), 25: np.float64(0.4155844155844156), 26: np.float64(0.5981308411214953), 27: np.float64(0.0), 28: np.float64(0.1276595744680851), 29: np.float64(0.6339622641509434), 30: np.float64(0.35294117647058826), 31: np.float64(0.02702702702702703), 32: np.float64(0.35833333333333334), 33: np.float64(0.046511627906976744), 34: np.float64(0.22408963585434175), 35: np.float64(0.16875), 36: np.float64(0.3384615384615385), 37: np.float64(0.13740458015267176), 38: np.float64(0.3409090909090909), 39: np.float64(0.09090909090909091), 40: np.float64(0.14893617021276595)}
Micro-average F1 score: 0.25409528573214957
Weighted-average F1 score: 0.23856544229555599
F1 score per class: {0: np.float64(0.1956521739130435), 1: np.float64(0.1050328227571116), 2: np.float64(0.19444444444444445), 3: np.float64(0.25510204081632654), 4: np.float64(0.8021978021978022), 6: np.float64(0.24060150375939848), 7: np.float64(0.017391304347826087), 8: np.float64(0.15269086357947434), 9: np.float64(0.5952380952380952), 11: np.float64(0.1864406779661017), 12: np.float64(0.15306122448979592), 13: np.float64(0.017241379310344827), 14: np.float64(0.04411764705882353), 15: np.float64(0.5), 19: np.float64(0.4097560975609756), 20: np.float64(0.264026402640264), 21: np.float64(0.09216589861751152), 22: np.float64(0.3300970873786408), 23: np.float64(0.6206896551724138), 24: np.float64(0.0), 25: np.float64(0.35294117647058826), 26: np.float64(0.6161137440758294), 27: np.float64(0.0), 28: np.float64(0.19047619047619047), 29: np.float64(0.6434108527131783), 30: np.float64(0.41379310344827586), 31: np.float64(0.037037037037037035), 32: np.float64(0.3616557734204793), 33: np.float64(0.04838709677419355), 34: np.float64(0.20725388601036268), 35: np.float64(0.13043478260869565), 36: np.float64(0.38181818181818183), 37: np.float64(0.18803418803418803), 38: np.float64(0.36923076923076925), 39: np.float64(0.0), 40: np.float64(0.1339712918660287)}
Micro-average F1 score: 0.26629047427112723
Weighted-average F1 score: 0.24852750211292632
cur_acc_wo_na:  ['0.7471', '0.4841', '0.3923', '0.5286', '0.4050', '0.4561', '0.5864']
his_acc_wo_na:  ['0.7471', '0.6538', '0.5129', '0.4737', '0.3830', '0.3846', '0.3887']
cur_acc des_wo_na:  ['0.7457', '0.4460', '0.3929', '0.5050', '0.3297', '0.4650', '0.5364']
his_acc des_wo_na:  ['0.7457', '0.6198', '0.4989', '0.4654', '0.3621', '0.3712', '0.3699']
cur_acc rrf_wo_na:  ['0.7528', '0.4683', '0.4133', '0.5000', '0.3565', '0.4540', '0.5734']
his_acc rrf_wo_na:  ['0.7528', '0.6320', '0.5059', '0.4591', '0.3648', '0.3705', '0.3840']
cur_acc_w_na:  ['0.6229', '0.3455', '0.3579', '0.4014', '0.2796', '0.3456', '0.3995']
his_acc_w_na:  ['0.6229', '0.4961', '0.4158', '0.3538', '0.2784', '0.2819', '0.2758']
cur_acc des_w_na:  ['0.6023', '0.3084', '0.3492', '0.3676', '0.2168', '0.3454', '0.3564']
his_acc des_w_na:  ['0.6023', '0.4500', '0.3911', '0.3292', '0.2517', '0.2630', '0.2541']
cur_acc rrf_w_na:  ['0.6163', '0.3288', '0.3721', '0.3775', '0.2366', '0.3405', '0.3859']
his_acc rrf_w_na:  ['0.6163', '0.4660', '0.4029', '0.3322', '0.2563', '0.2644', '0.2663']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 124.2748288CurrentTrain: epoch  0, batch     1 | loss: 145.3983507CurrentTrain: epoch  0, batch     2 | loss: 109.6996004CurrentTrain: epoch  0, batch     3 | loss: 84.1010802CurrentTrain: epoch  0, batch     4 | loss: 64.3297514CurrentTrain: epoch  1, batch     0 | loss: 88.9401983CurrentTrain: epoch  1, batch     1 | loss: 91.3006275CurrentTrain: epoch  1, batch     2 | loss: 107.6928456CurrentTrain: epoch  1, batch     3 | loss: 131.6323156CurrentTrain: epoch  1, batch     4 | loss: 112.5359007CurrentTrain: epoch  2, batch     0 | loss: 110.9955565CurrentTrain: epoch  2, batch     1 | loss: 127.4513730CurrentTrain: epoch  2, batch     2 | loss: 101.7405947CurrentTrain: epoch  2, batch     3 | loss: 104.5521508CurrentTrain: epoch  2, batch     4 | loss: 52.7014410CurrentTrain: epoch  3, batch     0 | loss: 80.6619320CurrentTrain: epoch  3, batch     1 | loss: 103.6107089CurrentTrain: epoch  3, batch     2 | loss: 82.3772890CurrentTrain: epoch  3, batch     3 | loss: 102.0321565CurrentTrain: epoch  3, batch     4 | loss: 87.1803552CurrentTrain: epoch  4, batch     0 | loss: 83.0244143CurrentTrain: epoch  4, batch     1 | loss: 69.5289644CurrentTrain: epoch  4, batch     2 | loss: 103.6259813CurrentTrain: epoch  4, batch     3 | loss: 81.0511073CurrentTrain: epoch  4, batch     4 | loss: 170.1121901CurrentTrain: epoch  5, batch     0 | loss: 81.1314300CurrentTrain: epoch  5, batch     1 | loss: 82.2406316CurrentTrain: epoch  5, batch     2 | loss: 82.6484163CurrentTrain: epoch  5, batch     3 | loss: 101.1751227CurrentTrain: epoch  5, batch     4 | loss: 51.7073866CurrentTrain: epoch  6, batch     0 | loss: 79.7658702CurrentTrain: epoch  6, batch     1 | loss: 83.0846245CurrentTrain: epoch  6, batch     2 | loss: 67.5111411CurrentTrain: epoch  6, batch     3 | loss: 95.8938539CurrentTrain: epoch  6, batch     4 | loss: 79.9050182CurrentTrain: epoch  7, batch     0 | loss: 95.7769401CurrentTrain: epoch  7, batch     1 | loss: 77.8319989CurrentTrain: epoch  7, batch     2 | loss: 126.4894051CurrentTrain: epoch  7, batch     3 | loss: 65.8364804CurrentTrain: epoch  7, batch     4 | loss: 60.7995348CurrentTrain: epoch  8, batch     0 | loss: 95.7700420CurrentTrain: epoch  8, batch     1 | loss: 77.8345038CurrentTrain: epoch  8, batch     2 | loss: 95.7811601CurrentTrain: epoch  8, batch     3 | loss: 77.4541558CurrentTrain: epoch  8, batch     4 | loss: 50.0590033CurrentTrain: epoch  9, batch     0 | loss: 97.1220557CurrentTrain: epoch  9, batch     1 | loss: 91.9956142CurrentTrain: epoch  9, batch     2 | loss: 74.0746522CurrentTrain: epoch  9, batch     3 | loss: 97.2809709CurrentTrain: epoch  9, batch     4 | loss: 58.7582250
MemoryTrain:  epoch  0, batch     0 | loss: 0.9263260MemoryTrain:  epoch  1, batch     0 | loss: 0.7208465MemoryTrain:  epoch  2, batch     0 | loss: 0.5700175MemoryTrain:  epoch  3, batch     0 | loss: 0.4546003MemoryTrain:  epoch  4, batch     0 | loss: 0.3870636MemoryTrain:  epoch  5, batch     0 | loss: 0.3117902MemoryTrain:  epoch  6, batch     0 | loss: 0.2858968MemoryTrain:  epoch  7, batch     0 | loss: 0.2350542MemoryTrain:  epoch  8, batch     0 | loss: 0.2303028MemoryTrain:  epoch  9, batch     0 | loss: 0.1982746

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.8761904761904762), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.5875), 11: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.7666666666666667), 17: np.float64(0.0), 18: np.float64(0.24242424242424243), 20: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5446009389671361
Weighted-average F1 score: 0.4673863785434033
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.6576271186440678), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.6272189349112426), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.7272727272727273), 17: np.float64(0.5), 18: np.float64(0.2987012987012987), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4624277456647399
Weighted-average F1 score: 0.3975301609071971
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.6906474820143885), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.6436781609195402), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.696969696969697), 17: np.float64(0.0), 18: np.float64(0.2978723404255319), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.48877805486284287
Weighted-average F1 score: 0.4308689509539383

F1 score per class: {0: np.float64(0.4782608695652174), 1: np.float64(0.18548387096774194), 2: np.float64(0.3448275862068966), 3: np.float64(0.47904191616766467), 4: np.float64(0.6666666666666666), 5: np.float64(0.7510204081632653), 6: np.float64(0.1016949152542373), 7: np.float64(0.023809523809523808), 8: np.float64(0.28846153846153844), 9: np.float64(0.7142857142857143), 10: np.float64(0.3122923588039867), 11: np.float64(0.18867924528301888), 12: np.float64(0.018518518518518517), 13: np.float64(0.046511627906976744), 14: np.float64(0.02631578947368421), 15: np.float64(0.6666666666666666), 16: np.float64(0.5609756097560976), 17: np.float64(0.0), 18: np.float64(0.12371134020618557), 19: np.float64(0.5266666666666666), 20: np.float64(0.45685279187817257), 21: np.float64(0.18421052631578946), 22: np.float64(0.4794007490636704), 23: np.float64(0.6966292134831461), 24: np.float64(0.0), 25: np.float64(0.3225806451612903), 26: np.float64(0.6815642458100558), 27: np.float64(0.0), 28: np.float64(0.2), 29: np.float64(0.8040201005025126), 30: np.float64(0.7777777777777778), 31: np.float64(0.15384615384615385), 32: np.float64(0.5954198473282443), 33: np.float64(0.16666666666666666), 34: np.float64(0.21875), 35: np.float64(0.21666666666666667), 36: np.float64(0.2564102564102564), 37: np.float64(0.18181818181818182), 38: np.float64(0.13333333333333333), 39: np.float64(0.21052631578947367), 40: np.float64(0.24203821656050956)}
Micro-average F1 score: 0.39113640983939824
Weighted-average F1 score: 0.3936241805536959
F1 score per class: {0: np.float64(0.2508710801393728), 1: np.float64(0.16535433070866143), 2: np.float64(0.19444444444444445), 3: np.float64(0.32075471698113206), 4: np.float64(0.7802197802197802), 5: np.float64(0.4813895781637717), 6: np.float64(0.32298136645962733), 7: np.float64(0.02702702702702703), 8: np.float64(0.25), 9: np.float64(0.352112676056338), 10: np.float64(0.3569023569023569), 11: np.float64(0.14414414414414414), 12: np.float64(0.2880658436213992), 13: np.float64(0.1111111111111111), 14: np.float64(0.05172413793103448), 15: np.float64(0.5714285714285714), 16: np.float64(0.5333333333333333), 17: np.float64(0.3333333333333333), 18: np.float64(0.16911764705882354), 19: np.float64(0.42), 20: np.float64(0.41836734693877553), 21: np.float64(0.1694915254237288), 22: np.float64(0.4035608308605341), 23: np.float64(0.6), 24: np.float64(0.0), 25: np.float64(0.410958904109589), 26: np.float64(0.6701570680628273), 27: np.float64(0.0), 28: np.float64(0.25925925925925924), 29: np.float64(0.7671232876712328), 30: np.float64(0.4186046511627907), 31: np.float64(0.06666666666666667), 32: np.float64(0.5014749262536873), 33: np.float64(0.0975609756097561), 34: np.float64(0.32786885245901637), 35: np.float64(0.27586206896551724), 36: np.float64(0.5481481481481482), 37: np.float64(0.1834862385321101), 38: np.float64(0.45614035087719296), 39: np.float64(0.14285714285714285), 40: np.float64(0.15300546448087432)}
Micro-average F1 score: 0.3570457634798369
Weighted-average F1 score: 0.34454966420548405
F1 score per class: {0: np.float64(0.3349282296650718), 1: np.float64(0.17829457364341086), 2: np.float64(0.30434782608695654), 3: np.float64(0.32075471698113206), 4: np.float64(0.7577639751552795), 5: np.float64(0.5378151260504201), 6: np.float64(0.2602739726027397), 7: np.float64(0.025), 8: np.float64(0.26112759643916916), 9: np.float64(0.6329113924050633), 10: np.float64(0.3510971786833856), 11: np.float64(0.14545454545454545), 12: np.float64(0.18181818181818182), 13: np.float64(0.04878048780487805), 14: np.float64(0.056074766355140186), 15: np.float64(0.6), 16: np.float64(0.4842105263157895), 17: np.float64(0.0), 18: np.float64(0.15671641791044777), 19: np.float64(0.4528301886792453), 20: np.float64(0.38181818181818183), 21: np.float64(0.16541353383458646), 22: np.float64(0.43125), 23: np.float64(0.6407766990291263), 24: np.float64(0.0), 25: np.float64(0.35294117647058826), 26: np.float64(0.6808510638297872), 27: np.float64(0.0), 28: np.float64(0.36363636363636365), 29: np.float64(0.7980769230769231), 30: np.float64(0.45454545454545453), 31: np.float64(0.08695652173913043), 32: np.float64(0.5125), 33: np.float64(0.11594202898550725), 34: np.float64(0.28699551569506726), 35: np.float64(0.22727272727272727), 36: np.float64(0.4329896907216495), 37: np.float64(0.1956521739130435), 38: np.float64(0.3783783783783784), 39: np.float64(0.18181818181818182), 40: np.float64(0.1306532663316583)}
Micro-average F1 score: 0.36118508655126497
Weighted-average F1 score: 0.3517215291541752

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.7076923076923077), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.5), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.4742268041237113), 17: np.float64(0.0), 18: np.float64(0.1889763779527559), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3651626442812172
Weighted-average F1 score: 0.30430109176189946
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.49363867684478374), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.5145631067961165), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.42857142857142855), 17: np.float64(0.3333333333333333), 18: np.float64(0.215962441314554), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2971768202080238
Weighted-average F1 score: 0.25731969014030714
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.5303867403314917), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.5209302325581395), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.4107142857142857), 17: np.float64(0.0), 18: np.float64(0.2153846153846154), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.31947840260798693
Weighted-average F1 score: 0.28031297935896693

F1 score per class: {0: np.float64(0.3350253807106599), 1: np.float64(0.10087719298245613), 2: np.float64(0.20408163265306123), 3: np.float64(0.3292181069958848), 4: np.float64(0.6329113924050633), 5: np.float64(0.5125348189415042), 6: np.float64(0.07792207792207792), 7: np.float64(0.012578616352201259), 8: np.float64(0.18126888217522658), 9: np.float64(0.625), 10: np.float64(0.20659340659340658), 11: np.float64(0.18867924528301888), 12: np.float64(0.01652892561983471), 13: np.float64(0.02631578947368421), 14: np.float64(0.023529411764705882), 15: np.float64(0.5714285714285714), 16: np.float64(0.31724137931034485), 17: np.float64(0.0), 18: np.float64(0.08664259927797834), 19: np.float64(0.45664739884393063), 20: np.float64(0.23376623376623376), 21: np.float64(0.1320754716981132), 22: np.float64(0.34972677595628415), 23: np.float64(0.62), 24: np.float64(0.0), 25: np.float64(0.3076923076923077), 26: np.float64(0.6039603960396039), 27: np.float64(0.0), 28: np.float64(0.15384615384615385), 29: np.float64(0.64), 30: np.float64(0.6829268292682927), 31: np.float64(0.06666666666666667), 32: np.float64(0.42857142857142855), 33: np.float64(0.10810810810810811), 34: np.float64(0.1339712918660287), 35: np.float64(0.15028901734104047), 36: np.float64(0.1941747572815534), 37: np.float64(0.13861386138613863), 38: np.float64(0.12121212121212122), 39: np.float64(0.16666666666666666), 40: np.float64(0.20652173913043478)}
Micro-average F1 score: 0.2783162158252568
Weighted-average F1 score: 0.2681784879262737
F1 score per class: {0: np.float64(0.16666666666666666), 1: np.float64(0.09032258064516129), 2: np.float64(0.1308411214953271), 3: np.float64(0.2), 4: np.float64(0.7171717171717171), 5: np.float64(0.2865583456425406), 6: np.float64(0.20717131474103587), 7: np.float64(0.015151515151515152), 8: np.float64(0.1375921375921376), 9: np.float64(0.2702702702702703), 10: np.float64(0.22698072805139186), 11: np.float64(0.14035087719298245), 12: np.float64(0.1583710407239819), 13: np.float64(0.06451612903225806), 14: np.float64(0.039735099337748346), 15: np.float64(0.4444444444444444), 16: np.float64(0.3018867924528302), 17: np.float64(0.16666666666666666), 18: np.float64(0.1111111111111111), 19: np.float64(0.3463917525773196), 20: np.float64(0.22343324250681199), 21: np.float64(0.11976047904191617), 22: np.float64(0.2905982905982906), 23: np.float64(0.4520547945205479), 24: np.float64(0.0), 25: np.float64(0.38961038961038963), 26: np.float64(0.5818181818181818), 27: np.float64(0.0), 28: np.float64(0.14285714285714285), 29: np.float64(0.5753424657534246), 30: np.float64(0.26865671641791045), 31: np.float64(0.029411764705882353), 32: np.float64(0.3512396694214876), 33: np.float64(0.05925925925925926), 34: np.float64(0.20202020202020202), 35: np.float64(0.1693121693121693), 36: np.float64(0.40437158469945356), 37: np.float64(0.136986301369863), 38: np.float64(0.2653061224489796), 39: np.float64(0.10810810810810811), 40: np.float64(0.11428571428571428)}
Micro-average F1 score: 0.23621103117505995
Weighted-average F1 score: 0.2249569787410276
F1 score per class: {0: np.float64(0.21671826625386997), 1: np.float64(0.09663865546218488), 2: np.float64(0.2), 3: np.float64(0.21052631578947367), 4: np.float64(0.7218934911242604), 5: np.float64(0.3368421052631579), 6: np.float64(0.17117117117117117), 7: np.float64(0.014285714285714285), 8: np.float64(0.14426229508196722), 9: np.float64(0.5319148936170213), 10: np.float64(0.21875), 11: np.float64(0.14285714285714285), 12: np.float64(0.12334801762114538), 13: np.float64(0.0273972602739726), 14: np.float64(0.04580152671755725), 15: np.float64(0.4444444444444444), 16: np.float64(0.27380952380952384), 17: np.float64(0.0), 18: np.float64(0.1076923076923077), 19: np.float64(0.3684210526315789), 20: np.float64(0.2), 21: np.float64(0.11578947368421053), 22: np.float64(0.31363636363636366), 23: np.float64(0.528), 24: np.float64(0.0), 25: np.float64(0.3380281690140845), 26: np.float64(0.5953488372093023), 27: np.float64(0.0), 28: np.float64(0.21621621621621623), 29: np.float64(0.6217228464419475), 30: np.float64(0.2857142857142857), 31: np.float64(0.04081632653061224), 32: np.float64(0.3588621444201313), 33: np.float64(0.07142857142857142), 34: np.float64(0.1792717086834734), 35: np.float64(0.14388489208633093), 36: np.float64(0.2978723404255319), 37: np.float64(0.14285714285714285), 38: np.float64(0.2641509433962264), 39: np.float64(0.14814814814814814), 40: np.float64(0.09811320754716982)}
Micro-average F1 score: 0.24414941494149414
Weighted-average F1 score: 0.23226559030386962
cur_acc_wo_na:  ['0.7471', '0.4841', '0.3923', '0.5286', '0.4050', '0.4561', '0.5864', '0.5446']
his_acc_wo_na:  ['0.7471', '0.6538', '0.5129', '0.4737', '0.3830', '0.3846', '0.3887', '0.3911']
cur_acc des_wo_na:  ['0.7457', '0.4460', '0.3929', '0.5050', '0.3297', '0.4650', '0.5364', '0.4624']
his_acc des_wo_na:  ['0.7457', '0.6198', '0.4989', '0.4654', '0.3621', '0.3712', '0.3699', '0.3570']
cur_acc rrf_wo_na:  ['0.7528', '0.4683', '0.4133', '0.5000', '0.3565', '0.4540', '0.5734', '0.4888']
his_acc rrf_wo_na:  ['0.7528', '0.6320', '0.5059', '0.4591', '0.3648', '0.3705', '0.3840', '0.3612']
cur_acc_w_na:  ['0.6229', '0.3455', '0.3579', '0.4014', '0.2796', '0.3456', '0.3995', '0.3652']
his_acc_w_na:  ['0.6229', '0.4961', '0.4158', '0.3538', '0.2784', '0.2819', '0.2758', '0.2783']
cur_acc des_w_na:  ['0.6023', '0.3084', '0.3492', '0.3676', '0.2168', '0.3454', '0.3564', '0.2972']
his_acc des_w_na:  ['0.6023', '0.4500', '0.3911', '0.3292', '0.2517', '0.2630', '0.2541', '0.2362']
cur_acc rrf_w_na:  ['0.6163', '0.3288', '0.3721', '0.3775', '0.2366', '0.3405', '0.3859', '0.3195']
his_acc rrf_w_na:  ['0.6163', '0.4660', '0.4029', '0.3322', '0.2563', '0.2644', '0.2663', '0.2441']
--------Round  1
seed:  200
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 6 3 2 4 0 5 1]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 129.3004379CurrentTrain: epoch  0, batch     1 | loss: 89.8706462CurrentTrain: epoch  0, batch     2 | loss: 78.5453616CurrentTrain: epoch  0, batch     3 | loss: 120.6638838CurrentTrain: epoch  0, batch     4 | loss: 77.4670345CurrentTrain: epoch  0, batch     5 | loss: 148.6213970CurrentTrain: epoch  0, batch     6 | loss: 87.9486794CurrentTrain: epoch  0, batch     7 | loss: 100.2376841CurrentTrain: epoch  0, batch     8 | loss: 86.4261345CurrentTrain: epoch  0, batch     9 | loss: 119.0365575CurrentTrain: epoch  0, batch    10 | loss: 90.3385735CurrentTrain: epoch  0, batch    11 | loss: 100.4251385CurrentTrain: epoch  0, batch    12 | loss: 86.2470075CurrentTrain: epoch  0, batch    13 | loss: 146.7566809CurrentTrain: epoch  0, batch    14 | loss: 100.2443359CurrentTrain: epoch  0, batch    15 | loss: 100.5337085CurrentTrain: epoch  0, batch    16 | loss: 99.5033363CurrentTrain: epoch  0, batch    17 | loss: 76.0592658CurrentTrain: epoch  0, batch    18 | loss: 86.9618747CurrentTrain: epoch  0, batch    19 | loss: 99.0564395CurrentTrain: epoch  0, batch    20 | loss: 118.7343053CurrentTrain: epoch  0, batch    21 | loss: 119.2424026CurrentTrain: epoch  0, batch    22 | loss: 99.3444931CurrentTrain: epoch  0, batch    23 | loss: 99.0136827CurrentTrain: epoch  0, batch    24 | loss: 86.4898473CurrentTrain: epoch  0, batch    25 | loss: 117.5609955CurrentTrain: epoch  0, batch    26 | loss: 99.2943373CurrentTrain: epoch  0, batch    27 | loss: 98.8033229CurrentTrain: epoch  0, batch    28 | loss: 85.7582527CurrentTrain: epoch  0, batch    29 | loss: 98.4809561CurrentTrain: epoch  0, batch    30 | loss: 98.6522930CurrentTrain: epoch  0, batch    31 | loss: 117.4696908CurrentTrain: epoch  0, batch    32 | loss: 83.6037298CurrentTrain: epoch  0, batch    33 | loss: 98.0159560CurrentTrain: epoch  0, batch    34 | loss: 117.1272727CurrentTrain: epoch  0, batch    35 | loss: 99.1723931CurrentTrain: epoch  0, batch    36 | loss: 98.6011562CurrentTrain: epoch  0, batch    37 | loss: 97.5095871CurrentTrain: epoch  0, batch    38 | loss: 84.6423965CurrentTrain: epoch  0, batch    39 | loss: 97.5944142CurrentTrain: epoch  0, batch    40 | loss: 145.3938363CurrentTrain: epoch  0, batch    41 | loss: 98.8286182CurrentTrain: epoch  0, batch    42 | loss: 96.8195068CurrentTrain: epoch  0, batch    43 | loss: 96.4546012CurrentTrain: epoch  0, batch    44 | loss: 115.1203338CurrentTrain: epoch  0, batch    45 | loss: 115.4269532CurrentTrain: epoch  0, batch    46 | loss: 141.8206245CurrentTrain: epoch  0, batch    47 | loss: 93.1723204CurrentTrain: epoch  0, batch    48 | loss: 84.4601080CurrentTrain: epoch  0, batch    49 | loss: 96.5611830CurrentTrain: epoch  0, batch    50 | loss: 73.0093058CurrentTrain: epoch  0, batch    51 | loss: 115.6106827CurrentTrain: epoch  0, batch    52 | loss: 81.9611099CurrentTrain: epoch  0, batch    53 | loss: 80.8089023CurrentTrain: epoch  0, batch    54 | loss: 72.9600860CurrentTrain: epoch  0, batch    55 | loss: 191.9699392CurrentTrain: epoch  0, batch    56 | loss: 142.8494318CurrentTrain: epoch  0, batch    57 | loss: 191.8699336CurrentTrain: epoch  0, batch    58 | loss: 112.3183862CurrentTrain: epoch  0, batch    59 | loss: 116.4772629CurrentTrain: epoch  0, batch    60 | loss: 138.2212671CurrentTrain: epoch  0, batch    61 | loss: 71.1159820CurrentTrain: epoch  0, batch    62 | loss: 190.7740011CurrentTrain: epoch  0, batch    63 | loss: 113.3313255CurrentTrain: epoch  0, batch    64 | loss: 81.3652624CurrentTrain: epoch  0, batch    65 | loss: 94.7023699CurrentTrain: epoch  0, batch    66 | loss: 136.5005156CurrentTrain: epoch  0, batch    67 | loss: 94.2762559CurrentTrain: epoch  0, batch    68 | loss: 82.0914838CurrentTrain: epoch  0, batch    69 | loss: 142.0641545CurrentTrain: epoch  0, batch    70 | loss: 93.9045959CurrentTrain: epoch  0, batch    71 | loss: 78.5545837CurrentTrain: epoch  0, batch    72 | loss: 96.4817750CurrentTrain: epoch  0, batch    73 | loss: 94.5409598CurrentTrain: epoch  0, batch    74 | loss: 113.7949762CurrentTrain: epoch  0, batch    75 | loss: 111.8486622CurrentTrain: epoch  0, batch    76 | loss: 141.3080618CurrentTrain: epoch  0, batch    77 | loss: 110.9914759CurrentTrain: epoch  0, batch    78 | loss: 109.9924684CurrentTrain: epoch  0, batch    79 | loss: 91.3616353CurrentTrain: epoch  0, batch    80 | loss: 80.9103730CurrentTrain: epoch  0, batch    81 | loss: 78.3012493CurrentTrain: epoch  0, batch    82 | loss: 92.1452042CurrentTrain: epoch  0, batch    83 | loss: 81.9941384CurrentTrain: epoch  0, batch    84 | loss: 79.4437352CurrentTrain: epoch  0, batch    85 | loss: 110.6121851CurrentTrain: epoch  0, batch    86 | loss: 79.5295444CurrentTrain: epoch  0, batch    87 | loss: 110.6956448CurrentTrain: epoch  0, batch    88 | loss: 76.4673681CurrentTrain: epoch  0, batch    89 | loss: 113.0307923CurrentTrain: epoch  0, batch    90 | loss: 91.5237269CurrentTrain: epoch  0, batch    91 | loss: 91.5211326CurrentTrain: epoch  0, batch    92 | loss: 88.2537116CurrentTrain: epoch  0, batch    93 | loss: 95.7621248CurrentTrain: epoch  0, batch    94 | loss: 138.1011728CurrentTrain: epoch  0, batch    95 | loss: 113.1758902CurrentTrain: epoch  1, batch     0 | loss: 90.2264670CurrentTrain: epoch  1, batch     1 | loss: 76.3796583CurrentTrain: epoch  1, batch     2 | loss: 113.7622618CurrentTrain: epoch  1, batch     3 | loss: 75.4810897CurrentTrain: epoch  1, batch     4 | loss: 108.3512968CurrentTrain: epoch  1, batch     5 | loss: 109.1670140CurrentTrain: epoch  1, batch     6 | loss: 133.7274384CurrentTrain: epoch  1, batch     7 | loss: 136.4646792CurrentTrain: epoch  1, batch     8 | loss: 142.5120721CurrentTrain: epoch  1, batch     9 | loss: 111.6564861CurrentTrain: epoch  1, batch    10 | loss: 91.8540604CurrentTrain: epoch  1, batch    11 | loss: 74.4006955CurrentTrain: epoch  1, batch    12 | loss: 113.3687349CurrentTrain: epoch  1, batch    13 | loss: 81.0888009CurrentTrain: epoch  1, batch    14 | loss: 90.7781144CurrentTrain: epoch  1, batch    15 | loss: 91.2984754CurrentTrain: epoch  1, batch    16 | loss: 107.0828516CurrentTrain: epoch  1, batch    17 | loss: 88.1342835CurrentTrain: epoch  1, batch    18 | loss: 88.3760445CurrentTrain: epoch  1, batch    19 | loss: 76.4785031CurrentTrain: epoch  1, batch    20 | loss: 77.7830773CurrentTrain: epoch  1, batch    21 | loss: 134.6323506CurrentTrain: epoch  1, batch    22 | loss: 73.5187955CurrentTrain: epoch  1, batch    23 | loss: 89.1095374CurrentTrain: epoch  1, batch    24 | loss: 73.8056212CurrentTrain: epoch  1, batch    25 | loss: 86.0059266CurrentTrain: epoch  1, batch    26 | loss: 88.4340148CurrentTrain: epoch  1, batch    27 | loss: 106.8548227CurrentTrain: epoch  1, batch    28 | loss: 137.3627098CurrentTrain: epoch  1, batch    29 | loss: 80.4170087CurrentTrain: epoch  1, batch    30 | loss: 89.2744248CurrentTrain: epoch  1, batch    31 | loss: 90.1668620CurrentTrain: epoch  1, batch    32 | loss: 77.0652623CurrentTrain: epoch  1, batch    33 | loss: 67.1616228CurrentTrain: epoch  1, batch    34 | loss: 135.4155214CurrentTrain: epoch  1, batch    35 | loss: 110.4612217CurrentTrain: epoch  1, batch    36 | loss: 76.5403174CurrentTrain: epoch  1, batch    37 | loss: 110.6356803CurrentTrain: epoch  1, batch    38 | loss: 141.5619657CurrentTrain: epoch  1, batch    39 | loss: 89.7981180CurrentTrain: epoch  1, batch    40 | loss: 85.0211626CurrentTrain: epoch  1, batch    41 | loss: 89.2134581CurrentTrain: epoch  1, batch    42 | loss: 109.7468995CurrentTrain: epoch  1, batch    43 | loss: 78.4730674CurrentTrain: epoch  1, batch    44 | loss: 105.0455999CurrentTrain: epoch  1, batch    45 | loss: 108.2639843CurrentTrain: epoch  1, batch    46 | loss: 185.7386554CurrentTrain: epoch  1, batch    47 | loss: 89.8886280CurrentTrain: epoch  1, batch    48 | loss: 91.3726068CurrentTrain: epoch  1, batch    49 | loss: 87.9139959CurrentTrain: epoch  1, batch    50 | loss: 106.2318879CurrentTrain: epoch  1, batch    51 | loss: 92.0598495CurrentTrain: epoch  1, batch    52 | loss: 136.5359913CurrentTrain: epoch  1, batch    53 | loss: 85.7905964CurrentTrain: epoch  1, batch    54 | loss: 85.7367550CurrentTrain: epoch  1, batch    55 | loss: 90.7710038CurrentTrain: epoch  1, batch    56 | loss: 75.9389406CurrentTrain: epoch  1, batch    57 | loss: 72.5089720CurrentTrain: epoch  1, batch    58 | loss: 109.2203703CurrentTrain: epoch  1, batch    59 | loss: 105.9780921CurrentTrain: epoch  1, batch    60 | loss: 72.5469545CurrentTrain: epoch  1, batch    61 | loss: 64.5204480CurrentTrain: epoch  1, batch    62 | loss: 109.6367157CurrentTrain: epoch  1, batch    63 | loss: 114.0727351CurrentTrain: epoch  1, batch    64 | loss: 76.0584920CurrentTrain: epoch  1, batch    65 | loss: 86.7529736CurrentTrain: epoch  1, batch    66 | loss: 106.4161395CurrentTrain: epoch  1, batch    67 | loss: 71.8192643CurrentTrain: epoch  1, batch    68 | loss: 90.0316311CurrentTrain: epoch  1, batch    69 | loss: 76.4018857CurrentTrain: epoch  1, batch    70 | loss: 109.2689891CurrentTrain: epoch  1, batch    71 | loss: 74.5324543CurrentTrain: epoch  1, batch    72 | loss: 105.5115331CurrentTrain: epoch  1, batch    73 | loss: 83.1407562CurrentTrain: epoch  1, batch    74 | loss: 85.8796201CurrentTrain: epoch  1, batch    75 | loss: 75.1519507CurrentTrain: epoch  1, batch    76 | loss: 85.6605440CurrentTrain: epoch  1, batch    77 | loss: 71.1815162CurrentTrain: epoch  1, batch    78 | loss: 90.5168915CurrentTrain: epoch  1, batch    79 | loss: 105.1683707CurrentTrain: epoch  1, batch    80 | loss: 86.2582734CurrentTrain: epoch  1, batch    81 | loss: 106.4722594CurrentTrain: epoch  1, batch    82 | loss: 78.5152463CurrentTrain: epoch  1, batch    83 | loss: 86.5142162CurrentTrain: epoch  1, batch    84 | loss: 76.7936944CurrentTrain: epoch  1, batch    85 | loss: 77.7214825CurrentTrain: epoch  1, batch    86 | loss: 88.9327466CurrentTrain: epoch  1, batch    87 | loss: 75.2005228CurrentTrain: epoch  1, batch    88 | loss: 102.6886655CurrentTrain: epoch  1, batch    89 | loss: 87.4837328CurrentTrain: epoch  1, batch    90 | loss: 77.1545404CurrentTrain: epoch  1, batch    91 | loss: 89.5597347CurrentTrain: epoch  1, batch    92 | loss: 88.2168035CurrentTrain: epoch  1, batch    93 | loss: 85.2086779CurrentTrain: epoch  1, batch    94 | loss: 88.1292566CurrentTrain: epoch  1, batch    95 | loss: 72.2539386CurrentTrain: epoch  2, batch     0 | loss: 64.6682885CurrentTrain: epoch  2, batch     1 | loss: 64.0813975CurrentTrain: epoch  2, batch     2 | loss: 83.4419276CurrentTrain: epoch  2, batch     3 | loss: 74.2789255CurrentTrain: epoch  2, batch     4 | loss: 61.7667825CurrentTrain: epoch  2, batch     5 | loss: 105.5094216CurrentTrain: epoch  2, batch     6 | loss: 76.0634336CurrentTrain: epoch  2, batch     7 | loss: 87.5263711CurrentTrain: epoch  2, batch     8 | loss: 135.5410520CurrentTrain: epoch  2, batch     9 | loss: 86.1545869CurrentTrain: epoch  2, batch    10 | loss: 82.8891947CurrentTrain: epoch  2, batch    11 | loss: 74.8389317CurrentTrain: epoch  2, batch    12 | loss: 63.5989463CurrentTrain: epoch  2, batch    13 | loss: 103.4965694CurrentTrain: epoch  2, batch    14 | loss: 83.5285997CurrentTrain: epoch  2, batch    15 | loss: 104.6077834CurrentTrain: epoch  2, batch    16 | loss: 62.3266618CurrentTrain: epoch  2, batch    17 | loss: 102.8426899CurrentTrain: epoch  2, batch    18 | loss: 130.3250190CurrentTrain: epoch  2, batch    19 | loss: 86.0590585CurrentTrain: epoch  2, batch    20 | loss: 87.7073618CurrentTrain: epoch  2, batch    21 | loss: 103.8327273CurrentTrain: epoch  2, batch    22 | loss: 92.8789214CurrentTrain: epoch  2, batch    23 | loss: 62.1770121CurrentTrain: epoch  2, batch    24 | loss: 62.8668512CurrentTrain: epoch  2, batch    25 | loss: 86.7040559CurrentTrain: epoch  2, batch    26 | loss: 68.7276539CurrentTrain: epoch  2, batch    27 | loss: 83.6685033CurrentTrain: epoch  2, batch    28 | loss: 75.4712862CurrentTrain: epoch  2, batch    29 | loss: 87.4308112CurrentTrain: epoch  2, batch    30 | loss: 86.6536749CurrentTrain: epoch  2, batch    31 | loss: 85.8684796CurrentTrain: epoch  2, batch    32 | loss: 108.1194397CurrentTrain: epoch  2, batch    33 | loss: 130.5861844CurrentTrain: epoch  2, batch    34 | loss: 87.5847179CurrentTrain: epoch  2, batch    35 | loss: 89.1862004CurrentTrain: epoch  2, batch    36 | loss: 128.9031916CurrentTrain: epoch  2, batch    37 | loss: 102.0308543CurrentTrain: epoch  2, batch    38 | loss: 85.7755202CurrentTrain: epoch  2, batch    39 | loss: 106.7244559CurrentTrain: epoch  2, batch    40 | loss: 86.0365929CurrentTrain: epoch  2, batch    41 | loss: 71.7744902CurrentTrain: epoch  2, batch    42 | loss: 64.4427082CurrentTrain: epoch  2, batch    43 | loss: 69.5912681CurrentTrain: epoch  2, batch    44 | loss: 132.2590832CurrentTrain: epoch  2, batch    45 | loss: 90.8288232CurrentTrain: epoch  2, batch    46 | loss: 88.5724167CurrentTrain: epoch  2, batch    47 | loss: 84.0206553CurrentTrain: epoch  2, batch    48 | loss: 129.4482081CurrentTrain: epoch  2, batch    49 | loss: 64.3239240CurrentTrain: epoch  2, batch    50 | loss: 107.9452541CurrentTrain: epoch  2, batch    51 | loss: 87.1987131CurrentTrain: epoch  2, batch    52 | loss: 106.3074592CurrentTrain: epoch  2, batch    53 | loss: 63.0440990CurrentTrain: epoch  2, batch    54 | loss: 107.2058079CurrentTrain: epoch  2, batch    55 | loss: 86.0333431CurrentTrain: epoch  2, batch    56 | loss: 104.6217470CurrentTrain: epoch  2, batch    57 | loss: 84.2219819CurrentTrain: epoch  2, batch    58 | loss: 83.9783209CurrentTrain: epoch  2, batch    59 | loss: 103.9001173CurrentTrain: epoch  2, batch    60 | loss: 100.6816524CurrentTrain: epoch  2, batch    61 | loss: 108.0079282CurrentTrain: epoch  2, batch    62 | loss: 74.2174020CurrentTrain: epoch  2, batch    63 | loss: 87.0003656CurrentTrain: epoch  2, batch    64 | loss: 61.7924264CurrentTrain: epoch  2, batch    65 | loss: 103.9763634CurrentTrain: epoch  2, batch    66 | loss: 70.0859313CurrentTrain: epoch  2, batch    67 | loss: 89.9934606CurrentTrain: epoch  2, batch    68 | loss: 72.9990984CurrentTrain: epoch  2, batch    69 | loss: 76.2867602CurrentTrain: epoch  2, batch    70 | loss: 134.9830472CurrentTrain: epoch  2, batch    71 | loss: 70.9731427CurrentTrain: epoch  2, batch    72 | loss: 83.4380424CurrentTrain: epoch  2, batch    73 | loss: 133.4230356CurrentTrain: epoch  2, batch    74 | loss: 84.7474850CurrentTrain: epoch  2, batch    75 | loss: 74.9117538CurrentTrain: epoch  2, batch    76 | loss: 106.3927371CurrentTrain: epoch  2, batch    77 | loss: 88.1401387CurrentTrain: epoch  2, batch    78 | loss: 105.5283451CurrentTrain: epoch  2, batch    79 | loss: 74.4542891CurrentTrain: epoch  2, batch    80 | loss: 133.6131100CurrentTrain: epoch  2, batch    81 | loss: 73.0451154CurrentTrain: epoch  2, batch    82 | loss: 92.1619803CurrentTrain: epoch  2, batch    83 | loss: 77.1641958CurrentTrain: epoch  2, batch    84 | loss: 69.7830589CurrentTrain: epoch  2, batch    85 | loss: 87.5112708CurrentTrain: epoch  2, batch    86 | loss: 138.2605062CurrentTrain: epoch  2, batch    87 | loss: 108.0334294CurrentTrain: epoch  2, batch    88 | loss: 86.0476478CurrentTrain: epoch  2, batch    89 | loss: 84.8588871CurrentTrain: epoch  2, batch    90 | loss: 74.0646572CurrentTrain: epoch  2, batch    91 | loss: 87.4616780CurrentTrain: epoch  2, batch    92 | loss: 106.3431996CurrentTrain: epoch  2, batch    93 | loss: 136.0306674CurrentTrain: epoch  2, batch    94 | loss: 75.1068545CurrentTrain: epoch  2, batch    95 | loss: 108.4362039CurrentTrain: epoch  3, batch     0 | loss: 136.1653311CurrentTrain: epoch  3, batch     1 | loss: 69.3897720CurrentTrain: epoch  3, batch     2 | loss: 62.9552385CurrentTrain: epoch  3, batch     3 | loss: 70.7196233CurrentTrain: epoch  3, batch     4 | loss: 104.1425437CurrentTrain: epoch  3, batch     5 | loss: 72.4633738CurrentTrain: epoch  3, batch     6 | loss: 69.9180718CurrentTrain: epoch  3, batch     7 | loss: 128.7415299CurrentTrain: epoch  3, batch     8 | loss: 81.4076813CurrentTrain: epoch  3, batch     9 | loss: 61.1781380CurrentTrain: epoch  3, batch    10 | loss: 88.1095722CurrentTrain: epoch  3, batch    11 | loss: 99.3110682CurrentTrain: epoch  3, batch    12 | loss: 71.5531611CurrentTrain: epoch  3, batch    13 | loss: 104.4128245CurrentTrain: epoch  3, batch    14 | loss: 73.1229834CurrentTrain: epoch  3, batch    15 | loss: 71.9508898CurrentTrain: epoch  3, batch    16 | loss: 88.6721192CurrentTrain: epoch  3, batch    17 | loss: 72.9244301CurrentTrain: epoch  3, batch    18 | loss: 84.6287621CurrentTrain: epoch  3, batch    19 | loss: 104.7723528CurrentTrain: epoch  3, batch    20 | loss: 83.6716289CurrentTrain: epoch  3, batch    21 | loss: 89.4087466CurrentTrain: epoch  3, batch    22 | loss: 79.8110260CurrentTrain: epoch  3, batch    23 | loss: 129.0246908CurrentTrain: epoch  3, batch    24 | loss: 68.2293661CurrentTrain: epoch  3, batch    25 | loss: 103.0558857CurrentTrain: epoch  3, batch    26 | loss: 103.6085149CurrentTrain: epoch  3, batch    27 | loss: 59.6517875CurrentTrain: epoch  3, batch    28 | loss: 83.9778969CurrentTrain: epoch  3, batch    29 | loss: 71.1119193CurrentTrain: epoch  3, batch    30 | loss: 131.4878460CurrentTrain: epoch  3, batch    31 | loss: 102.8131715CurrentTrain: epoch  3, batch    32 | loss: 137.0641504CurrentTrain: epoch  3, batch    33 | loss: 101.2135123CurrentTrain: epoch  3, batch    34 | loss: 105.3063790CurrentTrain: epoch  3, batch    35 | loss: 83.5428330CurrentTrain: epoch  3, batch    36 | loss: 100.5415325CurrentTrain: epoch  3, batch    37 | loss: 70.1073365CurrentTrain: epoch  3, batch    38 | loss: 73.4850530CurrentTrain: epoch  3, batch    39 | loss: 86.3149509CurrentTrain: epoch  3, batch    40 | loss: 58.5419400CurrentTrain: epoch  3, batch    41 | loss: 61.6183595CurrentTrain: epoch  3, batch    42 | loss: 132.0887100CurrentTrain: epoch  3, batch    43 | loss: 90.7796938CurrentTrain: epoch  3, batch    44 | loss: 100.6103084CurrentTrain: epoch  3, batch    45 | loss: 57.9229223CurrentTrain: epoch  3, batch    46 | loss: 129.9650422CurrentTrain: epoch  3, batch    47 | loss: 100.6821558CurrentTrain: epoch  3, batch    48 | loss: 82.4313345CurrentTrain: epoch  3, batch    49 | loss: 81.8604763CurrentTrain: epoch  3, batch    50 | loss: 100.4278866CurrentTrain: epoch  3, batch    51 | loss: 70.1049526CurrentTrain: epoch  3, batch    52 | loss: 105.1607020CurrentTrain: epoch  3, batch    53 | loss: 70.8105863CurrentTrain: epoch  3, batch    54 | loss: 72.2814261CurrentTrain: epoch  3, batch    55 | loss: 102.8806791CurrentTrain: epoch  3, batch    56 | loss: 102.9330434CurrentTrain: epoch  3, batch    57 | loss: 84.0680873CurrentTrain: epoch  3, batch    58 | loss: 71.0295006CurrentTrain: epoch  3, batch    59 | loss: 102.4520080CurrentTrain: epoch  3, batch    60 | loss: 85.9552624CurrentTrain: epoch  3, batch    61 | loss: 87.7172666CurrentTrain: epoch  3, batch    62 | loss: 81.2681431CurrentTrain: epoch  3, batch    63 | loss: 84.3318464CurrentTrain: epoch  3, batch    64 | loss: 81.3970049CurrentTrain: epoch  3, batch    65 | loss: 63.7236357CurrentTrain: epoch  3, batch    66 | loss: 86.9152657CurrentTrain: epoch  3, batch    67 | loss: 70.5428650CurrentTrain: epoch  3, batch    68 | loss: 101.3840601CurrentTrain: epoch  3, batch    69 | loss: 62.2952906CurrentTrain: epoch  3, batch    70 | loss: 85.7840762CurrentTrain: epoch  3, batch    71 | loss: 95.3263777CurrentTrain: epoch  3, batch    72 | loss: 73.5683563CurrentTrain: epoch  3, batch    73 | loss: 85.1876183CurrentTrain: epoch  3, batch    74 | loss: 70.7942045CurrentTrain: epoch  3, batch    75 | loss: 80.9722743CurrentTrain: epoch  3, batch    76 | loss: 86.6160566CurrentTrain: epoch  3, batch    77 | loss: 91.4878428CurrentTrain: epoch  3, batch    78 | loss: 106.2763453CurrentTrain: epoch  3, batch    79 | loss: 101.2255467CurrentTrain: epoch  3, batch    80 | loss: 81.9105701CurrentTrain: epoch  3, batch    81 | loss: 101.1538432CurrentTrain: epoch  3, batch    82 | loss: 74.2754987CurrentTrain: epoch  3, batch    83 | loss: 133.0321490CurrentTrain: epoch  3, batch    84 | loss: 81.3146753CurrentTrain: epoch  3, batch    85 | loss: 85.6652548CurrentTrain: epoch  3, batch    86 | loss: 83.1553898CurrentTrain: epoch  3, batch    87 | loss: 107.1613614CurrentTrain: epoch  3, batch    88 | loss: 173.6792338CurrentTrain: epoch  3, batch    89 | loss: 87.6031875CurrentTrain: epoch  3, batch    90 | loss: 87.3097281CurrentTrain: epoch  3, batch    91 | loss: 102.9799865CurrentTrain: epoch  3, batch    92 | loss: 102.7143349CurrentTrain: epoch  3, batch    93 | loss: 98.0572582CurrentTrain: epoch  3, batch    94 | loss: 83.9390467CurrentTrain: epoch  3, batch    95 | loss: 73.3121364CurrentTrain: epoch  4, batch     0 | loss: 79.0409133CurrentTrain: epoch  4, batch     1 | loss: 98.3033106CurrentTrain: epoch  4, batch     2 | loss: 81.4076670CurrentTrain: epoch  4, batch     3 | loss: 69.7515434CurrentTrain: epoch  4, batch     4 | loss: 131.3118956CurrentTrain: epoch  4, batch     5 | loss: 127.7927685CurrentTrain: epoch  4, batch     6 | loss: 82.4314103CurrentTrain: epoch  4, batch     7 | loss: 83.9550709CurrentTrain: epoch  4, batch     8 | loss: 68.4750656CurrentTrain: epoch  4, batch     9 | loss: 103.3997585CurrentTrain: epoch  4, batch    10 | loss: 100.7138904CurrentTrain: epoch  4, batch    11 | loss: 101.1123711CurrentTrain: epoch  4, batch    12 | loss: 71.6033064CurrentTrain: epoch  4, batch    13 | loss: 76.3269284CurrentTrain: epoch  4, batch    14 | loss: 85.0548617CurrentTrain: epoch  4, batch    15 | loss: 57.9794167CurrentTrain: epoch  4, batch    16 | loss: 132.0905353CurrentTrain: epoch  4, batch    17 | loss: 71.5913325CurrentTrain: epoch  4, batch    18 | loss: 125.0909352CurrentTrain: epoch  4, batch    19 | loss: 98.5970114CurrentTrain: epoch  4, batch    20 | loss: 86.9424949CurrentTrain: epoch  4, batch    21 | loss: 81.7464080CurrentTrain: epoch  4, batch    22 | loss: 83.6631800CurrentTrain: epoch  4, batch    23 | loss: 78.9691276CurrentTrain: epoch  4, batch    24 | loss: 83.8393643CurrentTrain: epoch  4, batch    25 | loss: 84.3281493CurrentTrain: epoch  4, batch    26 | loss: 69.9682807CurrentTrain: epoch  4, batch    27 | loss: 81.0185066CurrentTrain: epoch  4, batch    28 | loss: 73.9296980CurrentTrain: epoch  4, batch    29 | loss: 86.8224399CurrentTrain: epoch  4, batch    30 | loss: 103.6893032CurrentTrain: epoch  4, batch    31 | loss: 68.0182564CurrentTrain: epoch  4, batch    32 | loss: 82.4676717CurrentTrain: epoch  4, batch    33 | loss: 82.2296226CurrentTrain: epoch  4, batch    34 | loss: 99.6070988CurrentTrain: epoch  4, batch    35 | loss: 65.7777475CurrentTrain: epoch  4, batch    36 | loss: 83.6508029CurrentTrain: epoch  4, batch    37 | loss: 96.8350975CurrentTrain: epoch  4, batch    38 | loss: 67.8083671CurrentTrain: epoch  4, batch    39 | loss: 70.6815893CurrentTrain: epoch  4, batch    40 | loss: 86.3832107CurrentTrain: epoch  4, batch    41 | loss: 81.5698735CurrentTrain: epoch  4, batch    42 | loss: 79.2825080CurrentTrain: epoch  4, batch    43 | loss: 82.2003077CurrentTrain: epoch  4, batch    44 | loss: 100.4231889CurrentTrain: epoch  4, batch    45 | loss: 72.7103379CurrentTrain: epoch  4, batch    46 | loss: 63.9580193CurrentTrain: epoch  4, batch    47 | loss: 80.5937264CurrentTrain: epoch  4, batch    48 | loss: 58.9626418CurrentTrain: epoch  4, batch    49 | loss: 82.2419758CurrentTrain: epoch  4, batch    50 | loss: 68.7077678CurrentTrain: epoch  4, batch    51 | loss: 85.0071215CurrentTrain: epoch  4, batch    52 | loss: 84.0834574CurrentTrain: epoch  4, batch    53 | loss: 85.0804334CurrentTrain: epoch  4, batch    54 | loss: 102.1320664CurrentTrain: epoch  4, batch    55 | loss: 101.7996259CurrentTrain: epoch  4, batch    56 | loss: 124.6580018CurrentTrain: epoch  4, batch    57 | loss: 68.3027012CurrentTrain: epoch  4, batch    58 | loss: 80.3361239CurrentTrain: epoch  4, batch    59 | loss: 72.3078165CurrentTrain: epoch  4, batch    60 | loss: 61.2961262CurrentTrain: epoch  4, batch    61 | loss: 87.4108846CurrentTrain: epoch  4, batch    62 | loss: 82.4383759CurrentTrain: epoch  4, batch    63 | loss: 71.4440899CurrentTrain: epoch  4, batch    64 | loss: 87.1234963CurrentTrain: epoch  4, batch    65 | loss: 82.7619529CurrentTrain: epoch  4, batch    66 | loss: 100.8950013CurrentTrain: epoch  4, batch    67 | loss: 71.3639429CurrentTrain: epoch  4, batch    68 | loss: 81.2244978CurrentTrain: epoch  4, batch    69 | loss: 106.7907016CurrentTrain: epoch  4, batch    70 | loss: 82.0290763CurrentTrain: epoch  4, batch    71 | loss: 137.0127107CurrentTrain: epoch  4, batch    72 | loss: 129.6910580CurrentTrain: epoch  4, batch    73 | loss: 101.2659320CurrentTrain: epoch  4, batch    74 | loss: 85.4922296CurrentTrain: epoch  4, batch    75 | loss: 84.4325379CurrentTrain: epoch  4, batch    76 | loss: 96.9578373CurrentTrain: epoch  4, batch    77 | loss: 98.8930377CurrentTrain: epoch  4, batch    78 | loss: 132.6067376CurrentTrain: epoch  4, batch    79 | loss: 126.7764190CurrentTrain: epoch  4, batch    80 | loss: 84.7468452CurrentTrain: epoch  4, batch    81 | loss: 79.6437295CurrentTrain: epoch  4, batch    82 | loss: 64.6845199CurrentTrain: epoch  4, batch    83 | loss: 100.0330334CurrentTrain: epoch  4, batch    84 | loss: 90.1672182CurrentTrain: epoch  4, batch    85 | loss: 103.1611154CurrentTrain: epoch  4, batch    86 | loss: 103.3110794CurrentTrain: epoch  4, batch    87 | loss: 71.1777525CurrentTrain: epoch  4, batch    88 | loss: 96.6230816CurrentTrain: epoch  4, batch    89 | loss: 103.2875080CurrentTrain: epoch  4, batch    90 | loss: 124.2278190CurrentTrain: epoch  4, batch    91 | loss: 82.5355636CurrentTrain: epoch  4, batch    92 | loss: 120.8931293CurrentTrain: epoch  4, batch    93 | loss: 101.5070253CurrentTrain: epoch  4, batch    94 | loss: 58.4630212CurrentTrain: epoch  4, batch    95 | loss: 69.0848492CurrentTrain: epoch  5, batch     0 | loss: 60.4160134CurrentTrain: epoch  5, batch     1 | loss: 100.2104870CurrentTrain: epoch  5, batch     2 | loss: 83.6125530CurrentTrain: epoch  5, batch     3 | loss: 99.1042441CurrentTrain: epoch  5, batch     4 | loss: 102.8755269CurrentTrain: epoch  5, batch     5 | loss: 81.9587165CurrentTrain: epoch  5, batch     6 | loss: 124.9305666CurrentTrain: epoch  5, batch     7 | loss: 79.7078446CurrentTrain: epoch  5, batch     8 | loss: 69.9370484CurrentTrain: epoch  5, batch     9 | loss: 55.3511516CurrentTrain: epoch  5, batch    10 | loss: 83.2446106CurrentTrain: epoch  5, batch    11 | loss: 125.1532769CurrentTrain: epoch  5, batch    12 | loss: 69.3605371CurrentTrain: epoch  5, batch    13 | loss: 102.9731428CurrentTrain: epoch  5, batch    14 | loss: 71.7818104CurrentTrain: epoch  5, batch    15 | loss: 98.7468233CurrentTrain: epoch  5, batch    16 | loss: 80.4384403CurrentTrain: epoch  5, batch    17 | loss: 72.9497758CurrentTrain: epoch  5, batch    18 | loss: 81.9902000CurrentTrain: epoch  5, batch    19 | loss: 83.6862191CurrentTrain: epoch  5, batch    20 | loss: 97.2155647CurrentTrain: epoch  5, batch    21 | loss: 70.8689994CurrentTrain: epoch  5, batch    22 | loss: 81.5763716CurrentTrain: epoch  5, batch    23 | loss: 99.2483179CurrentTrain: epoch  5, batch    24 | loss: 76.9093388CurrentTrain: epoch  5, batch    25 | loss: 63.5785784CurrentTrain: epoch  5, batch    26 | loss: 71.3402388CurrentTrain: epoch  5, batch    27 | loss: 103.6102728CurrentTrain: epoch  5, batch    28 | loss: 104.1658648CurrentTrain: epoch  5, batch    29 | loss: 80.4225740CurrentTrain: epoch  5, batch    30 | loss: 100.5709865CurrentTrain: epoch  5, batch    31 | loss: 69.7995297CurrentTrain: epoch  5, batch    32 | loss: 80.2907237CurrentTrain: epoch  5, batch    33 | loss: 70.2075888CurrentTrain: epoch  5, batch    34 | loss: 82.8976602CurrentTrain: epoch  5, batch    35 | loss: 78.9265231CurrentTrain: epoch  5, batch    36 | loss: 70.2069948CurrentTrain: epoch  5, batch    37 | loss: 102.7640402CurrentTrain: epoch  5, batch    38 | loss: 84.7767686CurrentTrain: epoch  5, batch    39 | loss: 95.4703276CurrentTrain: epoch  5, batch    40 | loss: 68.7296370CurrentTrain: epoch  5, batch    41 | loss: 102.8063210CurrentTrain: epoch  5, batch    42 | loss: 80.1139025CurrentTrain: epoch  5, batch    43 | loss: 78.1570655CurrentTrain: epoch  5, batch    44 | loss: 65.6051761CurrentTrain: epoch  5, batch    45 | loss: 64.8903709CurrentTrain: epoch  5, batch    46 | loss: 101.2787957CurrentTrain: epoch  5, batch    47 | loss: 130.4639311CurrentTrain: epoch  5, batch    48 | loss: 66.8132521CurrentTrain: epoch  5, batch    49 | loss: 70.2811681CurrentTrain: epoch  5, batch    50 | loss: 60.3966773CurrentTrain: epoch  5, batch    51 | loss: 100.8702878CurrentTrain: epoch  5, batch    52 | loss: 124.7471079CurrentTrain: epoch  5, batch    53 | loss: 70.3289475CurrentTrain: epoch  5, batch    54 | loss: 102.8373188CurrentTrain: epoch  5, batch    55 | loss: 95.7574769CurrentTrain: epoch  5, batch    56 | loss: 68.2242062CurrentTrain: epoch  5, batch    57 | loss: 100.4068561CurrentTrain: epoch  5, batch    58 | loss: 66.4534361CurrentTrain: epoch  5, batch    59 | loss: 72.0075671CurrentTrain: epoch  5, batch    60 | loss: 96.3693152CurrentTrain: epoch  5, batch    61 | loss: 62.5513074CurrentTrain: epoch  5, batch    62 | loss: 71.2086195CurrentTrain: epoch  5, batch    63 | loss: 82.5117533CurrentTrain: epoch  5, batch    64 | loss: 123.8523679CurrentTrain: epoch  5, batch    65 | loss: 66.8961307CurrentTrain: epoch  5, batch    66 | loss: 130.6931283CurrentTrain: epoch  5, batch    67 | loss: 69.8655338CurrentTrain: epoch  5, batch    68 | loss: 95.3213919CurrentTrain: epoch  5, batch    69 | loss: 78.0217150CurrentTrain: epoch  5, batch    70 | loss: 126.5439419CurrentTrain: epoch  5, batch    71 | loss: 95.8309563CurrentTrain: epoch  5, batch    72 | loss: 124.1788104CurrentTrain: epoch  5, batch    73 | loss: 72.3885815CurrentTrain: epoch  5, batch    74 | loss: 81.6424267CurrentTrain: epoch  5, batch    75 | loss: 70.8526727CurrentTrain: epoch  5, batch    76 | loss: 80.0185143CurrentTrain: epoch  5, batch    77 | loss: 66.4239492CurrentTrain: epoch  5, batch    78 | loss: 70.9500523CurrentTrain: epoch  5, batch    79 | loss: 69.4813853CurrentTrain: epoch  5, batch    80 | loss: 102.1370114CurrentTrain: epoch  5, batch    81 | loss: 84.5860023CurrentTrain: epoch  5, batch    82 | loss: 95.1770277CurrentTrain: epoch  5, batch    83 | loss: 81.7558349CurrentTrain: epoch  5, batch    84 | loss: 98.5455495CurrentTrain: epoch  5, batch    85 | loss: 124.2396216CurrentTrain: epoch  5, batch    86 | loss: 91.8545186CurrentTrain: epoch  5, batch    87 | loss: 84.4565988CurrentTrain: epoch  5, batch    88 | loss: 80.5743934CurrentTrain: epoch  5, batch    89 | loss: 82.3865926CurrentTrain: epoch  5, batch    90 | loss: 126.5366727CurrentTrain: epoch  5, batch    91 | loss: 96.9897524CurrentTrain: epoch  5, batch    92 | loss: 81.7411255CurrentTrain: epoch  5, batch    93 | loss: 100.3237006CurrentTrain: epoch  5, batch    94 | loss: 82.5689352CurrentTrain: epoch  5, batch    95 | loss: 84.9030071CurrentTrain: epoch  6, batch     0 | loss: 68.4866858CurrentTrain: epoch  6, batch     1 | loss: 69.4446102CurrentTrain: epoch  6, batch     2 | loss: 78.0514266CurrentTrain: epoch  6, batch     3 | loss: 69.1602262CurrentTrain: epoch  6, batch     4 | loss: 91.7512198CurrentTrain: epoch  6, batch     5 | loss: 66.8810997CurrentTrain: epoch  6, batch     6 | loss: 81.2214643CurrentTrain: epoch  6, batch     7 | loss: 79.1890620CurrentTrain: epoch  6, batch     8 | loss: 70.1935727CurrentTrain: epoch  6, batch     9 | loss: 98.8859506CurrentTrain: epoch  6, batch    10 | loss: 53.7130206CurrentTrain: epoch  6, batch    11 | loss: 128.5096297CurrentTrain: epoch  6, batch    12 | loss: 99.7188471CurrentTrain: epoch  6, batch    13 | loss: 67.1168140CurrentTrain: epoch  6, batch    14 | loss: 96.0957236CurrentTrain: epoch  6, batch    15 | loss: 65.1526716CurrentTrain: epoch  6, batch    16 | loss: 81.4089358CurrentTrain: epoch  6, batch    17 | loss: 104.2794991CurrentTrain: epoch  6, batch    18 | loss: 83.2932910CurrentTrain: epoch  6, batch    19 | loss: 80.7179654CurrentTrain: epoch  6, batch    20 | loss: 76.1702584CurrentTrain: epoch  6, batch    21 | loss: 83.3082269CurrentTrain: epoch  6, batch    22 | loss: 76.7505395CurrentTrain: epoch  6, batch    23 | loss: 79.1763813CurrentTrain: epoch  6, batch    24 | loss: 98.1252648CurrentTrain: epoch  6, batch    25 | loss: 80.9042947CurrentTrain: epoch  6, batch    26 | loss: 78.8216184CurrentTrain: epoch  6, batch    27 | loss: 127.9401579CurrentTrain: epoch  6, batch    28 | loss: 64.7500522CurrentTrain: epoch  6, batch    29 | loss: 81.3972855CurrentTrain: epoch  6, batch    30 | loss: 75.7814395CurrentTrain: epoch  6, batch    31 | loss: 66.4634115CurrentTrain: epoch  6, batch    32 | loss: 125.3453767CurrentTrain: epoch  6, batch    33 | loss: 79.0365285CurrentTrain: epoch  6, batch    34 | loss: 83.3724380CurrentTrain: epoch  6, batch    35 | loss: 99.0877711CurrentTrain: epoch  6, batch    36 | loss: 69.8728569CurrentTrain: epoch  6, batch    37 | loss: 91.2686968CurrentTrain: epoch  6, batch    38 | loss: 56.4748439CurrentTrain: epoch  6, batch    39 | loss: 103.3262223CurrentTrain: epoch  6, batch    40 | loss: 67.4720722CurrentTrain: epoch  6, batch    41 | loss: 61.0717411CurrentTrain: epoch  6, batch    42 | loss: 80.6733522CurrentTrain: epoch  6, batch    43 | loss: 58.1346059CurrentTrain: epoch  6, batch    44 | loss: 66.2194916CurrentTrain: epoch  6, batch    45 | loss: 99.3494540CurrentTrain: epoch  6, batch    46 | loss: 66.4196172CurrentTrain: epoch  6, batch    47 | loss: 101.8334492CurrentTrain: epoch  6, batch    48 | loss: 101.5821942CurrentTrain: epoch  6, batch    49 | loss: 100.1084396CurrentTrain: epoch  6, batch    50 | loss: 69.7517391CurrentTrain: epoch  6, batch    51 | loss: 69.3046301CurrentTrain: epoch  6, batch    52 | loss: 68.1391061CurrentTrain: epoch  6, batch    53 | loss: 127.3924748CurrentTrain: epoch  6, batch    54 | loss: 69.0542810CurrentTrain: epoch  6, batch    55 | loss: 94.6059350CurrentTrain: epoch  6, batch    56 | loss: 80.3118872CurrentTrain: epoch  6, batch    57 | loss: 81.7800035CurrentTrain: epoch  6, batch    58 | loss: 87.2903258CurrentTrain: epoch  6, batch    59 | loss: 80.1795618CurrentTrain: epoch  6, batch    60 | loss: 82.0550346CurrentTrain: epoch  6, batch    61 | loss: 68.2995356CurrentTrain: epoch  6, batch    62 | loss: 78.7192625CurrentTrain: epoch  6, batch    63 | loss: 83.9786663CurrentTrain: epoch  6, batch    64 | loss: 95.2080317CurrentTrain: epoch  6, batch    65 | loss: 64.5968602CurrentTrain: epoch  6, batch    66 | loss: 102.6483622CurrentTrain: epoch  6, batch    67 | loss: 97.2355729CurrentTrain: epoch  6, batch    68 | loss: 94.6654301CurrentTrain: epoch  6, batch    69 | loss: 94.6361147CurrentTrain: epoch  6, batch    70 | loss: 76.0982428CurrentTrain: epoch  6, batch    71 | loss: 66.0960756CurrentTrain: epoch  6, batch    72 | loss: 124.8639470CurrentTrain: epoch  6, batch    73 | loss: 95.0455790CurrentTrain: epoch  6, batch    74 | loss: 81.9666100CurrentTrain: epoch  6, batch    75 | loss: 100.3775369CurrentTrain: epoch  6, batch    76 | loss: 124.7690602CurrentTrain: epoch  6, batch    77 | loss: 83.5713034CurrentTrain: epoch  6, batch    78 | loss: 81.4058720CurrentTrain: epoch  6, batch    79 | loss: 80.2867023CurrentTrain: epoch  6, batch    80 | loss: 66.4737848CurrentTrain: epoch  6, batch    81 | loss: 102.5833540CurrentTrain: epoch  6, batch    82 | loss: 68.0545450CurrentTrain: epoch  6, batch    83 | loss: 98.2384757CurrentTrain: epoch  6, batch    84 | loss: 97.1481518CurrentTrain: epoch  6, batch    85 | loss: 77.1327603CurrentTrain: epoch  6, batch    86 | loss: 80.7912559CurrentTrain: epoch  6, batch    87 | loss: 103.2156287CurrentTrain: epoch  6, batch    88 | loss: 80.8344976CurrentTrain: epoch  6, batch    89 | loss: 61.6453818CurrentTrain: epoch  6, batch    90 | loss: 125.0684613CurrentTrain: epoch  6, batch    91 | loss: 100.9007167CurrentTrain: epoch  6, batch    92 | loss: 82.5851241CurrentTrain: epoch  6, batch    93 | loss: 76.8381759CurrentTrain: epoch  6, batch    94 | loss: 81.4203080CurrentTrain: epoch  6, batch    95 | loss: 67.4425430CurrentTrain: epoch  7, batch     0 | loss: 66.5787034CurrentTrain: epoch  7, batch     1 | loss: 76.6743831CurrentTrain: epoch  7, batch     2 | loss: 64.8525441CurrentTrain: epoch  7, batch     3 | loss: 81.5609088CurrentTrain: epoch  7, batch     4 | loss: 79.3113255CurrentTrain: epoch  7, batch     5 | loss: 98.9612852CurrentTrain: epoch  7, batch     6 | loss: 122.0788505CurrentTrain: epoch  7, batch     7 | loss: 75.7691215CurrentTrain: epoch  7, batch     8 | loss: 63.4451484CurrentTrain: epoch  7, batch     9 | loss: 66.5226389CurrentTrain: epoch  7, batch    10 | loss: 57.5606691CurrentTrain: epoch  7, batch    11 | loss: 79.3586686CurrentTrain: epoch  7, batch    12 | loss: 98.3425210CurrentTrain: epoch  7, batch    13 | loss: 56.2396926CurrentTrain: epoch  7, batch    14 | loss: 65.6714455CurrentTrain: epoch  7, batch    15 | loss: 76.6863644CurrentTrain: epoch  7, batch    16 | loss: 76.8777864CurrentTrain: epoch  7, batch    17 | loss: 67.6468722CurrentTrain: epoch  7, batch    18 | loss: 124.6275447CurrentTrain: epoch  7, batch    19 | loss: 93.9833904CurrentTrain: epoch  7, batch    20 | loss: 70.4709682CurrentTrain: epoch  7, batch    21 | loss: 69.0843814CurrentTrain: epoch  7, batch    22 | loss: 78.6733722CurrentTrain: epoch  7, batch    23 | loss: 99.2408224CurrentTrain: epoch  7, batch    24 | loss: 78.8686531CurrentTrain: epoch  7, batch    25 | loss: 79.5399762CurrentTrain: epoch  7, batch    26 | loss: 99.4698293CurrentTrain: epoch  7, batch    27 | loss: 121.2405211CurrentTrain: epoch  7, batch    28 | loss: 79.8365903CurrentTrain: epoch  7, batch    29 | loss: 92.1938518CurrentTrain: epoch  7, batch    30 | loss: 55.1092722CurrentTrain: epoch  7, batch    31 | loss: 82.3108728CurrentTrain: epoch  7, batch    32 | loss: 99.8027234CurrentTrain: epoch  7, batch    33 | loss: 79.0228681CurrentTrain: epoch  7, batch    34 | loss: 77.5946592CurrentTrain: epoch  7, batch    35 | loss: 124.7206297CurrentTrain: epoch  7, batch    36 | loss: 79.8870243CurrentTrain: epoch  7, batch    37 | loss: 79.2176067CurrentTrain: epoch  7, batch    38 | loss: 95.3008986CurrentTrain: epoch  7, batch    39 | loss: 70.2843787CurrentTrain: epoch  7, batch    40 | loss: 81.1369996CurrentTrain: epoch  7, batch    41 | loss: 118.1312536CurrentTrain: epoch  7, batch    42 | loss: 68.6653800CurrentTrain: epoch  7, batch    43 | loss: 97.6560148CurrentTrain: epoch  7, batch    44 | loss: 96.2497931CurrentTrain: epoch  7, batch    45 | loss: 78.9627182CurrentTrain: epoch  7, batch    46 | loss: 97.8674135CurrentTrain: epoch  7, batch    47 | loss: 99.8878556CurrentTrain: epoch  7, batch    48 | loss: 96.1929330CurrentTrain: epoch  7, batch    49 | loss: 70.4818223CurrentTrain: epoch  7, batch    50 | loss: 56.7305693CurrentTrain: epoch  7, batch    51 | loss: 95.3269896CurrentTrain: epoch  7, batch    52 | loss: 76.0940200CurrentTrain: epoch  7, batch    53 | loss: 82.7650731CurrentTrain: epoch  7, batch    54 | loss: 63.5672691CurrentTrain: epoch  7, batch    55 | loss: 76.0818457CurrentTrain: epoch  7, batch    56 | loss: 77.3428257CurrentTrain: epoch  7, batch    57 | loss: 96.7240128CurrentTrain: epoch  7, batch    58 | loss: 97.6618236CurrentTrain: epoch  7, batch    59 | loss: 75.4872527CurrentTrain: epoch  7, batch    60 | loss: 75.1463701CurrentTrain: epoch  7, batch    61 | loss: 80.1914551CurrentTrain: epoch  7, batch    62 | loss: 77.7409461CurrentTrain: epoch  7, batch    63 | loss: 101.3717531CurrentTrain: epoch  7, batch    64 | loss: 68.4300599CurrentTrain: epoch  7, batch    65 | loss: 76.7105981CurrentTrain: epoch  7, batch    66 | loss: 97.3691378CurrentTrain: epoch  7, batch    67 | loss: 99.2776535CurrentTrain: epoch  7, batch    68 | loss: 77.9236508CurrentTrain: epoch  7, batch    69 | loss: 65.0262462CurrentTrain: epoch  7, batch    70 | loss: 66.0368857CurrentTrain: epoch  7, batch    71 | loss: 60.0822716CurrentTrain: epoch  7, batch    72 | loss: 100.9500385CurrentTrain: epoch  7, batch    73 | loss: 77.3204586CurrentTrain: epoch  7, batch    74 | loss: 84.4068908CurrentTrain: epoch  7, batch    75 | loss: 76.6879649CurrentTrain: epoch  7, batch    76 | loss: 129.3312416CurrentTrain: epoch  7, batch    77 | loss: 67.6597895CurrentTrain: epoch  7, batch    78 | loss: 122.3878758CurrentTrain: epoch  7, batch    79 | loss: 81.3596745CurrentTrain: epoch  7, batch    80 | loss: 128.4716878CurrentTrain: epoch  7, batch    81 | loss: 57.0202319CurrentTrain: epoch  7, batch    82 | loss: 66.8397199CurrentTrain: epoch  7, batch    83 | loss: 57.3205392CurrentTrain: epoch  7, batch    84 | loss: 66.6348885CurrentTrain: epoch  7, batch    85 | loss: 125.0554149CurrentTrain: epoch  7, batch    86 | loss: 59.3441685CurrentTrain: epoch  7, batch    87 | loss: 126.4302443CurrentTrain: epoch  7, batch    88 | loss: 79.1462819CurrentTrain: epoch  7, batch    89 | loss: 79.4920428CurrentTrain: epoch  7, batch    90 | loss: 128.4168849CurrentTrain: epoch  7, batch    91 | loss: 79.9349956CurrentTrain: epoch  7, batch    92 | loss: 53.9673022CurrentTrain: epoch  7, batch    93 | loss: 90.6640504CurrentTrain: epoch  7, batch    94 | loss: 77.5698992CurrentTrain: epoch  7, batch    95 | loss: 142.4649791CurrentTrain: epoch  8, batch     0 | loss: 77.3250516CurrentTrain: epoch  8, batch     1 | loss: 66.5289195CurrentTrain: epoch  8, batch     2 | loss: 60.3149439CurrentTrain: epoch  8, batch     3 | loss: 78.5163433CurrentTrain: epoch  8, batch     4 | loss: 65.3494692CurrentTrain: epoch  8, batch     5 | loss: 77.4962077CurrentTrain: epoch  8, batch     6 | loss: 61.2510547CurrentTrain: epoch  8, batch     7 | loss: 82.4188535CurrentTrain: epoch  8, batch     8 | loss: 77.7604618CurrentTrain: epoch  8, batch     9 | loss: 57.0904688CurrentTrain: epoch  8, batch    10 | loss: 79.1577896CurrentTrain: epoch  8, batch    11 | loss: 61.6875960CurrentTrain: epoch  8, batch    12 | loss: 79.7661434CurrentTrain: epoch  8, batch    13 | loss: 95.6470537CurrentTrain: epoch  8, batch    14 | loss: 98.7768968CurrentTrain: epoch  8, batch    15 | loss: 64.9256738CurrentTrain: epoch  8, batch    16 | loss: 124.0603150CurrentTrain: epoch  8, batch    17 | loss: 81.0939610CurrentTrain: epoch  8, batch    18 | loss: 80.7673886CurrentTrain: epoch  8, batch    19 | loss: 115.8605039CurrentTrain: epoch  8, batch    20 | loss: 78.5500368CurrentTrain: epoch  8, batch    21 | loss: 81.4807655CurrentTrain: epoch  8, batch    22 | loss: 76.7020067CurrentTrain: epoch  8, batch    23 | loss: 94.1295994CurrentTrain: epoch  8, batch    24 | loss: 78.2537337CurrentTrain: epoch  8, batch    25 | loss: 78.6482227CurrentTrain: epoch  8, batch    26 | loss: 98.2758560CurrentTrain: epoch  8, batch    27 | loss: 78.6947435CurrentTrain: epoch  8, batch    28 | loss: 98.7449469CurrentTrain: epoch  8, batch    29 | loss: 78.0356937CurrentTrain: epoch  8, batch    30 | loss: 79.9716683CurrentTrain: epoch  8, batch    31 | loss: 57.9565012CurrentTrain: epoch  8, batch    32 | loss: 62.0342374CurrentTrain: epoch  8, batch    33 | loss: 118.5180785CurrentTrain: epoch  8, batch    34 | loss: 122.3450160CurrentTrain: epoch  8, batch    35 | loss: 93.3397251CurrentTrain: epoch  8, batch    36 | loss: 90.7924323CurrentTrain: epoch  8, batch    37 | loss: 79.8094451CurrentTrain: epoch  8, batch    38 | loss: 79.6977162CurrentTrain: epoch  8, batch    39 | loss: 81.3066428CurrentTrain: epoch  8, batch    40 | loss: 80.0614459CurrentTrain: epoch  8, batch    41 | loss: 79.0355679CurrentTrain: epoch  8, batch    42 | loss: 66.4715475CurrentTrain: epoch  8, batch    43 | loss: 127.3792885CurrentTrain: epoch  8, batch    44 | loss: 124.9746141CurrentTrain: epoch  8, batch    45 | loss: 61.4487207CurrentTrain: epoch  8, batch    46 | loss: 58.8172393CurrentTrain: epoch  8, batch    47 | loss: 79.3543927CurrentTrain: epoch  8, batch    48 | loss: 82.8646670CurrentTrain: epoch  8, batch    49 | loss: 70.2353525CurrentTrain: epoch  8, batch    50 | loss: 54.2900863CurrentTrain: epoch  8, batch    51 | loss: 93.1502038CurrentTrain: epoch  8, batch    52 | loss: 122.0300682CurrentTrain: epoch  8, batch    53 | loss: 75.7118798CurrentTrain: epoch  8, batch    54 | loss: 69.9411585CurrentTrain: epoch  8, batch    55 | loss: 66.4008802CurrentTrain: epoch  8, batch    56 | loss: 66.3282446CurrentTrain: epoch  8, batch    57 | loss: 77.7386331CurrentTrain: epoch  8, batch    58 | loss: 62.0549952CurrentTrain: epoch  8, batch    59 | loss: 84.7159799CurrentTrain: epoch  8, batch    60 | loss: 98.7345568CurrentTrain: epoch  8, batch    61 | loss: 66.8437166CurrentTrain: epoch  8, batch    62 | loss: 120.9692966CurrentTrain: epoch  8, batch    63 | loss: 69.1650878CurrentTrain: epoch  8, batch    64 | loss: 97.6589835CurrentTrain: epoch  8, batch    65 | loss: 57.0612514CurrentTrain: epoch  8, batch    66 | loss: 94.4626594CurrentTrain: epoch  8, batch    67 | loss: 97.1808732CurrentTrain: epoch  8, batch    68 | loss: 96.6909115CurrentTrain: epoch  8, batch    69 | loss: 97.1133738CurrentTrain: epoch  8, batch    70 | loss: 61.1676893CurrentTrain: epoch  8, batch    71 | loss: 53.0240654CurrentTrain: epoch  8, batch    72 | loss: 91.0343397CurrentTrain: epoch  8, batch    73 | loss: 77.7483978CurrentTrain: epoch  8, batch    74 | loss: 81.8410113CurrentTrain: epoch  8, batch    75 | loss: 96.9317643CurrentTrain: epoch  8, batch    76 | loss: 78.9435452CurrentTrain: epoch  8, batch    77 | loss: 96.3303457CurrentTrain: epoch  8, batch    78 | loss: 70.1174003CurrentTrain: epoch  8, batch    79 | loss: 75.0266189CurrentTrain: epoch  8, batch    80 | loss: 74.9520481CurrentTrain: epoch  8, batch    81 | loss: 80.7960236CurrentTrain: epoch  8, batch    82 | loss: 65.9650757CurrentTrain: epoch  8, batch    83 | loss: 167.3933847CurrentTrain: epoch  8, batch    84 | loss: 67.4754870CurrentTrain: epoch  8, batch    85 | loss: 78.6416289CurrentTrain: epoch  8, batch    86 | loss: 66.8974464CurrentTrain: epoch  8, batch    87 | loss: 65.3347008CurrentTrain: epoch  8, batch    88 | loss: 82.8868392CurrentTrain: epoch  8, batch    89 | loss: 92.0033491CurrentTrain: epoch  8, batch    90 | loss: 62.0502088CurrentTrain: epoch  8, batch    91 | loss: 82.9811644CurrentTrain: epoch  8, batch    92 | loss: 67.4954055CurrentTrain: epoch  8, batch    93 | loss: 104.0914480CurrentTrain: epoch  8, batch    94 | loss: 65.9789120CurrentTrain: epoch  8, batch    95 | loss: 79.0420740CurrentTrain: epoch  9, batch     0 | loss: 92.9785128CurrentTrain: epoch  9, batch     1 | loss: 62.6715924CurrentTrain: epoch  9, batch     2 | loss: 96.7106656CurrentTrain: epoch  9, batch     3 | loss: 56.3416552CurrentTrain: epoch  9, batch     4 | loss: 94.1861373CurrentTrain: epoch  9, batch     5 | loss: 63.1032003CurrentTrain: epoch  9, batch     6 | loss: 61.0591401CurrentTrain: epoch  9, batch     7 | loss: 95.7859919CurrentTrain: epoch  9, batch     8 | loss: 91.1098723CurrentTrain: epoch  9, batch     9 | loss: 80.4041309CurrentTrain: epoch  9, batch    10 | loss: 97.1850164CurrentTrain: epoch  9, batch    11 | loss: 126.0938846CurrentTrain: epoch  9, batch    12 | loss: 95.5907327CurrentTrain: epoch  9, batch    13 | loss: 93.7497168CurrentTrain: epoch  9, batch    14 | loss: 93.7718923CurrentTrain: epoch  9, batch    15 | loss: 64.8402375CurrentTrain: epoch  9, batch    16 | loss: 76.6992647CurrentTrain: epoch  9, batch    17 | loss: 128.9910696CurrentTrain: epoch  9, batch    18 | loss: 79.6645502CurrentTrain: epoch  9, batch    19 | loss: 94.1142717CurrentTrain: epoch  9, batch    20 | loss: 88.4296569CurrentTrain: epoch  9, batch    21 | loss: 60.3367048CurrentTrain: epoch  9, batch    22 | loss: 76.9457729CurrentTrain: epoch  9, batch    23 | loss: 98.6869621CurrentTrain: epoch  9, batch    24 | loss: 97.8411359CurrentTrain: epoch  9, batch    25 | loss: 96.3909938CurrentTrain: epoch  9, batch    26 | loss: 77.6117261CurrentTrain: epoch  9, batch    27 | loss: 67.1443281CurrentTrain: epoch  9, batch    28 | loss: 64.5847339CurrentTrain: epoch  9, batch    29 | loss: 80.0278256CurrentTrain: epoch  9, batch    30 | loss: 58.6463079CurrentTrain: epoch  9, batch    31 | loss: 95.7548234CurrentTrain: epoch  9, batch    32 | loss: 65.9947146CurrentTrain: epoch  9, batch    33 | loss: 75.7935926CurrentTrain: epoch  9, batch    34 | loss: 118.3622031CurrentTrain: epoch  9, batch    35 | loss: 78.0723242CurrentTrain: epoch  9, batch    36 | loss: 64.2954732CurrentTrain: epoch  9, batch    37 | loss: 168.6167490CurrentTrain: epoch  9, batch    38 | loss: 81.4947325CurrentTrain: epoch  9, batch    39 | loss: 73.4651633CurrentTrain: epoch  9, batch    40 | loss: 100.6032073CurrentTrain: epoch  9, batch    41 | loss: 66.5630397CurrentTrain: epoch  9, batch    42 | loss: 62.6590146CurrentTrain: epoch  9, batch    43 | loss: 57.6198732CurrentTrain: epoch  9, batch    44 | loss: 74.7100356CurrentTrain: epoch  9, batch    45 | loss: 65.3116440CurrentTrain: epoch  9, batch    46 | loss: 120.9506817CurrentTrain: epoch  9, batch    47 | loss: 126.8422368CurrentTrain: epoch  9, batch    48 | loss: 79.4938047CurrentTrain: epoch  9, batch    49 | loss: 67.3122830CurrentTrain: epoch  9, batch    50 | loss: 76.0678811CurrentTrain: epoch  9, batch    51 | loss: 68.8938521CurrentTrain: epoch  9, batch    52 | loss: 70.8902353CurrentTrain: epoch  9, batch    53 | loss: 92.2847830CurrentTrain: epoch  9, batch    54 | loss: 63.7633120CurrentTrain: epoch  9, batch    55 | loss: 78.0145821CurrentTrain: epoch  9, batch    56 | loss: 65.3175773CurrentTrain: epoch  9, batch    57 | loss: 77.3280390CurrentTrain: epoch  9, batch    58 | loss: 64.7133665CurrentTrain: epoch  9, batch    59 | loss: 73.1460299CurrentTrain: epoch  9, batch    60 | loss: 93.7217704CurrentTrain: epoch  9, batch    61 | loss: 96.1645398CurrentTrain: epoch  9, batch    62 | loss: 72.9794141CurrentTrain: epoch  9, batch    63 | loss: 94.0181013CurrentTrain: epoch  9, batch    64 | loss: 164.1302256CurrentTrain: epoch  9, batch    65 | loss: 76.9846331CurrentTrain: epoch  9, batch    66 | loss: 97.5460914CurrentTrain: epoch  9, batch    67 | loss: 77.7816263CurrentTrain: epoch  9, batch    68 | loss: 75.8854809CurrentTrain: epoch  9, batch    69 | loss: 67.5867301CurrentTrain: epoch  9, batch    70 | loss: 75.0194166CurrentTrain: epoch  9, batch    71 | loss: 73.6742298CurrentTrain: epoch  9, batch    72 | loss: 65.7868988CurrentTrain: epoch  9, batch    73 | loss: 62.1537635CurrentTrain: epoch  9, batch    74 | loss: 79.2966839CurrentTrain: epoch  9, batch    75 | loss: 58.2290119CurrentTrain: epoch  9, batch    76 | loss: 74.0595511CurrentTrain: epoch  9, batch    77 | loss: 64.8392399CurrentTrain: epoch  9, batch    78 | loss: 97.7715188CurrentTrain: epoch  9, batch    79 | loss: 77.7670108CurrentTrain: epoch  9, batch    80 | loss: 121.1947916CurrentTrain: epoch  9, batch    81 | loss: 74.9244776CurrentTrain: epoch  9, batch    82 | loss: 96.5253228CurrentTrain: epoch  9, batch    83 | loss: 63.5106460CurrentTrain: epoch  9, batch    84 | loss: 97.4931675CurrentTrain: epoch  9, batch    85 | loss: 66.4400759CurrentTrain: epoch  9, batch    86 | loss: 74.1190842CurrentTrain: epoch  9, batch    87 | loss: 81.9502068CurrentTrain: epoch  9, batch    88 | loss: 67.0243010CurrentTrain: epoch  9, batch    89 | loss: 174.6176077CurrentTrain: epoch  9, batch    90 | loss: 66.1475082CurrentTrain: epoch  9, batch    91 | loss: 76.1077769CurrentTrain: epoch  9, batch    92 | loss: 63.9429621CurrentTrain: epoch  9, batch    93 | loss: 79.0795085CurrentTrain: epoch  9, batch    94 | loss: 63.8748518CurrentTrain: epoch  9, batch    95 | loss: 81.9303750

F1 score per class: {32: np.float64(0.5621621621621622), 6: np.float64(0.8310502283105022), 19: np.float64(0.3902439024390244), 24: np.float64(0.7570621468926554), 26: np.float64(0.94), 29: np.float64(0.8151658767772512)}
Micro-average F1 score: 0.7705711519845111
Weighted-average F1 score: 0.7736535307608552
F1 score per class: {32: np.float64(0.6415094339622641), 6: np.float64(0.8034934497816594), 19: np.float64(0.24390243902439024), 24: np.float64(0.7597765363128491), 26: np.float64(0.94), 29: np.float64(0.8380952380952381)}
Micro-average F1 score: 0.7553956834532374
Weighted-average F1 score: 0.7362328119231648
F1 score per class: {32: np.float64(0.6476190476190476), 6: np.float64(0.8), 19: np.float64(0.37037037037037035), 24: np.float64(0.7640449438202247), 26: np.float64(0.94), 29: np.float64(0.827906976744186)}
Micro-average F1 score: 0.7746090156393745
Weighted-average F1 score: 0.7686752838576231

F1 score per class: {32: np.float64(0.5621621621621622), 6: np.float64(0.8310502283105022), 19: np.float64(0.3902439024390244), 24: np.float64(0.7570621468926554), 26: np.float64(0.94), 29: np.float64(0.8151658767772512)}
Micro-average F1 score: 0.7705711519845111
Weighted-average F1 score: 0.7736535307608552
F1 score per class: {32: np.float64(0.6415094339622641), 6: np.float64(0.8034934497816594), 19: np.float64(0.24390243902439024), 24: np.float64(0.7597765363128491), 26: np.float64(0.94), 29: np.float64(0.8380952380952381)}
Micro-average F1 score: 0.7553956834532374
Weighted-average F1 score: 0.7362328119231648
F1 score per class: {32: np.float64(0.6476190476190476), 6: np.float64(0.8), 19: np.float64(0.37037037037037035), 24: np.float64(0.7640449438202247), 26: np.float64(0.94), 29: np.float64(0.827906976744186)}
Micro-average F1 score: 0.7746090156393745
Weighted-average F1 score: 0.7686752838576231

F1 score per class: {32: np.float64(0.42105263157894735), 6: np.float64(0.774468085106383), 19: np.float64(0.22535211267605634), 24: np.float64(0.7015706806282722), 26: np.float64(0.8623853211009175), 29: np.float64(0.6441947565543071)}
Micro-average F1 score: 0.6476810414971521
Weighted-average F1 score: 0.6351287123416994
F1 score per class: {32: np.float64(0.47058823529411764), 6: np.float64(0.7419354838709677), 19: np.float64(0.1360544217687075), 24: np.float64(0.6938775510204082), 26: np.float64(0.8430493273542601), 29: np.float64(0.676923076923077)}
Micro-average F1 score: 0.6162876008804109
Weighted-average F1 score: 0.5856966307241186
F1 score per class: {32: np.float64(0.47719298245614034), 6: np.float64(0.736), 19: np.float64(0.19801980198019803), 24: np.float64(0.6974358974358974), 26: np.float64(0.8430493273542601), 29: np.float64(0.6666666666666666)}
Micro-average F1 score: 0.6373959121877366
Weighted-average F1 score: 0.6181832579988293

F1 score per class: {32: np.float64(0.42105263157894735), 6: np.float64(0.774468085106383), 19: np.float64(0.22535211267605634), 24: np.float64(0.7015706806282722), 26: np.float64(0.8623853211009175), 29: np.float64(0.6441947565543071)}
Micro-average F1 score: 0.6476810414971521
Weighted-average F1 score: 0.6351287123416994
F1 score per class: {32: np.float64(0.47058823529411764), 6: np.float64(0.7419354838709677), 19: np.float64(0.1360544217687075), 24: np.float64(0.6938775510204082), 26: np.float64(0.8430493273542601), 29: np.float64(0.676923076923077)}
Micro-average F1 score: 0.6162876008804109
Weighted-average F1 score: 0.5856966307241186
F1 score per class: {32: np.float64(0.47719298245614034), 6: np.float64(0.736), 19: np.float64(0.19801980198019803), 24: np.float64(0.6974358974358974), 26: np.float64(0.8430493273542601), 29: np.float64(0.6666666666666666)}
Micro-average F1 score: 0.6373959121877366
Weighted-average F1 score: 0.6181832579988293
cur_acc_wo_na:  ['0.7706']
his_acc_wo_na:  ['0.7706']
cur_acc des_wo_na:  ['0.7554']
his_acc des_wo_na:  ['0.7554']
cur_acc rrf_wo_na:  ['0.7746']
his_acc rrf_wo_na:  ['0.7746']
cur_acc_w_na:  ['0.6477']
his_acc_w_na:  ['0.6477']
cur_acc des_w_na:  ['0.6163']
his_acc des_w_na:  ['0.6163']
cur_acc rrf_w_na:  ['0.6374']
his_acc rrf_w_na:  ['0.6374']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 83.3684859CurrentTrain: epoch  0, batch     1 | loss: 94.1998145CurrentTrain: epoch  0, batch     2 | loss: 94.3800121CurrentTrain: epoch  0, batch     3 | loss: 69.7917275CurrentTrain: epoch  1, batch     0 | loss: 136.6283848CurrentTrain: epoch  1, batch     1 | loss: 71.3442807CurrentTrain: epoch  1, batch     2 | loss: 109.4399575CurrentTrain: epoch  1, batch     3 | loss: 63.4078771CurrentTrain: epoch  2, batch     0 | loss: 102.8723102CurrentTrain: epoch  2, batch     1 | loss: 87.6998416CurrentTrain: epoch  2, batch     2 | loss: 84.2068589CurrentTrain: epoch  2, batch     3 | loss: 60.6805527CurrentTrain: epoch  3, batch     0 | loss: 101.8656544CurrentTrain: epoch  3, batch     1 | loss: 68.0609879CurrentTrain: epoch  3, batch     2 | loss: 100.6843213CurrentTrain: epoch  3, batch     3 | loss: 59.9283655CurrentTrain: epoch  4, batch     0 | loss: 95.1210388CurrentTrain: epoch  4, batch     1 | loss: 97.1122161CurrentTrain: epoch  4, batch     2 | loss: 67.5002348CurrentTrain: epoch  4, batch     3 | loss: 79.2351157CurrentTrain: epoch  5, batch     0 | loss: 124.8396841CurrentTrain: epoch  5, batch     1 | loss: 79.5933630CurrentTrain: epoch  5, batch     2 | loss: 68.0326260CurrentTrain: epoch  5, batch     3 | loss: 44.3293725CurrentTrain: epoch  6, batch     0 | loss: 67.9033290CurrentTrain: epoch  6, batch     1 | loss: 66.9694806CurrentTrain: epoch  6, batch     2 | loss: 64.4756033CurrentTrain: epoch  6, batch     3 | loss: 101.4299081CurrentTrain: epoch  7, batch     0 | loss: 118.2012842CurrentTrain: epoch  7, batch     1 | loss: 76.5180415CurrentTrain: epoch  7, batch     2 | loss: 77.3678136CurrentTrain: epoch  7, batch     3 | loss: 46.7628028CurrentTrain: epoch  8, batch     0 | loss: 90.9777468CurrentTrain: epoch  8, batch     1 | loss: 115.7636383CurrentTrain: epoch  8, batch     2 | loss: 93.2296370CurrentTrain: epoch  8, batch     3 | loss: 37.2466888CurrentTrain: epoch  9, batch     0 | loss: 64.0995480CurrentTrain: epoch  9, batch     1 | loss: 63.3842807CurrentTrain: epoch  9, batch     2 | loss: 96.7798271CurrentTrain: epoch  9, batch     3 | loss: 53.4691849
MemoryTrain:  epoch  0, batch     0 | loss: 1.2194843MemoryTrain:  epoch  1, batch     0 | loss: 1.0507648MemoryTrain:  epoch  2, batch     0 | loss: 0.8466802MemoryTrain:  epoch  3, batch     0 | loss: 0.6807446MemoryTrain:  epoch  4, batch     0 | loss: 0.5760271MemoryTrain:  epoch  5, batch     0 | loss: 0.4342467MemoryTrain:  epoch  6, batch     0 | loss: 0.3658804MemoryTrain:  epoch  7, batch     0 | loss: 0.3346886MemoryTrain:  epoch  8, batch     0 | loss: 0.2680698MemoryTrain:  epoch  9, batch     0 | loss: 0.2592783

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.3793103448275862), 36: np.float64(0.0), 6: np.float64(0.7472527472527473), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.8648648648648649), 26: np.float64(0.0), 29: np.float64(0.47058823529411764), 30: np.float64(0.6788990825688074)}
Micro-average F1 score: 0.5525672371638142
Weighted-average F1 score: 0.49723579352307956
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.5333333333333333), 36: np.float64(0.0), 6: np.float64(0.7526881720430108), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.576271186440678), 26: np.float64(0.0), 29: np.float64(0.3076923076923077), 30: np.float64(0.6901408450704225)}
Micro-average F1 score: 0.5420560747663551
Weighted-average F1 score: 0.48115715463171466
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.5833333333333334), 36: np.float64(0.0), 6: np.float64(0.7608695652173914), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.7441860465116279), 26: np.float64(0.0), 29: np.float64(0.3076923076923077), 30: np.float64(0.7121212121212122)}
Micro-average F1 score: 0.582995951417004
Weighted-average F1 score: 0.5138360958552265

F1 score per class: {32: np.float64(0.546448087431694), 33: np.float64(0.29333333333333333), 36: np.float64(0.788135593220339), 6: np.float64(0.723404255319149), 8: np.float64(0.36), 19: np.float64(0.7597765363128491), 20: np.float64(0.9029126213592233), 24: np.float64(0.8648648648648649), 26: np.float64(0.7782805429864253), 29: np.float64(0.4), 30: np.float64(0.6379310344827587)}
Micro-average F1 score: 0.6863270777479893
Weighted-average F1 score: 0.6920658834097153
F1 score per class: {32: np.float64(0.6329113924050633), 33: np.float64(0.418848167539267), 36: np.float64(0.7251908396946565), 6: np.float64(0.7216494845360825), 8: np.float64(0.2631578947368421), 19: np.float64(0.723404255319149), 20: np.float64(0.8857142857142857), 24: np.float64(0.3695652173913043), 26: np.float64(0.775330396475771), 29: np.float64(0.16), 30: np.float64(0.5903614457831325)}
Micro-average F1 score: 0.6391982182628062
Weighted-average F1 score: 0.6192613874365747
F1 score per class: {32: np.float64(0.6146788990825688), 33: np.float64(0.4263959390862944), 36: np.float64(0.7258687258687259), 6: np.float64(0.7291666666666666), 8: np.float64(0.273972602739726), 19: np.float64(0.7431693989071039), 20: np.float64(0.8952380952380953), 24: np.float64(0.6274509803921569), 26: np.float64(0.7857142857142857), 29: np.float64(0.17391304347826086), 30: np.float64(0.6308724832214765)}
Micro-average F1 score: 0.6623681125439624
Weighted-average F1 score: 0.6470389609250657

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.3188405797101449), 36: np.float64(0.0), 6: np.float64(0.5862068965517241), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.8205128205128205), 26: np.float64(0.0), 29: np.float64(0.38095238095238093), 30: np.float64(0.6115702479338843)}
Micro-average F1 score: 0.4321223709369025
Weighted-average F1 score: 0.3711468646774966
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.39800995024875624), 36: np.float64(0.0), 6: np.float64(0.5882352941176471), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.5), 26: np.float64(0.0), 29: np.float64(0.18604651162790697), 30: np.float64(0.5536723163841808)}
Micro-average F1 score: 0.3913630229419703
Weighted-average F1 score: 0.34883843850634294
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.43523316062176165), 36: np.float64(0.0), 6: np.float64(0.5882352941176471), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.6808510638297872), 26: np.float64(0.0), 29: np.float64(0.20512820512820512), 30: np.float64(0.573170731707317)}
Micro-average F1 score: 0.4222873900293255
Weighted-average F1 score: 0.3724158743801003

F1 score per class: {32: np.float64(0.411522633744856), 33: np.float64(0.2233502538071066), 36: np.float64(0.7018867924528301), 6: np.float64(0.5), 8: np.float64(0.1935483870967742), 19: np.float64(0.68), 20: np.float64(0.7914893617021277), 24: np.float64(0.8205128205128205), 26: np.float64(0.5951557093425606), 29: np.float64(0.26666666666666666), 30: np.float64(0.556390977443609)}
Micro-average F1 score: 0.5505376344086022
Weighted-average F1 score: 0.5420111857023312
F1 score per class: {32: np.float64(0.42857142857142855), 33: np.float64(0.27491408934707906), 36: np.float64(0.6312292358803987), 6: np.float64(0.49645390070921985), 8: np.float64(0.14492753623188406), 19: np.float64(0.6325581395348837), 20: np.float64(0.7530364372469636), 24: np.float64(0.27419354838709675), 26: np.float64(0.5732899022801303), 29: np.float64(0.10526315789473684), 30: np.float64(0.4688995215311005)}
Micro-average F1 score: 0.4785327219674865
Weighted-average F1 score: 0.4588674530568392
F1 score per class: {32: np.float64(0.43086816720257237), 33: np.float64(0.28187919463087246), 36: np.float64(0.6287625418060201), 6: np.float64(0.5035971223021583), 8: np.float64(0.14705882352941177), 19: np.float64(0.6507177033492823), 20: np.float64(0.7704918032786885), 24: np.float64(0.5333333333333333), 26: np.float64(0.5886287625418061), 29: np.float64(0.12121212121212122), 30: np.float64(0.5026737967914439)}
Micro-average F1 score: 0.5026690391459074
Weighted-average F1 score: 0.4841470625312305
cur_acc_wo_na:  ['0.7706', '0.5526']
his_acc_wo_na:  ['0.7706', '0.6863']
cur_acc des_wo_na:  ['0.7554', '0.5421']
his_acc des_wo_na:  ['0.7554', '0.6392']
cur_acc rrf_wo_na:  ['0.7746', '0.5830']
his_acc rrf_wo_na:  ['0.7746', '0.6624']
cur_acc_w_na:  ['0.6477', '0.4321']
his_acc_w_na:  ['0.6477', '0.5505']
cur_acc des_w_na:  ['0.6163', '0.3914']
his_acc des_w_na:  ['0.6163', '0.4785']
cur_acc rrf_w_na:  ['0.6374', '0.4223']
his_acc rrf_w_na:  ['0.6374', '0.5027']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 103.4792186CurrentTrain: epoch  0, batch     1 | loss: 96.7001443CurrentTrain: epoch  0, batch     2 | loss: 90.8717062CurrentTrain: epoch  0, batch     3 | loss: 116.2213919CurrentTrain: epoch  0, batch     4 | loss: 21.4641500CurrentTrain: epoch  1, batch     0 | loss: 108.1916359CurrentTrain: epoch  1, batch     1 | loss: 73.7801160CurrentTrain: epoch  1, batch     2 | loss: 90.5096722CurrentTrain: epoch  1, batch     3 | loss: 85.1008012CurrentTrain: epoch  1, batch     4 | loss: 22.0378071CurrentTrain: epoch  2, batch     0 | loss: 85.8544868CurrentTrain: epoch  2, batch     1 | loss: 87.5249674CurrentTrain: epoch  2, batch     2 | loss: 82.6732996CurrentTrain: epoch  2, batch     3 | loss: 125.1406147CurrentTrain: epoch  2, batch     4 | loss: 43.7850940CurrentTrain: epoch  3, batch     0 | loss: 71.1247431CurrentTrain: epoch  3, batch     1 | loss: 68.4741208CurrentTrain: epoch  3, batch     2 | loss: 100.2411889CurrentTrain: epoch  3, batch     3 | loss: 100.0442846CurrentTrain: epoch  3, batch     4 | loss: 17.4277651CurrentTrain: epoch  4, batch     0 | loss: 85.7306147CurrentTrain: epoch  4, batch     1 | loss: 98.1989854CurrentTrain: epoch  4, batch     2 | loss: 80.3837768CurrentTrain: epoch  4, batch     3 | loss: 76.7081555CurrentTrain: epoch  4, batch     4 | loss: 23.4485714CurrentTrain: epoch  5, batch     0 | loss: 66.9791759CurrentTrain: epoch  5, batch     1 | loss: 96.5038945CurrentTrain: epoch  5, batch     2 | loss: 84.4511082CurrentTrain: epoch  5, batch     3 | loss: 69.6817352CurrentTrain: epoch  5, batch     4 | loss: 12.2338377CurrentTrain: epoch  6, batch     0 | loss: 94.5723157CurrentTrain: epoch  6, batch     1 | loss: 61.4749340CurrentTrain: epoch  6, batch     2 | loss: 79.3705090CurrentTrain: epoch  6, batch     3 | loss: 123.6784657CurrentTrain: epoch  6, batch     4 | loss: 24.3434748CurrentTrain: epoch  7, batch     0 | loss: 120.1924131CurrentTrain: epoch  7, batch     1 | loss: 122.7219737CurrentTrain: epoch  7, batch     2 | loss: 63.8702461CurrentTrain: epoch  7, batch     3 | loss: 65.1728439CurrentTrain: epoch  7, batch     4 | loss: 17.9571863CurrentTrain: epoch  8, batch     0 | loss: 75.4418681CurrentTrain: epoch  8, batch     1 | loss: 120.8768326CurrentTrain: epoch  8, batch     2 | loss: 62.4727612CurrentTrain: epoch  8, batch     3 | loss: 95.3191206CurrentTrain: epoch  8, batch     4 | loss: 23.4503258CurrentTrain: epoch  9, batch     0 | loss: 66.1852871CurrentTrain: epoch  9, batch     1 | loss: 118.6691604CurrentTrain: epoch  9, batch     2 | loss: 95.0371444CurrentTrain: epoch  9, batch     3 | loss: 76.6312623CurrentTrain: epoch  9, batch     4 | loss: 8.5844866
MemoryTrain:  epoch  0, batch     0 | loss: 1.2195147MemoryTrain:  epoch  1, batch     0 | loss: 1.1190390MemoryTrain:  epoch  2, batch     0 | loss: 0.9210381MemoryTrain:  epoch  3, batch     0 | loss: 0.6727457MemoryTrain:  epoch  4, batch     0 | loss: 0.5813513MemoryTrain:  epoch  5, batch     0 | loss: 0.5550367MemoryTrain:  epoch  6, batch     0 | loss: 0.4750723MemoryTrain:  epoch  7, batch     0 | loss: 0.4335001MemoryTrain:  epoch  8, batch     0 | loss: 0.4117190MemoryTrain:  epoch  9, batch     0 | loss: 0.3684932

F1 score per class: {32: np.float64(0.5833333333333334), 33: np.float64(0.0), 2: np.float64(0.0), 6: np.float64(0.6111111111111112), 39: np.float64(0.525), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.37037037037037035), 20: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.5454545454545454)}
Micro-average F1 score: 0.52
Weighted-average F1 score: 0.47443588741931286
F1 score per class: {32: np.float64(0.5185185185185185), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.5588235294117647), 6: np.float64(0.47619047619047616), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.32), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.5454545454545454)}
Micro-average F1 score: 0.3869653767820774
Weighted-average F1 score: 0.2880200422414955
F1 score per class: {32: np.float64(0.5384615384615384), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.5588235294117647), 6: np.float64(0.47904191616766467), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.27586206896551724), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.48)}
Micro-average F1 score: 0.41575492341356673
Weighted-average F1 score: 0.3325474260383204

F1 score per class: {32: np.float64(0.5), 33: np.float64(0.5380116959064327), 2: np.float64(0.22018348623853212), 36: np.float64(0.4467005076142132), 6: np.float64(0.358974358974359), 39: np.float64(0.822429906542056), 8: np.float64(0.6593406593406593), 11: np.float64(0.36363636363636365), 12: np.float64(0.7272727272727273), 19: np.float64(0.0970873786407767), 20: np.float64(0.8481675392670157), 24: np.float64(0.8648648648648649), 26: np.float64(0.7426160337552743), 28: np.float64(0.26666666666666666), 29: np.float64(0.4044943820224719), 30: np.float64(0.2857142857142857)}
Micro-average F1 score: 0.5631951466127402
Weighted-average F1 score: 0.5501181412025904
F1 score per class: {32: np.float64(0.358974358974359), 33: np.float64(0.6431718061674009), 2: np.float64(0.359375), 36: np.float64(0.46060606060606063), 6: np.float64(0.2702702702702703), 39: np.float64(0.7428571428571429), 8: np.float64(0.6185567010309279), 11: np.float64(0.25), 12: np.float64(0.7513812154696132), 19: np.float64(0.16666666666666666), 20: np.float64(0.8), 24: np.float64(0.3695652173913043), 26: np.float64(0.717741935483871), 28: np.float64(0.2962962962962963), 29: np.float64(0.5826771653543307), 30: np.float64(0.2926829268292683)}
Micro-average F1 score: 0.5390858607432721
Weighted-average F1 score: 0.5131199111022393
F1 score per class: {32: np.float64(0.4), 33: np.float64(0.625), 2: np.float64(0.4111111111111111), 36: np.float64(0.4393063583815029), 6: np.float64(0.27491408934707906), 39: np.float64(0.7647058823529411), 8: np.float64(0.6185567010309279), 11: np.float64(0.26865671641791045), 12: np.float64(0.7415730337078652), 19: np.float64(0.11267605633802817), 20: np.float64(0.8), 24: np.float64(0.6666666666666666), 26: np.float64(0.7035573122529645), 28: np.float64(0.2727272727272727), 29: np.float64(0.584070796460177), 30: np.float64(0.24)}
Micro-average F1 score: 0.5500679655641142
Weighted-average F1 score: 0.5252230655862855

F1 score per class: {32: np.float64(0.358974358974359), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.5207100591715976), 6: np.float64(0.45652173913043476), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.16129032258064516), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.36363636363636365)}
Micro-average F1 score: 0.3788706739526412
Weighted-average F1 score: 0.32397981811373466
F1 score per class: {32: np.float64(0.32558139534883723), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.4662576687116564), 6: np.float64(0.38095238095238093), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.16666666666666666), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.36363636363636365)}
Micro-average F1 score: 0.2631578947368421
Weighted-average F1 score: 0.20182825462376575
F1 score per class: {32: np.float64(0.3333333333333333), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.4523809523809524), 6: np.float64(0.3883495145631068), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.13114754098360656), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.2727272727272727)}
Micro-average F1 score: 0.2878787878787879
Weighted-average F1 score: 0.2346670353471992

F1 score per class: {32: np.float64(0.28), 33: np.float64(0.36947791164658633), 2: np.float64(0.192), 36: np.float64(0.36363636363636365), 6: np.float64(0.22826086956521738), 39: np.float64(0.7652173913043478), 8: np.float64(0.45454545454545453), 11: np.float64(0.21333333333333335), 12: np.float64(0.6564102564102564), 19: np.float64(0.0546448087431694), 20: np.float64(0.7605633802816901), 24: np.float64(0.8205128205128205), 26: np.float64(0.5365853658536586), 28: np.float64(0.25), 29: np.float64(0.3564356435643564), 30: np.float64(0.16)}
Micro-average F1 score: 0.4250286150324304
Weighted-average F1 score: 0.39888044368628756
F1 score per class: {32: np.float64(0.21212121212121213), 33: np.float64(0.40782122905027934), 2: np.float64(0.22604422604422605), 36: np.float64(0.36018957345971564), 6: np.float64(0.16597510373443983), 39: np.float64(0.6691176470588235), 8: np.float64(0.4166666666666667), 11: np.float64(0.15254237288135594), 12: np.float64(0.6699507389162561), 19: np.float64(0.08421052631578947), 20: np.float64(0.7346938775510204), 24: np.float64(0.2595419847328244), 26: np.float64(0.5281899109792285), 28: np.float64(0.21621621621621623), 29: np.float64(0.48366013071895425), 30: np.float64(0.1348314606741573)}
Micro-average F1 score: 0.38254016368596544
Weighted-average F1 score: 0.3541276111112334
F1 score per class: {32: np.float64(0.2413793103448276), 33: np.float64(0.4126984126984127), 2: np.float64(0.3045267489711934), 36: np.float64(0.33480176211453744), 6: np.float64(0.16806722689075632), 39: np.float64(0.6946564885496184), 8: np.float64(0.4195804195804196), 11: np.float64(0.1592920353982301), 12: np.float64(0.6666666666666666), 19: np.float64(0.05555555555555555), 20: np.float64(0.7346938775510204), 24: np.float64(0.6071428571428571), 26: np.float64(0.5144508670520231), 28: np.float64(0.21428571428571427), 29: np.float64(0.4925373134328358), 30: np.float64(0.11009174311926606)}
Micro-average F1 score: 0.39829396325459315
Weighted-average F1 score: 0.3676270973852171
cur_acc_wo_na:  ['0.7706', '0.5526', '0.5200']
his_acc_wo_na:  ['0.7706', '0.6863', '0.5632']
cur_acc des_wo_na:  ['0.7554', '0.5421', '0.3870']
his_acc des_wo_na:  ['0.7554', '0.6392', '0.5391']
cur_acc rrf_wo_na:  ['0.7746', '0.5830', '0.4158']
his_acc rrf_wo_na:  ['0.7746', '0.6624', '0.5501']
cur_acc_w_na:  ['0.6477', '0.4321', '0.3789']
his_acc_w_na:  ['0.6477', '0.5505', '0.4250']
cur_acc des_w_na:  ['0.6163', '0.3914', '0.2632']
his_acc des_w_na:  ['0.6163', '0.4785', '0.3825']
cur_acc rrf_w_na:  ['0.6374', '0.4223', '0.2879']
his_acc rrf_w_na:  ['0.6374', '0.5027', '0.3983']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 87.6023031CurrentTrain: epoch  0, batch     1 | loss: 113.6670815CurrentTrain: epoch  0, batch     2 | loss: 117.9174360CurrentTrain: epoch  0, batch     3 | loss: 140.9165418CurrentTrain: epoch  0, batch     4 | loss: 87.8131006CurrentTrain: epoch  1, batch     0 | loss: 85.9470224CurrentTrain: epoch  1, batch     1 | loss: 93.6778955CurrentTrain: epoch  1, batch     2 | loss: 102.5141458CurrentTrain: epoch  1, batch     3 | loss: 133.2028178CurrentTrain: epoch  1, batch     4 | loss: 67.1059280CurrentTrain: epoch  2, batch     0 | loss: 85.5086500CurrentTrain: epoch  2, batch     1 | loss: 105.5350329CurrentTrain: epoch  2, batch     2 | loss: 85.1976740CurrentTrain: epoch  2, batch     3 | loss: 103.8662960CurrentTrain: epoch  2, batch     4 | loss: 84.6419107CurrentTrain: epoch  3, batch     0 | loss: 72.4020083CurrentTrain: epoch  3, batch     1 | loss: 83.6061493CurrentTrain: epoch  3, batch     2 | loss: 105.0609485CurrentTrain: epoch  3, batch     3 | loss: 84.9043110CurrentTrain: epoch  3, batch     4 | loss: 54.3237993CurrentTrain: epoch  4, batch     0 | loss: 100.1805714CurrentTrain: epoch  4, batch     1 | loss: 98.5447763CurrentTrain: epoch  4, batch     2 | loss: 71.0488712CurrentTrain: epoch  4, batch     3 | loss: 84.3440836CurrentTrain: epoch  4, batch     4 | loss: 64.6016062CurrentTrain: epoch  5, batch     0 | loss: 126.8634878CurrentTrain: epoch  5, batch     1 | loss: 81.6314088CurrentTrain: epoch  5, batch     2 | loss: 81.7477260CurrentTrain: epoch  5, batch     3 | loss: 99.2145615CurrentTrain: epoch  5, batch     4 | loss: 50.6486462CurrentTrain: epoch  6, batch     0 | loss: 77.5777547CurrentTrain: epoch  6, batch     1 | loss: 99.3860899CurrentTrain: epoch  6, batch     2 | loss: 96.8155583CurrentTrain: epoch  6, batch     3 | loss: 77.9181142CurrentTrain: epoch  6, batch     4 | loss: 104.7923121CurrentTrain: epoch  7, batch     0 | loss: 63.2483447CurrentTrain: epoch  7, batch     1 | loss: 98.8477761CurrentTrain: epoch  7, batch     2 | loss: 93.4979353CurrentTrain: epoch  7, batch     3 | loss: 97.8669129CurrentTrain: epoch  7, batch     4 | loss: 107.0680831CurrentTrain: epoch  8, batch     0 | loss: 62.3549511CurrentTrain: epoch  8, batch     1 | loss: 98.8896685CurrentTrain: epoch  8, batch     2 | loss: 66.4160604CurrentTrain: epoch  8, batch     3 | loss: 124.2457191CurrentTrain: epoch  8, batch     4 | loss: 76.1500738CurrentTrain: epoch  9, batch     0 | loss: 76.6585681CurrentTrain: epoch  9, batch     1 | loss: 78.3776494CurrentTrain: epoch  9, batch     2 | loss: 78.4815867CurrentTrain: epoch  9, batch     3 | loss: 119.7158754CurrentTrain: epoch  9, batch     4 | loss: 48.0521958
MemoryTrain:  epoch  0, batch     0 | loss: 1.1702997MemoryTrain:  epoch  1, batch     0 | loss: 1.0924278MemoryTrain:  epoch  2, batch     0 | loss: 0.8048866MemoryTrain:  epoch  3, batch     0 | loss: 0.6395566MemoryTrain:  epoch  4, batch     0 | loss: 0.5400434MemoryTrain:  epoch  5, batch     0 | loss: 0.5165918MemoryTrain:  epoch  6, batch     0 | loss: 0.4846058MemoryTrain:  epoch  7, batch     0 | loss: 0.4067295MemoryTrain:  epoch  8, batch     0 | loss: 0.3290514MemoryTrain:  epoch  9, batch     0 | loss: 0.2614038

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.8362068965517241), 2: np.float64(0.0), 5: np.float64(0.45714285714285713), 6: np.float64(0.0), 39: np.float64(0.0), 10: np.float64(0.6538461538461539), 11: np.float64(0.36363636363636365), 12: np.float64(0.09302325581395349), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.546448087431694
Weighted-average F1 score: 0.5286998251916253
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.7348484848484849), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.54421768707483), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.6567164179104478), 17: np.float64(0.6153846153846154), 18: np.float64(0.46875), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5385779122541604
Weighted-average F1 score: 0.4818433213815416
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.7509578544061303), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.543046357615894), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.7096774193548387), 17: np.float64(0.6153846153846154), 18: np.float64(0.2), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5345911949685535
Weighted-average F1 score: 0.4899188741074746

F1 score per class: {2: np.float64(0.4444444444444444), 5: np.float64(0.7320754716981132), 6: np.float64(0.40993788819875776), 8: np.float64(0.06896551724137931), 10: np.float64(0.28699551569506726), 11: np.float64(0.23255813953488372), 12: np.float64(0.3121951219512195), 16: np.float64(0.5862068965517241), 17: np.float64(0.23529411764705882), 18: np.float64(0.05714285714285714), 19: np.float64(0.8133971291866029), 20: np.float64(0.5121951219512195), 24: np.float64(0.42105263157894735), 26: np.float64(0.7052631578947368), 28: np.float64(0.08247422680412371), 29: np.float64(0.782608695652174), 30: np.float64(0.8421052631578947), 32: np.float64(0.7489361702127659), 33: np.float64(0.25), 36: np.float64(0.18421052631578946), 39: np.float64(0.23255813953488372)}
Micro-average F1 score: 0.49659045326915363
Weighted-average F1 score: 0.5099508692131492
F1 score per class: {2: np.float64(0.4666666666666667), 5: np.float64(0.6081504702194357), 6: np.float64(0.5551020408163265), 8: np.float64(0.36231884057971014), 10: np.float64(0.3902439024390244), 11: np.float64(0.2857142857142857), 12: np.float64(0.2968197879858657), 16: np.float64(0.5569620253164557), 17: np.float64(0.24242424242424243), 18: np.float64(0.2564102564102564), 19: np.float64(0.7389558232931727), 20: np.float64(0.5454545454545454), 24: np.float64(0.29508196721311475), 26: np.float64(0.694300518134715), 28: np.float64(0.14814814814814814), 29: np.float64(0.8064516129032258), 30: np.float64(0.35789473684210527), 32: np.float64(0.7007874015748031), 33: np.float64(0.17142857142857143), 36: np.float64(0.5378151260504201), 39: np.float64(0.20408163265306123)}
Micro-average F1 score: 0.5085085085085085
Weighted-average F1 score: 0.49906471254608475
F1 score per class: {2: np.float64(0.4666666666666667), 5: np.float64(0.6182965299684543), 6: np.float64(0.5685279187817259), 8: np.float64(0.18867924528301888), 10: np.float64(0.3445378151260504), 11: np.float64(0.2872340425531915), 12: np.float64(0.3076923076923077), 16: np.float64(0.6197183098591549), 17: np.float64(0.2962962962962963), 18: np.float64(0.1111111111111111), 19: np.float64(0.7419354838709677), 20: np.float64(0.5494505494505495), 24: np.float64(0.32142857142857145), 26: np.float64(0.7015706806282722), 28: np.float64(0.10256410256410256), 29: np.float64(0.8), 30: np.float64(0.6938775510204082), 32: np.float64(0.6976744186046512), 33: np.float64(0.2222222222222222), 36: np.float64(0.47058823529411764), 39: np.float64(0.20833333333333334)}
Micro-average F1 score: 0.504025201260063
Weighted-average F1 score: 0.4996697941476329

F1 score per class: {2: np.float64(0.0), 5: np.float64(0.6217948717948718), 6: np.float64(0.0), 10: np.float64(0.367816091954023), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.39080459770114945), 17: np.float64(0.3076923076923077), 18: np.float64(0.0851063829787234), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.3588516746411483
Weighted-average F1 score: 0.32749392634755803
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.5623188405797102), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.4519774011299435), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.41509433962264153), 17: np.float64(0.47058823529411764), 18: np.float64(0.297029702970297), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.34563106796116505
Weighted-average F1 score: 0.3009179741549169
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.5747800586510264), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.42487046632124353), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.43137254901960786), 17: np.float64(0.47058823529411764), 18: np.float64(0.15873015873015872), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.3476482617586912
Weighted-average F1 score: 0.3090960983497462

F1 score per class: {2: np.float64(0.27906976744186046), 5: np.float64(0.45754716981132076), 6: np.float64(0.2661290322580645), 8: np.float64(0.06593406593406594), 10: np.float64(0.20382165605095542), 11: np.float64(0.17543859649122806), 12: np.float64(0.1871345029239766), 16: np.float64(0.3300970873786408), 17: np.float64(0.13333333333333333), 18: np.float64(0.041237113402061855), 19: np.float64(0.7456140350877193), 20: np.float64(0.358974358974359), 24: np.float64(0.25), 26: np.float64(0.6350710900473934), 28: np.float64(0.0425531914893617), 29: np.float64(0.6857142857142857), 30: np.float64(0.8), 32: np.float64(0.544891640866873), 33: np.float64(0.2222222222222222), 36: np.float64(0.16666666666666666), 39: np.float64(0.11494252873563218)}
Micro-average F1 score: 0.35472779369627505
Weighted-average F1 score: 0.34506206963694025
F1 score per class: {2: np.float64(0.2692307692307692), 5: np.float64(0.40501043841336115), 6: np.float64(0.317016317016317), 8: np.float64(0.29069767441860467), 10: np.float64(0.27303754266211605), 11: np.float64(0.25287356321839083), 12: np.float64(0.17573221757322174), 16: np.float64(0.3235294117647059), 17: np.float64(0.14035087719298245), 18: np.float64(0.14634146341463414), 19: np.float64(0.6456140350877193), 20: np.float64(0.35294117647058826), 24: np.float64(0.17475728155339806), 26: np.float64(0.5851528384279476), 28: np.float64(0.08163265306122448), 29: np.float64(0.6944444444444444), 30: np.float64(0.2595419847328244), 32: np.float64(0.5174418604651163), 33: np.float64(0.13333333333333333), 36: np.float64(0.4), 39: np.float64(0.10638297872340426)}
Micro-average F1 score: 0.3517193630279252
Weighted-average F1 score: 0.33697120497966115
F1 score per class: {2: np.float64(0.27450980392156865), 5: np.float64(0.41350210970464135), 6: np.float64(0.34146341463414637), 8: np.float64(0.16666666666666666), 10: np.float64(0.23631123919308358), 11: np.float64(0.225), 12: np.float64(0.18181818181818182), 16: np.float64(0.3464566929133858), 17: np.float64(0.16326530612244897), 18: np.float64(0.072992700729927), 19: np.float64(0.6666666666666666), 20: np.float64(0.352112676056338), 24: np.float64(0.1836734693877551), 26: np.float64(0.6175115207373272), 28: np.float64(0.0547945205479452), 29: np.float64(0.6915887850467289), 30: np.float64(0.6296296296296297), 32: np.float64(0.5084745762711864), 33: np.float64(0.1875), 36: np.float64(0.3902439024390244), 39: np.float64(0.10752688172043011)}
Micro-average F1 score: 0.35450516986706054
Weighted-average F1 score: 0.3406268431155319
cur_acc_wo_na:  ['0.7706', '0.5526', '0.5200', '0.5464']
his_acc_wo_na:  ['0.7706', '0.6863', '0.5632', '0.4966']
cur_acc des_wo_na:  ['0.7554', '0.5421', '0.3870', '0.5386']
his_acc des_wo_na:  ['0.7554', '0.6392', '0.5391', '0.5085']
cur_acc rrf_wo_na:  ['0.7746', '0.5830', '0.4158', '0.5346']
his_acc rrf_wo_na:  ['0.7746', '0.6624', '0.5501', '0.5040']
cur_acc_w_na:  ['0.6477', '0.4321', '0.3789', '0.3589']
his_acc_w_na:  ['0.6477', '0.5505', '0.4250', '0.3547']
cur_acc des_w_na:  ['0.6163', '0.3914', '0.2632', '0.3456']
his_acc des_w_na:  ['0.6163', '0.4785', '0.3825', '0.3517']
cur_acc rrf_w_na:  ['0.6374', '0.4223', '0.2879', '0.3476']
his_acc rrf_w_na:  ['0.6374', '0.5027', '0.3983', '0.3545']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 89.4618404CurrentTrain: epoch  0, batch     1 | loss: 102.1924054CurrentTrain: epoch  0, batch     2 | loss: 84.3609751CurrentTrain: epoch  0, batch     3 | loss: 144.1927569CurrentTrain: epoch  0, batch     4 | loss: 69.6583731CurrentTrain: epoch  1, batch     0 | loss: 81.9897897CurrentTrain: epoch  1, batch     1 | loss: 105.2361968CurrentTrain: epoch  1, batch     2 | loss: 178.8172806CurrentTrain: epoch  1, batch     3 | loss: 95.1886716CurrentTrain: epoch  1, batch     4 | loss: 60.3486419CurrentTrain: epoch  2, batch     0 | loss: 88.5576755CurrentTrain: epoch  2, batch     1 | loss: 90.1199563CurrentTrain: epoch  2, batch     2 | loss: 87.5082161CurrentTrain: epoch  2, batch     3 | loss: 104.7077821CurrentTrain: epoch  2, batch     4 | loss: 76.6185293CurrentTrain: epoch  3, batch     0 | loss: 68.4318951CurrentTrain: epoch  3, batch     1 | loss: 71.5376434CurrentTrain: epoch  3, batch     2 | loss: 88.2292135CurrentTrain: epoch  3, batch     3 | loss: 86.9977207CurrentTrain: epoch  3, batch     4 | loss: 147.1878892CurrentTrain: epoch  4, batch     0 | loss: 81.8839292CurrentTrain: epoch  4, batch     1 | loss: 85.0130906CurrentTrain: epoch  4, batch     2 | loss: 84.0931960CurrentTrain: epoch  4, batch     3 | loss: 83.1751633CurrentTrain: epoch  4, batch     4 | loss: 69.9402540CurrentTrain: epoch  5, batch     0 | loss: 84.2708007CurrentTrain: epoch  5, batch     1 | loss: 126.6342925CurrentTrain: epoch  5, batch     2 | loss: 98.4429868CurrentTrain: epoch  5, batch     3 | loss: 66.7643474CurrentTrain: epoch  5, batch     4 | loss: 48.4391290CurrentTrain: epoch  6, batch     0 | loss: 79.5879089CurrentTrain: epoch  6, batch     1 | loss: 82.0974973CurrentTrain: epoch  6, batch     2 | loss: 68.1521756CurrentTrain: epoch  6, batch     3 | loss: 81.2201929CurrentTrain: epoch  6, batch     4 | loss: 54.5352852CurrentTrain: epoch  7, batch     0 | loss: 77.8746970CurrentTrain: epoch  7, batch     1 | loss: 79.8205937CurrentTrain: epoch  7, batch     2 | loss: 81.7491821CurrentTrain: epoch  7, batch     3 | loss: 68.9215014CurrentTrain: epoch  7, batch     4 | loss: 68.4499108CurrentTrain: epoch  8, batch     0 | loss: 93.5010954CurrentTrain: epoch  8, batch     1 | loss: 123.5927546CurrentTrain: epoch  8, batch     2 | loss: 120.0934998CurrentTrain: epoch  8, batch     3 | loss: 65.6062653CurrentTrain: epoch  8, batch     4 | loss: 50.5518561CurrentTrain: epoch  9, batch     0 | loss: 66.9868875CurrentTrain: epoch  9, batch     1 | loss: 81.4490554CurrentTrain: epoch  9, batch     2 | loss: 75.9360831CurrentTrain: epoch  9, batch     3 | loss: 94.5516586CurrentTrain: epoch  9, batch     4 | loss: 68.9765238
MemoryTrain:  epoch  0, batch     0 | loss: 1.1988947MemoryTrain:  epoch  1, batch     0 | loss: 1.0897788MemoryTrain:  epoch  2, batch     0 | loss: 0.8720415MemoryTrain:  epoch  3, batch     0 | loss: 0.7996925MemoryTrain:  epoch  4, batch     0 | loss: 0.5559658MemoryTrain:  epoch  5, batch     0 | loss: 0.4736719MemoryTrain:  epoch  6, batch     0 | loss: 0.3930397MemoryTrain:  epoch  7, batch     0 | loss: 0.3509352MemoryTrain:  epoch  8, batch     0 | loss: 0.2940881MemoryTrain:  epoch  9, batch     0 | loss: 0.2606017

F1 score per class: {1: np.float64(0.24489795918367346), 3: np.float64(0.6936416184971098), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.047619047619047616), 18: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.47058823529411764), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6666666666666666), 39: np.float64(0.0)}
Micro-average F1 score: 0.4024024024024024
Weighted-average F1 score: 0.3775426919675244
F1 score per class: {1: np.float64(0.2360248447204969), 3: np.float64(0.6605504587155964), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.08163265306122448), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.48148148148148145), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6527777777777778)}
Micro-average F1 score: 0.3760217983651226
Weighted-average F1 score: 0.3434533229576483
F1 score per class: {1: np.float64(0.24324324324324326), 3: np.float64(0.68), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.05825242718446602), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.47719298245614034), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6524822695035462), 39: np.float64(0.0)}
Micro-average F1 score: 0.3808630393996248
Weighted-average F1 score: 0.3489900743340959

F1 score per class: {1: np.float64(0.21301775147928995), 2: np.float64(0.45454545454545453), 3: np.float64(0.5429864253393665), 5: np.float64(0.8370044052863436), 6: np.float64(0.4550898203592814), 8: np.float64(0.06818181818181818), 10: np.float64(0.31386861313868614), 11: np.float64(0.07936507936507936), 12: np.float64(0.23333333333333334), 14: np.float64(0.03125), 16: np.float64(0.576271186440678), 17: np.float64(0.125), 18: np.float64(0.03333333333333333), 19: np.float64(0.6751054852320675), 20: np.float64(0.5063291139240507), 22: np.float64(0.36199095022624433), 24: np.float64(0.0), 26: np.float64(0.7311827956989247), 28: np.float64(0.11627906976744186), 29: np.float64(0.7684210526315789), 30: np.float64(0.8571428571428571), 32: np.float64(0.6153846153846154), 33: np.float64(0.0), 34: np.float64(0.20246913580246914), 36: np.float64(0.23076923076923078), 39: np.float64(0.26666666666666666)}
Micro-average F1 score: 0.41162608012568735
Weighted-average F1 score: 0.4059699232189371
F1 score per class: {1: np.float64(0.19689119170984457), 2: np.float64(0.4666666666666667), 3: np.float64(0.48), 5: np.float64(0.7153284671532847), 6: np.float64(0.5338983050847458), 8: np.float64(0.3333333333333333), 10: np.float64(0.36947791164658633), 11: np.float64(0.06504065040650407), 12: np.float64(0.2938775510204082), 14: np.float64(0.05405405405405406), 16: np.float64(0.5333333333333333), 17: np.float64(0.26666666666666666), 18: np.float64(0.03508771929824561), 19: np.float64(0.6101694915254238), 20: np.float64(0.5121951219512195), 22: np.float64(0.3951367781155015), 24: np.float64(0.10526315789473684), 26: np.float64(0.7046632124352331), 28: np.float64(0.11594202898550725), 29: np.float64(0.776595744680851), 30: np.float64(0.7083333333333334), 32: np.float64(0.5442622950819672), 33: np.float64(0.20689655172413793), 34: np.float64(0.17702448210922786), 36: np.float64(0.5714285714285714), 39: np.float64(0.1702127659574468)}
Micro-average F1 score: 0.41594136509390744
Weighted-average F1 score: 0.402164095600524
F1 score per class: {1: np.float64(0.2057142857142857), 2: np.float64(0.48), 3: np.float64(0.49635036496350365), 5: np.float64(0.7424242424242424), 6: np.float64(0.5204081632653061), 8: np.float64(0.12903225806451613), 10: np.float64(0.34507042253521125), 11: np.float64(0.06153846153846154), 12: np.float64(0.2905982905982906), 14: np.float64(0.0379746835443038), 16: np.float64(0.547945205479452), 17: np.float64(0.3333333333333333), 18: np.float64(0.03278688524590164), 19: np.float64(0.6171003717472119), 20: np.float64(0.5060240963855421), 22: np.float64(0.3788300835654596), 24: np.float64(0.07407407407407407), 26: np.float64(0.7195767195767195), 28: np.float64(0.12048192771084337), 29: np.float64(0.7807486631016043), 30: np.float64(0.8648648648648649), 32: np.float64(0.564625850340136), 33: np.float64(0.16666666666666666), 34: np.float64(0.1694290976058932), 36: np.float64(0.4375), 39: np.float64(0.24489795918367346)}
Micro-average F1 score: 0.40415977310328527
Weighted-average F1 score: 0.39016877248366344

F1 score per class: {1: np.float64(0.13584905660377358), 2: np.float64(0.0), 3: np.float64(0.5429864253393665), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.046511627906976744), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.3463203463203463), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.5222929936305732), 39: np.float64(0.0)}
Micro-average F1 score: 0.2776243093922652
Weighted-average F1 score: 0.2581501216467486
F1 score per class: {1: np.float64(0.13380281690140844), 2: np.float64(0.0), 3: np.float64(0.46153846153846156), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0761904761904762), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.35911602209944754), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.4723618090452261), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.25075711689884916
Weighted-average F1 score: 0.232149243867693
F1 score per class: {1: np.float64(0.13533834586466165), 2: np.float64(0.0), 3: np.float64(0.4857142857142857), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.05555555555555555), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.35324675324675325), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.467005076142132), 39: np.float64(0.0)}
Micro-average F1 score: 0.25566750629722923
Weighted-average F1 score: 0.23755995373208547

F1 score per class: {1: np.float64(0.1111111111111111), 2: np.float64(0.25), 3: np.float64(0.345821325648415), 5: np.float64(0.5956112852664577), 6: np.float64(0.2846441947565543), 8: np.float64(0.06521739130434782), 10: np.float64(0.215), 11: np.float64(0.07462686567164178), 12: np.float64(0.14736842105263157), 14: np.float64(0.028169014084507043), 16: np.float64(0.34), 17: np.float64(0.09090909090909091), 18: np.float64(0.024390243902439025), 19: np.float64(0.5925925925925926), 20: np.float64(0.37735849056603776), 22: np.float64(0.2543720190779014), 24: np.float64(0.0), 26: np.float64(0.6507177033492823), 28: np.float64(0.06060606060606061), 29: np.float64(0.6517857142857143), 30: np.float64(0.8108108108108109), 32: np.float64(0.45325779036827196), 33: np.float64(0.0), 34: np.float64(0.11884057971014493), 36: np.float64(0.1935483870967742), 39: np.float64(0.12903225806451613)}
Micro-average F1 score: 0.28749085588880763
Weighted-average F1 score: 0.2754618470281536
F1 score per class: {1: np.float64(0.10526315789473684), 2: np.float64(0.25925925925925924), 3: np.float64(0.2857142857142857), 5: np.float64(0.4803921568627451), 6: np.float64(0.30288461538461536), 8: np.float64(0.2709677419354839), 10: np.float64(0.2541436464088398), 11: np.float64(0.058823529411764705), 12: np.float64(0.16783216783216784), 14: np.float64(0.046511627906976744), 16: np.float64(0.31007751937984496), 17: np.float64(0.15384615384615385), 18: np.float64(0.023529411764705882), 19: np.float64(0.5202312138728323), 20: np.float64(0.3853211009174312), 22: np.float64(0.2765957446808511), 24: np.float64(0.0851063829787234), 26: np.float64(0.5964912280701754), 28: np.float64(0.064), 29: np.float64(0.6547085201793722), 30: np.float64(0.6415094339622641), 32: np.float64(0.3824884792626728), 33: np.float64(0.13043478260869565), 34: np.float64(0.10456062291434928), 36: np.float64(0.3891891891891892), 39: np.float64(0.08791208791208792)}
Micro-average F1 score: 0.27857033287314004
Weighted-average F1 score: 0.26588013484267453
F1 score per class: {1: np.float64(0.10778443113772455), 2: np.float64(0.2608695652173913), 3: np.float64(0.2975929978118162), 5: np.float64(0.49), 6: np.float64(0.31097560975609756), 8: np.float64(0.11428571428571428), 10: np.float64(0.23167848699763594), 11: np.float64(0.05755395683453238), 12: np.float64(0.16666666666666666), 14: np.float64(0.03314917127071823), 16: np.float64(0.3225806451612903), 17: np.float64(0.1951219512195122), 18: np.float64(0.021739130434782608), 19: np.float64(0.5303514376996805), 20: np.float64(0.3684210526315789), 22: np.float64(0.26356589147286824), 24: np.float64(0.0625), 26: np.float64(0.6238532110091743), 28: np.float64(0.06535947712418301), 29: np.float64(0.6576576576576577), 30: np.float64(0.8205128205128205), 32: np.float64(0.40487804878048783), 33: np.float64(0.13793103448275862), 34: np.float64(0.09924487594390508), 36: np.float64(0.3333333333333333), 39: np.float64(0.12903225806451613)}
Micro-average F1 score: 0.2727272727272727
Weighted-average F1 score: 0.25923869534083915
cur_acc_wo_na:  ['0.7706', '0.5526', '0.5200', '0.5464', '0.4024']
his_acc_wo_na:  ['0.7706', '0.6863', '0.5632', '0.4966', '0.4116']
cur_acc des_wo_na:  ['0.7554', '0.5421', '0.3870', '0.5386', '0.3760']
his_acc des_wo_na:  ['0.7554', '0.6392', '0.5391', '0.5085', '0.4159']
cur_acc rrf_wo_na:  ['0.7746', '0.5830', '0.4158', '0.5346', '0.3809']
his_acc rrf_wo_na:  ['0.7746', '0.6624', '0.5501', '0.5040', '0.4042']
cur_acc_w_na:  ['0.6477', '0.4321', '0.3789', '0.3589', '0.2776']
his_acc_w_na:  ['0.6477', '0.5505', '0.4250', '0.3547', '0.2875']
cur_acc des_w_na:  ['0.6163', '0.3914', '0.2632', '0.3456', '0.2508']
his_acc des_w_na:  ['0.6163', '0.4785', '0.3825', '0.3517', '0.2786']
cur_acc rrf_w_na:  ['0.6374', '0.4223', '0.2879', '0.3476', '0.2557']
his_acc rrf_w_na:  ['0.6374', '0.5027', '0.3983', '0.3545', '0.2727']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 83.7161391CurrentTrain: epoch  0, batch     1 | loss: 100.4004469CurrentTrain: epoch  0, batch     2 | loss: 76.5021366CurrentTrain: epoch  0, batch     3 | loss: 18.0959199CurrentTrain: epoch  1, batch     0 | loss: 79.8436761CurrentTrain: epoch  1, batch     1 | loss: 73.1254542CurrentTrain: epoch  1, batch     2 | loss: 101.3380533CurrentTrain: epoch  1, batch     3 | loss: 11.8189280CurrentTrain: epoch  2, batch     0 | loss: 70.8120512CurrentTrain: epoch  2, batch     1 | loss: 67.4259305CurrentTrain: epoch  2, batch     2 | loss: 84.3546517CurrentTrain: epoch  2, batch     3 | loss: 11.3505923CurrentTrain: epoch  3, batch     0 | loss: 79.5709529CurrentTrain: epoch  3, batch     1 | loss: 66.8628366CurrentTrain: epoch  3, batch     2 | loss: 96.9861900CurrentTrain: epoch  3, batch     3 | loss: 20.7699804CurrentTrain: epoch  4, batch     0 | loss: 82.7066528CurrentTrain: epoch  4, batch     1 | loss: 65.1767582CurrentTrain: epoch  4, batch     2 | loss: 62.8030280CurrentTrain: epoch  4, batch     3 | loss: 6.6335954CurrentTrain: epoch  5, batch     0 | loss: 61.9661698CurrentTrain: epoch  5, batch     1 | loss: 77.6435562CurrentTrain: epoch  5, batch     2 | loss: 75.0178719CurrentTrain: epoch  5, batch     3 | loss: 21.2802601CurrentTrain: epoch  6, batch     0 | loss: 64.5856754CurrentTrain: epoch  6, batch     1 | loss: 66.4590748CurrentTrain: epoch  6, batch     2 | loss: 63.4999193CurrentTrain: epoch  6, batch     3 | loss: 4.6526327CurrentTrain: epoch  7, batch     0 | loss: 61.9176867CurrentTrain: epoch  7, batch     1 | loss: 65.5966372CurrentTrain: epoch  7, batch     2 | loss: 64.2924258CurrentTrain: epoch  7, batch     3 | loss: 20.0096447CurrentTrain: epoch  8, batch     0 | loss: 62.5788969CurrentTrain: epoch  8, batch     1 | loss: 61.2582573CurrentTrain: epoch  8, batch     2 | loss: 75.1450921CurrentTrain: epoch  8, batch     3 | loss: 20.5078746CurrentTrain: epoch  9, batch     0 | loss: 62.8088780CurrentTrain: epoch  9, batch     1 | loss: 61.6139994CurrentTrain: epoch  9, batch     2 | loss: 61.1894468CurrentTrain: epoch  9, batch     3 | loss: 15.6480376
MemoryTrain:  epoch  0, batch     0 | loss: 0.7844487MemoryTrain:  epoch  1, batch     0 | loss: 0.6258400MemoryTrain:  epoch  2, batch     0 | loss: 0.5229044MemoryTrain:  epoch  3, batch     0 | loss: 0.4032562MemoryTrain:  epoch  4, batch     0 | loss: 0.3409369MemoryTrain:  epoch  5, batch     0 | loss: 0.3005216MemoryTrain:  epoch  6, batch     0 | loss: 0.2431863MemoryTrain:  epoch  7, batch     0 | loss: 0.2109244MemoryTrain:  epoch  8, batch     0 | loss: 0.1864267MemoryTrain:  epoch  9, batch     0 | loss: 0.1762272

F1 score per class: {32: np.float64(0.0), 1: np.float64(0.0), 34: np.float64(0.7272727272727273), 3: np.float64(0.9411764705882353), 7: np.float64(0.0), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.6666666666666666), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.432)}
Micro-average F1 score: 0.4
Weighted-average F1 score: 0.3203838240663187
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.5), 9: np.float64(0.6666666666666666), 10: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.4), 32: np.float64(0.0), 34: np.float64(0.0), 40: np.float64(0.6268656716417911)}
Micro-average F1 score: 0.44654088050314467
Weighted-average F1 score: 0.3859794166422788
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.5454545454545454), 9: np.float64(0.9056603773584906), 10: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.4), 32: np.float64(0.0), 34: np.float64(0.0), 40: np.float64(0.6131386861313869)}
Micro-average F1 score: 0.4682274247491639
Weighted-average F1 score: 0.3850385232674174

F1 score per class: {1: np.float64(0.1891891891891892), 2: np.float64(0.45454545454545453), 3: np.float64(0.6161137440758294), 5: np.float64(0.782258064516129), 6: np.float64(0.0), 7: np.float64(0.047619047619047616), 8: np.float64(0.06818181818181818), 9: np.float64(0.9411764705882353), 10: np.float64(0.30526315789473685), 11: np.float64(0.13138686131386862), 12: np.float64(0.1342281879194631), 14: np.float64(0.02040816326530612), 16: np.float64(0.5454545454545454), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5761316872427984), 20: np.float64(0.5977011494252874), 22: np.float64(0.46511627906976744), 24: np.float64(0.0), 26: np.float64(0.7252747252747253), 27: np.float64(0.0), 28: np.float64(0.15625), 29: np.float64(0.7567567567567568), 30: np.float64(0.8333333333333334), 31: np.float64(0.18181818181818182), 32: np.float64(0.6048387096774194), 33: np.float64(0.0), 34: np.float64(0.21122112211221122), 36: np.float64(0.24), 39: np.float64(0.125), 40: np.float64(0.13602015113350127)}
Micro-average F1 score: 0.3715982187036121
Weighted-average F1 score: 0.36585857409156836
F1 score per class: {1: np.float64(0.18018018018018017), 2: np.float64(0.4117647058823529), 3: np.float64(0.5569620253164557), 5: np.float64(0.627831715210356), 6: np.float64(0.1415929203539823), 7: np.float64(0.03870967741935484), 8: np.float64(0.22857142857142856), 9: np.float64(0.6024096385542169), 10: np.float64(0.3558282208588957), 11: np.float64(0.06896551724137931), 12: np.float64(0.18848167539267016), 14: np.float64(0.05755395683453238), 16: np.float64(0.4675324675324675), 17: np.float64(0.38095238095238093), 18: np.float64(0.05405405405405406), 19: np.float64(0.5568627450980392), 20: np.float64(0.5555555555555556), 22: np.float64(0.41846153846153844), 24: np.float64(0.07692307692307693), 26: np.float64(0.6990291262135923), 27: np.float64(0.0), 28: np.float64(0.08163265306122448), 29: np.float64(0.7650273224043715), 30: np.float64(0.7441860465116279), 31: np.float64(0.07407407407407407), 32: np.float64(0.5877862595419847), 33: np.float64(0.1875), 34: np.float64(0.17254901960784313), 36: np.float64(0.5378151260504201), 39: np.float64(0.1111111111111111), 40: np.float64(0.268370607028754)}
Micro-average F1 score: 0.367791077257889
Weighted-average F1 score: 0.3531320661430803
F1 score per class: {1: np.float64(0.1826086956521739), 2: np.float64(0.41379310344827586), 3: np.float64(0.5739130434782609), 5: np.float64(0.6783216783216783), 6: np.float64(0.09345794392523364), 7: np.float64(0.037267080745341616), 8: np.float64(0.16326530612244897), 9: np.float64(0.8727272727272727), 10: np.float64(0.3473053892215569), 11: np.float64(0.06666666666666667), 12: np.float64(0.17582417582417584), 14: np.float64(0.034482758620689655), 16: np.float64(0.5714285714285714), 17: np.float64(0.23529411764705882), 18: np.float64(0.057971014492753624), 19: np.float64(0.5666666666666667), 20: np.float64(0.5747126436781609), 22: np.float64(0.422360248447205), 24: np.float64(0.08), 26: np.float64(0.72), 27: np.float64(0.0), 28: np.float64(0.08421052631578947), 29: np.float64(0.7650273224043715), 30: np.float64(0.8108108108108109), 31: np.float64(0.09523809523809523), 32: np.float64(0.5891472868217055), 33: np.float64(0.08695652173913043), 34: np.float64(0.1702127659574468), 36: np.float64(0.35555555555555557), 39: np.float64(0.10256410256410256), 40: np.float64(0.23661971830985915)}
Micro-average F1 score: 0.36306447989215906
Weighted-average F1 score: 0.3475645082264451

F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.6666666666666666), 9: np.float64(0.9230769230769231), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.6666666666666666), 32: np.float64(0.0), 34: np.float64(0.0), 40: np.float64(0.4153846153846154)}
Micro-average F1 score: 0.34782608695652173
Weighted-average F1 score: 0.26484220907297834
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.46153846153846156), 9: np.float64(0.6097560975609756), 10: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.3333333333333333), 32: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 40: np.float64(0.5915492957746479)}
Micro-average F1 score: 0.3631713554987212
Weighted-average F1 score: 0.2994463190483018
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.5), 9: np.float64(0.8571428571428571), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.3333333333333333), 32: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 40: np.float64(0.5753424657534246)}
Micro-average F1 score: 0.3835616438356164
Weighted-average F1 score: 0.30049534412902856

F1 score per class: {1: np.float64(0.109375), 2: np.float64(0.2702702702702703), 3: np.float64(0.4024767801857585), 5: np.float64(0.5623188405797102), 6: np.float64(0.0), 7: np.float64(0.023255813953488372), 8: np.float64(0.06666666666666667), 9: np.float64(0.9056603773584906), 10: np.float64(0.23107569721115537), 11: np.float64(0.125), 12: np.float64(0.10101010101010101), 14: np.float64(0.018691588785046728), 16: np.float64(0.32608695652173914), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.546875), 20: np.float64(0.4297520661157025), 22: np.float64(0.343980343980344), 24: np.float64(0.0), 26: np.float64(0.6470588235294118), 27: np.float64(0.0), 28: np.float64(0.09523809523809523), 29: np.float64(0.6481481481481481), 30: np.float64(0.7894736842105263), 31: np.float64(0.1), 32: np.float64(0.4658385093167702), 33: np.float64(0.0), 34: np.float64(0.12549019607843137), 36: np.float64(0.21686746987951808), 39: np.float64(0.06451612903225806), 40: np.float64(0.11368421052631579)}
Micro-average F1 score: 0.2745886654478976
Weighted-average F1 score: 0.26189944464913834
F1 score per class: {1: np.float64(0.10498687664041995), 2: np.float64(0.21875), 3: np.float64(0.358695652173913), 5: np.float64(0.4282560706401766), 6: np.float64(0.11851851851851852), 7: np.float64(0.01764705882352941), 8: np.float64(0.21238938053097345), 9: np.float64(0.4854368932038835), 10: np.float64(0.2648401826484018), 11: np.float64(0.06504065040650407), 12: np.float64(0.1245674740484429), 14: np.float64(0.05063291139240506), 16: np.float64(0.2748091603053435), 17: np.float64(0.2222222222222222), 18: np.float64(0.03305785123966942), 19: np.float64(0.505338078291815), 20: np.float64(0.36764705882352944), 22: np.float64(0.29694323144104806), 24: np.float64(0.06666666666666667), 26: np.float64(0.5877551020408164), 27: np.float64(0.0), 28: np.float64(0.0446927374301676), 29: np.float64(0.6572769953051644), 30: np.float64(0.6808510638297872), 31: np.float64(0.038461538461538464), 32: np.float64(0.4438040345821326), 33: np.float64(0.14285714285714285), 34: np.float64(0.10268378063010501), 36: np.float64(0.4025157232704403), 39: np.float64(0.057971014492753624), 40: np.float64(0.2193211488250653)}
Micro-average F1 score: 0.2574649603900061
Weighted-average F1 score: 0.24205045545544207
F1 score per class: {1: np.float64(0.10741687979539642), 2: np.float64(0.24), 3: np.float64(0.36464088397790057), 5: np.float64(0.46411483253588515), 6: np.float64(0.08547008547008547), 7: np.float64(0.0169971671388102), 8: np.float64(0.15841584158415842), 9: np.float64(0.7868852459016393), 10: np.float64(0.2543859649122807), 11: np.float64(0.0625), 12: np.float64(0.11764705882352941), 14: np.float64(0.02962962962962963), 16: np.float64(0.32432432432432434), 17: np.float64(0.14814814814814814), 18: np.float64(0.03508771929824561), 19: np.float64(0.53125), 20: np.float64(0.373134328358209), 22: np.float64(0.30022075055187636), 24: np.float64(0.06896551724137931), 26: np.float64(0.6343612334801763), 27: np.float64(0.0), 28: np.float64(0.046511627906976744), 29: np.float64(0.6572769953051644), 30: np.float64(0.7692307692307693), 31: np.float64(0.04878048780487805), 32: np.float64(0.44574780058651026), 33: np.float64(0.07692307692307693), 34: np.float64(0.10220673635307782), 36: np.float64(0.27586206896551724), 39: np.float64(0.05405405405405406), 40: np.float64(0.19134396355353075)}
Micro-average F1 score: 0.25569620253164554
Weighted-average F1 score: 0.23861731168933598
cur_acc_wo_na:  ['0.7706', '0.5526', '0.5200', '0.5464', '0.4024', '0.4000']
his_acc_wo_na:  ['0.7706', '0.6863', '0.5632', '0.4966', '0.4116', '0.3716']
cur_acc des_wo_na:  ['0.7554', '0.5421', '0.3870', '0.5386', '0.3760', '0.4465']
his_acc des_wo_na:  ['0.7554', '0.6392', '0.5391', '0.5085', '0.4159', '0.3678']
cur_acc rrf_wo_na:  ['0.7746', '0.5830', '0.4158', '0.5346', '0.3809', '0.4682']
his_acc rrf_wo_na:  ['0.7746', '0.6624', '0.5501', '0.5040', '0.4042', '0.3631']
cur_acc_w_na:  ['0.6477', '0.4321', '0.3789', '0.3589', '0.2776', '0.3478']
his_acc_w_na:  ['0.6477', '0.5505', '0.4250', '0.3547', '0.2875', '0.2746']
cur_acc des_w_na:  ['0.6163', '0.3914', '0.2632', '0.3456', '0.2508', '0.3632']
his_acc des_w_na:  ['0.6163', '0.4785', '0.3825', '0.3517', '0.2786', '0.2575']
cur_acc rrf_w_na:  ['0.6374', '0.4223', '0.2879', '0.3476', '0.2557', '0.3836']
his_acc rrf_w_na:  ['0.6374', '0.5027', '0.3983', '0.3545', '0.2727', '0.2557']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 99.7606801CurrentTrain: epoch  0, batch     1 | loss: 88.0089316CurrentTrain: epoch  0, batch     2 | loss: 86.5113097CurrentTrain: epoch  0, batch     3 | loss: 73.2579119CurrentTrain: epoch  1, batch     0 | loss: 78.1649328CurrentTrain: epoch  1, batch     1 | loss: 92.0703486CurrentTrain: epoch  1, batch     2 | loss: 88.7897821CurrentTrain: epoch  1, batch     3 | loss: 69.3075072CurrentTrain: epoch  2, batch     0 | loss: 70.2052892CurrentTrain: epoch  2, batch     1 | loss: 71.9637059CurrentTrain: epoch  2, batch     2 | loss: 84.1815183CurrentTrain: epoch  2, batch     3 | loss: 87.4943002CurrentTrain: epoch  3, batch     0 | loss: 80.3545431CurrentTrain: epoch  3, batch     1 | loss: 68.2410534CurrentTrain: epoch  3, batch     2 | loss: 103.0306716CurrentTrain: epoch  3, batch     3 | loss: 46.6033064CurrentTrain: epoch  4, batch     0 | loss: 76.3172210CurrentTrain: epoch  4, batch     1 | loss: 77.5581377CurrentTrain: epoch  4, batch     2 | loss: 97.7176302CurrentTrain: epoch  4, batch     3 | loss: 57.4801019CurrentTrain: epoch  5, batch     0 | loss: 64.6988966CurrentTrain: epoch  5, batch     1 | loss: 98.0965772CurrentTrain: epoch  5, batch     2 | loss: 79.1393721CurrentTrain: epoch  5, batch     3 | loss: 84.6330617CurrentTrain: epoch  6, batch     0 | loss: 63.3102244CurrentTrain: epoch  6, batch     1 | loss: 97.3297189CurrentTrain: epoch  6, batch     2 | loss: 80.7063023CurrentTrain: epoch  6, batch     3 | loss: 44.0036667CurrentTrain: epoch  7, batch     0 | loss: 77.5292406CurrentTrain: epoch  7, batch     1 | loss: 75.7607757CurrentTrain: epoch  7, batch     2 | loss: 65.1540946CurrentTrain: epoch  7, batch     3 | loss: 63.6981458CurrentTrain: epoch  8, batch     0 | loss: 117.9309751CurrentTrain: epoch  8, batch     1 | loss: 77.6033233CurrentTrain: epoch  8, batch     2 | loss: 66.8542579CurrentTrain: epoch  8, batch     3 | loss: 66.1923038CurrentTrain: epoch  9, batch     0 | loss: 62.5351865CurrentTrain: epoch  9, batch     1 | loss: 74.4900446CurrentTrain: epoch  9, batch     2 | loss: 80.2204455CurrentTrain: epoch  9, batch     3 | loss: 53.1569414
MemoryTrain:  epoch  0, batch     0 | loss: 0.8570733MemoryTrain:  epoch  1, batch     0 | loss: 0.8113877MemoryTrain:  epoch  2, batch     0 | loss: 0.6512438MemoryTrain:  epoch  3, batch     0 | loss: 0.5770681MemoryTrain:  epoch  4, batch     0 | loss: 0.4646636MemoryTrain:  epoch  5, batch     0 | loss: 0.4398643MemoryTrain:  epoch  6, batch     0 | loss: 0.3797130MemoryTrain:  epoch  7, batch     0 | loss: 0.3407712MemoryTrain:  epoch  8, batch     0 | loss: 0.2846968MemoryTrain:  epoch  9, batch     0 | loss: 0.2408758

F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.8888888888888888), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 25: np.float64(0.375), 28: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.8484848484848485), 37: np.float64(0.5773195876288659), 38: np.float64(0.5714285714285714), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.48
Weighted-average F1 score: 0.364728609735053
F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.6363636363636364), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5333333333333333), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.8301886792452831), 36: np.float64(0.0), 37: np.float64(0.4807692307692308), 38: np.float64(0.7058823529411765), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.41081081081081083
Weighted-average F1 score: 0.2908264065904353
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.6666666666666666), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5205479452054794), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.8380952380952381), 36: np.float64(0.0), 37: np.float64(0.4954128440366973), 38: np.float64(0.6222222222222222), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4220532319391635
Weighted-average F1 score: 0.30269227746266836

F1 score per class: {1: np.float64(0.1826086956521739), 2: np.float64(0.45454545454545453), 3: np.float64(0.2857142857142857), 5: np.float64(0.7372549019607844), 6: np.float64(0.0), 7: np.float64(0.040268456375838924), 8: np.float64(0.06818181818181818), 9: np.float64(0.8888888888888888), 10: np.float64(0.27586206896551724), 11: np.float64(0.13008130081300814), 12: np.float64(0.05673758865248227), 14: np.float64(0.0196078431372549), 15: np.float64(0.5925925925925926), 16: np.float64(0.6101694915254238), 17: np.float64(0.0), 18: np.float64(0.04081632653061224), 19: np.float64(0.5394190871369294), 20: np.float64(0.4444444444444444), 22: np.float64(0.4344569288389513), 24: np.float64(0.0), 25: np.float64(0.36363636363636365), 26: np.float64(0.7243243243243244), 27: np.float64(0.0), 28: np.float64(0.12048192771084337), 29: np.float64(0.7731958762886598), 30: np.float64(0.7894736842105263), 31: np.float64(0.11764705882352941), 32: np.float64(0.5474452554744526), 33: np.float64(0.10526315789473684), 34: np.float64(0.20134228187919462), 35: np.float64(0.3111111111111111), 36: np.float64(0.029850746268656716), 37: np.float64(0.19243986254295534), 38: np.float64(0.27906976744186046), 39: np.float64(0.1935483870967742), 40: np.float64(0.23492063492063492)}
Micro-average F1 score: 0.34301147873058746
Weighted-average F1 score: 0.3483335281773287
F1 score per class: {1: np.float64(0.15810276679841898), 2: np.float64(0.34146341463414637), 3: np.float64(0.35023041474654376), 5: np.float64(0.5286103542234333), 6: np.float64(0.1951219512195122), 7: np.float64(0.050955414012738856), 8: np.float64(0.3088235294117647), 9: np.float64(0.5494505494505495), 10: np.float64(0.3942307692307692), 11: np.float64(0.1), 12: np.float64(0.15384615384615385), 14: np.float64(0.056179775280898875), 15: np.float64(0.3333333333333333), 16: np.float64(0.46938775510204084), 17: np.float64(0.0), 18: np.float64(0.24096385542168675), 19: np.float64(0.48859934853420195), 20: np.float64(0.5348837209302325), 22: np.float64(0.4083044982698962), 24: np.float64(0.12121212121212122), 25: np.float64(0.49382716049382713), 26: np.float64(0.7029702970297029), 27: np.float64(0.0), 28: np.float64(0.08163265306122448), 29: np.float64(0.7807486631016043), 30: np.float64(0.6415094339622641), 31: np.float64(0.038461538461538464), 32: np.float64(0.5208333333333334), 33: np.float64(0.21052631578947367), 34: np.float64(0.1842818428184282), 35: np.float64(0.29333333333333333), 36: np.float64(0.4166666666666667), 37: np.float64(0.1497005988023952), 38: np.float64(0.2748091603053435), 39: np.float64(0.07142857142857142), 40: np.float64(0.23841059602649006)}
Micro-average F1 score: 0.33085106382978724
Weighted-average F1 score: 0.3138825002458329
F1 score per class: {1: np.float64(0.15810276679841898), 2: np.float64(0.4666666666666667), 3: np.float64(0.40217391304347827), 5: np.float64(0.573134328358209), 6: np.float64(0.10810810810810811), 7: np.float64(0.05128205128205128), 8: np.float64(0.12121212121212122), 9: np.float64(0.7741935483870968), 10: np.float64(0.35944700460829493), 11: np.float64(0.11382113821138211), 12: np.float64(0.14736842105263157), 14: np.float64(0.06060606060606061), 15: np.float64(0.3333333333333333), 16: np.float64(0.547945205479452), 17: np.float64(0.0), 18: np.float64(0.19444444444444445), 19: np.float64(0.5236363636363637), 20: np.float64(0.5365853658536586), 22: np.float64(0.4154929577464789), 24: np.float64(0.06666666666666667), 25: np.float64(0.5), 26: np.float64(0.7070707070707071), 27: np.float64(0.0), 28: np.float64(0.08928571428571429), 29: np.float64(0.7807486631016043), 30: np.float64(0.75), 31: np.float64(0.07142857142857142), 32: np.float64(0.5277777777777778), 33: np.float64(0.16666666666666666), 34: np.float64(0.1641337386018237), 35: np.float64(0.2829581993569132), 36: np.float64(0.1388888888888889), 37: np.float64(0.1424802110817942), 38: np.float64(0.22950819672131148), 39: np.float64(0.05128205128205128), 40: np.float64(0.2138728323699422)}
Micro-average F1 score: 0.32262855021347686
Weighted-average F1 score: 0.3077950846928376

F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.6666666666666666), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 25: np.float64(0.36363636363636365), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.7368421052631579), 37: np.float64(0.5045045045045045), 38: np.float64(0.47058823529411764), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3541666666666667
Weighted-average F1 score: 0.2597294778595088
F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.5185185185185185), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.4878048780487805), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.7213114754098361), 36: np.float64(0.0), 37: np.float64(0.4166666666666667), 38: np.float64(0.5142857142857142), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.28824273072060685
Weighted-average F1 score: 0.20552894222097726
F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.5384615384615384), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.48717948717948717), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.7333333333333333), 36: np.float64(0.0), 37: np.float64(0.421875), 38: np.float64(0.4117647058823529), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.29838709677419356
Weighted-average F1 score: 0.21554353502273554

F1 score per class: {1: np.float64(0.10268948655256724), 2: np.float64(0.25), 3: np.float64(0.21518987341772153), 5: np.float64(0.5578635014836796), 6: np.float64(0.0), 7: np.float64(0.0189873417721519), 8: np.float64(0.06315789473684211), 9: np.float64(0.8275862068965517), 10: np.float64(0.22535211267605634), 11: np.float64(0.11940298507462686), 12: np.float64(0.037914691943127965), 14: np.float64(0.017543859649122806), 15: np.float64(0.34782608695652173), 16: np.float64(0.3956043956043956), 17: np.float64(0.0), 18: np.float64(0.02702702702702703), 19: np.float64(0.49429657794676807), 20: np.float64(0.3076923076923077), 22: np.float64(0.3240223463687151), 24: np.float64(0.0), 25: np.float64(0.35294117647058826), 26: np.float64(0.6442307692307693), 27: np.float64(0.0), 28: np.float64(0.06944444444444445), 29: np.float64(0.6607929515418502), 30: np.float64(0.75), 31: np.float64(0.06666666666666667), 32: np.float64(0.4166666666666667), 33: np.float64(0.10526315789473684), 34: np.float64(0.12658227848101267), 35: np.float64(0.1838074398249453), 36: np.float64(0.028985507246376812), 37: np.float64(0.1154639175257732), 38: np.float64(0.15584415584415584), 39: np.float64(0.1), 40: np.float64(0.193717277486911)}
Micro-average F1 score: 0.24640258690379951
Weighted-average F1 score: 0.23666214918833473
F1 score per class: {1: np.float64(0.08695652173913043), 2: np.float64(0.2), 3: np.float64(0.2331288343558282), 5: np.float64(0.3745173745173745), 6: np.float64(0.1568627450980392), 7: np.float64(0.02373887240356083), 8: np.float64(0.25301204819277107), 9: np.float64(0.42016806722689076), 10: np.float64(0.2611464968152866), 11: np.float64(0.096), 12: np.float64(0.09771986970684039), 14: np.float64(0.04608294930875576), 15: np.float64(0.25), 16: np.float64(0.2804878048780488), 17: np.float64(0.0), 18: np.float64(0.13245033112582782), 19: np.float64(0.4225352112676056), 20: np.float64(0.36220472440944884), 22: np.float64(0.2885085574572127), 24: np.float64(0.0975609756097561), 25: np.float64(0.425531914893617), 26: np.float64(0.5892116182572614), 27: np.float64(0.0), 28: np.float64(0.04060913705583756), 29: np.float64(0.6517857142857143), 30: np.float64(0.5573770491803278), 31: np.float64(0.02127659574468085), 32: np.float64(0.3787878787878788), 33: np.float64(0.14285714285714285), 34: np.float64(0.11409395973154363), 35: np.float64(0.1749502982107356), 36: np.float64(0.3007518796992481), 37: np.float64(0.0998003992015968), 38: np.float64(0.15), 39: np.float64(0.0425531914893617), 40: np.float64(0.18181818181818182)}
Micro-average F1 score: 0.22558027079303675
Weighted-average F1 score: 0.21135413338151443
F1 score per class: {1: np.float64(0.087527352297593), 2: np.float64(0.2641509433962264), 3: np.float64(0.2642857142857143), 5: np.float64(0.41113490364025695), 6: np.float64(0.096), 7: np.float64(0.02416918429003021), 8: np.float64(0.10810810810810811), 9: np.float64(0.6857142857142857), 10: np.float64(0.254071661237785), 11: np.float64(0.1111111111111111), 12: np.float64(0.09395973154362416), 14: np.float64(0.049019607843137254), 15: np.float64(0.2413793103448276), 16: np.float64(0.32), 17: np.float64(0.0), 18: np.float64(0.11023622047244094), 19: np.float64(0.46153846153846156), 20: np.float64(0.3548387096774194), 22: np.float64(0.28921568627450983), 24: np.float64(0.058823529411764705), 25: np.float64(0.4418604651162791), 26: np.float64(0.611353711790393), 27: np.float64(0.0), 28: np.float64(0.04672897196261682), 29: np.float64(0.6576576576576577), 30: np.float64(0.6976744186046512), 31: np.float64(0.03571428571428571), 32: np.float64(0.3877551020408163), 33: np.float64(0.12903225806451613), 34: np.float64(0.10207939508506617), 35: np.float64(0.17254901960784313), 36: np.float64(0.12987012987012986), 37: np.float64(0.0919931856899489), 38: np.float64(0.12173913043478261), 39: np.float64(0.028985507246376812), 40: np.float64(0.16371681415929204)}
Micro-average F1 score: 0.22250672129048776
Weighted-average F1 score: 0.20755554362776715
cur_acc_wo_na:  ['0.7706', '0.5526', '0.5200', '0.5464', '0.4024', '0.4000', '0.4800']
his_acc_wo_na:  ['0.7706', '0.6863', '0.5632', '0.4966', '0.4116', '0.3716', '0.3430']
cur_acc des_wo_na:  ['0.7554', '0.5421', '0.3870', '0.5386', '0.3760', '0.4465', '0.4108']
his_acc des_wo_na:  ['0.7554', '0.6392', '0.5391', '0.5085', '0.4159', '0.3678', '0.3309']
cur_acc rrf_wo_na:  ['0.7746', '0.5830', '0.4158', '0.5346', '0.3809', '0.4682', '0.4221']
his_acc rrf_wo_na:  ['0.7746', '0.6624', '0.5501', '0.5040', '0.4042', '0.3631', '0.3226']
cur_acc_w_na:  ['0.6477', '0.4321', '0.3789', '0.3589', '0.2776', '0.3478', '0.3542']
his_acc_w_na:  ['0.6477', '0.5505', '0.4250', '0.3547', '0.2875', '0.2746', '0.2464']
cur_acc des_w_na:  ['0.6163', '0.3914', '0.2632', '0.3456', '0.2508', '0.3632', '0.2882']
his_acc des_w_na:  ['0.6163', '0.4785', '0.3825', '0.3517', '0.2786', '0.2575', '0.2256']
cur_acc rrf_w_na:  ['0.6374', '0.4223', '0.2879', '0.3476', '0.2557', '0.3836', '0.2984']
his_acc rrf_w_na:  ['0.6374', '0.5027', '0.3983', '0.3545', '0.2727', '0.2557', '0.2225']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 96.1270811CurrentTrain: epoch  0, batch     1 | loss: 150.7818615CurrentTrain: epoch  0, batch     2 | loss: 85.1086655CurrentTrain: epoch  0, batch     3 | loss: 83.4871307CurrentTrain: epoch  1, batch     0 | loss: 91.8342677CurrentTrain: epoch  1, batch     1 | loss: 81.6416953CurrentTrain: epoch  1, batch     2 | loss: 77.9448786CurrentTrain: epoch  1, batch     3 | loss: 73.4669077CurrentTrain: epoch  2, batch     0 | loss: 111.3527411CurrentTrain: epoch  2, batch     1 | loss: 77.1742980CurrentTrain: epoch  2, batch     2 | loss: 83.1015208CurrentTrain: epoch  2, batch     3 | loss: 85.0937208CurrentTrain: epoch  3, batch     0 | loss: 106.4343580CurrentTrain: epoch  3, batch     1 | loss: 87.9869572CurrentTrain: epoch  3, batch     2 | loss: 79.3896556CurrentTrain: epoch  3, batch     3 | loss: 64.4422163CurrentTrain: epoch  4, batch     0 | loss: 81.5041755CurrentTrain: epoch  4, batch     1 | loss: 98.1767723CurrentTrain: epoch  4, batch     2 | loss: 130.5033762CurrentTrain: epoch  4, batch     3 | loss: 65.3429112CurrentTrain: epoch  5, batch     0 | loss: 76.8307915CurrentTrain: epoch  5, batch     1 | loss: 80.8168820CurrentTrain: epoch  5, batch     2 | loss: 86.7007132CurrentTrain: epoch  5, batch     3 | loss: 75.4578116CurrentTrain: epoch  6, batch     0 | loss: 102.3646756CurrentTrain: epoch  6, batch     1 | loss: 68.6021943CurrentTrain: epoch  6, batch     2 | loss: 77.2412529CurrentTrain: epoch  6, batch     3 | loss: 65.9464397CurrentTrain: epoch  7, batch     0 | loss: 82.2042508CurrentTrain: epoch  7, batch     1 | loss: 66.9412627CurrentTrain: epoch  7, batch     2 | loss: 75.7157358CurrentTrain: epoch  7, batch     3 | loss: 79.8110365CurrentTrain: epoch  8, batch     0 | loss: 100.7002227CurrentTrain: epoch  8, batch     1 | loss: 76.9210147CurrentTrain: epoch  8, batch     2 | loss: 79.7535111CurrentTrain: epoch  8, batch     3 | loss: 59.8937705CurrentTrain: epoch  9, batch     0 | loss: 66.2072385CurrentTrain: epoch  9, batch     1 | loss: 74.6579853CurrentTrain: epoch  9, batch     2 | loss: 97.8007165CurrentTrain: epoch  9, batch     3 | loss: 75.3288283
MemoryTrain:  epoch  0, batch     0 | loss: 0.8846458MemoryTrain:  epoch  1, batch     0 | loss: 0.7646617MemoryTrain:  epoch  2, batch     0 | loss: 0.7431104MemoryTrain:  epoch  3, batch     0 | loss: 0.5388596MemoryTrain:  epoch  4, batch     0 | loss: 0.4304997MemoryTrain:  epoch  5, batch     0 | loss: 0.4126828MemoryTrain:  epoch  6, batch     0 | loss: 0.3592265MemoryTrain:  epoch  7, batch     0 | loss: 0.3437997MemoryTrain:  epoch  8, batch     0 | loss: 0.2790441MemoryTrain:  epoch  9, batch     0 | loss: 0.2813216

F1 score per class: {0: np.float64(0.8831168831168831), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8777777777777778), 5: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.36363636363636365), 14: np.float64(0.0), 15: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3018867924528302), 22: np.float64(0.0), 23: np.float64(0.8), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.6007462686567164
Weighted-average F1 score: 0.4834500796287279
F1 score per class: {0: np.float64(0.7142857142857143), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7623762376237624), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.2631578947368421), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.37142857142857144), 22: np.float64(0.0), 23: np.float64(0.6666666666666666), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.435506241331484
Weighted-average F1 score: 0.33367344568412993
F1 score per class: {0: np.float64(0.7692307692307693), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8163265306122449), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.2564102564102564), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.375), 22: np.float64(0.0), 23: np.float64(0.6987951807228916), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.48348348348348347
Weighted-average F1 score: 0.3725457033659414

F1 score per class: {0: np.float64(0.35051546391752575), 1: np.float64(0.17592592592592593), 2: np.float64(0.4117647058823529), 3: np.float64(0.30158730158730157), 4: np.float64(0.8729281767955801), 5: np.float64(0.7899159663865546), 6: np.float64(0.0196078431372549), 7: np.float64(0.03870967741935484), 8: np.float64(0.023809523809523808), 9: np.float64(0.9056603773584906), 10: np.float64(0.23129251700680273), 11: np.float64(0.1076923076923077), 12: np.float64(0.030303030303030304), 13: np.float64(0.04395604395604396), 14: np.float64(0.020202020202020204), 15: np.float64(0.5185185185185185), 16: np.float64(0.5714285714285714), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5607476635514018), 20: np.float64(0.4358974358974359), 21: np.float64(0.12903225806451613), 22: np.float64(0.36633663366336633), 23: np.float64(0.6990291262135923), 24: np.float64(0.0), 25: np.float64(0.4), 26: np.float64(0.6931818181818182), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.7731958762886598), 30: np.float64(0.8108108108108109), 31: np.float64(0.125), 32: np.float64(0.5170068027210885), 33: np.float64(0.0), 34: np.float64(0.16326530612244897), 35: np.float64(0.33884297520661155), 36: np.float64(0.0), 37: np.float64(0.25116279069767444), 38: np.float64(0.29508196721311475), 39: np.float64(0.1694915254237288), 40: np.float64(0.31343283582089554)}
Micro-average F1 score: 0.3572161773763088
Weighted-average F1 score: 0.3551577870278781
F1 score per class: {0: np.float64(0.20114942528735633), 1: np.float64(0.17073170731707318), 2: np.float64(0.23333333333333334), 3: np.float64(0.34977578475336324), 4: np.float64(0.7298578199052133), 5: np.float64(0.5552407932011332), 6: np.float64(0.21374045801526717), 7: np.float64(0.03940886699507389), 8: np.float64(0.288), 9: np.float64(0.6024096385542169), 10: np.float64(0.2755102040816326), 11: np.float64(0.13432835820895522), 12: np.float64(0.10837438423645321), 13: np.float64(0.03875968992248062), 14: np.float64(0.04477611940298507), 15: np.float64(0.4), 16: np.float64(0.5057471264367817), 17: np.float64(0.0), 18: np.float64(0.23529411764705882), 19: np.float64(0.501628664495114), 20: np.float64(0.5106382978723404), 21: np.float64(0.16049382716049382), 22: np.float64(0.3884297520661157), 23: np.float64(0.5806451612903226), 24: np.float64(0.0), 25: np.float64(0.5), 26: np.float64(0.6504854368932039), 27: np.float64(0.0), 28: np.float64(0.047619047619047616), 29: np.float64(0.7708333333333334), 30: np.float64(0.6296296296296297), 31: np.float64(0.058823529411764705), 32: np.float64(0.5064102564102564), 33: np.float64(0.15), 34: np.float64(0.22295081967213115), 35: np.float64(0.26627218934911245), 36: np.float64(0.40816326530612246), 37: np.float64(0.16822429906542055), 38: np.float64(0.2689075630252101), 39: np.float64(0.046511627906976744), 40: np.float64(0.32)}
Micro-average F1 score: 0.3269821757836509
Weighted-average F1 score: 0.3049678751964621
F1 score per class: {0: np.float64(0.24475524475524477), 1: np.float64(0.18181818181818182), 2: np.float64(0.2916666666666667), 3: np.float64(0.4022346368715084), 4: np.float64(0.7920792079207921), 5: np.float64(0.6666666666666666), 6: np.float64(0.1724137931034483), 7: np.float64(0.04040404040404041), 8: np.float64(0.10752688172043011), 9: np.float64(0.8135593220338984), 10: np.float64(0.2702702702702703), 11: np.float64(0.11510791366906475), 12: np.float64(0.09803921568627451), 13: np.float64(0.039525691699604744), 14: np.float64(0.030303030303030304), 15: np.float64(0.375), 16: np.float64(0.5833333333333334), 17: np.float64(0.0), 18: np.float64(0.18666666666666668), 19: np.float64(0.5488721804511278), 20: np.float64(0.5111111111111111), 21: np.float64(0.15894039735099338), 22: np.float64(0.3865546218487395), 23: np.float64(0.6170212765957447), 24: np.float64(0.0), 25: np.float64(0.4657534246575342), 26: np.float64(0.6633165829145728), 27: np.float64(0.0), 28: np.float64(0.044444444444444446), 29: np.float64(0.7708333333333334), 30: np.float64(0.75), 31: np.float64(0.08695652173913043), 32: np.float64(0.48598130841121495), 33: np.float64(0.21428571428571427), 34: np.float64(0.2066420664206642), 35: np.float64(0.2857142857142857), 36: np.float64(0.21333333333333335), 37: np.float64(0.20973782771535582), 38: np.float64(0.2524271844660194), 39: np.float64(0.07017543859649122), 40: np.float64(0.2909090909090909)}
Micro-average F1 score: 0.33584463418717564
Weighted-average F1 score: 0.3152661877506903

F1 score per class: {0: np.float64(0.8192771084337349), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8315789473684211), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.19047619047619047), 14: np.float64(0.0), 15: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.23880597014925373), 22: np.float64(0.0), 23: np.float64(0.7058823529411765), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.45161290322580644
Weighted-average F1 score: 0.3387363400321838
F1 score per class: {0: np.float64(0.6140350877192983), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7162790697674418), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.14285714285714285), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.2736842105263158), 22: np.float64(0.0), 23: np.float64(0.5567010309278351), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3124378109452736
Weighted-average F1 score: 0.2347635032909962
F1 score per class: {0: np.float64(0.6796116504854369), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7729468599033816), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.14492753623188406), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.2696629213483146), 22: np.float64(0.0), 23: np.float64(0.5858585858585859), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3496199782844734
Weighted-average F1 score: 0.2609702441703138

F1 score per class: {0: np.float64(0.23448275862068965), 1: np.float64(0.09336609336609336), 2: np.float64(0.25), 3: np.float64(0.2331288343558282), 4: np.float64(0.797979797979798), 5: np.float64(0.6394557823129252), 6: np.float64(0.01834862385321101), 7: np.float64(0.019417475728155338), 8: np.float64(0.022727272727272728), 9: np.float64(0.8727272727272727), 10: np.float64(0.18478260869565216), 11: np.float64(0.09032258064516129), 12: np.float64(0.022598870056497175), 13: np.float64(0.020512820512820513), 14: np.float64(0.01834862385321101), 15: np.float64(0.32558139534883723), 16: np.float64(0.34782608695652173), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5172413793103449), 20: np.float64(0.2982456140350877), 21: np.float64(0.09467455621301775), 22: np.float64(0.2690909090909091), 23: np.float64(0.5806451612903226), 24: np.float64(0.0), 25: np.float64(0.38235294117647056), 26: np.float64(0.6192893401015228), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.6493506493506493), 30: np.float64(0.75), 31: np.float64(0.06896551724137931), 32: np.float64(0.36538461538461536), 33: np.float64(0.0), 34: np.float64(0.12), 35: np.float64(0.205), 36: np.float64(0.0), 37: np.float64(0.16119402985074627), 38: np.float64(0.18), 39: np.float64(0.09174311926605505), 40: np.float64(0.2625)}
Micro-average F1 score: 0.2582751966750779
Weighted-average F1 score: 0.24235911449050562
F1 score per class: {0: np.float64(0.13307984790874525), 1: np.float64(0.09375), 2: np.float64(0.14285714285714285), 3: np.float64(0.22608695652173913), 4: np.float64(0.6285714285714286), 5: np.float64(0.38811881188118813), 6: np.float64(0.17391304347826086), 7: np.float64(0.019464720194647202), 8: np.float64(0.24161073825503357), 9: np.float64(0.49019607843137253), 10: np.float64(0.19708029197080293), 11: np.float64(0.11920529801324503), 12: np.float64(0.06896551724137931), 13: np.float64(0.01845018450184502), 14: np.float64(0.037037037037037035), 15: np.float64(0.3076923076923077), 16: np.float64(0.27848101265822783), 17: np.float64(0.0), 18: np.float64(0.12658227848101267), 19: np.float64(0.43137254901960786), 20: np.float64(0.32653061224489793), 21: np.float64(0.11926605504587157), 22: np.float64(0.2781065088757396), 23: np.float64(0.4426229508196721), 24: np.float64(0.0), 25: np.float64(0.43478260869565216), 26: np.float64(0.5469387755102041), 27: np.float64(0.0), 28: np.float64(0.025), 29: np.float64(0.6218487394957983), 30: np.float64(0.53125), 31: np.float64(0.024096385542168676), 32: np.float64(0.3550561797752809), 33: np.float64(0.1016949152542373), 34: np.float64(0.13627254509018036), 35: np.float64(0.16071428571428573), 36: np.float64(0.3125), 37: np.float64(0.11868131868131868), 38: np.float64(0.1553398058252427), 39: np.float64(0.02564102564102564), 40: np.float64(0.25236593059936907)}
Micro-average F1 score: 0.22159741747370612
Weighted-average F1 score: 0.2041456331853086
F1 score per class: {0: np.float64(0.16279069767441862), 1: np.float64(0.09744779582366589), 2: np.float64(0.175), 3: np.float64(0.27692307692307694), 4: np.float64(0.7111111111111111), 5: np.float64(0.45714285714285713), 6: np.float64(0.15037593984962405), 7: np.float64(0.020100502512562814), 8: np.float64(0.09433962264150944), 9: np.float64(0.7741935483870968), 10: np.float64(0.20408163265306123), 11: np.float64(0.0963855421686747), 12: np.float64(0.062111801242236024), 13: np.float64(0.01845018450184502), 14: np.float64(0.02531645569620253), 15: np.float64(0.2608695652173913), 16: np.float64(0.3157894736842105), 17: np.float64(0.0), 18: np.float64(0.1), 19: np.float64(0.4850498338870432), 20: np.float64(0.31724137931034485), 21: np.float64(0.11594202898550725), 22: np.float64(0.27299703264094954), 23: np.float64(0.4603174603174603), 24: np.float64(0.0), 25: np.float64(0.40476190476190477), 26: np.float64(0.5814977973568282), 27: np.float64(0.0), 28: np.float64(0.024096385542168676), 29: np.float64(0.6324786324786325), 30: np.float64(0.6976744186046512), 31: np.float64(0.041666666666666664), 32: np.float64(0.33766233766233766), 33: np.float64(0.16666666666666666), 34: np.float64(0.13023255813953488), 35: np.float64(0.1749502982107356), 36: np.float64(0.19753086419753085), 37: np.float64(0.13333333333333333), 38: np.float64(0.15853658536585366), 39: np.float64(0.0380952380952381), 40: np.float64(0.22792022792022792)}
Micro-average F1 score: 0.22902157780568558
Weighted-average F1 score: 0.20970196977126485
cur_acc_wo_na:  ['0.7706', '0.5526', '0.5200', '0.5464', '0.4024', '0.4000', '0.4800', '0.6007']
his_acc_wo_na:  ['0.7706', '0.6863', '0.5632', '0.4966', '0.4116', '0.3716', '0.3430', '0.3572']
cur_acc des_wo_na:  ['0.7554', '0.5421', '0.3870', '0.5386', '0.3760', '0.4465', '0.4108', '0.4355']
his_acc des_wo_na:  ['0.7554', '0.6392', '0.5391', '0.5085', '0.4159', '0.3678', '0.3309', '0.3270']
cur_acc rrf_wo_na:  ['0.7746', '0.5830', '0.4158', '0.5346', '0.3809', '0.4682', '0.4221', '0.4835']
his_acc rrf_wo_na:  ['0.7746', '0.6624', '0.5501', '0.5040', '0.4042', '0.3631', '0.3226', '0.3358']
cur_acc_w_na:  ['0.6477', '0.4321', '0.3789', '0.3589', '0.2776', '0.3478', '0.3542', '0.4516']
his_acc_w_na:  ['0.6477', '0.5505', '0.4250', '0.3547', '0.2875', '0.2746', '0.2464', '0.2583']
cur_acc des_w_na:  ['0.6163', '0.3914', '0.2632', '0.3456', '0.2508', '0.3632', '0.2882', '0.3124']
his_acc des_w_na:  ['0.6163', '0.4785', '0.3825', '0.3517', '0.2786', '0.2575', '0.2256', '0.2216']
cur_acc rrf_w_na:  ['0.6374', '0.4223', '0.2879', '0.3476', '0.2557', '0.3836', '0.2984', '0.3496']
his_acc rrf_w_na:  ['0.6374', '0.5027', '0.3983', '0.3545', '0.2727', '0.2557', '0.2225', '0.2290']
--------Round  2
seed:  300
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 2 3 1 5 6 0 4]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 85.0288738CurrentTrain: epoch  0, batch     1 | loss: 79.6946741CurrentTrain: epoch  0, batch     2 | loss: 103.3027814CurrentTrain: epoch  0, batch     3 | loss: 102.3563452CurrentTrain: epoch  0, batch     4 | loss: 87.4592133CurrentTrain: epoch  0, batch     5 | loss: 119.8583115CurrentTrain: epoch  0, batch     6 | loss: 100.5131064CurrentTrain: epoch  0, batch     7 | loss: 119.6340728CurrentTrain: epoch  0, batch     8 | loss: 86.3221264CurrentTrain: epoch  0, batch     9 | loss: 119.2527409CurrentTrain: epoch  0, batch    10 | loss: 86.2030121CurrentTrain: epoch  0, batch    11 | loss: 86.7449064CurrentTrain: epoch  0, batch    12 | loss: 86.6850817CurrentTrain: epoch  0, batch    13 | loss: 119.7271519CurrentTrain: epoch  0, batch    14 | loss: 146.7858934CurrentTrain: epoch  0, batch    15 | loss: 118.2604807CurrentTrain: epoch  0, batch    16 | loss: 118.7160441CurrentTrain: epoch  0, batch    17 | loss: 99.9569012CurrentTrain: epoch  0, batch    18 | loss: 145.5499185CurrentTrain: epoch  0, batch    19 | loss: 100.0270752CurrentTrain: epoch  0, batch    20 | loss: 76.5529471CurrentTrain: epoch  0, batch    21 | loss: 87.9547629CurrentTrain: epoch  0, batch    22 | loss: 87.2594707CurrentTrain: epoch  0, batch    23 | loss: 117.7437771CurrentTrain: epoch  0, batch    24 | loss: 117.1905593CurrentTrain: epoch  0, batch    25 | loss: 117.5541939CurrentTrain: epoch  0, batch    26 | loss: 85.3659621CurrentTrain: epoch  0, batch    27 | loss: 192.0667674CurrentTrain: epoch  0, batch    28 | loss: 99.4957667CurrentTrain: epoch  0, batch    29 | loss: 99.3405510CurrentTrain: epoch  0, batch    30 | loss: 98.7421684CurrentTrain: epoch  0, batch    31 | loss: 85.6879731CurrentTrain: epoch  0, batch    32 | loss: 118.1489569CurrentTrain: epoch  0, batch    33 | loss: 85.0877774CurrentTrain: epoch  0, batch    34 | loss: 98.7328978CurrentTrain: epoch  0, batch    35 | loss: 98.5556618CurrentTrain: epoch  0, batch    36 | loss: 117.4436057CurrentTrain: epoch  0, batch    37 | loss: 97.2943023CurrentTrain: epoch  0, batch    38 | loss: 97.7042101CurrentTrain: epoch  0, batch    39 | loss: 116.7541951CurrentTrain: epoch  0, batch    40 | loss: 84.8775530CurrentTrain: epoch  0, batch    41 | loss: 98.9208011CurrentTrain: epoch  0, batch    42 | loss: 146.2763896CurrentTrain: epoch  0, batch    43 | loss: 116.8553222CurrentTrain: epoch  0, batch    44 | loss: 98.1616155CurrentTrain: epoch  0, batch    45 | loss: 97.8332339CurrentTrain: epoch  0, batch    46 | loss: 84.3434360CurrentTrain: epoch  0, batch    47 | loss: 96.8757676CurrentTrain: epoch  0, batch    48 | loss: 97.2704239CurrentTrain: epoch  0, batch    49 | loss: 97.4427591CurrentTrain: epoch  0, batch    50 | loss: 84.7077073CurrentTrain: epoch  0, batch    51 | loss: 116.8555338CurrentTrain: epoch  0, batch    52 | loss: 72.9153218CurrentTrain: epoch  0, batch    53 | loss: 116.7349267CurrentTrain: epoch  0, batch    54 | loss: 95.5628530CurrentTrain: epoch  0, batch    55 | loss: 114.4984071CurrentTrain: epoch  0, batch    56 | loss: 143.7784193CurrentTrain: epoch  0, batch    57 | loss: 71.1843012CurrentTrain: epoch  0, batch    58 | loss: 114.9239670CurrentTrain: epoch  0, batch    59 | loss: 79.9185911CurrentTrain: epoch  0, batch    60 | loss: 113.3616759CurrentTrain: epoch  0, batch    61 | loss: 96.5851887CurrentTrain: epoch  0, batch    62 | loss: 95.8116797CurrentTrain: epoch  0, batch    63 | loss: 70.8683289CurrentTrain: epoch  0, batch    64 | loss: 114.5722709CurrentTrain: epoch  0, batch    65 | loss: 92.3313521CurrentTrain: epoch  0, batch    66 | loss: 95.6384489CurrentTrain: epoch  0, batch    67 | loss: 138.5288797CurrentTrain: epoch  0, batch    68 | loss: 110.3784742CurrentTrain: epoch  0, batch    69 | loss: 80.9522074CurrentTrain: epoch  0, batch    70 | loss: 77.7194145CurrentTrain: epoch  0, batch    71 | loss: 80.5629103CurrentTrain: epoch  0, batch    72 | loss: 115.3387224CurrentTrain: epoch  0, batch    73 | loss: 95.7141663CurrentTrain: epoch  0, batch    74 | loss: 77.3383434CurrentTrain: epoch  0, batch    75 | loss: 92.6872527CurrentTrain: epoch  0, batch    76 | loss: 70.6337917CurrentTrain: epoch  0, batch    77 | loss: 94.2085604CurrentTrain: epoch  0, batch    78 | loss: 81.3372436CurrentTrain: epoch  0, batch    79 | loss: 114.3428057CurrentTrain: epoch  0, batch    80 | loss: 93.9670718CurrentTrain: epoch  0, batch    81 | loss: 94.0890120CurrentTrain: epoch  0, batch    82 | loss: 81.6610464CurrentTrain: epoch  0, batch    83 | loss: 89.9698610CurrentTrain: epoch  0, batch    84 | loss: 110.9700359CurrentTrain: epoch  0, batch    85 | loss: 92.3889012CurrentTrain: epoch  0, batch    86 | loss: 90.8366630CurrentTrain: epoch  0, batch    87 | loss: 110.7015340CurrentTrain: epoch  0, batch    88 | loss: 93.8773084CurrentTrain: epoch  0, batch    89 | loss: 110.3744359CurrentTrain: epoch  0, batch    90 | loss: 92.2852475CurrentTrain: epoch  0, batch    91 | loss: 78.2317009CurrentTrain: epoch  0, batch    92 | loss: 79.8553420CurrentTrain: epoch  0, batch    93 | loss: 94.4087650CurrentTrain: epoch  0, batch    94 | loss: 91.6822695CurrentTrain: epoch  0, batch    95 | loss: 117.4938825CurrentTrain: epoch  1, batch     0 | loss: 79.0053691CurrentTrain: epoch  1, batch     1 | loss: 78.3722691CurrentTrain: epoch  1, batch     2 | loss: 110.6205247CurrentTrain: epoch  1, batch     3 | loss: 80.4223671CurrentTrain: epoch  1, batch     4 | loss: 76.1336687CurrentTrain: epoch  1, batch     5 | loss: 106.3970785CurrentTrain: epoch  1, batch     6 | loss: 93.4530607CurrentTrain: epoch  1, batch     7 | loss: 76.1796647CurrentTrain: epoch  1, batch     8 | loss: 80.6576075CurrentTrain: epoch  1, batch     9 | loss: 94.4336069CurrentTrain: epoch  1, batch    10 | loss: 108.2304782CurrentTrain: epoch  1, batch    11 | loss: 112.4656934CurrentTrain: epoch  1, batch    12 | loss: 108.4333931CurrentTrain: epoch  1, batch    13 | loss: 110.8538016CurrentTrain: epoch  1, batch    14 | loss: 91.7678395CurrentTrain: epoch  1, batch    15 | loss: 142.8893692CurrentTrain: epoch  1, batch    16 | loss: 89.9369042CurrentTrain: epoch  1, batch    17 | loss: 102.6410321CurrentTrain: epoch  1, batch    18 | loss: 106.5681259CurrentTrain: epoch  1, batch    19 | loss: 88.4769860CurrentTrain: epoch  1, batch    20 | loss: 187.0725751CurrentTrain: epoch  1, batch    21 | loss: 108.9051789CurrentTrain: epoch  1, batch    22 | loss: 93.0882727CurrentTrain: epoch  1, batch    23 | loss: 104.2550842CurrentTrain: epoch  1, batch    24 | loss: 107.7929487CurrentTrain: epoch  1, batch    25 | loss: 89.1443978CurrentTrain: epoch  1, batch    26 | loss: 81.2923628CurrentTrain: epoch  1, batch    27 | loss: 66.6404492CurrentTrain: epoch  1, batch    28 | loss: 109.2324113CurrentTrain: epoch  1, batch    29 | loss: 75.5721793CurrentTrain: epoch  1, batch    30 | loss: 76.9813687CurrentTrain: epoch  1, batch    31 | loss: 89.2786807CurrentTrain: epoch  1, batch    32 | loss: 67.7718103CurrentTrain: epoch  1, batch    33 | loss: 76.9506086CurrentTrain: epoch  1, batch    34 | loss: 89.4290328CurrentTrain: epoch  1, batch    35 | loss: 92.1831996CurrentTrain: epoch  1, batch    36 | loss: 89.8244906CurrentTrain: epoch  1, batch    37 | loss: 77.9524609CurrentTrain: epoch  1, batch    38 | loss: 67.7175136CurrentTrain: epoch  1, batch    39 | loss: 73.7045007CurrentTrain: epoch  1, batch    40 | loss: 84.5539444CurrentTrain: epoch  1, batch    41 | loss: 109.9992420CurrentTrain: epoch  1, batch    42 | loss: 82.9437366CurrentTrain: epoch  1, batch    43 | loss: 108.7968170CurrentTrain: epoch  1, batch    44 | loss: 74.9477671CurrentTrain: epoch  1, batch    45 | loss: 108.7224454CurrentTrain: epoch  1, batch    46 | loss: 68.2934158CurrentTrain: epoch  1, batch    47 | loss: 75.8773412CurrentTrain: epoch  1, batch    48 | loss: 91.9373448CurrentTrain: epoch  1, batch    49 | loss: 107.7953660CurrentTrain: epoch  1, batch    50 | loss: 71.8369161CurrentTrain: epoch  1, batch    51 | loss: 74.4509692CurrentTrain: epoch  1, batch    52 | loss: 109.4860194CurrentTrain: epoch  1, batch    53 | loss: 107.4282327CurrentTrain: epoch  1, batch    54 | loss: 86.6416473CurrentTrain: epoch  1, batch    55 | loss: 138.1672257CurrentTrain: epoch  1, batch    56 | loss: 91.6046542CurrentTrain: epoch  1, batch    57 | loss: 111.3078041CurrentTrain: epoch  1, batch    58 | loss: 183.7755888CurrentTrain: epoch  1, batch    59 | loss: 90.8127073CurrentTrain: epoch  1, batch    60 | loss: 109.5557963CurrentTrain: epoch  1, batch    61 | loss: 64.7404781CurrentTrain: epoch  1, batch    62 | loss: 77.4669160CurrentTrain: epoch  1, batch    63 | loss: 106.4965246CurrentTrain: epoch  1, batch    64 | loss: 90.4449268CurrentTrain: epoch  1, batch    65 | loss: 102.5757488CurrentTrain: epoch  1, batch    66 | loss: 72.5010656CurrentTrain: epoch  1, batch    67 | loss: 84.3120993CurrentTrain: epoch  1, batch    68 | loss: 133.8334630CurrentTrain: epoch  1, batch    69 | loss: 92.9500146CurrentTrain: epoch  1, batch    70 | loss: 89.6879747CurrentTrain: epoch  1, batch    71 | loss: 99.3713908CurrentTrain: epoch  1, batch    72 | loss: 86.7143385CurrentTrain: epoch  1, batch    73 | loss: 75.4362082CurrentTrain: epoch  1, batch    74 | loss: 106.8743006CurrentTrain: epoch  1, batch    75 | loss: 87.0854150CurrentTrain: epoch  1, batch    76 | loss: 108.4567999CurrentTrain: epoch  1, batch    77 | loss: 101.5800428CurrentTrain: epoch  1, batch    78 | loss: 78.2606744CurrentTrain: epoch  1, batch    79 | loss: 90.9529199CurrentTrain: epoch  1, batch    80 | loss: 85.3279336CurrentTrain: epoch  1, batch    81 | loss: 109.4323095CurrentTrain: epoch  1, batch    82 | loss: 68.2510400CurrentTrain: epoch  1, batch    83 | loss: 106.0836518CurrentTrain: epoch  1, batch    84 | loss: 89.6809107CurrentTrain: epoch  1, batch    85 | loss: 137.8329822CurrentTrain: epoch  1, batch    86 | loss: 72.6305707CurrentTrain: epoch  1, batch    87 | loss: 63.0801657CurrentTrain: epoch  1, batch    88 | loss: 106.5369347CurrentTrain: epoch  1, batch    89 | loss: 136.5143657CurrentTrain: epoch  1, batch    90 | loss: 87.8914159CurrentTrain: epoch  1, batch    91 | loss: 88.1994138CurrentTrain: epoch  1, batch    92 | loss: 76.1215051CurrentTrain: epoch  1, batch    93 | loss: 74.9848742CurrentTrain: epoch  1, batch    94 | loss: 73.0665238CurrentTrain: epoch  1, batch    95 | loss: 75.1636921CurrentTrain: epoch  2, batch     0 | loss: 86.3200747CurrentTrain: epoch  2, batch     1 | loss: 88.7471266CurrentTrain: epoch  2, batch     2 | loss: 80.3982990CurrentTrain: epoch  2, batch     3 | loss: 62.5178249CurrentTrain: epoch  2, batch     4 | loss: 131.3721809CurrentTrain: epoch  2, batch     5 | loss: 71.7642298CurrentTrain: epoch  2, batch     6 | loss: 61.3897089CurrentTrain: epoch  2, batch     7 | loss: 102.4907699CurrentTrain: epoch  2, batch     8 | loss: 87.1959852CurrentTrain: epoch  2, batch     9 | loss: 107.3845978CurrentTrain: epoch  2, batch    10 | loss: 82.7296808CurrentTrain: epoch  2, batch    11 | loss: 106.9564955CurrentTrain: epoch  2, batch    12 | loss: 138.0692406CurrentTrain: epoch  2, batch    13 | loss: 134.4552719CurrentTrain: epoch  2, batch    14 | loss: 86.5033976CurrentTrain: epoch  2, batch    15 | loss: 102.8139606CurrentTrain: epoch  2, batch    16 | loss: 102.9826583CurrentTrain: epoch  2, batch    17 | loss: 73.7232956CurrentTrain: epoch  2, batch    18 | loss: 86.1910533CurrentTrain: epoch  2, batch    19 | loss: 104.6593161CurrentTrain: epoch  2, batch    20 | loss: 178.3141084CurrentTrain: epoch  2, batch    21 | loss: 101.9716923CurrentTrain: epoch  2, batch    22 | loss: 106.4162263CurrentTrain: epoch  2, batch    23 | loss: 137.9227605CurrentTrain: epoch  2, batch    24 | loss: 103.5461598CurrentTrain: epoch  2, batch    25 | loss: 65.3048196CurrentTrain: epoch  2, batch    26 | loss: 89.0027676CurrentTrain: epoch  2, batch    27 | loss: 72.1159208CurrentTrain: epoch  2, batch    28 | loss: 91.2429108CurrentTrain: epoch  2, batch    29 | loss: 82.1306149CurrentTrain: epoch  2, batch    30 | loss: 132.6124012CurrentTrain: epoch  2, batch    31 | loss: 81.3996487CurrentTrain: epoch  2, batch    32 | loss: 87.6782808CurrentTrain: epoch  2, batch    33 | loss: 72.8589997CurrentTrain: epoch  2, batch    34 | loss: 89.0857501CurrentTrain: epoch  2, batch    35 | loss: 74.0362955CurrentTrain: epoch  2, batch    36 | loss: 73.6568937CurrentTrain: epoch  2, batch    37 | loss: 86.9367882CurrentTrain: epoch  2, batch    38 | loss: 87.2274486CurrentTrain: epoch  2, batch    39 | loss: 136.8564874CurrentTrain: epoch  2, batch    40 | loss: 104.6656182CurrentTrain: epoch  2, batch    41 | loss: 106.7959778CurrentTrain: epoch  2, batch    42 | loss: 88.0466062CurrentTrain: epoch  2, batch    43 | loss: 71.4057329CurrentTrain: epoch  2, batch    44 | loss: 103.8249909CurrentTrain: epoch  2, batch    45 | loss: 132.1553877CurrentTrain: epoch  2, batch    46 | loss: 85.9238395CurrentTrain: epoch  2, batch    47 | loss: 82.4071232CurrentTrain: epoch  2, batch    48 | loss: 85.7055538CurrentTrain: epoch  2, batch    49 | loss: 178.8568876CurrentTrain: epoch  2, batch    50 | loss: 101.4524011CurrentTrain: epoch  2, batch    51 | loss: 104.4147409CurrentTrain: epoch  2, batch    52 | loss: 88.8311794CurrentTrain: epoch  2, batch    53 | loss: 87.4538346CurrentTrain: epoch  2, batch    54 | loss: 72.2215078CurrentTrain: epoch  2, batch    55 | loss: 85.8019672CurrentTrain: epoch  2, batch    56 | loss: 66.6278052CurrentTrain: epoch  2, batch    57 | loss: 134.9563455CurrentTrain: epoch  2, batch    58 | loss: 100.8612618CurrentTrain: epoch  2, batch    59 | loss: 75.1130442CurrentTrain: epoch  2, batch    60 | loss: 89.0933530CurrentTrain: epoch  2, batch    61 | loss: 84.2527263CurrentTrain: epoch  2, batch    62 | loss: 74.7968188CurrentTrain: epoch  2, batch    63 | loss: 85.6179447CurrentTrain: epoch  2, batch    64 | loss: 103.2693794CurrentTrain: epoch  2, batch    65 | loss: 86.6523971CurrentTrain: epoch  2, batch    66 | loss: 70.4112745CurrentTrain: epoch  2, batch    67 | loss: 84.2985325CurrentTrain: epoch  2, batch    68 | loss: 94.4931142CurrentTrain: epoch  2, batch    69 | loss: 108.7928734CurrentTrain: epoch  2, batch    70 | loss: 84.7045818CurrentTrain: epoch  2, batch    71 | loss: 136.5502311CurrentTrain: epoch  2, batch    72 | loss: 131.6253243CurrentTrain: epoch  2, batch    73 | loss: 84.6414428CurrentTrain: epoch  2, batch    74 | loss: 91.5125832CurrentTrain: epoch  2, batch    75 | loss: 91.6692469CurrentTrain: epoch  2, batch    76 | loss: 74.4582881CurrentTrain: epoch  2, batch    77 | loss: 87.7492161CurrentTrain: epoch  2, batch    78 | loss: 84.9809446CurrentTrain: epoch  2, batch    79 | loss: 88.3504417CurrentTrain: epoch  2, batch    80 | loss: 81.1975552CurrentTrain: epoch  2, batch    81 | loss: 71.2534299CurrentTrain: epoch  2, batch    82 | loss: 103.9139286CurrentTrain: epoch  2, batch    83 | loss: 73.9272513CurrentTrain: epoch  2, batch    84 | loss: 86.6393170CurrentTrain: epoch  2, batch    85 | loss: 72.7129159CurrentTrain: epoch  2, batch    86 | loss: 85.0917126CurrentTrain: epoch  2, batch    87 | loss: 83.4815349CurrentTrain: epoch  2, batch    88 | loss: 101.5551177CurrentTrain: epoch  2, batch    89 | loss: 58.1352782CurrentTrain: epoch  2, batch    90 | loss: 103.8689801CurrentTrain: epoch  2, batch    91 | loss: 70.2682003CurrentTrain: epoch  2, batch    92 | loss: 83.2775780CurrentTrain: epoch  2, batch    93 | loss: 81.0491024CurrentTrain: epoch  2, batch    94 | loss: 180.4709344CurrentTrain: epoch  2, batch    95 | loss: 60.3696128CurrentTrain: epoch  3, batch     0 | loss: 86.6417746CurrentTrain: epoch  3, batch     1 | loss: 71.6250953CurrentTrain: epoch  3, batch     2 | loss: 136.6550493CurrentTrain: epoch  3, batch     3 | loss: 59.5350925CurrentTrain: epoch  3, batch     4 | loss: 63.7069006CurrentTrain: epoch  3, batch     5 | loss: 106.1176573CurrentTrain: epoch  3, batch     6 | loss: 71.2590977CurrentTrain: epoch  3, batch     7 | loss: 102.3547549CurrentTrain: epoch  3, batch     8 | loss: 104.7769791CurrentTrain: epoch  3, batch     9 | loss: 102.2519582CurrentTrain: epoch  3, batch    10 | loss: 84.6724077CurrentTrain: epoch  3, batch    11 | loss: 85.3937191CurrentTrain: epoch  3, batch    12 | loss: 63.1379908CurrentTrain: epoch  3, batch    13 | loss: 132.0327574CurrentTrain: epoch  3, batch    14 | loss: 132.4467583CurrentTrain: epoch  3, batch    15 | loss: 71.7540031CurrentTrain: epoch  3, batch    16 | loss: 100.7393539CurrentTrain: epoch  3, batch    17 | loss: 105.4538562CurrentTrain: epoch  3, batch    18 | loss: 85.2006974CurrentTrain: epoch  3, batch    19 | loss: 99.9110441CurrentTrain: epoch  3, batch    20 | loss: 70.2151019CurrentTrain: epoch  3, batch    21 | loss: 99.4435060CurrentTrain: epoch  3, batch    22 | loss: 103.0131497CurrentTrain: epoch  3, batch    23 | loss: 103.0851859CurrentTrain: epoch  3, batch    24 | loss: 103.0502520CurrentTrain: epoch  3, batch    25 | loss: 90.1550434CurrentTrain: epoch  3, batch    26 | loss: 83.3159725CurrentTrain: epoch  3, batch    27 | loss: 88.9647112CurrentTrain: epoch  3, batch    28 | loss: 66.7032103CurrentTrain: epoch  3, batch    29 | loss: 103.5168210CurrentTrain: epoch  3, batch    30 | loss: 130.8813944CurrentTrain: epoch  3, batch    31 | loss: 62.3470265CurrentTrain: epoch  3, batch    32 | loss: 103.5073193CurrentTrain: epoch  3, batch    33 | loss: 81.6478935CurrentTrain: epoch  3, batch    34 | loss: 100.2379793CurrentTrain: epoch  3, batch    35 | loss: 76.5680805CurrentTrain: epoch  3, batch    36 | loss: 70.1892671CurrentTrain: epoch  3, batch    37 | loss: 71.3146612CurrentTrain: epoch  3, batch    38 | loss: 100.9964771CurrentTrain: epoch  3, batch    39 | loss: 58.9811951CurrentTrain: epoch  3, batch    40 | loss: 70.9020556CurrentTrain: epoch  3, batch    41 | loss: 84.8995997CurrentTrain: epoch  3, batch    42 | loss: 70.3923341CurrentTrain: epoch  3, batch    43 | loss: 106.4643870CurrentTrain: epoch  3, batch    44 | loss: 100.2093223CurrentTrain: epoch  3, batch    45 | loss: 106.8843200CurrentTrain: epoch  3, batch    46 | loss: 60.6815714CurrentTrain: epoch  3, batch    47 | loss: 64.0537689CurrentTrain: epoch  3, batch    48 | loss: 75.1933854CurrentTrain: epoch  3, batch    49 | loss: 69.1125451CurrentTrain: epoch  3, batch    50 | loss: 62.6060276CurrentTrain: epoch  3, batch    51 | loss: 72.3072528CurrentTrain: epoch  3, batch    52 | loss: 66.8850051CurrentTrain: epoch  3, batch    53 | loss: 82.2110864CurrentTrain: epoch  3, batch    54 | loss: 84.9117260CurrentTrain: epoch  3, batch    55 | loss: 60.7969994CurrentTrain: epoch  3, batch    56 | loss: 81.8101016CurrentTrain: epoch  3, batch    57 | loss: 97.5581510CurrentTrain: epoch  3, batch    58 | loss: 104.7406416CurrentTrain: epoch  3, batch    59 | loss: 88.9514383CurrentTrain: epoch  3, batch    60 | loss: 81.1401964CurrentTrain: epoch  3, batch    61 | loss: 68.8824544CurrentTrain: epoch  3, batch    62 | loss: 72.7718577CurrentTrain: epoch  3, batch    63 | loss: 138.9160308CurrentTrain: epoch  3, batch    64 | loss: 69.9927005CurrentTrain: epoch  3, batch    65 | loss: 128.6688609CurrentTrain: epoch  3, batch    66 | loss: 127.6266240CurrentTrain: epoch  3, batch    67 | loss: 85.8532848CurrentTrain: epoch  3, batch    68 | loss: 73.3721553CurrentTrain: epoch  3, batch    69 | loss: 86.7945725CurrentTrain: epoch  3, batch    70 | loss: 101.8787914CurrentTrain: epoch  3, batch    71 | loss: 100.7997090CurrentTrain: epoch  3, batch    72 | loss: 80.7987978CurrentTrain: epoch  3, batch    73 | loss: 70.2538415CurrentTrain: epoch  3, batch    74 | loss: 87.2265954CurrentTrain: epoch  3, batch    75 | loss: 103.0744548CurrentTrain: epoch  3, batch    76 | loss: 69.6275936CurrentTrain: epoch  3, batch    77 | loss: 69.5560827CurrentTrain: epoch  3, batch    78 | loss: 104.1605693CurrentTrain: epoch  3, batch    79 | loss: 85.1725497CurrentTrain: epoch  3, batch    80 | loss: 104.6645878CurrentTrain: epoch  3, batch    81 | loss: 72.7206062CurrentTrain: epoch  3, batch    82 | loss: 73.9867693CurrentTrain: epoch  3, batch    83 | loss: 74.7045606CurrentTrain: epoch  3, batch    84 | loss: 70.5383701CurrentTrain: epoch  3, batch    85 | loss: 105.1203585CurrentTrain: epoch  3, batch    86 | loss: 63.4831255CurrentTrain: epoch  3, batch    87 | loss: 87.4429941CurrentTrain: epoch  3, batch    88 | loss: 126.9053226CurrentTrain: epoch  3, batch    89 | loss: 86.4484240CurrentTrain: epoch  3, batch    90 | loss: 70.7730087CurrentTrain: epoch  3, batch    91 | loss: 71.3267247CurrentTrain: epoch  3, batch    92 | loss: 72.5989040CurrentTrain: epoch  3, batch    93 | loss: 69.6391170CurrentTrain: epoch  3, batch    94 | loss: 106.4903879CurrentTrain: epoch  3, batch    95 | loss: 67.3749317CurrentTrain: epoch  4, batch     0 | loss: 67.3083804CurrentTrain: epoch  4, batch     1 | loss: 102.1100656CurrentTrain: epoch  4, batch     2 | loss: 69.0477815CurrentTrain: epoch  4, batch     3 | loss: 85.5260515CurrentTrain: epoch  4, batch     4 | loss: 61.2841179CurrentTrain: epoch  4, batch     5 | loss: 69.0918123CurrentTrain: epoch  4, batch     6 | loss: 85.4970273CurrentTrain: epoch  4, batch     7 | loss: 80.8703153CurrentTrain: epoch  4, batch     8 | loss: 69.8439244CurrentTrain: epoch  4, batch     9 | loss: 75.5506538CurrentTrain: epoch  4, batch    10 | loss: 73.5400167CurrentTrain: epoch  4, batch    11 | loss: 78.1881035CurrentTrain: epoch  4, batch    12 | loss: 73.9636134CurrentTrain: epoch  4, batch    13 | loss: 127.4786469CurrentTrain: epoch  4, batch    14 | loss: 102.5672020CurrentTrain: epoch  4, batch    15 | loss: 85.8758244CurrentTrain: epoch  4, batch    16 | loss: 80.8762120CurrentTrain: epoch  4, batch    17 | loss: 85.1326849CurrentTrain: epoch  4, batch    18 | loss: 99.6188382CurrentTrain: epoch  4, batch    19 | loss: 127.7709924CurrentTrain: epoch  4, batch    20 | loss: 80.1717858CurrentTrain: epoch  4, batch    21 | loss: 126.7187596CurrentTrain: epoch  4, batch    22 | loss: 71.7975086CurrentTrain: epoch  4, batch    23 | loss: 86.9876359CurrentTrain: epoch  4, batch    24 | loss: 82.0983775CurrentTrain: epoch  4, batch    25 | loss: 69.2521186CurrentTrain: epoch  4, batch    26 | loss: 76.0787274CurrentTrain: epoch  4, batch    27 | loss: 83.3185486CurrentTrain: epoch  4, batch    28 | loss: 104.1547673CurrentTrain: epoch  4, batch    29 | loss: 67.6174396CurrentTrain: epoch  4, batch    30 | loss: 93.3663181CurrentTrain: epoch  4, batch    31 | loss: 72.5322462CurrentTrain: epoch  4, batch    32 | loss: 100.4253724CurrentTrain: epoch  4, batch    33 | loss: 62.5170388CurrentTrain: epoch  4, batch    34 | loss: 96.8822644CurrentTrain: epoch  4, batch    35 | loss: 89.0840660CurrentTrain: epoch  4, batch    36 | loss: 127.9669447CurrentTrain: epoch  4, batch    37 | loss: 104.3717134CurrentTrain: epoch  4, batch    38 | loss: 103.2773442CurrentTrain: epoch  4, batch    39 | loss: 99.7841709CurrentTrain: epoch  4, batch    40 | loss: 85.1691103CurrentTrain: epoch  4, batch    41 | loss: 82.1349888CurrentTrain: epoch  4, batch    42 | loss: 96.7827252CurrentTrain: epoch  4, batch    43 | loss: 103.6440332CurrentTrain: epoch  4, batch    44 | loss: 132.9781877CurrentTrain: epoch  4, batch    45 | loss: 83.0087023CurrentTrain: epoch  4, batch    46 | loss: 82.3875000CurrentTrain: epoch  4, batch    47 | loss: 105.0715820CurrentTrain: epoch  4, batch    48 | loss: 128.8610355CurrentTrain: epoch  4, batch    49 | loss: 82.1517681CurrentTrain: epoch  4, batch    50 | loss: 91.9313016CurrentTrain: epoch  4, batch    51 | loss: 125.7812609CurrentTrain: epoch  4, batch    52 | loss: 83.7721585CurrentTrain: epoch  4, batch    53 | loss: 69.1583037CurrentTrain: epoch  4, batch    54 | loss: 62.8346509CurrentTrain: epoch  4, batch    55 | loss: 101.9726085CurrentTrain: epoch  4, batch    56 | loss: 80.2346051CurrentTrain: epoch  4, batch    57 | loss: 74.2525092CurrentTrain: epoch  4, batch    58 | loss: 67.6047988CurrentTrain: epoch  4, batch    59 | loss: 101.1339440CurrentTrain: epoch  4, batch    60 | loss: 73.3539978CurrentTrain: epoch  4, batch    61 | loss: 83.8090144CurrentTrain: epoch  4, batch    62 | loss: 82.0988090CurrentTrain: epoch  4, batch    63 | loss: 80.6980143CurrentTrain: epoch  4, batch    64 | loss: 70.6360204CurrentTrain: epoch  4, batch    65 | loss: 69.3111104CurrentTrain: epoch  4, batch    66 | loss: 100.1802933CurrentTrain: epoch  4, batch    67 | loss: 82.1106741CurrentTrain: epoch  4, batch    68 | loss: 60.2386876CurrentTrain: epoch  4, batch    69 | loss: 127.9924081CurrentTrain: epoch  4, batch    70 | loss: 80.8290495CurrentTrain: epoch  4, batch    71 | loss: 127.9308971CurrentTrain: epoch  4, batch    72 | loss: 59.1677264CurrentTrain: epoch  4, batch    73 | loss: 126.7796735CurrentTrain: epoch  4, batch    74 | loss: 61.3541573CurrentTrain: epoch  4, batch    75 | loss: 72.4352986CurrentTrain: epoch  4, batch    76 | loss: 68.7676276CurrentTrain: epoch  4, batch    77 | loss: 107.0546277CurrentTrain: epoch  4, batch    78 | loss: 104.5700601CurrentTrain: epoch  4, batch    79 | loss: 83.2924832CurrentTrain: epoch  4, batch    80 | loss: 75.4782541CurrentTrain: epoch  4, batch    81 | loss: 103.8330531CurrentTrain: epoch  4, batch    82 | loss: 77.9953490CurrentTrain: epoch  4, batch    83 | loss: 102.3847381CurrentTrain: epoch  4, batch    84 | loss: 70.5801831CurrentTrain: epoch  4, batch    85 | loss: 99.2188374CurrentTrain: epoch  4, batch    86 | loss: 103.8001946CurrentTrain: epoch  4, batch    87 | loss: 99.2916517CurrentTrain: epoch  4, batch    88 | loss: 100.8494763CurrentTrain: epoch  4, batch    89 | loss: 100.1391143CurrentTrain: epoch  4, batch    90 | loss: 99.0242726CurrentTrain: epoch  4, batch    91 | loss: 85.5623821CurrentTrain: epoch  4, batch    92 | loss: 101.5477955CurrentTrain: epoch  4, batch    93 | loss: 67.2573757CurrentTrain: epoch  4, batch    94 | loss: 71.3013094CurrentTrain: epoch  4, batch    95 | loss: 66.7568735CurrentTrain: epoch  5, batch     0 | loss: 100.3715899CurrentTrain: epoch  5, batch     1 | loss: 69.1227368CurrentTrain: epoch  5, batch     2 | loss: 97.4335996CurrentTrain: epoch  5, batch     3 | loss: 120.6951829CurrentTrain: epoch  5, batch     4 | loss: 69.5030357CurrentTrain: epoch  5, batch     5 | loss: 94.8148924CurrentTrain: epoch  5, batch     6 | loss: 99.9374154CurrentTrain: epoch  5, batch     7 | loss: 82.5327554CurrentTrain: epoch  5, batch     8 | loss: 66.3141766CurrentTrain: epoch  5, batch     9 | loss: 58.3948406CurrentTrain: epoch  5, batch    10 | loss: 100.6958778CurrentTrain: epoch  5, batch    11 | loss: 99.1316839CurrentTrain: epoch  5, batch    12 | loss: 65.7858294CurrentTrain: epoch  5, batch    13 | loss: 95.5096013CurrentTrain: epoch  5, batch    14 | loss: 103.4499446CurrentTrain: epoch  5, batch    15 | loss: 68.1515209CurrentTrain: epoch  5, batch    16 | loss: 127.6104554CurrentTrain: epoch  5, batch    17 | loss: 78.8666372CurrentTrain: epoch  5, batch    18 | loss: 96.4212393CurrentTrain: epoch  5, batch    19 | loss: 104.2786009CurrentTrain: epoch  5, batch    20 | loss: 84.1008145CurrentTrain: epoch  5, batch    21 | loss: 79.0089006CurrentTrain: epoch  5, batch    22 | loss: 83.9782779CurrentTrain: epoch  5, batch    23 | loss: 80.7117386CurrentTrain: epoch  5, batch    24 | loss: 67.6719685CurrentTrain: epoch  5, batch    25 | loss: 99.9697935CurrentTrain: epoch  5, batch    26 | loss: 78.5185293CurrentTrain: epoch  5, batch    27 | loss: 66.4215895CurrentTrain: epoch  5, batch    28 | loss: 127.9779568CurrentTrain: epoch  5, batch    29 | loss: 71.0577348CurrentTrain: epoch  5, batch    30 | loss: 92.3296981CurrentTrain: epoch  5, batch    31 | loss: 80.7580021CurrentTrain: epoch  5, batch    32 | loss: 71.5053329CurrentTrain: epoch  5, batch    33 | loss: 91.2666051CurrentTrain: epoch  5, batch    34 | loss: 97.9563134CurrentTrain: epoch  5, batch    35 | loss: 56.7151962CurrentTrain: epoch  5, batch    36 | loss: 68.3340306CurrentTrain: epoch  5, batch    37 | loss: 127.6173326CurrentTrain: epoch  5, batch    38 | loss: 80.1491776CurrentTrain: epoch  5, batch    39 | loss: 64.1037778CurrentTrain: epoch  5, batch    40 | loss: 130.0450252CurrentTrain: epoch  5, batch    41 | loss: 80.8990492CurrentTrain: epoch  5, batch    42 | loss: 82.7980481CurrentTrain: epoch  5, batch    43 | loss: 65.8522078CurrentTrain: epoch  5, batch    44 | loss: 99.5057451CurrentTrain: epoch  5, batch    45 | loss: 78.7821334CurrentTrain: epoch  5, batch    46 | loss: 70.3863945CurrentTrain: epoch  5, batch    47 | loss: 69.3809800CurrentTrain: epoch  5, batch    48 | loss: 105.2013708CurrentTrain: epoch  5, batch    49 | loss: 55.0215378CurrentTrain: epoch  5, batch    50 | loss: 95.2207033CurrentTrain: epoch  5, batch    51 | loss: 72.7789041CurrentTrain: epoch  5, batch    52 | loss: 83.4839434CurrentTrain: epoch  5, batch    53 | loss: 83.4424987CurrentTrain: epoch  5, batch    54 | loss: 83.7435484CurrentTrain: epoch  5, batch    55 | loss: 123.6928120CurrentTrain: epoch  5, batch    56 | loss: 177.5625988CurrentTrain: epoch  5, batch    57 | loss: 68.7028214CurrentTrain: epoch  5, batch    58 | loss: 82.6985216CurrentTrain: epoch  5, batch    59 | loss: 84.2072468CurrentTrain: epoch  5, batch    60 | loss: 64.6086748CurrentTrain: epoch  5, batch    61 | loss: 98.4763716CurrentTrain: epoch  5, batch    62 | loss: 98.1483920CurrentTrain: epoch  5, batch    63 | loss: 68.1092786CurrentTrain: epoch  5, batch    64 | loss: 79.9230753CurrentTrain: epoch  5, batch    65 | loss: 170.9068129CurrentTrain: epoch  5, batch    66 | loss: 81.2120008CurrentTrain: epoch  5, batch    67 | loss: 101.2562373CurrentTrain: epoch  5, batch    68 | loss: 67.0398520CurrentTrain: epoch  5, batch    69 | loss: 81.4344595CurrentTrain: epoch  5, batch    70 | loss: 74.2023844CurrentTrain: epoch  5, batch    71 | loss: 173.1811131CurrentTrain: epoch  5, batch    72 | loss: 58.1956108CurrentTrain: epoch  5, batch    73 | loss: 99.3365603CurrentTrain: epoch  5, batch    74 | loss: 71.1269671CurrentTrain: epoch  5, batch    75 | loss: 71.2795385CurrentTrain: epoch  5, batch    76 | loss: 69.8807951CurrentTrain: epoch  5, batch    77 | loss: 67.3164303CurrentTrain: epoch  5, batch    78 | loss: 71.0266853CurrentTrain: epoch  5, batch    79 | loss: 59.1709594CurrentTrain: epoch  5, batch    80 | loss: 94.2406073CurrentTrain: epoch  5, batch    81 | loss: 72.0012769CurrentTrain: epoch  5, batch    82 | loss: 77.7245613CurrentTrain: epoch  5, batch    83 | loss: 71.0886294CurrentTrain: epoch  5, batch    84 | loss: 97.8693307CurrentTrain: epoch  5, batch    85 | loss: 102.6445024CurrentTrain: epoch  5, batch    86 | loss: 84.0293588CurrentTrain: epoch  5, batch    87 | loss: 85.7406525CurrentTrain: epoch  5, batch    88 | loss: 83.5194925CurrentTrain: epoch  5, batch    89 | loss: 80.1851657CurrentTrain: epoch  5, batch    90 | loss: 82.3279231CurrentTrain: epoch  5, batch    91 | loss: 101.0435660CurrentTrain: epoch  5, batch    92 | loss: 84.6140071CurrentTrain: epoch  5, batch    93 | loss: 71.6640683CurrentTrain: epoch  5, batch    94 | loss: 99.2591457CurrentTrain: epoch  5, batch    95 | loss: 69.0643933CurrentTrain: epoch  6, batch     0 | loss: 100.8439382CurrentTrain: epoch  6, batch     1 | loss: 75.7272534CurrentTrain: epoch  6, batch     2 | loss: 82.6494149CurrentTrain: epoch  6, batch     3 | loss: 77.8900655CurrentTrain: epoch  6, batch     4 | loss: 79.5468958CurrentTrain: epoch  6, batch     5 | loss: 98.1061393CurrentTrain: epoch  6, batch     6 | loss: 84.2058093CurrentTrain: epoch  6, batch     7 | loss: 80.6235969CurrentTrain: epoch  6, batch     8 | loss: 99.0393044CurrentTrain: epoch  6, batch     9 | loss: 120.1321859CurrentTrain: epoch  6, batch    10 | loss: 79.4426278CurrentTrain: epoch  6, batch    11 | loss: 103.2115988CurrentTrain: epoch  6, batch    12 | loss: 80.4767198CurrentTrain: epoch  6, batch    13 | loss: 80.6940776CurrentTrain: epoch  6, batch    14 | loss: 63.8611290CurrentTrain: epoch  6, batch    15 | loss: 121.9166394CurrentTrain: epoch  6, batch    16 | loss: 94.8092202CurrentTrain: epoch  6, batch    17 | loss: 120.7293122CurrentTrain: epoch  6, batch    18 | loss: 131.0741287CurrentTrain: epoch  6, batch    19 | loss: 69.6873171CurrentTrain: epoch  6, batch    20 | loss: 175.5600015CurrentTrain: epoch  6, batch    21 | loss: 82.7312713CurrentTrain: epoch  6, batch    22 | loss: 77.5328228CurrentTrain: epoch  6, batch    23 | loss: 99.8730702CurrentTrain: epoch  6, batch    24 | loss: 65.2133869CurrentTrain: epoch  6, batch    25 | loss: 100.3806475CurrentTrain: epoch  6, batch    26 | loss: 66.5909310CurrentTrain: epoch  6, batch    27 | loss: 62.9832990CurrentTrain: epoch  6, batch    28 | loss: 78.6904411CurrentTrain: epoch  6, batch    29 | loss: 125.5613294CurrentTrain: epoch  6, batch    30 | loss: 70.4113509CurrentTrain: epoch  6, batch    31 | loss: 67.8443715CurrentTrain: epoch  6, batch    32 | loss: 68.4288686CurrentTrain: epoch  6, batch    33 | loss: 126.2831588CurrentTrain: epoch  6, batch    34 | loss: 83.0734504CurrentTrain: epoch  6, batch    35 | loss: 66.7916475CurrentTrain: epoch  6, batch    36 | loss: 100.1565518CurrentTrain: epoch  6, batch    37 | loss: 122.8187254CurrentTrain: epoch  6, batch    38 | loss: 99.7435259CurrentTrain: epoch  6, batch    39 | loss: 68.9051967CurrentTrain: epoch  6, batch    40 | loss: 97.2554116CurrentTrain: epoch  6, batch    41 | loss: 100.1681742CurrentTrain: epoch  6, batch    42 | loss: 58.6071263CurrentTrain: epoch  6, batch    43 | loss: 77.9092863CurrentTrain: epoch  6, batch    44 | loss: 78.0598830CurrentTrain: epoch  6, batch    45 | loss: 56.2964890CurrentTrain: epoch  6, batch    46 | loss: 69.8524384CurrentTrain: epoch  6, batch    47 | loss: 77.6764649CurrentTrain: epoch  6, batch    48 | loss: 67.2507758CurrentTrain: epoch  6, batch    49 | loss: 123.2950534CurrentTrain: epoch  6, batch    50 | loss: 119.6986785CurrentTrain: epoch  6, batch    51 | loss: 59.5766028CurrentTrain: epoch  6, batch    52 | loss: 65.3399989CurrentTrain: epoch  6, batch    53 | loss: 67.1877997CurrentTrain: epoch  6, batch    54 | loss: 81.8120472CurrentTrain: epoch  6, batch    55 | loss: 123.6606842CurrentTrain: epoch  6, batch    56 | loss: 124.2521569CurrentTrain: epoch  6, batch    57 | loss: 82.1277797CurrentTrain: epoch  6, batch    58 | loss: 96.5494207CurrentTrain: epoch  6, batch    59 | loss: 98.1270335CurrentTrain: epoch  6, batch    60 | loss: 102.2112684CurrentTrain: epoch  6, batch    61 | loss: 68.0201011CurrentTrain: epoch  6, batch    62 | loss: 76.8247495CurrentTrain: epoch  6, batch    63 | loss: 79.8744863CurrentTrain: epoch  6, batch    64 | loss: 77.3600861CurrentTrain: epoch  6, batch    65 | loss: 103.0849636CurrentTrain: epoch  6, batch    66 | loss: 79.1477097CurrentTrain: epoch  6, batch    67 | loss: 95.7296685CurrentTrain: epoch  6, batch    68 | loss: 84.1752417CurrentTrain: epoch  6, batch    69 | loss: 95.4650851CurrentTrain: epoch  6, batch    70 | loss: 98.2416788CurrentTrain: epoch  6, batch    71 | loss: 94.0023600CurrentTrain: epoch  6, batch    72 | loss: 54.8208734CurrentTrain: epoch  6, batch    73 | loss: 83.4788213CurrentTrain: epoch  6, batch    74 | loss: 100.8809586CurrentTrain: epoch  6, batch    75 | loss: 71.5910112CurrentTrain: epoch  6, batch    76 | loss: 79.7594617CurrentTrain: epoch  6, batch    77 | loss: 103.1966892CurrentTrain: epoch  6, batch    78 | loss: 98.7921159CurrentTrain: epoch  6, batch    79 | loss: 97.1222008CurrentTrain: epoch  6, batch    80 | loss: 96.7122303CurrentTrain: epoch  6, batch    81 | loss: 71.2209265CurrentTrain: epoch  6, batch    82 | loss: 79.3571131CurrentTrain: epoch  6, batch    83 | loss: 66.3277624CurrentTrain: epoch  6, batch    84 | loss: 96.0372144CurrentTrain: epoch  6, batch    85 | loss: 74.1891329CurrentTrain: epoch  6, batch    86 | loss: 96.9745355CurrentTrain: epoch  6, batch    87 | loss: 97.6635348CurrentTrain: epoch  6, batch    88 | loss: 119.7541260CurrentTrain: epoch  6, batch    89 | loss: 73.5880145CurrentTrain: epoch  6, batch    90 | loss: 63.9390629CurrentTrain: epoch  6, batch    91 | loss: 123.3871725CurrentTrain: epoch  6, batch    92 | loss: 65.4689566CurrentTrain: epoch  6, batch    93 | loss: 64.1031743CurrentTrain: epoch  6, batch    94 | loss: 64.6657411CurrentTrain: epoch  6, batch    95 | loss: 107.4963587CurrentTrain: epoch  7, batch     0 | loss: 62.2702179CurrentTrain: epoch  7, batch     1 | loss: 67.1896548CurrentTrain: epoch  7, batch     2 | loss: 124.4482064CurrentTrain: epoch  7, batch     3 | loss: 96.8504862CurrentTrain: epoch  7, batch     4 | loss: 121.3674140CurrentTrain: epoch  7, batch     5 | loss: 80.2405658CurrentTrain: epoch  7, batch     6 | loss: 77.0580145CurrentTrain: epoch  7, batch     7 | loss: 94.6882907CurrentTrain: epoch  7, batch     8 | loss: 55.0150825CurrentTrain: epoch  7, batch     9 | loss: 64.9884635CurrentTrain: epoch  7, batch    10 | loss: 118.4722496CurrentTrain: epoch  7, batch    11 | loss: 126.0499439CurrentTrain: epoch  7, batch    12 | loss: 77.6134566CurrentTrain: epoch  7, batch    13 | loss: 81.9367584CurrentTrain: epoch  7, batch    14 | loss: 54.5629795CurrentTrain: epoch  7, batch    15 | loss: 97.5037671CurrentTrain: epoch  7, batch    16 | loss: 65.2497634CurrentTrain: epoch  7, batch    17 | loss: 102.1238825CurrentTrain: epoch  7, batch    18 | loss: 66.5950130CurrentTrain: epoch  7, batch    19 | loss: 93.8853815CurrentTrain: epoch  7, batch    20 | loss: 97.3434511CurrentTrain: epoch  7, batch    21 | loss: 83.7141819CurrentTrain: epoch  7, batch    22 | loss: 94.2211680CurrentTrain: epoch  7, batch    23 | loss: 83.0527984CurrentTrain: epoch  7, batch    24 | loss: 123.3863315CurrentTrain: epoch  7, batch    25 | loss: 76.1718223CurrentTrain: epoch  7, batch    26 | loss: 82.9084948CurrentTrain: epoch  7, batch    27 | loss: 57.2455079CurrentTrain: epoch  7, batch    28 | loss: 56.2383058CurrentTrain: epoch  7, batch    29 | loss: 63.9171085CurrentTrain: epoch  7, batch    30 | loss: 98.6196772CurrentTrain: epoch  7, batch    31 | loss: 67.5422750CurrentTrain: epoch  7, batch    32 | loss: 96.0084701CurrentTrain: epoch  7, batch    33 | loss: 94.9988165CurrentTrain: epoch  7, batch    34 | loss: 97.8791244CurrentTrain: epoch  7, batch    35 | loss: 81.6843093CurrentTrain: epoch  7, batch    36 | loss: 77.3352529CurrentTrain: epoch  7, batch    37 | loss: 63.5889800CurrentTrain: epoch  7, batch    38 | loss: 76.8164072CurrentTrain: epoch  7, batch    39 | loss: 76.8277284CurrentTrain: epoch  7, batch    40 | loss: 128.9526205CurrentTrain: epoch  7, batch    41 | loss: 78.4752613CurrentTrain: epoch  7, batch    42 | loss: 78.2429905CurrentTrain: epoch  7, batch    43 | loss: 124.6546001CurrentTrain: epoch  7, batch    44 | loss: 57.0470346CurrentTrain: epoch  7, batch    45 | loss: 102.0533410CurrentTrain: epoch  7, batch    46 | loss: 65.5897639CurrentTrain: epoch  7, batch    47 | loss: 79.6909493CurrentTrain: epoch  7, batch    48 | loss: 80.9290050CurrentTrain: epoch  7, batch    49 | loss: 125.3288597CurrentTrain: epoch  7, batch    50 | loss: 100.1599410CurrentTrain: epoch  7, batch    51 | loss: 101.6009645CurrentTrain: epoch  7, batch    52 | loss: 76.5439245CurrentTrain: epoch  7, batch    53 | loss: 123.1162640CurrentTrain: epoch  7, batch    54 | loss: 80.1990473CurrentTrain: epoch  7, batch    55 | loss: 81.2853779CurrentTrain: epoch  7, batch    56 | loss: 64.8260654CurrentTrain: epoch  7, batch    57 | loss: 125.3836446CurrentTrain: epoch  7, batch    58 | loss: 69.9987040CurrentTrain: epoch  7, batch    59 | loss: 81.9417474CurrentTrain: epoch  7, batch    60 | loss: 94.3591368CurrentTrain: epoch  7, batch    61 | loss: 78.8951991CurrentTrain: epoch  7, batch    62 | loss: 98.5561052CurrentTrain: epoch  7, batch    63 | loss: 80.3134002CurrentTrain: epoch  7, batch    64 | loss: 56.4984648CurrentTrain: epoch  7, batch    65 | loss: 78.0707923CurrentTrain: epoch  7, batch    66 | loss: 67.3715640CurrentTrain: epoch  7, batch    67 | loss: 81.4579539CurrentTrain: epoch  7, batch    68 | loss: 79.3317170CurrentTrain: epoch  7, batch    69 | loss: 99.2696044CurrentTrain: epoch  7, batch    70 | loss: 79.5675561CurrentTrain: epoch  7, batch    71 | loss: 56.5775705CurrentTrain: epoch  7, batch    72 | loss: 77.6726718CurrentTrain: epoch  7, batch    73 | loss: 78.5727250CurrentTrain: epoch  7, batch    74 | loss: 123.1776029CurrentTrain: epoch  7, batch    75 | loss: 95.2614417CurrentTrain: epoch  7, batch    76 | loss: 78.8417031CurrentTrain: epoch  7, batch    77 | loss: 57.1099189CurrentTrain: epoch  7, batch    78 | loss: 260.6801066CurrentTrain: epoch  7, batch    79 | loss: 78.6922414CurrentTrain: epoch  7, batch    80 | loss: 78.7724513CurrentTrain: epoch  7, batch    81 | loss: 63.3877260CurrentTrain: epoch  7, batch    82 | loss: 102.8070213CurrentTrain: epoch  7, batch    83 | loss: 77.9551773CurrentTrain: epoch  7, batch    84 | loss: 81.8543414CurrentTrain: epoch  7, batch    85 | loss: 79.1652536CurrentTrain: epoch  7, batch    86 | loss: 125.4344365CurrentTrain: epoch  7, batch    87 | loss: 99.5368833CurrentTrain: epoch  7, batch    88 | loss: 122.6457116CurrentTrain: epoch  7, batch    89 | loss: 78.3398896CurrentTrain: epoch  7, batch    90 | loss: 80.1973437CurrentTrain: epoch  7, batch    91 | loss: 125.1950988CurrentTrain: epoch  7, batch    92 | loss: 126.5031003CurrentTrain: epoch  7, batch    93 | loss: 65.1340089CurrentTrain: epoch  7, batch    94 | loss: 52.0134509CurrentTrain: epoch  7, batch    95 | loss: 101.2575240CurrentTrain: epoch  8, batch     0 | loss: 99.9550269CurrentTrain: epoch  8, batch     1 | loss: 97.2001966CurrentTrain: epoch  8, batch     2 | loss: 79.7282533CurrentTrain: epoch  8, batch     3 | loss: 64.2872909CurrentTrain: epoch  8, batch     4 | loss: 67.0031549CurrentTrain: epoch  8, batch     5 | loss: 93.0126121CurrentTrain: epoch  8, batch     6 | loss: 77.9739599CurrentTrain: epoch  8, batch     7 | loss: 127.1465727CurrentTrain: epoch  8, batch     8 | loss: 67.3936399CurrentTrain: epoch  8, batch     9 | loss: 63.5226528CurrentTrain: epoch  8, batch    10 | loss: 60.2928933CurrentTrain: epoch  8, batch    11 | loss: 63.4065702CurrentTrain: epoch  8, batch    12 | loss: 64.4105004CurrentTrain: epoch  8, batch    13 | loss: 171.4637197CurrentTrain: epoch  8, batch    14 | loss: 78.7447205CurrentTrain: epoch  8, batch    15 | loss: 78.7040595CurrentTrain: epoch  8, batch    16 | loss: 124.5394546CurrentTrain: epoch  8, batch    17 | loss: 98.3170495CurrentTrain: epoch  8, batch    18 | loss: 98.0042287CurrentTrain: epoch  8, batch    19 | loss: 66.5599549CurrentTrain: epoch  8, batch    20 | loss: 54.5523921CurrentTrain: epoch  8, batch    21 | loss: 63.4863738CurrentTrain: epoch  8, batch    22 | loss: 124.5840076CurrentTrain: epoch  8, batch    23 | loss: 76.5546573CurrentTrain: epoch  8, batch    24 | loss: 97.0016702CurrentTrain: epoch  8, batch    25 | loss: 65.1006663CurrentTrain: epoch  8, batch    26 | loss: 94.8625984CurrentTrain: epoch  8, batch    27 | loss: 119.7778954CurrentTrain: epoch  8, batch    28 | loss: 81.8694821CurrentTrain: epoch  8, batch    29 | loss: 91.6302614CurrentTrain: epoch  8, batch    30 | loss: 69.4765283CurrentTrain: epoch  8, batch    31 | loss: 125.8263016CurrentTrain: epoch  8, batch    32 | loss: 122.4663255CurrentTrain: epoch  8, batch    33 | loss: 92.0602596CurrentTrain: epoch  8, batch    34 | loss: 126.1583847CurrentTrain: epoch  8, batch    35 | loss: 120.3242016CurrentTrain: epoch  8, batch    36 | loss: 76.9879417CurrentTrain: epoch  8, batch    37 | loss: 94.6131022CurrentTrain: epoch  8, batch    38 | loss: 125.2757990CurrentTrain: epoch  8, batch    39 | loss: 78.8286030CurrentTrain: epoch  8, batch    40 | loss: 77.1732010CurrentTrain: epoch  8, batch    41 | loss: 62.2759744CurrentTrain: epoch  8, batch    42 | loss: 167.1583047CurrentTrain: epoch  8, batch    43 | loss: 94.0711475CurrentTrain: epoch  8, batch    44 | loss: 94.7889103CurrentTrain: epoch  8, batch    45 | loss: 78.9836126CurrentTrain: epoch  8, batch    46 | loss: 81.6476388CurrentTrain: epoch  8, batch    47 | loss: 122.7403249CurrentTrain: epoch  8, batch    48 | loss: 76.3176291CurrentTrain: epoch  8, batch    49 | loss: 64.9790963CurrentTrain: epoch  8, batch    50 | loss: 67.6404875CurrentTrain: epoch  8, batch    51 | loss: 66.7955983CurrentTrain: epoch  8, batch    52 | loss: 63.6276285CurrentTrain: epoch  8, batch    53 | loss: 105.1657131CurrentTrain: epoch  8, batch    54 | loss: 96.6845466CurrentTrain: epoch  8, batch    55 | loss: 80.0298914CurrentTrain: epoch  8, batch    56 | loss: 80.0104523CurrentTrain: epoch  8, batch    57 | loss: 89.4886387CurrentTrain: epoch  8, batch    58 | loss: 93.7167298CurrentTrain: epoch  8, batch    59 | loss: 122.8652652CurrentTrain: epoch  8, batch    60 | loss: 78.6857199CurrentTrain: epoch  8, batch    61 | loss: 100.0780165CurrentTrain: epoch  8, batch    62 | loss: 63.6065459CurrentTrain: epoch  8, batch    63 | loss: 67.3025793CurrentTrain: epoch  8, batch    64 | loss: 76.6063446CurrentTrain: epoch  8, batch    65 | loss: 96.3686028CurrentTrain: epoch  8, batch    66 | loss: 65.0881241CurrentTrain: epoch  8, batch    67 | loss: 77.7608250CurrentTrain: epoch  8, batch    68 | loss: 78.0517349CurrentTrain: epoch  8, batch    69 | loss: 67.5641773CurrentTrain: epoch  8, batch    70 | loss: 69.0988455CurrentTrain: epoch  8, batch    71 | loss: 66.8562567CurrentTrain: epoch  8, batch    72 | loss: 126.8594461CurrentTrain: epoch  8, batch    73 | loss: 67.3846727CurrentTrain: epoch  8, batch    74 | loss: 74.8893839CurrentTrain: epoch  8, batch    75 | loss: 100.9059339CurrentTrain: epoch  8, batch    76 | loss: 79.5707590CurrentTrain: epoch  8, batch    77 | loss: 66.8401119CurrentTrain: epoch  8, batch    78 | loss: 63.6842059CurrentTrain: epoch  8, batch    79 | loss: 54.1683315CurrentTrain: epoch  8, batch    80 | loss: 77.2480958CurrentTrain: epoch  8, batch    81 | loss: 64.5746779CurrentTrain: epoch  8, batch    82 | loss: 64.7179940CurrentTrain: epoch  8, batch    83 | loss: 64.1291264CurrentTrain: epoch  8, batch    84 | loss: 98.2330650CurrentTrain: epoch  8, batch    85 | loss: 79.3060579CurrentTrain: epoch  8, batch    86 | loss: 56.8129771CurrentTrain: epoch  8, batch    87 | loss: 76.5078363CurrentTrain: epoch  8, batch    88 | loss: 79.5495179CurrentTrain: epoch  8, batch    89 | loss: 66.7139430CurrentTrain: epoch  8, batch    90 | loss: 124.7423585CurrentTrain: epoch  8, batch    91 | loss: 64.2972261CurrentTrain: epoch  8, batch    92 | loss: 68.5872791CurrentTrain: epoch  8, batch    93 | loss: 98.5127845CurrentTrain: epoch  8, batch    94 | loss: 97.0123717CurrentTrain: epoch  8, batch    95 | loss: 82.8659913CurrentTrain: epoch  9, batch     0 | loss: 120.0136951CurrentTrain: epoch  9, batch     1 | loss: 78.6619578CurrentTrain: epoch  9, batch     2 | loss: 66.7328925CurrentTrain: epoch  9, batch     3 | loss: 121.3080045CurrentTrain: epoch  9, batch     4 | loss: 163.3349769CurrentTrain: epoch  9, batch     5 | loss: 98.6754963CurrentTrain: epoch  9, batch     6 | loss: 102.1724569CurrentTrain: epoch  9, batch     7 | loss: 64.9180534CurrentTrain: epoch  9, batch     8 | loss: 79.0814369CurrentTrain: epoch  9, batch     9 | loss: 81.5476062CurrentTrain: epoch  9, batch    10 | loss: 66.1875367CurrentTrain: epoch  9, batch    11 | loss: 79.1126006CurrentTrain: epoch  9, batch    12 | loss: 65.9815628CurrentTrain: epoch  9, batch    13 | loss: 77.7808404CurrentTrain: epoch  9, batch    14 | loss: 92.6275591CurrentTrain: epoch  9, batch    15 | loss: 57.0321161CurrentTrain: epoch  9, batch    16 | loss: 124.6952525CurrentTrain: epoch  9, batch    17 | loss: 122.8922845CurrentTrain: epoch  9, batch    18 | loss: 73.0726976CurrentTrain: epoch  9, batch    19 | loss: 97.4320780CurrentTrain: epoch  9, batch    20 | loss: 77.5483675CurrentTrain: epoch  9, batch    21 | loss: 95.8105200CurrentTrain: epoch  9, batch    22 | loss: 74.3667192CurrentTrain: epoch  9, batch    23 | loss: 91.4334993CurrentTrain: epoch  9, batch    24 | loss: 94.4453404CurrentTrain: epoch  9, batch    25 | loss: 98.0434085CurrentTrain: epoch  9, batch    26 | loss: 79.4206434CurrentTrain: epoch  9, batch    27 | loss: 169.9243378CurrentTrain: epoch  9, batch    28 | loss: 67.4091305CurrentTrain: epoch  9, batch    29 | loss: 96.5136308CurrentTrain: epoch  9, batch    30 | loss: 75.6134071CurrentTrain: epoch  9, batch    31 | loss: 73.3732024CurrentTrain: epoch  9, batch    32 | loss: 75.2778417CurrentTrain: epoch  9, batch    33 | loss: 76.3823738CurrentTrain: epoch  9, batch    34 | loss: 65.9251110CurrentTrain: epoch  9, batch    35 | loss: 67.7347876CurrentTrain: epoch  9, batch    36 | loss: 77.8468836CurrentTrain: epoch  9, batch    37 | loss: 65.8993585CurrentTrain: epoch  9, batch    38 | loss: 73.8831229CurrentTrain: epoch  9, batch    39 | loss: 97.0567717CurrentTrain: epoch  9, batch    40 | loss: 78.3003707CurrentTrain: epoch  9, batch    41 | loss: 73.8477624CurrentTrain: epoch  9, batch    42 | loss: 75.4500034CurrentTrain: epoch  9, batch    43 | loss: 67.5797115CurrentTrain: epoch  9, batch    44 | loss: 53.0264348CurrentTrain: epoch  9, batch    45 | loss: 66.0064097CurrentTrain: epoch  9, batch    46 | loss: 80.9436730CurrentTrain: epoch  9, batch    47 | loss: 57.4058958CurrentTrain: epoch  9, batch    48 | loss: 76.3398107CurrentTrain: epoch  9, batch    49 | loss: 72.3421241CurrentTrain: epoch  9, batch    50 | loss: 67.8771890CurrentTrain: epoch  9, batch    51 | loss: 68.6840087CurrentTrain: epoch  9, batch    52 | loss: 94.5963077CurrentTrain: epoch  9, batch    53 | loss: 99.1231529CurrentTrain: epoch  9, batch    54 | loss: 74.7123312CurrentTrain: epoch  9, batch    55 | loss: 76.6469558CurrentTrain: epoch  9, batch    56 | loss: 127.3475827CurrentTrain: epoch  9, batch    57 | loss: 75.8154711CurrentTrain: epoch  9, batch    58 | loss: 96.1101411CurrentTrain: epoch  9, batch    59 | loss: 73.4204546CurrentTrain: epoch  9, batch    60 | loss: 52.7343115CurrentTrain: epoch  9, batch    61 | loss: 78.0323794CurrentTrain: epoch  9, batch    62 | loss: 76.8134259CurrentTrain: epoch  9, batch    63 | loss: 97.8620740CurrentTrain: epoch  9, batch    64 | loss: 119.2756140CurrentTrain: epoch  9, batch    65 | loss: 125.1153820CurrentTrain: epoch  9, batch    66 | loss: 121.4199647CurrentTrain: epoch  9, batch    67 | loss: 78.3114292CurrentTrain: epoch  9, batch    68 | loss: 76.2947436CurrentTrain: epoch  9, batch    69 | loss: 62.9382542CurrentTrain: epoch  9, batch    70 | loss: 75.7494642CurrentTrain: epoch  9, batch    71 | loss: 66.1985426CurrentTrain: epoch  9, batch    72 | loss: 77.9184735CurrentTrain: epoch  9, batch    73 | loss: 116.9554684CurrentTrain: epoch  9, batch    74 | loss: 56.6271422CurrentTrain: epoch  9, batch    75 | loss: 64.2792938CurrentTrain: epoch  9, batch    76 | loss: 76.6842302CurrentTrain: epoch  9, batch    77 | loss: 61.9984309CurrentTrain: epoch  9, batch    78 | loss: 68.3018264CurrentTrain: epoch  9, batch    79 | loss: 57.2343967CurrentTrain: epoch  9, batch    80 | loss: 92.7443998CurrentTrain: epoch  9, batch    81 | loss: 98.3454079CurrentTrain: epoch  9, batch    82 | loss: 68.9853133CurrentTrain: epoch  9, batch    83 | loss: 66.0691495CurrentTrain: epoch  9, batch    84 | loss: 74.7438634CurrentTrain: epoch  9, batch    85 | loss: 80.9520612CurrentTrain: epoch  9, batch    86 | loss: 57.8158072CurrentTrain: epoch  9, batch    87 | loss: 122.3120626CurrentTrain: epoch  9, batch    88 | loss: 52.6073828CurrentTrain: epoch  9, batch    89 | loss: 57.4818999CurrentTrain: epoch  9, batch    90 | loss: 65.5554290CurrentTrain: epoch  9, batch    91 | loss: 118.7406363CurrentTrain: epoch  9, batch    92 | loss: 125.5584203CurrentTrain: epoch  9, batch    93 | loss: 61.9768954CurrentTrain: epoch  9, batch    94 | loss: 80.7399007CurrentTrain: epoch  9, batch    95 | loss: 109.7937897

F1 score per class: {32: np.float64(0.5789473684210527), 6: np.float64(0.7878787878787878), 19: np.float64(0.35555555555555557), 24: np.float64(0.7640449438202247), 26: np.float64(0.9238578680203046), 29: np.float64(0.8229665071770335)}
Micro-average F1 score: 0.76
Weighted-average F1 score: 0.7590797978726684
F1 score per class: {32: np.float64(0.5743589743589743), 6: np.float64(0.7763713080168776), 19: np.float64(0.2191780821917808), 24: np.float64(0.7542857142857143), 26: np.float64(0.9346733668341709), 29: np.float64(0.8127853881278538)}
Micro-average F1 score: 0.7358834244080146
Weighted-average F1 score: 0.7220815851003255
F1 score per class: {32: np.float64(0.5743589743589743), 6: np.float64(0.7763713080168776), 19: np.float64(0.2909090909090909), 24: np.float64(0.7542857142857143), 26: np.float64(0.9292929292929293), 29: np.float64(0.8110599078341014)}
Micro-average F1 score: 0.7465181058495822
Weighted-average F1 score: 0.741013869382427

F1 score per class: {32: np.float64(0.5789473684210527), 6: np.float64(0.7878787878787878), 19: np.float64(0.35555555555555557), 24: np.float64(0.7640449438202247), 26: np.float64(0.9238578680203046), 29: np.float64(0.8229665071770335)}
Micro-average F1 score: 0.76
Weighted-average F1 score: 0.7590797978726684
F1 score per class: {32: np.float64(0.5743589743589743), 6: np.float64(0.7763713080168776), 19: np.float64(0.2191780821917808), 24: np.float64(0.7542857142857143), 26: np.float64(0.9346733668341709), 29: np.float64(0.8127853881278538)}
Micro-average F1 score: 0.7358834244080146
Weighted-average F1 score: 0.7220815851003255
F1 score per class: {32: np.float64(0.5743589743589743), 6: np.float64(0.7763713080168776), 19: np.float64(0.2909090909090909), 24: np.float64(0.7542857142857143), 26: np.float64(0.9292929292929293), 29: np.float64(0.8110599078341014)}
Micro-average F1 score: 0.7465181058495822
Weighted-average F1 score: 0.741013869382427

F1 score per class: {32: np.float64(0.4296875), 6: np.float64(0.728), 19: np.float64(0.1951219512195122), 24: np.float64(0.7083333333333334), 26: np.float64(0.8504672897196262), 29: np.float64(0.6615384615384615)}
Micro-average F1 score: 0.6363636363636364
Weighted-average F1 score: 0.6204961228517754
F1 score per class: {32: np.float64(0.4375), 6: np.float64(0.7076923076923077), 19: np.float64(0.12307692307692308), 24: np.float64(0.7021276595744681), 26: np.float64(0.8651162790697674), 29: np.float64(0.6267605633802817)}
Micro-average F1 score: 0.6061515378844711
Weighted-average F1 score: 0.5789753796477705
F1 score per class: {32: np.float64(0.4375), 6: np.float64(0.7104247104247104), 19: np.float64(0.1568627450980392), 24: np.float64(0.7021276595744681), 26: np.float64(0.8598130841121495), 29: np.float64(0.6285714285714286)}
Micro-average F1 score: 0.6189376443418014
Weighted-average F1 score: 0.5983774421510366

F1 score per class: {32: np.float64(0.4296875), 6: np.float64(0.728), 19: np.float64(0.1951219512195122), 24: np.float64(0.7083333333333334), 26: np.float64(0.8504672897196262), 29: np.float64(0.6615384615384615)}
Micro-average F1 score: 0.6363636363636364
Weighted-average F1 score: 0.6204961228517754
F1 score per class: {32: np.float64(0.4375), 6: np.float64(0.7076923076923077), 19: np.float64(0.12307692307692308), 24: np.float64(0.7021276595744681), 26: np.float64(0.8651162790697674), 29: np.float64(0.6267605633802817)}
Micro-average F1 score: 0.6061515378844711
Weighted-average F1 score: 0.5789753796477705
F1 score per class: {32: np.float64(0.4375), 6: np.float64(0.7104247104247104), 19: np.float64(0.1568627450980392), 24: np.float64(0.7021276595744681), 26: np.float64(0.8598130841121495), 29: np.float64(0.6285714285714286)}
Micro-average F1 score: 0.6189376443418014
Weighted-average F1 score: 0.5983774421510366
cur_acc_wo_na:  ['0.7600']
his_acc_wo_na:  ['0.7600']
cur_acc des_wo_na:  ['0.7359']
his_acc des_wo_na:  ['0.7359']
cur_acc rrf_wo_na:  ['0.7465']
his_acc rrf_wo_na:  ['0.7465']
cur_acc_w_na:  ['0.6364']
his_acc_w_na:  ['0.6364']
cur_acc des_w_na:  ['0.6062']
his_acc des_w_na:  ['0.6062']
cur_acc rrf_w_na:  ['0.6189']
his_acc rrf_w_na:  ['0.6189']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 93.3309459CurrentTrain: epoch  0, batch     1 | loss: 120.7098838CurrentTrain: epoch  0, batch     2 | loss: 115.7260803CurrentTrain: epoch  0, batch     3 | loss: 116.3585217CurrentTrain: epoch  0, batch     4 | loss: 58.2382358CurrentTrain: epoch  1, batch     0 | loss: 91.6110994CurrentTrain: epoch  1, batch     1 | loss: 106.5125920CurrentTrain: epoch  1, batch     2 | loss: 110.0203920CurrentTrain: epoch  1, batch     3 | loss: 86.7190660CurrentTrain: epoch  1, batch     4 | loss: 88.7207216CurrentTrain: epoch  2, batch     0 | loss: 85.9825998CurrentTrain: epoch  2, batch     1 | loss: 104.4973897CurrentTrain: epoch  2, batch     2 | loss: 106.6574927CurrentTrain: epoch  2, batch     3 | loss: 83.9396519CurrentTrain: epoch  2, batch     4 | loss: 84.8583354CurrentTrain: epoch  3, batch     0 | loss: 266.6208768CurrentTrain: epoch  3, batch     1 | loss: 83.0695208CurrentTrain: epoch  3, batch     2 | loss: 82.7699440CurrentTrain: epoch  3, batch     3 | loss: 104.3265408CurrentTrain: epoch  3, batch     4 | loss: 53.7997905CurrentTrain: epoch  4, batch     0 | loss: 72.0979618CurrentTrain: epoch  4, batch     1 | loss: 97.1611520CurrentTrain: epoch  4, batch     2 | loss: 128.0261285CurrentTrain: epoch  4, batch     3 | loss: 84.4886395CurrentTrain: epoch  4, batch     4 | loss: 82.0458008CurrentTrain: epoch  5, batch     0 | loss: 103.2327722CurrentTrain: epoch  5, batch     1 | loss: 82.9155952CurrentTrain: epoch  5, batch     2 | loss: 124.6605065CurrentTrain: epoch  5, batch     3 | loss: 78.9733106CurrentTrain: epoch  5, batch     4 | loss: 78.0245018CurrentTrain: epoch  6, batch     0 | loss: 78.6628506CurrentTrain: epoch  6, batch     1 | loss: 123.6594092CurrentTrain: epoch  6, batch     2 | loss: 79.6261925CurrentTrain: epoch  6, batch     3 | loss: 123.9944200CurrentTrain: epoch  6, batch     4 | loss: 63.3540275CurrentTrain: epoch  7, batch     0 | loss: 68.0809354CurrentTrain: epoch  7, batch     1 | loss: 98.6065205CurrentTrain: epoch  7, batch     2 | loss: 64.3113532CurrentTrain: epoch  7, batch     3 | loss: 81.6629699CurrentTrain: epoch  7, batch     4 | loss: 161.8442373CurrentTrain: epoch  8, batch     0 | loss: 66.3897384CurrentTrain: epoch  8, batch     1 | loss: 124.7437054CurrentTrain: epoch  8, batch     2 | loss: 67.4674623CurrentTrain: epoch  8, batch     3 | loss: 79.5734664CurrentTrain: epoch  8, batch     4 | loss: 72.8280273CurrentTrain: epoch  9, batch     0 | loss: 63.7509254CurrentTrain: epoch  9, batch     1 | loss: 80.7864779CurrentTrain: epoch  9, batch     2 | loss: 77.0516195CurrentTrain: epoch  9, batch     3 | loss: 96.7757568CurrentTrain: epoch  9, batch     4 | loss: 76.3826842
MemoryTrain:  epoch  0, batch     0 | loss: 1.5867796MemoryTrain:  epoch  1, batch     0 | loss: 1.3916620MemoryTrain:  epoch  2, batch     0 | loss: 1.1435118MemoryTrain:  epoch  3, batch     0 | loss: 0.8346204MemoryTrain:  epoch  4, batch     0 | loss: 0.6556864MemoryTrain:  epoch  5, batch     0 | loss: 0.5767804MemoryTrain:  epoch  6, batch     0 | loss: 0.4561477MemoryTrain:  epoch  7, batch     0 | loss: 0.3710290MemoryTrain:  epoch  8, batch     0 | loss: 0.3289333MemoryTrain:  epoch  9, batch     0 | loss: 0.2642360

F1 score per class: {32: np.float64(0.8888888888888888), 5: np.float64(0.0), 6: np.float64(0.20869565217391303), 10: np.float64(0.6666666666666666), 16: np.float64(0.0), 17: np.float64(0.42105263157894735), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5576519916142557
Weighted-average F1 score: 0.6003114354492475
F1 score per class: {32: np.float64(0.7245283018867924), 5: np.float64(0.0), 6: np.float64(0.4084507042253521), 10: np.float64(0.6666666666666666), 16: np.float64(0.0), 17: np.float64(0.45977011494252873), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5244865718799369
Weighted-average F1 score: 0.5089372692882689
F1 score per class: {32: np.float64(0.7692307692307693), 5: np.float64(0.0), 6: np.float64(0.4195804195804196), 10: np.float64(0.6774193548387096), 16: np.float64(0.0), 17: np.float64(0.49382716049382713), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5514950166112956
Weighted-average F1 score: 0.5353518267958535

F1 score per class: {32: np.float64(0.8720379146919431), 5: np.float64(0.5233644859813084), 6: np.float64(0.2), 10: np.float64(0.6538461538461539), 16: np.float64(0.0), 17: np.float64(0.375), 18: np.float64(0.7782426778242678), 19: np.float64(0.425531914893617), 24: np.float64(0.7368421052631579), 26: np.float64(0.8969072164948454), 29: np.float64(0.7965367965367965)}
Micro-average F1 score: 0.686984126984127
Weighted-average F1 score: 0.7176144958224051
F1 score per class: {32: np.float64(0.6808510638297872), 5: np.float64(0.5650224215246636), 6: np.float64(0.36024844720496896), 10: np.float64(0.6176470588235294), 16: np.float64(0.0), 17: np.float64(0.4), 18: np.float64(0.6808510638297872), 19: np.float64(0.22988505747126436), 24: np.float64(0.7195767195767195), 26: np.float64(0.8878048780487805), 29: np.float64(0.7833333333333333)}
Micro-average F1 score: 0.6336206896551724
Weighted-average F1 score: 0.6316043921525492
F1 score per class: {32: np.float64(0.7279693486590039), 5: np.float64(0.5636363636363636), 6: np.float64(0.37037037037037035), 10: np.float64(0.6461538461538462), 16: np.float64(0.0), 17: np.float64(0.449438202247191), 18: np.float64(0.7137546468401487), 19: np.float64(0.29850746268656714), 24: np.float64(0.7157894736842105), 26: np.float64(0.896551724137931), 29: np.float64(0.7768595041322314)}
Micro-average F1 score: 0.657703081232493
Weighted-average F1 score: 0.6620786010674615

F1 score per class: {32: np.float64(0.7244094488188977), 5: np.float64(0.0), 6: np.float64(0.19834710743801653), 10: np.float64(0.43037974683544306), 16: np.float64(0.0), 17: np.float64(0.3116883116883117), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.42356687898089174
Weighted-average F1 score: 0.4240922853317551
F1 score per class: {32: np.float64(0.5348189415041783), 5: np.float64(0.0), 6: np.float64(0.34523809523809523), 10: np.float64(0.4117647058823529), 16: np.float64(0.0), 17: np.float64(0.3053435114503817), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.36523652365236525
Weighted-average F1 score: 0.3480942262648309
F1 score per class: {32: np.float64(0.572289156626506), 5: np.float64(0.0), 6: np.float64(0.36585365853658536), 10: np.float64(0.42), 16: np.float64(0.0), 17: np.float64(0.3252032520325203), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.3892145369284877
Weighted-average F1 score: 0.3701095288708624

F1 score per class: {32: np.float64(0.696969696969697), 5: np.float64(0.34890965732087226), 6: np.float64(0.1875), 10: np.float64(0.40476190476190477), 16: np.float64(0.0), 17: np.float64(0.2608695652173913), 18: np.float64(0.6940298507462687), 19: np.float64(0.22988505747126436), 24: np.float64(0.660377358490566), 26: np.float64(0.8018433179723502), 29: np.float64(0.6032786885245902)}
Micro-average F1 score: 0.5396508728179551
Weighted-average F1 score: 0.5423420156128673
F1 score per class: {32: np.float64(0.47880299251870323), 5: np.float64(0.3620689655172414), 6: np.float64(0.2857142857142857), 10: np.float64(0.35294117647058826), 16: np.float64(0.0), 17: np.float64(0.25806451612903225), 18: np.float64(0.573134328358209), 19: np.float64(0.13157894736842105), 24: np.float64(0.6325581395348837), 26: np.float64(0.7428571428571429), 29: np.float64(0.5930599369085173)}
Micro-average F1 score: 0.4668519253672092
Weighted-average F1 score: 0.4560436970525092
F1 score per class: {32: np.float64(0.5121293800539084), 5: np.float64(0.36151603498542273), 6: np.float64(0.30612244897959184), 10: np.float64(0.375), 16: np.float64(0.0), 17: np.float64(0.28169014084507044), 18: np.float64(0.6056782334384858), 19: np.float64(0.15873015873015872), 24: np.float64(0.6445497630331753), 26: np.float64(0.7811158798283262), 29: np.float64(0.5930599369085173)}
Micro-average F1 score: 0.48977889027951604
Weighted-average F1 score: 0.47975867386702864
cur_acc_wo_na:  ['0.7600', '0.5577']
his_acc_wo_na:  ['0.7600', '0.6870']
cur_acc des_wo_na:  ['0.7359', '0.5245']
his_acc des_wo_na:  ['0.7359', '0.6336']
cur_acc rrf_wo_na:  ['0.7465', '0.5515']
his_acc rrf_wo_na:  ['0.7465', '0.6577']
cur_acc_w_na:  ['0.6364', '0.4236']
his_acc_w_na:  ['0.6364', '0.5397']
cur_acc des_w_na:  ['0.6062', '0.3652']
his_acc des_w_na:  ['0.6062', '0.4669']
cur_acc rrf_w_na:  ['0.6189', '0.3892']
his_acc rrf_w_na:  ['0.6189', '0.4898']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 81.9342996CurrentTrain: epoch  0, batch     1 | loss: 97.1035904CurrentTrain: epoch  0, batch     2 | loss: 112.9594391CurrentTrain: epoch  0, batch     3 | loss: 78.5480150CurrentTrain: epoch  0, batch     4 | loss: 40.9766760CurrentTrain: epoch  1, batch     0 | loss: 91.7864226CurrentTrain: epoch  1, batch     1 | loss: 78.3121500CurrentTrain: epoch  1, batch     2 | loss: 92.2120958CurrentTrain: epoch  1, batch     3 | loss: 85.6858496CurrentTrain: epoch  1, batch     4 | loss: 38.8179010CurrentTrain: epoch  2, batch     0 | loss: 101.6962577CurrentTrain: epoch  2, batch     1 | loss: 89.8637965CurrentTrain: epoch  2, batch     2 | loss: 103.4751462CurrentTrain: epoch  2, batch     3 | loss: 68.4566704CurrentTrain: epoch  2, batch     4 | loss: 24.6226783CurrentTrain: epoch  3, batch     0 | loss: 84.7171204CurrentTrain: epoch  3, batch     1 | loss: 71.6147886CurrentTrain: epoch  3, batch     2 | loss: 101.0233098CurrentTrain: epoch  3, batch     3 | loss: 82.8784314CurrentTrain: epoch  3, batch     4 | loss: 13.1222472CurrentTrain: epoch  4, batch     0 | loss: 99.8944110CurrentTrain: epoch  4, batch     1 | loss: 81.6757904CurrentTrain: epoch  4, batch     2 | loss: 66.0245691CurrentTrain: epoch  4, batch     3 | loss: 81.8700910CurrentTrain: epoch  4, batch     4 | loss: 40.5848298CurrentTrain: epoch  5, batch     0 | loss: 80.1701181CurrentTrain: epoch  5, batch     1 | loss: 95.5939854CurrentTrain: epoch  5, batch     2 | loss: 95.3505497CurrentTrain: epoch  5, batch     3 | loss: 78.9676913CurrentTrain: epoch  5, batch     4 | loss: 40.6110139CurrentTrain: epoch  6, batch     0 | loss: 65.5287997CurrentTrain: epoch  6, batch     1 | loss: 80.4219958CurrentTrain: epoch  6, batch     2 | loss: 77.9613783CurrentTrain: epoch  6, batch     3 | loss: 98.9351443CurrentTrain: epoch  6, batch     4 | loss: 15.5471101CurrentTrain: epoch  7, batch     0 | loss: 95.5867173CurrentTrain: epoch  7, batch     1 | loss: 96.1390806CurrentTrain: epoch  7, batch     2 | loss: 70.9285958CurrentTrain: epoch  7, batch     3 | loss: 124.1840370CurrentTrain: epoch  7, batch     4 | loss: 24.1487376CurrentTrain: epoch  8, batch     0 | loss: 96.0178582CurrentTrain: epoch  8, batch     1 | loss: 91.1798343CurrentTrain: epoch  8, batch     2 | loss: 65.8194927CurrentTrain: epoch  8, batch     3 | loss: 65.7379646CurrentTrain: epoch  8, batch     4 | loss: 24.9028148CurrentTrain: epoch  9, batch     0 | loss: 76.6639138CurrentTrain: epoch  9, batch     1 | loss: 74.9182869CurrentTrain: epoch  9, batch     2 | loss: 75.3046781CurrentTrain: epoch  9, batch     3 | loss: 78.3930701CurrentTrain: epoch  9, batch     4 | loss: 24.6304420
MemoryTrain:  epoch  0, batch     0 | loss: 1.1308699MemoryTrain:  epoch  1, batch     0 | loss: 1.0258895MemoryTrain:  epoch  2, batch     0 | loss: 0.7558339MemoryTrain:  epoch  3, batch     0 | loss: 0.6167574MemoryTrain:  epoch  4, batch     0 | loss: 0.5232364MemoryTrain:  epoch  5, batch     0 | loss: 0.4445296MemoryTrain:  epoch  6, batch     0 | loss: 0.4162186MemoryTrain:  epoch  7, batch     0 | loss: 0.3227026MemoryTrain:  epoch  8, batch     0 | loss: 0.2910056MemoryTrain:  epoch  9, batch     0 | loss: 0.2497522

F1 score per class: {32: np.float64(0.5555555555555556), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.5428571428571428), 39: np.float64(0.6309523809523809), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.2926829268292683), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.26666666666666666)}
Micro-average F1 score: 0.4851258581235698
Weighted-average F1 score: 0.41311255314388007
F1 score per class: {32: np.float64(0.6086956521739131), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.4740740740740741), 11: np.float64(0.6022727272727273), 12: np.float64(0.0), 10: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.23529411764705882), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.2857142857142857)}
Micro-average F1 score: 0.4087301587301587
Weighted-average F1 score: 0.32524068401216516
F1 score per class: {32: np.float64(0.631578947368421), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.5323741007194245), 11: np.float64(0.5847953216374269), 12: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.2553191489361702), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.30303030303030304)}
Micro-average F1 score: 0.4444444444444444
Weighted-average F1 score: 0.3642665020591107

F1 score per class: {32: np.float64(0.5), 2: np.float64(0.898989898989899), 5: np.float64(0.48756218905472637), 6: np.float64(0.20869565217391303), 39: np.float64(0.36363636363636365), 11: np.float64(0.4491525423728814), 12: np.float64(0.4888888888888889), 10: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.7763713080168776), 18: np.float64(0.35), 19: np.float64(0.7487179487179487), 24: np.float64(0.13043478260869565), 26: np.float64(0.8432432432432433), 28: np.float64(0.7301587301587301), 29: np.float64(0.23529411764705882)}
Micro-average F1 score: 0.5767045454545454
Weighted-average F1 score: 0.5840824259805123
F1 score per class: {32: np.float64(0.45161290322580644), 2: np.float64(0.7084870848708487), 5: np.float64(0.5210084033613446), 6: np.float64(0.4161073825503356), 39: np.float64(0.34972677595628415), 11: np.float64(0.3897058823529412), 12: np.float64(0.52), 10: np.float64(0.0), 16: np.float64(0.23728813559322035), 17: np.float64(0.7084870848708487), 18: np.float64(0.2857142857142857), 19: np.float64(0.7254901960784313), 24: np.float64(0.11538461538461539), 26: np.float64(0.8631578947368421), 28: np.float64(0.6666666666666666), 29: np.float64(0.2564102564102564)}
Micro-average F1 score: 0.5513825835740818
Weighted-average F1 score: 0.5441227867839448
F1 score per class: {32: np.float64(0.5454545454545454), 2: np.float64(0.8173913043478261), 5: np.float64(0.5135135135135135), 6: np.float64(0.40875912408759124), 39: np.float64(0.37373737373737376), 11: np.float64(0.3831417624521073), 12: np.float64(0.5306122448979592), 10: np.float64(0.0), 16: np.float64(0.044444444444444446), 17: np.float64(0.758893280632411), 18: np.float64(0.39215686274509803), 19: np.float64(0.736318407960199), 24: np.float64(0.11428571428571428), 26: np.float64(0.8556149732620321), 28: np.float64(0.6738351254480287), 29: np.float64(0.2702702702702703)}
Micro-average F1 score: 0.5695538057742782
Weighted-average F1 score: 0.5656995806856127

F1 score per class: {32: np.float64(0.4), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.4523809523809524), 11: np.float64(0.5247524752475248), 12: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.15584415584415584), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.18181818181818182)}
Micro-average F1 score: 0.34811165845648606
Weighted-average F1 score: 0.28800774582952804
F1 score per class: {32: np.float64(0.4), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.41025641025641024), 11: np.float64(0.49074074074074076), 12: np.float64(0.0), 10: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.12903225806451613), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.2)}
Micro-average F1 score: 0.2798913043478261
Weighted-average F1 score: 0.21932515233819286
F1 score per class: {32: np.float64(0.42857142857142855), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.44047619047619047), 11: np.float64(0.4807692307692308), 12: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.12903225806451613), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.20833333333333334)}
Micro-average F1 score: 0.30498533724340177
Weighted-average F1 score: 0.2448274396821739

F1 score per class: {32: np.float64(0.3448275862068966), 2: np.float64(0.7841409691629956), 5: np.float64(0.29253731343283584), 6: np.float64(0.192), 39: np.float64(0.247557003257329), 11: np.float64(0.23873873873873874), 12: np.float64(0.3793103448275862), 10: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.7159533073929961), 18: np.float64(0.22580645161290322), 19: np.float64(0.6636363636363637), 24: np.float64(0.07142857142857142), 26: np.float64(0.7572815533980582), 28: np.float64(0.5542168674698795), 29: np.float64(0.12307692307692308)}
Micro-average F1 score: 0.41898864809081526
Weighted-average F1 score: 0.3989032165501272
F1 score per class: {32: np.float64(0.2857142857142857), 2: np.float64(0.5079365079365079), 5: np.float64(0.29245283018867924), 6: np.float64(0.3502824858757062), 39: np.float64(0.2644628099173554), 10: np.float64(0.2058252427184466), 12: np.float64(0.3333333333333333), 11: np.float64(0.0), 16: np.float64(0.12389380530973451), 17: np.float64(0.6442953020134228), 18: np.float64(0.17094017094017094), 19: np.float64(0.6192468619246861), 24: np.float64(0.06486486486486487), 26: np.float64(0.7699530516431925), 28: np.float64(0.49214659685863876), 29: np.float64(0.14084507042253522)}
Micro-average F1 score: 0.3822603719599428
Weighted-average F1 score: 0.3633320759313854
F1 score per class: {32: np.float64(0.35294117647058826), 2: np.float64(0.6163934426229508), 5: np.float64(0.30158730158730157), 6: np.float64(0.34782608695652173), 39: np.float64(0.2596491228070175), 11: np.float64(0.20449897750511248), 12: np.float64(0.3466666666666667), 10: np.float64(0.0), 16: np.float64(0.028169014084507043), 17: np.float64(0.6857142857142857), 18: np.float64(0.23529411764705882), 19: np.float64(0.6379310344827587), 24: np.float64(0.059113300492610835), 26: np.float64(0.7619047619047619), 28: np.float64(0.4986737400530504), 29: np.float64(0.14492753623188406)}
Micro-average F1 score: 0.39889705882352944
Weighted-average F1 score: 0.3786503793745499
cur_acc_wo_na:  ['0.7600', '0.5577', '0.4851']
his_acc_wo_na:  ['0.7600', '0.6870', '0.5767']
cur_acc des_wo_na:  ['0.7359', '0.5245', '0.4087']
his_acc des_wo_na:  ['0.7359', '0.6336', '0.5514']
cur_acc rrf_wo_na:  ['0.7465', '0.5515', '0.4444']
his_acc rrf_wo_na:  ['0.7465', '0.6577', '0.5696']
cur_acc_w_na:  ['0.6364', '0.4236', '0.3481']
his_acc_w_na:  ['0.6364', '0.5397', '0.4190']
cur_acc des_w_na:  ['0.6062', '0.3652', '0.2799']
his_acc des_w_na:  ['0.6062', '0.4669', '0.3823']
cur_acc rrf_w_na:  ['0.6189', '0.3892', '0.3050']
his_acc rrf_w_na:  ['0.6189', '0.4898', '0.3989']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 113.8345898CurrentTrain: epoch  0, batch     1 | loss: 121.7496862CurrentTrain: epoch  0, batch     2 | loss: 99.4044099CurrentTrain: epoch  0, batch     3 | loss: 101.6612856CurrentTrain: epoch  1, batch     0 | loss: 91.2798933CurrentTrain: epoch  1, batch     1 | loss: 81.9315052CurrentTrain: epoch  1, batch     2 | loss: 107.4875604CurrentTrain: epoch  1, batch     3 | loss: 79.7167603CurrentTrain: epoch  2, batch     0 | loss: 106.3722585CurrentTrain: epoch  2, batch     1 | loss: 85.0593597CurrentTrain: epoch  2, batch     2 | loss: 91.2913345CurrentTrain: epoch  2, batch     3 | loss: 83.3967089CurrentTrain: epoch  3, batch     0 | loss: 104.8721456CurrentTrain: epoch  3, batch     1 | loss: 103.4785041CurrentTrain: epoch  3, batch     2 | loss: 87.8914298CurrentTrain: epoch  3, batch     3 | loss: 78.1889460CurrentTrain: epoch  4, batch     0 | loss: 101.1530516CurrentTrain: epoch  4, batch     1 | loss: 86.6813497CurrentTrain: epoch  4, batch     2 | loss: 83.2389857CurrentTrain: epoch  4, batch     3 | loss: 68.0340419CurrentTrain: epoch  5, batch     0 | loss: 80.2085402CurrentTrain: epoch  5, batch     1 | loss: 121.8328245CurrentTrain: epoch  5, batch     2 | loss: 98.7904530CurrentTrain: epoch  5, batch     3 | loss: 59.0934233CurrentTrain: epoch  6, batch     0 | loss: 64.9890387CurrentTrain: epoch  6, batch     1 | loss: 83.2846687CurrentTrain: epoch  6, batch     2 | loss: 78.9974243CurrentTrain: epoch  6, batch     3 | loss: 141.9083608CurrentTrain: epoch  7, batch     0 | loss: 100.8389306CurrentTrain: epoch  7, batch     1 | loss: 95.4566779CurrentTrain: epoch  7, batch     2 | loss: 78.2191315CurrentTrain: epoch  7, batch     3 | loss: 77.4530382CurrentTrain: epoch  8, batch     0 | loss: 66.9336430CurrentTrain: epoch  8, batch     1 | loss: 67.5102624CurrentTrain: epoch  8, batch     2 | loss: 82.0122979CurrentTrain: epoch  8, batch     3 | loss: 79.0386605CurrentTrain: epoch  9, batch     0 | loss: 65.3951786CurrentTrain: epoch  9, batch     1 | loss: 62.8398246CurrentTrain: epoch  9, batch     2 | loss: 167.9463768CurrentTrain: epoch  9, batch     3 | loss: 101.2486959
MemoryTrain:  epoch  0, batch     0 | loss: 0.9591211MemoryTrain:  epoch  1, batch     0 | loss: 0.8957098MemoryTrain:  epoch  2, batch     0 | loss: 0.7621802MemoryTrain:  epoch  3, batch     0 | loss: 0.6096483MemoryTrain:  epoch  4, batch     0 | loss: 0.5652630MemoryTrain:  epoch  5, batch     0 | loss: 0.4794271MemoryTrain:  epoch  6, batch     0 | loss: 0.4470954MemoryTrain:  epoch  7, batch     0 | loss: 0.4411610MemoryTrain:  epoch  8, batch     0 | loss: 0.3294681MemoryTrain:  epoch  9, batch     0 | loss: 0.3635237

F1 score per class: {0: np.float64(0.9014084507042254), 2: np.float64(0.0), 4: np.float64(0.8235294117647058), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.2857142857142857), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.5454545454545454), 23: np.float64(0.7555555555555555), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.6385542168674698
Weighted-average F1 score: 0.533979038484531
F1 score per class: {0: np.float64(0.7951807228915663), 2: np.float64(0.0), 4: np.float64(0.8128342245989305), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.26666666666666666), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.425531914893617), 23: np.float64(0.6590909090909091), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5186385737439222
Weighted-average F1 score: 0.41257631075770984
F1 score per class: {0: np.float64(0.8311688311688312), 2: np.float64(0.0), 4: np.float64(0.8522727272727273), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.25), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.4421052631578947), 23: np.float64(0.6823529411764706), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5435897435897435
Weighted-average F1 score: 0.42464007979805946

F1 score per class: {0: np.float64(0.7804878048780488), 2: np.float64(0.36363636363636365), 4: np.float64(0.8235294117647058), 5: np.float64(0.8663594470046083), 6: np.float64(0.5067873303167421), 10: np.float64(0.17391304347826086), 11: np.float64(0.33507853403141363), 12: np.float64(0.3854166666666667), 13: np.float64(0.043478260869565216), 16: np.float64(0.47619047619047616), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.7521367521367521), 21: np.float64(0.328125), 23: np.float64(0.7157894736842105), 24: np.float64(0.19047619047619047), 26: np.float64(0.7208121827411168), 28: np.float64(0.0), 29: np.float64(0.8601036269430051), 32: np.float64(0.694980694980695), 39: np.float64(0.27906976744186046)}
Micro-average F1 score: 0.5742956387495176
Weighted-average F1 score: 0.5760719906647921
F1 score per class: {0: np.float64(0.48175182481751827), 2: np.float64(0.3181818181818182), 4: np.float64(0.7875647668393783), 5: np.float64(0.6510067114093959), 6: np.float64(0.4777327935222672), 10: np.float64(0.3150684931506849), 11: np.float64(0.37073170731707317), 12: np.float64(0.3709677419354839), 13: np.float64(0.039603960396039604), 16: np.float64(0.65625), 17: np.float64(0.0), 18: np.float64(0.21818181818181817), 19: np.float64(0.6886446886446886), 21: np.float64(0.20725388601036268), 23: np.float64(0.6041666666666666), 24: np.float64(0.3225806451612903), 26: np.float64(0.6729857819905213), 28: np.float64(0.12698412698412698), 29: np.float64(0.8383838383838383), 32: np.float64(0.6453900709219859), 39: np.float64(0.20833333333333334)}
Micro-average F1 score: 0.5155951623169955
Weighted-average F1 score: 0.49732568099768654
F1 score per class: {0: np.float64(0.5981308411214953), 2: np.float64(0.3783783783783784), 4: np.float64(0.847457627118644), 5: np.float64(0.7384615384615385), 6: np.float64(0.49382716049382713), 10: np.float64(0.2595419847328244), 11: np.float64(0.35514018691588783), 12: np.float64(0.36444444444444446), 13: np.float64(0.035398230088495575), 16: np.float64(0.6545454545454545), 17: np.float64(0.0), 18: np.float64(0.2222222222222222), 19: np.float64(0.7265625), 21: np.float64(0.20588235294117646), 23: np.float64(0.6170212765957447), 24: np.float64(0.32), 26: np.float64(0.6859903381642513), 28: np.float64(0.17777777777777778), 29: np.float64(0.8426395939086294), 32: np.float64(0.6618705035971223), 39: np.float64(0.19230769230769232)}
Micro-average F1 score: 0.5323499832383507
Weighted-average F1 score: 0.5119082217529362

F1 score per class: {0: np.float64(0.8533333333333334), 2: np.float64(0.0), 4: np.float64(0.7954545454545454), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.16666666666666666), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.39622641509433965), 23: np.float64(0.6868686868686869), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.48773006134969327
Weighted-average F1 score: 0.3738009991600139
F1 score per class: {0: np.float64(0.7096774193548387), 2: np.float64(0.0), 4: np.float64(0.7638190954773869), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.13333333333333333), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3252032520325203), 23: np.float64(0.5979381443298969), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.38369304556354916
Weighted-average F1 score: 0.2907312144510624
F1 score per class: {0: np.float64(0.7529411764705882), 2: np.float64(0.0), 4: np.float64(0.8108108108108109), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.13793103448275862), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.328125), 23: np.float64(0.6105263157894737), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.4050955414012739
Weighted-average F1 score: 0.3000067758849347

F1 score per class: {0: np.float64(0.6666666666666666), 2: np.float64(0.24), 4: np.float64(0.7821229050279329), 5: np.float64(0.7258687258687259), 6: np.float64(0.2994652406417112), 10: np.float64(0.16666666666666666), 11: np.float64(0.22377622377622378), 12: np.float64(0.21082621082621084), 13: np.float64(0.02127659574468085), 16: np.float64(0.35714285714285715), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.6795366795366795), 21: np.float64(0.20689655172413793), 23: np.float64(0.5811965811965812), 24: np.float64(0.14814814814814814), 26: np.float64(0.6396396396396397), 28: np.float64(0.0), 29: np.float64(0.7477477477477478), 32: np.float64(0.4918032786885246), 39: np.float64(0.15584415584415584)}
Micro-average F1 score: 0.4198645598194131
Weighted-average F1 score: 0.39710693648440515
F1 score per class: {0: np.float64(0.38823529411764707), 2: np.float64(0.20588235294117646), 4: np.float64(0.6909090909090909), 5: np.float64(0.45539906103286387), 6: np.float64(0.2651685393258427), 10: np.float64(0.24864864864864866), 11: np.float64(0.26480836236933797), 12: np.float64(0.2039911308203991), 13: np.float64(0.022598870056497175), 16: np.float64(0.4077669902912621), 17: np.float64(0.0), 18: np.float64(0.12371134020618557), 19: np.float64(0.618421052631579), 21: np.float64(0.14184397163120568), 23: np.float64(0.48739495798319327), 24: np.float64(0.18867924528301888), 26: np.float64(0.5916666666666667), 28: np.float64(0.06722689075630252), 29: np.float64(0.7155172413793104), 32: np.float64(0.4607594936708861), 39: np.float64(0.11235955056179775)}
Micro-average F1 score: 0.3618494527585437
Weighted-average F1 score: 0.3408434030526232
F1 score per class: {0: np.float64(0.48484848484848486), 2: np.float64(0.23333333333333334), 4: np.float64(0.7692307692307693), 5: np.float64(0.5378151260504201), 6: np.float64(0.2803738317757009), 10: np.float64(0.23129251700680273), 11: np.float64(0.25333333333333335), 12: np.float64(0.1971153846153846), 13: np.float64(0.01904761904761905), 16: np.float64(0.43373493975903615), 17: np.float64(0.0), 18: np.float64(0.1276595744680851), 19: np.float64(0.6526315789473685), 21: np.float64(0.1390728476821192), 23: np.float64(0.5043478260869565), 24: np.float64(0.21621621621621623), 26: np.float64(0.6068376068376068), 28: np.float64(0.0963855421686747), 29: np.float64(0.7186147186147186), 32: np.float64(0.46938775510204084), 39: np.float64(0.10638297872340426)}
Micro-average F1 score: 0.37728676645283915
Weighted-average F1 score: 0.3519283297480718
cur_acc_wo_na:  ['0.7600', '0.5577', '0.4851', '0.6386']
his_acc_wo_na:  ['0.7600', '0.6870', '0.5767', '0.5743']
cur_acc des_wo_na:  ['0.7359', '0.5245', '0.4087', '0.5186']
his_acc des_wo_na:  ['0.7359', '0.6336', '0.5514', '0.5156']
cur_acc rrf_wo_na:  ['0.7465', '0.5515', '0.4444', '0.5436']
his_acc rrf_wo_na:  ['0.7465', '0.6577', '0.5696', '0.5323']
cur_acc_w_na:  ['0.6364', '0.4236', '0.3481', '0.4877']
his_acc_w_na:  ['0.6364', '0.5397', '0.4190', '0.4199']
cur_acc des_w_na:  ['0.6062', '0.3652', '0.2799', '0.3837']
his_acc des_w_na:  ['0.6062', '0.4669', '0.3823', '0.3618']
cur_acc rrf_w_na:  ['0.6189', '0.3892', '0.3050', '0.4051']
his_acc rrf_w_na:  ['0.6189', '0.4898', '0.3989', '0.3773']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 77.3744587CurrentTrain: epoch  0, batch     1 | loss: 118.6174160CurrentTrain: epoch  0, batch     2 | loss: 95.1477972CurrentTrain: epoch  0, batch     3 | loss: 77.5999695CurrentTrain: epoch  1, batch     0 | loss: 90.2422814CurrentTrain: epoch  1, batch     1 | loss: 73.8677422CurrentTrain: epoch  1, batch     2 | loss: 135.6988574CurrentTrain: epoch  1, batch     3 | loss: 56.0573202CurrentTrain: epoch  2, batch     0 | loss: 100.1100744CurrentTrain: epoch  2, batch     1 | loss: 79.9261376CurrentTrain: epoch  2, batch     2 | loss: 71.2971274CurrentTrain: epoch  2, batch     3 | loss: 73.7774761CurrentTrain: epoch  3, batch     0 | loss: 84.0248192CurrentTrain: epoch  3, batch     1 | loss: 79.3820037CurrentTrain: epoch  3, batch     2 | loss: 82.3579309CurrentTrain: epoch  3, batch     3 | loss: 87.2128451CurrentTrain: epoch  4, batch     0 | loss: 81.7301844CurrentTrain: epoch  4, batch     1 | loss: 85.5050337CurrentTrain: epoch  4, batch     2 | loss: 68.0098229CurrentTrain: epoch  4, batch     3 | loss: 52.7754518CurrentTrain: epoch  5, batch     0 | loss: 80.9991876CurrentTrain: epoch  5, batch     1 | loss: 75.3975393CurrentTrain: epoch  5, batch     2 | loss: 81.8802288CurrentTrain: epoch  5, batch     3 | loss: 68.2048587CurrentTrain: epoch  6, batch     0 | loss: 73.4330349CurrentTrain: epoch  6, batch     1 | loss: 68.2707312CurrentTrain: epoch  6, batch     2 | loss: 100.7903776CurrentTrain: epoch  6, batch     3 | loss: 53.3140480CurrentTrain: epoch  7, batch     0 | loss: 77.0063798CurrentTrain: epoch  7, batch     1 | loss: 78.8364407CurrentTrain: epoch  7, batch     2 | loss: 93.7255254CurrentTrain: epoch  7, batch     3 | loss: 62.5423949CurrentTrain: epoch  8, batch     0 | loss: 96.8049374CurrentTrain: epoch  8, batch     1 | loss: 64.3884220CurrentTrain: epoch  8, batch     2 | loss: 74.8494140CurrentTrain: epoch  8, batch     3 | loss: 64.0284086CurrentTrain: epoch  9, batch     0 | loss: 76.6609946CurrentTrain: epoch  9, batch     1 | loss: 77.3153000CurrentTrain: epoch  9, batch     2 | loss: 79.4261303CurrentTrain: epoch  9, batch     3 | loss: 46.3093200
MemoryTrain:  epoch  0, batch     0 | loss: 0.9309904MemoryTrain:  epoch  1, batch     0 | loss: 0.8382953MemoryTrain:  epoch  2, batch     0 | loss: 0.6990053MemoryTrain:  epoch  3, batch     0 | loss: 0.5608044MemoryTrain:  epoch  4, batch     0 | loss: 0.4563041MemoryTrain:  epoch  5, batch     0 | loss: 0.3993061MemoryTrain:  epoch  6, batch     0 | loss: 0.3423458MemoryTrain:  epoch  7, batch     0 | loss: 0.2961165MemoryTrain:  epoch  8, batch     0 | loss: 0.2395256MemoryTrain:  epoch  9, batch     0 | loss: 0.2148900

F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.7619047619047619), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.5945945945945946), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.8080808080808081), 37: np.float64(0.34210526315789475), 38: np.float64(0.7017543859649122)}
Micro-average F1 score: 0.4835680751173709
Weighted-average F1 score: 0.3825532162374268
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.6666666666666666), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.6097560975609756), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.8380952380952381), 37: np.float64(0.5555555555555556), 38: np.float64(0.7540983606557377), 39: np.float64(0.0)}
Micro-average F1 score: 0.4726027397260274
Weighted-average F1 score: 0.36667120544546083
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.6666666666666666), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.6075949367088608), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.8349514563106796), 37: np.float64(0.5490196078431373), 38: np.float64(0.7666666666666667), 39: np.float64(0.0)}
Micro-average F1 score: 0.49500998003992014
Weighted-average F1 score: 0.3758267640512434

F1 score per class: {0: np.float64(0.7792207792207793), 2: np.float64(0.4), 4: np.float64(0.8304093567251462), 5: np.float64(0.7768595041322314), 6: np.float64(0.43601895734597157), 10: np.float64(0.05660377358490566), 11: np.float64(0.2926829268292683), 12: np.float64(0.4387755102040816), 13: np.float64(0.046511627906976744), 15: np.float64(0.21052631578947367), 16: np.float64(0.6122448979591837), 17: np.float64(0.0), 18: np.float64(0.10714285714285714), 19: np.float64(0.7172995780590717), 21: np.float64(0.22018348623853212), 23: np.float64(0.7126436781609196), 24: np.float64(0.09523809523809523), 25: np.float64(0.5945945945945946), 26: np.float64(0.7244897959183674), 28: np.float64(0.20689655172413793), 29: np.float64(0.8585858585858586), 32: np.float64(0.7142857142857143), 35: np.float64(0.5673758865248227), 37: np.float64(0.14772727272727273), 38: np.float64(0.2222222222222222), 39: np.float64(0.0)}
Micro-average F1 score: 0.5073260073260073
Weighted-average F1 score: 0.491411578708279
F1 score per class: {0: np.float64(0.528), 2: np.float64(0.2413793103448276), 4: np.float64(0.7575757575757576), 5: np.float64(0.5384615384615384), 6: np.float64(0.44360902255639095), 10: np.float64(0.22900763358778625), 11: np.float64(0.2360248447204969), 12: np.float64(0.38461538461538464), 13: np.float64(0.03571428571428571), 15: np.float64(0.2857142857142857), 16: np.float64(0.6133333333333333), 17: np.float64(0.0), 18: np.float64(0.21875), 19: np.float64(0.6715328467153284), 21: np.float64(0.17475728155339806), 23: np.float64(0.6021505376344086), 24: np.float64(0.41025641025641024), 25: np.float64(0.6097560975609756), 26: np.float64(0.676056338028169), 28: np.float64(0.18181818181818182), 29: np.float64(0.8543689320388349), 32: np.float64(0.6976744186046512), 35: np.float64(0.5057471264367817), 37: np.float64(0.1388888888888889), 38: np.float64(0.22330097087378642), 39: np.float64(0.11764705882352941)}
Micro-average F1 score: 0.4359275805313896
Weighted-average F1 score: 0.4045444472041453
F1 score per class: {0: np.float64(0.7529411764705882), 2: np.float64(0.2978723404255319), 4: np.float64(0.8295454545454546), 5: np.float64(0.6577181208053692), 6: np.float64(0.46153846153846156), 10: np.float64(0.17886178861788618), 11: np.float64(0.2557077625570776), 12: np.float64(0.4051724137931034), 13: np.float64(0.0380952380952381), 15: np.float64(0.24489795918367346), 16: np.float64(0.6774193548387096), 17: np.float64(0.0), 18: np.float64(0.15384615384615385), 19: np.float64(0.696969696969697), 21: np.float64(0.19607843137254902), 23: np.float64(0.6136363636363636), 24: np.float64(0.3448275862068966), 25: np.float64(0.6075949367088608), 26: np.float64(0.6794258373205742), 28: np.float64(0.18181818181818182), 29: np.float64(0.8502415458937198), 32: np.float64(0.7086614173228346), 35: np.float64(0.5308641975308642), 37: np.float64(0.14814814814814814), 38: np.float64(0.21904761904761905), 39: np.float64(0.10526315789473684)}
Micro-average F1 score: 0.4673913043478261
Weighted-average F1 score: 0.4361088579489023

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.5), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.5365853658536586), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.7017543859649122), 37: np.float64(0.29545454545454547), 38: np.float64(0.5)}
Micro-average F1 score: 0.34390651085141904
Weighted-average F1 score: 0.2652784285530817
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.5217391304347826), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5319148936170213), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.7096774193548387), 37: np.float64(0.46511627906976744), 38: np.float64(0.4842105263157895), 39: np.float64(0.0)}
Micro-average F1 score: 0.323943661971831
Weighted-average F1 score: 0.2541699145306331
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.48), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5274725274725275), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.7107438016528925), 37: np.float64(0.45528455284552843), 38: np.float64(0.5411764705882353), 39: np.float64(0.0)}
Micro-average F1 score: 0.33787465940054495
Weighted-average F1 score: 0.25713598562838413

F1 score per class: {0: np.float64(0.6521739130434783), 2: np.float64(0.2641509433962264), 4: np.float64(0.7802197802197802), 5: np.float64(0.6103896103896104), 6: np.float64(0.26512968299711814), 10: np.float64(0.05504587155963303), 11: np.float64(0.20055710306406685), 12: np.float64(0.21882951653944022), 13: np.float64(0.025974025974025976), 15: np.float64(0.1032258064516129), 16: np.float64(0.42857142857142855), 17: np.float64(0.0), 18: np.float64(0.06896551724137931), 19: np.float64(0.6227106227106227), 21: np.float64(0.15789473684210525), 23: np.float64(0.6078431372549019), 24: np.float64(0.07142857142857142), 25: np.float64(0.5365853658536586), 26: np.float64(0.6283185840707964), 28: np.float64(0.09523809523809523), 29: np.float64(0.6995884773662552), 32: np.float64(0.5421686746987951), 35: np.float64(0.39800995024875624), 37: np.float64(0.09352517985611511), 38: np.float64(0.11834319526627218), 39: np.float64(0.0)}
Micro-average F1 score: 0.35711216158143533
Weighted-average F1 score: 0.3311785882999746
F1 score per class: {0: np.float64(0.38823529411764707), 2: np.float64(0.14736842105263157), 4: np.float64(0.6818181818181818), 5: np.float64(0.3649906890130354), 6: np.float64(0.25), 10: np.float64(0.18518518518518517), 11: np.float64(0.17757009345794392), 12: np.float64(0.18867924528301888), 13: np.float64(0.019801980198019802), 15: np.float64(0.1875), 16: np.float64(0.3709677419354839), 17: np.float64(0.0), 18: np.float64(0.12844036697247707), 19: np.float64(0.5954692556634305), 21: np.float64(0.11688311688311688), 23: np.float64(0.4745762711864407), 24: np.float64(0.20253164556962025), 25: np.float64(0.5102040816326531), 26: np.float64(0.5714285714285714), 28: np.float64(0.1), 29: np.float64(0.676923076923077), 32: np.float64(0.5187319884726225), 35: np.float64(0.3384615384615385), 37: np.float64(0.08592910848549946), 38: np.float64(0.11302211302211303), 39: np.float64(0.08)}
Micro-average F1 score: 0.2904590318032273
Weighted-average F1 score: 0.266295879494554
F1 score per class: {0: np.float64(0.5981308411214953), 2: np.float64(0.19444444444444445), 4: np.float64(0.7724867724867724), 5: np.float64(0.4792176039119804), 6: np.float64(0.2714285714285714), 10: np.float64(0.15942028985507245), 11: np.float64(0.1761006289308176), 12: np.float64(0.19222903885480572), 13: np.float64(0.02127659574468085), 15: np.float64(0.15384615384615385), 16: np.float64(0.4158415841584158), 17: np.float64(0.0), 18: np.float64(0.10204081632653061), 19: np.float64(0.6174496644295302), 21: np.float64(0.12578616352201258), 23: np.float64(0.48214285714285715), 24: np.float64(0.20408163265306123), 25: np.float64(0.5), 26: np.float64(0.5843621399176955), 28: np.float64(0.08695652173913043), 29: np.float64(0.6901960784313725), 32: np.float64(0.5263157894736842), 35: np.float64(0.35390946502057613), 37: np.float64(0.08931419457735247), 38: np.float64(0.11246943765281174), 39: np.float64(0.08)}
Micro-average F1 score: 0.3154585152838428
Weighted-average F1 score: 0.2877673085169171
cur_acc_wo_na:  ['0.7600', '0.5577', '0.4851', '0.6386', '0.4836']
his_acc_wo_na:  ['0.7600', '0.6870', '0.5767', '0.5743', '0.5073']
cur_acc des_wo_na:  ['0.7359', '0.5245', '0.4087', '0.5186', '0.4726']
his_acc des_wo_na:  ['0.7359', '0.6336', '0.5514', '0.5156', '0.4359']
cur_acc rrf_wo_na:  ['0.7465', '0.5515', '0.4444', '0.5436', '0.4950']
his_acc rrf_wo_na:  ['0.7465', '0.6577', '0.5696', '0.5323', '0.4674']
cur_acc_w_na:  ['0.6364', '0.4236', '0.3481', '0.4877', '0.3439']
his_acc_w_na:  ['0.6364', '0.5397', '0.4190', '0.4199', '0.3571']
cur_acc des_w_na:  ['0.6062', '0.3652', '0.2799', '0.3837', '0.3239']
his_acc des_w_na:  ['0.6062', '0.4669', '0.3823', '0.3618', '0.2905']
cur_acc rrf_w_na:  ['0.6189', '0.3892', '0.3050', '0.4051', '0.3379']
his_acc rrf_w_na:  ['0.6189', '0.4898', '0.3989', '0.3773', '0.3155']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 95.1678681CurrentTrain: epoch  0, batch     1 | loss: 98.9056613CurrentTrain: epoch  0, batch     2 | loss: 78.2170025CurrentTrain: epoch  0, batch     3 | loss: 59.0211889CurrentTrain: epoch  1, batch     0 | loss: 75.2773871CurrentTrain: epoch  1, batch     1 | loss: 74.9729753CurrentTrain: epoch  1, batch     2 | loss: 83.9275791CurrentTrain: epoch  1, batch     3 | loss: 54.8423461CurrentTrain: epoch  2, batch     0 | loss: 70.9729232CurrentTrain: epoch  2, batch     1 | loss: 103.5406256CurrentTrain: epoch  2, batch     2 | loss: 86.2382622CurrentTrain: epoch  2, batch     3 | loss: 51.8869753CurrentTrain: epoch  3, batch     0 | loss: 69.8517499CurrentTrain: epoch  3, batch     1 | loss: 101.3990689CurrentTrain: epoch  3, batch     2 | loss: 82.7451751CurrentTrain: epoch  3, batch     3 | loss: 49.0263972CurrentTrain: epoch  4, batch     0 | loss: 68.1341606CurrentTrain: epoch  4, batch     1 | loss: 80.9815225CurrentTrain: epoch  4, batch     2 | loss: 67.8369691CurrentTrain: epoch  4, batch     3 | loss: 105.6916426CurrentTrain: epoch  5, batch     0 | loss: 92.2894904CurrentTrain: epoch  5, batch     1 | loss: 80.0239619CurrentTrain: epoch  5, batch     2 | loss: 98.4660405CurrentTrain: epoch  5, batch     3 | loss: 46.6712768CurrentTrain: epoch  6, batch     0 | loss: 79.0155919CurrentTrain: epoch  6, batch     1 | loss: 94.9482368CurrentTrain: epoch  6, batch     2 | loss: 67.1186117CurrentTrain: epoch  6, batch     3 | loss: 52.8108589CurrentTrain: epoch  7, batch     0 | loss: 78.2082334CurrentTrain: epoch  7, batch     1 | loss: 81.1055497CurrentTrain: epoch  7, batch     2 | loss: 61.0237155CurrentTrain: epoch  7, batch     3 | loss: 59.4995932CurrentTrain: epoch  8, batch     0 | loss: 92.2790792CurrentTrain: epoch  8, batch     1 | loss: 91.8456463CurrentTrain: epoch  8, batch     2 | loss: 89.1203743CurrentTrain: epoch  8, batch     3 | loss: 47.0134465CurrentTrain: epoch  9, batch     0 | loss: 74.7775462CurrentTrain: epoch  9, batch     1 | loss: 98.4967004CurrentTrain: epoch  9, batch     2 | loss: 90.9895462CurrentTrain: epoch  9, batch     3 | loss: 34.7358564
MemoryTrain:  epoch  0, batch     0 | loss: 0.7788446MemoryTrain:  epoch  1, batch     0 | loss: 0.8044750MemoryTrain:  epoch  2, batch     0 | loss: 0.6080196MemoryTrain:  epoch  3, batch     0 | loss: 0.4642439MemoryTrain:  epoch  4, batch     0 | loss: 0.4184529MemoryTrain:  epoch  5, batch     0 | loss: 0.3604905MemoryTrain:  epoch  6, batch     0 | loss: 0.3503982MemoryTrain:  epoch  7, batch     0 | loss: 0.2835332MemoryTrain:  epoch  8, batch     0 | loss: 0.2520172MemoryTrain:  epoch  9, batch     0 | loss: 0.2322576

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.5853658536585366), 11: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.8807339449541285), 21: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.9473684210526315), 32: np.float64(0.0), 33: np.float64(0.4), 36: np.float64(0.4444444444444444), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5506607929515418
Weighted-average F1 score: 0.4631946165596514
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.7417218543046358), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.8380952380952381), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.75), 32: np.float64(0.0), 33: np.float64(0.4444444444444444), 35: np.float64(0.0), 36: np.float64(0.6758620689655173), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5269645608628659
Weighted-average F1 score: 0.41367847249657563
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.7114093959731543), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.8333333333333334), 21: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8372093023255814), 32: np.float64(0.0), 33: np.float64(0.5333333333333333), 35: np.float64(0.0), 36: np.float64(0.6423357664233577), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5475792988313857
Weighted-average F1 score: 0.43806531231353313

F1 score per class: {0: np.float64(0.7948717948717948), 2: np.float64(0.4827586206896552), 4: np.float64(0.7804878048780488), 5: np.float64(0.8407079646017699), 6: np.float64(0.4368932038834951), 8: np.float64(0.4022346368715084), 10: np.float64(0.07692307692307693), 11: np.float64(0.22325581395348837), 12: np.float64(0.2857142857142857), 13: np.float64(0.07142857142857142), 15: np.float64(0.28), 16: np.float64(0.3076923076923077), 17: np.float64(0.0), 18: np.float64(0.08333333333333333), 19: np.float64(0.7906976744186046), 20: np.float64(0.4528301886792453), 21: np.float64(0.17582417582417584), 23: np.float64(0.5897435897435898), 24: np.float64(0.2727272727272727), 25: np.float64(0.4), 26: np.float64(0.6831683168316832), 28: np.float64(0.19047619047619047), 29: np.float64(0.835820895522388), 30: np.float64(0.9230769230769231), 32: np.float64(0.6524822695035462), 33: np.float64(0.15789473684210525), 35: np.float64(0.4631578947368421), 36: np.float64(0.273972602739726), 37: np.float64(0.1917808219178082), 38: np.float64(0.3076923076923077), 39: np.float64(0.0)}
Micro-average F1 score: 0.4986830553116769
Weighted-average F1 score: 0.5127292199563046
F1 score per class: {0: np.float64(0.532258064516129), 2: np.float64(0.23728813559322035), 4: np.float64(0.8287292817679558), 5: np.float64(0.5577464788732395), 6: np.float64(0.45161290322580644), 8: np.float64(0.40875912408759124), 10: np.float64(0.14516129032258066), 11: np.float64(0.28846153846153844), 12: np.float64(0.34545454545454546), 13: np.float64(0.07017543859649122), 15: np.float64(0.2857142857142857), 16: np.float64(0.4927536231884058), 17: np.float64(0.0), 18: np.float64(0.19607843137254902), 19: np.float64(0.6716981132075471), 20: np.float64(0.47058823529411764), 21: np.float64(0.20765027322404372), 23: np.float64(0.5591397849462365), 24: np.float64(0.391304347826087), 25: np.float64(0.3684210526315789), 26: np.float64(0.6572769953051644), 28: np.float64(0.23076923076923078), 29: np.float64(0.8450704225352113), 30: np.float64(0.46153846153846156), 32: np.float64(0.6844106463878327), 33: np.float64(0.16), 35: np.float64(0.48863636363636365), 36: np.float64(0.3161290322580645), 37: np.float64(0.09865470852017937), 38: np.float64(0.21782178217821782), 39: np.float64(0.06666666666666667)}
Micro-average F1 score: 0.44430135222150674
Weighted-average F1 score: 0.4309530088312912
F1 score per class: {0: np.float64(0.6666666666666666), 2: np.float64(0.32558139534883723), 4: np.float64(0.8255813953488372), 5: np.float64(0.7111111111111111), 6: np.float64(0.4344262295081967), 8: np.float64(0.39849624060150374), 10: np.float64(0.11570247933884298), 11: np.float64(0.2540983606557377), 12: np.float64(0.3490566037735849), 13: np.float64(0.06779661016949153), 15: np.float64(0.25), 16: np.float64(0.43137254901960786), 17: np.float64(0.0), 18: np.float64(0.2), 19: np.float64(0.714859437751004), 20: np.float64(0.44776119402985076), 21: np.float64(0.22988505747126436), 23: np.float64(0.6097560975609756), 24: np.float64(0.3684210526315789), 25: np.float64(0.4), 26: np.float64(0.6730769230769231), 28: np.float64(0.24), 29: np.float64(0.8309178743961353), 30: np.float64(0.5294117647058824), 32: np.float64(0.6642335766423357), 33: np.float64(0.1568627450980392), 35: np.float64(0.47368421052631576), 36: np.float64(0.3087719298245614), 37: np.float64(0.13333333333333333), 38: np.float64(0.23668639053254437), 39: np.float64(0.0)}
Micro-average F1 score: 0.4594407210538479
Weighted-average F1 score: 0.4471913957081196

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.5333333333333333), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.6274509803921569), 21: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.9), 32: np.float64(0.0), 33: np.float64(0.4), 35: np.float64(0.0), 36: np.float64(0.37735849056603776), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.3968253968253968
Weighted-average F1 score: 0.3170726483244738
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.6187845303867403), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5827814569536424), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.6545454545454545), 32: np.float64(0.0), 33: np.float64(0.4444444444444444), 35: np.float64(0.0), 36: np.float64(0.5130890052356021), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.34826883910386963
Weighted-average F1 score: 0.27858738680742356
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.5888888888888889), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5844155844155844), 21: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.75), 32: np.float64(0.0), 33: np.float64(0.47058823529411764), 35: np.float64(0.0), 36: np.float64(0.4756756756756757), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.36403995560488345
Weighted-average F1 score: 0.2954037212816844

F1 score per class: {0: np.float64(0.6326530612244898), 2: np.float64(0.2916666666666667), 4: np.float64(0.7441860465116279), 5: np.float64(0.7063197026022305), 6: np.float64(0.2616279069767442), 8: np.float64(0.3), 10: np.float64(0.07547169811320754), 11: np.float64(0.17582417582417584), 12: np.float64(0.1660377358490566), 13: np.float64(0.041666666666666664), 15: np.float64(0.15555555555555556), 16: np.float64(0.25), 17: np.float64(0.0), 18: np.float64(0.05405405405405406), 19: np.float64(0.7203389830508474), 20: np.float64(0.22018348623853212), 21: np.float64(0.12903225806451613), 23: np.float64(0.5476190476190477), 24: np.float64(0.20689655172413793), 25: np.float64(0.38235294117647056), 26: np.float64(0.5948275862068966), 28: np.float64(0.12903225806451613), 29: np.float64(0.6829268292682927), 30: np.float64(0.8372093023255814), 32: np.float64(0.48293963254593175), 33: np.float64(0.11538461538461539), 35: np.float64(0.3333333333333333), 36: np.float64(0.1941747572815534), 37: np.float64(0.1794871794871795), 38: np.float64(0.22988505747126436), 39: np.float64(0.0)}
Micro-average F1 score: 0.36947094535993064
Weighted-average F1 score: 0.3573119450141384
F1 score per class: {0: np.float64(0.4), 2: np.float64(0.16279069767441862), 4: np.float64(0.7653061224489796), 5: np.float64(0.3574007220216607), 6: np.float64(0.26666666666666666), 8: np.float64(0.23578947368421052), 10: np.float64(0.13043478260869565), 11: np.float64(0.21660649819494585), 12: np.float64(0.18581907090464547), 13: np.float64(0.039603960396039604), 15: np.float64(0.17391304347826086), 16: np.float64(0.3148148148148148), 17: np.float64(0.0), 18: np.float64(0.1388888888888889), 19: np.float64(0.5973154362416108), 20: np.float64(0.2328042328042328), 21: np.float64(0.14901960784313725), 23: np.float64(0.4297520661157025), 24: np.float64(0.20689655172413793), 25: np.float64(0.35), 26: np.float64(0.5668016194331984), 28: np.float64(0.13636363636363635), 29: np.float64(0.6642066420664207), 30: np.float64(0.3333333333333333), 32: np.float64(0.5070422535211268), 33: np.float64(0.11764705882352941), 35: np.float64(0.3104693140794224), 36: np.float64(0.21030042918454936), 37: np.float64(0.05459057071960298), 38: np.float64(0.12607449856733524), 39: np.float64(0.037037037037037035)}
Micro-average F1 score: 0.2980561555075594
Weighted-average F1 score: 0.28217520184844824
F1 score per class: {0: np.float64(0.5039370078740157), 2: np.float64(0.21212121212121213), 4: np.float64(0.7717391304347826), 5: np.float64(0.5378151260504201), 6: np.float64(0.2566585956416465), 8: np.float64(0.22894168466522677), 10: np.float64(0.10687022900763359), 11: np.float64(0.18562874251497005), 12: np.float64(0.18048780487804877), 13: np.float64(0.038834951456310676), 15: np.float64(0.14814814814814814), 16: np.float64(0.3013698630136986), 17: np.float64(0.0), 18: np.float64(0.12658227848101267), 19: np.float64(0.6402877697841727), 20: np.float64(0.22167487684729065), 21: np.float64(0.1532567049808429), 23: np.float64(0.49019607843137253), 24: np.float64(0.23728813559322035), 25: np.float64(0.3783783783783784), 26: np.float64(0.5809128630705395), 28: np.float64(0.14285714285714285), 29: np.float64(0.6615384615384615), 30: np.float64(0.41379310344827586), 32: np.float64(0.4932249322493225), 33: np.float64(0.09876543209876543), 35: np.float64(0.314410480349345), 36: np.float64(0.20512820512820512), 37: np.float64(0.08494208494208494), 38: np.float64(0.13114754098360656), 39: np.float64(0.0)}
Micro-average F1 score: 0.3136141347215649
Weighted-average F1 score: 0.2956934037555205
cur_acc_wo_na:  ['0.7600', '0.5577', '0.4851', '0.6386', '0.4836', '0.5507']
his_acc_wo_na:  ['0.7600', '0.6870', '0.5767', '0.5743', '0.5073', '0.4987']
cur_acc des_wo_na:  ['0.7359', '0.5245', '0.4087', '0.5186', '0.4726', '0.5270']
his_acc des_wo_na:  ['0.7359', '0.6336', '0.5514', '0.5156', '0.4359', '0.4443']
cur_acc rrf_wo_na:  ['0.7465', '0.5515', '0.4444', '0.5436', '0.4950', '0.5476']
his_acc rrf_wo_na:  ['0.7465', '0.6577', '0.5696', '0.5323', '0.4674', '0.4594']
cur_acc_w_na:  ['0.6364', '0.4236', '0.3481', '0.4877', '0.3439', '0.3968']
his_acc_w_na:  ['0.6364', '0.5397', '0.4190', '0.4199', '0.3571', '0.3695']
cur_acc des_w_na:  ['0.6062', '0.3652', '0.2799', '0.3837', '0.3239', '0.3483']
his_acc des_w_na:  ['0.6062', '0.4669', '0.3823', '0.3618', '0.2905', '0.2981']
cur_acc rrf_w_na:  ['0.6189', '0.3892', '0.3050', '0.4051', '0.3379', '0.3640']
his_acc rrf_w_na:  ['0.6189', '0.4898', '0.3989', '0.3773', '0.3155', '0.3136']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 105.1431182CurrentTrain: epoch  0, batch     1 | loss: 83.0662031CurrentTrain: epoch  0, batch     2 | loss: 92.3170909CurrentTrain: epoch  0, batch     3 | loss: 12.6390255CurrentTrain: epoch  1, batch     0 | loss: 72.8540362CurrentTrain: epoch  1, batch     1 | loss: 76.5181168CurrentTrain: epoch  1, batch     2 | loss: 113.1003046CurrentTrain: epoch  1, batch     3 | loss: 25.5822012CurrentTrain: epoch  2, batch     0 | loss: 72.3669653CurrentTrain: epoch  2, batch     1 | loss: 81.1322958CurrentTrain: epoch  2, batch     2 | loss: 70.8117721CurrentTrain: epoch  2, batch     3 | loss: 19.8232959CurrentTrain: epoch  3, batch     0 | loss: 81.1719514CurrentTrain: epoch  3, batch     1 | loss: 79.6003444CurrentTrain: epoch  3, batch     2 | loss: 94.1336057CurrentTrain: epoch  3, batch     3 | loss: 20.5394457CurrentTrain: epoch  4, batch     0 | loss: 77.2928826CurrentTrain: epoch  4, batch     1 | loss: 70.9710309CurrentTrain: epoch  4, batch     2 | loss: 66.9271581CurrentTrain: epoch  4, batch     3 | loss: 5.4685713CurrentTrain: epoch  5, batch     0 | loss: 65.9855279CurrentTrain: epoch  5, batch     1 | loss: 75.7538451CurrentTrain: epoch  5, batch     2 | loss: 76.8661038CurrentTrain: epoch  5, batch     3 | loss: 18.1594880CurrentTrain: epoch  6, batch     0 | loss: 68.4959956CurrentTrain: epoch  6, batch     1 | loss: 62.5576974CurrentTrain: epoch  6, batch     2 | loss: 79.0885800CurrentTrain: epoch  6, batch     3 | loss: 3.9732166CurrentTrain: epoch  7, batch     0 | loss: 75.8741050CurrentTrain: epoch  7, batch     1 | loss: 80.1266654CurrentTrain: epoch  7, batch     2 | loss: 60.8638629CurrentTrain: epoch  7, batch     3 | loss: 17.4101478CurrentTrain: epoch  8, batch     0 | loss: 59.8302603CurrentTrain: epoch  8, batch     1 | loss: 94.1332721CurrentTrain: epoch  8, batch     2 | loss: 75.8825655CurrentTrain: epoch  8, batch     3 | loss: 5.4813779CurrentTrain: epoch  9, batch     0 | loss: 61.8662505CurrentTrain: epoch  9, batch     1 | loss: 65.7235004CurrentTrain: epoch  9, batch     2 | loss: 60.8130880CurrentTrain: epoch  9, batch     3 | loss: 5.7867336
MemoryTrain:  epoch  0, batch     0 | loss: 0.7906568MemoryTrain:  epoch  1, batch     0 | loss: 0.6668129MemoryTrain:  epoch  2, batch     0 | loss: 0.5488125MemoryTrain:  epoch  3, batch     0 | loss: 0.4514677MemoryTrain:  epoch  4, batch     0 | loss: 0.3903630MemoryTrain:  epoch  5, batch     0 | loss: 0.3351023MemoryTrain:  epoch  6, batch     0 | loss: 0.2773067MemoryTrain:  epoch  7, batch     0 | loss: 0.2459105MemoryTrain:  epoch  8, batch     0 | loss: 0.2283954MemoryTrain:  epoch  9, batch     0 | loss: 0.1948928

F1 score per class: {0: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6), 8: np.float64(0.0), 9: np.float64(0.847457627118644), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.6206896551724138), 31: np.float64(0.5), 32: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.224)}
Micro-average F1 score: 0.32601880877742945
Weighted-average F1 score: 0.2666592008667018
F1 score per class: {0: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6), 8: np.float64(0.0), 9: np.float64(0.6756756756756757), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.5714285714285714), 30: np.float64(0.0), 31: np.float64(0.2), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.43609022556390975)}
Micro-average F1 score: 0.3687150837988827
Weighted-average F1 score: 0.30307264617014396
F1 score per class: {0: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6), 8: np.float64(0.0), 9: np.float64(0.78125), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.625), 30: np.float64(0.0), 31: np.float64(0.2857142857142857), 32: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.4264705882352941)}
Micro-average F1 score: 0.39420289855072466
Weighted-average F1 score: 0.3246366728509586

F1 score per class: {0: np.float64(0.48175182481751827), 2: np.float64(0.4117647058823529), 4: np.float64(0.75), 5: np.float64(0.7966101694915254), 6: np.float64(0.22580645161290322), 7: np.float64(0.040268456375838924), 8: np.float64(0.4583333333333333), 9: np.float64(0.8333333333333334), 10: np.float64(0.09345794392523364), 11: np.float64(0.22608695652173913), 12: np.float64(0.28187919463087246), 13: np.float64(0.04597701149425287), 15: np.float64(0.2727272727272727), 16: np.float64(0.3902439024390244), 17: np.float64(0.0), 18: np.float64(0.11320754716981132), 19: np.float64(0.6147859922178989), 20: np.float64(0.3798449612403101), 21: np.float64(0.08888888888888889), 23: np.float64(0.6075949367088608), 24: np.float64(0.0), 25: np.float64(0.3880597014925373), 26: np.float64(0.6732673267326733), 27: np.float64(0.2903225806451613), 28: np.float64(0.1), 29: np.float64(0.8223350253807107), 30: np.float64(0.8484848484848485), 31: np.float64(0.2857142857142857), 32: np.float64(0.6810344827586207), 33: np.float64(0.14634146341463414), 35: np.float64(0.379746835443038), 36: np.float64(0.5), 37: np.float64(0.1643835616438356), 38: np.float64(0.24), 39: np.float64(0.0), 40: np.float64(0.0989399293286219)}
Micro-average F1 score: 0.4265787471468425
Weighted-average F1 score: 0.4150887099923703
F1 score per class: {0: np.float64(0.34594594594594597), 2: np.float64(0.22580645161290322), 4: np.float64(0.8202247191011236), 5: np.float64(0.5159574468085106), 6: np.float64(0.348993288590604), 7: np.float64(0.04411764705882353), 8: np.float64(0.4336283185840708), 9: np.float64(0.6024096385542169), 10: np.float64(0.15873015873015872), 11: np.float64(0.2723735408560311), 12: np.float64(0.2682926829268293), 13: np.float64(0.03225806451612903), 15: np.float64(0.25), 16: np.float64(0.5), 17: np.float64(0.0), 18: np.float64(0.21505376344086022), 19: np.float64(0.562962962962963), 20: np.float64(0.37398373983739835), 21: np.float64(0.22388059701492538), 23: np.float64(0.5714285714285714), 24: np.float64(0.18181818181818182), 25: np.float64(0.4), 26: np.float64(0.6698113207547169), 27: np.float64(0.3137254901960784), 28: np.float64(0.13333333333333333), 29: np.float64(0.8316831683168316), 30: np.float64(0.6666666666666666), 31: np.float64(0.05405405405405406), 32: np.float64(0.6907630522088354), 33: np.float64(0.10344827586206896), 35: np.float64(0.5222929936305732), 36: np.float64(0.45685279187817257), 37: np.float64(0.13333333333333333), 38: np.float64(0.2857142857142857), 39: np.float64(0.0), 40: np.float64(0.20350877192982456)}
Micro-average F1 score: 0.405189620758483
Weighted-average F1 score: 0.385045082085985
F1 score per class: {0: np.float64(0.35294117647058826), 2: np.float64(0.3111111111111111), 4: np.float64(0.8117647058823529), 5: np.float64(0.676056338028169), 6: np.float64(0.3262411347517731), 7: np.float64(0.04316546762589928), 8: np.float64(0.44), 9: np.float64(0.746268656716418), 10: np.float64(0.12173913043478261), 11: np.float64(0.2517985611510791), 12: np.float64(0.25766871165644173), 13: np.float64(0.03333333333333333), 15: np.float64(0.28), 16: np.float64(0.5), 17: np.float64(0.0), 18: np.float64(0.17142857142857143), 19: np.float64(0.596078431372549), 20: np.float64(0.3560606060606061), 21: np.float64(0.18518518518518517), 23: np.float64(0.6097560975609756), 24: np.float64(0.15384615384615385), 25: np.float64(0.42857142857142855), 26: np.float64(0.6794258373205742), 27: np.float64(0.35714285714285715), 28: np.float64(0.13333333333333333), 29: np.float64(0.8258706467661692), 30: np.float64(0.7804878048780488), 31: np.float64(0.10526315789473684), 32: np.float64(0.6774193548387096), 33: np.float64(0.10526315789473684), 35: np.float64(0.5087719298245614), 36: np.float64(0.41450777202072536), 37: np.float64(0.125), 38: np.float64(0.3), 39: np.float64(0.0), 40: np.float64(0.18770226537216828)}
Micro-average F1 score: 0.4147186147186147
Weighted-average F1 score: 0.3937454396617283

F1 score per class: {0: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5), 8: np.float64(0.0), 9: np.float64(0.78125), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.5294117647058824), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.4), 32: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.17834394904458598)}
Micro-average F1 score: 0.2561576354679803
Weighted-average F1 score: 0.21019780316367015
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5), 8: np.float64(0.0), 9: np.float64(0.5747126436781609), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.5333333333333333), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.14285714285714285), 32: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.3493975903614458)}
Micro-average F1 score: 0.2732919254658385
Weighted-average F1 score: 0.22650240515106201
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5), 8: np.float64(0.0), 9: np.float64(0.704225352112676), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.5405405405405406), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.18181818181818182), 32: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.3391812865497076)}
Micro-average F1 score: 0.3008849557522124
Weighted-average F1 score: 0.2506957099675352

F1 score per class: {0: np.float64(0.32673267326732675), 2: np.float64(0.2545454545454545), 4: np.float64(0.7058823529411765), 5: np.float64(0.6416382252559727), 6: np.float64(0.175), 7: np.float64(0.020202020202020204), 8: np.float64(0.35294117647058826), 9: np.float64(0.7692307692307693), 10: np.float64(0.09174311926605505), 11: np.float64(0.18055555555555555), 12: np.float64(0.15384615384615385), 13: np.float64(0.023255813953488372), 15: np.float64(0.17142857142857143), 16: np.float64(0.3018867924528302), 17: np.float64(0.0), 18: np.float64(0.07317073170731707), 19: np.float64(0.5663082437275986), 20: np.float64(0.1625207296849088), 21: np.float64(0.07407407407407407), 23: np.float64(0.5333333333333333), 24: np.float64(0.0), 25: np.float64(0.36619718309859156), 26: np.float64(0.5887445887445888), 27: np.float64(0.1956521739130435), 28: np.float64(0.0425531914893617), 29: np.float64(0.680672268907563), 30: np.float64(0.8), 31: np.float64(0.15384615384615385), 32: np.float64(0.511326860841424), 33: np.float64(0.0967741935483871), 35: np.float64(0.26785714285714285), 36: np.float64(0.3333333333333333), 37: np.float64(0.15584415584415584), 38: np.float64(0.14173228346456693), 39: np.float64(0.0), 40: np.float64(0.06982543640897755)}
Micro-average F1 score: 0.3021918792669781
Weighted-average F1 score: 0.2771496528557051
F1 score per class: {0: np.float64(0.2471042471042471), 2: np.float64(0.14893617021276595), 4: np.float64(0.7724867724867724), 5: np.float64(0.31493506493506496), 6: np.float64(0.23853211009174313), 7: np.float64(0.022304832713754646), 8: np.float64(0.2873900293255132), 9: np.float64(0.49504950495049505), 10: np.float64(0.14388489208633093), 11: np.float64(0.2), 12: np.float64(0.15492957746478872), 13: np.float64(0.01680672268907563), 15: np.float64(0.1875), 16: np.float64(0.2956521739130435), 17: np.float64(0.0), 18: np.float64(0.1388888888888889), 19: np.float64(0.5135135135135135), 20: np.float64(0.17692307692307693), 21: np.float64(0.15), 23: np.float64(0.45217391304347826), 24: np.float64(0.12244897959183673), 25: np.float64(0.379746835443038), 26: np.float64(0.5657370517928287), 27: np.float64(0.25396825396825395), 28: np.float64(0.0625), 29: np.float64(0.6693227091633466), 30: np.float64(0.6071428571428571), 31: np.float64(0.030303030303030304), 32: np.float64(0.5134328358208955), 33: np.float64(0.061855670103092786), 35: np.float64(0.3504273504273504), 36: np.float64(0.33210332103321033), 37: np.float64(0.07166123778501629), 38: np.float64(0.15441176470588236), 39: np.float64(0.0), 40: np.float64(0.1457286432160804)}
Micro-average F1 score: 0.2735480393477968
Weighted-average F1 score: 0.25331473778148844
F1 score per class: {0: np.float64(0.2490566037735849), 2: np.float64(0.2028985507246377), 4: np.float64(0.7624309392265194), 5: np.float64(0.463768115942029), 6: np.float64(0.22772277227722773), 7: np.float64(0.021897810218978103), 8: np.float64(0.3188405797101449), 9: np.float64(0.6493506493506493), 10: np.float64(0.11666666666666667), 11: np.float64(0.1881720430107527), 12: np.float64(0.14736842105263157), 13: np.float64(0.017857142857142856), 15: np.float64(0.1794871794871795), 16: np.float64(0.3582089552238806), 17: np.float64(0.0), 18: np.float64(0.1111111111111111), 19: np.float64(0.5547445255474452), 20: np.float64(0.16666666666666666), 21: np.float64(0.13333333333333333), 23: np.float64(0.5154639175257731), 24: np.float64(0.1111111111111111), 25: np.float64(0.40540540540540543), 26: np.float64(0.5941422594142259), 27: np.float64(0.2702702702702703), 28: np.float64(0.06521739130434782), 29: np.float64(0.6720647773279352), 30: np.float64(0.7272727272727273), 31: np.float64(0.058823529411764705), 32: np.float64(0.5045045045045045), 33: np.float64(0.06666666666666667), 35: np.float64(0.3372093023255814), 36: np.float64(0.2888086642599278), 37: np.float64(0.08823529411764706), 38: np.float64(0.1643835616438356), 39: np.float64(0.0), 40: np.float64(0.13488372093023257)}
Micro-average F1 score: 0.28885873661993067
Weighted-average F1 score: 0.26576524938334517
cur_acc_wo_na:  ['0.7600', '0.5577', '0.4851', '0.6386', '0.4836', '0.5507', '0.3260']
his_acc_wo_na:  ['0.7600', '0.6870', '0.5767', '0.5743', '0.5073', '0.4987', '0.4266']
cur_acc des_wo_na:  ['0.7359', '0.5245', '0.4087', '0.5186', '0.4726', '0.5270', '0.3687']
his_acc des_wo_na:  ['0.7359', '0.6336', '0.5514', '0.5156', '0.4359', '0.4443', '0.4052']
cur_acc rrf_wo_na:  ['0.7465', '0.5515', '0.4444', '0.5436', '0.4950', '0.5476', '0.3942']
his_acc rrf_wo_na:  ['0.7465', '0.6577', '0.5696', '0.5323', '0.4674', '0.4594', '0.4147']
cur_acc_w_na:  ['0.6364', '0.4236', '0.3481', '0.4877', '0.3439', '0.3968', '0.2562']
his_acc_w_na:  ['0.6364', '0.5397', '0.4190', '0.4199', '0.3571', '0.3695', '0.3022']
cur_acc des_w_na:  ['0.6062', '0.3652', '0.2799', '0.3837', '0.3239', '0.3483', '0.2733']
his_acc des_w_na:  ['0.6062', '0.4669', '0.3823', '0.3618', '0.2905', '0.2981', '0.2735']
cur_acc rrf_w_na:  ['0.6189', '0.3892', '0.3050', '0.4051', '0.3379', '0.3640', '0.3009']
his_acc rrf_w_na:  ['0.6189', '0.4898', '0.3989', '0.3773', '0.3155', '0.3136', '0.2889']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 100.7612306CurrentTrain: epoch  0, batch     1 | loss: 100.3001618CurrentTrain: epoch  0, batch     2 | loss: 85.0389568CurrentTrain: epoch  0, batch     3 | loss: 117.8963522CurrentTrain: epoch  0, batch     4 | loss: 62.2679696CurrentTrain: epoch  1, batch     0 | loss: 91.4325659CurrentTrain: epoch  1, batch     1 | loss: 88.9670200CurrentTrain: epoch  1, batch     2 | loss: 77.8206658CurrentTrain: epoch  1, batch     3 | loss: 135.4584106CurrentTrain: epoch  1, batch     4 | loss: 81.1139491CurrentTrain: epoch  2, batch     0 | loss: 85.9624630CurrentTrain: epoch  2, batch     1 | loss: 105.3638665CurrentTrain: epoch  2, batch     2 | loss: 74.3650382CurrentTrain: epoch  2, batch     3 | loss: 103.8041679CurrentTrain: epoch  2, batch     4 | loss: 49.2827764CurrentTrain: epoch  3, batch     0 | loss: 105.4320604CurrentTrain: epoch  3, batch     1 | loss: 85.8352999CurrentTrain: epoch  3, batch     2 | loss: 72.6201525CurrentTrain: epoch  3, batch     3 | loss: 68.5613658CurrentTrain: epoch  3, batch     4 | loss: 71.0457280CurrentTrain: epoch  4, batch     0 | loss: 68.8651783CurrentTrain: epoch  4, batch     1 | loss: 98.9738358CurrentTrain: epoch  4, batch     2 | loss: 101.1713572CurrentTrain: epoch  4, batch     3 | loss: 125.3317922CurrentTrain: epoch  4, batch     4 | loss: 39.6050423CurrentTrain: epoch  5, batch     0 | loss: 80.2442205CurrentTrain: epoch  5, batch     1 | loss: 101.7224570CurrentTrain: epoch  5, batch     2 | loss: 79.1914387CurrentTrain: epoch  5, batch     3 | loss: 81.1643343CurrentTrain: epoch  5, batch     4 | loss: 54.5120303CurrentTrain: epoch  6, batch     0 | loss: 82.2164338CurrentTrain: epoch  6, batch     1 | loss: 69.4687922CurrentTrain: epoch  6, batch     2 | loss: 68.8226319CurrentTrain: epoch  6, batch     3 | loss: 80.0114927CurrentTrain: epoch  6, batch     4 | loss: 94.8681643CurrentTrain: epoch  7, batch     0 | loss: 77.0106805CurrentTrain: epoch  7, batch     1 | loss: 80.7598870CurrentTrain: epoch  7, batch     2 | loss: 94.5360718CurrentTrain: epoch  7, batch     3 | loss: 93.1280997CurrentTrain: epoch  7, batch     4 | loss: 93.7238806CurrentTrain: epoch  8, batch     0 | loss: 97.3439467CurrentTrain: epoch  8, batch     1 | loss: 96.1882090CurrentTrain: epoch  8, batch     2 | loss: 119.6162742CurrentTrain: epoch  8, batch     3 | loss: 90.3069576CurrentTrain: epoch  8, batch     4 | loss: 42.8603978CurrentTrain: epoch  9, batch     0 | loss: 94.1626102CurrentTrain: epoch  9, batch     1 | loss: 78.3717918CurrentTrain: epoch  9, batch     2 | loss: 64.7412095CurrentTrain: epoch  9, batch     3 | loss: 94.8292634CurrentTrain: epoch  9, batch     4 | loss: 67.0678000
MemoryTrain:  epoch  0, batch     0 | loss: 1.1291927MemoryTrain:  epoch  1, batch     0 | loss: 0.9336651MemoryTrain:  epoch  2, batch     0 | loss: 0.8074640MemoryTrain:  epoch  3, batch     0 | loss: 0.6403655MemoryTrain:  epoch  4, batch     0 | loss: 0.4834704MemoryTrain:  epoch  5, batch     0 | loss: 0.4634036MemoryTrain:  epoch  6, batch     0 | loss: 0.3713841MemoryTrain:  epoch  7, batch     0 | loss: 0.3504599MemoryTrain:  epoch  8, batch     0 | loss: 0.3070574MemoryTrain:  epoch  9, batch     0 | loss: 0.2638649

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.19753086419753085), 3: np.float64(0.7272727272727273), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 14: np.float64(0.05970149253731343), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.5352112676056338), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6890756302521008), 35: np.float64(0.0), 36: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.37029501525940994
Weighted-average F1 score: 0.3133601552768791
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.21818181818181817), 2: np.float64(0.0), 3: np.float64(0.6046511627906976), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.08333333333333333), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5503875968992248), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.676056338028169), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3382997370727432
Weighted-average F1 score: 0.287506365542637
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.21818181818181817), 3: np.float64(0.5988700564971752), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.07272727272727272), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5691056910569106), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6808510638297872), 35: np.float64(0.0), 36: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.35315645013723695
Weighted-average F1 score: 0.3045682491224152

F1 score per class: {0: np.float64(0.5172413793103449), 1: np.float64(0.15458937198067632), 2: np.float64(0.4444444444444444), 3: np.float64(0.39751552795031053), 4: np.float64(0.6666666666666666), 5: np.float64(0.8266666666666667), 6: np.float64(0.2595419847328244), 7: np.float64(0.05357142857142857), 8: np.float64(0.35714285714285715), 9: np.float64(0.847457627118644), 10: np.float64(0.07547169811320754), 11: np.float64(0.12790697674418605), 12: np.float64(0.25675675675675674), 13: np.float64(0.06349206349206349), 14: np.float64(0.03404255319148936), 15: np.float64(0.5217391304347826), 16: np.float64(0.17647058823529413), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5714285714285714), 20: np.float64(0.4051724137931034), 21: np.float64(0.0), 22: np.float64(0.44881889763779526), 23: np.float64(0.6352941176470588), 24: np.float64(0.0), 25: np.float64(0.3492063492063492), 26: np.float64(0.6699507389162561), 27: np.float64(0.0), 28: np.float64(0.25), 29: np.float64(0.7794871794871795), 30: np.float64(0.8484848484848485), 31: np.float64(0.4), 32: np.float64(0.6090534979423868), 33: np.float64(0.21428571428571427), 34: np.float64(0.16367265469061876), 35: np.float64(0.05970149253731343), 36: np.float64(0.42424242424242425), 37: np.float64(0.057971014492753624), 38: np.float64(0.14084507042253522), 39: np.float64(0.0), 40: np.float64(0.13125)}
Micro-average F1 score: 0.35792349726775957
Weighted-average F1 score: 0.34379911229006066
F1 score per class: {0: np.float64(0.38323353293413176), 1: np.float64(0.16744186046511628), 2: np.float64(0.28), 3: np.float64(0.3611111111111111), 4: np.float64(0.7529411764705882), 5: np.float64(0.5159574468085106), 6: np.float64(0.29931972789115646), 7: np.float64(0.05128205128205128), 8: np.float64(0.3958333333333333), 9: np.float64(0.5050505050505051), 10: np.float64(0.09009009009009009), 11: np.float64(0.18333333333333332), 12: np.float64(0.2389937106918239), 13: np.float64(0.04938271604938271), 14: np.float64(0.05925925925925926), 15: np.float64(0.3333333333333333), 16: np.float64(0.49056603773584906), 17: np.float64(0.0), 18: np.float64(0.10526315789473684), 19: np.float64(0.5255474452554745), 20: np.float64(0.4397905759162304), 21: np.float64(0.057971014492753624), 22: np.float64(0.4316109422492401), 23: np.float64(0.6122448979591837), 24: np.float64(0.0), 25: np.float64(0.39436619718309857), 26: np.float64(0.6698113207547169), 27: np.float64(0.0), 28: np.float64(0.11320754716981132), 29: np.float64(0.8058252427184466), 30: np.float64(0.7083333333333334), 31: np.float64(0.058823529411764705), 32: np.float64(0.5357142857142857), 33: np.float64(0.16216216216216217), 34: np.float64(0.1465648854961832), 35: np.float64(0.2882882882882883), 36: np.float64(0.5454545454545454), 37: np.float64(0.03636363636363636), 38: np.float64(0.23448275862068965), 39: np.float64(0.10526315789473684), 40: np.float64(0.22857142857142856)}
Micro-average F1 score: 0.35354200988467877
Weighted-average F1 score: 0.34008856484835565
F1 score per class: {0: np.float64(0.3699421965317919), 1: np.float64(0.16901408450704225), 2: np.float64(0.3888888888888889), 3: np.float64(0.3375796178343949), 4: np.float64(0.7607361963190185), 5: np.float64(0.6981818181818182), 6: np.float64(0.29577464788732394), 7: np.float64(0.05042016806722689), 8: np.float64(0.423841059602649), 9: np.float64(0.7575757575757576), 10: np.float64(0.10714285714285714), 11: np.float64(0.16541353383458646), 12: np.float64(0.2222222222222222), 13: np.float64(0.043010752688172046), 14: np.float64(0.04597701149425287), 15: np.float64(0.36363636363636365), 16: np.float64(0.3076923076923077), 17: np.float64(0.0), 18: np.float64(0.07547169811320754), 19: np.float64(0.5647058823529412), 20: np.float64(0.42574257425742573), 21: np.float64(0.045454545454545456), 22: np.float64(0.45901639344262296), 23: np.float64(0.611764705882353), 24: np.float64(0.0), 25: np.float64(0.38235294117647056), 26: np.float64(0.6729857819905213), 27: np.float64(0.0), 28: np.float64(0.13043478260869565), 29: np.float64(0.801980198019802), 30: np.float64(0.8333333333333334), 31: np.float64(0.10526315789473684), 32: np.float64(0.5639097744360902), 33: np.float64(0.17647058823529413), 34: np.float64(0.15286624203821655), 35: np.float64(0.2553191489361702), 36: np.float64(0.5454545454545454), 37: np.float64(0.046511627906976744), 38: np.float64(0.1565217391304348), 39: np.float64(0.0), 40: np.float64(0.20809248554913296)}
Micro-average F1 score: 0.3587772925764192
Weighted-average F1 score: 0.3410077984789408

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.11188811188811189), 2: np.float64(0.0), 3: np.float64(0.5161290322580645), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.04519774011299435), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.456), 23: np.float64(0.0), 25: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.49696969696969695), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.24863387978142076
Weighted-average F1 score: 0.21500334452401676
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.12286689419795221), 2: np.float64(0.0), 3: np.float64(0.4297520661157025), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.06956521739130435), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.4382716049382716), 23: np.float64(0.0), 25: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.4752475247524752), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.22428820453224868
Weighted-average F1 score: 0.196716523512575
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.12203389830508475), 2: np.float64(0.0), 3: np.float64(0.4189723320158103), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.05970149253731343), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.4605263157894737), 23: np.float64(0.0), 25: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.49740932642487046), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.23536585365853657
Weighted-average F1 score: 0.20752747893573717

F1 score per class: {0: np.float64(0.3821656050955414), 1: np.float64(0.08421052631578947), 2: np.float64(0.25), 3: np.float64(0.2490272373540856), 4: np.float64(0.6410256410256411), 5: np.float64(0.6763636363636364), 6: np.float64(0.18478260869565216), 7: np.float64(0.0273972602739726), 8: np.float64(0.3053435114503817), 9: np.float64(0.7936507936507936), 10: np.float64(0.07407407407407407), 11: np.float64(0.1073170731707317), 12: np.float64(0.1412639405204461), 13: np.float64(0.03305785123966942), 14: np.float64(0.02531645569620253), 15: np.float64(0.3157894736842105), 16: np.float64(0.17142857142857143), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5255474452554745), 20: np.float64(0.18951612903225806), 21: np.float64(0.0), 22: np.float64(0.34234234234234234), 23: np.float64(0.5625), 24: np.float64(0.0), 25: np.float64(0.3283582089552239), 26: np.float64(0.5887445887445888), 27: np.float64(0.0), 28: np.float64(0.14285714285714285), 29: np.float64(0.6386554621848739), 30: np.float64(0.8), 31: np.float64(0.18181818181818182), 32: np.float64(0.44047619047619047), 33: np.float64(0.14285714285714285), 34: np.float64(0.09891435464414958), 35: np.float64(0.047619047619047616), 36: np.float64(0.2727272727272727), 37: np.float64(0.05128205128205128), 38: np.float64(0.09803921568627451), 39: np.float64(0.0), 40: np.float64(0.09836065573770492)}
Micro-average F1 score: 0.25338491295938104
Weighted-average F1 score: 0.23314487124291386
F1 score per class: {0: np.float64(0.2882882882882883), 1: np.float64(0.09090909090909091), 2: np.float64(0.17721518987341772), 3: np.float64(0.22317596566523606), 4: np.float64(0.7071823204419889), 5: np.float64(0.31751227495908346), 6: np.float64(0.20754716981132076), 7: np.float64(0.025210084033613446), 8: np.float64(0.27941176470588236), 9: np.float64(0.3968253968253968), 10: np.float64(0.0847457627118644), 11: np.float64(0.17886178861788618), 12: np.float64(0.13620071684587814), 13: np.float64(0.025157232704402517), 14: np.float64(0.047337278106508875), 15: np.float64(0.24), 16: np.float64(0.3466666666666667), 17: np.float64(0.0), 18: np.float64(0.06060606060606061), 19: np.float64(0.47840531561461797), 20: np.float64(0.21649484536082475), 21: np.float64(0.05194805194805195), 22: np.float64(0.3021276595744681), 23: np.float64(0.4444444444444444), 24: np.float64(0.0), 25: np.float64(0.3684210526315789), 26: np.float64(0.570281124497992), 27: np.float64(0.0), 28: np.float64(0.057692307692307696), 29: np.float64(0.6459143968871596), 30: np.float64(0.6071428571428571), 31: np.float64(0.028985507246376812), 32: np.float64(0.38860103626943004), 33: np.float64(0.1), 34: np.float64(0.09031044214487301), 35: np.float64(0.18823529411764706), 36: np.float64(0.3127035830618892), 37: np.float64(0.029197080291970802), 38: np.float64(0.13545816733067728), 39: np.float64(0.07407407407407407), 40: np.float64(0.1651376146788991)}
Micro-average F1 score: 0.23937534857780257
Weighted-average F1 score: 0.22521521104302664
F1 score per class: {0: np.float64(0.27586206896551724), 1: np.float64(0.0906801007556675), 2: np.float64(0.23333333333333334), 3: np.float64(0.2082514734774067), 4: np.float64(0.7251461988304093), 5: np.float64(0.49104859335038364), 6: np.float64(0.20689655172413793), 7: np.float64(0.024691358024691357), 8: np.float64(0.3282051282051282), 9: np.float64(0.6578947368421053), 10: np.float64(0.10344827586206896), 11: np.float64(0.15942028985507245), 12: np.float64(0.12811387900355872), 13: np.float64(0.02185792349726776), 14: np.float64(0.034934497816593885), 15: np.float64(0.22641509433962265), 16: np.float64(0.26666666666666666), 17: np.float64(0.0), 18: np.float64(0.04395604395604396), 19: np.float64(0.5179856115107914), 20: np.float64(0.20574162679425836), 21: np.float64(0.04081632653061224), 22: np.float64(0.332541567695962), 23: np.float64(0.49056603773584906), 24: np.float64(0.0), 25: np.float64(0.3561643835616438), 26: np.float64(0.5819672131147541), 27: np.float64(0.0), 28: np.float64(0.061855670103092786), 29: np.float64(0.6532258064516129), 30: np.float64(0.7317073170731707), 31: np.float64(0.05263157894736842), 32: np.float64(0.4098360655737705), 33: np.float64(0.10714285714285714), 34: np.float64(0.09320388349514563), 35: np.float64(0.17647058823529413), 36: np.float64(0.3111111111111111), 37: np.float64(0.0380952380952381), 38: np.float64(0.0972972972972973), 39: np.float64(0.0), 40: np.float64(0.15384615384615385)}
Micro-average F1 score: 0.24657863145258102
Weighted-average F1 score: 0.2277436790156919
cur_acc_wo_na:  ['0.7600', '0.5577', '0.4851', '0.6386', '0.4836', '0.5507', '0.3260', '0.3703']
his_acc_wo_na:  ['0.7600', '0.6870', '0.5767', '0.5743', '0.5073', '0.4987', '0.4266', '0.3579']
cur_acc des_wo_na:  ['0.7359', '0.5245', '0.4087', '0.5186', '0.4726', '0.5270', '0.3687', '0.3383']
his_acc des_wo_na:  ['0.7359', '0.6336', '0.5514', '0.5156', '0.4359', '0.4443', '0.4052', '0.3535']
cur_acc rrf_wo_na:  ['0.7465', '0.5515', '0.4444', '0.5436', '0.4950', '0.5476', '0.3942', '0.3532']
his_acc rrf_wo_na:  ['0.7465', '0.6577', '0.5696', '0.5323', '0.4674', '0.4594', '0.4147', '0.3588']
cur_acc_w_na:  ['0.6364', '0.4236', '0.3481', '0.4877', '0.3439', '0.3968', '0.2562', '0.2486']
his_acc_w_na:  ['0.6364', '0.5397', '0.4190', '0.4199', '0.3571', '0.3695', '0.3022', '0.2534']
cur_acc des_w_na:  ['0.6062', '0.3652', '0.2799', '0.3837', '0.3239', '0.3483', '0.2733', '0.2243']
his_acc des_w_na:  ['0.6062', '0.4669', '0.3823', '0.3618', '0.2905', '0.2981', '0.2735', '0.2394']
cur_acc rrf_w_na:  ['0.6189', '0.3892', '0.3050', '0.4051', '0.3379', '0.3640', '0.3009', '0.2354']
his_acc rrf_w_na:  ['0.6189', '0.4898', '0.3989', '0.3773', '0.3155', '0.3136', '0.2889', '0.2466']
--------Round  3
seed:  400
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 0 1 2 5 3 4 6]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 110.3891770CurrentTrain: epoch  0, batch     1 | loss: 200.4824042CurrentTrain: epoch  0, batch     2 | loss: 121.2992533CurrentTrain: epoch  0, batch     3 | loss: 102.0438969CurrentTrain: epoch  0, batch     4 | loss: 87.1438242CurrentTrain: epoch  0, batch     5 | loss: 89.2813027CurrentTrain: epoch  0, batch     6 | loss: 77.7941400CurrentTrain: epoch  0, batch     7 | loss: 119.6123360CurrentTrain: epoch  0, batch     8 | loss: 117.9500130CurrentTrain: epoch  0, batch     9 | loss: 119.0262626CurrentTrain: epoch  0, batch    10 | loss: 147.4794570CurrentTrain: epoch  0, batch    11 | loss: 118.7724404CurrentTrain: epoch  0, batch    12 | loss: 100.5762860CurrentTrain: epoch  0, batch    13 | loss: 147.0847682CurrentTrain: epoch  0, batch    14 | loss: 118.1986009CurrentTrain: epoch  0, batch    15 | loss: 86.8730635CurrentTrain: epoch  0, batch    16 | loss: 99.8807556CurrentTrain: epoch  0, batch    17 | loss: 86.7138610CurrentTrain: epoch  0, batch    18 | loss: 100.1218194CurrentTrain: epoch  0, batch    19 | loss: 118.1525096CurrentTrain: epoch  0, batch    20 | loss: 86.2135402CurrentTrain: epoch  0, batch    21 | loss: 145.8373895CurrentTrain: epoch  0, batch    22 | loss: 75.8535337CurrentTrain: epoch  0, batch    23 | loss: 99.3861029CurrentTrain: epoch  0, batch    24 | loss: 117.9291357CurrentTrain: epoch  0, batch    25 | loss: 98.9391395CurrentTrain: epoch  0, batch    26 | loss: 86.6218509CurrentTrain: epoch  0, batch    27 | loss: 85.7740192CurrentTrain: epoch  0, batch    28 | loss: 117.6873512CurrentTrain: epoch  0, batch    29 | loss: 98.6776123CurrentTrain: epoch  0, batch    30 | loss: 117.9775991CurrentTrain: epoch  0, batch    31 | loss: 75.8766723CurrentTrain: epoch  0, batch    32 | loss: 116.4085794CurrentTrain: epoch  0, batch    33 | loss: 117.7493142CurrentTrain: epoch  0, batch    34 | loss: 84.6481122CurrentTrain: epoch  0, batch    35 | loss: 144.9539603CurrentTrain: epoch  0, batch    36 | loss: 98.3568010CurrentTrain: epoch  0, batch    37 | loss: 98.4062836CurrentTrain: epoch  0, batch    38 | loss: 84.2377234CurrentTrain: epoch  0, batch    39 | loss: 98.0291253CurrentTrain: epoch  0, batch    40 | loss: 97.2389123CurrentTrain: epoch  0, batch    41 | loss: 97.3920998CurrentTrain: epoch  0, batch    42 | loss: 116.0981583CurrentTrain: epoch  0, batch    43 | loss: 145.1257457CurrentTrain: epoch  0, batch    44 | loss: 97.8675286CurrentTrain: epoch  0, batch    45 | loss: 116.9156541CurrentTrain: epoch  0, batch    46 | loss: 114.6784952CurrentTrain: epoch  0, batch    47 | loss: 95.5481624CurrentTrain: epoch  0, batch    48 | loss: 117.3088362CurrentTrain: epoch  0, batch    49 | loss: 96.8762580CurrentTrain: epoch  0, batch    50 | loss: 81.8458357CurrentTrain: epoch  0, batch    51 | loss: 97.6695094CurrentTrain: epoch  0, batch    52 | loss: 72.2351152CurrentTrain: epoch  0, batch    53 | loss: 84.1685790CurrentTrain: epoch  0, batch    54 | loss: 141.4888665CurrentTrain: epoch  0, batch    55 | loss: 83.5447367CurrentTrain: epoch  0, batch    56 | loss: 95.4138911CurrentTrain: epoch  0, batch    57 | loss: 115.9313681CurrentTrain: epoch  0, batch    58 | loss: 188.8570691CurrentTrain: epoch  0, batch    59 | loss: 141.6891295CurrentTrain: epoch  0, batch    60 | loss: 94.9367129CurrentTrain: epoch  0, batch    61 | loss: 92.6159766CurrentTrain: epoch  0, batch    62 | loss: 191.2477121CurrentTrain: epoch  0, batch    63 | loss: 114.1723791CurrentTrain: epoch  0, batch    64 | loss: 81.1301077CurrentTrain: epoch  0, batch    65 | loss: 81.1314305CurrentTrain: epoch  0, batch    66 | loss: 113.1267784CurrentTrain: epoch  0, batch    67 | loss: 112.7978856CurrentTrain: epoch  0, batch    68 | loss: 94.3862138CurrentTrain: epoch  0, batch    69 | loss: 140.2861396CurrentTrain: epoch  0, batch    70 | loss: 90.3374946CurrentTrain: epoch  0, batch    71 | loss: 69.6200423CurrentTrain: epoch  0, batch    72 | loss: 115.4268210CurrentTrain: epoch  0, batch    73 | loss: 92.9397520CurrentTrain: epoch  0, batch    74 | loss: 95.7690245CurrentTrain: epoch  0, batch    75 | loss: 96.4420017CurrentTrain: epoch  0, batch    76 | loss: 79.4882180CurrentTrain: epoch  0, batch    77 | loss: 77.8582716CurrentTrain: epoch  0, batch    78 | loss: 71.8099675CurrentTrain: epoch  0, batch    79 | loss: 94.5461532CurrentTrain: epoch  0, batch    80 | loss: 79.6566087CurrentTrain: epoch  0, batch    81 | loss: 79.4391786CurrentTrain: epoch  0, batch    82 | loss: 80.7624643CurrentTrain: epoch  0, batch    83 | loss: 67.6232759CurrentTrain: epoch  0, batch    84 | loss: 95.5842687CurrentTrain: epoch  0, batch    85 | loss: 109.6329356CurrentTrain: epoch  0, batch    86 | loss: 80.8500079CurrentTrain: epoch  0, batch    87 | loss: 94.8374894CurrentTrain: epoch  0, batch    88 | loss: 92.2073625CurrentTrain: epoch  0, batch    89 | loss: 137.7702758CurrentTrain: epoch  0, batch    90 | loss: 141.1499726CurrentTrain: epoch  0, batch    91 | loss: 111.2591167CurrentTrain: epoch  0, batch    92 | loss: 77.7400537CurrentTrain: epoch  0, batch    93 | loss: 80.2422530CurrentTrain: epoch  0, batch    94 | loss: 86.6264621CurrentTrain: epoch  0, batch    95 | loss: 95.1910442CurrentTrain: epoch  1, batch     0 | loss: 67.7838544CurrentTrain: epoch  1, batch     1 | loss: 80.5748188CurrentTrain: epoch  1, batch     2 | loss: 66.8139210CurrentTrain: epoch  1, batch     3 | loss: 109.4522922CurrentTrain: epoch  1, batch     4 | loss: 75.9445859CurrentTrain: epoch  1, batch     5 | loss: 88.8258902CurrentTrain: epoch  1, batch     6 | loss: 107.8302707CurrentTrain: epoch  1, batch     7 | loss: 89.0812117CurrentTrain: epoch  1, batch     8 | loss: 65.9555657CurrentTrain: epoch  1, batch     9 | loss: 78.1583666CurrentTrain: epoch  1, batch    10 | loss: 86.8254810CurrentTrain: epoch  1, batch    11 | loss: 140.8210631CurrentTrain: epoch  1, batch    12 | loss: 78.5493032CurrentTrain: epoch  1, batch    13 | loss: 110.5629726CurrentTrain: epoch  1, batch    14 | loss: 78.2744106CurrentTrain: epoch  1, batch    15 | loss: 92.5341211CurrentTrain: epoch  1, batch    16 | loss: 89.7053031CurrentTrain: epoch  1, batch    17 | loss: 90.2633206CurrentTrain: epoch  1, batch    18 | loss: 92.0190631CurrentTrain: epoch  1, batch    19 | loss: 109.0811586CurrentTrain: epoch  1, batch    20 | loss: 70.3569970CurrentTrain: epoch  1, batch    21 | loss: 74.5770836CurrentTrain: epoch  1, batch    22 | loss: 141.3014623CurrentTrain: epoch  1, batch    23 | loss: 137.1052960CurrentTrain: epoch  1, batch    24 | loss: 76.2202826CurrentTrain: epoch  1, batch    25 | loss: 79.7684678CurrentTrain: epoch  1, batch    26 | loss: 109.6351858CurrentTrain: epoch  1, batch    27 | loss: 75.7081025CurrentTrain: epoch  1, batch    28 | loss: 79.0144474CurrentTrain: epoch  1, batch    29 | loss: 135.8715716CurrentTrain: epoch  1, batch    30 | loss: 78.3879023CurrentTrain: epoch  1, batch    31 | loss: 77.1079894CurrentTrain: epoch  1, batch    32 | loss: 93.0310627CurrentTrain: epoch  1, batch    33 | loss: 73.8678932CurrentTrain: epoch  1, batch    34 | loss: 90.1139908CurrentTrain: epoch  1, batch    35 | loss: 135.7030675CurrentTrain: epoch  1, batch    36 | loss: 138.6569988CurrentTrain: epoch  1, batch    37 | loss: 192.3356471CurrentTrain: epoch  1, batch    38 | loss: 88.1947216CurrentTrain: epoch  1, batch    39 | loss: 77.6691749CurrentTrain: epoch  1, batch    40 | loss: 90.7636800CurrentTrain: epoch  1, batch    41 | loss: 79.0862973CurrentTrain: epoch  1, batch    42 | loss: 88.6742644CurrentTrain: epoch  1, batch    43 | loss: 67.9588590CurrentTrain: epoch  1, batch    44 | loss: 138.0626617CurrentTrain: epoch  1, batch    45 | loss: 109.0460351CurrentTrain: epoch  1, batch    46 | loss: 136.4243538CurrentTrain: epoch  1, batch    47 | loss: 75.9591601CurrentTrain: epoch  1, batch    48 | loss: 73.3916058CurrentTrain: epoch  1, batch    49 | loss: 107.1306770CurrentTrain: epoch  1, batch    50 | loss: 74.2077387CurrentTrain: epoch  1, batch    51 | loss: 78.9676529CurrentTrain: epoch  1, batch    52 | loss: 136.0961151CurrentTrain: epoch  1, batch    53 | loss: 90.8068043CurrentTrain: epoch  1, batch    54 | loss: 92.6035550CurrentTrain: epoch  1, batch    55 | loss: 133.3509397CurrentTrain: epoch  1, batch    56 | loss: 103.9061180CurrentTrain: epoch  1, batch    57 | loss: 66.3784532CurrentTrain: epoch  1, batch    58 | loss: 106.3643061CurrentTrain: epoch  1, batch    59 | loss: 83.3010261CurrentTrain: epoch  1, batch    60 | loss: 65.3564244CurrentTrain: epoch  1, batch    61 | loss: 67.6279912CurrentTrain: epoch  1, batch    62 | loss: 90.4995952CurrentTrain: epoch  1, batch    63 | loss: 76.2102114CurrentTrain: epoch  1, batch    64 | loss: 77.6215868CurrentTrain: epoch  1, batch    65 | loss: 92.2094919CurrentTrain: epoch  1, batch    66 | loss: 65.6538607CurrentTrain: epoch  1, batch    67 | loss: 108.0126520CurrentTrain: epoch  1, batch    68 | loss: 62.2089328CurrentTrain: epoch  1, batch    69 | loss: 109.8673461CurrentTrain: epoch  1, batch    70 | loss: 140.4023819CurrentTrain: epoch  1, batch    71 | loss: 69.5116185CurrentTrain: epoch  1, batch    72 | loss: 140.9084074CurrentTrain: epoch  1, batch    73 | loss: 138.6672899CurrentTrain: epoch  1, batch    74 | loss: 67.5487574CurrentTrain: epoch  1, batch    75 | loss: 66.4677609CurrentTrain: epoch  1, batch    76 | loss: 76.5157065CurrentTrain: epoch  1, batch    77 | loss: 78.9356267CurrentTrain: epoch  1, batch    78 | loss: 109.4471665CurrentTrain: epoch  1, batch    79 | loss: 87.2967047CurrentTrain: epoch  1, batch    80 | loss: 70.6169652CurrentTrain: epoch  1, batch    81 | loss: 135.0785194CurrentTrain: epoch  1, batch    82 | loss: 76.1686368CurrentTrain: epoch  1, batch    83 | loss: 104.4524821CurrentTrain: epoch  1, batch    84 | loss: 70.8119087CurrentTrain: epoch  1, batch    85 | loss: 88.9950892CurrentTrain: epoch  1, batch    86 | loss: 90.1939472CurrentTrain: epoch  1, batch    87 | loss: 88.0928036CurrentTrain: epoch  1, batch    88 | loss: 99.0190403CurrentTrain: epoch  1, batch    89 | loss: 86.1032477CurrentTrain: epoch  1, batch    90 | loss: 104.2354550CurrentTrain: epoch  1, batch    91 | loss: 89.7449940CurrentTrain: epoch  1, batch    92 | loss: 86.6619080CurrentTrain: epoch  1, batch    93 | loss: 105.1312239CurrentTrain: epoch  1, batch    94 | loss: 84.6867634CurrentTrain: epoch  1, batch    95 | loss: 62.1474995CurrentTrain: epoch  2, batch     0 | loss: 98.3005368CurrentTrain: epoch  2, batch     1 | loss: 75.3740657CurrentTrain: epoch  2, batch     2 | loss: 69.8065498CurrentTrain: epoch  2, batch     3 | loss: 61.4136791CurrentTrain: epoch  2, batch     4 | loss: 99.8509606CurrentTrain: epoch  2, batch     5 | loss: 107.5580153CurrentTrain: epoch  2, batch     6 | loss: 86.0014491CurrentTrain: epoch  2, batch     7 | loss: 72.6783404CurrentTrain: epoch  2, batch     8 | loss: 72.8833171CurrentTrain: epoch  2, batch     9 | loss: 103.4834006CurrentTrain: epoch  2, batch    10 | loss: 73.8908071CurrentTrain: epoch  2, batch    11 | loss: 90.3818641CurrentTrain: epoch  2, batch    12 | loss: 71.1245348CurrentTrain: epoch  2, batch    13 | loss: 73.4698225CurrentTrain: epoch  2, batch    14 | loss: 106.8287371CurrentTrain: epoch  2, batch    15 | loss: 64.4715319CurrentTrain: epoch  2, batch    16 | loss: 65.0847978CurrentTrain: epoch  2, batch    17 | loss: 177.1578987CurrentTrain: epoch  2, batch    18 | loss: 83.6321664CurrentTrain: epoch  2, batch    19 | loss: 108.7621457CurrentTrain: epoch  2, batch    20 | loss: 86.4477490CurrentTrain: epoch  2, batch    21 | loss: 99.3742032CurrentTrain: epoch  2, batch    22 | loss: 69.7777249CurrentTrain: epoch  2, batch    23 | loss: 73.9991714CurrentTrain: epoch  2, batch    24 | loss: 71.3089337CurrentTrain: epoch  2, batch    25 | loss: 74.9855308CurrentTrain: epoch  2, batch    26 | loss: 104.0926869CurrentTrain: epoch  2, batch    27 | loss: 62.9162969CurrentTrain: epoch  2, batch    28 | loss: 106.2060623CurrentTrain: epoch  2, batch    29 | loss: 71.4140795CurrentTrain: epoch  2, batch    30 | loss: 102.7675982CurrentTrain: epoch  2, batch    31 | loss: 107.7642661CurrentTrain: epoch  2, batch    32 | loss: 80.9926083CurrentTrain: epoch  2, batch    33 | loss: 75.0598254CurrentTrain: epoch  2, batch    34 | loss: 88.9360527CurrentTrain: epoch  2, batch    35 | loss: 89.1994081CurrentTrain: epoch  2, batch    36 | loss: 84.3534571CurrentTrain: epoch  2, batch    37 | loss: 134.0318392CurrentTrain: epoch  2, batch    38 | loss: 72.2561584CurrentTrain: epoch  2, batch    39 | loss: 103.5525381CurrentTrain: epoch  2, batch    40 | loss: 86.4866507CurrentTrain: epoch  2, batch    41 | loss: 75.8696647CurrentTrain: epoch  2, batch    42 | loss: 73.7507667CurrentTrain: epoch  2, batch    43 | loss: 71.5411361CurrentTrain: epoch  2, batch    44 | loss: 110.8216520CurrentTrain: epoch  2, batch    45 | loss: 84.9028888CurrentTrain: epoch  2, batch    46 | loss: 109.8595704CurrentTrain: epoch  2, batch    47 | loss: 108.0905098CurrentTrain: epoch  2, batch    48 | loss: 104.4758570CurrentTrain: epoch  2, batch    49 | loss: 106.8257979CurrentTrain: epoch  2, batch    50 | loss: 78.2755855CurrentTrain: epoch  2, batch    51 | loss: 74.3024232CurrentTrain: epoch  2, batch    52 | loss: 88.9802474CurrentTrain: epoch  2, batch    53 | loss: 83.2831170CurrentTrain: epoch  2, batch    54 | loss: 106.1766908CurrentTrain: epoch  2, batch    55 | loss: 87.0756119CurrentTrain: epoch  2, batch    56 | loss: 133.9627434CurrentTrain: epoch  2, batch    57 | loss: 104.9667366CurrentTrain: epoch  2, batch    58 | loss: 87.5979348CurrentTrain: epoch  2, batch    59 | loss: 88.5262399CurrentTrain: epoch  2, batch    60 | loss: 100.9037329CurrentTrain: epoch  2, batch    61 | loss: 122.7157902CurrentTrain: epoch  2, batch    62 | loss: 86.8743752CurrentTrain: epoch  2, batch    63 | loss: 87.9845547CurrentTrain: epoch  2, batch    64 | loss: 88.4111087CurrentTrain: epoch  2, batch    65 | loss: 88.1366835CurrentTrain: epoch  2, batch    66 | loss: 107.1162906CurrentTrain: epoch  2, batch    67 | loss: 103.9861979CurrentTrain: epoch  2, batch    68 | loss: 134.4493637CurrentTrain: epoch  2, batch    69 | loss: 108.4793155CurrentTrain: epoch  2, batch    70 | loss: 64.6943476CurrentTrain: epoch  2, batch    71 | loss: 100.4196433CurrentTrain: epoch  2, batch    72 | loss: 179.6051480CurrentTrain: epoch  2, batch    73 | loss: 88.5152687CurrentTrain: epoch  2, batch    74 | loss: 85.0477902CurrentTrain: epoch  2, batch    75 | loss: 72.5469328CurrentTrain: epoch  2, batch    76 | loss: 101.0462382CurrentTrain: epoch  2, batch    77 | loss: 82.5578152CurrentTrain: epoch  2, batch    78 | loss: 72.7665891CurrentTrain: epoch  2, batch    79 | loss: 106.0230105CurrentTrain: epoch  2, batch    80 | loss: 181.4634081CurrentTrain: epoch  2, batch    81 | loss: 86.1306570CurrentTrain: epoch  2, batch    82 | loss: 87.8518869CurrentTrain: epoch  2, batch    83 | loss: 59.5503500CurrentTrain: epoch  2, batch    84 | loss: 87.3533875CurrentTrain: epoch  2, batch    85 | loss: 61.4744283CurrentTrain: epoch  2, batch    86 | loss: 82.1958987CurrentTrain: epoch  2, batch    87 | loss: 100.0306115CurrentTrain: epoch  2, batch    88 | loss: 126.0932797CurrentTrain: epoch  2, batch    89 | loss: 134.9695372CurrentTrain: epoch  2, batch    90 | loss: 130.1122393CurrentTrain: epoch  2, batch    91 | loss: 109.2104724CurrentTrain: epoch  2, batch    92 | loss: 109.2488851CurrentTrain: epoch  2, batch    93 | loss: 109.5240957CurrentTrain: epoch  2, batch    94 | loss: 73.7302893CurrentTrain: epoch  2, batch    95 | loss: 71.9933759CurrentTrain: epoch  3, batch     0 | loss: 60.3100501CurrentTrain: epoch  3, batch     1 | loss: 63.2508732CurrentTrain: epoch  3, batch     2 | loss: 71.3410935CurrentTrain: epoch  3, batch     3 | loss: 86.2158621CurrentTrain: epoch  3, batch     4 | loss: 69.8370414CurrentTrain: epoch  3, batch     5 | loss: 83.9862100CurrentTrain: epoch  3, batch     6 | loss: 106.9484779CurrentTrain: epoch  3, batch     7 | loss: 81.3127348CurrentTrain: epoch  3, batch     8 | loss: 61.2285320CurrentTrain: epoch  3, batch     9 | loss: 109.4097010CurrentTrain: epoch  3, batch    10 | loss: 84.6835433CurrentTrain: epoch  3, batch    11 | loss: 99.7577467CurrentTrain: epoch  3, batch    12 | loss: 88.1569016CurrentTrain: epoch  3, batch    13 | loss: 107.5885681CurrentTrain: epoch  3, batch    14 | loss: 87.5192580CurrentTrain: epoch  3, batch    15 | loss: 105.4039414CurrentTrain: epoch  3, batch    16 | loss: 104.1908400CurrentTrain: epoch  3, batch    17 | loss: 73.1173348CurrentTrain: epoch  3, batch    18 | loss: 83.5566699CurrentTrain: epoch  3, batch    19 | loss: 86.9502847CurrentTrain: epoch  3, batch    20 | loss: 74.3124553CurrentTrain: epoch  3, batch    21 | loss: 68.9710910CurrentTrain: epoch  3, batch    22 | loss: 101.9053688CurrentTrain: epoch  3, batch    23 | loss: 177.7906425CurrentTrain: epoch  3, batch    24 | loss: 83.2493284CurrentTrain: epoch  3, batch    25 | loss: 104.8044240CurrentTrain: epoch  3, batch    26 | loss: 99.4076565CurrentTrain: epoch  3, batch    27 | loss: 132.1852593CurrentTrain: epoch  3, batch    28 | loss: 68.4351619CurrentTrain: epoch  3, batch    29 | loss: 102.2009802CurrentTrain: epoch  3, batch    30 | loss: 86.1199600CurrentTrain: epoch  3, batch    31 | loss: 67.9149188CurrentTrain: epoch  3, batch    32 | loss: 103.5750382CurrentTrain: epoch  3, batch    33 | loss: 85.8814807CurrentTrain: epoch  3, batch    34 | loss: 71.9767823CurrentTrain: epoch  3, batch    35 | loss: 63.9534479CurrentTrain: epoch  3, batch    36 | loss: 88.3274580CurrentTrain: epoch  3, batch    37 | loss: 67.5664096CurrentTrain: epoch  3, batch    38 | loss: 105.3069922CurrentTrain: epoch  3, batch    39 | loss: 83.6501677CurrentTrain: epoch  3, batch    40 | loss: 101.2248945CurrentTrain: epoch  3, batch    41 | loss: 83.0307106CurrentTrain: epoch  3, batch    42 | loss: 84.5212459CurrentTrain: epoch  3, batch    43 | loss: 85.4880605CurrentTrain: epoch  3, batch    44 | loss: 72.6722713CurrentTrain: epoch  3, batch    45 | loss: 84.8084670CurrentTrain: epoch  3, batch    46 | loss: 68.2475714CurrentTrain: epoch  3, batch    47 | loss: 80.5639556CurrentTrain: epoch  3, batch    48 | loss: 75.8098303CurrentTrain: epoch  3, batch    49 | loss: 105.6446196CurrentTrain: epoch  3, batch    50 | loss: 83.9326985CurrentTrain: epoch  3, batch    51 | loss: 86.0667629CurrentTrain: epoch  3, batch    52 | loss: 103.7929716CurrentTrain: epoch  3, batch    53 | loss: 60.4358948CurrentTrain: epoch  3, batch    54 | loss: 68.1534431CurrentTrain: epoch  3, batch    55 | loss: 81.3171478CurrentTrain: epoch  3, batch    56 | loss: 72.5178825CurrentTrain: epoch  3, batch    57 | loss: 105.2818919CurrentTrain: epoch  3, batch    58 | loss: 173.1885875CurrentTrain: epoch  3, batch    59 | loss: 81.7632892CurrentTrain: epoch  3, batch    60 | loss: 102.4840085CurrentTrain: epoch  3, batch    61 | loss: 100.9602864CurrentTrain: epoch  3, batch    62 | loss: 134.4175130CurrentTrain: epoch  3, batch    63 | loss: 85.2727819CurrentTrain: epoch  3, batch    64 | loss: 68.7304442CurrentTrain: epoch  3, batch    65 | loss: 73.9358415CurrentTrain: epoch  3, batch    66 | loss: 68.9962046CurrentTrain: epoch  3, batch    67 | loss: 131.0639338CurrentTrain: epoch  3, batch    68 | loss: 101.8441633CurrentTrain: epoch  3, batch    69 | loss: 106.9929274CurrentTrain: epoch  3, batch    70 | loss: 68.9717067CurrentTrain: epoch  3, batch    71 | loss: 73.5743455CurrentTrain: epoch  3, batch    72 | loss: 84.3764714CurrentTrain: epoch  3, batch    73 | loss: 101.3829782CurrentTrain: epoch  3, batch    74 | loss: 60.8684963CurrentTrain: epoch  3, batch    75 | loss: 72.8802681CurrentTrain: epoch  3, batch    76 | loss: 128.1114063CurrentTrain: epoch  3, batch    77 | loss: 70.4056123CurrentTrain: epoch  3, batch    78 | loss: 79.0010912CurrentTrain: epoch  3, batch    79 | loss: 83.7802289CurrentTrain: epoch  3, batch    80 | loss: 87.7553139CurrentTrain: epoch  3, batch    81 | loss: 74.6679146CurrentTrain: epoch  3, batch    82 | loss: 57.6783989CurrentTrain: epoch  3, batch    83 | loss: 84.5111571CurrentTrain: epoch  3, batch    84 | loss: 105.7928861CurrentTrain: epoch  3, batch    85 | loss: 79.5990815CurrentTrain: epoch  3, batch    86 | loss: 85.4436912CurrentTrain: epoch  3, batch    87 | loss: 88.3633180CurrentTrain: epoch  3, batch    88 | loss: 85.7271647CurrentTrain: epoch  3, batch    89 | loss: 131.6901117CurrentTrain: epoch  3, batch    90 | loss: 64.1075729CurrentTrain: epoch  3, batch    91 | loss: 104.7227797CurrentTrain: epoch  3, batch    92 | loss: 73.7610012CurrentTrain: epoch  3, batch    93 | loss: 66.4784190CurrentTrain: epoch  3, batch    94 | loss: 72.9168318CurrentTrain: epoch  3, batch    95 | loss: 74.7768609CurrentTrain: epoch  4, batch     0 | loss: 85.1781517CurrentTrain: epoch  4, batch     1 | loss: 86.9662909CurrentTrain: epoch  4, batch     2 | loss: 61.0367294CurrentTrain: epoch  4, batch     3 | loss: 134.0746135CurrentTrain: epoch  4, batch     4 | loss: 82.9620457CurrentTrain: epoch  4, batch     5 | loss: 83.5388961CurrentTrain: epoch  4, batch     6 | loss: 74.0388676CurrentTrain: epoch  4, batch     7 | loss: 68.0715519CurrentTrain: epoch  4, batch     8 | loss: 87.9692594CurrentTrain: epoch  4, batch     9 | loss: 65.3445010CurrentTrain: epoch  4, batch    10 | loss: 84.9234742CurrentTrain: epoch  4, batch    11 | loss: 82.7520988CurrentTrain: epoch  4, batch    12 | loss: 69.0640420CurrentTrain: epoch  4, batch    13 | loss: 123.9773640CurrentTrain: epoch  4, batch    14 | loss: 83.8809959CurrentTrain: epoch  4, batch    15 | loss: 75.9172360CurrentTrain: epoch  4, batch    16 | loss: 101.2486074CurrentTrain: epoch  4, batch    17 | loss: 84.0514040CurrentTrain: epoch  4, batch    18 | loss: 60.6124446CurrentTrain: epoch  4, batch    19 | loss: 70.7761701CurrentTrain: epoch  4, batch    20 | loss: 67.9296821CurrentTrain: epoch  4, batch    21 | loss: 57.3114073CurrentTrain: epoch  4, batch    22 | loss: 82.5125895CurrentTrain: epoch  4, batch    23 | loss: 92.4321869CurrentTrain: epoch  4, batch    24 | loss: 131.1891615CurrentTrain: epoch  4, batch    25 | loss: 70.6472201CurrentTrain: epoch  4, batch    26 | loss: 95.9097399CurrentTrain: epoch  4, batch    27 | loss: 79.2973119CurrentTrain: epoch  4, batch    28 | loss: 84.5099822CurrentTrain: epoch  4, batch    29 | loss: 127.1358178CurrentTrain: epoch  4, batch    30 | loss: 82.9043047CurrentTrain: epoch  4, batch    31 | loss: 101.2197352CurrentTrain: epoch  4, batch    32 | loss: 95.4222180CurrentTrain: epoch  4, batch    33 | loss: 100.8191504CurrentTrain: epoch  4, batch    34 | loss: 103.8207388CurrentTrain: epoch  4, batch    35 | loss: 82.2214546CurrentTrain: epoch  4, batch    36 | loss: 86.1789787CurrentTrain: epoch  4, batch    37 | loss: 82.4531629CurrentTrain: epoch  4, batch    38 | loss: 128.0946982CurrentTrain: epoch  4, batch    39 | loss: 87.7911701CurrentTrain: epoch  4, batch    40 | loss: 103.6419364CurrentTrain: epoch  4, batch    41 | loss: 84.7129088CurrentTrain: epoch  4, batch    42 | loss: 76.9069705CurrentTrain: epoch  4, batch    43 | loss: 129.8475165CurrentTrain: epoch  4, batch    44 | loss: 83.3789269CurrentTrain: epoch  4, batch    45 | loss: 100.1631810CurrentTrain: epoch  4, batch    46 | loss: 94.4032617CurrentTrain: epoch  4, batch    47 | loss: 71.1818519CurrentTrain: epoch  4, batch    48 | loss: 80.8019970CurrentTrain: epoch  4, batch    49 | loss: 81.9970327CurrentTrain: epoch  4, batch    50 | loss: 84.7628709CurrentTrain: epoch  4, batch    51 | loss: 101.6715732CurrentTrain: epoch  4, batch    52 | loss: 77.0486804CurrentTrain: epoch  4, batch    53 | loss: 70.4212664CurrentTrain: epoch  4, batch    54 | loss: 103.7654530CurrentTrain: epoch  4, batch    55 | loss: 80.7995085CurrentTrain: epoch  4, batch    56 | loss: 82.0947220CurrentTrain: epoch  4, batch    57 | loss: 87.0639393CurrentTrain: epoch  4, batch    58 | loss: 63.9801824CurrentTrain: epoch  4, batch    59 | loss: 79.9872136CurrentTrain: epoch  4, batch    60 | loss: 110.1726497CurrentTrain: epoch  4, batch    61 | loss: 71.1247821CurrentTrain: epoch  4, batch    62 | loss: 82.9484041CurrentTrain: epoch  4, batch    63 | loss: 83.2952413CurrentTrain: epoch  4, batch    64 | loss: 98.2986419CurrentTrain: epoch  4, batch    65 | loss: 70.3292453CurrentTrain: epoch  4, batch    66 | loss: 82.0828231CurrentTrain: epoch  4, batch    67 | loss: 78.9663886CurrentTrain: epoch  4, batch    68 | loss: 84.6241452CurrentTrain: epoch  4, batch    69 | loss: 88.1084933CurrentTrain: epoch  4, batch    70 | loss: 70.6134299CurrentTrain: epoch  4, batch    71 | loss: 97.7875870CurrentTrain: epoch  4, batch    72 | loss: 81.7559243CurrentTrain: epoch  4, batch    73 | loss: 71.2243195CurrentTrain: epoch  4, batch    74 | loss: 86.6892103CurrentTrain: epoch  4, batch    75 | loss: 67.0541650CurrentTrain: epoch  4, batch    76 | loss: 104.1330861CurrentTrain: epoch  4, batch    77 | loss: 71.5051700CurrentTrain: epoch  4, batch    78 | loss: 128.5797891CurrentTrain: epoch  4, batch    79 | loss: 70.8496950CurrentTrain: epoch  4, batch    80 | loss: 84.1176964CurrentTrain: epoch  4, batch    81 | loss: 77.7315998CurrentTrain: epoch  4, batch    82 | loss: 65.2529600CurrentTrain: epoch  4, batch    83 | loss: 82.0478288CurrentTrain: epoch  4, batch    84 | loss: 100.2352012CurrentTrain: epoch  4, batch    85 | loss: 67.5966939CurrentTrain: epoch  4, batch    86 | loss: 174.2253544CurrentTrain: epoch  4, batch    87 | loss: 101.1492574CurrentTrain: epoch  4, batch    88 | loss: 81.0612033CurrentTrain: epoch  4, batch    89 | loss: 70.5833064CurrentTrain: epoch  4, batch    90 | loss: 85.2757892CurrentTrain: epoch  4, batch    91 | loss: 70.1926228CurrentTrain: epoch  4, batch    92 | loss: 97.9802463CurrentTrain: epoch  4, batch    93 | loss: 79.9905425CurrentTrain: epoch  4, batch    94 | loss: 84.7152082CurrentTrain: epoch  4, batch    95 | loss: 84.4900456CurrentTrain: epoch  5, batch     0 | loss: 64.7307761CurrentTrain: epoch  5, batch     1 | loss: 79.9604874CurrentTrain: epoch  5, batch     2 | loss: 69.8959590CurrentTrain: epoch  5, batch     3 | loss: 81.8054629CurrentTrain: epoch  5, batch     4 | loss: 101.3354705CurrentTrain: epoch  5, batch     5 | loss: 166.2220962CurrentTrain: epoch  5, batch     6 | loss: 130.2756644CurrentTrain: epoch  5, batch     7 | loss: 96.8724540CurrentTrain: epoch  5, batch     8 | loss: 82.5126183CurrentTrain: epoch  5, batch     9 | loss: 170.0442976CurrentTrain: epoch  5, batch    10 | loss: 98.1001230CurrentTrain: epoch  5, batch    11 | loss: 66.2914736CurrentTrain: epoch  5, batch    12 | loss: 99.4973746CurrentTrain: epoch  5, batch    13 | loss: 80.4701758CurrentTrain: epoch  5, batch    14 | loss: 83.5468425CurrentTrain: epoch  5, batch    15 | loss: 79.9292739CurrentTrain: epoch  5, batch    16 | loss: 86.1248911CurrentTrain: epoch  5, batch    17 | loss: 83.6977133CurrentTrain: epoch  5, batch    18 | loss: 82.7426019CurrentTrain: epoch  5, batch    19 | loss: 76.5335364CurrentTrain: epoch  5, batch    20 | loss: 84.2834196CurrentTrain: epoch  5, batch    21 | loss: 100.9094565CurrentTrain: epoch  5, batch    22 | loss: 97.7534497CurrentTrain: epoch  5, batch    23 | loss: 82.3420008CurrentTrain: epoch  5, batch    24 | loss: 103.2445906CurrentTrain: epoch  5, batch    25 | loss: 58.3166766CurrentTrain: epoch  5, batch    26 | loss: 70.5857737CurrentTrain: epoch  5, batch    27 | loss: 82.8254386CurrentTrain: epoch  5, batch    28 | loss: 64.8974078CurrentTrain: epoch  5, batch    29 | loss: 65.5158539CurrentTrain: epoch  5, batch    30 | loss: 57.0000968CurrentTrain: epoch  5, batch    31 | loss: 67.3659868CurrentTrain: epoch  5, batch    32 | loss: 72.8459756CurrentTrain: epoch  5, batch    33 | loss: 81.7919982CurrentTrain: epoch  5, batch    34 | loss: 77.7645448CurrentTrain: epoch  5, batch    35 | loss: 79.3719020CurrentTrain: epoch  5, batch    36 | loss: 92.9542329CurrentTrain: epoch  5, batch    37 | loss: 99.0980786CurrentTrain: epoch  5, batch    38 | loss: 83.6187693CurrentTrain: epoch  5, batch    39 | loss: 69.9765228CurrentTrain: epoch  5, batch    40 | loss: 58.8315494CurrentTrain: epoch  5, batch    41 | loss: 121.5266775CurrentTrain: epoch  5, batch    42 | loss: 87.7380688CurrentTrain: epoch  5, batch    43 | loss: 81.7755982CurrentTrain: epoch  5, batch    44 | loss: 95.2185565CurrentTrain: epoch  5, batch    45 | loss: 99.6153403CurrentTrain: epoch  5, batch    46 | loss: 82.8957338CurrentTrain: epoch  5, batch    47 | loss: 56.4762353CurrentTrain: epoch  5, batch    48 | loss: 81.9420742CurrentTrain: epoch  5, batch    49 | loss: 97.2449797CurrentTrain: epoch  5, batch    50 | loss: 84.1767912CurrentTrain: epoch  5, batch    51 | loss: 83.7369814CurrentTrain: epoch  5, batch    52 | loss: 97.6542093CurrentTrain: epoch  5, batch    53 | loss: 125.8011292CurrentTrain: epoch  5, batch    54 | loss: 82.6715032CurrentTrain: epoch  5, batch    55 | loss: 80.4547930CurrentTrain: epoch  5, batch    56 | loss: 83.4961820CurrentTrain: epoch  5, batch    57 | loss: 69.4656469CurrentTrain: epoch  5, batch    58 | loss: 100.5333368CurrentTrain: epoch  5, batch    59 | loss: 128.4709791CurrentTrain: epoch  5, batch    60 | loss: 80.7502262CurrentTrain: epoch  5, batch    61 | loss: 90.8051823CurrentTrain: epoch  5, batch    62 | loss: 98.6361877CurrentTrain: epoch  5, batch    63 | loss: 70.0593367CurrentTrain: epoch  5, batch    64 | loss: 85.5148001CurrentTrain: epoch  5, batch    65 | loss: 77.5909566CurrentTrain: epoch  5, batch    66 | loss: 69.3474575CurrentTrain: epoch  5, batch    67 | loss: 82.0614218CurrentTrain: epoch  5, batch    68 | loss: 71.6855346CurrentTrain: epoch  5, batch    69 | loss: 76.8474666CurrentTrain: epoch  5, batch    70 | loss: 99.6400338CurrentTrain: epoch  5, batch    71 | loss: 83.3949233CurrentTrain: epoch  5, batch    72 | loss: 70.5853824CurrentTrain: epoch  5, batch    73 | loss: 100.6194848CurrentTrain: epoch  5, batch    74 | loss: 77.1266174CurrentTrain: epoch  5, batch    75 | loss: 124.2966320CurrentTrain: epoch  5, batch    76 | loss: 61.6447933CurrentTrain: epoch  5, batch    77 | loss: 123.5300363CurrentTrain: epoch  5, batch    78 | loss: 98.5906266CurrentTrain: epoch  5, batch    79 | loss: 79.1315982CurrentTrain: epoch  5, batch    80 | loss: 80.0362687CurrentTrain: epoch  5, batch    81 | loss: 84.9146726CurrentTrain: epoch  5, batch    82 | loss: 69.6468287CurrentTrain: epoch  5, batch    83 | loss: 98.1984666CurrentTrain: epoch  5, batch    84 | loss: 81.3185545CurrentTrain: epoch  5, batch    85 | loss: 67.5914848CurrentTrain: epoch  5, batch    86 | loss: 83.4089723CurrentTrain: epoch  5, batch    87 | loss: 98.2960431CurrentTrain: epoch  5, batch    88 | loss: 130.3131081CurrentTrain: epoch  5, batch    89 | loss: 67.0246437CurrentTrain: epoch  5, batch    90 | loss: 78.8225330CurrentTrain: epoch  5, batch    91 | loss: 68.3485073CurrentTrain: epoch  5, batch    92 | loss: 102.0981809CurrentTrain: epoch  5, batch    93 | loss: 57.1517059CurrentTrain: epoch  5, batch    94 | loss: 70.6034612CurrentTrain: epoch  5, batch    95 | loss: 84.0245066CurrentTrain: epoch  6, batch     0 | loss: 78.1428658CurrentTrain: epoch  6, batch     1 | loss: 81.4461831CurrentTrain: epoch  6, batch     2 | loss: 97.8824846CurrentTrain: epoch  6, batch     3 | loss: 68.7963060CurrentTrain: epoch  6, batch     4 | loss: 56.9597694CurrentTrain: epoch  6, batch     5 | loss: 76.6454537CurrentTrain: epoch  6, batch     6 | loss: 82.9790499CurrentTrain: epoch  6, batch     7 | loss: 80.9485355CurrentTrain: epoch  6, batch     8 | loss: 83.1955207CurrentTrain: epoch  6, batch     9 | loss: 98.0435510CurrentTrain: epoch  6, batch    10 | loss: 68.8025533CurrentTrain: epoch  6, batch    11 | loss: 59.5675459CurrentTrain: epoch  6, batch    12 | loss: 120.4223243CurrentTrain: epoch  6, batch    13 | loss: 80.6797494CurrentTrain: epoch  6, batch    14 | loss: 97.0998408CurrentTrain: epoch  6, batch    15 | loss: 69.3700349CurrentTrain: epoch  6, batch    16 | loss: 55.6595880CurrentTrain: epoch  6, batch    17 | loss: 79.8066944CurrentTrain: epoch  6, batch    18 | loss: 66.4666744CurrentTrain: epoch  6, batch    19 | loss: 98.2389186CurrentTrain: epoch  6, batch    20 | loss: 62.9378660CurrentTrain: epoch  6, batch    21 | loss: 78.5505199CurrentTrain: epoch  6, batch    22 | loss: 67.6628273CurrentTrain: epoch  6, batch    23 | loss: 57.0832106CurrentTrain: epoch  6, batch    24 | loss: 83.2205199CurrentTrain: epoch  6, batch    25 | loss: 59.4587266CurrentTrain: epoch  6, batch    26 | loss: 57.0264870CurrentTrain: epoch  6, batch    27 | loss: 80.8044355CurrentTrain: epoch  6, batch    28 | loss: 64.6645037CurrentTrain: epoch  6, batch    29 | loss: 94.2933681CurrentTrain: epoch  6, batch    30 | loss: 80.5802948CurrentTrain: epoch  6, batch    31 | loss: 66.9006579CurrentTrain: epoch  6, batch    32 | loss: 128.9069075CurrentTrain: epoch  6, batch    33 | loss: 78.2632082CurrentTrain: epoch  6, batch    34 | loss: 100.2308920CurrentTrain: epoch  6, batch    35 | loss: 56.8976705CurrentTrain: epoch  6, batch    36 | loss: 82.5817331CurrentTrain: epoch  6, batch    37 | loss: 60.8476468CurrentTrain: epoch  6, batch    38 | loss: 79.6288337CurrentTrain: epoch  6, batch    39 | loss: 97.3932724CurrentTrain: epoch  6, batch    40 | loss: 83.9381078CurrentTrain: epoch  6, batch    41 | loss: 79.5391672CurrentTrain: epoch  6, batch    42 | loss: 104.9155848CurrentTrain: epoch  6, batch    43 | loss: 78.4579049CurrentTrain: epoch  6, batch    44 | loss: 100.3589566CurrentTrain: epoch  6, batch    45 | loss: 124.0845104CurrentTrain: epoch  6, batch    46 | loss: 82.1869928CurrentTrain: epoch  6, batch    47 | loss: 173.5506058CurrentTrain: epoch  6, batch    48 | loss: 175.3190892CurrentTrain: epoch  6, batch    49 | loss: 175.1726494CurrentTrain: epoch  6, batch    50 | loss: 57.6713555CurrentTrain: epoch  6, batch    51 | loss: 83.1276130CurrentTrain: epoch  6, batch    52 | loss: 94.8822770CurrentTrain: epoch  6, batch    53 | loss: 99.6417496CurrentTrain: epoch  6, batch    54 | loss: 67.0272550CurrentTrain: epoch  6, batch    55 | loss: 59.9635171CurrentTrain: epoch  6, batch    56 | loss: 78.2156277CurrentTrain: epoch  6, batch    57 | loss: 82.7734167CurrentTrain: epoch  6, batch    58 | loss: 62.9614693CurrentTrain: epoch  6, batch    59 | loss: 99.6420352CurrentTrain: epoch  6, batch    60 | loss: 70.7898060CurrentTrain: epoch  6, batch    61 | loss: 80.5011899CurrentTrain: epoch  6, batch    62 | loss: 101.6353167CurrentTrain: epoch  6, batch    63 | loss: 57.4185665CurrentTrain: epoch  6, batch    64 | loss: 81.9389762CurrentTrain: epoch  6, batch    65 | loss: 57.2070745CurrentTrain: epoch  6, batch    66 | loss: 69.7150913CurrentTrain: epoch  6, batch    67 | loss: 68.2066378CurrentTrain: epoch  6, batch    68 | loss: 66.4037097CurrentTrain: epoch  6, batch    69 | loss: 64.0925206CurrentTrain: epoch  6, batch    70 | loss: 79.2227987CurrentTrain: epoch  6, batch    71 | loss: 82.5207104CurrentTrain: epoch  6, batch    72 | loss: 101.4480074CurrentTrain: epoch  6, batch    73 | loss: 55.5047485CurrentTrain: epoch  6, batch    74 | loss: 129.4495325CurrentTrain: epoch  6, batch    75 | loss: 66.8396805CurrentTrain: epoch  6, batch    76 | loss: 85.3410243CurrentTrain: epoch  6, batch    77 | loss: 97.0479196CurrentTrain: epoch  6, batch    78 | loss: 83.9502572CurrentTrain: epoch  6, batch    79 | loss: 78.3255037CurrentTrain: epoch  6, batch    80 | loss: 66.1038548CurrentTrain: epoch  6, batch    81 | loss: 102.1710660CurrentTrain: epoch  6, batch    82 | loss: 75.9746822CurrentTrain: epoch  6, batch    83 | loss: 177.8599251CurrentTrain: epoch  6, batch    84 | loss: 81.2770023CurrentTrain: epoch  6, batch    85 | loss: 82.0003299CurrentTrain: epoch  6, batch    86 | loss: 123.8182256CurrentTrain: epoch  6, batch    87 | loss: 80.0483975CurrentTrain: epoch  6, batch    88 | loss: 55.0959688CurrentTrain: epoch  6, batch    89 | loss: 68.8968589CurrentTrain: epoch  6, batch    90 | loss: 76.0474521CurrentTrain: epoch  6, batch    91 | loss: 97.4920291CurrentTrain: epoch  6, batch    92 | loss: 80.2854664CurrentTrain: epoch  6, batch    93 | loss: 99.5525186CurrentTrain: epoch  6, batch    94 | loss: 53.1362263CurrentTrain: epoch  6, batch    95 | loss: 82.2602668CurrentTrain: epoch  7, batch     0 | loss: 66.3388444CurrentTrain: epoch  7, batch     1 | loss: 56.0556536CurrentTrain: epoch  7, batch     2 | loss: 99.8033226CurrentTrain: epoch  7, batch     3 | loss: 94.7363808CurrentTrain: epoch  7, batch     4 | loss: 78.3588441CurrentTrain: epoch  7, batch     5 | loss: 77.4991369CurrentTrain: epoch  7, batch     6 | loss: 72.8410743CurrentTrain: epoch  7, batch     7 | loss: 96.1457569CurrentTrain: epoch  7, batch     8 | loss: 120.4268827CurrentTrain: epoch  7, batch     9 | loss: 80.2244475CurrentTrain: epoch  7, batch    10 | loss: 76.2307620CurrentTrain: epoch  7, batch    11 | loss: 98.2955269CurrentTrain: epoch  7, batch    12 | loss: 56.3296996CurrentTrain: epoch  7, batch    13 | loss: 79.1035570CurrentTrain: epoch  7, batch    14 | loss: 65.6120015CurrentTrain: epoch  7, batch    15 | loss: 81.1080499CurrentTrain: epoch  7, batch    16 | loss: 77.6766600CurrentTrain: epoch  7, batch    17 | loss: 99.2620226CurrentTrain: epoch  7, batch    18 | loss: 75.7242938CurrentTrain: epoch  7, batch    19 | loss: 94.5709013CurrentTrain: epoch  7, batch    20 | loss: 99.6838216CurrentTrain: epoch  7, batch    21 | loss: 126.3703072CurrentTrain: epoch  7, batch    22 | loss: 97.8329420CurrentTrain: epoch  7, batch    23 | loss: 68.1489710CurrentTrain: epoch  7, batch    24 | loss: 59.6545992CurrentTrain: epoch  7, batch    25 | loss: 85.1587973CurrentTrain: epoch  7, batch    26 | loss: 97.1914689CurrentTrain: epoch  7, batch    27 | loss: 99.2251960CurrentTrain: epoch  7, batch    28 | loss: 67.0041536CurrentTrain: epoch  7, batch    29 | loss: 97.7927306CurrentTrain: epoch  7, batch    30 | loss: 66.9597610CurrentTrain: epoch  7, batch    31 | loss: 57.6761706CurrentTrain: epoch  7, batch    32 | loss: 127.4117883CurrentTrain: epoch  7, batch    33 | loss: 64.7798850CurrentTrain: epoch  7, batch    34 | loss: 62.7997318CurrentTrain: epoch  7, batch    35 | loss: 123.4389995CurrentTrain: epoch  7, batch    36 | loss: 99.3714947CurrentTrain: epoch  7, batch    37 | loss: 60.2843413CurrentTrain: epoch  7, batch    38 | loss: 55.4815470CurrentTrain: epoch  7, batch    39 | loss: 94.5692508CurrentTrain: epoch  7, batch    40 | loss: 80.6649884CurrentTrain: epoch  7, batch    41 | loss: 66.2971043CurrentTrain: epoch  7, batch    42 | loss: 94.3414052CurrentTrain: epoch  7, batch    43 | loss: 100.8446104CurrentTrain: epoch  7, batch    44 | loss: 102.3293439CurrentTrain: epoch  7, batch    45 | loss: 64.7736548CurrentTrain: epoch  7, batch    46 | loss: 66.9001876CurrentTrain: epoch  7, batch    47 | loss: 97.4533469CurrentTrain: epoch  7, batch    48 | loss: 63.9261052CurrentTrain: epoch  7, batch    49 | loss: 68.7581783CurrentTrain: epoch  7, batch    50 | loss: 100.4344460CurrentTrain: epoch  7, batch    51 | loss: 100.5556602CurrentTrain: epoch  7, batch    52 | loss: 65.0340360CurrentTrain: epoch  7, batch    53 | loss: 124.1690777CurrentTrain: epoch  7, batch    54 | loss: 59.5776410CurrentTrain: epoch  7, batch    55 | loss: 56.2003322CurrentTrain: epoch  7, batch    56 | loss: 59.5935461CurrentTrain: epoch  7, batch    57 | loss: 78.5716060CurrentTrain: epoch  7, batch    58 | loss: 66.3768781CurrentTrain: epoch  7, batch    59 | loss: 80.6523329CurrentTrain: epoch  7, batch    60 | loss: 79.5519660CurrentTrain: epoch  7, batch    61 | loss: 77.6202809CurrentTrain: epoch  7, batch    62 | loss: 59.8267472CurrentTrain: epoch  7, batch    63 | loss: 79.0871149CurrentTrain: epoch  7, batch    64 | loss: 99.1347238CurrentTrain: epoch  7, batch    65 | loss: 98.9596681CurrentTrain: epoch  7, batch    66 | loss: 75.7132429CurrentTrain: epoch  7, batch    67 | loss: 93.9662575CurrentTrain: epoch  7, batch    68 | loss: 98.9139991CurrentTrain: epoch  7, batch    69 | loss: 97.4669129CurrentTrain: epoch  7, batch    70 | loss: 67.3241282CurrentTrain: epoch  7, batch    71 | loss: 99.0207239CurrentTrain: epoch  7, batch    72 | loss: 78.3583348CurrentTrain: epoch  7, batch    73 | loss: 78.1305453CurrentTrain: epoch  7, batch    74 | loss: 92.2013826CurrentTrain: epoch  7, batch    75 | loss: 68.1325330CurrentTrain: epoch  7, batch    76 | loss: 78.2463275CurrentTrain: epoch  7, batch    77 | loss: 97.8186000CurrentTrain: epoch  7, batch    78 | loss: 97.2648591CurrentTrain: epoch  7, batch    79 | loss: 84.0551643CurrentTrain: epoch  7, batch    80 | loss: 64.6750059CurrentTrain: epoch  7, batch    81 | loss: 82.7044236CurrentTrain: epoch  7, batch    82 | loss: 99.1922922CurrentTrain: epoch  7, batch    83 | loss: 65.9628813CurrentTrain: epoch  7, batch    84 | loss: 64.7976883CurrentTrain: epoch  7, batch    85 | loss: 98.6850220CurrentTrain: epoch  7, batch    86 | loss: 79.4314157CurrentTrain: epoch  7, batch    87 | loss: 96.7438580CurrentTrain: epoch  7, batch    88 | loss: 101.2702177CurrentTrain: epoch  7, batch    89 | loss: 93.3547240CurrentTrain: epoch  7, batch    90 | loss: 78.8280876CurrentTrain: epoch  7, batch    91 | loss: 99.5251808CurrentTrain: epoch  7, batch    92 | loss: 77.4707559CurrentTrain: epoch  7, batch    93 | loss: 80.0004268CurrentTrain: epoch  7, batch    94 | loss: 94.7787173CurrentTrain: epoch  7, batch    95 | loss: 62.0097529CurrentTrain: epoch  8, batch     0 | loss: 79.7239303CurrentTrain: epoch  8, batch     1 | loss: 66.8081076CurrentTrain: epoch  8, batch     2 | loss: 68.5574631CurrentTrain: epoch  8, batch     3 | loss: 127.1865092CurrentTrain: epoch  8, batch     4 | loss: 77.5655678CurrentTrain: epoch  8, batch     5 | loss: 75.3141223CurrentTrain: epoch  8, batch     6 | loss: 61.6781720CurrentTrain: epoch  8, batch     7 | loss: 56.7387290CurrentTrain: epoch  8, batch     8 | loss: 58.5234778CurrentTrain: epoch  8, batch     9 | loss: 68.1628026CurrentTrain: epoch  8, batch    10 | loss: 97.8721157CurrentTrain: epoch  8, batch    11 | loss: 66.3904659CurrentTrain: epoch  8, batch    12 | loss: 81.5848532CurrentTrain: epoch  8, batch    13 | loss: 80.9242029CurrentTrain: epoch  8, batch    14 | loss: 80.8526607CurrentTrain: epoch  8, batch    15 | loss: 119.0088946CurrentTrain: epoch  8, batch    16 | loss: 122.1704140CurrentTrain: epoch  8, batch    17 | loss: 60.5865304CurrentTrain: epoch  8, batch    18 | loss: 64.8809804CurrentTrain: epoch  8, batch    19 | loss: 55.6678568CurrentTrain: epoch  8, batch    20 | loss: 65.0861291CurrentTrain: epoch  8, batch    21 | loss: 94.5975764CurrentTrain: epoch  8, batch    22 | loss: 77.5381615CurrentTrain: epoch  8, batch    23 | loss: 95.0576585CurrentTrain: epoch  8, batch    24 | loss: 125.3865078CurrentTrain: epoch  8, batch    25 | loss: 62.0841971CurrentTrain: epoch  8, batch    26 | loss: 75.8893273CurrentTrain: epoch  8, batch    27 | loss: 52.4543847CurrentTrain: epoch  8, batch    28 | loss: 78.1201784CurrentTrain: epoch  8, batch    29 | loss: 65.4841511CurrentTrain: epoch  8, batch    30 | loss: 124.9045608CurrentTrain: epoch  8, batch    31 | loss: 94.4749674CurrentTrain: epoch  8, batch    32 | loss: 78.4912587CurrentTrain: epoch  8, batch    33 | loss: 78.7953958CurrentTrain: epoch  8, batch    34 | loss: 77.3710601CurrentTrain: epoch  8, batch    35 | loss: 62.5517307CurrentTrain: epoch  8, batch    36 | loss: 75.8230411CurrentTrain: epoch  8, batch    37 | loss: 69.2537091CurrentTrain: epoch  8, batch    38 | loss: 72.7973899CurrentTrain: epoch  8, batch    39 | loss: 102.9626340CurrentTrain: epoch  8, batch    40 | loss: 68.2853408CurrentTrain: epoch  8, batch    41 | loss: 118.7885194CurrentTrain: epoch  8, batch    42 | loss: 81.0075101CurrentTrain: epoch  8, batch    43 | loss: 56.9386365CurrentTrain: epoch  8, batch    44 | loss: 56.1376207CurrentTrain: epoch  8, batch    45 | loss: 81.1610824CurrentTrain: epoch  8, batch    46 | loss: 124.9418903CurrentTrain: epoch  8, batch    47 | loss: 101.8594456CurrentTrain: epoch  8, batch    48 | loss: 54.8060779CurrentTrain: epoch  8, batch    49 | loss: 65.9127992CurrentTrain: epoch  8, batch    50 | loss: 59.9038497CurrentTrain: epoch  8, batch    51 | loss: 67.5686711CurrentTrain: epoch  8, batch    52 | loss: 77.2745769CurrentTrain: epoch  8, batch    53 | loss: 64.4516207CurrentTrain: epoch  8, batch    54 | loss: 92.7180831CurrentTrain: epoch  8, batch    55 | loss: 264.4663262CurrentTrain: epoch  8, batch    56 | loss: 77.8176761CurrentTrain: epoch  8, batch    57 | loss: 118.3254832CurrentTrain: epoch  8, batch    58 | loss: 75.5254638CurrentTrain: epoch  8, batch    59 | loss: 65.3808918CurrentTrain: epoch  8, batch    60 | loss: 81.8299607CurrentTrain: epoch  8, batch    61 | loss: 66.0861618CurrentTrain: epoch  8, batch    62 | loss: 79.1909748CurrentTrain: epoch  8, batch    63 | loss: 99.0340951CurrentTrain: epoch  8, batch    64 | loss: 77.2690259CurrentTrain: epoch  8, batch    65 | loss: 124.2727535CurrentTrain: epoch  8, batch    66 | loss: 81.2385160CurrentTrain: epoch  8, batch    67 | loss: 75.6472156CurrentTrain: epoch  8, batch    68 | loss: 126.4348898CurrentTrain: epoch  8, batch    69 | loss: 59.5978215CurrentTrain: epoch  8, batch    70 | loss: 127.6158326CurrentTrain: epoch  8, batch    71 | loss: 75.4195647CurrentTrain: epoch  8, batch    72 | loss: 64.3414003CurrentTrain: epoch  8, batch    73 | loss: 91.9672847CurrentTrain: epoch  8, batch    74 | loss: 78.3565190CurrentTrain: epoch  8, batch    75 | loss: 98.3444071CurrentTrain: epoch  8, batch    76 | loss: 64.8371076CurrentTrain: epoch  8, batch    77 | loss: 97.2900677CurrentTrain: epoch  8, batch    78 | loss: 167.1810729CurrentTrain: epoch  8, batch    79 | loss: 75.5053549CurrentTrain: epoch  8, batch    80 | loss: 124.0254919CurrentTrain: epoch  8, batch    81 | loss: 73.7714757CurrentTrain: epoch  8, batch    82 | loss: 67.2227970CurrentTrain: epoch  8, batch    83 | loss: 73.6253420CurrentTrain: epoch  8, batch    84 | loss: 95.9023584CurrentTrain: epoch  8, batch    85 | loss: 78.3436228CurrentTrain: epoch  8, batch    86 | loss: 123.8635415CurrentTrain: epoch  8, batch    87 | loss: 77.4470257CurrentTrain: epoch  8, batch    88 | loss: 70.4418220CurrentTrain: epoch  8, batch    89 | loss: 79.9708639CurrentTrain: epoch  8, batch    90 | loss: 94.8338144CurrentTrain: epoch  8, batch    91 | loss: 79.8793825CurrentTrain: epoch  8, batch    92 | loss: 77.7081925CurrentTrain: epoch  8, batch    93 | loss: 96.9673947CurrentTrain: epoch  8, batch    94 | loss: 77.8395990CurrentTrain: epoch  8, batch    95 | loss: 52.3786761CurrentTrain: epoch  9, batch     0 | loss: 78.7680062CurrentTrain: epoch  9, batch     1 | loss: 81.7942911CurrentTrain: epoch  9, batch     2 | loss: 96.6372988CurrentTrain: epoch  9, batch     3 | loss: 123.6262596CurrentTrain: epoch  9, batch     4 | loss: 66.7237839CurrentTrain: epoch  9, batch     5 | loss: 64.0074797CurrentTrain: epoch  9, batch     6 | loss: 66.2310022CurrentTrain: epoch  9, batch     7 | loss: 57.2830854CurrentTrain: epoch  9, batch     8 | loss: 63.2617828CurrentTrain: epoch  9, batch     9 | loss: 96.5289620CurrentTrain: epoch  9, batch    10 | loss: 91.6920260CurrentTrain: epoch  9, batch    11 | loss: 55.4754072CurrentTrain: epoch  9, batch    12 | loss: 98.4343497CurrentTrain: epoch  9, batch    13 | loss: 63.8794758CurrentTrain: epoch  9, batch    14 | loss: 76.3586811CurrentTrain: epoch  9, batch    15 | loss: 166.8016212CurrentTrain: epoch  9, batch    16 | loss: 67.9125473CurrentTrain: epoch  9, batch    17 | loss: 75.0215049CurrentTrain: epoch  9, batch    18 | loss: 63.5325735CurrentTrain: epoch  9, batch    19 | loss: 164.7519632CurrentTrain: epoch  9, batch    20 | loss: 66.2083009CurrentTrain: epoch  9, batch    21 | loss: 93.8537168CurrentTrain: epoch  9, batch    22 | loss: 58.1806366CurrentTrain: epoch  9, batch    23 | loss: 89.7970047CurrentTrain: epoch  9, batch    24 | loss: 77.4070012CurrentTrain: epoch  9, batch    25 | loss: 80.9070451CurrentTrain: epoch  9, batch    26 | loss: 67.8271106CurrentTrain: epoch  9, batch    27 | loss: 126.1301611CurrentTrain: epoch  9, batch    28 | loss: 75.2418703CurrentTrain: epoch  9, batch    29 | loss: 94.7273694CurrentTrain: epoch  9, batch    30 | loss: 77.3947267CurrentTrain: epoch  9, batch    31 | loss: 61.9674257CurrentTrain: epoch  9, batch    32 | loss: 101.1962811CurrentTrain: epoch  9, batch    33 | loss: 98.3251472CurrentTrain: epoch  9, batch    34 | loss: 72.1703620CurrentTrain: epoch  9, batch    35 | loss: 125.8256400CurrentTrain: epoch  9, batch    36 | loss: 61.9459545CurrentTrain: epoch  9, batch    37 | loss: 78.2084647CurrentTrain: epoch  9, batch    38 | loss: 69.1158771CurrentTrain: epoch  9, batch    39 | loss: 77.9705365CurrentTrain: epoch  9, batch    40 | loss: 91.1068691CurrentTrain: epoch  9, batch    41 | loss: 60.2900887CurrentTrain: epoch  9, batch    42 | loss: 92.2755612CurrentTrain: epoch  9, batch    43 | loss: 92.6057600CurrentTrain: epoch  9, batch    44 | loss: 121.5218899CurrentTrain: epoch  9, batch    45 | loss: 74.2545363CurrentTrain: epoch  9, batch    46 | loss: 81.1705865CurrentTrain: epoch  9, batch    47 | loss: 98.5699075CurrentTrain: epoch  9, batch    48 | loss: 124.6587554CurrentTrain: epoch  9, batch    49 | loss: 76.1165488CurrentTrain: epoch  9, batch    50 | loss: 77.5324536CurrentTrain: epoch  9, batch    51 | loss: 57.0398570CurrentTrain: epoch  9, batch    52 | loss: 64.8520307CurrentTrain: epoch  9, batch    53 | loss: 69.3820290CurrentTrain: epoch  9, batch    54 | loss: 99.1415335CurrentTrain: epoch  9, batch    55 | loss: 57.0996861CurrentTrain: epoch  9, batch    56 | loss: 97.0357681CurrentTrain: epoch  9, batch    57 | loss: 61.9245109CurrentTrain: epoch  9, batch    58 | loss: 69.3558592CurrentTrain: epoch  9, batch    59 | loss: 90.4355127CurrentTrain: epoch  9, batch    60 | loss: 62.9952067CurrentTrain: epoch  9, batch    61 | loss: 75.6805120CurrentTrain: epoch  9, batch    62 | loss: 75.9293972CurrentTrain: epoch  9, batch    63 | loss: 74.9019604CurrentTrain: epoch  9, batch    64 | loss: 63.9915578CurrentTrain: epoch  9, batch    65 | loss: 54.0174123CurrentTrain: epoch  9, batch    66 | loss: 93.1871199CurrentTrain: epoch  9, batch    67 | loss: 75.5941934CurrentTrain: epoch  9, batch    68 | loss: 77.1955304CurrentTrain: epoch  9, batch    69 | loss: 76.8357448CurrentTrain: epoch  9, batch    70 | loss: 66.8479954CurrentTrain: epoch  9, batch    71 | loss: 124.6624192CurrentTrain: epoch  9, batch    72 | loss: 121.1315064CurrentTrain: epoch  9, batch    73 | loss: 96.7681146CurrentTrain: epoch  9, batch    74 | loss: 76.6516557CurrentTrain: epoch  9, batch    75 | loss: 91.2762320CurrentTrain: epoch  9, batch    76 | loss: 78.1410684CurrentTrain: epoch  9, batch    77 | loss: 57.2316283CurrentTrain: epoch  9, batch    78 | loss: 74.2767863CurrentTrain: epoch  9, batch    79 | loss: 69.5907290CurrentTrain: epoch  9, batch    80 | loss: 77.8166604CurrentTrain: epoch  9, batch    81 | loss: 65.2330280CurrentTrain: epoch  9, batch    82 | loss: 67.3732768CurrentTrain: epoch  9, batch    83 | loss: 75.8775627CurrentTrain: epoch  9, batch    84 | loss: 96.0641407CurrentTrain: epoch  9, batch    85 | loss: 101.2737712CurrentTrain: epoch  9, batch    86 | loss: 66.2109397CurrentTrain: epoch  9, batch    87 | loss: 63.7435510CurrentTrain: epoch  9, batch    88 | loss: 93.6747258CurrentTrain: epoch  9, batch    89 | loss: 78.6050893CurrentTrain: epoch  9, batch    90 | loss: 77.6958709CurrentTrain: epoch  9, batch    91 | loss: 63.6406398CurrentTrain: epoch  9, batch    92 | loss: 75.4925534CurrentTrain: epoch  9, batch    93 | loss: 78.2403356CurrentTrain: epoch  9, batch    94 | loss: 79.2238725CurrentTrain: epoch  9, batch    95 | loss: 81.7804458

F1 score per class: {32: np.float64(0.6146341463414634), 6: np.float64(0.7926267281105991), 19: np.float64(0.34782608695652173), 24: np.float64(0.7407407407407407), 26: np.float64(0.9292929292929293), 29: np.float64(0.8256880733944955)}
Micro-average F1 score: 0.7623485554520038
Weighted-average F1 score: 0.7593529164806483
F1 score per class: {32: np.float64(0.6203703703703703), 6: np.float64(0.788135593220339), 19: np.float64(0.2641509433962264), 24: np.float64(0.7311827956989247), 26: np.float64(0.9556650246305419), 29: np.float64(0.82)}
Micro-average F1 score: 0.7568555758683729
Weighted-average F1 score: 0.749496362199393
F1 score per class: {32: np.float64(0.6175115207373272), 6: np.float64(0.7965367965367965), 19: np.float64(0.27450980392156865), 24: np.float64(0.7311827956989247), 26: np.float64(0.94), 29: np.float64(0.8258706467661692)}
Micro-average F1 score: 0.7569060773480663
Weighted-average F1 score: 0.7499095907667077

F1 score per class: {32: np.float64(0.6146341463414634), 6: np.float64(0.7926267281105991), 19: np.float64(0.34782608695652173), 24: np.float64(0.7407407407407407), 26: np.float64(0.9292929292929293), 29: np.float64(0.8256880733944955)}
Micro-average F1 score: 0.7623485554520038
Weighted-average F1 score: 0.7593529164806483
F1 score per class: {32: np.float64(0.6203703703703703), 6: np.float64(0.788135593220339), 19: np.float64(0.2641509433962264), 24: np.float64(0.7311827956989247), 26: np.float64(0.9556650246305419), 29: np.float64(0.82)}
Micro-average F1 score: 0.7568555758683729
Weighted-average F1 score: 0.749496362199393
F1 score per class: {32: np.float64(0.6175115207373272), 6: np.float64(0.7965367965367965), 19: np.float64(0.27450980392156865), 24: np.float64(0.7311827956989247), 26: np.float64(0.94), 29: np.float64(0.8258706467661692)}
Micro-average F1 score: 0.7569060773480663
Weighted-average F1 score: 0.7499095907667077

F1 score per class: {32: np.float64(0.42857142857142855), 6: np.float64(0.7381974248927039), 19: np.float64(0.19047619047619047), 24: np.float64(0.6730769230769231), 26: np.float64(0.8558139534883721), 29: np.float64(0.627177700348432)}
Micro-average F1 score: 0.619227857683573
Weighted-average F1 score: 0.6006073294316845
F1 score per class: {32: np.float64(0.42948717948717946), 6: np.float64(0.7181467181467182), 19: np.float64(0.17073170731707318), 24: np.float64(0.6666666666666666), 26: np.float64(0.8584070796460177), 29: np.float64(0.656)}
Micro-average F1 score: 0.6211552888222055
Weighted-average F1 score: 0.6037497728510852
F1 score per class: {32: np.float64(0.42948717948717946), 6: np.float64(0.7330677290836654), 19: np.float64(0.17073170731707318), 24: np.float64(0.6601941747572816), 26: np.float64(0.8623853211009175), 29: np.float64(0.6484375)}
Micro-average F1 score: 0.6203773584905661
Weighted-average F1 score: 0.6016971980488083

F1 score per class: {32: np.float64(0.42857142857142855), 6: np.float64(0.7381974248927039), 19: np.float64(0.19047619047619047), 24: np.float64(0.6730769230769231), 26: np.float64(0.8558139534883721), 29: np.float64(0.627177700348432)}
Micro-average F1 score: 0.619227857683573
Weighted-average F1 score: 0.6006073294316845
F1 score per class: {32: np.float64(0.42948717948717946), 6: np.float64(0.7181467181467182), 19: np.float64(0.17073170731707318), 24: np.float64(0.6666666666666666), 26: np.float64(0.8584070796460177), 29: np.float64(0.656)}
Micro-average F1 score: 0.6211552888222055
Weighted-average F1 score: 0.6037497728510852
F1 score per class: {32: np.float64(0.42948717948717946), 6: np.float64(0.7330677290836654), 19: np.float64(0.17073170731707318), 24: np.float64(0.6601941747572816), 26: np.float64(0.8623853211009175), 29: np.float64(0.6484375)}
Micro-average F1 score: 0.6203773584905661
Weighted-average F1 score: 0.6016971980488083
cur_acc_wo_na:  ['0.7623']
his_acc_wo_na:  ['0.7623']
cur_acc des_wo_na:  ['0.7569']
his_acc des_wo_na:  ['0.7569']
cur_acc rrf_wo_na:  ['0.7569']
his_acc rrf_wo_na:  ['0.7569']
cur_acc_w_na:  ['0.6192']
his_acc_w_na:  ['0.6192']
cur_acc des_w_na:  ['0.6212']
his_acc des_w_na:  ['0.6212']
cur_acc rrf_w_na:  ['0.6204']
his_acc rrf_w_na:  ['0.6204']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 83.3145282CurrentTrain: epoch  0, batch     1 | loss: 146.4824519CurrentTrain: epoch  0, batch     2 | loss: 77.4135980CurrentTrain: epoch  0, batch     3 | loss: 13.3756588CurrentTrain: epoch  1, batch     0 | loss: 88.0683437CurrentTrain: epoch  1, batch     1 | loss: 83.5241908CurrentTrain: epoch  1, batch     2 | loss: 85.6757857CurrentTrain: epoch  1, batch     3 | loss: 14.7717827CurrentTrain: epoch  2, batch     0 | loss: 71.9399301CurrentTrain: epoch  2, batch     1 | loss: 81.2974620CurrentTrain: epoch  2, batch     2 | loss: 71.1439804CurrentTrain: epoch  2, batch     3 | loss: 10.4328502CurrentTrain: epoch  3, batch     0 | loss: 80.3124811CurrentTrain: epoch  3, batch     1 | loss: 85.9803310CurrentTrain: epoch  3, batch     2 | loss: 65.6908953CurrentTrain: epoch  3, batch     3 | loss: 21.4986411CurrentTrain: epoch  4, batch     0 | loss: 80.1741192CurrentTrain: epoch  4, batch     1 | loss: 79.5408257CurrentTrain: epoch  4, batch     2 | loss: 76.9685258CurrentTrain: epoch  4, batch     3 | loss: 17.6437799CurrentTrain: epoch  5, batch     0 | loss: 78.0178241CurrentTrain: epoch  5, batch     1 | loss: 65.3943928CurrentTrain: epoch  5, batch     2 | loss: 66.2761861CurrentTrain: epoch  5, batch     3 | loss: 10.0787381CurrentTrain: epoch  6, batch     0 | loss: 66.0173805CurrentTrain: epoch  6, batch     1 | loss: 63.1492689CurrentTrain: epoch  6, batch     2 | loss: 65.2577108CurrentTrain: epoch  6, batch     3 | loss: 16.8864561CurrentTrain: epoch  7, batch     0 | loss: 65.3425691CurrentTrain: epoch  7, batch     1 | loss: 73.9373896CurrentTrain: epoch  7, batch     2 | loss: 91.2718088CurrentTrain: epoch  7, batch     3 | loss: 18.9490700CurrentTrain: epoch  8, batch     0 | loss: 60.2897580CurrentTrain: epoch  8, batch     1 | loss: 119.4353799CurrentTrain: epoch  8, batch     2 | loss: 63.6350900CurrentTrain: epoch  8, batch     3 | loss: 8.8955579CurrentTrain: epoch  9, batch     0 | loss: 62.6621617CurrentTrain: epoch  9, batch     1 | loss: 62.0828076CurrentTrain: epoch  9, batch     2 | loss: 76.5603467CurrentTrain: epoch  9, batch     3 | loss: 5.3002822
MemoryTrain:  epoch  0, batch     0 | loss: 2.2614493MemoryTrain:  epoch  1, batch     0 | loss: 2.2505320MemoryTrain:  epoch  2, batch     0 | loss: 1.6179533MemoryTrain:  epoch  3, batch     0 | loss: 1.4500269MemoryTrain:  epoch  4, batch     0 | loss: 1.2077511MemoryTrain:  epoch  5, batch     0 | loss: 1.0106686MemoryTrain:  epoch  6, batch     0 | loss: 0.8529092MemoryTrain:  epoch  7, batch     0 | loss: 0.7523967MemoryTrain:  epoch  8, batch     0 | loss: 0.6155480MemoryTrain:  epoch  9, batch     0 | loss: 0.5618290

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6666666666666666), 7: np.float64(0.7741935483870968), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.41379310344827586), 26: np.float64(0.0), 27: np.float64(0.2857142857142857), 29: np.float64(0.0), 31: np.float64(0.1935483870967742)}
Micro-average F1 score: 0.31186440677966104
Weighted-average F1 score: 0.273069641821908
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5454545454545454), 7: np.float64(0.7142857142857143), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.48), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.37735849056603776)}
Micro-average F1 score: 0.37630662020905925
Weighted-average F1 score: 0.31676833146131866
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6), 7: np.float64(0.7692307692307693), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.4444444444444444), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.35185185185185186)}
Micro-average F1 score: 0.37992831541218636
Weighted-average F1 score: 0.32300785634118967

F1 score per class: {32: np.float64(0.40789473684210525), 6: np.float64(0.061855670103092786), 7: np.float64(0.7741935483870968), 40: np.float64(0.6459143968871596), 9: np.float64(0.18181818181818182), 19: np.float64(0.7362637362637363), 24: np.float64(0.32432432432432434), 26: np.float64(0.9246231155778895), 27: np.float64(0.15384615384615385), 29: np.float64(0.826530612244898), 31: np.float64(0.0664819944598338)}
Micro-average F1 score: 0.5095057034220533
Weighted-average F1 score: 0.44093194311832634
F1 score per class: {32: np.float64(0.37681159420289856), 6: np.float64(0.05357142857142857), 7: np.float64(0.6666666666666666), 40: np.float64(0.6335877862595419), 9: np.float64(0.30303030303030304), 19: np.float64(0.7368421052631579), 24: np.float64(0.36363636363636365), 26: np.float64(0.9253731343283582), 27: np.float64(0.0), 29: np.float64(0.8041237113402062), 31: np.float64(0.22598870056497175)}
Micro-average F1 score: 0.5692414752957551
Weighted-average F1 score: 0.5306533249244185
F1 score per class: {32: np.float64(0.37142857142857144), 6: np.float64(0.05405405405405406), 7: np.float64(0.7575757575757576), 40: np.float64(0.6434108527131783), 9: np.float64(0.2857142857142857), 19: np.float64(0.7419354838709677), 24: np.float64(0.35294117647058826), 26: np.float64(0.9306930693069307), 27: np.float64(0.0), 29: np.float64(0.7959183673469388), 31: np.float64(0.20765027322404372)}
Micro-average F1 score: 0.5716292134831461
Weighted-average F1 score: 0.5326298163508733

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.7272727272727273), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.3870967741935484), 26: np.float64(0.0), 27: np.float64(0.2222222222222222), 29: np.float64(0.0), 31: np.float64(0.17777777777777778)}
Micro-average F1 score: 0.2822085889570552
Weighted-average F1 score: 0.25011942308046997
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.4), 7: np.float64(0.6666666666666666), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.4444444444444444), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.3669724770642202)}
Micro-average F1 score: 0.33962264150943394
Weighted-average F1 score: 0.2839939237672643
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.46153846153846156), 7: np.float64(0.7246376811594203), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.41379310344827586), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.3392857142857143)}
Micro-average F1 score: 0.34527687296416937
Weighted-average F1 score: 0.292233103968428

F1 score per class: {32: np.float64(0.28440366972477066), 6: np.float64(0.03870967741935484), 7: np.float64(0.7272727272727273), 40: np.float64(0.6102941176470589), 9: np.float64(0.16), 19: np.float64(0.6802030456852792), 24: np.float64(0.2608695652173913), 26: np.float64(0.8440366972477065), 27: np.float64(0.06666666666666667), 29: np.float64(0.675), 31: np.float64(0.05286343612334802)}
Micro-average F1 score: 0.4185320145757418
Weighted-average F1 score: 0.3611359630223303
F1 score per class: {32: np.float64(0.28415300546448086), 6: np.float64(0.03225806451612903), 7: np.float64(0.6097560975609756), 40: np.float64(0.5928571428571429), 9: np.float64(0.18518518518518517), 19: np.float64(0.660377358490566), 24: np.float64(0.2926829268292683), 26: np.float64(0.8416289592760181), 27: np.float64(0.0), 29: np.float64(0.6695278969957081), 31: np.float64(0.19801980198019803)}
Micro-average F1 score: 0.4722863741339492
Weighted-average F1 score: 0.43320641537788646
F1 score per class: {32: np.float64(0.2765957446808511), 6: np.float64(0.03333333333333333), 7: np.float64(0.7142857142857143), 40: np.float64(0.6014492753623188), 9: np.float64(0.20512820512820512), 19: np.float64(0.6764705882352942), 24: np.float64(0.2857142857142857), 26: np.float64(0.8392857142857143), 27: np.float64(0.0), 29: np.float64(0.6610169491525424), 31: np.float64(0.1792452830188679)}
Micro-average F1 score: 0.4765807962529274
Weighted-average F1 score: 0.43697472577914154
cur_acc_wo_na:  ['0.7623', '0.3119']
his_acc_wo_na:  ['0.7623', '0.5095']
cur_acc des_wo_na:  ['0.7569', '0.3763']
his_acc des_wo_na:  ['0.7569', '0.5692']
cur_acc rrf_wo_na:  ['0.7569', '0.3799']
his_acc rrf_wo_na:  ['0.7569', '0.5716']
cur_acc_w_na:  ['0.6192', '0.2822']
his_acc_w_na:  ['0.6192', '0.4185']
cur_acc des_w_na:  ['0.6212', '0.3396']
his_acc des_w_na:  ['0.6212', '0.4723']
cur_acc rrf_w_na:  ['0.6204', '0.3453']
his_acc rrf_w_na:  ['0.6204', '0.4766']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 104.0752416CurrentTrain: epoch  0, batch     1 | loss: 105.7024952CurrentTrain: epoch  0, batch     2 | loss: 89.7040578CurrentTrain: epoch  0, batch     3 | loss: 96.1103726CurrentTrain: epoch  1, batch     0 | loss: 84.2168633CurrentTrain: epoch  1, batch     1 | loss: 108.3732423CurrentTrain: epoch  1, batch     2 | loss: 78.3411018CurrentTrain: epoch  1, batch     3 | loss: 146.2501279CurrentTrain: epoch  2, batch     0 | loss: 95.0362296CurrentTrain: epoch  2, batch     1 | loss: 128.5190033CurrentTrain: epoch  2, batch     2 | loss: 89.2340103CurrentTrain: epoch  2, batch     3 | loss: 69.4209515CurrentTrain: epoch  3, batch     0 | loss: 73.8933426CurrentTrain: epoch  3, batch     1 | loss: 134.2302265CurrentTrain: epoch  3, batch     2 | loss: 73.0611342CurrentTrain: epoch  3, batch     3 | loss: 58.9210707CurrentTrain: epoch  4, batch     0 | loss: 83.6248946CurrentTrain: epoch  4, batch     1 | loss: 86.5313304CurrentTrain: epoch  4, batch     2 | loss: 70.9956913CurrentTrain: epoch  4, batch     3 | loss: 86.4766461CurrentTrain: epoch  5, batch     0 | loss: 83.2773240CurrentTrain: epoch  5, batch     1 | loss: 80.3946341CurrentTrain: epoch  5, batch     2 | loss: 84.5416272CurrentTrain: epoch  5, batch     3 | loss: 79.1496074CurrentTrain: epoch  6, batch     0 | loss: 82.8233730CurrentTrain: epoch  6, batch     1 | loss: 96.6336219CurrentTrain: epoch  6, batch     2 | loss: 96.3350573CurrentTrain: epoch  6, batch     3 | loss: 66.0684084CurrentTrain: epoch  7, batch     0 | loss: 69.4804801CurrentTrain: epoch  7, batch     1 | loss: 98.7918744CurrentTrain: epoch  7, batch     2 | loss: 82.6009082CurrentTrain: epoch  7, batch     3 | loss: 61.9111995CurrentTrain: epoch  8, batch     0 | loss: 65.1619252CurrentTrain: epoch  8, batch     1 | loss: 95.4701868CurrentTrain: epoch  8, batch     2 | loss: 100.7712307CurrentTrain: epoch  8, batch     3 | loss: 76.5095071CurrentTrain: epoch  9, batch     0 | loss: 77.3617554CurrentTrain: epoch  9, batch     1 | loss: 122.4084686CurrentTrain: epoch  9, batch     2 | loss: 95.8262334CurrentTrain: epoch  9, batch     3 | loss: 52.9304260
MemoryTrain:  epoch  0, batch     0 | loss: 1.6920074MemoryTrain:  epoch  1, batch     0 | loss: 1.3917869MemoryTrain:  epoch  2, batch     0 | loss: 1.2135339MemoryTrain:  epoch  3, batch     0 | loss: 0.9297429MemoryTrain:  epoch  4, batch     0 | loss: 0.7626741MemoryTrain:  epoch  5, batch     0 | loss: 0.6921650MemoryTrain:  epoch  6, batch     0 | loss: 0.5507662MemoryTrain:  epoch  7, batch     0 | loss: 0.4367538MemoryTrain:  epoch  8, batch     0 | loss: 0.4050467MemoryTrain:  epoch  9, batch     0 | loss: 0.3704837

F1 score per class: {0: np.float64(0.8947368421052632), 32: np.float64(0.907103825136612), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.21739130434782608), 40: np.float64(0.0), 13: np.float64(0.5897435897435898), 19: np.float64(0.5915492957746479), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.6252354048964218
Weighted-average F1 score: 0.5177251756374444
F1 score per class: {0: np.float64(0.7674418604651163), 32: np.float64(0.8823529411764706), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.14814814814814814), 9: np.float64(0.0), 13: np.float64(0.39603960396039606), 19: np.float64(0.5681818181818182), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.5475040257648953
Weighted-average F1 score: 0.45797217737427737
F1 score per class: {0: np.float64(0.8148148148148148), 32: np.float64(0.9263157894736842), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.12121212121212122), 40: np.float64(0.0), 13: np.float64(0.45544554455445546), 19: np.float64(0.6172839506172839), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.5916955017301038
Weighted-average F1 score: 0.4901761305536937

F1 score per class: {32: np.float64(0.7010309278350515), 0: np.float64(0.907103825136612), 4: np.float64(0.4050632911392405), 6: np.float64(0.06666666666666667), 7: np.float64(0.8), 40: np.float64(0.09523809523809523), 9: np.float64(0.6470588235294118), 13: np.float64(0.32167832167832167), 19: np.float64(0.56), 21: np.float64(0.1), 23: np.float64(0.6903553299492385), 24: np.float64(0.3684210526315789), 26: np.float64(0.9117647058823529), 27: np.float64(0.11764705882352941), 29: np.float64(0.7906976744186046), 31: np.float64(0.21333333333333335)}
Micro-average F1 score: 0.5627118644067797
Weighted-average F1 score: 0.512468676351592
F1 score per class: {32: np.float64(0.5546218487394958), 0: np.float64(0.8780487804878049), 4: np.float64(0.4195121951219512), 6: np.float64(0.06666666666666667), 7: np.float64(0.6493506493506493), 40: np.float64(0.08), 9: np.float64(0.5742574257425742), 13: np.float64(0.17167381974248927), 19: np.float64(0.5208333333333334), 21: np.float64(0.3076923076923077), 23: np.float64(0.6829268292682927), 24: np.float64(0.30434782608695654), 26: np.float64(0.9047619047619048), 27: np.float64(0.08), 29: np.float64(0.7454545454545455), 31: np.float64(0.147239263803681)}
Micro-average F1 score: 0.5209865858935526
Weighted-average F1 score: 0.47696920150894795
F1 score per class: {32: np.float64(0.5641025641025641), 0: np.float64(0.9263157894736842), 4: np.float64(0.45652173913043476), 6: np.float64(0.07058823529411765), 7: np.float64(0.7058823529411765), 40: np.float64(0.06153846153846154), 9: np.float64(0.6176470588235294), 13: np.float64(0.2119815668202765), 19: np.float64(0.5681818181818182), 21: np.float64(0.14285714285714285), 23: np.float64(0.6896551724137931), 24: np.float64(0.3333333333333333), 26: np.float64(0.9090909090909091), 27: np.float64(0.06666666666666667), 29: np.float64(0.7557603686635944), 31: np.float64(0.13903743315508021)}
Micro-average F1 score: 0.5395095367847411
Weighted-average F1 score: 0.4909977125847129

F1 score per class: {0: np.float64(0.8607594936708861), 32: np.float64(0.8691099476439791), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.10204081632653061), 40: np.float64(0.0), 13: np.float64(0.42592592592592593), 19: np.float64(0.5454545454545454), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.47092198581560285
Weighted-average F1 score: 0.3585373866970708
F1 score per class: {0: np.float64(0.7333333333333333), 32: np.float64(0.8256880733944955), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.08163265306122448), 9: np.float64(0.0), 13: np.float64(0.28776978417266186), 19: np.float64(0.46296296296296297), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.4101326899879373
Weighted-average F1 score: 0.3271093160809511
F1 score per class: {0: np.float64(0.7674418604651163), 32: np.float64(0.88), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.07017543859649122), 40: np.float64(0.0), 13: np.float64(0.32167832167832167), 19: np.float64(0.5), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.4464751958224543
Weighted-average F1 score: 0.3512486190435536

F1 score per class: {32: np.float64(0.5230769230769231), 0: np.float64(0.8645833333333334), 4: np.float64(0.2711864406779661), 6: np.float64(0.043478260869565216), 7: np.float64(0.75), 40: np.float64(0.0411522633744856), 9: np.float64(0.6135458167330677), 13: np.float64(0.21100917431192662), 19: np.float64(0.5121951219512195), 21: np.float64(0.07692307692307693), 23: np.float64(0.6210045662100456), 24: np.float64(0.2916666666666667), 26: np.float64(0.7982832618025751), 27: np.float64(0.07692307692307693), 29: np.float64(0.5902777777777778), 31: np.float64(0.18181818181818182)}
Micro-average F1 score: 0.43717080511662904
Weighted-average F1 score: 0.38678109737946587
F1 score per class: {32: np.float64(0.4520547945205479), 0: np.float64(0.8108108108108109), 4: np.float64(0.26380368098159507), 6: np.float64(0.0379746835443038), 7: np.float64(0.5494505494505495), 40: np.float64(0.04), 9: np.float64(0.5178571428571429), 13: np.float64(0.11173184357541899), 19: np.float64(0.42016806722689076), 21: np.float64(0.1875), 23: np.float64(0.6140350877192983), 24: np.float64(0.2222222222222222), 26: np.float64(0.7786885245901639), 27: np.float64(0.045454545454545456), 29: np.float64(0.5324675324675324), 31: np.float64(0.12)}
Micro-average F1 score: 0.394624713208784
Weighted-average F1 score: 0.3561190189478625
F1 score per class: {32: np.float64(0.44594594594594594), 0: np.float64(0.8756218905472637), 4: np.float64(0.2906574394463668), 6: np.float64(0.04054054054054054), 7: np.float64(0.6486486486486487), 40: np.float64(0.031746031746031744), 9: np.float64(0.5714285714285714), 13: np.float64(0.13450292397660818), 19: np.float64(0.46296296296296297), 21: np.float64(0.1), 23: np.float64(0.625), 24: np.float64(0.24561403508771928), 26: np.float64(0.7883817427385892), 27: np.float64(0.03773584905660377), 29: np.float64(0.5503355704697986), 31: np.float64(0.11353711790393013)}
Micro-average F1 score: 0.4136490250696379
Weighted-average F1 score: 0.3690165112556378
cur_acc_wo_na:  ['0.7623', '0.3119', '0.6252']
his_acc_wo_na:  ['0.7623', '0.5095', '0.5627']
cur_acc des_wo_na:  ['0.7569', '0.3763', '0.5475']
his_acc des_wo_na:  ['0.7569', '0.5692', '0.5210']
cur_acc rrf_wo_na:  ['0.7569', '0.3799', '0.5917']
his_acc rrf_wo_na:  ['0.7569', '0.5716', '0.5395']
cur_acc_w_na:  ['0.6192', '0.2822', '0.4709']
his_acc_w_na:  ['0.6192', '0.4185', '0.4372']
cur_acc des_w_na:  ['0.6212', '0.3396', '0.4101']
his_acc des_w_na:  ['0.6212', '0.4723', '0.3946']
cur_acc rrf_w_na:  ['0.6204', '0.3453', '0.4465']
his_acc rrf_w_na:  ['0.6204', '0.4766', '0.4136']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 112.4177447CurrentTrain: epoch  0, batch     1 | loss: 115.6411282CurrentTrain: epoch  0, batch     2 | loss: 144.6544231CurrentTrain: epoch  0, batch     3 | loss: 140.2929291CurrentTrain: epoch  0, batch     4 | loss: 51.2380389CurrentTrain: epoch  1, batch     0 | loss: 112.7299588CurrentTrain: epoch  1, batch     1 | loss: 134.5244403CurrentTrain: epoch  1, batch     2 | loss: 90.3133878CurrentTrain: epoch  1, batch     3 | loss: 86.5821691CurrentTrain: epoch  1, batch     4 | loss: 81.8884097CurrentTrain: epoch  2, batch     0 | loss: 132.7811314CurrentTrain: epoch  2, batch     1 | loss: 83.5602054CurrentTrain: epoch  2, batch     2 | loss: 87.2460473CurrentTrain: epoch  2, batch     3 | loss: 88.4621558CurrentTrain: epoch  2, batch     4 | loss: 64.5683009CurrentTrain: epoch  3, batch     0 | loss: 85.0506402CurrentTrain: epoch  3, batch     1 | loss: 81.8544808CurrentTrain: epoch  3, batch     2 | loss: 133.9245618CurrentTrain: epoch  3, batch     3 | loss: 81.0744163CurrentTrain: epoch  3, batch     4 | loss: 115.1960804CurrentTrain: epoch  4, batch     0 | loss: 128.8890753CurrentTrain: epoch  4, batch     1 | loss: 80.0166839CurrentTrain: epoch  4, batch     2 | loss: 99.8208888CurrentTrain: epoch  4, batch     3 | loss: 128.2079929CurrentTrain: epoch  4, batch     4 | loss: 62.3275036CurrentTrain: epoch  5, batch     0 | loss: 105.4754360CurrentTrain: epoch  5, batch     1 | loss: 96.7724835CurrentTrain: epoch  5, batch     2 | loss: 96.7327706CurrentTrain: epoch  5, batch     3 | loss: 100.0993819CurrentTrain: epoch  5, batch     4 | loss: 105.2311751CurrentTrain: epoch  6, batch     0 | loss: 79.3719738CurrentTrain: epoch  6, batch     1 | loss: 100.8513353CurrentTrain: epoch  6, batch     2 | loss: 125.6520579CurrentTrain: epoch  6, batch     3 | loss: 78.8480190CurrentTrain: epoch  6, batch     4 | loss: 61.1986208CurrentTrain: epoch  7, batch     0 | loss: 82.7113707CurrentTrain: epoch  7, batch     1 | loss: 66.3001920CurrentTrain: epoch  7, batch     2 | loss: 81.5460493CurrentTrain: epoch  7, batch     3 | loss: 81.7647145CurrentTrain: epoch  7, batch     4 | loss: 59.2875714CurrentTrain: epoch  8, batch     0 | loss: 123.9212651CurrentTrain: epoch  8, batch     1 | loss: 90.8792292CurrentTrain: epoch  8, batch     2 | loss: 80.3100483CurrentTrain: epoch  8, batch     3 | loss: 65.8387693CurrentTrain: epoch  8, batch     4 | loss: 109.6604925CurrentTrain: epoch  9, batch     0 | loss: 95.3507698CurrentTrain: epoch  9, batch     1 | loss: 168.6364878CurrentTrain: epoch  9, batch     2 | loss: 73.5326928CurrentTrain: epoch  9, batch     3 | loss: 95.3553574CurrentTrain: epoch  9, batch     4 | loss: 47.8334959
MemoryTrain:  epoch  0, batch     0 | loss: 0.9684210MemoryTrain:  epoch  1, batch     0 | loss: 0.8769825MemoryTrain:  epoch  2, batch     0 | loss: 0.7706893MemoryTrain:  epoch  3, batch     0 | loss: 0.6061858MemoryTrain:  epoch  4, batch     0 | loss: 0.4578353MemoryTrain:  epoch  5, batch     0 | loss: 0.4022607MemoryTrain:  epoch  6, batch     0 | loss: 0.3325230MemoryTrain:  epoch  7, batch     0 | loss: 0.2838234MemoryTrain:  epoch  8, batch     0 | loss: 0.2667460MemoryTrain:  epoch  9, batch     0 | loss: 0.2447353

F1 score per class: {32: np.float64(0.8715596330275229), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.27350427350427353), 40: np.float64(0.0), 10: np.float64(0.7213114754098361), 13: np.float64(0.0), 16: np.float64(0.2608695652173913), 17: np.float64(0.0), 18: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5335892514395394
Weighted-average F1 score: 0.5396003721284972
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.6312292358803987), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.632258064516129), 13: np.float64(0.0), 16: np.float64(0.6666666666666666), 17: np.float64(0.3333333333333333), 18: np.float64(0.5), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5281501340482574
Weighted-average F1 score: 0.48117291480924945
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.7063197026022305), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.5174825174825175), 13: np.float64(0.0), 16: np.float64(0.6764705882352942), 17: np.float64(0.3333333333333333), 18: np.float64(0.4307692307692308), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5285935085007728
Weighted-average F1 score: 0.4862188647062125

F1 score per class: {0: np.float64(0.7727272727272727), 4: np.float64(0.8888888888888888), 5: np.float64(0.8370044052863436), 6: np.float64(0.3741935483870968), 7: np.float64(0.07317073170731707), 9: np.float64(0.7692307692307693), 10: np.float64(0.24806201550387597), 13: np.float64(0.045454545454545456), 16: np.float64(0.6027397260273972), 17: np.float64(0.0), 18: np.float64(0.24489795918367346), 19: np.float64(0.6396761133603239), 21: np.float64(0.39316239316239315), 23: np.float64(0.5925925925925926), 24: np.float64(0.0), 26: np.float64(0.6733668341708543), 27: np.float64(0.36363636363636365), 29: np.float64(0.883495145631068), 31: np.float64(0.15384615384615385), 32: np.float64(0.7813953488372093), 40: np.float64(0.16030534351145037)}
Micro-average F1 score: 0.5640618802062674
Weighted-average F1 score: 0.5434951211862656
F1 score per class: {0: np.float64(0.5714285714285714), 4: np.float64(0.900990099009901), 5: np.float64(0.5523255813953488), 6: np.float64(0.4083769633507853), 7: np.float64(0.07317073170731707), 9: np.float64(0.6024096385542169), 10: np.float64(0.5444444444444444), 13: np.float64(0.19047619047619047), 16: np.float64(0.5287356321839081), 17: np.float64(0.09302325581395349), 18: np.float64(0.3971631205673759), 19: np.float64(0.5394736842105263), 21: np.float64(0.13953488372093023), 23: np.float64(0.5833333333333334), 24: np.float64(0.2608695652173913), 26: np.float64(0.6798029556650246), 27: np.float64(0.2857142857142857), 29: np.float64(0.8598130841121495), 31: np.float64(0.05128205128205128), 32: np.float64(0.6940639269406392), 40: np.float64(0.125)}
Micro-average F1 score: 0.5028864656831302
Weighted-average F1 score: 0.46824026128106516
F1 score per class: {0: np.float64(0.6), 4: np.float64(0.9417989417989417), 5: np.float64(0.6397306397306397), 6: np.float64(0.4126984126984127), 7: np.float64(0.07692307692307693), 9: np.float64(0.684931506849315), 10: np.float64(0.45121951219512196), 13: np.float64(0.12121212121212122), 16: np.float64(0.5542168674698795), 17: np.float64(0.12121212121212122), 18: np.float64(0.3888888888888889), 19: np.float64(0.5765124555160143), 21: np.float64(0.1643835616438356), 23: np.float64(0.6021505376344086), 24: np.float64(0.12903225806451613), 26: np.float64(0.6733668341708543), 27: np.float64(0.28169014084507044), 29: np.float64(0.8679245283018868), 31: np.float64(0.06896551724137931), 32: np.float64(0.7149321266968326), 40: np.float64(0.10784313725490197)}
Micro-average F1 score: 0.5213467545990975
Weighted-average F1 score: 0.4872924547591202

F1 score per class: {0: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.7089552238805971), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.2644628099173554), 13: np.float64(0.0), 16: np.float64(0.4782608695652174), 17: np.float64(0.0), 18: np.float64(0.19047619047619047), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.39154929577464787
Weighted-average F1 score: 0.3669648651742608
F1 score per class: {0: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.45023696682464454), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.5104166666666666), 13: np.float64(0.0), 16: np.float64(0.36507936507936506), 17: np.float64(0.15384615384615385), 18: np.float64(0.3181818181818182), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.33877901977644026
Weighted-average F1 score: 0.30870903386825843
F1 score per class: {0: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.5080213903743316), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.4327485380116959), 13: np.float64(0.0), 16: np.float64(0.38333333333333336), 17: np.float64(0.15384615384615385), 18: np.float64(0.28), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.34234234234234234
Weighted-average F1 score: 0.31075849485032075

F1 score per class: {0: np.float64(0.6181818181818182), 4: np.float64(0.8465608465608465), 5: np.float64(0.6506849315068494), 6: np.float64(0.2543859649122807), 7: np.float64(0.043478260869565216), 9: np.float64(0.704225352112676), 10: np.float64(0.21476510067114093), 13: np.float64(0.02631578947368421), 16: np.float64(0.37606837606837606), 17: np.float64(0.0), 18: np.float64(0.17647058823529413), 19: np.float64(0.5917602996254682), 21: np.float64(0.23834196891191708), 23: np.float64(0.5217391304347826), 24: np.float64(0.0), 26: np.float64(0.5929203539823009), 27: np.float64(0.2222222222222222), 29: np.float64(0.7398373983739838), 31: np.float64(0.09523809523809523), 32: np.float64(0.5793103448275863), 40: np.float64(0.13043478260869565)}
Micro-average F1 score: 0.43794271635355714
Weighted-average F1 score: 0.4114087710072504
F1 score per class: {0: np.float64(0.4473684210526316), 4: np.float64(0.8310502283105022), 5: np.float64(0.3392857142857143), 6: np.float64(0.26804123711340205), 7: np.float64(0.0392156862745098), 9: np.float64(0.4424778761061947), 10: np.float64(0.38735177865612647), 13: np.float64(0.125), 16: np.float64(0.2754491017964072), 17: np.float64(0.047058823529411764), 18: np.float64(0.23829787234042554), 19: np.float64(0.45555555555555555), 21: np.float64(0.09448818897637795), 23: np.float64(0.4628099173553719), 24: np.float64(0.15), 26: np.float64(0.5948275862068966), 27: np.float64(0.18018018018018017), 29: np.float64(0.6666666666666666), 31: np.float64(0.02666666666666667), 32: np.float64(0.5049833887043189), 40: np.float64(0.09734513274336283)}
Micro-average F1 score: 0.354510513226317
Weighted-average F1 score: 0.32790448596132127
F1 score per class: {0: np.float64(0.4583333333333333), 4: np.float64(0.8855721393034826), 5: np.float64(0.40860215053763443), 6: np.float64(0.2736842105263158), 7: np.float64(0.041666666666666664), 9: np.float64(0.6172839506172839), 10: np.float64(0.33035714285714285), 13: np.float64(0.07547169811320754), 16: np.float64(0.2911392405063291), 17: np.float64(0.0625), 18: np.float64(0.23333333333333334), 19: np.float64(0.4879518072289157), 21: np.float64(0.10746268656716418), 23: np.float64(0.4745762711864407), 24: np.float64(0.08695652173913043), 26: np.float64(0.5903083700440529), 27: np.float64(0.17857142857142858), 29: np.float64(0.7022900763358778), 31: np.float64(0.0392156862745098), 32: np.float64(0.5180327868852459), 40: np.float64(0.08148148148148149)}
Micro-average F1 score: 0.37578183637728296
Weighted-average F1 score: 0.3470388522485049
cur_acc_wo_na:  ['0.7623', '0.3119', '0.6252', '0.5336']
his_acc_wo_na:  ['0.7623', '0.5095', '0.5627', '0.5641']
cur_acc des_wo_na:  ['0.7569', '0.3763', '0.5475', '0.5282']
his_acc des_wo_na:  ['0.7569', '0.5692', '0.5210', '0.5029']
cur_acc rrf_wo_na:  ['0.7569', '0.3799', '0.5917', '0.5286']
his_acc rrf_wo_na:  ['0.7569', '0.5716', '0.5395', '0.5213']
cur_acc_w_na:  ['0.6192', '0.2822', '0.4709', '0.3915']
his_acc_w_na:  ['0.6192', '0.4185', '0.4372', '0.4379']
cur_acc des_w_na:  ['0.6212', '0.3396', '0.4101', '0.3388']
his_acc des_w_na:  ['0.6212', '0.4723', '0.3946', '0.3545']
cur_acc rrf_w_na:  ['0.6204', '0.3453', '0.4465', '0.3423']
his_acc rrf_w_na:  ['0.6204', '0.4766', '0.4136', '0.3758']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 76.1798058CurrentTrain: epoch  0, batch     1 | loss: 94.4641496CurrentTrain: epoch  0, batch     2 | loss: 96.1562539CurrentTrain: epoch  0, batch     3 | loss: 61.6735630CurrentTrain: epoch  1, batch     0 | loss: 84.0964200CurrentTrain: epoch  1, batch     1 | loss: 89.3429307CurrentTrain: epoch  1, batch     2 | loss: 74.9962165CurrentTrain: epoch  1, batch     3 | loss: 50.7143094CurrentTrain: epoch  2, batch     0 | loss: 71.0234735CurrentTrain: epoch  2, batch     1 | loss: 68.8460618CurrentTrain: epoch  2, batch     2 | loss: 99.2605280CurrentTrain: epoch  2, batch     3 | loss: 120.7372224CurrentTrain: epoch  3, batch     0 | loss: 67.1571152CurrentTrain: epoch  3, batch     1 | loss: 77.9996350CurrentTrain: epoch  3, batch     2 | loss: 72.0068374CurrentTrain: epoch  3, batch     3 | loss: 88.6348412CurrentTrain: epoch  4, batch     0 | loss: 68.7287748CurrentTrain: epoch  4, batch     1 | loss: 82.4721085CurrentTrain: epoch  4, batch     2 | loss: 69.0088645CurrentTrain: epoch  4, batch     3 | loss: 43.7222319CurrentTrain: epoch  5, batch     0 | loss: 66.8682088CurrentTrain: epoch  5, batch     1 | loss: 81.3898555CurrentTrain: epoch  5, batch     2 | loss: 95.1749822CurrentTrain: epoch  5, batch     3 | loss: 52.3405792CurrentTrain: epoch  6, batch     0 | loss: 78.5957308CurrentTrain: epoch  6, batch     1 | loss: 79.2037684CurrentTrain: epoch  6, batch     2 | loss: 64.9982424CurrentTrain: epoch  6, batch     3 | loss: 66.6082653CurrentTrain: epoch  7, batch     0 | loss: 78.0415200CurrentTrain: epoch  7, batch     1 | loss: 94.8320440CurrentTrain: epoch  7, batch     2 | loss: 92.7721113CurrentTrain: epoch  7, batch     3 | loss: 52.2533007CurrentTrain: epoch  8, batch     0 | loss: 62.7053630CurrentTrain: epoch  8, batch     1 | loss: 79.1597407CurrentTrain: epoch  8, batch     2 | loss: 63.6374256CurrentTrain: epoch  8, batch     3 | loss: 66.1681759CurrentTrain: epoch  9, batch     0 | loss: 96.9128242CurrentTrain: epoch  9, batch     1 | loss: 61.8499704CurrentTrain: epoch  9, batch     2 | loss: 65.5719055CurrentTrain: epoch  9, batch     3 | loss: 58.9337772
MemoryTrain:  epoch  0, batch     0 | loss: 0.8060590MemoryTrain:  epoch  1, batch     0 | loss: 0.7656135MemoryTrain:  epoch  2, batch     0 | loss: 0.6118229MemoryTrain:  epoch  3, batch     0 | loss: 0.5134256MemoryTrain:  epoch  4, batch     0 | loss: 0.4722628MemoryTrain:  epoch  5, batch     0 | loss: 0.3702410MemoryTrain:  epoch  6, batch     0 | loss: 0.2877559MemoryTrain:  epoch  7, batch     0 | loss: 0.2535187MemoryTrain:  epoch  8, batch     0 | loss: 0.2095056MemoryTrain:  epoch  9, batch     0 | loss: 0.1986833

F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.6666666666666666), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.44776119402985076), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.7476635514018691), 37: np.float64(0.6722689075630253), 38: np.float64(0.5714285714285714), 40: np.float64(0.0)}
Micro-average F1 score: 0.4978165938864629
Weighted-average F1 score: 0.4030458197218064
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.631578947368421), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.7567567567567568), 37: np.float64(0.6875), 38: np.float64(0.6296296296296297), 40: np.float64(0.0)}
Micro-average F1 score: 0.4721189591078067
Weighted-average F1 score: 0.36857562700917385
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.631578947368421), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5205479452054794), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.7567567567567568), 37: np.float64(0.6376811594202898), 38: np.float64(0.6530612244897959), 40: np.float64(0.0)}
Micro-average F1 score: 0.4875239923224568
Weighted-average F1 score: 0.3921079341565768

F1 score per class: {0: np.float64(0.7096774193548387), 4: np.float64(0.8372093023255814), 5: np.float64(0.7948717948717948), 6: np.float64(0.37209302325581395), 7: np.float64(0.05504587155963303), 9: np.float64(0.7575757575757576), 10: np.float64(0.2585034013605442), 13: np.float64(0.08450704225352113), 15: np.float64(0.2413793103448276), 16: np.float64(0.647887323943662), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5795918367346938), 21: np.float64(0.125), 23: np.float64(0.6582278481012658), 24: np.float64(0.0), 25: np.float64(0.44776119402985076), 26: np.float64(0.6798029556650246), 27: np.float64(0.3157894736842105), 29: np.float64(0.8627450980392157), 31: np.float64(0.2222222222222222), 32: np.float64(0.7549019607843137), 35: np.float64(0.4), 37: np.float64(0.25477707006369427), 38: np.float64(0.3582089552238806), 40: np.float64(0.2391304347826087)}
Micro-average F1 score: 0.47944377267230953
Weighted-average F1 score: 0.4441144557980902
F1 score per class: {0: np.float64(0.5811965811965812), 4: np.float64(0.8865979381443299), 5: np.float64(0.572289156626506), 6: np.float64(0.35964912280701755), 7: np.float64(0.05555555555555555), 9: np.float64(0.5208333333333334), 10: np.float64(0.37362637362637363), 13: np.float64(0.12), 15: np.float64(0.46153846153846156), 16: np.float64(0.5116279069767442), 17: np.float64(0.0), 18: np.float64(0.4117647058823529), 19: np.float64(0.5571428571428572), 21: np.float64(0.17475728155339806), 23: np.float64(0.5773195876288659), 24: np.float64(0.2631578947368421), 25: np.float64(0.5), 26: np.float64(0.663594470046083), 27: np.float64(0.2807017543859649), 29: np.float64(0.861244019138756), 31: np.float64(0.08695652173913043), 32: np.float64(0.748898678414097), 35: np.float64(0.40384615384615385), 37: np.float64(0.26993865030674846), 38: np.float64(0.3655913978494624), 40: np.float64(0.25675675675675674)}
Micro-average F1 score: 0.48038950500405736
Weighted-average F1 score: 0.4522688508226655
F1 score per class: {0: np.float64(0.6601941747572816), 4: np.float64(0.9139784946236559), 5: np.float64(0.643598615916955), 6: np.float64(0.3904761904761905), 7: np.float64(0.05504587155963303), 9: np.float64(0.7142857142857143), 10: np.float64(0.3468208092485549), 13: np.float64(0.1), 15: np.float64(0.34285714285714286), 16: np.float64(0.5789473684210527), 17: np.float64(0.0), 18: np.float64(0.12), 19: np.float64(0.5954198473282443), 21: np.float64(0.1532258064516129), 23: np.float64(0.6172839506172839), 24: np.float64(0.08333333333333333), 25: np.float64(0.5205479452054794), 26: np.float64(0.6666666666666666), 27: np.float64(0.3050847457627119), 29: np.float64(0.861244019138756), 31: np.float64(0.10526315789473684), 32: np.float64(0.7420814479638009), 35: np.float64(0.4077669902912621), 37: np.float64(0.2359249329758713), 38: np.float64(0.37209302325581395), 40: np.float64(0.24539877300613497)}
Micro-average F1 score: 0.4779595231494317
Weighted-average F1 score: 0.4435451077470938

F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.4666666666666667), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.4166666666666667), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.5882352941176471), 37: np.float64(0.5369127516778524), 38: np.float64(0.5217391304347826), 40: np.float64(0.0)}
Micro-average F1 score: 0.3545878693623639
Weighted-average F1 score: 0.28245069211271856
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.5), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.46153846153846156), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6176470588235294), 37: np.float64(0.5641025641025641), 38: np.float64(0.5483870967741935), 40: np.float64(0.0)}
Micro-average F1 score: 0.33731739707835323
Weighted-average F1 score: 0.26141124536987087
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.5), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.4935064935064935), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6086956521739131), 37: np.float64(0.5176470588235295), 38: np.float64(0.5614035087719298), 40: np.float64(0.0)}
Micro-average F1 score: 0.3518005540166205
Weighted-average F1 score: 0.2793014631511842

F1 score per class: {0: np.float64(0.5689655172413793), 4: np.float64(0.7912087912087912), 5: np.float64(0.6019417475728155), 6: np.float64(0.24060150375939848), 7: np.float64(0.03), 9: np.float64(0.6944444444444444), 10: np.float64(0.20540540540540542), 13: np.float64(0.05042016806722689), 15: np.float64(0.12173913043478261), 16: np.float64(0.3709677419354839), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5259259259259259), 21: np.float64(0.08469055374592833), 23: np.float64(0.5777777777777777), 24: np.float64(0.0), 25: np.float64(0.4166666666666667), 26: np.float64(0.5948275862068966), 27: np.float64(0.20930232558139536), 29: np.float64(0.6795366795366795), 31: np.float64(0.15384615384615385), 32: np.float64(0.5833333333333334), 35: np.float64(0.23255813953488372), 37: np.float64(0.1388888888888889), 38: np.float64(0.21428571428571427), 40: np.float64(0.19555555555555557)}
Micro-average F1 score: 0.34203148587448784
Weighted-average F1 score: 0.30770806241017334
F1 score per class: {0: np.float64(0.4594594594594595), 4: np.float64(0.8349514563106796), 5: np.float64(0.3815261044176707), 6: np.float64(0.21808510638297873), 7: np.float64(0.030612244897959183), 9: np.float64(0.3968253968253968), 10: np.float64(0.25), 13: np.float64(0.08333333333333333), 15: np.float64(0.3157894736842105), 16: np.float64(0.28205128205128205), 17: np.float64(0.0), 18: np.float64(0.23529411764705882), 19: np.float64(0.4921135646687697), 21: np.float64(0.12040133779264214), 23: np.float64(0.45901639344262296), 24: np.float64(0.15625), 25: np.float64(0.45), 26: np.float64(0.5454545454545454), 27: np.float64(0.17582417582417584), 29: np.float64(0.6844106463878327), 31: np.float64(0.044444444444444446), 32: np.float64(0.5610561056105611), 35: np.float64(0.24705882352941178), 37: np.float64(0.16666666666666666), 38: np.float64(0.2138364779874214), 40: np.float64(0.21348314606741572)}
Micro-average F1 score: 0.3366824644549763
Weighted-average F1 score: 0.31272938491194807
F1 score per class: {0: np.float64(0.53125), 4: np.float64(0.8629441624365483), 5: np.float64(0.44075829383886256), 6: np.float64(0.23837209302325582), 7: np.float64(0.030303030303030304), 9: np.float64(0.6410256410256411), 10: np.float64(0.24390243902439024), 13: np.float64(0.06896551724137931), 15: np.float64(0.20689655172413793), 16: np.float64(0.3142857142857143), 17: np.float64(0.0), 18: np.float64(0.09836065573770492), 19: np.float64(0.5288135593220339), 21: np.float64(0.10497237569060773), 23: np.float64(0.5208333333333334), 24: np.float64(0.0625), 25: np.float64(0.4935064935064935), 26: np.float64(0.5634920634920635), 27: np.float64(0.1836734693877551), 29: np.float64(0.6792452830188679), 31: np.float64(0.06666666666666667), 32: np.float64(0.5578231292517006), 35: np.float64(0.24778761061946902), 37: np.float64(0.13990461049284578), 38: np.float64(0.2119205298013245), 40: np.float64(0.20512820512820512)}
Micro-average F1 score: 0.3386368100569633
Weighted-average F1 score: 0.3090252746096823
cur_acc_wo_na:  ['0.7623', '0.3119', '0.6252', '0.5336', '0.4978']
his_acc_wo_na:  ['0.7623', '0.5095', '0.5627', '0.5641', '0.4794']
cur_acc des_wo_na:  ['0.7569', '0.3763', '0.5475', '0.5282', '0.4721']
his_acc des_wo_na:  ['0.7569', '0.5692', '0.5210', '0.5029', '0.4804']
cur_acc rrf_wo_na:  ['0.7569', '0.3799', '0.5917', '0.5286', '0.4875']
his_acc rrf_wo_na:  ['0.7569', '0.5716', '0.5395', '0.5213', '0.4780']
cur_acc_w_na:  ['0.6192', '0.2822', '0.4709', '0.3915', '0.3546']
his_acc_w_na:  ['0.6192', '0.4185', '0.4372', '0.4379', '0.3420']
cur_acc des_w_na:  ['0.6212', '0.3396', '0.4101', '0.3388', '0.3373']
his_acc des_w_na:  ['0.6212', '0.4723', '0.3946', '0.3545', '0.3367']
cur_acc rrf_w_na:  ['0.6204', '0.3453', '0.4465', '0.3423', '0.3518']
his_acc rrf_w_na:  ['0.6204', '0.4766', '0.4136', '0.3758', '0.3386']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 148.2217683CurrentTrain: epoch  0, batch     1 | loss: 79.4793016CurrentTrain: epoch  0, batch     2 | loss: 92.7976560CurrentTrain: epoch  0, batch     3 | loss: 112.1599573CurrentTrain: epoch  0, batch     4 | loss: 23.1516717CurrentTrain: epoch  1, batch     0 | loss: 135.4814163CurrentTrain: epoch  1, batch     1 | loss: 101.6895399CurrentTrain: epoch  1, batch     2 | loss: 74.7991023CurrentTrain: epoch  1, batch     3 | loss: 90.0876836CurrentTrain: epoch  1, batch     4 | loss: 29.2042544CurrentTrain: epoch  2, batch     0 | loss: 105.4760095CurrentTrain: epoch  2, batch     1 | loss: 82.9485992CurrentTrain: epoch  2, batch     2 | loss: 129.0285003CurrentTrain: epoch  2, batch     3 | loss: 71.8750327CurrentTrain: epoch  2, batch     4 | loss: 19.0417701CurrentTrain: epoch  3, batch     0 | loss: 83.3398229CurrentTrain: epoch  3, batch     1 | loss: 82.4398543CurrentTrain: epoch  3, batch     2 | loss: 100.2838822CurrentTrain: epoch  3, batch     3 | loss: 68.5492858CurrentTrain: epoch  3, batch     4 | loss: 39.3520446CurrentTrain: epoch  4, batch     0 | loss: 69.4494539CurrentTrain: epoch  4, batch     1 | loss: 98.8464636CurrentTrain: epoch  4, batch     2 | loss: 67.5621219CurrentTrain: epoch  4, batch     3 | loss: 97.9771682CurrentTrain: epoch  4, batch     4 | loss: 26.3561937CurrentTrain: epoch  5, batch     0 | loss: 84.5510279CurrentTrain: epoch  5, batch     1 | loss: 96.8338966CurrentTrain: epoch  5, batch     2 | loss: 78.0111046CurrentTrain: epoch  5, batch     3 | loss: 62.9294401CurrentTrain: epoch  5, batch     4 | loss: 39.6837595CurrentTrain: epoch  6, batch     0 | loss: 94.6638739CurrentTrain: epoch  6, batch     1 | loss: 95.7454607CurrentTrain: epoch  6, batch     2 | loss: 78.0138807CurrentTrain: epoch  6, batch     3 | loss: 77.2505030CurrentTrain: epoch  6, batch     4 | loss: 22.8792422CurrentTrain: epoch  7, batch     0 | loss: 67.4398418CurrentTrain: epoch  7, batch     1 | loss: 79.8686105CurrentTrain: epoch  7, batch     2 | loss: 77.6998301CurrentTrain: epoch  7, batch     3 | loss: 92.9964681CurrentTrain: epoch  7, batch     4 | loss: 23.1702853CurrentTrain: epoch  8, batch     0 | loss: 79.3362847CurrentTrain: epoch  8, batch     1 | loss: 77.0558376CurrentTrain: epoch  8, batch     2 | loss: 76.6568767CurrentTrain: epoch  8, batch     3 | loss: 62.9962365CurrentTrain: epoch  8, batch     4 | loss: 39.4288536CurrentTrain: epoch  9, batch     0 | loss: 76.0343837CurrentTrain: epoch  9, batch     1 | loss: 77.3566769CurrentTrain: epoch  9, batch     2 | loss: 91.7680216CurrentTrain: epoch  9, batch     3 | loss: 76.8246139CurrentTrain: epoch  9, batch     4 | loss: 38.4001620
MemoryTrain:  epoch  0, batch     0 | loss: 0.9333357MemoryTrain:  epoch  1, batch     0 | loss: 0.8750658MemoryTrain:  epoch  2, batch     0 | loss: 0.7086453MemoryTrain:  epoch  3, batch     0 | loss: 0.5750892MemoryTrain:  epoch  4, batch     0 | loss: 0.5023543MemoryTrain:  epoch  5, batch     0 | loss: 0.4375188MemoryTrain:  epoch  6, batch     0 | loss: 0.3740158MemoryTrain:  epoch  7, batch     0 | loss: 0.3706381MemoryTrain:  epoch  8, batch     0 | loss: 0.2814344MemoryTrain:  epoch  9, batch     0 | loss: 0.2999039

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.6666666666666666), 4: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.4460431654676259), 12: np.float64(0.39705882352941174), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.35294117647058826), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.25806451612903225), 40: np.float64(0.0)}
Micro-average F1 score: 0.32751091703056767
Weighted-average F1 score: 0.24521291400977654
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.45161290322580644), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.3548387096774194), 12: np.float64(0.49382716049382713), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.2916666666666667), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.3333333333333333), 40: np.float64(0.0)}
Micro-average F1 score: 0.29411764705882354
Weighted-average F1 score: 0.21023680421529883
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.6363636363636364), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.38095238095238093), 12: np.float64(0.46153846153846156), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.2727272727272727), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.27586206896551724), 40: np.float64(0.0)}
Micro-average F1 score: 0.3073852295409182
Weighted-average F1 score: 0.22181271080757506

F1 score per class: {0: np.float64(0.7209302325581395), 2: np.float64(0.30434782608695654), 4: np.float64(0.7904191616766467), 5: np.float64(0.8516746411483254), 6: np.float64(0.2676056338028169), 7: np.float64(0.07228915662650602), 9: np.float64(0.746268656716418), 10: np.float64(0.15789473684210525), 11: np.float64(0.23220973782771537), 12: np.float64(0.3016759776536313), 13: np.float64(0.05333333333333334), 15: np.float64(0.34146341463414637), 16: np.float64(0.6129032258064516), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5887096774193549), 21: np.float64(0.18705035971223022), 23: np.float64(0.6666666666666666), 24: np.float64(0.09090909090909091), 25: np.float64(0.4), 26: np.float64(0.7015706806282722), 27: np.float64(0.25), 28: np.float64(0.12244897959183673), 29: np.float64(0.8426395939086294), 31: np.float64(0.0), 32: np.float64(0.7735849056603774), 35: np.float64(0.4246575342465753), 37: np.float64(0.288), 38: np.float64(0.18461538461538463), 39: np.float64(0.07476635514018691), 40: np.float64(0.2823529411764706)}
Micro-average F1 score: 0.4503007734173589
Weighted-average F1 score: 0.42439028346241414
F1 score per class: {0: np.float64(0.5), 2: np.float64(0.13333333333333333), 4: np.float64(0.8279569892473119), 5: np.float64(0.6834532374100719), 6: np.float64(0.35944700460829493), 7: np.float64(0.056074766355140186), 9: np.float64(0.5263157894736842), 10: np.float64(0.31645569620253167), 11: np.float64(0.21674876847290642), 12: np.float64(0.26578073089701), 13: np.float64(0.06451612903225806), 15: np.float64(0.4), 16: np.float64(0.5714285714285714), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5605536332179931), 21: np.float64(0.1978021978021978), 23: np.float64(0.6526315789473685), 24: np.float64(0.1935483870967742), 25: np.float64(0.5789473684210527), 26: np.float64(0.6859903381642513), 27: np.float64(0.34615384615384615), 28: np.float64(0.11864406779661017), 29: np.float64(0.8307692307692308), 31: np.float64(0.08695652173913043), 32: np.float64(0.7044534412955465), 35: np.float64(0.4), 37: np.float64(0.21666666666666667), 38: np.float64(0.3076923076923077), 39: np.float64(0.09523809523809523), 40: np.float64(0.23943661971830985)}
Micro-average F1 score: 0.43440444551824114
Weighted-average F1 score: 0.41090771744639326
F1 score per class: {0: np.float64(0.6938775510204082), 2: np.float64(0.23728813559322035), 4: np.float64(0.847457627118644), 5: np.float64(0.7265625), 6: np.float64(0.38202247191011235), 7: np.float64(0.06382978723404255), 9: np.float64(0.746268656716418), 10: np.float64(0.2556390977443609), 11: np.float64(0.22641509433962265), 12: np.float64(0.28125), 13: np.float64(0.10810810810810811), 15: np.float64(0.3684210526315789), 16: np.float64(0.6285714285714286), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5808823529411765), 21: np.float64(0.18627450980392157), 23: np.float64(0.6666666666666666), 24: np.float64(0.08333333333333333), 25: np.float64(0.5753424657534246), 26: np.float64(0.693069306930693), 27: np.float64(0.36), 28: np.float64(0.10619469026548672), 29: np.float64(0.8307692307692308), 31: np.float64(0.1), 32: np.float64(0.723404255319149), 35: np.float64(0.44324324324324327), 37: np.float64(0.23529411764705882), 38: np.float64(0.23376623376623376), 39: np.float64(0.0761904761904762), 40: np.float64(0.22929936305732485)}
Micro-average F1 score: 0.44992215879605607
Weighted-average F1 score: 0.4237528003638686

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.4375), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.36257309941520466), 12: np.float64(0.34615384615384615), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.1875), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.14035087719298245), 40: np.float64(0.0)}
Micro-average F1 score: 0.23148148148148148
Weighted-average F1 score: 0.17733279803117857
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.2692307692307692), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.2913907284768212), 12: np.float64(0.41450777202072536), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.14583333333333334), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.1702127659574468), 40: np.float64(0.0)}
Micro-average F1 score: 0.19950124688279303
Weighted-average F1 score: 0.1491151224336524
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.34146341463414637), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.3137254901960784), 12: np.float64(0.3956043956043956), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.13793103448275862), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.13114754098360656), 40: np.float64(0.0)}
Micro-average F1 score: 0.2098092643051771
Weighted-average F1 score: 0.15693016062323428

F1 score per class: {0: np.float64(0.5740740740740741), 2: np.float64(0.208955223880597), 4: np.float64(0.7415730337078652), 5: np.float64(0.726530612244898), 6: np.float64(0.17117117117117117), 7: np.float64(0.04285714285714286), 9: np.float64(0.684931506849315), 10: np.float64(0.144), 11: np.float64(0.15736040609137056), 12: np.float64(0.16927899686520376), 13: np.float64(0.036036036036036036), 15: np.float64(0.2222222222222222), 16: np.float64(0.37254901960784315), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5468164794007491), 21: np.float64(0.12380952380952381), 23: np.float64(0.5909090909090909), 24: np.float64(0.07407407407407407), 25: np.float64(0.38235294117647056), 26: np.float64(0.6203703703703703), 27: np.float64(0.18181818181818182), 28: np.float64(0.06060606060606061), 29: np.float64(0.6916666666666667), 31: np.float64(0.0), 32: np.float64(0.5963636363636363), 35: np.float64(0.2719298245614035), 37: np.float64(0.21176470588235294), 38: np.float64(0.12), 39: np.float64(0.041237113402061855), 40: np.float64(0.23880597014925373)}
Micro-average F1 score: 0.3317155518041781
Weighted-average F1 score: 0.30091728277939944
F1 score per class: {0: np.float64(0.3783783783783784), 2: np.float64(0.08536585365853659), 4: np.float64(0.7777777777777778), 5: np.float64(0.5013192612137203), 6: np.float64(0.2125340599455041), 7: np.float64(0.03225806451612903), 9: np.float64(0.4), 10: np.float64(0.24752475247524752), 11: np.float64(0.1437908496732026), 12: np.float64(0.145985401459854), 13: np.float64(0.05128205128205128), 15: np.float64(0.2553191489361702), 16: np.float64(0.3116883116883117), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5225806451612903), 21: np.float64(0.13740458015267176), 23: np.float64(0.5299145299145299), 24: np.float64(0.11764705882352941), 25: np.float64(0.5569620253164557), 26: np.float64(0.5941422594142259), 27: np.float64(0.225), 28: np.float64(0.0625), 29: np.float64(0.680672268907563), 31: np.float64(0.045454545454545456), 32: np.float64(0.5225225225225225), 35: np.float64(0.2551928783382789), 37: np.float64(0.1793103448275862), 38: np.float64(0.21428571428571427), 39: np.float64(0.05128205128205128), 40: np.float64(0.2)}
Micro-average F1 score: 0.3066689408152823
Weighted-average F1 score: 0.28261834615974474
F1 score per class: {0: np.float64(0.5528455284552846), 2: np.float64(0.13592233009708737), 4: np.float64(0.7978723404255319), 5: np.float64(0.5552238805970149), 6: np.float64(0.2361111111111111), 7: np.float64(0.03592814371257485), 9: np.float64(0.6578947368421053), 10: np.float64(0.2138364779874214), 11: np.float64(0.15047021943573669), 12: np.float64(0.1522198731501057), 13: np.float64(0.08), 15: np.float64(0.21875), 16: np.float64(0.3492063492063492), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5429553264604811), 21: np.float64(0.12666666666666668), 23: np.float64(0.5833333333333334), 24: np.float64(0.0625), 25: np.float64(0.5526315789473685), 26: np.float64(0.6008583690987125), 27: np.float64(0.22784810126582278), 28: np.float64(0.05429864253393665), 29: np.float64(0.680672268907563), 31: np.float64(0.05555555555555555), 32: np.float64(0.5345911949685535), 35: np.float64(0.281786941580756), 37: np.float64(0.19393939393939394), 38: np.float64(0.16666666666666666), 39: np.float64(0.041025641025641026), 40: np.float64(0.1935483870967742)}
Micro-average F1 score: 0.32128960533629797
Weighted-average F1 score: 0.29310855856472195
cur_acc_wo_na:  ['0.7623', '0.3119', '0.6252', '0.5336', '0.4978', '0.3275']
his_acc_wo_na:  ['0.7623', '0.5095', '0.5627', '0.5641', '0.4794', '0.4503']
cur_acc des_wo_na:  ['0.7569', '0.3763', '0.5475', '0.5282', '0.4721', '0.2941']
his_acc des_wo_na:  ['0.7569', '0.5692', '0.5210', '0.5029', '0.4804', '0.4344']
cur_acc rrf_wo_na:  ['0.7569', '0.3799', '0.5917', '0.5286', '0.4875', '0.3074']
his_acc rrf_wo_na:  ['0.7569', '0.5716', '0.5395', '0.5213', '0.4780', '0.4499']
cur_acc_w_na:  ['0.6192', '0.2822', '0.4709', '0.3915', '0.3546', '0.2315']
his_acc_w_na:  ['0.6192', '0.4185', '0.4372', '0.4379', '0.3420', '0.3317']
cur_acc des_w_na:  ['0.6212', '0.3396', '0.4101', '0.3388', '0.3373', '0.1995']
his_acc des_w_na:  ['0.6212', '0.4723', '0.3946', '0.3545', '0.3367', '0.3067']
cur_acc rrf_w_na:  ['0.6204', '0.3453', '0.4465', '0.3423', '0.3518', '0.2098']
his_acc rrf_w_na:  ['0.6204', '0.4766', '0.4136', '0.3758', '0.3386', '0.3213']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 95.9301469CurrentTrain: epoch  0, batch     1 | loss: 97.7569454CurrentTrain: epoch  0, batch     2 | loss: 205.1502426CurrentTrain: epoch  0, batch     3 | loss: 90.9719507CurrentTrain: epoch  0, batch     4 | loss: 81.2376805CurrentTrain: epoch  1, batch     0 | loss: 75.9208248CurrentTrain: epoch  1, batch     1 | loss: 97.7599807CurrentTrain: epoch  1, batch     2 | loss: 106.3468332CurrentTrain: epoch  1, batch     3 | loss: 107.6076948CurrentTrain: epoch  1, batch     4 | loss: 52.1675896CurrentTrain: epoch  2, batch     0 | loss: 106.8681088CurrentTrain: epoch  2, batch     1 | loss: 74.0340425CurrentTrain: epoch  2, batch     2 | loss: 71.6577182CurrentTrain: epoch  2, batch     3 | loss: 89.1550256CurrentTrain: epoch  2, batch     4 | loss: 61.1006517CurrentTrain: epoch  3, batch     0 | loss: 109.1764037CurrentTrain: epoch  3, batch     1 | loss: 85.8081908CurrentTrain: epoch  3, batch     2 | loss: 97.7917552CurrentTrain: epoch  3, batch     3 | loss: 101.8913978CurrentTrain: epoch  3, batch     4 | loss: 99.2941173CurrentTrain: epoch  4, batch     0 | loss: 99.9916027CurrentTrain: epoch  4, batch     1 | loss: 125.2815718CurrentTrain: epoch  4, batch     2 | loss: 82.7228090CurrentTrain: epoch  4, batch     3 | loss: 71.2733679CurrentTrain: epoch  4, batch     4 | loss: 55.7983517CurrentTrain: epoch  5, batch     0 | loss: 80.1680421CurrentTrain: epoch  5, batch     1 | loss: 79.0600340CurrentTrain: epoch  5, batch     2 | loss: 82.7954489CurrentTrain: epoch  5, batch     3 | loss: 124.9600159CurrentTrain: epoch  5, batch     4 | loss: 56.4712075CurrentTrain: epoch  6, batch     0 | loss: 81.2948292CurrentTrain: epoch  6, batch     1 | loss: 97.6572785CurrentTrain: epoch  6, batch     2 | loss: 166.5856107CurrentTrain: epoch  6, batch     3 | loss: 68.4829680CurrentTrain: epoch  6, batch     4 | loss: 49.6708500CurrentTrain: epoch  7, batch     0 | loss: 77.9407373CurrentTrain: epoch  7, batch     1 | loss: 96.0039904CurrentTrain: epoch  7, batch     2 | loss: 97.7855612CurrentTrain: epoch  7, batch     3 | loss: 80.9249202CurrentTrain: epoch  7, batch     4 | loss: 54.8539091CurrentTrain: epoch  8, batch     0 | loss: 94.8979993CurrentTrain: epoch  8, batch     1 | loss: 68.1583276CurrentTrain: epoch  8, batch     2 | loss: 96.4266303CurrentTrain: epoch  8, batch     3 | loss: 93.9195553CurrentTrain: epoch  8, batch     4 | loss: 66.8944582CurrentTrain: epoch  9, batch     0 | loss: 79.6083805CurrentTrain: epoch  9, batch     1 | loss: 78.8969571CurrentTrain: epoch  9, batch     2 | loss: 96.5929221CurrentTrain: epoch  9, batch     3 | loss: 78.0148585CurrentTrain: epoch  9, batch     4 | loss: 41.7232222
MemoryTrain:  epoch  0, batch     0 | loss: 1.3259663MemoryTrain:  epoch  1, batch     0 | loss: 1.1019394MemoryTrain:  epoch  2, batch     0 | loss: 0.8607323MemoryTrain:  epoch  3, batch     0 | loss: 0.7089290MemoryTrain:  epoch  4, batch     0 | loss: 0.6503856MemoryTrain:  epoch  5, batch     0 | loss: 0.5296645MemoryTrain:  epoch  6, batch     0 | loss: 0.4404580MemoryTrain:  epoch  7, batch     0 | loss: 0.3883421MemoryTrain:  epoch  8, batch     0 | loss: 0.3426082MemoryTrain:  epoch  9, batch     0 | loss: 0.2878314

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.2222222222222222), 2: np.float64(0.0), 3: np.float64(0.5100671140939598), 6: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.08823529411764706), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5441696113074205), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6881720430107527), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.34647302904564314
Weighted-average F1 score: 0.29735862662623186
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.2658959537572254), 2: np.float64(0.0), 3: np.float64(0.5517241379310345), 5: np.float64(0.0), 6: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.08791208791208792), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5736434108527132), 23: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.7627118644067796), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.34245366284201234
Weighted-average F1 score: 0.2864495641090425
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.23170731707317074), 2: np.float64(0.0), 3: np.float64(0.5393258426966292), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.04819277108433735), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5818181818181818), 23: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.7222222222222222), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.34686346863468637
Weighted-average F1 score: 0.2978247864188766

F1 score per class: {0: np.float64(0.7435897435897436), 1: np.float64(0.17346938775510204), 2: np.float64(0.3333333333333333), 3: np.float64(0.29343629343629346), 4: np.float64(0.7904191616766467), 5: np.float64(0.8558139534883721), 6: np.float64(0.3253012048192771), 7: np.float64(0.0547945205479452), 9: np.float64(0.7692307692307693), 10: np.float64(0.18803418803418803), 11: np.float64(0.2079207920792079), 12: np.float64(0.18604651162790697), 13: np.float64(0.125), 14: np.float64(0.0759493670886076), 15: np.float64(0.4444444444444444), 16: np.float64(0.6415094339622641), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5415162454873647), 21: np.float64(0.064), 22: np.float64(0.41847826086956524), 23: np.float64(0.675), 24: np.float64(0.0), 25: np.float64(0.4), 26: np.float64(0.6896551724137931), 27: np.float64(0.0), 28: np.float64(0.12244897959183673), 29: np.float64(0.8040201005025126), 31: np.float64(0.0), 32: np.float64(0.6565656565656566), 34: np.float64(0.29357798165137616), 35: np.float64(0.2097902097902098), 37: np.float64(0.21505376344086022), 38: np.float64(0.20253164556962025), 39: np.float64(0.07692307692307693), 40: np.float64(0.25477707006369427)}
Micro-average F1 score: 0.39659803043867503
Weighted-average F1 score: 0.3792404179420327
F1 score per class: {0: np.float64(0.528), 1: np.float64(0.19008264462809918), 2: np.float64(0.175), 3: np.float64(0.3076923076923077), 4: np.float64(0.8228571428571428), 5: np.float64(0.6666666666666666), 6: np.float64(0.3448275862068966), 7: np.float64(0.08), 9: np.float64(0.4854368932038835), 10: np.float64(0.2876712328767123), 11: np.float64(0.15625), 12: np.float64(0.28187919463087246), 13: np.float64(0.1509433962264151), 14: np.float64(0.05673758865248227), 15: np.float64(0.5), 16: np.float64(0.6571428571428571), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5234899328859061), 21: np.float64(0.03418803418803419), 22: np.float64(0.46984126984126984), 23: np.float64(0.6346153846153846), 24: np.float64(0.09523809523809523), 25: np.float64(0.48), 26: np.float64(0.6857142857142857), 27: np.float64(0.0), 28: np.float64(0.12727272727272726), 29: np.float64(0.7789473684210526), 31: np.float64(0.0), 32: np.float64(0.6039215686274509), 34: np.float64(0.24456521739130435), 35: np.float64(0.15028901734104047), 37: np.float64(0.08771929824561403), 38: np.float64(0.25688073394495414), 39: np.float64(0.11428571428571428), 40: np.float64(0.23225806451612904)}
Micro-average F1 score: 0.37424471299093653
Weighted-average F1 score: 0.3569487411968192
F1 score per class: {0: np.float64(0.6947368421052632), 1: np.float64(0.17272727272727273), 2: np.float64(0.22950819672131148), 3: np.float64(0.2981366459627329), 4: np.float64(0.8095238095238095), 5: np.float64(0.7755102040816326), 6: np.float64(0.35294117647058826), 7: np.float64(0.08450704225352113), 9: np.float64(0.746268656716418), 10: np.float64(0.24817518248175183), 11: np.float64(0.17218543046357615), 12: np.float64(0.2992125984251969), 13: np.float64(0.12903225806451613), 14: np.float64(0.03571428571428571), 15: np.float64(0.46153846153846156), 16: np.float64(0.6551724137931034), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.531986531986532), 21: np.float64(0.061068702290076333), 22: np.float64(0.4481792717086835), 23: np.float64(0.6373626373626373), 24: np.float64(0.0), 25: np.float64(0.45714285714285713), 26: np.float64(0.6796116504854369), 27: np.float64(0.0), 28: np.float64(0.12612612612612611), 29: np.float64(0.7853403141361257), 31: np.float64(0.0), 32: np.float64(0.6153846153846154), 34: np.float64(0.23636363636363636), 35: np.float64(0.1610738255033557), 37: np.float64(0.09090909090909091), 38: np.float64(0.26262626262626265), 39: np.float64(0.09302325581395349), 40: np.float64(0.21686746987951808)}
Micro-average F1 score: 0.38163672654690617
Weighted-average F1 score: 0.36190631923191036

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.12142857142857143), 2: np.float64(0.0), 3: np.float64(0.36893203883495146), 5: np.float64(0.0), 6: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.08571428571428572), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.4095744680851064), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6153846153846154), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2348804500703235
Weighted-average F1 score: 0.20230475375692925
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.14556962025316456), 2: np.float64(0.0), 3: np.float64(0.3855421686746988), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.08), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.4457831325301205), 23: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6206896551724138), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2255813953488372
Weighted-average F1 score: 0.1933945058751203
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.12666666666666668), 2: np.float64(0.0), 3: np.float64(0.3794466403162055), 5: np.float64(0.0), 6: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0449438202247191), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.44321329639889195), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.22926829268292684
Weighted-average F1 score: 0.1998490328966199

F1 score per class: {0: np.float64(0.5523809523809524), 1: np.float64(0.09115281501340483), 2: np.float64(0.208955223880597), 3: np.float64(0.18673218673218672), 4: np.float64(0.75), 5: np.float64(0.696969696969697), 6: np.float64(0.1978021978021978), 7: np.float64(0.031496062992125984), 9: np.float64(0.6944444444444444), 10: np.float64(0.16541353383458646), 11: np.float64(0.13548387096774195), 12: np.float64(0.10996563573883161), 13: np.float64(0.07017543859649122), 14: np.float64(0.06741573033707865), 15: np.float64(0.2857142857142857), 16: np.float64(0.44155844155844154), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5), 21: np.float64(0.04878048780487805), 22: np.float64(0.28413284132841327), 23: np.float64(0.5625), 24: np.float64(0.0), 25: np.float64(0.38235294117647056), 26: np.float64(0.603448275862069), 27: np.float64(0.0), 28: np.float64(0.06030150753768844), 29: np.float64(0.6611570247933884), 31: np.float64(0.0), 32: np.float64(0.48872180451127817), 34: np.float64(0.2119205298013245), 35: np.float64(0.14563106796116504), 37: np.float64(0.14492753623188406), 38: np.float64(0.13445378151260504), 39: np.float64(0.041666666666666664), 40: np.float64(0.21739130434782608)}
Micro-average F1 score: 0.2827960421321417
Weighted-average F1 score: 0.26025227533327455
F1 score per class: {0: np.float64(0.3815028901734104), 1: np.float64(0.1010989010989011), 2: np.float64(0.11570247933884298), 3: np.float64(0.1935483870967742), 4: np.float64(0.7741935483870968), 5: np.float64(0.47619047619047616), 6: np.float64(0.19950124688279303), 7: np.float64(0.043478260869565216), 9: np.float64(0.33557046979865773), 10: np.float64(0.23204419889502761), 11: np.float64(0.11560693641618497), 12: np.float64(0.14814814814814814), 13: np.float64(0.0898876404494382), 14: np.float64(0.04419889502762431), 15: np.float64(0.35294117647058826), 16: np.float64(0.4), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.48297213622291024), 21: np.float64(0.029411764705882353), 22: np.float64(0.32456140350877194), 23: np.float64(0.4782608695652174), 24: np.float64(0.08695652173913043), 25: np.float64(0.45569620253164556), 26: np.float64(0.5925925925925926), 27: np.float64(0.0), 28: np.float64(0.06829268292682927), 29: np.float64(0.6636771300448431), 31: np.float64(0.0), 32: np.float64(0.42777777777777776), 34: np.float64(0.15873015873015872), 35: np.float64(0.10038610038610038), 37: np.float64(0.07092198581560284), 38: np.float64(0.16279069767441862), 39: np.float64(0.061068702290076333), 40: np.float64(0.1956521739130435)}
Micro-average F1 score: 0.25814014066163066
Weighted-average F1 score: 0.24028039829932094
F1 score per class: {0: np.float64(0.5076923076923077), 1: np.float64(0.09047619047619047), 2: np.float64(0.14432989690721648), 3: np.float64(0.1889763779527559), 4: np.float64(0.768361581920904), 5: np.float64(0.581039755351682), 6: np.float64(0.2099125364431487), 7: np.float64(0.043795620437956206), 9: np.float64(0.6410256410256411), 10: np.float64(0.2125), 11: np.float64(0.11926605504587157), 12: np.float64(0.15932914046121593), 13: np.float64(0.07547169811320754), 14: np.float64(0.029197080291970802), 15: np.float64(0.27906976744186046), 16: np.float64(0.3917525773195876), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.4906832298136646), 21: np.float64(0.047619047619047616), 22: np.float64(0.3076923076923077), 23: np.float64(0.5321100917431193), 24: np.float64(0.0), 25: np.float64(0.43243243243243246), 26: np.float64(0.5882352941176471), 27: np.float64(0.0), 28: np.float64(0.06896551724137931), 29: np.float64(0.6696428571428571), 31: np.float64(0.0), 32: np.float64(0.43636363636363634), 34: np.float64(0.15384615384615385), 35: np.float64(0.10344827586206896), 37: np.float64(0.07246376811594203), 38: np.float64(0.17105263157894737), 39: np.float64(0.049689440993788817), 40: np.float64(0.18274111675126903)}
Micro-average F1 score: 0.2652976273067851
Weighted-average F1 score: 0.24462587139515846
cur_acc_wo_na:  ['0.7623', '0.3119', '0.6252', '0.5336', '0.4978', '0.3275', '0.3465']
his_acc_wo_na:  ['0.7623', '0.5095', '0.5627', '0.5641', '0.4794', '0.4503', '0.3966']
cur_acc des_wo_na:  ['0.7569', '0.3763', '0.5475', '0.5282', '0.4721', '0.2941', '0.3425']
his_acc des_wo_na:  ['0.7569', '0.5692', '0.5210', '0.5029', '0.4804', '0.4344', '0.3742']
cur_acc rrf_wo_na:  ['0.7569', '0.3799', '0.5917', '0.5286', '0.4875', '0.3074', '0.3469']
his_acc rrf_wo_na:  ['0.7569', '0.5716', '0.5395', '0.5213', '0.4780', '0.4499', '0.3816']
cur_acc_w_na:  ['0.6192', '0.2822', '0.4709', '0.3915', '0.3546', '0.2315', '0.2349']
his_acc_w_na:  ['0.6192', '0.4185', '0.4372', '0.4379', '0.3420', '0.3317', '0.2828']
cur_acc des_w_na:  ['0.6212', '0.3396', '0.4101', '0.3388', '0.3373', '0.1995', '0.2256']
his_acc des_w_na:  ['0.6212', '0.4723', '0.3946', '0.3545', '0.3367', '0.3067', '0.2581']
cur_acc rrf_w_na:  ['0.6204', '0.3453', '0.4465', '0.3423', '0.3518', '0.2098', '0.2293']
his_acc rrf_w_na:  ['0.6204', '0.4766', '0.4136', '0.3758', '0.3386', '0.3213', '0.2653']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 94.9269511CurrentTrain: epoch  0, batch     1 | loss: 85.2605311CurrentTrain: epoch  0, batch     2 | loss: 84.0361927CurrentTrain: epoch  0, batch     3 | loss: 57.9860324CurrentTrain: epoch  1, batch     0 | loss: 86.5850610CurrentTrain: epoch  1, batch     1 | loss: 86.6419541CurrentTrain: epoch  1, batch     2 | loss: 107.3681510CurrentTrain: epoch  1, batch     3 | loss: 55.0365870CurrentTrain: epoch  2, batch     0 | loss: 85.7314360CurrentTrain: epoch  2, batch     1 | loss: 81.3208278CurrentTrain: epoch  2, batch     2 | loss: 102.1283075CurrentTrain: epoch  2, batch     3 | loss: 49.2518034CurrentTrain: epoch  3, batch     0 | loss: 66.7229036CurrentTrain: epoch  3, batch     1 | loss: 70.6794960CurrentTrain: epoch  3, batch     2 | loss: 128.3212017CurrentTrain: epoch  3, batch     3 | loss: 48.6139516CurrentTrain: epoch  4, batch     0 | loss: 83.4436126CurrentTrain: epoch  4, batch     1 | loss: 78.6638453CurrentTrain: epoch  4, batch     2 | loss: 65.9324443CurrentTrain: epoch  4, batch     3 | loss: 58.6250083CurrentTrain: epoch  5, batch     0 | loss: 77.1438626CurrentTrain: epoch  5, batch     1 | loss: 81.0346802CurrentTrain: epoch  5, batch     2 | loss: 62.0588124CurrentTrain: epoch  5, batch     3 | loss: 62.4521761CurrentTrain: epoch  6, batch     0 | loss: 64.5959327CurrentTrain: epoch  6, batch     1 | loss: 95.3331030CurrentTrain: epoch  6, batch     2 | loss: 67.5925805CurrentTrain: epoch  6, batch     3 | loss: 46.3590465CurrentTrain: epoch  7, batch     0 | loss: 61.3070068CurrentTrain: epoch  7, batch     1 | loss: 92.3768361CurrentTrain: epoch  7, batch     2 | loss: 94.1100096CurrentTrain: epoch  7, batch     3 | loss: 57.6089116CurrentTrain: epoch  8, batch     0 | loss: 77.2618212CurrentTrain: epoch  8, batch     1 | loss: 94.1973144CurrentTrain: epoch  8, batch     2 | loss: 59.7428488CurrentTrain: epoch  8, batch     3 | loss: 72.4554761CurrentTrain: epoch  9, batch     0 | loss: 77.0258198CurrentTrain: epoch  9, batch     1 | loss: 71.7845517CurrentTrain: epoch  9, batch     2 | loss: 71.8421715CurrentTrain: epoch  9, batch     3 | loss: 103.1268135
MemoryTrain:  epoch  0, batch     0 | loss: 0.7712471MemoryTrain:  epoch  1, batch     0 | loss: 0.6997617MemoryTrain:  epoch  2, batch     0 | loss: 0.5600537MemoryTrain:  epoch  3, batch     0 | loss: 0.4503108MemoryTrain:  epoch  4, batch     0 | loss: 0.3850611MemoryTrain:  epoch  5, batch     0 | loss: 0.3244641MemoryTrain:  epoch  6, batch     0 | loss: 0.3280484MemoryTrain:  epoch  7, batch     0 | loss: 0.2773894MemoryTrain:  epoch  8, batch     0 | loss: 0.2336606MemoryTrain:  epoch  9, batch     0 | loss: 0.1939374

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.6285714285714286), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.8947368421052632), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8333333333333334), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.4), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.43010752688172044), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5155038759689923
Weighted-average F1 score: 0.4145596305421165
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.6099290780141844), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.7884615384615384), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.85), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.4), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.6518518518518519), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.48925619834710743
Weighted-average F1 score: 0.37552566679600474
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.6153846153846154), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.7884615384615384), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8421052631578947), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.26666666666666666), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.6218487394957983), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.48951048951048953
Weighted-average F1 score: 0.37419816110518195

F1 score per class: {0: np.float64(0.5862068965517241), 1: np.float64(0.19305019305019305), 2: np.float64(0.4375), 3: np.float64(0.3206751054852321), 4: np.float64(0.8187134502923976), 5: np.float64(0.8493150684931506), 6: np.float64(0.3023255813953488), 7: np.float64(0.028985507246376812), 8: np.float64(0.277602523659306), 9: np.float64(0.7352941176470589), 10: np.float64(0.057692307692307696), 11: np.float64(0.19730941704035873), 12: np.float64(0.16049382716049382), 13: np.float64(0.08888888888888889), 14: np.float64(0.06593406593406594), 15: np.float64(0.375), 16: np.float64(0.5925925925925926), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.49504950495049505), 20: np.float64(0.4473684210526316), 21: np.float64(0.0784313725490196), 22: np.float64(0.44785276073619634), 23: np.float64(0.6506024096385542), 24: np.float64(0.0), 25: np.float64(0.3225806451612903), 26: np.float64(0.6896551724137931), 27: np.float64(0.0), 28: np.float64(0.25), 29: np.float64(0.7722772277227723), 30: np.float64(0.8333333333333334), 31: np.float64(0.05714285714285714), 32: np.float64(0.592274678111588), 33: np.float64(0.13043478260869565), 34: np.float64(0.28776978417266186), 35: np.float64(0.20689655172413793), 36: np.float64(0.31746031746031744), 37: np.float64(0.34408602150537637), 38: np.float64(0.32142857142857145), 39: np.float64(0.058823529411764705), 40: np.float64(0.2011173184357542)}
Micro-average F1 score: 0.3869980879541109
Weighted-average F1 score: 0.3780715220226792
F1 score per class: {0: np.float64(0.41975308641975306), 1: np.float64(0.16083916083916083), 2: np.float64(0.1346153846153846), 3: np.float64(0.24793388429752067), 4: np.float64(0.8314606741573034), 5: np.float64(0.60625), 6: np.float64(0.31746031746031744), 7: np.float64(0.08333333333333333), 8: np.float64(0.2747603833865815), 9: np.float64(0.5), 10: np.float64(0.1951219512195122), 11: np.float64(0.16129032258064516), 12: np.float64(0.2332155477031802), 13: np.float64(0.125), 14: np.float64(0.06299212598425197), 15: np.float64(0.5217391304347826), 16: np.float64(0.6197183098591549), 17: np.float64(0.0), 18: np.float64(0.08), 19: np.float64(0.46321525885558584), 20: np.float64(0.543046357615894), 21: np.float64(0.047619047619047616), 22: np.float64(0.3826530612244898), 23: np.float64(0.5825242718446602), 24: np.float64(0.0), 25: np.float64(0.5), 26: np.float64(0.6605504587155964), 27: np.float64(0.0), 28: np.float64(0.21052631578947367), 29: np.float64(0.7738693467336684), 30: np.float64(0.44155844155844154), 31: np.float64(0.029411764705882353), 32: np.float64(0.5670498084291188), 33: np.float64(0.11538461538461539), 34: np.float64(0.2838283828382838), 35: np.float64(0.20717131474103587), 36: np.float64(0.34375), 37: np.float64(0.11009174311926606), 38: np.float64(0.32098765432098764), 39: np.float64(0.10909090909090909), 40: np.float64(0.1527777777777778)}
Micro-average F1 score: 0.35905767668562144
Weighted-average F1 score: 0.34952786173359557
F1 score per class: {0: np.float64(0.4563758389261745), 1: np.float64(0.18248175182481752), 2: np.float64(0.22950819672131148), 3: np.float64(0.23622047244094488), 4: np.float64(0.8571428571428571), 5: np.float64(0.7032967032967034), 6: np.float64(0.31693989071038253), 7: np.float64(0.08571428571428572), 8: np.float64(0.27414330218068533), 9: np.float64(0.684931506849315), 10: np.float64(0.1415929203539823), 11: np.float64(0.16901408450704225), 12: np.float64(0.25203252032520324), 13: np.float64(0.125), 14: np.float64(0.0625), 15: np.float64(0.42857142857142855), 16: np.float64(0.6129032258064516), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.4853801169590643), 20: np.float64(0.47953216374269003), 21: np.float64(0.05714285714285714), 22: np.float64(0.4297520661157025), 23: np.float64(0.6666666666666666), 24: np.float64(0.0), 25: np.float64(0.4411764705882353), 26: np.float64(0.6542056074766355), 27: np.float64(0.0), 28: np.float64(0.18181818181818182), 29: np.float64(0.78), 30: np.float64(0.5614035087719298), 31: np.float64(0.038461538461538464), 32: np.float64(0.5577689243027888), 33: np.float64(0.07547169811320754), 34: np.float64(0.2857142857142857), 35: np.float64(0.20353982300884957), 36: np.float64(0.3474178403755869), 37: np.float64(0.12280701754385964), 38: np.float64(0.3055555555555556), 39: np.float64(0.11538461538461539), 40: np.float64(0.13333333333333333)}
Micro-average F1 score: 0.36871123363197794
Weighted-average F1 score: 0.359247749588007

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.4971751412429379), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.6415094339622641), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7894736842105263), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.375), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.3305785123966942), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3468057366362451
Weighted-average F1 score: 0.28011963117010813
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.4942528735632184), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.6029411764705882), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7906976744186046), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.375), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.5), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.32456140350877194
Weighted-average F1 score: 0.2514808192335008
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.49162011173184356), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5942028985507246), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7804878048780488), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.25), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.46540880503144655), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.32825322391559203
Weighted-average F1 score: 0.25690605305984426

F1 score per class: {0: np.float64(0.4358974358974359), 1: np.float64(0.10416666666666667), 2: np.float64(0.25925925925925924), 3: np.float64(0.1953727506426735), 4: np.float64(0.7692307692307693), 5: np.float64(0.6813186813186813), 6: np.float64(0.18374558303886926), 7: np.float64(0.01639344262295082), 8: np.float64(0.15970961887477314), 9: np.float64(0.6493506493506493), 10: np.float64(0.05555555555555555), 11: np.float64(0.1456953642384106), 12: np.float64(0.09961685823754789), 13: np.float64(0.05333333333333334), 14: np.float64(0.05714285714285714), 15: np.float64(0.2222222222222222), 16: np.float64(0.4266666666666667), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.4437869822485207), 20: np.float64(0.21935483870967742), 21: np.float64(0.06217616580310881), 22: np.float64(0.31877729257641924), 23: np.float64(0.5806451612903226), 24: np.float64(0.0), 25: np.float64(0.3125), 26: np.float64(0.5907172995780591), 27: np.float64(0.0), 28: np.float64(0.13114754098360656), 29: np.float64(0.6290322580645161), 30: np.float64(0.7142857142857143), 31: np.float64(0.03225806451612903), 32: np.float64(0.42990654205607476), 33: np.float64(0.08955223880597014), 34: np.float64(0.2094240837696335), 35: np.float64(0.13846153846153847), 36: np.float64(0.20725388601036268), 37: np.float64(0.2711864406779661), 38: np.float64(0.1956521739130435), 39: np.float64(0.034482758620689655), 40: np.float64(0.16071428571428573)}
Micro-average F1 score: 0.27047975410931446
Weighted-average F1 score: 0.2545809993622454
F1 score per class: {0: np.float64(0.3022222222222222), 1: np.float64(0.08630393996247655), 2: np.float64(0.09395973154362416), 3: np.float64(0.15748031496062992), 4: np.float64(0.7914438502673797), 5: np.float64(0.39591836734693875), 6: np.float64(0.18867924528301888), 7: np.float64(0.045454545454545456), 8: np.float64(0.15955473098330242), 9: np.float64(0.36764705882352944), 10: np.float64(0.17142857142857143), 11: np.float64(0.15625), 12: np.float64(0.12267657992565056), 13: np.float64(0.06896551724137931), 14: np.float64(0.052980132450331126), 15: np.float64(0.4), 16: np.float64(0.37606837606837606), 17: np.float64(0.0), 18: np.float64(0.06451612903225806), 19: np.float64(0.4146341463414634), 20: np.float64(0.2837370242214533), 21: np.float64(0.041666666666666664), 22: np.float64(0.26881720430107525), 23: np.float64(0.425531914893617), 24: np.float64(0.0), 25: np.float64(0.475), 26: np.float64(0.555984555984556), 27: np.float64(0.0), 28: np.float64(0.13043478260869565), 29: np.float64(0.6497890295358649), 30: np.float64(0.34), 31: np.float64(0.017699115044247787), 32: np.float64(0.4134078212290503), 33: np.float64(0.07228915662650602), 34: np.float64(0.172), 35: np.float64(0.1309823677581864), 36: np.float64(0.22278481012658227), 37: np.float64(0.08391608391608392), 38: np.float64(0.19696969696969696), 39: np.float64(0.06060606060606061), 40: np.float64(0.125)}
Micro-average F1 score: 0.2447668623324842
Weighted-average F1 score: 0.23249379581766402
F1 score per class: {0: np.float64(0.3300970873786408), 1: np.float64(0.09784735812133072), 2: np.float64(0.14432989690721648), 3: np.float64(0.15228426395939088), 4: np.float64(0.8152173913043478), 5: np.float64(0.5065963060686016), 6: np.float64(0.1870967741935484), 7: np.float64(0.047244094488188976), 8: np.float64(0.15855855855855855), 9: np.float64(0.5617977528089888), 10: np.float64(0.12903225806451613), 11: np.float64(0.1437125748502994), 12: np.float64(0.13191489361702127), 13: np.float64(0.06896551724137931), 14: np.float64(0.052980132450331126), 15: np.float64(0.2727272727272727), 16: np.float64(0.38), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.43116883116883115), 20: np.float64(0.25386996904024767), 21: np.float64(0.049586776859504134), 22: np.float64(0.2899628252788104), 23: np.float64(0.5504587155963303), 24: np.float64(0.0), 25: np.float64(0.4166666666666667), 26: np.float64(0.5555555555555556), 27: np.float64(0.0), 28: np.float64(0.1111111111111111), 29: np.float64(0.6554621848739496), 30: np.float64(0.4444444444444444), 31: np.float64(0.02197802197802198), 32: np.float64(0.4034582132564842), 33: np.float64(0.047058823529411764), 34: np.float64(0.18947368421052632), 35: np.float64(0.13031161473087818), 36: np.float64(0.23125), 37: np.float64(0.0945945945945946), 38: np.float64(0.17886178861788618), 39: np.float64(0.07407407407407407), 40: np.float64(0.11)}
Micro-average F1 score: 0.25370480142264373
Weighted-average F1 score: 0.24027386704106024
cur_acc_wo_na:  ['0.7623', '0.3119', '0.6252', '0.5336', '0.4978', '0.3275', '0.3465', '0.5155']
his_acc_wo_na:  ['0.7623', '0.5095', '0.5627', '0.5641', '0.4794', '0.4503', '0.3966', '0.3870']
cur_acc des_wo_na:  ['0.7569', '0.3763', '0.5475', '0.5282', '0.4721', '0.2941', '0.3425', '0.4893']
his_acc des_wo_na:  ['0.7569', '0.5692', '0.5210', '0.5029', '0.4804', '0.4344', '0.3742', '0.3591']
cur_acc rrf_wo_na:  ['0.7569', '0.3799', '0.5917', '0.5286', '0.4875', '0.3074', '0.3469', '0.4895']
his_acc rrf_wo_na:  ['0.7569', '0.5716', '0.5395', '0.5213', '0.4780', '0.4499', '0.3816', '0.3687']
cur_acc_w_na:  ['0.6192', '0.2822', '0.4709', '0.3915', '0.3546', '0.2315', '0.2349', '0.3468']
his_acc_w_na:  ['0.6192', '0.4185', '0.4372', '0.4379', '0.3420', '0.3317', '0.2828', '0.2705']
cur_acc des_w_na:  ['0.6212', '0.3396', '0.4101', '0.3388', '0.3373', '0.1995', '0.2256', '0.3246']
his_acc des_w_na:  ['0.6212', '0.4723', '0.3946', '0.3545', '0.3367', '0.3067', '0.2581', '0.2448']
cur_acc rrf_w_na:  ['0.6204', '0.3453', '0.4465', '0.3423', '0.3518', '0.2098', '0.2293', '0.3283']
his_acc rrf_w_na:  ['0.6204', '0.4766', '0.4136', '0.3758', '0.3386', '0.3213', '0.2653', '0.2537']
--------Round  4
seed:  500
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 5 6 4 2 1 3 0]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 128.5957515CurrentTrain: epoch  0, batch     1 | loss: 81.1061273CurrentTrain: epoch  0, batch     2 | loss: 122.6673997CurrentTrain: epoch  0, batch     3 | loss: 101.5094963CurrentTrain: epoch  0, batch     4 | loss: 101.2465668CurrentTrain: epoch  0, batch     5 | loss: 87.2371363CurrentTrain: epoch  0, batch     6 | loss: 118.5034698CurrentTrain: epoch  0, batch     7 | loss: 99.9375571CurrentTrain: epoch  0, batch     8 | loss: 146.7485509CurrentTrain: epoch  0, batch     9 | loss: 100.1369365CurrentTrain: epoch  0, batch    10 | loss: 118.0586945CurrentTrain: epoch  0, batch    11 | loss: 118.6537816CurrentTrain: epoch  0, batch    12 | loss: 100.5065029CurrentTrain: epoch  0, batch    13 | loss: 119.3034641CurrentTrain: epoch  0, batch    14 | loss: 99.9371605CurrentTrain: epoch  0, batch    15 | loss: 192.8493944CurrentTrain: epoch  0, batch    16 | loss: 118.8880254CurrentTrain: epoch  0, batch    17 | loss: 118.2655134CurrentTrain: epoch  0, batch    18 | loss: 117.6319162CurrentTrain: epoch  0, batch    19 | loss: 99.5577795CurrentTrain: epoch  0, batch    20 | loss: 86.5459397CurrentTrain: epoch  0, batch    21 | loss: 87.5489414CurrentTrain: epoch  0, batch    22 | loss: 99.0582159CurrentTrain: epoch  0, batch    23 | loss: 98.4303701CurrentTrain: epoch  0, batch    24 | loss: 85.2954262CurrentTrain: epoch  0, batch    25 | loss: 116.7952007CurrentTrain: epoch  0, batch    26 | loss: 98.2672903CurrentTrain: epoch  0, batch    27 | loss: 75.9294346CurrentTrain: epoch  0, batch    28 | loss: 117.6486611CurrentTrain: epoch  0, batch    29 | loss: 85.5170540CurrentTrain: epoch  0, batch    30 | loss: 117.2767527CurrentTrain: epoch  0, batch    31 | loss: 84.8510291CurrentTrain: epoch  0, batch    32 | loss: 74.9021276CurrentTrain: epoch  0, batch    33 | loss: 191.3920540CurrentTrain: epoch  0, batch    34 | loss: 84.0210334CurrentTrain: epoch  0, batch    35 | loss: 85.2829436CurrentTrain: epoch  0, batch    36 | loss: 116.7911202CurrentTrain: epoch  0, batch    37 | loss: 74.6431758CurrentTrain: epoch  0, batch    38 | loss: 96.2826127CurrentTrain: epoch  0, batch    39 | loss: 96.7836048CurrentTrain: epoch  0, batch    40 | loss: 97.3341083CurrentTrain: epoch  0, batch    41 | loss: 73.7195572CurrentTrain: epoch  0, batch    42 | loss: 190.2322667CurrentTrain: epoch  0, batch    43 | loss: 73.6614997CurrentTrain: epoch  0, batch    44 | loss: 115.1039617CurrentTrain: epoch  0, batch    45 | loss: 82.2421807CurrentTrain: epoch  0, batch    46 | loss: 96.6747077CurrentTrain: epoch  0, batch    47 | loss: 114.9526676CurrentTrain: epoch  0, batch    48 | loss: 82.9243595CurrentTrain: epoch  0, batch    49 | loss: 95.5564505CurrentTrain: epoch  0, batch    50 | loss: 94.7368178CurrentTrain: epoch  0, batch    51 | loss: 115.4177689CurrentTrain: epoch  0, batch    52 | loss: 82.9030239CurrentTrain: epoch  0, batch    53 | loss: 83.3459701CurrentTrain: epoch  0, batch    54 | loss: 97.3042326CurrentTrain: epoch  0, batch    55 | loss: 81.4522479CurrentTrain: epoch  0, batch    56 | loss: 81.5102470CurrentTrain: epoch  0, batch    57 | loss: 111.0403335CurrentTrain: epoch  0, batch    58 | loss: 112.5133405CurrentTrain: epoch  0, batch    59 | loss: 142.6869510CurrentTrain: epoch  0, batch    60 | loss: 93.4189479CurrentTrain: epoch  0, batch    61 | loss: 94.4025366CurrentTrain: epoch  0, batch    62 | loss: 93.3553498CurrentTrain: epoch  0, batch    63 | loss: 78.7496559CurrentTrain: epoch  0, batch    64 | loss: 95.1705869CurrentTrain: epoch  0, batch    65 | loss: 90.2014940CurrentTrain: epoch  0, batch    66 | loss: 80.9206625CurrentTrain: epoch  0, batch    67 | loss: 70.3252250CurrentTrain: epoch  0, batch    68 | loss: 78.5670064CurrentTrain: epoch  0, batch    69 | loss: 96.9289506CurrentTrain: epoch  0, batch    70 | loss: 112.8771165CurrentTrain: epoch  0, batch    71 | loss: 112.2472362CurrentTrain: epoch  0, batch    72 | loss: 76.6453557CurrentTrain: epoch  0, batch    73 | loss: 106.7124998CurrentTrain: epoch  0, batch    74 | loss: 75.3268139CurrentTrain: epoch  0, batch    75 | loss: 94.3784542CurrentTrain: epoch  0, batch    76 | loss: 141.2199426CurrentTrain: epoch  0, batch    77 | loss: 186.6789238CurrentTrain: epoch  0, batch    78 | loss: 79.8456033CurrentTrain: epoch  0, batch    79 | loss: 80.2955635CurrentTrain: epoch  0, batch    80 | loss: 138.5439237CurrentTrain: epoch  0, batch    81 | loss: 81.5055785CurrentTrain: epoch  0, batch    82 | loss: 143.0148837CurrentTrain: epoch  0, batch    83 | loss: 186.8480604CurrentTrain: epoch  0, batch    84 | loss: 82.5439356CurrentTrain: epoch  0, batch    85 | loss: 68.2358936CurrentTrain: epoch  0, batch    86 | loss: 89.6607193CurrentTrain: epoch  0, batch    87 | loss: 67.1352387CurrentTrain: epoch  0, batch    88 | loss: 113.8511087CurrentTrain: epoch  0, batch    89 | loss: 78.1940557CurrentTrain: epoch  0, batch    90 | loss: 91.8595478CurrentTrain: epoch  0, batch    91 | loss: 111.1729877CurrentTrain: epoch  0, batch    92 | loss: 93.9463719CurrentTrain: epoch  0, batch    93 | loss: 112.9087699CurrentTrain: epoch  0, batch    94 | loss: 87.2881491CurrentTrain: epoch  0, batch    95 | loss: 76.5006955CurrentTrain: epoch  1, batch     0 | loss: 81.3211249CurrentTrain: epoch  1, batch     1 | loss: 90.9928834CurrentTrain: epoch  1, batch     2 | loss: 68.9224531CurrentTrain: epoch  1, batch     3 | loss: 139.1124235CurrentTrain: epoch  1, batch     4 | loss: 110.7015274CurrentTrain: epoch  1, batch     5 | loss: 91.1032625CurrentTrain: epoch  1, batch     6 | loss: 138.2667221CurrentTrain: epoch  1, batch     7 | loss: 74.9475990CurrentTrain: epoch  1, batch     8 | loss: 89.6870009CurrentTrain: epoch  1, batch     9 | loss: 90.9704163CurrentTrain: epoch  1, batch    10 | loss: 87.5328859CurrentTrain: epoch  1, batch    11 | loss: 90.1060535CurrentTrain: epoch  1, batch    12 | loss: 184.6051168CurrentTrain: epoch  1, batch    13 | loss: 78.9361893CurrentTrain: epoch  1, batch    14 | loss: 73.8408909CurrentTrain: epoch  1, batch    15 | loss: 91.6990458CurrentTrain: epoch  1, batch    16 | loss: 66.6470601CurrentTrain: epoch  1, batch    17 | loss: 78.1688196CurrentTrain: epoch  1, batch    18 | loss: 62.6712599CurrentTrain: epoch  1, batch    19 | loss: 108.9212524CurrentTrain: epoch  1, batch    20 | loss: 84.8083481CurrentTrain: epoch  1, batch    21 | loss: 91.5761351CurrentTrain: epoch  1, batch    22 | loss: 74.4831963CurrentTrain: epoch  1, batch    23 | loss: 109.6384741CurrentTrain: epoch  1, batch    24 | loss: 93.0620890CurrentTrain: epoch  1, batch    25 | loss: 102.9688295CurrentTrain: epoch  1, batch    26 | loss: 101.7261186CurrentTrain: epoch  1, batch    27 | loss: 89.6643961CurrentTrain: epoch  1, batch    28 | loss: 90.7256814CurrentTrain: epoch  1, batch    29 | loss: 89.6367982CurrentTrain: epoch  1, batch    30 | loss: 88.3322523CurrentTrain: epoch  1, batch    31 | loss: 106.9875006CurrentTrain: epoch  1, batch    32 | loss: 75.8302078CurrentTrain: epoch  1, batch    33 | loss: 106.0823776CurrentTrain: epoch  1, batch    34 | loss: 88.1840656CurrentTrain: epoch  1, batch    35 | loss: 87.2865194CurrentTrain: epoch  1, batch    36 | loss: 78.6966829CurrentTrain: epoch  1, batch    37 | loss: 85.4937868CurrentTrain: epoch  1, batch    38 | loss: 66.5678180CurrentTrain: epoch  1, batch    39 | loss: 108.6873574CurrentTrain: epoch  1, batch    40 | loss: 106.6751984CurrentTrain: epoch  1, batch    41 | loss: 107.0173982CurrentTrain: epoch  1, batch    42 | loss: 89.1859652CurrentTrain: epoch  1, batch    43 | loss: 86.8229561CurrentTrain: epoch  1, batch    44 | loss: 90.5591318CurrentTrain: epoch  1, batch    45 | loss: 134.7510691CurrentTrain: epoch  1, batch    46 | loss: 82.9703640CurrentTrain: epoch  1, batch    47 | loss: 103.0681249CurrentTrain: epoch  1, batch    48 | loss: 108.1607370CurrentTrain: epoch  1, batch    49 | loss: 108.3154141CurrentTrain: epoch  1, batch    50 | loss: 78.6054954CurrentTrain: epoch  1, batch    51 | loss: 111.5308645CurrentTrain: epoch  1, batch    52 | loss: 86.9943033CurrentTrain: epoch  1, batch    53 | loss: 92.1376524CurrentTrain: epoch  1, batch    54 | loss: 140.3851295CurrentTrain: epoch  1, batch    55 | loss: 83.6118051CurrentTrain: epoch  1, batch    56 | loss: 71.1942144CurrentTrain: epoch  1, batch    57 | loss: 106.8270309CurrentTrain: epoch  1, batch    58 | loss: 88.1872765CurrentTrain: epoch  1, batch    59 | loss: 85.3796500CurrentTrain: epoch  1, batch    60 | loss: 71.2244771CurrentTrain: epoch  1, batch    61 | loss: 89.9009950CurrentTrain: epoch  1, batch    62 | loss: 104.0157098CurrentTrain: epoch  1, batch    63 | loss: 86.2284646CurrentTrain: epoch  1, batch    64 | loss: 86.7228691CurrentTrain: epoch  1, batch    65 | loss: 77.3807134CurrentTrain: epoch  1, batch    66 | loss: 88.8900272CurrentTrain: epoch  1, batch    67 | loss: 74.6443336CurrentTrain: epoch  1, batch    68 | loss: 76.1545540CurrentTrain: epoch  1, batch    69 | loss: 107.3270938CurrentTrain: epoch  1, batch    70 | loss: 105.3868740CurrentTrain: epoch  1, batch    71 | loss: 74.9443950CurrentTrain: epoch  1, batch    72 | loss: 182.1889438CurrentTrain: epoch  1, batch    73 | loss: 64.8620674CurrentTrain: epoch  1, batch    74 | loss: 75.9312606CurrentTrain: epoch  1, batch    75 | loss: 106.9843287CurrentTrain: epoch  1, batch    76 | loss: 107.2322476CurrentTrain: epoch  1, batch    77 | loss: 106.6404947CurrentTrain: epoch  1, batch    78 | loss: 104.4753191CurrentTrain: epoch  1, batch    79 | loss: 73.8139816CurrentTrain: epoch  1, batch    80 | loss: 91.1681252CurrentTrain: epoch  1, batch    81 | loss: 63.8881551CurrentTrain: epoch  1, batch    82 | loss: 77.7560244CurrentTrain: epoch  1, batch    83 | loss: 74.1085706CurrentTrain: epoch  1, batch    84 | loss: 83.6662791CurrentTrain: epoch  1, batch    85 | loss: 107.2562610CurrentTrain: epoch  1, batch    86 | loss: 92.1849264CurrentTrain: epoch  1, batch    87 | loss: 90.1098969CurrentTrain: epoch  1, batch    88 | loss: 109.3806552CurrentTrain: epoch  1, batch    89 | loss: 182.8234873CurrentTrain: epoch  1, batch    90 | loss: 87.3022300CurrentTrain: epoch  1, batch    91 | loss: 138.6688723CurrentTrain: epoch  1, batch    92 | loss: 109.3704963CurrentTrain: epoch  1, batch    93 | loss: 72.2681455CurrentTrain: epoch  1, batch    94 | loss: 104.2666290CurrentTrain: epoch  1, batch    95 | loss: 74.9208036CurrentTrain: epoch  2, batch     0 | loss: 105.4992178CurrentTrain: epoch  2, batch     1 | loss: 130.5117066CurrentTrain: epoch  2, batch     2 | loss: 87.6977448CurrentTrain: epoch  2, batch     3 | loss: 110.3586045CurrentTrain: epoch  2, batch     4 | loss: 86.8421261CurrentTrain: epoch  2, batch     5 | loss: 90.9133931CurrentTrain: epoch  2, batch     6 | loss: 86.7723954CurrentTrain: epoch  2, batch     7 | loss: 88.1337571CurrentTrain: epoch  2, batch     8 | loss: 87.3237012CurrentTrain: epoch  2, batch     9 | loss: 69.4669864CurrentTrain: epoch  2, batch    10 | loss: 102.7336767CurrentTrain: epoch  2, batch    11 | loss: 65.2313589CurrentTrain: epoch  2, batch    12 | loss: 134.5477882CurrentTrain: epoch  2, batch    13 | loss: 72.3037839CurrentTrain: epoch  2, batch    14 | loss: 72.3885355CurrentTrain: epoch  2, batch    15 | loss: 71.7298065CurrentTrain: epoch  2, batch    16 | loss: 105.0754048CurrentTrain: epoch  2, batch    17 | loss: 88.1840199CurrentTrain: epoch  2, batch    18 | loss: 107.3638443CurrentTrain: epoch  2, batch    19 | loss: 84.9681996CurrentTrain: epoch  2, batch    20 | loss: 104.5519861CurrentTrain: epoch  2, batch    21 | loss: 87.4278451CurrentTrain: epoch  2, batch    22 | loss: 138.8366555CurrentTrain: epoch  2, batch    23 | loss: 102.4705479CurrentTrain: epoch  2, batch    24 | loss: 88.7908291CurrentTrain: epoch  2, batch    25 | loss: 104.7380520CurrentTrain: epoch  2, batch    26 | loss: 105.7676115CurrentTrain: epoch  2, batch    27 | loss: 89.3493186CurrentTrain: epoch  2, batch    28 | loss: 92.4603041CurrentTrain: epoch  2, batch    29 | loss: 108.2536341CurrentTrain: epoch  2, batch    30 | loss: 73.4968398CurrentTrain: epoch  2, batch    31 | loss: 77.4475625CurrentTrain: epoch  2, batch    32 | loss: 86.5727620CurrentTrain: epoch  2, batch    33 | loss: 75.0829598CurrentTrain: epoch  2, batch    34 | loss: 88.8201707CurrentTrain: epoch  2, batch    35 | loss: 105.4558246CurrentTrain: epoch  2, batch    36 | loss: 84.1110746CurrentTrain: epoch  2, batch    37 | loss: 70.8340257CurrentTrain: epoch  2, batch    38 | loss: 64.1765807CurrentTrain: epoch  2, batch    39 | loss: 71.6654155CurrentTrain: epoch  2, batch    40 | loss: 84.7964740CurrentTrain: epoch  2, batch    41 | loss: 87.1003901CurrentTrain: epoch  2, batch    42 | loss: 85.8782590CurrentTrain: epoch  2, batch    43 | loss: 86.9491517CurrentTrain: epoch  2, batch    44 | loss: 88.1719751CurrentTrain: epoch  2, batch    45 | loss: 85.0142721CurrentTrain: epoch  2, batch    46 | loss: 84.2222239CurrentTrain: epoch  2, batch    47 | loss: 131.4900670CurrentTrain: epoch  2, batch    48 | loss: 133.6839232CurrentTrain: epoch  2, batch    49 | loss: 68.0677881CurrentTrain: epoch  2, batch    50 | loss: 62.6621753CurrentTrain: epoch  2, batch    51 | loss: 73.1037742CurrentTrain: epoch  2, batch    52 | loss: 72.8471112CurrentTrain: epoch  2, batch    53 | loss: 69.6377055CurrentTrain: epoch  2, batch    54 | loss: 82.8639683CurrentTrain: epoch  2, batch    55 | loss: 102.9745191CurrentTrain: epoch  2, batch    56 | loss: 71.9102571CurrentTrain: epoch  2, batch    57 | loss: 102.9494259CurrentTrain: epoch  2, batch    58 | loss: 132.6698755CurrentTrain: epoch  2, batch    59 | loss: 71.1309875CurrentTrain: epoch  2, batch    60 | loss: 88.6423068CurrentTrain: epoch  2, batch    61 | loss: 88.4172398CurrentTrain: epoch  2, batch    62 | loss: 72.0672770CurrentTrain: epoch  2, batch    63 | loss: 75.2449468CurrentTrain: epoch  2, batch    64 | loss: 79.9544629CurrentTrain: epoch  2, batch    65 | loss: 60.1638769CurrentTrain: epoch  2, batch    66 | loss: 103.8717937CurrentTrain: epoch  2, batch    67 | loss: 71.5560499CurrentTrain: epoch  2, batch    68 | loss: 88.3867194CurrentTrain: epoch  2, batch    69 | loss: 87.4911095CurrentTrain: epoch  2, batch    70 | loss: 91.1387259CurrentTrain: epoch  2, batch    71 | loss: 129.2721380CurrentTrain: epoch  2, batch    72 | loss: 60.6829348CurrentTrain: epoch  2, batch    73 | loss: 104.0414087CurrentTrain: epoch  2, batch    74 | loss: 61.3437028CurrentTrain: epoch  2, batch    75 | loss: 86.0110048CurrentTrain: epoch  2, batch    76 | loss: 69.1417542CurrentTrain: epoch  2, batch    77 | loss: 64.8812680CurrentTrain: epoch  2, batch    78 | loss: 133.4075407CurrentTrain: epoch  2, batch    79 | loss: 104.7051225CurrentTrain: epoch  2, batch    80 | loss: 63.8921884CurrentTrain: epoch  2, batch    81 | loss: 77.5835074CurrentTrain: epoch  2, batch    82 | loss: 63.5188060CurrentTrain: epoch  2, batch    83 | loss: 85.1746231CurrentTrain: epoch  2, batch    84 | loss: 103.8576373CurrentTrain: epoch  2, batch    85 | loss: 70.2220150CurrentTrain: epoch  2, batch    86 | loss: 64.8906509CurrentTrain: epoch  2, batch    87 | loss: 84.0368711CurrentTrain: epoch  2, batch    88 | loss: 136.2518070CurrentTrain: epoch  2, batch    89 | loss: 74.4464972CurrentTrain: epoch  2, batch    90 | loss: 105.2298108CurrentTrain: epoch  2, batch    91 | loss: 107.7800455CurrentTrain: epoch  2, batch    92 | loss: 83.0005083CurrentTrain: epoch  2, batch    93 | loss: 88.7555584CurrentTrain: epoch  2, batch    94 | loss: 106.2537280CurrentTrain: epoch  2, batch    95 | loss: 72.4256391CurrentTrain: epoch  3, batch     0 | loss: 104.4382717CurrentTrain: epoch  3, batch     1 | loss: 82.7832859CurrentTrain: epoch  3, batch     2 | loss: 84.7780538CurrentTrain: epoch  3, batch     3 | loss: 73.4690229CurrentTrain: epoch  3, batch     4 | loss: 72.5157029CurrentTrain: epoch  3, batch     5 | loss: 82.7424606CurrentTrain: epoch  3, batch     6 | loss: 86.9995215CurrentTrain: epoch  3, batch     7 | loss: 125.4291285CurrentTrain: epoch  3, batch     8 | loss: 60.0231032CurrentTrain: epoch  3, batch     9 | loss: 106.4617855CurrentTrain: epoch  3, batch    10 | loss: 77.0438736CurrentTrain: epoch  3, batch    11 | loss: 69.0342554CurrentTrain: epoch  3, batch    12 | loss: 127.0532665CurrentTrain: epoch  3, batch    13 | loss: 72.0688460CurrentTrain: epoch  3, batch    14 | loss: 175.7022404CurrentTrain: epoch  3, batch    15 | loss: 131.9726476CurrentTrain: epoch  3, batch    16 | loss: 100.4850310CurrentTrain: epoch  3, batch    17 | loss: 85.5447327CurrentTrain: epoch  3, batch    18 | loss: 69.0032314CurrentTrain: epoch  3, batch    19 | loss: 71.8092486CurrentTrain: epoch  3, batch    20 | loss: 125.9774105CurrentTrain: epoch  3, batch    21 | loss: 69.3212256CurrentTrain: epoch  3, batch    22 | loss: 70.5419017CurrentTrain: epoch  3, batch    23 | loss: 73.7630931CurrentTrain: epoch  3, batch    24 | loss: 83.7172503CurrentTrain: epoch  3, batch    25 | loss: 88.8158002CurrentTrain: epoch  3, batch    26 | loss: 65.3071276CurrentTrain: epoch  3, batch    27 | loss: 65.8307044CurrentTrain: epoch  3, batch    28 | loss: 85.5942348CurrentTrain: epoch  3, batch    29 | loss: 67.6734738CurrentTrain: epoch  3, batch    30 | loss: 72.2356745CurrentTrain: epoch  3, batch    31 | loss: 83.4658357CurrentTrain: epoch  3, batch    32 | loss: 86.4324734CurrentTrain: epoch  3, batch    33 | loss: 80.8691275CurrentTrain: epoch  3, batch    34 | loss: 85.2836027CurrentTrain: epoch  3, batch    35 | loss: 83.0632504CurrentTrain: epoch  3, batch    36 | loss: 81.6102698CurrentTrain: epoch  3, batch    37 | loss: 102.0785762CurrentTrain: epoch  3, batch    38 | loss: 111.6024987CurrentTrain: epoch  3, batch    39 | loss: 86.4223357CurrentTrain: epoch  3, batch    40 | loss: 62.5753996CurrentTrain: epoch  3, batch    41 | loss: 103.1444316CurrentTrain: epoch  3, batch    42 | loss: 88.8725702CurrentTrain: epoch  3, batch    43 | loss: 72.2837808CurrentTrain: epoch  3, batch    44 | loss: 86.4414973CurrentTrain: epoch  3, batch    45 | loss: 85.8058660CurrentTrain: epoch  3, batch    46 | loss: 72.7558804CurrentTrain: epoch  3, batch    47 | loss: 80.8374951CurrentTrain: epoch  3, batch    48 | loss: 66.3626302CurrentTrain: epoch  3, batch    49 | loss: 75.6092325CurrentTrain: epoch  3, batch    50 | loss: 70.0353469CurrentTrain: epoch  3, batch    51 | loss: 80.4706959CurrentTrain: epoch  3, batch    52 | loss: 86.8142714CurrentTrain: epoch  3, batch    53 | loss: 82.7633445CurrentTrain: epoch  3, batch    54 | loss: 73.7683340CurrentTrain: epoch  3, batch    55 | loss: 135.2799475CurrentTrain: epoch  3, batch    56 | loss: 81.3562646CurrentTrain: epoch  3, batch    57 | loss: 98.2676479CurrentTrain: epoch  3, batch    58 | loss: 60.6746688CurrentTrain: epoch  3, batch    59 | loss: 100.9413983CurrentTrain: epoch  3, batch    60 | loss: 84.4205442CurrentTrain: epoch  3, batch    61 | loss: 84.3947021CurrentTrain: epoch  3, batch    62 | loss: 183.0755422CurrentTrain: epoch  3, batch    63 | loss: 84.9630846CurrentTrain: epoch  3, batch    64 | loss: 83.5829031CurrentTrain: epoch  3, batch    65 | loss: 105.6217519CurrentTrain: epoch  3, batch    66 | loss: 78.5353046CurrentTrain: epoch  3, batch    67 | loss: 68.3119384CurrentTrain: epoch  3, batch    68 | loss: 72.3911793CurrentTrain: epoch  3, batch    69 | loss: 71.7362306CurrentTrain: epoch  3, batch    70 | loss: 57.8784389CurrentTrain: epoch  3, batch    71 | loss: 79.8878391CurrentTrain: epoch  3, batch    72 | loss: 78.5278508CurrentTrain: epoch  3, batch    73 | loss: 86.4365596CurrentTrain: epoch  3, batch    74 | loss: 107.7952192CurrentTrain: epoch  3, batch    75 | loss: 84.6913969CurrentTrain: epoch  3, batch    76 | loss: 87.0720007CurrentTrain: epoch  3, batch    77 | loss: 87.0344212CurrentTrain: epoch  3, batch    78 | loss: 73.0383166CurrentTrain: epoch  3, batch    79 | loss: 103.8222957CurrentTrain: epoch  3, batch    80 | loss: 71.2579888CurrentTrain: epoch  3, batch    81 | loss: 100.1269266CurrentTrain: epoch  3, batch    82 | loss: 101.7762677CurrentTrain: epoch  3, batch    83 | loss: 64.6332415CurrentTrain: epoch  3, batch    84 | loss: 88.2285470CurrentTrain: epoch  3, batch    85 | loss: 128.7877197CurrentTrain: epoch  3, batch    86 | loss: 72.4785099CurrentTrain: epoch  3, batch    87 | loss: 101.5093850CurrentTrain: epoch  3, batch    88 | loss: 105.3356070CurrentTrain: epoch  3, batch    89 | loss: 80.4009357CurrentTrain: epoch  3, batch    90 | loss: 80.9838707CurrentTrain: epoch  3, batch    91 | loss: 85.1759693CurrentTrain: epoch  3, batch    92 | loss: 102.6664943CurrentTrain: epoch  3, batch    93 | loss: 74.7487324CurrentTrain: epoch  3, batch    94 | loss: 68.5068155CurrentTrain: epoch  3, batch    95 | loss: 75.8740692CurrentTrain: epoch  4, batch     0 | loss: 82.2927767CurrentTrain: epoch  4, batch     1 | loss: 61.7777727CurrentTrain: epoch  4, batch     2 | loss: 66.2259117CurrentTrain: epoch  4, batch     3 | loss: 169.1196966CurrentTrain: epoch  4, batch     4 | loss: 98.0453041CurrentTrain: epoch  4, batch     5 | loss: 76.8295832CurrentTrain: epoch  4, batch     6 | loss: 73.8226333CurrentTrain: epoch  4, batch     7 | loss: 80.4292159CurrentTrain: epoch  4, batch     8 | loss: 98.4028298CurrentTrain: epoch  4, batch     9 | loss: 70.9209518CurrentTrain: epoch  4, batch    10 | loss: 102.1685485CurrentTrain: epoch  4, batch    11 | loss: 71.0988011CurrentTrain: epoch  4, batch    12 | loss: 83.7712453CurrentTrain: epoch  4, batch    13 | loss: 70.2882065CurrentTrain: epoch  4, batch    14 | loss: 100.1824049CurrentTrain: epoch  4, batch    15 | loss: 104.4549581CurrentTrain: epoch  4, batch    16 | loss: 132.7029439CurrentTrain: epoch  4, batch    17 | loss: 125.0392623CurrentTrain: epoch  4, batch    18 | loss: 84.1688770CurrentTrain: epoch  4, batch    19 | loss: 69.4996882CurrentTrain: epoch  4, batch    20 | loss: 69.2277263CurrentTrain: epoch  4, batch    21 | loss: 126.9310444CurrentTrain: epoch  4, batch    22 | loss: 104.4212709CurrentTrain: epoch  4, batch    23 | loss: 81.2300720CurrentTrain: epoch  4, batch    24 | loss: 101.0441028CurrentTrain: epoch  4, batch    25 | loss: 66.0652303CurrentTrain: epoch  4, batch    26 | loss: 85.9372531CurrentTrain: epoch  4, batch    27 | loss: 100.7194212CurrentTrain: epoch  4, batch    28 | loss: 125.5908983CurrentTrain: epoch  4, batch    29 | loss: 78.7700160CurrentTrain: epoch  4, batch    30 | loss: 83.9043045CurrentTrain: epoch  4, batch    31 | loss: 68.1707981CurrentTrain: epoch  4, batch    32 | loss: 87.0604244CurrentTrain: epoch  4, batch    33 | loss: 61.9565454CurrentTrain: epoch  4, batch    34 | loss: 103.2944216CurrentTrain: epoch  4, batch    35 | loss: 84.0329294CurrentTrain: epoch  4, batch    36 | loss: 105.4388768CurrentTrain: epoch  4, batch    37 | loss: 75.4456852CurrentTrain: epoch  4, batch    38 | loss: 85.5253999CurrentTrain: epoch  4, batch    39 | loss: 65.9653460CurrentTrain: epoch  4, batch    40 | loss: 70.8092928CurrentTrain: epoch  4, batch    41 | loss: 83.4988615CurrentTrain: epoch  4, batch    42 | loss: 61.3357951CurrentTrain: epoch  4, batch    43 | loss: 103.4034783CurrentTrain: epoch  4, batch    44 | loss: 80.7587770CurrentTrain: epoch  4, batch    45 | loss: 98.0668881CurrentTrain: epoch  4, batch    46 | loss: 86.2686656CurrentTrain: epoch  4, batch    47 | loss: 126.4363542CurrentTrain: epoch  4, batch    48 | loss: 99.9041848CurrentTrain: epoch  4, batch    49 | loss: 67.8930152CurrentTrain: epoch  4, batch    50 | loss: 86.0304216CurrentTrain: epoch  4, batch    51 | loss: 129.3885147CurrentTrain: epoch  4, batch    52 | loss: 74.4237194CurrentTrain: epoch  4, batch    53 | loss: 84.8506278CurrentTrain: epoch  4, batch    54 | loss: 100.9344343CurrentTrain: epoch  4, batch    55 | loss: 97.7856908CurrentTrain: epoch  4, batch    56 | loss: 78.6847945CurrentTrain: epoch  4, batch    57 | loss: 86.8883854CurrentTrain: epoch  4, batch    58 | loss: 84.1967094CurrentTrain: epoch  4, batch    59 | loss: 70.1123671CurrentTrain: epoch  4, batch    60 | loss: 81.8962570CurrentTrain: epoch  4, batch    61 | loss: 63.5716359CurrentTrain: epoch  4, batch    62 | loss: 66.1494172CurrentTrain: epoch  4, batch    63 | loss: 86.1341052CurrentTrain: epoch  4, batch    64 | loss: 100.8527779CurrentTrain: epoch  4, batch    65 | loss: 67.5042170CurrentTrain: epoch  4, batch    66 | loss: 101.8445964CurrentTrain: epoch  4, batch    67 | loss: 69.1722797CurrentTrain: epoch  4, batch    68 | loss: 84.9616857CurrentTrain: epoch  4, batch    69 | loss: 76.9822454CurrentTrain: epoch  4, batch    70 | loss: 60.8719877CurrentTrain: epoch  4, batch    71 | loss: 103.8259398CurrentTrain: epoch  4, batch    72 | loss: 176.9941213CurrentTrain: epoch  4, batch    73 | loss: 68.4418247CurrentTrain: epoch  4, batch    74 | loss: 102.4214289CurrentTrain: epoch  4, batch    75 | loss: 74.7581758CurrentTrain: epoch  4, batch    76 | loss: 59.3217418CurrentTrain: epoch  4, batch    77 | loss: 84.2768755CurrentTrain: epoch  4, batch    78 | loss: 63.4603104CurrentTrain: epoch  4, batch    79 | loss: 83.8954357CurrentTrain: epoch  4, batch    80 | loss: 128.7758582CurrentTrain: epoch  4, batch    81 | loss: 84.3746104CurrentTrain: epoch  4, batch    82 | loss: 71.7346861CurrentTrain: epoch  4, batch    83 | loss: 129.1005512CurrentTrain: epoch  4, batch    84 | loss: 77.9746324CurrentTrain: epoch  4, batch    85 | loss: 103.7850181CurrentTrain: epoch  4, batch    86 | loss: 102.3289773CurrentTrain: epoch  4, batch    87 | loss: 83.2651397CurrentTrain: epoch  4, batch    88 | loss: 82.0445157CurrentTrain: epoch  4, batch    89 | loss: 70.8895198CurrentTrain: epoch  4, batch    90 | loss: 71.1243635CurrentTrain: epoch  4, batch    91 | loss: 135.3812194CurrentTrain: epoch  4, batch    92 | loss: 70.8309148CurrentTrain: epoch  4, batch    93 | loss: 70.3916927CurrentTrain: epoch  4, batch    94 | loss: 103.2048153CurrentTrain: epoch  4, batch    95 | loss: 46.2726896CurrentTrain: epoch  5, batch     0 | loss: 79.3987011CurrentTrain: epoch  5, batch     1 | loss: 62.5236856CurrentTrain: epoch  5, batch     2 | loss: 67.8559505CurrentTrain: epoch  5, batch     3 | loss: 125.3782563CurrentTrain: epoch  5, batch     4 | loss: 94.1843155CurrentTrain: epoch  5, batch     5 | loss: 94.2601159CurrentTrain: epoch  5, batch     6 | loss: 99.2572101CurrentTrain: epoch  5, batch     7 | loss: 78.3635366CurrentTrain: epoch  5, batch     8 | loss: 56.6181761CurrentTrain: epoch  5, batch     9 | loss: 103.5141278CurrentTrain: epoch  5, batch    10 | loss: 129.0055206CurrentTrain: epoch  5, batch    11 | loss: 78.8639606CurrentTrain: epoch  5, batch    12 | loss: 99.5024939CurrentTrain: epoch  5, batch    13 | loss: 72.1865507CurrentTrain: epoch  5, batch    14 | loss: 79.4978529CurrentTrain: epoch  5, batch    15 | loss: 81.2900682CurrentTrain: epoch  5, batch    16 | loss: 79.6727346CurrentTrain: epoch  5, batch    17 | loss: 80.5581047CurrentTrain: epoch  5, batch    18 | loss: 84.6592569CurrentTrain: epoch  5, batch    19 | loss: 123.7717998CurrentTrain: epoch  5, batch    20 | loss: 80.4619191CurrentTrain: epoch  5, batch    21 | loss: 99.8637723CurrentTrain: epoch  5, batch    22 | loss: 80.2806473CurrentTrain: epoch  5, batch    23 | loss: 92.6980064CurrentTrain: epoch  5, batch    24 | loss: 103.6895033CurrentTrain: epoch  5, batch    25 | loss: 80.7030348CurrentTrain: epoch  5, batch    26 | loss: 67.0547387CurrentTrain: epoch  5, batch    27 | loss: 96.3468216CurrentTrain: epoch  5, batch    28 | loss: 104.0612298CurrentTrain: epoch  5, batch    29 | loss: 71.3011729CurrentTrain: epoch  5, batch    30 | loss: 103.9737130CurrentTrain: epoch  5, batch    31 | loss: 81.6317929CurrentTrain: epoch  5, batch    32 | loss: 68.9436163CurrentTrain: epoch  5, batch    33 | loss: 85.9250925CurrentTrain: epoch  5, batch    34 | loss: 79.5402575CurrentTrain: epoch  5, batch    35 | loss: 79.3000428CurrentTrain: epoch  5, batch    36 | loss: 68.2665007CurrentTrain: epoch  5, batch    37 | loss: 70.5417060CurrentTrain: epoch  5, batch    38 | loss: 100.4750799CurrentTrain: epoch  5, batch    39 | loss: 56.7903514CurrentTrain: epoch  5, batch    40 | loss: 81.1128723CurrentTrain: epoch  5, batch    41 | loss: 58.6249638CurrentTrain: epoch  5, batch    42 | loss: 71.6421009CurrentTrain: epoch  5, batch    43 | loss: 56.1277209CurrentTrain: epoch  5, batch    44 | loss: 58.6970697CurrentTrain: epoch  5, batch    45 | loss: 85.5883075CurrentTrain: epoch  5, batch    46 | loss: 98.6285269CurrentTrain: epoch  5, batch    47 | loss: 102.0195585CurrentTrain: epoch  5, batch    48 | loss: 124.4667629CurrentTrain: epoch  5, batch    49 | loss: 99.6137680CurrentTrain: epoch  5, batch    50 | loss: 81.8769599CurrentTrain: epoch  5, batch    51 | loss: 82.4626464CurrentTrain: epoch  5, batch    52 | loss: 126.4745082CurrentTrain: epoch  5, batch    53 | loss: 87.9525031CurrentTrain: epoch  5, batch    54 | loss: 66.9407290CurrentTrain: epoch  5, batch    55 | loss: 101.8875747CurrentTrain: epoch  5, batch    56 | loss: 59.8369086CurrentTrain: epoch  5, batch    57 | loss: 96.6706003CurrentTrain: epoch  5, batch    58 | loss: 127.8680627CurrentTrain: epoch  5, batch    59 | loss: 94.8970207CurrentTrain: epoch  5, batch    60 | loss: 67.9223532CurrentTrain: epoch  5, batch    61 | loss: 72.0574993CurrentTrain: epoch  5, batch    62 | loss: 85.2485855CurrentTrain: epoch  5, batch    63 | loss: 63.9285359CurrentTrain: epoch  5, batch    64 | loss: 87.0725800CurrentTrain: epoch  5, batch    65 | loss: 76.8709301CurrentTrain: epoch  5, batch    66 | loss: 83.1331078CurrentTrain: epoch  5, batch    67 | loss: 83.7758398CurrentTrain: epoch  5, batch    68 | loss: 99.7474574CurrentTrain: epoch  5, batch    69 | loss: 65.0147315CurrentTrain: epoch  5, batch    70 | loss: 78.3764828CurrentTrain: epoch  5, batch    71 | loss: 126.4502193CurrentTrain: epoch  5, batch    72 | loss: 57.1067171CurrentTrain: epoch  5, batch    73 | loss: 59.5647458CurrentTrain: epoch  5, batch    74 | loss: 72.2706722CurrentTrain: epoch  5, batch    75 | loss: 64.2736958CurrentTrain: epoch  5, batch    76 | loss: 71.8365319CurrentTrain: epoch  5, batch    77 | loss: 72.8247081CurrentTrain: epoch  5, batch    78 | loss: 57.8580176CurrentTrain: epoch  5, batch    79 | loss: 68.1061815CurrentTrain: epoch  5, batch    80 | loss: 80.0286165CurrentTrain: epoch  5, batch    81 | loss: 100.4849503CurrentTrain: epoch  5, batch    82 | loss: 76.1520756CurrentTrain: epoch  5, batch    83 | loss: 124.5101893CurrentTrain: epoch  5, batch    84 | loss: 55.0954414CurrentTrain: epoch  5, batch    85 | loss: 99.2250430CurrentTrain: epoch  5, batch    86 | loss: 86.0768924CurrentTrain: epoch  5, batch    87 | loss: 129.1918260CurrentTrain: epoch  5, batch    88 | loss: 67.2261950CurrentTrain: epoch  5, batch    89 | loss: 100.8252632CurrentTrain: epoch  5, batch    90 | loss: 130.0515175CurrentTrain: epoch  5, batch    91 | loss: 99.4381816CurrentTrain: epoch  5, batch    92 | loss: 81.2440784CurrentTrain: epoch  5, batch    93 | loss: 72.5396869CurrentTrain: epoch  5, batch    94 | loss: 58.5090383CurrentTrain: epoch  5, batch    95 | loss: 80.5685506CurrentTrain: epoch  6, batch     0 | loss: 80.2732520CurrentTrain: epoch  6, batch     1 | loss: 81.3589088CurrentTrain: epoch  6, batch     2 | loss: 78.0924064CurrentTrain: epoch  6, batch     3 | loss: 79.9683065CurrentTrain: epoch  6, batch     4 | loss: 102.4486822CurrentTrain: epoch  6, batch     5 | loss: 79.7040188CurrentTrain: epoch  6, batch     6 | loss: 74.5823250CurrentTrain: epoch  6, batch     7 | loss: 81.8804769CurrentTrain: epoch  6, batch     8 | loss: 64.9544051CurrentTrain: epoch  6, batch     9 | loss: 97.7609700CurrentTrain: epoch  6, batch    10 | loss: 66.5900481CurrentTrain: epoch  6, batch    11 | loss: 66.3356263CurrentTrain: epoch  6, batch    12 | loss: 65.5269718CurrentTrain: epoch  6, batch    13 | loss: 100.4556859CurrentTrain: epoch  6, batch    14 | loss: 68.8202137CurrentTrain: epoch  6, batch    15 | loss: 68.9069916CurrentTrain: epoch  6, batch    16 | loss: 88.9666558CurrentTrain: epoch  6, batch    17 | loss: 99.2126473CurrentTrain: epoch  6, batch    18 | loss: 65.9161989CurrentTrain: epoch  6, batch    19 | loss: 125.5620603CurrentTrain: epoch  6, batch    20 | loss: 67.5062497CurrentTrain: epoch  6, batch    21 | loss: 55.0344714CurrentTrain: epoch  6, batch    22 | loss: 66.9271372CurrentTrain: epoch  6, batch    23 | loss: 69.2925902CurrentTrain: epoch  6, batch    24 | loss: 75.2923499CurrentTrain: epoch  6, batch    25 | loss: 98.5708214CurrentTrain: epoch  6, batch    26 | loss: 92.9681900CurrentTrain: epoch  6, batch    27 | loss: 77.5987297CurrentTrain: epoch  6, batch    28 | loss: 98.0026737CurrentTrain: epoch  6, batch    29 | loss: 80.4725427CurrentTrain: epoch  6, batch    30 | loss: 82.5094212CurrentTrain: epoch  6, batch    31 | loss: 101.7770890CurrentTrain: epoch  6, batch    32 | loss: 98.2863782CurrentTrain: epoch  6, batch    33 | loss: 81.9720996CurrentTrain: epoch  6, batch    34 | loss: 99.5505098CurrentTrain: epoch  6, batch    35 | loss: 83.8892853CurrentTrain: epoch  6, batch    36 | loss: 118.6981504CurrentTrain: epoch  6, batch    37 | loss: 101.0880212CurrentTrain: epoch  6, batch    38 | loss: 95.0386453CurrentTrain: epoch  6, batch    39 | loss: 58.2334330CurrentTrain: epoch  6, batch    40 | loss: 77.7792157CurrentTrain: epoch  6, batch    41 | loss: 79.2355247CurrentTrain: epoch  6, batch    42 | loss: 76.2199547CurrentTrain: epoch  6, batch    43 | loss: 120.3531549CurrentTrain: epoch  6, batch    44 | loss: 126.4747708CurrentTrain: epoch  6, batch    45 | loss: 98.2238887CurrentTrain: epoch  6, batch    46 | loss: 92.2856327CurrentTrain: epoch  6, batch    47 | loss: 64.5762248CurrentTrain: epoch  6, batch    48 | loss: 99.7451665CurrentTrain: epoch  6, batch    49 | loss: 96.9228770CurrentTrain: epoch  6, batch    50 | loss: 64.7213633CurrentTrain: epoch  6, batch    51 | loss: 83.7367214CurrentTrain: epoch  6, batch    52 | loss: 68.2886733CurrentTrain: epoch  6, batch    53 | loss: 85.2892487CurrentTrain: epoch  6, batch    54 | loss: 100.3170563CurrentTrain: epoch  6, batch    55 | loss: 81.8202998CurrentTrain: epoch  6, batch    56 | loss: 95.5311411CurrentTrain: epoch  6, batch    57 | loss: 97.3739627CurrentTrain: epoch  6, batch    58 | loss: 100.1135321CurrentTrain: epoch  6, batch    59 | loss: 64.8762576CurrentTrain: epoch  6, batch    60 | loss: 79.3613149CurrentTrain: epoch  6, batch    61 | loss: 129.8750518CurrentTrain: epoch  6, batch    62 | loss: 84.3396653CurrentTrain: epoch  6, batch    63 | loss: 66.5846186CurrentTrain: epoch  6, batch    64 | loss: 56.3974671CurrentTrain: epoch  6, batch    65 | loss: 67.6280159CurrentTrain: epoch  6, batch    66 | loss: 100.8535894CurrentTrain: epoch  6, batch    67 | loss: 80.9615606CurrentTrain: epoch  6, batch    68 | loss: 78.2854560CurrentTrain: epoch  6, batch    69 | loss: 60.7893616CurrentTrain: epoch  6, batch    70 | loss: 81.9926388CurrentTrain: epoch  6, batch    71 | loss: 99.2847498CurrentTrain: epoch  6, batch    72 | loss: 99.2464816CurrentTrain: epoch  6, batch    73 | loss: 100.8396769CurrentTrain: epoch  6, batch    74 | loss: 69.4020797CurrentTrain: epoch  6, batch    75 | loss: 71.5318844CurrentTrain: epoch  6, batch    76 | loss: 60.8740944CurrentTrain: epoch  6, batch    77 | loss: 99.2365429CurrentTrain: epoch  6, batch    78 | loss: 79.6401715CurrentTrain: epoch  6, batch    79 | loss: 58.4434968CurrentTrain: epoch  6, batch    80 | loss: 83.4685487CurrentTrain: epoch  6, batch    81 | loss: 102.3486815CurrentTrain: epoch  6, batch    82 | loss: 71.5944621CurrentTrain: epoch  6, batch    83 | loss: 97.0274347CurrentTrain: epoch  6, batch    84 | loss: 81.8027707CurrentTrain: epoch  6, batch    85 | loss: 63.2790180CurrentTrain: epoch  6, batch    86 | loss: 84.5213467CurrentTrain: epoch  6, batch    87 | loss: 94.8437140CurrentTrain: epoch  6, batch    88 | loss: 96.9745016CurrentTrain: epoch  6, batch    89 | loss: 104.0353149CurrentTrain: epoch  6, batch    90 | loss: 101.7285672CurrentTrain: epoch  6, batch    91 | loss: 101.8933498CurrentTrain: epoch  6, batch    92 | loss: 79.2290740CurrentTrain: epoch  6, batch    93 | loss: 79.2660043CurrentTrain: epoch  6, batch    94 | loss: 81.5400231CurrentTrain: epoch  6, batch    95 | loss: 71.0268308CurrentTrain: epoch  7, batch     0 | loss: 63.1862377CurrentTrain: epoch  7, batch     1 | loss: 122.2623549CurrentTrain: epoch  7, batch     2 | loss: 96.9033673CurrentTrain: epoch  7, batch     3 | loss: 67.6654382CurrentTrain: epoch  7, batch     4 | loss: 79.8965532CurrentTrain: epoch  7, batch     5 | loss: 103.5506463CurrentTrain: epoch  7, batch     6 | loss: 75.0576797CurrentTrain: epoch  7, batch     7 | loss: 54.1202347CurrentTrain: epoch  7, batch     8 | loss: 68.1463318CurrentTrain: epoch  7, batch     9 | loss: 67.1066155CurrentTrain: epoch  7, batch    10 | loss: 102.8752150CurrentTrain: epoch  7, batch    11 | loss: 79.1415459CurrentTrain: epoch  7, batch    12 | loss: 96.9421087CurrentTrain: epoch  7, batch    13 | loss: 76.9333766CurrentTrain: epoch  7, batch    14 | loss: 95.9108184CurrentTrain: epoch  7, batch    15 | loss: 68.7331959CurrentTrain: epoch  7, batch    16 | loss: 91.8354503CurrentTrain: epoch  7, batch    17 | loss: 95.1260735CurrentTrain: epoch  7, batch    18 | loss: 66.6054047CurrentTrain: epoch  7, batch    19 | loss: 66.1830510CurrentTrain: epoch  7, batch    20 | loss: 64.6364770CurrentTrain: epoch  7, batch    21 | loss: 121.9433529CurrentTrain: epoch  7, batch    22 | loss: 65.1701170CurrentTrain: epoch  7, batch    23 | loss: 69.0448693CurrentTrain: epoch  7, batch    24 | loss: 65.4790654CurrentTrain: epoch  7, batch    25 | loss: 69.4668326CurrentTrain: epoch  7, batch    26 | loss: 99.5829122CurrentTrain: epoch  7, batch    27 | loss: 98.4370861CurrentTrain: epoch  7, batch    28 | loss: 78.8746446CurrentTrain: epoch  7, batch    29 | loss: 97.5675127CurrentTrain: epoch  7, batch    30 | loss: 82.4784485CurrentTrain: epoch  7, batch    31 | loss: 68.3474203CurrentTrain: epoch  7, batch    32 | loss: 78.3375246CurrentTrain: epoch  7, batch    33 | loss: 97.5644323CurrentTrain: epoch  7, batch    34 | loss: 76.5576628CurrentTrain: epoch  7, batch    35 | loss: 80.4612416CurrentTrain: epoch  7, batch    36 | loss: 72.9167934CurrentTrain: epoch  7, batch    37 | loss: 122.8016648CurrentTrain: epoch  7, batch    38 | loss: 80.4620444CurrentTrain: epoch  7, batch    39 | loss: 65.2734022CurrentTrain: epoch  7, batch    40 | loss: 64.7291995CurrentTrain: epoch  7, batch    41 | loss: 82.9504909CurrentTrain: epoch  7, batch    42 | loss: 121.9431140CurrentTrain: epoch  7, batch    43 | loss: 77.7854896CurrentTrain: epoch  7, batch    44 | loss: 66.1107251CurrentTrain: epoch  7, batch    45 | loss: 99.8009960CurrentTrain: epoch  7, batch    46 | loss: 80.4078700CurrentTrain: epoch  7, batch    47 | loss: 65.3651634CurrentTrain: epoch  7, batch    48 | loss: 96.3144110CurrentTrain: epoch  7, batch    49 | loss: 99.5866483CurrentTrain: epoch  7, batch    50 | loss: 68.7123584CurrentTrain: epoch  7, batch    51 | loss: 94.3764395CurrentTrain: epoch  7, batch    52 | loss: 116.2971586CurrentTrain: epoch  7, batch    53 | loss: 64.7293345CurrentTrain: epoch  7, batch    54 | loss: 66.1053207CurrentTrain: epoch  7, batch    55 | loss: 66.6795958CurrentTrain: epoch  7, batch    56 | loss: 62.0360699CurrentTrain: epoch  7, batch    57 | loss: 127.3975781CurrentTrain: epoch  7, batch    58 | loss: 60.5728746CurrentTrain: epoch  7, batch    59 | loss: 64.2077336CurrentTrain: epoch  7, batch    60 | loss: 76.6568794CurrentTrain: epoch  7, batch    61 | loss: 100.0119008CurrentTrain: epoch  7, batch    62 | loss: 69.4374916CurrentTrain: epoch  7, batch    63 | loss: 130.1660958CurrentTrain: epoch  7, batch    64 | loss: 64.3145471CurrentTrain: epoch  7, batch    65 | loss: 84.9308801CurrentTrain: epoch  7, batch    66 | loss: 127.9910979CurrentTrain: epoch  7, batch    67 | loss: 80.9042573CurrentTrain: epoch  7, batch    68 | loss: 121.2061116CurrentTrain: epoch  7, batch    69 | loss: 101.7069940CurrentTrain: epoch  7, batch    70 | loss: 95.4532029CurrentTrain: epoch  7, batch    71 | loss: 83.8176780CurrentTrain: epoch  7, batch    72 | loss: 78.4395418CurrentTrain: epoch  7, batch    73 | loss: 69.3219639CurrentTrain: epoch  7, batch    74 | loss: 122.1229258CurrentTrain: epoch  7, batch    75 | loss: 98.8247231CurrentTrain: epoch  7, batch    76 | loss: 78.5656373CurrentTrain: epoch  7, batch    77 | loss: 54.6121838CurrentTrain: epoch  7, batch    78 | loss: 70.9350088CurrentTrain: epoch  7, batch    79 | loss: 80.8650182CurrentTrain: epoch  7, batch    80 | loss: 68.1665090CurrentTrain: epoch  7, batch    81 | loss: 100.2532729CurrentTrain: epoch  7, batch    82 | loss: 70.5789606CurrentTrain: epoch  7, batch    83 | loss: 95.7211772CurrentTrain: epoch  7, batch    84 | loss: 81.7577590CurrentTrain: epoch  7, batch    85 | loss: 122.5598190CurrentTrain: epoch  7, batch    86 | loss: 80.2953568CurrentTrain: epoch  7, batch    87 | loss: 58.0989303CurrentTrain: epoch  7, batch    88 | loss: 61.6219199CurrentTrain: epoch  7, batch    89 | loss: 68.8865385CurrentTrain: epoch  7, batch    90 | loss: 78.5408238CurrentTrain: epoch  7, batch    91 | loss: 99.0527161CurrentTrain: epoch  7, batch    92 | loss: 65.5826742CurrentTrain: epoch  7, batch    93 | loss: 118.9091461CurrentTrain: epoch  7, batch    94 | loss: 75.4805398CurrentTrain: epoch  7, batch    95 | loss: 77.6262796CurrentTrain: epoch  8, batch     0 | loss: 68.6749911CurrentTrain: epoch  8, batch     1 | loss: 125.2627992CurrentTrain: epoch  8, batch     2 | loss: 64.8891067CurrentTrain: epoch  8, batch     3 | loss: 54.9729267CurrentTrain: epoch  8, batch     4 | loss: 96.2693073CurrentTrain: epoch  8, batch     5 | loss: 95.4295273CurrentTrain: epoch  8, batch     6 | loss: 94.8788527CurrentTrain: epoch  8, batch     7 | loss: 66.3470779CurrentTrain: epoch  8, batch     8 | loss: 79.4837872CurrentTrain: epoch  8, batch     9 | loss: 55.2118335CurrentTrain: epoch  8, batch    10 | loss: 75.6797168CurrentTrain: epoch  8, batch    11 | loss: 77.9496702CurrentTrain: epoch  8, batch    12 | loss: 80.0287032CurrentTrain: epoch  8, batch    13 | loss: 53.8593164CurrentTrain: epoch  8, batch    14 | loss: 122.4528307CurrentTrain: epoch  8, batch    15 | loss: 67.5780387CurrentTrain: epoch  8, batch    16 | loss: 101.6338781CurrentTrain: epoch  8, batch    17 | loss: 93.1883001CurrentTrain: epoch  8, batch    18 | loss: 65.1206295CurrentTrain: epoch  8, batch    19 | loss: 95.3867294CurrentTrain: epoch  8, batch    20 | loss: 78.9380630CurrentTrain: epoch  8, batch    21 | loss: 98.4555816CurrentTrain: epoch  8, batch    22 | loss: 168.1491021CurrentTrain: epoch  8, batch    23 | loss: 77.3208511CurrentTrain: epoch  8, batch    24 | loss: 81.0058293CurrentTrain: epoch  8, batch    25 | loss: 118.5376372CurrentTrain: epoch  8, batch    26 | loss: 76.7465103CurrentTrain: epoch  8, batch    27 | loss: 81.9461847CurrentTrain: epoch  8, batch    28 | loss: 81.8830142CurrentTrain: epoch  8, batch    29 | loss: 66.1220305CurrentTrain: epoch  8, batch    30 | loss: 77.6283347CurrentTrain: epoch  8, batch    31 | loss: 120.0318725CurrentTrain: epoch  8, batch    32 | loss: 75.6070484CurrentTrain: epoch  8, batch    33 | loss: 73.4896824CurrentTrain: epoch  8, batch    34 | loss: 62.5124903CurrentTrain: epoch  8, batch    35 | loss: 76.8663421CurrentTrain: epoch  8, batch    36 | loss: 76.2289576CurrentTrain: epoch  8, batch    37 | loss: 123.7299053CurrentTrain: epoch  8, batch    38 | loss: 98.8415696CurrentTrain: epoch  8, batch    39 | loss: 124.8800804CurrentTrain: epoch  8, batch    40 | loss: 56.0640476CurrentTrain: epoch  8, batch    41 | loss: 92.1457802CurrentTrain: epoch  8, batch    42 | loss: 98.6375424CurrentTrain: epoch  8, batch    43 | loss: 74.8833285CurrentTrain: epoch  8, batch    44 | loss: 56.8282503CurrentTrain: epoch  8, batch    45 | loss: 55.9079068CurrentTrain: epoch  8, batch    46 | loss: 82.2363091CurrentTrain: epoch  8, batch    47 | loss: 75.3943224CurrentTrain: epoch  8, batch    48 | loss: 83.3468985CurrentTrain: epoch  8, batch    49 | loss: 77.1741005CurrentTrain: epoch  8, batch    50 | loss: 78.4206979CurrentTrain: epoch  8, batch    51 | loss: 77.9924105CurrentTrain: epoch  8, batch    52 | loss: 75.1706191CurrentTrain: epoch  8, batch    53 | loss: 74.3416616CurrentTrain: epoch  8, batch    54 | loss: 119.9602912CurrentTrain: epoch  8, batch    55 | loss: 99.4061705CurrentTrain: epoch  8, batch    56 | loss: 58.1773238CurrentTrain: epoch  8, batch    57 | loss: 97.3912291CurrentTrain: epoch  8, batch    58 | loss: 75.3003591CurrentTrain: epoch  8, batch    59 | loss: 123.5460637CurrentTrain: epoch  8, batch    60 | loss: 67.1721465CurrentTrain: epoch  8, batch    61 | loss: 74.2135019CurrentTrain: epoch  8, batch    62 | loss: 169.4863322CurrentTrain: epoch  8, batch    63 | loss: 64.8283422CurrentTrain: epoch  8, batch    64 | loss: 79.8618531CurrentTrain: epoch  8, batch    65 | loss: 67.8741332CurrentTrain: epoch  8, batch    66 | loss: 74.3233841CurrentTrain: epoch  8, batch    67 | loss: 95.5451929CurrentTrain: epoch  8, batch    68 | loss: 100.7723829CurrentTrain: epoch  8, batch    69 | loss: 64.8492359CurrentTrain: epoch  8, batch    70 | loss: 68.7296789CurrentTrain: epoch  8, batch    71 | loss: 78.0387380CurrentTrain: epoch  8, batch    72 | loss: 78.1074370CurrentTrain: epoch  8, batch    73 | loss: 122.1884625CurrentTrain: epoch  8, batch    74 | loss: 75.5178014CurrentTrain: epoch  8, batch    75 | loss: 64.5524043CurrentTrain: epoch  8, batch    76 | loss: 96.3180237CurrentTrain: epoch  8, batch    77 | loss: 64.7996355CurrentTrain: epoch  8, batch    78 | loss: 95.7430695CurrentTrain: epoch  8, batch    79 | loss: 60.8768615CurrentTrain: epoch  8, batch    80 | loss: 95.6052549CurrentTrain: epoch  8, batch    81 | loss: 80.2697567CurrentTrain: epoch  8, batch    82 | loss: 62.7601776CurrentTrain: epoch  8, batch    83 | loss: 67.6175158CurrentTrain: epoch  8, batch    84 | loss: 78.5531037CurrentTrain: epoch  8, batch    85 | loss: 80.2277457CurrentTrain: epoch  8, batch    86 | loss: 95.1381795CurrentTrain: epoch  8, batch    87 | loss: 55.4128916CurrentTrain: epoch  8, batch    88 | loss: 162.5391084CurrentTrain: epoch  8, batch    89 | loss: 62.7561395CurrentTrain: epoch  8, batch    90 | loss: 98.2144700CurrentTrain: epoch  8, batch    91 | loss: 64.7995294CurrentTrain: epoch  8, batch    92 | loss: 62.3423144CurrentTrain: epoch  8, batch    93 | loss: 68.8889780CurrentTrain: epoch  8, batch    94 | loss: 61.0071562CurrentTrain: epoch  8, batch    95 | loss: 83.3213172CurrentTrain: epoch  9, batch     0 | loss: 76.0452858CurrentTrain: epoch  9, batch     1 | loss: 63.1499496CurrentTrain: epoch  9, batch     2 | loss: 121.7740801CurrentTrain: epoch  9, batch     3 | loss: 79.4340188CurrentTrain: epoch  9, batch     4 | loss: 73.4438251CurrentTrain: epoch  9, batch     5 | loss: 80.7085711CurrentTrain: epoch  9, batch     6 | loss: 65.0348547CurrentTrain: epoch  9, batch     7 | loss: 66.8391805CurrentTrain: epoch  9, batch     8 | loss: 76.4778143CurrentTrain: epoch  9, batch     9 | loss: 78.4776824CurrentTrain: epoch  9, batch    10 | loss: 75.8744724CurrentTrain: epoch  9, batch    11 | loss: 77.9782151CurrentTrain: epoch  9, batch    12 | loss: 97.0728346CurrentTrain: epoch  9, batch    13 | loss: 77.2440589CurrentTrain: epoch  9, batch    14 | loss: 79.2607870CurrentTrain: epoch  9, batch    15 | loss: 63.4064744CurrentTrain: epoch  9, batch    16 | loss: 78.6187003CurrentTrain: epoch  9, batch    17 | loss: 75.4184910CurrentTrain: epoch  9, batch    18 | loss: 125.7967323CurrentTrain: epoch  9, batch    19 | loss: 62.1143090CurrentTrain: epoch  9, batch    20 | loss: 95.9484111CurrentTrain: epoch  9, batch    21 | loss: 117.7998121CurrentTrain: epoch  9, batch    22 | loss: 93.4244087CurrentTrain: epoch  9, batch    23 | loss: 76.5895506CurrentTrain: epoch  9, batch    24 | loss: 96.7005199CurrentTrain: epoch  9, batch    25 | loss: 61.7664209CurrentTrain: epoch  9, batch    26 | loss: 67.3209624CurrentTrain: epoch  9, batch    27 | loss: 77.9325527CurrentTrain: epoch  9, batch    28 | loss: 120.2891082CurrentTrain: epoch  9, batch    29 | loss: 54.4935888CurrentTrain: epoch  9, batch    30 | loss: 77.6745816CurrentTrain: epoch  9, batch    31 | loss: 97.5473087CurrentTrain: epoch  9, batch    32 | loss: 73.9624614CurrentTrain: epoch  9, batch    33 | loss: 77.3628166CurrentTrain: epoch  9, batch    34 | loss: 123.5597368CurrentTrain: epoch  9, batch    35 | loss: 66.8499386CurrentTrain: epoch  9, batch    36 | loss: 73.6757700CurrentTrain: epoch  9, batch    37 | loss: 98.2721675CurrentTrain: epoch  9, batch    38 | loss: 94.7809284CurrentTrain: epoch  9, batch    39 | loss: 80.5381107CurrentTrain: epoch  9, batch    40 | loss: 55.7452610CurrentTrain: epoch  9, batch    41 | loss: 96.2788571CurrentTrain: epoch  9, batch    42 | loss: 66.8414480CurrentTrain: epoch  9, batch    43 | loss: 74.6901001CurrentTrain: epoch  9, batch    44 | loss: 64.6524651CurrentTrain: epoch  9, batch    45 | loss: 94.6734910CurrentTrain: epoch  9, batch    46 | loss: 77.8898064CurrentTrain: epoch  9, batch    47 | loss: 97.9001068CurrentTrain: epoch  9, batch    48 | loss: 78.8395502CurrentTrain: epoch  9, batch    49 | loss: 77.4791638CurrentTrain: epoch  9, batch    50 | loss: 61.3668511CurrentTrain: epoch  9, batch    51 | loss: 68.2372542CurrentTrain: epoch  9, batch    52 | loss: 98.8787789CurrentTrain: epoch  9, batch    53 | loss: 79.4691637CurrentTrain: epoch  9, batch    54 | loss: 95.7504502CurrentTrain: epoch  9, batch    55 | loss: 74.7609367CurrentTrain: epoch  9, batch    56 | loss: 76.5773086CurrentTrain: epoch  9, batch    57 | loss: 58.6223131CurrentTrain: epoch  9, batch    58 | loss: 61.9031945CurrentTrain: epoch  9, batch    59 | loss: 123.6278488CurrentTrain: epoch  9, batch    60 | loss: 98.7868426CurrentTrain: epoch  9, batch    61 | loss: 79.9173204CurrentTrain: epoch  9, batch    62 | loss: 66.2272682CurrentTrain: epoch  9, batch    63 | loss: 120.9323398CurrentTrain: epoch  9, batch    64 | loss: 75.6091948CurrentTrain: epoch  9, batch    65 | loss: 80.1004601CurrentTrain: epoch  9, batch    66 | loss: 64.5844437CurrentTrain: epoch  9, batch    67 | loss: 91.5322624CurrentTrain: epoch  9, batch    68 | loss: 73.5810873CurrentTrain: epoch  9, batch    69 | loss: 66.1654551CurrentTrain: epoch  9, batch    70 | loss: 67.2017328CurrentTrain: epoch  9, batch    71 | loss: 68.8924117CurrentTrain: epoch  9, batch    72 | loss: 94.8515301CurrentTrain: epoch  9, batch    73 | loss: 74.2444604CurrentTrain: epoch  9, batch    74 | loss: 78.2112352CurrentTrain: epoch  9, batch    75 | loss: 66.4345253CurrentTrain: epoch  9, batch    76 | loss: 97.7331787CurrentTrain: epoch  9, batch    77 | loss: 79.7649655CurrentTrain: epoch  9, batch    78 | loss: 55.4564060CurrentTrain: epoch  9, batch    79 | loss: 123.9382779CurrentTrain: epoch  9, batch    80 | loss: 78.5487746CurrentTrain: epoch  9, batch    81 | loss: 75.9844620CurrentTrain: epoch  9, batch    82 | loss: 95.3993651CurrentTrain: epoch  9, batch    83 | loss: 63.9679608CurrentTrain: epoch  9, batch    84 | loss: 75.3260514CurrentTrain: epoch  9, batch    85 | loss: 58.6016577CurrentTrain: epoch  9, batch    86 | loss: 77.0166412CurrentTrain: epoch  9, batch    87 | loss: 94.7367368CurrentTrain: epoch  9, batch    88 | loss: 77.5166352CurrentTrain: epoch  9, batch    89 | loss: 74.8903096CurrentTrain: epoch  9, batch    90 | loss: 65.1953302CurrentTrain: epoch  9, batch    91 | loss: 92.5956269CurrentTrain: epoch  9, batch    92 | loss: 73.7386436CurrentTrain: epoch  9, batch    93 | loss: 67.9197791CurrentTrain: epoch  9, batch    94 | loss: 167.5237271CurrentTrain: epoch  9, batch    95 | loss: 66.7573231

F1 score per class: {32: np.float64(0.5714285714285714), 6: np.float64(0.8071748878923767), 19: np.float64(0.29411764705882354), 24: np.float64(0.7415730337078652), 26: np.float64(0.9333333333333333), 29: np.float64(0.8229665071770335)}
Micro-average F1 score: 0.7613526570048309
Weighted-average F1 score: 0.7641358781412441
F1 score per class: {32: np.float64(0.642570281124498), 6: np.float64(0.7913043478260869), 19: np.float64(0.2153846153846154), 24: np.float64(0.7311827956989247), 26: np.float64(0.95), 29: np.float64(0.822429906542056)}
Micro-average F1 score: 0.75
Weighted-average F1 score: 0.7354222744471571
F1 score per class: {32: np.float64(0.6502057613168725), 6: np.float64(0.7947598253275109), 19: np.float64(0.27450980392156865), 24: np.float64(0.73224043715847), 26: np.float64(0.9547738693467337), 29: np.float64(0.822429906542056)}
Micro-average F1 score: 0.7631814119749777
Weighted-average F1 score: 0.7547717862899291

F1 score per class: {32: np.float64(0.5714285714285714), 6: np.float64(0.8071748878923767), 19: np.float64(0.29411764705882354), 24: np.float64(0.7415730337078652), 26: np.float64(0.9333333333333333), 29: np.float64(0.8229665071770335)}
Micro-average F1 score: 0.7613526570048309
Weighted-average F1 score: 0.7641358781412441
F1 score per class: {32: np.float64(0.642570281124498), 6: np.float64(0.7913043478260869), 19: np.float64(0.2153846153846154), 24: np.float64(0.7311827956989247), 26: np.float64(0.95), 29: np.float64(0.822429906542056)}
Micro-average F1 score: 0.75
Weighted-average F1 score: 0.7354222744471571
F1 score per class: {32: np.float64(0.6502057613168725), 6: np.float64(0.7947598253275109), 19: np.float64(0.27450980392156865), 24: np.float64(0.73224043715847), 26: np.float64(0.9547738693467337), 29: np.float64(0.822429906542056)}
Micro-average F1 score: 0.7631814119749777
Weighted-average F1 score: 0.7547717862899291

F1 score per class: {32: np.float64(0.42105263157894735), 6: np.float64(0.75), 19: np.float64(0.18518518518518517), 24: np.float64(0.6839378238341969), 26: np.float64(0.8544600938967136), 29: np.float64(0.6490566037735849)}
Micro-average F1 score: 0.6401299756295694
Weighted-average F1 score: 0.6294753875993301
F1 score per class: {32: np.float64(0.431266846361186), 6: np.float64(0.728), 19: np.float64(0.11764705882352941), 24: np.float64(0.6570048309178744), 26: np.float64(0.852017937219731), 29: np.float64(0.6494464944649446)}
Micro-average F1 score: 0.5954198473282443
Weighted-average F1 score: 0.5678317898643584
F1 score per class: {32: np.float64(0.4388888888888889), 6: np.float64(0.7338709677419355), 19: np.float64(0.1590909090909091), 24: np.float64(0.6568627450980392), 26: np.float64(0.8597285067873304), 29: np.float64(0.6470588235294118)}
Micro-average F1 score: 0.6130653266331658
Weighted-average F1 score: 0.5914232804934892

F1 score per class: {32: np.float64(0.42105263157894735), 6: np.float64(0.75), 19: np.float64(0.18518518518518517), 24: np.float64(0.6839378238341969), 26: np.float64(0.8544600938967136), 29: np.float64(0.6490566037735849)}
Micro-average F1 score: 0.6401299756295694
Weighted-average F1 score: 0.6294753875993301
F1 score per class: {32: np.float64(0.431266846361186), 6: np.float64(0.728), 19: np.float64(0.11764705882352941), 24: np.float64(0.6570048309178744), 26: np.float64(0.852017937219731), 29: np.float64(0.6494464944649446)}
Micro-average F1 score: 0.5954198473282443
Weighted-average F1 score: 0.5678317898643584
F1 score per class: {32: np.float64(0.4388888888888889), 6: np.float64(0.7338709677419355), 19: np.float64(0.1590909090909091), 24: np.float64(0.6568627450980392), 26: np.float64(0.8597285067873304), 29: np.float64(0.6470588235294118)}
Micro-average F1 score: 0.6130653266331658
Weighted-average F1 score: 0.5914232804934892
cur_acc_wo_na:  ['0.7614']
his_acc_wo_na:  ['0.7614']
cur_acc des_wo_na:  ['0.7500']
his_acc des_wo_na:  ['0.7500']
cur_acc rrf_wo_na:  ['0.7632']
his_acc rrf_wo_na:  ['0.7632']
cur_acc_w_na:  ['0.6401']
his_acc_w_na:  ['0.6401']
cur_acc des_w_na:  ['0.5954']
his_acc des_w_na:  ['0.5954']
cur_acc rrf_w_na:  ['0.6131']
his_acc rrf_w_na:  ['0.6131']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 94.0193850CurrentTrain: epoch  0, batch     1 | loss: 90.0727752CurrentTrain: epoch  0, batch     2 | loss: 143.0624404CurrentTrain: epoch  0, batch     3 | loss: 53.5508339CurrentTrain: epoch  1, batch     0 | loss: 74.4382458CurrentTrain: epoch  1, batch     1 | loss: 88.1419872CurrentTrain: epoch  1, batch     2 | loss: 104.3026403CurrentTrain: epoch  1, batch     3 | loss: 72.3871200CurrentTrain: epoch  2, batch     0 | loss: 106.2196553CurrentTrain: epoch  2, batch     1 | loss: 82.4973992CurrentTrain: epoch  2, batch     2 | loss: 83.4301184CurrentTrain: epoch  2, batch     3 | loss: 85.7261477CurrentTrain: epoch  3, batch     0 | loss: 81.6478486CurrentTrain: epoch  3, batch     1 | loss: 70.9914489CurrentTrain: epoch  3, batch     2 | loss: 99.3619278CurrentTrain: epoch  3, batch     3 | loss: 85.4026288CurrentTrain: epoch  4, batch     0 | loss: 98.0322442CurrentTrain: epoch  4, batch     1 | loss: 68.9911988CurrentTrain: epoch  4, batch     2 | loss: 68.7210784CurrentTrain: epoch  4, batch     3 | loss: 57.1898355CurrentTrain: epoch  5, batch     0 | loss: 80.8806583CurrentTrain: epoch  5, batch     1 | loss: 70.9737334CurrentTrain: epoch  5, batch     2 | loss: 65.2408300CurrentTrain: epoch  5, batch     3 | loss: 54.4095438CurrentTrain: epoch  6, batch     0 | loss: 79.1671611CurrentTrain: epoch  6, batch     1 | loss: 75.3421142CurrentTrain: epoch  6, batch     2 | loss: 65.2858557CurrentTrain: epoch  6, batch     3 | loss: 86.1183393CurrentTrain: epoch  7, batch     0 | loss: 97.6359349CurrentTrain: epoch  7, batch     1 | loss: 63.7555245CurrentTrain: epoch  7, batch     2 | loss: 77.5032256CurrentTrain: epoch  7, batch     3 | loss: 82.3093468CurrentTrain: epoch  8, batch     0 | loss: 64.3286985CurrentTrain: epoch  8, batch     1 | loss: 77.8953477CurrentTrain: epoch  8, batch     2 | loss: 78.9604984CurrentTrain: epoch  8, batch     3 | loss: 63.2076244CurrentTrain: epoch  9, batch     0 | loss: 64.2540449CurrentTrain: epoch  9, batch     1 | loss: 75.9835015CurrentTrain: epoch  9, batch     2 | loss: 80.2675107CurrentTrain: epoch  9, batch     3 | loss: 43.3710420
MemoryTrain:  epoch  0, batch     0 | loss: 2.5114282MemoryTrain:  epoch  1, batch     0 | loss: 2.2052420MemoryTrain:  epoch  2, batch     0 | loss: 1.8261487MemoryTrain:  epoch  3, batch     0 | loss: 1.4150238MemoryTrain:  epoch  4, batch     0 | loss: 1.2501294MemoryTrain:  epoch  5, batch     0 | loss: 1.0603829MemoryTrain:  epoch  6, batch     0 | loss: 0.9225646MemoryTrain:  epoch  7, batch     0 | loss: 0.7776388MemoryTrain:  epoch  8, batch     0 | loss: 0.6587607MemoryTrain:  epoch  9, batch     0 | loss: 0.5583924

F1 score per class: {32: np.float64(0.0), 35: np.float64(0.64), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.5277777777777778), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.8316831683168316), 26: np.float64(0.5811965811965812), 29: np.float64(0.4)}
Micro-average F1 score: 0.5851063829787234
Weighted-average F1 score: 0.55810239485487
F1 score per class: {32: np.float64(0.0), 35: np.float64(0.7), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.7878787878787878), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.8035714285714286), 26: np.float64(0.6434782608695652), 29: np.float64(0.6060606060606061)}
Micro-average F1 score: 0.6420824295010846
Weighted-average F1 score: 0.5825760290434203
F1 score per class: {32: np.float64(0.0), 35: np.float64(0.6666666666666666), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.7058823529411765), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.8245614035087719), 26: np.float64(0.592), 29: np.float64(0.7547169811320755)}
Micro-average F1 score: 0.6484018264840182
Weighted-average F1 score: 0.598830143163488

F1 score per class: {32: np.float64(0.6440677966101694), 35: np.float64(0.32), 37: np.float64(0.7889908256880734), 6: np.float64(0.2), 38: np.float64(0.5277777777777778), 15: np.float64(0.7555555555555555), 19: np.float64(0.90625), 24: np.float64(0.8), 25: np.float64(0.6268656716417911), 26: np.float64(0.4121212121212121), 29: np.float64(0.4)}
Micro-average F1 score: 0.6741871267418713
Weighted-average F1 score: 0.6654463398339742
F1 score per class: {32: np.float64(0.5925925925925926), 35: np.float64(0.3888888888888889), 37: np.float64(0.7678571428571429), 6: np.float64(0.28125), 38: np.float64(0.7878787878787878), 15: np.float64(0.6834170854271356), 19: np.float64(0.9253731343283582), 24: np.float64(0.8), 25: np.float64(0.5555555555555556), 26: np.float64(0.48366013071895425), 29: np.float64(0.45977011494252873)}
Micro-average F1 score: 0.6650887573964497
Weighted-average F1 score: 0.6456523318496702
F1 score per class: {32: np.float64(0.5860805860805861), 35: np.float64(0.32653061224489793), 37: np.float64(0.7782805429864253), 6: np.float64(0.2857142857142857), 38: np.float64(0.7058823529411765), 15: np.float64(0.7010309278350515), 19: np.float64(0.9292929292929293), 24: np.float64(0.8), 25: np.float64(0.5875), 26: np.float64(0.43529411764705883), 29: np.float64(0.6666666666666666)}
Micro-average F1 score: 0.6719512195121952
Weighted-average F1 score: 0.6543655179552261

F1 score per class: {32: np.float64(0.0), 35: np.float64(0.41025641025641024), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.48717948717948717), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.6942148760330579), 26: np.float64(0.5354330708661418), 29: np.float64(0.3181818181818182)}
Micro-average F1 score: 0.47413793103448276
Weighted-average F1 score: 0.43393182024850646
F1 score per class: {32: np.float64(0.0), 35: np.float64(0.56), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.7090909090909091), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.6521739130434783), 26: np.float64(0.5692307692307692), 29: np.float64(0.41237113402061853)}
Micro-average F1 score: 0.4925124792013311
Weighted-average F1 score: 0.43641541313907967
F1 score per class: {32: np.float64(0.0), 35: np.float64(0.45714285714285713), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.631578947368421), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.6811594202898551), 26: np.float64(0.524822695035461), 29: np.float64(0.5063291139240507)}
Micro-average F1 score: 0.5008818342151675
Weighted-average F1 score: 0.4540457891765843

F1 score per class: {32: np.float64(0.4550898203592814), 35: np.float64(0.16161616161616163), 37: np.float64(0.7226890756302521), 6: np.float64(0.15384615384615385), 38: np.float64(0.48717948717948717), 15: np.float64(0.6699507389162561), 19: np.float64(0.7909090909090909), 24: np.float64(0.6638297872340425), 25: np.float64(0.4444444444444444), 26: np.float64(0.30493273542600896), 29: np.float64(0.2857142857142857)}
Micro-average F1 score: 0.5327739905610908
Weighted-average F1 score: 0.5110031920742044
F1 score per class: {32: np.float64(0.3747072599531616), 35: np.float64(0.32558139534883723), 37: np.float64(0.7078189300411523), 6: np.float64(0.14173228346456693), 38: np.float64(0.7027027027027027), 15: np.float64(0.5938864628820961), 19: np.float64(0.7815126050420168), 24: np.float64(0.6527196652719666), 25: np.float64(0.375), 26: np.float64(0.36097560975609755), 29: np.float64(0.25477707006369427)}
Micro-average F1 score: 0.49756529437804337
Weighted-average F1 score: 0.46926667372559755
F1 score per class: {32: np.float64(0.37037037037037035), 35: np.float64(0.20253164556962025), 37: np.float64(0.7107438016528925), 6: np.float64(0.1724137931034483), 38: np.float64(0.625), 15: np.float64(0.6181818181818182), 19: np.float64(0.8034934497816594), 24: np.float64(0.6527196652719666), 25: np.float64(0.4), 26: np.float64(0.3274336283185841), 29: np.float64(0.35714285714285715)}
Micro-average F1 score: 0.5083025830258303
Weighted-average F1 score: 0.4822458985807151
cur_acc_wo_na:  ['0.7614', '0.5851']
his_acc_wo_na:  ['0.7614', '0.6742']
cur_acc des_wo_na:  ['0.7500', '0.6421']
his_acc des_wo_na:  ['0.7500', '0.6651']
cur_acc rrf_wo_na:  ['0.7632', '0.6484']
his_acc rrf_wo_na:  ['0.7632', '0.6720']
cur_acc_w_na:  ['0.6401', '0.4741']
his_acc_w_na:  ['0.6401', '0.5328']
cur_acc des_w_na:  ['0.5954', '0.4925']
his_acc des_w_na:  ['0.5954', '0.4976']
cur_acc rrf_w_na:  ['0.6131', '0.5009']
his_acc rrf_w_na:  ['0.6131', '0.5083']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 119.7753946CurrentTrain: epoch  0, batch     1 | loss: 85.9349769CurrentTrain: epoch  0, batch     2 | loss: 81.0278416CurrentTrain: epoch  0, batch     3 | loss: 51.3686823CurrentTrain: epoch  1, batch     0 | loss: 80.9364162CurrentTrain: epoch  1, batch     1 | loss: 72.7839096CurrentTrain: epoch  1, batch     2 | loss: 85.7899430CurrentTrain: epoch  1, batch     3 | loss: 85.9420444CurrentTrain: epoch  2, batch     0 | loss: 82.8971719CurrentTrain: epoch  2, batch     1 | loss: 82.8275000CurrentTrain: epoch  2, batch     2 | loss: 86.4010018CurrentTrain: epoch  2, batch     3 | loss: 49.9069060CurrentTrain: epoch  3, batch     0 | loss: 101.6647542CurrentTrain: epoch  3, batch     1 | loss: 85.8909465CurrentTrain: epoch  3, batch     2 | loss: 80.1666806CurrentTrain: epoch  3, batch     3 | loss: 58.1078133CurrentTrain: epoch  4, batch     0 | loss: 80.8562737CurrentTrain: epoch  4, batch     1 | loss: 98.8405474CurrentTrain: epoch  4, batch     2 | loss: 81.0624102CurrentTrain: epoch  4, batch     3 | loss: 56.8277628CurrentTrain: epoch  5, batch     0 | loss: 64.7799474CurrentTrain: epoch  5, batch     1 | loss: 82.3161358CurrentTrain: epoch  5, batch     2 | loss: 76.3648592CurrentTrain: epoch  5, batch     3 | loss: 50.1830793CurrentTrain: epoch  6, batch     0 | loss: 77.9439284CurrentTrain: epoch  6, batch     1 | loss: 67.0455852CurrentTrain: epoch  6, batch     2 | loss: 79.2252156CurrentTrain: epoch  6, batch     3 | loss: 58.1587898CurrentTrain: epoch  7, batch     0 | loss: 80.6486424CurrentTrain: epoch  7, batch     1 | loss: 73.8902552CurrentTrain: epoch  7, batch     2 | loss: 64.9611448CurrentTrain: epoch  7, batch     3 | loss: 71.2762462CurrentTrain: epoch  8, batch     0 | loss: 93.4937687CurrentTrain: epoch  8, batch     1 | loss: 93.4803992CurrentTrain: epoch  8, batch     2 | loss: 75.6482666CurrentTrain: epoch  8, batch     3 | loss: 53.6230156CurrentTrain: epoch  9, batch     0 | loss: 76.4204128CurrentTrain: epoch  9, batch     1 | loss: 97.6669565CurrentTrain: epoch  9, batch     2 | loss: 60.5893581CurrentTrain: epoch  9, batch     3 | loss: 45.7176785
MemoryTrain:  epoch  0, batch     0 | loss: 1.3146413MemoryTrain:  epoch  1, batch     0 | loss: 1.4230180MemoryTrain:  epoch  2, batch     0 | loss: 0.9920209MemoryTrain:  epoch  3, batch     0 | loss: 0.8140437MemoryTrain:  epoch  4, batch     0 | loss: 0.6772581MemoryTrain:  epoch  5, batch     0 | loss: 0.6409673MemoryTrain:  epoch  6, batch     0 | loss: 0.4652261MemoryTrain:  epoch  7, batch     0 | loss: 0.3926210MemoryTrain:  epoch  8, batch     0 | loss: 0.3793212MemoryTrain:  epoch  9, batch     0 | loss: 0.3154152

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.45), 35: np.float64(0.0), 36: np.float64(0.4657534246575342), 37: np.float64(0.0), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.9142857142857143), 15: np.float64(0.0), 20: np.float64(0.4), 24: np.float64(0.0), 26: np.float64(0.5274725274725275), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.4583333333333333
Weighted-average F1 score: 0.3778738541429919
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.6266666666666667), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.6588235294117647), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.7906976744186046), 20: np.float64(0.0), 24: np.float64(0.4444444444444444), 25: np.float64(0.0), 26: np.float64(0.6917293233082706), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.5668662674650699
Weighted-average F1 score: 0.4892490717428758
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.5874125874125874), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.6), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.0), 15: np.float64(0.8717948717948718), 19: np.float64(0.0), 20: np.float64(0.36363636363636365), 24: np.float64(0.0), 26: np.float64(0.6371681415929203), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.5301724137931034
Weighted-average F1 score: 0.44378704081693177

F1 score per class: {32: np.float64(0.5701754385964912), 33: np.float64(0.39705882352941174), 35: np.float64(0.48484848484848486), 36: np.float64(0.8076923076923077), 37: np.float64(0.4358974358974359), 6: np.float64(0.26666666666666666), 38: np.float64(0.4225352112676056), 8: np.float64(0.7157894736842105), 15: np.float64(0.8923076923076924), 19: np.float64(0.9142857142857143), 20: np.float64(0.7878787878787878), 24: np.float64(0.2857142857142857), 25: np.float64(0.5208333333333334), 26: np.float64(0.46153846153846156), 29: np.float64(0.275), 30: np.float64(0.0)}
Micro-average F1 score: 0.6126436781609196
Weighted-average F1 score: 0.6420971692778261
F1 score per class: {32: np.float64(0.6259541984732825), 33: np.float64(0.5164835164835165), 35: np.float64(0.56), 36: np.float64(0.7555555555555555), 37: np.float64(0.5833333333333334), 6: np.float64(0.2857142857142857), 38: np.float64(0.6808510638297872), 8: np.float64(0.6699029126213593), 15: np.float64(0.8756218905472637), 19: np.float64(0.5151515151515151), 20: np.float64(0.7904761904761904), 24: np.float64(0.16), 25: np.float64(0.6131386861313869), 26: np.float64(0.47668393782383417), 29: np.float64(0.28), 30: np.float64(0.4897959183673469)}
Micro-average F1 score: 0.6181818181818182
Weighted-average F1 score: 0.6108562933424483
F1 score per class: {32: np.float64(0.6070038910505836), 33: np.float64(0.48), 35: np.float64(0.5161290322580645), 36: np.float64(0.7359307359307359), 37: np.float64(0.5517241379310345), 6: np.float64(0.3157894736842105), 38: np.float64(0.6511627906976745), 8: np.float64(0.6934673366834171), 15: np.float64(0.8979591836734694), 19: np.float64(0.6938775510204082), 20: np.float64(0.7980769230769231), 24: np.float64(0.14814814814814814), 25: np.float64(0.6511627906976745), 26: np.float64(0.4645161290322581), 29: np.float64(0.3125), 30: np.float64(0.34146341463414637)}
Micro-average F1 score: 0.6220472440944882
Weighted-average F1 score: 0.6195799242093825

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.39705882352941174), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.41975308641975306), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.8648648648648649), 20: np.float64(0.0), 24: np.float64(0.34782608695652173), 25: np.float64(0.0), 26: np.float64(0.4528301886792453), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.35772357723577236
Weighted-average F1 score: 0.27213125205236255
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.49214659685863876), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.5333333333333333), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.7083333333333334), 20: np.float64(0.0), 24: np.float64(0.3333333333333333), 25: np.float64(0.0), 26: np.float64(0.5227272727272727), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.39664804469273746
Weighted-average F1 score: 0.33754871268958814
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.4745762711864407), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.4948453608247423), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.8292682926829268), 20: np.float64(0.0), 24: np.float64(0.25), 25: np.float64(0.0), 26: np.float64(0.4931506849315068), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.3778801843317972
Weighted-average F1 score: 0.30900864234025516

F1 score per class: {32: np.float64(0.39156626506024095), 33: np.float64(0.33962264150943394), 35: np.float64(0.3137254901960784), 36: np.float64(0.7400881057268722), 37: np.float64(0.288135593220339), 6: np.float64(0.21621621621621623), 38: np.float64(0.39473684210526316), 8: np.float64(0.6267281105990783), 15: np.float64(0.7565217391304347), 19: np.float64(0.7804878048780488), 20: np.float64(0.6046511627906976), 24: np.float64(0.1951219512195122), 25: np.float64(0.3875968992248062), 26: np.float64(0.3779527559055118), 29: np.float64(0.2558139534883721), 30: np.float64(0.0)}
Micro-average F1 score: 0.4912442396313364
Weighted-average F1 score: 0.4970356330935655
F1 score per class: {32: np.float64(0.41624365482233505), 33: np.float64(0.35471698113207545), 35: np.float64(0.4), 36: np.float64(0.6772908366533864), 37: np.float64(0.3708609271523179), 6: np.float64(0.15730337078651685), 38: np.float64(0.6153846153846154), 8: np.float64(0.575), 15: np.float64(0.7183673469387755), 19: np.float64(0.4146341463414634), 20: np.float64(0.6102941176470589), 24: np.float64(0.1095890410958904), 25: np.float64(0.417910447761194), 26: np.float64(0.35384615384615387), 29: np.float64(0.2204724409448819), 30: np.float64(0.3037974683544304)}
Micro-average F1 score: 0.46234309623430964
Weighted-average F1 score: 0.45005468998380466
F1 score per class: {32: np.float64(0.40625), 33: np.float64(0.34710743801652894), 35: np.float64(0.34782608695652173), 36: np.float64(0.6614785992217899), 37: np.float64(0.35036496350364965), 6: np.float64(0.19672131147540983), 38: np.float64(0.5957446808510638), 8: np.float64(0.6), 15: np.float64(0.7521367521367521), 19: np.float64(0.576271186440678), 20: np.float64(0.6125461254612546), 24: np.float64(0.1), 25: np.float64(0.45901639344262296), 26: np.float64(0.3564356435643564), 29: np.float64(0.26548672566371684), 30: np.float64(0.2)}
Micro-average F1 score: 0.4746526473901615
Weighted-average F1 score: 0.4642221420350784
cur_acc_wo_na:  ['0.7614', '0.5851', '0.4583']
his_acc_wo_na:  ['0.7614', '0.6742', '0.6126']
cur_acc des_wo_na:  ['0.7500', '0.6421', '0.5669']
his_acc des_wo_na:  ['0.7500', '0.6651', '0.6182']
cur_acc rrf_wo_na:  ['0.7632', '0.6484', '0.5302']
his_acc rrf_wo_na:  ['0.7632', '0.6720', '0.6220']
cur_acc_w_na:  ['0.6401', '0.4741', '0.3577']
his_acc_w_na:  ['0.6401', '0.5328', '0.4912']
cur_acc des_w_na:  ['0.5954', '0.4925', '0.3966']
his_acc des_w_na:  ['0.5954', '0.4976', '0.4623']
cur_acc rrf_w_na:  ['0.6131', '0.5009', '0.3779']
his_acc rrf_w_na:  ['0.6131', '0.5083', '0.4747']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 100.7813156CurrentTrain: epoch  0, batch     1 | loss: 142.5208336CurrentTrain: epoch  0, batch     2 | loss: 93.5665746CurrentTrain: epoch  0, batch     3 | loss: 85.0941137CurrentTrain: epoch  0, batch     4 | loss: 65.7630873CurrentTrain: epoch  1, batch     0 | loss: 76.4437201CurrentTrain: epoch  1, batch     1 | loss: 108.7627811CurrentTrain: epoch  1, batch     2 | loss: 91.8134910CurrentTrain: epoch  1, batch     3 | loss: 73.9659909CurrentTrain: epoch  1, batch     4 | loss: 111.1801717CurrentTrain: epoch  2, batch     0 | loss: 107.2514032CurrentTrain: epoch  2, batch     1 | loss: 76.5263294CurrentTrain: epoch  2, batch     2 | loss: 86.1933238CurrentTrain: epoch  2, batch     3 | loss: 86.6531651CurrentTrain: epoch  2, batch     4 | loss: 47.6424491CurrentTrain: epoch  3, batch     0 | loss: 129.9956934CurrentTrain: epoch  3, batch     1 | loss: 98.7997935CurrentTrain: epoch  3, batch     2 | loss: 83.2406596CurrentTrain: epoch  3, batch     3 | loss: 85.5129265CurrentTrain: epoch  3, batch     4 | loss: 57.3020773CurrentTrain: epoch  4, batch     0 | loss: 86.7852755CurrentTrain: epoch  4, batch     1 | loss: 84.1363235CurrentTrain: epoch  4, batch     2 | loss: 79.1796780CurrentTrain: epoch  4, batch     3 | loss: 98.5061206CurrentTrain: epoch  4, batch     4 | loss: 55.7006732CurrentTrain: epoch  5, batch     0 | loss: 66.4048790CurrentTrain: epoch  5, batch     1 | loss: 80.2738876CurrentTrain: epoch  5, batch     2 | loss: 123.5301415CurrentTrain: epoch  5, batch     3 | loss: 105.5636034CurrentTrain: epoch  5, batch     4 | loss: 68.2997258CurrentTrain: epoch  6, batch     0 | loss: 70.7493326CurrentTrain: epoch  6, batch     1 | loss: 80.5560306CurrentTrain: epoch  6, batch     2 | loss: 96.5836956CurrentTrain: epoch  6, batch     3 | loss: 80.6598329CurrentTrain: epoch  6, batch     4 | loss: 69.8861145CurrentTrain: epoch  7, batch     0 | loss: 79.0345018CurrentTrain: epoch  7, batch     1 | loss: 95.6917581CurrentTrain: epoch  7, batch     2 | loss: 81.4079084CurrentTrain: epoch  7, batch     3 | loss: 98.4955463CurrentTrain: epoch  7, batch     4 | loss: 37.3118187CurrentTrain: epoch  8, batch     0 | loss: 80.7275610CurrentTrain: epoch  8, batch     1 | loss: 65.8884317CurrentTrain: epoch  8, batch     2 | loss: 67.1941937CurrentTrain: epoch  8, batch     3 | loss: 96.2306294CurrentTrain: epoch  8, batch     4 | loss: 68.6537464CurrentTrain: epoch  9, batch     0 | loss: 123.8992175CurrentTrain: epoch  9, batch     1 | loss: 93.9911235CurrentTrain: epoch  9, batch     2 | loss: 96.8001404CurrentTrain: epoch  9, batch     3 | loss: 64.8799162CurrentTrain: epoch  9, batch     4 | loss: 51.7473312
MemoryTrain:  epoch  0, batch     0 | loss: 1.6758066MemoryTrain:  epoch  1, batch     0 | loss: 1.2636533MemoryTrain:  epoch  2, batch     0 | loss: 1.1665729MemoryTrain:  epoch  3, batch     0 | loss: 1.0846786MemoryTrain:  epoch  4, batch     0 | loss: 0.7856442MemoryTrain:  epoch  5, batch     0 | loss: 0.7012162MemoryTrain:  epoch  6, batch     0 | loss: 0.6096342MemoryTrain:  epoch  7, batch     0 | loss: 0.4950673MemoryTrain:  epoch  8, batch     0 | loss: 0.4144013MemoryTrain:  epoch  9, batch     0 | loss: 0.3689925

F1 score per class: {32: np.float64(0.2430939226519337), 1: np.float64(0.6578947368421053), 34: np.float64(0.0), 3: np.float64(0.06818181818181818), 35: np.float64(0.0), 37: np.float64(0.5555555555555556), 33: np.float64(0.0), 6: np.float64(0.0), 14: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.6851851851851852), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.39667458432304037
Weighted-average F1 score: 0.34446590283416595
F1 score per class: {1: np.float64(0.2413793103448276), 3: np.float64(0.5408805031446541), 6: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.038461538461538464), 19: np.float64(0.0), 22: np.float64(0.5405405405405406), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6181818181818182), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0)}
Micro-average F1 score: 0.320962888665998
Weighted-average F1 score: 0.2669548006854687
F1 score per class: {32: np.float64(0.2413793103448276), 1: np.float64(0.5609756097560976), 34: np.float64(0.0), 3: np.float64(0.0), 35: np.float64(0.05504587155963303), 37: np.float64(0.0), 33: np.float64(0.5412844036697247), 6: np.float64(0.0), 36: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.6610169491525424), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.34890965732087226
Weighted-average F1 score: 0.29916466731898067

F1 score per class: {1: np.float64(0.19730941704035873), 3: np.float64(0.4444444444444444), 6: np.float64(0.5652173913043478), 8: np.float64(0.37168141592920356), 14: np.float64(0.058823529411764705), 15: np.float64(0.5833333333333334), 19: np.float64(0.7317073170731707), 20: np.float64(0.3283582089552239), 22: np.float64(0.5213270142180095), 24: np.float64(0.09090909090909091), 25: np.float64(0.36923076923076925), 26: np.float64(0.7052631578947368), 29: np.float64(0.864321608040201), 30: np.float64(0.8484848484848485), 32: np.float64(0.6188340807174888), 33: np.float64(0.21428571428571427), 34: np.float64(0.2971887550200803), 35: np.float64(0.11494252873563218), 36: np.float64(0.43010752688172044), 37: np.float64(0.16666666666666666), 38: np.float64(0.13333333333333333)}
Micro-average F1 score: 0.46897064288368634
Weighted-average F1 score: 0.46870268593448267
F1 score per class: {1: np.float64(0.19444444444444445), 3: np.float64(0.35537190082644626), 6: np.float64(0.6051660516605166), 8: np.float64(0.5054945054945055), 14: np.float64(0.03278688524590164), 15: np.float64(0.6363636363636364), 19: np.float64(0.6377952755905512), 20: np.float64(0.5168539325842697), 22: np.float64(0.4838709677419355), 24: np.float64(0.09090909090909091), 25: np.float64(0.6813186813186813), 26: np.float64(0.6766169154228856), 29: np.float64(0.8425925925925926), 30: np.float64(0.6545454545454545), 32: np.float64(0.5905511811023622), 33: np.float64(0.19230769230769232), 34: np.float64(0.3333333333333333), 35: np.float64(0.17777777777777778), 36: np.float64(0.5443786982248521), 37: np.float64(0.23300970873786409), 38: np.float64(0.34782608695652173)}
Micro-average F1 score: 0.47699004975124376
Weighted-average F1 score: 0.4663170406934609
F1 score per class: {1: np.float64(0.19004524886877827), 3: np.float64(0.36363636363636365), 6: np.float64(0.6136363636363636), 8: np.float64(0.4507042253521127), 14: np.float64(0.045112781954887216), 15: np.float64(0.5833333333333334), 19: np.float64(0.6666666666666666), 20: np.float64(0.48717948717948717), 22: np.float64(0.48760330578512395), 24: np.float64(0.11764705882352941), 25: np.float64(0.65), 26: np.float64(0.6974358974358974), 29: np.float64(0.8695652173913043), 30: np.float64(0.8947368421052632), 32: np.float64(0.5934959349593496), 33: np.float64(0.18604651162790697), 34: np.float64(0.30115830115830117), 35: np.float64(0.11764705882352941), 36: np.float64(0.5132743362831859), 37: np.float64(0.20454545454545456), 38: np.float64(0.2926829268292683)}
Micro-average F1 score: 0.4690873405299313
Weighted-average F1 score: 0.4533234736957469

F1 score per class: {32: np.float64(0.138801261829653), 1: np.float64(0.5128205128205128), 34: np.float64(0.0), 3: np.float64(0.05504587155963303), 35: np.float64(0.0), 37: np.float64(0.47619047619047616), 6: np.float64(0.0), 38: np.float64(0.0), 33: np.float64(0.0), 14: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.5441176470588235), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.2825719120135364
Weighted-average F1 score: 0.24419916589300722
F1 score per class: {1: np.float64(0.13636363636363635), 3: np.float64(0.4056603773584906), 6: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.030303030303030304), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.44776119402985076), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.4657534246575342), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.21993127147766323
Weighted-average F1 score: 0.18746807861390866
F1 score per class: {1: np.float64(0.13636363636363635), 3: np.float64(0.4088888888888889), 6: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.04477611940298507), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.43703703703703706), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.5131578947368421), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.24103299856527977
Weighted-average F1 score: 0.21100628334338348

F1 score per class: {1: np.float64(0.10784313725490197), 3: np.float64(0.31347962382445144), 6: np.float64(0.3693181818181818), 8: np.float64(0.328125), 14: np.float64(0.04316546762589928), 15: np.float64(0.3888888888888889), 19: np.float64(0.6521739130434783), 20: np.float64(0.2558139534883721), 22: np.float64(0.41825095057034223), 24: np.float64(0.08333333333333333), 25: np.float64(0.34782608695652173), 26: np.float64(0.6203703703703703), 29: np.float64(0.7350427350427351), 30: np.float64(0.8), 32: np.float64(0.4842105263157895), 33: np.float64(0.18181818181818182), 34: np.float64(0.2215568862275449), 35: np.float64(0.08928571428571429), 36: np.float64(0.35714285714285715), 37: np.float64(0.16), 38: np.float64(0.09523809523809523)}
Micro-average F1 score: 0.35730464326160816
Weighted-average F1 score: 0.34269380383657977
F1 score per class: {1: np.float64(0.10687022900763359), 3: np.float64(0.23756906077348067), 6: np.float64(0.3904761904761905), 8: np.float64(0.37551020408163266), 14: np.float64(0.024539877300613498), 15: np.float64(0.4666666666666667), 19: np.float64(0.5510204081632653), 20: np.float64(0.3194444444444444), 22: np.float64(0.36585365853658536), 24: np.float64(0.06557377049180328), 25: np.float64(0.6138613861386139), 26: np.float64(0.5787234042553191), 29: np.float64(0.674074074074074), 30: np.float64(0.5217391304347826), 32: np.float64(0.43103448275862066), 33: np.float64(0.125), 34: np.float64(0.23208191126279865), 35: np.float64(0.11650485436893204), 36: np.float64(0.40350877192982454), 37: np.float64(0.1935483870967742), 38: np.float64(0.2)}
Micro-average F1 score: 0.34286991506481895
Weighted-average F1 score: 0.3300548447759041
F1 score per class: {1: np.float64(0.105), 3: np.float64(0.2402088772845953), 6: np.float64(0.3960880195599022), 8: np.float64(0.38095238095238093), 14: np.float64(0.03428571428571429), 15: np.float64(0.4375), 19: np.float64(0.5787545787545788), 20: np.float64(0.3333333333333333), 22: np.float64(0.36419753086419754), 24: np.float64(0.1), 25: np.float64(0.5977011494252874), 26: np.float64(0.6044444444444445), 29: np.float64(0.7003891050583657), 30: np.float64(0.8292682926829268), 32: np.float64(0.43582089552238806), 33: np.float64(0.11940298507462686), 34: np.float64(0.21311475409836064), 35: np.float64(0.08333333333333333), 36: np.float64(0.40559440559440557), 37: np.float64(0.18181818181818182), 38: np.float64(0.16)}
Micro-average F1 score: 0.3429801482898828
Weighted-average F1 score: 0.3248877888430663
cur_acc_wo_na:  ['0.7614', '0.5851', '0.4583', '0.3967']
his_acc_wo_na:  ['0.7614', '0.6742', '0.6126', '0.4690']
cur_acc des_wo_na:  ['0.7500', '0.6421', '0.5669', '0.3210']
his_acc des_wo_na:  ['0.7500', '0.6651', '0.6182', '0.4770']
cur_acc rrf_wo_na:  ['0.7632', '0.6484', '0.5302', '0.3489']
his_acc rrf_wo_na:  ['0.7632', '0.6720', '0.6220', '0.4691']
cur_acc_w_na:  ['0.6401', '0.4741', '0.3577', '0.2826']
his_acc_w_na:  ['0.6401', '0.5328', '0.4912', '0.3573']
cur_acc des_w_na:  ['0.5954', '0.4925', '0.3966', '0.2199']
his_acc des_w_na:  ['0.5954', '0.4976', '0.4623', '0.3429']
cur_acc rrf_w_na:  ['0.6131', '0.5009', '0.3779', '0.2410']
his_acc rrf_w_na:  ['0.6131', '0.5083', '0.4747', '0.3430']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 151.5190412CurrentTrain: epoch  0, batch     1 | loss: 99.1845250CurrentTrain: epoch  0, batch     2 | loss: 87.7459386CurrentTrain: epoch  0, batch     3 | loss: 91.8697769CurrentTrain: epoch  0, batch     4 | loss: 121.3182277CurrentTrain: epoch  1, batch     0 | loss: 91.7964936CurrentTrain: epoch  1, batch     1 | loss: 105.9958420CurrentTrain: epoch  1, batch     2 | loss: 95.5378588CurrentTrain: epoch  1, batch     3 | loss: 103.9531808CurrentTrain: epoch  1, batch     4 | loss: 65.8802164CurrentTrain: epoch  2, batch     0 | loss: 90.6730807CurrentTrain: epoch  2, batch     1 | loss: 68.8722254CurrentTrain: epoch  2, batch     2 | loss: 105.9785411CurrentTrain: epoch  2, batch     3 | loss: 101.2919093CurrentTrain: epoch  2, batch     4 | loss: 116.6959351CurrentTrain: epoch  3, batch     0 | loss: 71.4583114CurrentTrain: epoch  3, batch     1 | loss: 98.1388181CurrentTrain: epoch  3, batch     2 | loss: 129.3333196CurrentTrain: epoch  3, batch     3 | loss: 86.2836247CurrentTrain: epoch  3, batch     4 | loss: 81.1043884CurrentTrain: epoch  4, batch     0 | loss: 82.0155408CurrentTrain: epoch  4, batch     1 | loss: 97.3646946CurrentTrain: epoch  4, batch     2 | loss: 123.0387044CurrentTrain: epoch  4, batch     3 | loss: 86.3004174CurrentTrain: epoch  4, batch     4 | loss: 53.4068544CurrentTrain: epoch  5, batch     0 | loss: 126.1944057CurrentTrain: epoch  5, batch     1 | loss: 84.8004476CurrentTrain: epoch  5, batch     2 | loss: 68.4775366CurrentTrain: epoch  5, batch     3 | loss: 99.2448103CurrentTrain: epoch  5, batch     4 | loss: 49.0406617CurrentTrain: epoch  6, batch     0 | loss: 84.1472148CurrentTrain: epoch  6, batch     1 | loss: 79.1814933CurrentTrain: epoch  6, batch     2 | loss: 84.0317901CurrentTrain: epoch  6, batch     3 | loss: 79.4663353CurrentTrain: epoch  6, batch     4 | loss: 63.2151064CurrentTrain: epoch  7, batch     0 | loss: 125.4614930CurrentTrain: epoch  7, batch     1 | loss: 98.1397849CurrentTrain: epoch  7, batch     2 | loss: 77.7889233CurrentTrain: epoch  7, batch     3 | loss: 80.4276072CurrentTrain: epoch  7, batch     4 | loss: 61.1691220CurrentTrain: epoch  8, batch     0 | loss: 97.0692978CurrentTrain: epoch  8, batch     1 | loss: 67.3156944CurrentTrain: epoch  8, batch     2 | loss: 123.0094656CurrentTrain: epoch  8, batch     3 | loss: 80.2118533CurrentTrain: epoch  8, batch     4 | loss: 40.4997741CurrentTrain: epoch  9, batch     0 | loss: 65.2152109CurrentTrain: epoch  9, batch     1 | loss: 95.5623472CurrentTrain: epoch  9, batch     2 | loss: 74.7037697CurrentTrain: epoch  9, batch     3 | loss: 96.1012818CurrentTrain: epoch  9, batch     4 | loss: 108.9204028
MemoryTrain:  epoch  0, batch     0 | loss: 1.1530865MemoryTrain:  epoch  1, batch     0 | loss: 0.8879264MemoryTrain:  epoch  2, batch     0 | loss: 0.7076263MemoryTrain:  epoch  3, batch     0 | loss: 0.6058008MemoryTrain:  epoch  4, batch     0 | loss: 0.4997988MemoryTrain:  epoch  5, batch     0 | loss: 0.4192064MemoryTrain:  epoch  6, batch     0 | loss: 0.3667195MemoryTrain:  epoch  7, batch     0 | loss: 0.2950292MemoryTrain:  epoch  8, batch     0 | loss: 0.2672979MemoryTrain:  epoch  9, batch     0 | loss: 0.2495750

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.8636363636363636), 34: np.float64(0.0), 3: np.float64(0.417910447761194), 37: np.float64(0.0), 6: np.float64(0.0), 5: np.float64(0.746268656716418), 10: np.float64(0.0), 14: np.float64(0.2711864406779661), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5473684210526316
Weighted-average F1 score: 0.5150454450804999
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.7376425855513308), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.5342465753424658), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.7272727272727273), 17: np.float64(0.0), 18: np.float64(0.2692307692307692), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.4868804664723032
Weighted-average F1 score: 0.4269057649534148
F1 score per class: {3: np.float64(0.0), 5: np.float64(0.7607843137254902), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.527027027027027), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.7164179104477612), 17: np.float64(0.0), 18: np.float64(0.36363636363636365), 19: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.513595166163142
Weighted-average F1 score: 0.45666265066520717

F1 score per class: {1: np.float64(0.1885245901639344), 3: np.float64(0.43373493975903615), 5: np.float64(0.7089552238805971), 6: np.float64(0.4307692307692308), 8: np.float64(0.09411764705882353), 10: np.float64(0.3027027027027027), 14: np.float64(0.06299212598425197), 15: np.float64(0.5161290322580645), 16: np.float64(0.6329113924050633), 17: np.float64(0.0), 18: np.float64(0.125), 19: np.float64(0.6972477064220184), 20: np.float64(0.3380281690140845), 22: np.float64(0.5436893203883495), 24: np.float64(0.09523809523809523), 25: np.float64(0.36363636363636365), 26: np.float64(0.69), 29: np.float64(0.8082901554404145), 30: np.float64(0.8235294117647058), 32: np.float64(0.5916666666666667), 33: np.float64(0.2608695652173913), 34: np.float64(0.21875), 35: np.float64(0.13636363636363635), 36: np.float64(0.11267605633802817), 37: np.float64(0.16), 38: np.float64(0.0)}
Micro-average F1 score: 0.42801086628433443
Weighted-average F1 score: 0.4375504254954782
F1 score per class: {1: np.float64(0.17937219730941703), 3: np.float64(0.3206751054852321), 5: np.float64(0.5623188405797102), 6: np.float64(0.5448028673835126), 8: np.float64(0.37681159420289856), 10: np.float64(0.39195979899497485), 14: np.float64(0.0410958904109589), 15: np.float64(0.48), 16: np.float64(0.6153846153846154), 17: np.float64(0.0), 18: np.float64(0.2), 19: np.float64(0.6360153256704981), 20: np.float64(0.22535211267605634), 22: np.float64(0.4864864864864865), 24: np.float64(0.09090909090909091), 25: np.float64(0.40425531914893614), 26: np.float64(0.6425339366515838), 29: np.float64(0.8490566037735849), 30: np.float64(0.53125), 32: np.float64(0.5614035087719298), 33: np.float64(0.17142857142857143), 34: np.float64(0.25396825396825395), 35: np.float64(0.1897810218978102), 36: np.float64(0.5409836065573771), 37: np.float64(0.183206106870229), 38: np.float64(0.3508771929824561)}
Micro-average F1 score: 0.4352766798418972
Weighted-average F1 score: 0.43148376543123623
F1 score per class: {1: np.float64(0.17467248908296942), 3: np.float64(0.3406113537117904), 5: np.float64(0.5896656534954408), 6: np.float64(0.5411764705882353), 8: np.float64(0.2692307692307692), 10: np.float64(0.3436123348017621), 14: np.float64(0.07228915662650602), 15: np.float64(0.4375), 16: np.float64(0.5925925925925926), 17: np.float64(0.0), 18: np.float64(0.21978021978021978), 19: np.float64(0.656), 20: np.float64(0.2571428571428571), 22: np.float64(0.5542168674698795), 24: np.float64(0.10526315789473684), 25: np.float64(0.44155844155844154), 26: np.float64(0.6729857819905213), 29: np.float64(0.8431372549019608), 30: np.float64(0.8292682926829268), 32: np.float64(0.56), 33: np.float64(0.17647058823529413), 34: np.float64(0.25170068027210885), 35: np.float64(0.16129032258064516), 36: np.float64(0.2823529411764706), 37: np.float64(0.23255813953488372), 38: np.float64(0.15)}
Micro-average F1 score: 0.4317295188556567
Weighted-average F1 score: 0.42901304338588736

F1 score per class: {3: np.float64(0.0), 5: np.float64(0.6909090909090909), 6: np.float64(0.0), 10: np.float64(0.3684210526315789), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.4424778761061947), 17: np.float64(0.0), 18: np.float64(0.19753086419753085), 19: np.float64(0.0), 20: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.3847102342786683
Weighted-average F1 score: 0.34669907922885707
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.5689149560117303), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.47560975609756095), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.45714285714285713), 17: np.float64(0.0), 18: np.float64(0.23728813559322035), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.32270531400966185
Weighted-average F1 score: 0.27279786832389463
F1 score per class: {3: np.float64(0.0), 5: np.float64(0.5843373493975904), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.45614035087719296), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.4444444444444444), 17: np.float64(0.0), 18: np.float64(0.3125), 19: np.float64(0.0), 20: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.34517766497461927
Weighted-average F1 score: 0.2976818006194476

F1 score per class: {1: np.float64(0.10154525386313466), 3: np.float64(0.32727272727272727), 5: np.float64(0.4947916666666667), 6: np.float64(0.2847457627118644), 8: np.float64(0.09195402298850575), 10: np.float64(0.23236514522821577), 14: np.float64(0.05263157894736842), 15: np.float64(0.32), 16: np.float64(0.30864197530864196), 17: np.float64(0.0), 18: np.float64(0.07207207207207207), 19: np.float64(0.6031746031746031), 20: np.float64(0.24), 22: np.float64(0.41947565543071164), 24: np.float64(0.09090909090909091), 25: np.float64(0.34782608695652173), 26: np.float64(0.5872340425531914), 29: np.float64(0.6753246753246753), 30: np.float64(0.7777777777777778), 32: np.float64(0.45806451612903226), 33: np.float64(0.1875), 34: np.float64(0.1432225063938619), 35: np.float64(0.1111111111111111), 36: np.float64(0.10526315789473684), 37: np.float64(0.15), 38: np.float64(0.0)}
Micro-average F1 score: 0.31274812527569473
Weighted-average F1 score: 0.30567480873988817
F1 score per class: {1: np.float64(0.0966183574879227), 3: np.float64(0.2222222222222222), 5: np.float64(0.37093690248565964), 6: np.float64(0.32688172043010755), 8: np.float64(0.31137724550898205), 10: np.float64(0.2775800711743772), 14: np.float64(0.033707865168539325), 15: np.float64(0.3157894736842105), 16: np.float64(0.35555555555555557), 17: np.float64(0.0), 18: np.float64(0.14285714285714285), 19: np.float64(0.5123456790123457), 20: np.float64(0.15384615384615385), 22: np.float64(0.3564356435643564), 24: np.float64(0.0625), 25: np.float64(0.34545454545454546), 26: np.float64(0.5338345864661654), 29: np.float64(0.6593406593406593), 30: np.float64(0.41975308641975306), 32: np.float64(0.4134366925064599), 33: np.float64(0.09836065573770492), 34: np.float64(0.16161616161616163), 35: np.float64(0.12264150943396226), 36: np.float64(0.3548387096774194), 37: np.float64(0.11940298507462686), 38: np.float64(0.2127659574468085)}
Micro-average F1 score: 0.3000170270730461
Weighted-average F1 score: 0.29272478233881466
F1 score per class: {1: np.float64(0.09389671361502347), 3: np.float64(0.23853211009174313), 5: np.float64(0.3967280163599182), 6: np.float64(0.33093525179856115), 8: np.float64(0.23333333333333334), 10: np.float64(0.2468354430379747), 14: np.float64(0.05714285714285714), 15: np.float64(0.3181818181818182), 16: np.float64(0.3310344827586207), 17: np.float64(0.0), 18: np.float64(0.14705882352941177), 19: np.float64(0.5342019543973942), 20: np.float64(0.17647058823529413), 22: np.float64(0.41566265060240964), 24: np.float64(0.08888888888888889), 25: np.float64(0.41975308641975306), 26: np.float64(0.5634920634920635), 29: np.float64(0.6771653543307087), 30: np.float64(0.723404255319149), 32: np.float64(0.41509433962264153), 33: np.float64(0.1), 34: np.float64(0.15513626834381553), 35: np.float64(0.1092896174863388), 36: np.float64(0.23076923076923078), 37: np.float64(0.2), 38: np.float64(0.09523809523809523)}
Micro-average F1 score: 0.3033625730994152
Weighted-average F1 score: 0.2934910488530568
cur_acc_wo_na:  ['0.7614', '0.5851', '0.4583', '0.3967', '0.5474']
his_acc_wo_na:  ['0.7614', '0.6742', '0.6126', '0.4690', '0.4280']
cur_acc des_wo_na:  ['0.7500', '0.6421', '0.5669', '0.3210', '0.4869']
his_acc des_wo_na:  ['0.7500', '0.6651', '0.6182', '0.4770', '0.4353']
cur_acc rrf_wo_na:  ['0.7632', '0.6484', '0.5302', '0.3489', '0.5136']
his_acc rrf_wo_na:  ['0.7632', '0.6720', '0.6220', '0.4691', '0.4317']
cur_acc_w_na:  ['0.6401', '0.4741', '0.3577', '0.2826', '0.3847']
his_acc_w_na:  ['0.6401', '0.5328', '0.4912', '0.3573', '0.3127']
cur_acc des_w_na:  ['0.5954', '0.4925', '0.3966', '0.2199', '0.3227']
his_acc des_w_na:  ['0.5954', '0.4976', '0.4623', '0.3429', '0.3000']
cur_acc rrf_w_na:  ['0.6131', '0.5009', '0.3779', '0.2410', '0.3452']
his_acc rrf_w_na:  ['0.6131', '0.5083', '0.4747', '0.3430', '0.3034']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 107.5796697CurrentTrain: epoch  0, batch     1 | loss: 143.5433688CurrentTrain: epoch  0, batch     2 | loss: 113.0248959CurrentTrain: epoch  0, batch     3 | loss: 94.6256978CurrentTrain: epoch  1, batch     0 | loss: 144.6141859CurrentTrain: epoch  1, batch     1 | loss: 77.8312987CurrentTrain: epoch  1, batch     2 | loss: 104.0727594CurrentTrain: epoch  1, batch     3 | loss: 73.1285194CurrentTrain: epoch  2, batch     0 | loss: 105.1343509CurrentTrain: epoch  2, batch     1 | loss: 75.7224612CurrentTrain: epoch  2, batch     2 | loss: 101.7362634CurrentTrain: epoch  2, batch     3 | loss: 59.7824926CurrentTrain: epoch  3, batch     0 | loss: 70.9781275CurrentTrain: epoch  3, batch     1 | loss: 85.5594198CurrentTrain: epoch  3, batch     2 | loss: 72.3974184CurrentTrain: epoch  3, batch     3 | loss: 70.8193938CurrentTrain: epoch  4, batch     0 | loss: 83.8673095CurrentTrain: epoch  4, batch     1 | loss: 84.2412407CurrentTrain: epoch  4, batch     2 | loss: 85.5354234CurrentTrain: epoch  4, batch     3 | loss: 61.5793352CurrentTrain: epoch  5, batch     0 | loss: 98.5784598CurrentTrain: epoch  5, batch     1 | loss: 85.3318357CurrentTrain: epoch  5, batch     2 | loss: 122.8609588CurrentTrain: epoch  5, batch     3 | loss: 60.8792947CurrentTrain: epoch  6, batch     0 | loss: 84.0863817CurrentTrain: epoch  6, batch     1 | loss: 98.2131768CurrentTrain: epoch  6, batch     2 | loss: 98.6243562CurrentTrain: epoch  6, batch     3 | loss: 51.1982881CurrentTrain: epoch  7, batch     0 | loss: 64.7660895CurrentTrain: epoch  7, batch     1 | loss: 94.6483800CurrentTrain: epoch  7, batch     2 | loss: 97.3132722CurrentTrain: epoch  7, batch     3 | loss: 84.0256427CurrentTrain: epoch  8, batch     0 | loss: 75.1504015CurrentTrain: epoch  8, batch     1 | loss: 76.4811404CurrentTrain: epoch  8, batch     2 | loss: 71.0659496CurrentTrain: epoch  8, batch     3 | loss: 99.6821746CurrentTrain: epoch  9, batch     0 | loss: 64.9776004CurrentTrain: epoch  9, batch     1 | loss: 66.9241551CurrentTrain: epoch  9, batch     2 | loss: 93.4210410CurrentTrain: epoch  9, batch     3 | loss: 77.2896433
MemoryTrain:  epoch  0, batch     0 | loss: 0.8717254MemoryTrain:  epoch  1, batch     0 | loss: 0.7141202MemoryTrain:  epoch  2, batch     0 | loss: 0.5926380MemoryTrain:  epoch  3, batch     0 | loss: 0.5196043MemoryTrain:  epoch  4, batch     0 | loss: 0.4725683MemoryTrain:  epoch  5, batch     0 | loss: 0.3928052MemoryTrain:  epoch  6, batch     0 | loss: 0.3021105MemoryTrain:  epoch  7, batch     0 | loss: 0.2782113MemoryTrain:  epoch  8, batch     0 | loss: 0.2239781MemoryTrain:  epoch  9, batch     0 | loss: 0.1946460

F1 score per class: {0: np.float64(0.8767123287671232), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.907103825136612), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.32), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.5384615384615384), 23: np.float64(0.735632183908046), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0)}
Micro-average F1 score: 0.650887573964497
Weighted-average F1 score: 0.536530456397106
F1 score per class: {0: np.float64(0.75), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8795811518324608), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.36363636363636365), 14: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.5625), 22: np.float64(0.0), 23: np.float64(0.627906976744186), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.562396006655574
Weighted-average F1 score: 0.45544507898056524
F1 score per class: {0: np.float64(0.8292682926829268), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8983957219251337), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.2962962962962963), 14: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.59375), 23: np.float64(0.627906976744186), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0)}
Micro-average F1 score: 0.6032315978456014
Weighted-average F1 score: 0.49281347652747803

F1 score per class: {0: np.float64(0.6037735849056604), 1: np.float64(0.1864406779661017), 3: np.float64(0.4), 4: np.float64(0.907103825136612), 5: np.float64(0.6985294117647058), 6: np.float64(0.484304932735426), 8: np.float64(0.04819277108433735), 10: np.float64(0.2648401826484018), 13: np.float64(0.05405405405405406), 14: np.float64(0.0), 15: np.float64(0.5217391304347826), 16: np.float64(0.6984126984126984), 17: np.float64(0.09090909090909091), 18: np.float64(0.12195121951219512), 19: np.float64(0.6902654867256637), 20: np.float64(0.36363636363636365), 21: np.float64(0.14358974358974358), 22: np.float64(0.5066666666666667), 23: np.float64(0.64), 24: np.float64(0.0), 25: np.float64(0.36923076923076925), 26: np.float64(0.6407766990291263), 29: np.float64(0.7897435897435897), 30: np.float64(0.7894736842105263), 32: np.float64(0.5770750988142292), 33: np.float64(0.23076923076923078), 34: np.float64(0.127208480565371), 35: np.float64(0.1414141414141414), 36: np.float64(0.11267605633802817), 37: np.float64(0.17647058823529413), 38: np.float64(0.125)}
Micro-average F1 score: 0.4228204494937021
Weighted-average F1 score: 0.4116870860154093
F1 score per class: {0: np.float64(0.32286995515695066), 1: np.float64(0.1891891891891892), 3: np.float64(0.28859060402684567), 4: np.float64(0.8795811518324608), 5: np.float64(0.5791044776119403), 6: np.float64(0.5159010600706714), 8: np.float64(0.425531914893617), 10: np.float64(0.35106382978723405), 13: np.float64(0.07547169811320754), 14: np.float64(0.041379310344827586), 15: np.float64(0.631578947368421), 16: np.float64(0.6133333333333333), 17: np.float64(0.2222222222222222), 18: np.float64(0.11594202898550725), 19: np.float64(0.6332046332046332), 20: np.float64(0.358974358974359), 21: np.float64(0.16589861751152074), 22: np.float64(0.5110132158590308), 23: np.float64(0.54), 24: np.float64(0.1), 25: np.float64(0.4772727272727273), 26: np.float64(0.6063348416289592), 29: np.float64(0.822429906542056), 30: np.float64(0.5396825396825397), 32: np.float64(0.5486111111111112), 33: np.float64(0.20689655172413793), 34: np.float64(0.22009569377990432), 35: np.float64(0.21052631578947367), 36: np.float64(0.5210084033613446), 37: np.float64(0.21818181818181817), 38: np.float64(0.3870967741935484)}
Micro-average F1 score: 0.4307241523650063
Weighted-average F1 score: 0.41174649258396057
F1 score per class: {0: np.float64(0.4444444444444444), 1: np.float64(0.19574468085106383), 3: np.float64(0.3154121863799283), 4: np.float64(0.8983957219251337), 5: np.float64(0.6274509803921569), 6: np.float64(0.5291828793774319), 8: np.float64(0.09090909090909091), 10: np.float64(0.308411214953271), 13: np.float64(0.057971014492753624), 14: np.float64(0.05084745762711865), 15: np.float64(0.6), 16: np.float64(0.6301369863013698), 17: np.float64(0.20689655172413793), 18: np.float64(0.11764705882352941), 19: np.float64(0.627906976744186), 20: np.float64(0.425), 21: np.float64(0.15637860082304528), 22: np.float64(0.5875706214689266), 23: np.float64(0.5454545454545454), 24: np.float64(0.10526315789473684), 25: np.float64(0.4931506849315068), 26: np.float64(0.6210045662100456), 29: np.float64(0.8217821782178217), 30: np.float64(0.7391304347826086), 32: np.float64(0.5642857142857143), 33: np.float64(0.17142857142857143), 34: np.float64(0.20168067226890757), 35: np.float64(0.1889763779527559), 36: np.float64(0.2619047619047619), 37: np.float64(0.24096385542168675), 38: np.float64(0.21052631578947367)}
Micro-average F1 score: 0.42650011153245593
Weighted-average F1 score: 0.4102763071443833

F1 score per class: {0: np.float64(0.8533333333333334), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8736842105263158), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.16666666666666666), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.3684210526315789), 23: np.float64(0.5925925925925926), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0)}
Micro-average F1 score: 0.4940119760479042
Weighted-average F1 score: 0.3815893031189083
F1 score per class: {0: np.float64(0.6545454545454545), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.84), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.21621621621621623), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.4090909090909091), 22: np.float64(0.0), 23: np.float64(0.5346534653465347), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.4092009685230024
Weighted-average F1 score: 0.31500034001259375
F1 score per class: {0: np.float64(0.7472527472527473), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.865979381443299), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.16666666666666666), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.42696629213483145), 22: np.float64(0.0), 23: np.float64(0.5294117647058824), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.4397905759162304
Weighted-average F1 score: 0.33603321484674425

F1 score per class: {0: np.float64(0.423841059602649), 1: np.float64(0.09843400447427293), 3: np.float64(0.28865979381443296), 4: np.float64(0.8556701030927835), 5: np.float64(0.5121293800539084), 6: np.float64(0.3), 8: np.float64(0.047619047619047616), 10: np.float64(0.19078947368421054), 13: np.float64(0.026578073089700997), 14: np.float64(0.0), 15: np.float64(0.41379310344827586), 16: np.float64(0.4), 17: np.float64(0.043478260869565216), 18: np.float64(0.07633587786259542), 19: np.float64(0.6), 20: np.float64(0.25225225225225223), 21: np.float64(0.09271523178807947), 22: np.float64(0.4810126582278481), 23: np.float64(0.47058823529411764), 24: np.float64(0.0), 25: np.float64(0.35294117647058826), 26: np.float64(0.55), 29: np.float64(0.6581196581196581), 30: np.float64(0.7142857142857143), 32: np.float64(0.4207492795389049), 33: np.float64(0.16216216216216217), 34: np.float64(0.08237986270022883), 35: np.float64(0.1), 36: np.float64(0.1095890410958904), 37: np.float64(0.16), 38: np.float64(0.1)}
Micro-average F1 score: 0.30473478106087576
Weighted-average F1 score: 0.28376614431681985
F1 score per class: {0: np.float64(0.20809248554913296), 1: np.float64(0.1016949152542373), 3: np.float64(0.18259023354564755), 4: np.float64(0.8038277511961722), 5: np.float64(0.3943089430894309), 6: np.float64(0.3060796645702306), 8: np.float64(0.3314917127071823), 10: np.float64(0.24812030075187969), 13: np.float64(0.0392156862745098), 14: np.float64(0.03488372093023256), 15: np.float64(0.5), 16: np.float64(0.34074074074074073), 17: np.float64(0.08571428571428572), 18: np.float64(0.07407407407407407), 19: np.float64(0.5093167701863354), 20: np.float64(0.2222222222222222), 21: np.float64(0.10588235294117647), 22: np.float64(0.39322033898305087), 23: np.float64(0.4251968503937008), 24: np.float64(0.09090909090909091), 25: np.float64(0.4329896907216495), 26: np.float64(0.5056603773584906), 29: np.float64(0.6446886446886447), 30: np.float64(0.43037974683544306), 32: np.float64(0.3910891089108911), 33: np.float64(0.13333333333333333), 34: np.float64(0.14153846153846153), 35: np.float64(0.1285140562248996), 36: np.float64(0.3974358974358974), 37: np.float64(0.17777777777777778), 38: np.float64(0.2222222222222222)}
Micro-average F1 score: 0.2967128027681661
Weighted-average F1 score: 0.2791446509723463
F1 score per class: {0: np.float64(0.2918454935622318), 1: np.float64(0.1050228310502283), 3: np.float64(0.205607476635514), 4: np.float64(0.835820895522388), 5: np.float64(0.4164859002169197), 6: np.float64(0.3119266055045872), 8: np.float64(0.08602150537634409), 10: np.float64(0.21428571428571427), 13: np.float64(0.03018867924528302), 14: np.float64(0.043478260869565216), 15: np.float64(0.48), 16: np.float64(0.34074074074074073), 17: np.float64(0.08955223880597014), 18: np.float64(0.07518796992481203), 19: np.float64(0.5126582278481012), 20: np.float64(0.272), 21: np.float64(0.10052910052910052), 22: np.float64(0.5073170731707317), 23: np.float64(0.421875), 24: np.float64(0.09523809523809523), 25: np.float64(0.4675324675324675), 26: np.float64(0.5230769230769231), 29: np.float64(0.664), 30: np.float64(0.5666666666666667), 32: np.float64(0.40512820512820513), 33: np.float64(0.1016949152542373), 34: np.float64(0.13008130081300814), 35: np.float64(0.12698412698412698), 36: np.float64(0.22448979591836735), 37: np.float64(0.2127659574468085), 38: np.float64(0.14285714285714285)}
Micro-average F1 score: 0.2970789310130516
Weighted-average F1 score: 0.2779147195982429
cur_acc_wo_na:  ['0.7614', '0.5851', '0.4583', '0.3967', '0.5474', '0.6509']
his_acc_wo_na:  ['0.7614', '0.6742', '0.6126', '0.4690', '0.4280', '0.4228']
cur_acc des_wo_na:  ['0.7500', '0.6421', '0.5669', '0.3210', '0.4869', '0.5624']
his_acc des_wo_na:  ['0.7500', '0.6651', '0.6182', '0.4770', '0.4353', '0.4307']
cur_acc rrf_wo_na:  ['0.7632', '0.6484', '0.5302', '0.3489', '0.5136', '0.6032']
his_acc rrf_wo_na:  ['0.7632', '0.6720', '0.6220', '0.4691', '0.4317', '0.4265']
cur_acc_w_na:  ['0.6401', '0.4741', '0.3577', '0.2826', '0.3847', '0.4940']
his_acc_w_na:  ['0.6401', '0.5328', '0.4912', '0.3573', '0.3127', '0.3047']
cur_acc des_w_na:  ['0.5954', '0.4925', '0.3966', '0.2199', '0.3227', '0.4092']
his_acc des_w_na:  ['0.5954', '0.4976', '0.4623', '0.3429', '0.3000', '0.2967']
cur_acc rrf_w_na:  ['0.6131', '0.5009', '0.3779', '0.2410', '0.3452', '0.4398']
his_acc rrf_w_na:  ['0.6131', '0.5083', '0.4747', '0.3430', '0.3034', '0.2971']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 91.1450021CurrentTrain: epoch  0, batch     1 | loss: 120.6116251CurrentTrain: epoch  0, batch     2 | loss: 113.1453719CurrentTrain: epoch  0, batch     3 | loss: 118.0579818CurrentTrain: epoch  0, batch     4 | loss: 29.3975672CurrentTrain: epoch  1, batch     0 | loss: 93.2387041CurrentTrain: epoch  1, batch     1 | loss: 135.3750570CurrentTrain: epoch  1, batch     2 | loss: 74.6746127CurrentTrain: epoch  1, batch     3 | loss: 184.2314082CurrentTrain: epoch  1, batch     4 | loss: 29.1240374CurrentTrain: epoch  2, batch     0 | loss: 109.4960613CurrentTrain: epoch  2, batch     1 | loss: 104.4263983CurrentTrain: epoch  2, batch     2 | loss: 99.1882143CurrentTrain: epoch  2, batch     3 | loss: 84.7726084CurrentTrain: epoch  2, batch     4 | loss: 14.8572545CurrentTrain: epoch  3, batch     0 | loss: 83.6467408CurrentTrain: epoch  3, batch     1 | loss: 84.1699314CurrentTrain: epoch  3, batch     2 | loss: 82.3508787CurrentTrain: epoch  3, batch     3 | loss: 81.5987198CurrentTrain: epoch  3, batch     4 | loss: 26.8509074CurrentTrain: epoch  4, batch     0 | loss: 69.9532992CurrentTrain: epoch  4, batch     1 | loss: 64.8096140CurrentTrain: epoch  4, batch     2 | loss: 86.3972943CurrentTrain: epoch  4, batch     3 | loss: 83.6841666CurrentTrain: epoch  4, batch     4 | loss: 42.9437508CurrentTrain: epoch  5, batch     0 | loss: 67.7870723CurrentTrain: epoch  5, batch     1 | loss: 122.8649835CurrentTrain: epoch  5, batch     2 | loss: 81.6046476CurrentTrain: epoch  5, batch     3 | loss: 79.0939171CurrentTrain: epoch  5, batch     4 | loss: 25.7365233CurrentTrain: epoch  6, batch     0 | loss: 79.5201087CurrentTrain: epoch  6, batch     1 | loss: 66.5410057CurrentTrain: epoch  6, batch     2 | loss: 77.4022025CurrentTrain: epoch  6, batch     3 | loss: 98.0526000CurrentTrain: epoch  6, batch     4 | loss: 39.8384026CurrentTrain: epoch  7, batch     0 | loss: 79.4639854CurrentTrain: epoch  7, batch     1 | loss: 68.0580694CurrentTrain: epoch  7, batch     2 | loss: 79.3013906CurrentTrain: epoch  7, batch     3 | loss: 77.8531796CurrentTrain: epoch  7, batch     4 | loss: 11.7757654CurrentTrain: epoch  8, batch     0 | loss: 65.1616226CurrentTrain: epoch  8, batch     1 | loss: 93.8239567CurrentTrain: epoch  8, batch     2 | loss: 80.6756271CurrentTrain: epoch  8, batch     3 | loss: 64.6451289CurrentTrain: epoch  8, batch     4 | loss: 24.2543852CurrentTrain: epoch  9, batch     0 | loss: 79.8419826CurrentTrain: epoch  9, batch     1 | loss: 91.8261717CurrentTrain: epoch  9, batch     2 | loss: 77.3394263CurrentTrain: epoch  9, batch     3 | loss: 76.0291498CurrentTrain: epoch  9, batch     4 | loss: 24.6441066
MemoryTrain:  epoch  0, batch     0 | loss: 0.8850162MemoryTrain:  epoch  1, batch     0 | loss: 0.8149089MemoryTrain:  epoch  2, batch     0 | loss: 0.6607650MemoryTrain:  epoch  3, batch     0 | loss: 0.5886471MemoryTrain:  epoch  4, batch     0 | loss: 0.4624101MemoryTrain:  epoch  5, batch     0 | loss: 0.4073440MemoryTrain:  epoch  6, batch     0 | loss: 0.3536890MemoryTrain:  epoch  7, batch     0 | loss: 0.3178079MemoryTrain:  epoch  8, batch     0 | loss: 0.2738838MemoryTrain:  epoch  9, batch     0 | loss: 0.2533812

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.5833333333333334), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.384), 12: np.float64(0.6888888888888889), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 28: np.float64(0.2926829268292683), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.1111111111111111)}
Micro-average F1 score: 0.42462845010615713
Weighted-average F1 score: 0.3498892545274659
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.5), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.4251968503937008), 12: np.float64(0.6907216494845361), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.4444444444444444), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.42857142857142855)}
Micro-average F1 score: 0.39713774597495527
Weighted-average F1 score: 0.2983969313568976
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.5185185185185185), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.4626865671641791), 12: np.float64(0.6914893617021277), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 28: np.float64(0.42857142857142855), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.34782608695652173)}
Micro-average F1 score: 0.42641509433962266
Weighted-average F1 score: 0.3317358283173957

F1 score per class: {0: np.float64(0.6666666666666666), 1: np.float64(0.17560975609756097), 2: np.float64(0.2545454545454545), 3: np.float64(0.4883720930232558), 4: np.float64(0.8571428571428571), 5: np.float64(0.746031746031746), 6: np.float64(0.4904214559386973), 8: np.float64(0.07058823529411765), 10: np.float64(0.39520958083832336), 11: np.float64(0.1518987341772152), 12: np.float64(0.3701492537313433), 13: np.float64(0.03508771929824561), 14: np.float64(0.0), 15: np.float64(0.3157894736842105), 16: np.float64(0.5373134328358209), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.7085201793721974), 20: np.float64(0.27692307692307694), 21: np.float64(0.18274111675126903), 22: np.float64(0.45390070921985815), 23: np.float64(0.7058823529411765), 24: np.float64(0.0), 25: np.float64(0.3880597014925373), 26: np.float64(0.6666666666666666), 28: np.float64(0.05333333333333334), 29: np.float64(0.7379679144385026), 30: np.float64(0.7692307692307693), 32: np.float64(0.6104417670682731), 33: np.float64(0.1), 34: np.float64(0.19298245614035087), 35: np.float64(0.15217391304347827), 36: np.float64(0.057971014492753624), 37: np.float64(0.15151515151515152), 38: np.float64(0.2222222222222222), 39: np.float64(0.06060606060606061)}
Micro-average F1 score: 0.4057780695994747
Weighted-average F1 score: 0.3938334023523791
F1 score per class: {0: np.float64(0.3333333333333333), 1: np.float64(0.18181818181818182), 2: np.float64(0.1686746987951807), 3: np.float64(0.3357142857142857), 4: np.float64(0.851063829787234), 5: np.float64(0.5861027190332326), 6: np.float64(0.47368421052631576), 8: np.float64(0.40718562874251496), 10: np.float64(0.35359116022099446), 11: np.float64(0.18685121107266436), 12: np.float64(0.29321663019693656), 13: np.float64(0.031746031746031744), 14: np.float64(0.046875), 15: np.float64(0.3870967741935484), 16: np.float64(0.5555555555555556), 17: np.float64(0.0), 18: np.float64(0.037037037037037035), 19: np.float64(0.6412213740458015), 20: np.float64(0.4318181818181818), 21: np.float64(0.16356877323420074), 22: np.float64(0.449438202247191), 23: np.float64(0.631578947368421), 24: np.float64(0.09523809523809523), 25: np.float64(0.4935064935064935), 26: np.float64(0.6310679611650486), 28: np.float64(0.11267605633802817), 29: np.float64(0.7539267015706806), 30: np.float64(0.6428571428571429), 32: np.float64(0.5093167701863354), 33: np.float64(0.25), 34: np.float64(0.19469026548672566), 35: np.float64(0.1746031746031746), 36: np.float64(0.3711340206185567), 37: np.float64(0.21739130434782608), 38: np.float64(0.38095238095238093), 39: np.float64(0.17391304347826086)}
Micro-average F1 score: 0.39378612716763006
Weighted-average F1 score: 0.3770950392150683
F1 score per class: {0: np.float64(0.532258064516129), 1: np.float64(0.18357487922705315), 2: np.float64(0.19444444444444445), 3: np.float64(0.3673469387755102), 4: np.float64(0.8743169398907104), 5: np.float64(0.6552901023890785), 6: np.float64(0.5102040816326531), 8: np.float64(0.14285714285714285), 10: np.float64(0.3595505617977528), 11: np.float64(0.19254658385093168), 12: np.float64(0.3058823529411765), 13: np.float64(0.03225806451612903), 14: np.float64(0.041237113402061855), 15: np.float64(0.34285714285714286), 16: np.float64(0.5675675675675675), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.6352941176470588), 20: np.float64(0.4444444444444444), 21: np.float64(0.16296296296296298), 22: np.float64(0.47368421052631576), 23: np.float64(0.6238532110091743), 24: np.float64(0.09523809523809523), 25: np.float64(0.4788732394366197), 26: np.float64(0.6372549019607843), 28: np.float64(0.08), 29: np.float64(0.7513227513227513), 30: np.float64(0.7906976744186046), 32: np.float64(0.5536332179930796), 33: np.float64(0.2222222222222222), 34: np.float64(0.19130434782608696), 35: np.float64(0.11650485436893204), 36: np.float64(0.10666666666666667), 37: np.float64(0.19718309859154928), 38: np.float64(0.36065573770491804), 39: np.float64(0.11428571428571428)}
Micro-average F1 score: 0.3951675759937646
Weighted-average F1 score: 0.3812084141839359

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.35), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.3116883116883117), 12: np.float64(0.5767441860465117), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.12903225806451613), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.08695652173913043)}
Micro-average F1 score: 0.29027576197387517
Weighted-average F1 score: 0.23297310765513501
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.27450980392156865), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.3375), 12: np.float64(0.5381526104417671), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.17391304347826086), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.3)}
Micro-average F1 score: 0.25754060324825984
Weighted-average F1 score: 0.20283490882224428
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.2916666666666667), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.3668639053254438), 12: np.float64(0.5394190871369294), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.16216216216216217), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.22857142857142856)}
Micro-average F1 score: 0.2766217870257038
Weighted-average F1 score: 0.2218257028768741

F1 score per class: {0: np.float64(0.4838709677419355), 1: np.float64(0.08737864077669903), 2: np.float64(0.14893617021276595), 3: np.float64(0.3835616438356164), 4: np.float64(0.8108108108108109), 5: np.float64(0.5875), 6: np.float64(0.27765726681127983), 8: np.float64(0.06741573033707865), 10: np.float64(0.28820960698689957), 11: np.float64(0.10084033613445378), 12: np.float64(0.148859543817527), 13: np.float64(0.016666666666666666), 14: np.float64(0.0), 15: np.float64(0.22641509433962265), 16: np.float64(0.3157894736842105), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.6370967741935484), 20: np.float64(0.20224719101123595), 21: np.float64(0.1157556270096463), 22: np.float64(0.44755244755244755), 23: np.float64(0.5373134328358209), 24: np.float64(0.0), 25: np.float64(0.36619718309859156), 26: np.float64(0.579185520361991), 28: np.float64(0.02843601895734597), 29: np.float64(0.6160714285714286), 30: np.float64(0.6382978723404256), 32: np.float64(0.44970414201183434), 33: np.float64(0.07692307692307693), 34: np.float64(0.16296296296296298), 35: np.float64(0.11290322580645161), 36: np.float64(0.05555555555555555), 37: np.float64(0.14285714285714285), 38: np.float64(0.14285714285714285), 39: np.float64(0.03773584905660377)}
Micro-average F1 score: 0.27548291233283806
Weighted-average F1 score: 0.25106831925967676
F1 score per class: {0: np.float64(0.21428571428571427), 1: np.float64(0.09113924050632911), 2: np.float64(0.08484848484848485), 3: np.float64(0.2211764705882353), 4: np.float64(0.7804878048780488), 5: np.float64(0.38415841584158417), 6: np.float64(0.25961538461538464), 8: np.float64(0.2857142857142857), 10: np.float64(0.24242424242424243), 11: np.float64(0.12413793103448276), 12: np.float64(0.12316176470588236), 13: np.float64(0.01652892561983471), 14: np.float64(0.038461538461538464), 15: np.float64(0.3), 16: np.float64(0.35714285714285715), 17: np.float64(0.0), 18: np.float64(0.0273972602739726), 19: np.float64(0.5401929260450161), 20: np.float64(0.2602739726027397), 21: np.float64(0.10551558752997602), 22: np.float64(0.38461538461538464), 23: np.float64(0.45), 24: np.float64(0.08), 25: np.float64(0.475), 26: np.float64(0.5327868852459017), 28: np.float64(0.05755395683453238), 29: np.float64(0.6260869565217392), 30: np.float64(0.5217391304347826), 32: np.float64(0.36123348017621143), 33: np.float64(0.1875), 34: np.float64(0.1437908496732026), 35: np.float64(0.11891891891891893), 36: np.float64(0.2903225806451613), 37: np.float64(0.18691588785046728), 38: np.float64(0.24489795918367346), 39: np.float64(0.09523809523809523)}
Micro-average F1 score: 0.25559854613671007
Weighted-average F1 score: 0.23690090428637015
F1 score per class: {0: np.float64(0.3626373626373626), 1: np.float64(0.09134615384615384), 2: np.float64(0.1), 3: np.float64(0.25210084033613445), 4: np.float64(0.8247422680412371), 5: np.float64(0.4304932735426009), 6: np.float64(0.2912621359223301), 8: np.float64(0.12727272727272726), 10: np.float64(0.2471042471042471), 11: np.float64(0.12863070539419086), 12: np.float64(0.12633624878522837), 13: np.float64(0.01652892561983471), 14: np.float64(0.03636363636363636), 15: np.float64(0.2608695652173913), 16: np.float64(0.3620689655172414), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5436241610738255), 20: np.float64(0.29508196721311475), 21: np.float64(0.10208816705336426), 22: np.float64(0.44171779141104295), 23: np.float64(0.4473684210526316), 24: np.float64(0.08), 25: np.float64(0.4533333333333333), 26: np.float64(0.5462184873949579), 28: np.float64(0.040955631399317405), 29: np.float64(0.6228070175438597), 30: np.float64(0.6296296296296297), 32: np.float64(0.39800995024875624), 33: np.float64(0.16216216216216217), 34: np.float64(0.14193548387096774), 35: np.float64(0.08275862068965517), 36: np.float64(0.09523809523809523), 37: np.float64(0.1794871794871795), 38: np.float64(0.22), 39: np.float64(0.06666666666666667)}
Micro-average F1 score: 0.2593682056528968
Weighted-average F1 score: 0.23901810224220185
cur_acc_wo_na:  ['0.7614', '0.5851', '0.4583', '0.3967', '0.5474', '0.6509', '0.4246']
his_acc_wo_na:  ['0.7614', '0.6742', '0.6126', '0.4690', '0.4280', '0.4228', '0.4058']
cur_acc des_wo_na:  ['0.7500', '0.6421', '0.5669', '0.3210', '0.4869', '0.5624', '0.3971']
his_acc des_wo_na:  ['0.7500', '0.6651', '0.6182', '0.4770', '0.4353', '0.4307', '0.3938']
cur_acc rrf_wo_na:  ['0.7632', '0.6484', '0.5302', '0.3489', '0.5136', '0.6032', '0.4264']
his_acc rrf_wo_na:  ['0.7632', '0.6720', '0.6220', '0.4691', '0.4317', '0.4265', '0.3952']
cur_acc_w_na:  ['0.6401', '0.4741', '0.3577', '0.2826', '0.3847', '0.4940', '0.2903']
his_acc_w_na:  ['0.6401', '0.5328', '0.4912', '0.3573', '0.3127', '0.3047', '0.2755']
cur_acc des_w_na:  ['0.5954', '0.4925', '0.3966', '0.2199', '0.3227', '0.4092', '0.2575']
his_acc des_w_na:  ['0.5954', '0.4976', '0.4623', '0.3429', '0.3000', '0.2967', '0.2556']
cur_acc rrf_w_na:  ['0.6131', '0.5009', '0.3779', '0.2410', '0.3452', '0.4398', '0.2766']
his_acc rrf_w_na:  ['0.6131', '0.5083', '0.4747', '0.3430', '0.3034', '0.2971', '0.2594']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 84.2488126CurrentTrain: epoch  0, batch     1 | loss: 101.3377274CurrentTrain: epoch  0, batch     2 | loss: 86.0457146CurrentTrain: epoch  0, batch     3 | loss: 25.7774281CurrentTrain: epoch  1, batch     0 | loss: 107.4980378CurrentTrain: epoch  1, batch     1 | loss: 73.9469795CurrentTrain: epoch  1, batch     2 | loss: 88.1887995CurrentTrain: epoch  1, batch     3 | loss: 13.7403105CurrentTrain: epoch  2, batch     0 | loss: 79.9463152CurrentTrain: epoch  2, batch     1 | loss: 69.3329977CurrentTrain: epoch  2, batch     2 | loss: 108.0874993CurrentTrain: epoch  2, batch     3 | loss: 6.2670149CurrentTrain: epoch  3, batch     0 | loss: 63.5863334CurrentTrain: epoch  3, batch     1 | loss: 97.8790296CurrentTrain: epoch  3, batch     2 | loss: 86.8523154CurrentTrain: epoch  3, batch     3 | loss: 17.8317723CurrentTrain: epoch  4, batch     0 | loss: 77.7411779CurrentTrain: epoch  4, batch     1 | loss: 68.5487296CurrentTrain: epoch  4, batch     2 | loss: 77.1482102CurrentTrain: epoch  4, batch     3 | loss: 16.6248400CurrentTrain: epoch  5, batch     0 | loss: 73.9100069CurrentTrain: epoch  5, batch     1 | loss: 81.5502664CurrentTrain: epoch  5, batch     2 | loss: 67.8297657CurrentTrain: epoch  5, batch     3 | loss: 7.5775982CurrentTrain: epoch  6, batch     0 | loss: 64.4208560CurrentTrain: epoch  6, batch     1 | loss: 78.7037896CurrentTrain: epoch  6, batch     2 | loss: 73.8736581CurrentTrain: epoch  6, batch     3 | loss: 11.9968846CurrentTrain: epoch  7, batch     0 | loss: 64.1919124CurrentTrain: epoch  7, batch     1 | loss: 61.6490856CurrentTrain: epoch  7, batch     2 | loss: 77.1063439CurrentTrain: epoch  7, batch     3 | loss: 9.2188883CurrentTrain: epoch  8, batch     0 | loss: 76.2882277CurrentTrain: epoch  8, batch     1 | loss: 62.7034468CurrentTrain: epoch  8, batch     2 | loss: 73.6634607CurrentTrain: epoch  8, batch     3 | loss: 4.0733890CurrentTrain: epoch  9, batch     0 | loss: 62.8426617CurrentTrain: epoch  9, batch     1 | loss: 72.5319647CurrentTrain: epoch  9, batch     2 | loss: 74.5625930CurrentTrain: epoch  9, batch     3 | loss: 9.3763478
MemoryTrain:  epoch  0, batch     0 | loss: 0.7652471MemoryTrain:  epoch  1, batch     0 | loss: 0.6363301MemoryTrain:  epoch  2, batch     0 | loss: 0.4970437MemoryTrain:  epoch  3, batch     0 | loss: 0.4849569MemoryTrain:  epoch  4, batch     0 | loss: 0.3492733MemoryTrain:  epoch  5, batch     0 | loss: 0.3053269MemoryTrain:  epoch  6, batch     0 | loss: 0.2788466MemoryTrain:  epoch  7, batch     0 | loss: 0.2587176MemoryTrain:  epoch  8, batch     0 | loss: 0.2062259MemoryTrain:  epoch  9, batch     0 | loss: 0.2089494

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 3: np.float64(0.0), 7: np.float64(0.5454545454545454), 9: np.float64(0.8333333333333334), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.08333333333333333), 31: np.float64(0.2222222222222222), 37: np.float64(0.0), 40: np.float64(0.5794392523364486)}
Micro-average F1 score: 0.42214532871972316
Weighted-average F1 score: 0.3238652209680247
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6666666666666666), 9: np.float64(0.6578947368421053), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.13333333333333333), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.6446280991735537)}
Micro-average F1 score: 0.42592592592592593
Weighted-average F1 score: 0.3498096480871601
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6666666666666666), 9: np.float64(0.7936507936507936), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.15384615384615385), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.639344262295082)}
Micro-average F1 score: 0.45098039215686275
Weighted-average F1 score: 0.36587835358327164

F1 score per class: {0: np.float64(0.33962264150943394), 1: np.float64(0.140625), 2: np.float64(0.25925925925925924), 3: np.float64(0.4), 4: np.float64(0.7904191616766467), 5: np.float64(0.7230769230769231), 6: np.float64(0.11965811965811966), 7: np.float64(0.02912621359223301), 8: np.float64(0.06976744186046512), 9: np.float64(0.819672131147541), 10: np.float64(0.2597402597402597), 11: np.float64(0.1566265060240964), 12: np.float64(0.34980988593155893), 13: np.float64(0.02040816326530612), 14: np.float64(0.0), 15: np.float64(0.48), 16: np.float64(0.5625), 17: np.float64(0.0), 18: np.float64(0.03389830508474576), 19: np.float64(0.5748987854251012), 20: np.float64(0.43037974683544306), 21: np.float64(0.1282051282051282), 22: np.float64(0.5066666666666667), 23: np.float64(0.7083333333333334), 24: np.float64(0.0), 25: np.float64(0.4411764705882353), 26: np.float64(0.6736842105263158), 27: np.float64(0.0425531914893617), 28: np.float64(0.06282722513089005), 29: np.float64(0.7243243243243244), 30: np.float64(0.8333333333333334), 31: np.float64(0.08333333333333333), 32: np.float64(0.5836909871244635), 33: np.float64(0.14285714285714285), 34: np.float64(0.22033898305084745), 35: np.float64(0.11267605633802817), 36: np.float64(0.08571428571428572), 37: np.float64(0.17647058823529413), 38: np.float64(0.2127659574468085), 39: np.float64(0.06060606060606061), 40: np.float64(0.33695652173913043)}
Micro-average F1 score: 0.3582273286828067
Weighted-average F1 score: 0.3385498161637297
F1 score per class: {0: np.float64(0.32710280373831774), 1: np.float64(0.1506849315068493), 2: np.float64(0.16666666666666666), 3: np.float64(0.41295546558704455), 4: np.float64(0.850828729281768), 5: np.float64(0.6198083067092651), 6: np.float64(0.14754098360655737), 7: np.float64(0.03347280334728033), 8: np.float64(0.41333333333333333), 9: np.float64(0.47619047619047616), 10: np.float64(0.24516129032258063), 11: np.float64(0.16597510373443983), 12: np.float64(0.24313725490196078), 13: np.float64(0.022727272727272728), 14: np.float64(0.05555555555555555), 15: np.float64(0.5217391304347826), 16: np.float64(0.5974025974025974), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5447761194029851), 20: np.float64(0.4318181818181818), 21: np.float64(0.1523809523809524), 22: np.float64(0.49673202614379086), 23: np.float64(0.6464646464646465), 24: np.float64(0.0), 25: np.float64(0.5), 26: np.float64(0.6473429951690821), 27: np.float64(0.0), 28: np.float64(0.09836065573770492), 29: np.float64(0.7182320441988951), 30: np.float64(0.7441860465116279), 31: np.float64(0.03278688524590164), 32: np.float64(0.555956678700361), 33: np.float64(0.25), 34: np.float64(0.2676056338028169), 35: np.float64(0.16279069767441862), 36: np.float64(0.25), 37: np.float64(0.20454545454545456), 38: np.float64(0.34375), 39: np.float64(0.1568627450980392), 40: np.float64(0.39)}
Micro-average F1 score: 0.36614982252942274
Weighted-average F1 score: 0.34643117546335445
F1 score per class: {0: np.float64(0.31390134529147984), 1: np.float64(0.15714285714285714), 2: np.float64(0.23333333333333334), 3: np.float64(0.4375), 4: np.float64(0.8522727272727273), 5: np.float64(0.6552901023890785), 6: np.float64(0.13333333333333333), 7: np.float64(0.034482758620689655), 8: np.float64(0.3063063063063063), 9: np.float64(0.7352941176470589), 10: np.float64(0.2564102564102564), 11: np.float64(0.17391304347826086), 12: np.float64(0.25806451612903225), 13: np.float64(0.02197802197802198), 14: np.float64(0.042105263157894736), 15: np.float64(0.5), 16: np.float64(0.6052631578947368), 17: np.float64(0.0), 18: np.float64(0.03571428571428571), 19: np.float64(0.576), 20: np.float64(0.3950617283950617), 21: np.float64(0.1743119266055046), 22: np.float64(0.5066666666666667), 23: np.float64(0.6530612244897959), 24: np.float64(0.0), 25: np.float64(0.4473684210526316), 26: np.float64(0.6568627450980392), 27: np.float64(0.0), 28: np.float64(0.0851063829787234), 29: np.float64(0.7182320441988951), 30: np.float64(0.8421052631578947), 31: np.float64(0.04), 32: np.float64(0.5384615384615384), 33: np.float64(0.24), 34: np.float64(0.2695035460992908), 35: np.float64(0.16470588235294117), 36: np.float64(0.20253164556962025), 37: np.float64(0.23376623376623376), 38: np.float64(0.25925925925925924), 39: np.float64(0.125), 40: np.float64(0.3842364532019704)}
Micro-average F1 score: 0.3678786700369434
Weighted-average F1 score: 0.3468666093934073

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5454545454545454), 9: np.float64(0.7575757575757576), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.08333333333333333), 28: np.float64(0.0), 31: np.float64(0.18181818181818182), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.5040650406504065)}
Micro-average F1 score: 0.33516483516483514
Weighted-average F1 score: 0.2554094604582409
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5714285714285714), 9: np.float64(0.5747126436781609), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.1), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.5954198473282443)}
Micro-average F1 score: 0.33906633906633904
Weighted-average F1 score: 0.2713712586652025
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5714285714285714), 9: np.float64(0.704225352112676), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.11764705882352941), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.582089552238806)}
Micro-average F1 score: 0.35751295336787564
Weighted-average F1 score: 0.2831456408751533

F1 score per class: {0: np.float64(0.21176470588235294), 1: np.float64(0.0743801652892562), 2: np.float64(0.15384615384615385), 3: np.float64(0.3013698630136986), 4: np.float64(0.7542857142857143), 5: np.float64(0.5266106442577031), 6: np.float64(0.0875), 7: np.float64(0.01507537688442211), 8: np.float64(0.06666666666666667), 9: np.float64(0.7246376811594203), 10: np.float64(0.20202020202020202), 11: np.float64(0.10097087378640776), 12: np.float64(0.14511041009463724), 13: np.float64(0.011428571428571429), 14: np.float64(0.0), 15: np.float64(0.4), 16: np.float64(0.3673469387755102), 17: np.float64(0.0), 18: np.float64(0.025), 19: np.float64(0.5419847328244275), 20: np.float64(0.26356589147286824), 21: np.float64(0.08064516129032258), 22: np.float64(0.49032258064516127), 23: np.float64(0.5714285714285714), 24: np.float64(0.0), 25: np.float64(0.4166666666666667), 26: np.float64(0.5818181818181818), 27: np.float64(0.0392156862745098), 28: np.float64(0.03389830508474576), 29: np.float64(0.6411483253588517), 30: np.float64(0.7894736842105263), 31: np.float64(0.034482758620689655), 32: np.float64(0.4563758389261745), 33: np.float64(0.10526315789473684), 34: np.float64(0.1780821917808219), 35: np.float64(0.08333333333333333), 36: np.float64(0.08333333333333333), 37: np.float64(0.16666666666666666), 38: np.float64(0.12987012987012986), 39: np.float64(0.03571428571428571), 40: np.float64(0.23846153846153847)}
Micro-average F1 score: 0.2490372272143774
Weighted-average F1 score: 0.22186805887650538
F1 score per class: {0: np.float64(0.21671826625386997), 1: np.float64(0.08333333333333333), 2: np.float64(0.08284023668639054), 3: np.float64(0.28254847645429365), 4: np.float64(0.8020833333333334), 5: np.float64(0.3991769547325103), 6: np.float64(0.11042944785276074), 7: np.float64(0.01680672268907563), 8: np.float64(0.3163265306122449), 9: np.float64(0.36496350364963503), 10: np.float64(0.18719211822660098), 11: np.float64(0.10498687664041995), 12: np.float64(0.11460258780036968), 13: np.float64(0.012578616352201259), 14: np.float64(0.04878048780487805), 15: np.float64(0.41379310344827586), 16: np.float64(0.37398373983739835), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.4882943143812709), 20: np.float64(0.25333333333333335), 21: np.float64(0.10158730158730159), 22: np.float64(0.4578313253012048), 23: np.float64(0.48484848484848486), 24: np.float64(0.0), 25: np.float64(0.47058823529411764), 26: np.float64(0.5447154471544715), 27: np.float64(0.0), 28: np.float64(0.049586776859504134), 29: np.float64(0.6341463414634146), 30: np.float64(0.6808510638297872), 31: np.float64(0.016129032258064516), 32: np.float64(0.4117647058823529), 33: np.float64(0.2222222222222222), 34: np.float64(0.20765027322404372), 35: np.float64(0.1206896551724138), 36: np.float64(0.21359223300970873), 37: np.float64(0.16981132075471697), 38: np.float64(0.20754716981132076), 39: np.float64(0.08247422680412371), 40: np.float64(0.3046875)}
Micro-average F1 score: 0.2526424336169116
Weighted-average F1 score: 0.2301372964829902
F1 score per class: {0: np.float64(0.20710059171597633), 1: np.float64(0.08461538461538462), 2: np.float64(0.112), 3: np.float64(0.3141025641025641), 4: np.float64(0.8108108108108109), 5: np.float64(0.42857142857142855), 6: np.float64(0.10191082802547771), 7: np.float64(0.017204301075268817), 8: np.float64(0.2556390977443609), 9: np.float64(0.6410256410256411), 10: np.float64(0.1932367149758454), 11: np.float64(0.10918114143920596), 12: np.float64(0.1198501872659176), 13: np.float64(0.012269938650306749), 14: np.float64(0.0380952380952381), 15: np.float64(0.375), 16: np.float64(0.3709677419354839), 17: np.float64(0.0), 18: np.float64(0.02631578947368421), 19: np.float64(0.5333333333333333), 20: np.float64(0.23703703703703705), 21: np.float64(0.11585365853658537), 22: np.float64(0.4691358024691358), 23: np.float64(0.49612403100775193), 24: np.float64(0.0), 25: np.float64(0.41975308641975306), 26: np.float64(0.5677966101694916), 27: np.float64(0.0), 28: np.float64(0.044444444444444446), 29: np.float64(0.6341463414634146), 30: np.float64(0.7619047619047619), 31: np.float64(0.019417475728155338), 32: np.float64(0.4), 33: np.float64(0.21428571428571427), 34: np.float64(0.2111111111111111), 35: np.float64(0.12173913043478261), 36: np.float64(0.18604651162790697), 37: np.float64(0.21428571428571427), 38: np.float64(0.15053763440860216), 39: np.float64(0.07228915662650602), 40: np.float64(0.29545454545454547)}
Micro-average F1 score: 0.255537547271745
Weighted-average F1 score: 0.23013801800788358
cur_acc_wo_na:  ['0.7614', '0.5851', '0.4583', '0.3967', '0.5474', '0.6509', '0.4246', '0.4221']
his_acc_wo_na:  ['0.7614', '0.6742', '0.6126', '0.4690', '0.4280', '0.4228', '0.4058', '0.3582']
cur_acc des_wo_na:  ['0.7500', '0.6421', '0.5669', '0.3210', '0.4869', '0.5624', '0.3971', '0.4259']
his_acc des_wo_na:  ['0.7500', '0.6651', '0.6182', '0.4770', '0.4353', '0.4307', '0.3938', '0.3661']
cur_acc rrf_wo_na:  ['0.7632', '0.6484', '0.5302', '0.3489', '0.5136', '0.6032', '0.4264', '0.4510']
his_acc rrf_wo_na:  ['0.7632', '0.6720', '0.6220', '0.4691', '0.4317', '0.4265', '0.3952', '0.3679']
cur_acc_w_na:  ['0.6401', '0.4741', '0.3577', '0.2826', '0.3847', '0.4940', '0.2903', '0.3352']
his_acc_w_na:  ['0.6401', '0.5328', '0.4912', '0.3573', '0.3127', '0.3047', '0.2755', '0.2490']
cur_acc des_w_na:  ['0.5954', '0.4925', '0.3966', '0.2199', '0.3227', '0.4092', '0.2575', '0.3391']
his_acc des_w_na:  ['0.5954', '0.4976', '0.4623', '0.3429', '0.3000', '0.2967', '0.2556', '0.2526']
cur_acc rrf_w_na:  ['0.6131', '0.5009', '0.3779', '0.2410', '0.3452', '0.4398', '0.2766', '0.3575']
his_acc rrf_w_na:  ['0.6131', '0.5083', '0.4747', '0.3430', '0.3034', '0.2971', '0.2594', '0.2555']
--------Round  5
seed:  600
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 2 0 1 6 3 4 5]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 108.3715807CurrentTrain: epoch  0, batch     1 | loss: 80.2098559CurrentTrain: epoch  0, batch     2 | loss: 119.8339094CurrentTrain: epoch  0, batch     3 | loss: 87.6112970CurrentTrain: epoch  0, batch     4 | loss: 88.0646976CurrentTrain: epoch  0, batch     5 | loss: 119.2571298CurrentTrain: epoch  0, batch     6 | loss: 101.9607267CurrentTrain: epoch  0, batch     7 | loss: 100.1073973CurrentTrain: epoch  0, batch     8 | loss: 86.9180096CurrentTrain: epoch  0, batch     9 | loss: 99.9724455CurrentTrain: epoch  0, batch    10 | loss: 100.7428697CurrentTrain: epoch  0, batch    11 | loss: 118.5609691CurrentTrain: epoch  0, batch    12 | loss: 86.0865641CurrentTrain: epoch  0, batch    13 | loss: 85.9262768CurrentTrain: epoch  0, batch    14 | loss: 99.5912475CurrentTrain: epoch  0, batch    15 | loss: 86.5486839CurrentTrain: epoch  0, batch    16 | loss: 99.0119190CurrentTrain: epoch  0, batch    17 | loss: 99.9471986CurrentTrain: epoch  0, batch    18 | loss: 99.3149330CurrentTrain: epoch  0, batch    19 | loss: 86.5812927CurrentTrain: epoch  0, batch    20 | loss: 145.8908131CurrentTrain: epoch  0, batch    21 | loss: 118.0145333CurrentTrain: epoch  0, batch    22 | loss: 117.8115921CurrentTrain: epoch  0, batch    23 | loss: 117.6856791CurrentTrain: epoch  0, batch    24 | loss: 75.9031402CurrentTrain: epoch  0, batch    25 | loss: 98.9844342CurrentTrain: epoch  0, batch    26 | loss: 192.1062380CurrentTrain: epoch  0, batch    27 | loss: 98.6989398CurrentTrain: epoch  0, batch    28 | loss: 191.5686191CurrentTrain: epoch  0, batch    29 | loss: 145.6489388CurrentTrain: epoch  0, batch    30 | loss: 117.5900480CurrentTrain: epoch  0, batch    31 | loss: 84.4084249CurrentTrain: epoch  0, batch    32 | loss: 116.4580532CurrentTrain: epoch  0, batch    33 | loss: 117.4461742CurrentTrain: epoch  0, batch    34 | loss: 117.1089417CurrentTrain: epoch  0, batch    35 | loss: 145.8849554CurrentTrain: epoch  0, batch    36 | loss: 96.8672341CurrentTrain: epoch  0, batch    37 | loss: 96.6838260CurrentTrain: epoch  0, batch    38 | loss: 82.4288147CurrentTrain: epoch  0, batch    39 | loss: 98.4319243CurrentTrain: epoch  0, batch    40 | loss: 84.8501754CurrentTrain: epoch  0, batch    41 | loss: 84.7924372CurrentTrain: epoch  0, batch    42 | loss: 83.7895841CurrentTrain: epoch  0, batch    43 | loss: 115.0981767CurrentTrain: epoch  0, batch    44 | loss: 96.6130433CurrentTrain: epoch  0, batch    45 | loss: 96.5302020CurrentTrain: epoch  0, batch    46 | loss: 94.5584013CurrentTrain: epoch  0, batch    47 | loss: 93.1750455CurrentTrain: epoch  0, batch    48 | loss: 82.5621911CurrentTrain: epoch  0, batch    49 | loss: 117.1500621CurrentTrain: epoch  0, batch    50 | loss: 96.1811470CurrentTrain: epoch  0, batch    51 | loss: 83.3693607CurrentTrain: epoch  0, batch    52 | loss: 81.3995441CurrentTrain: epoch  0, batch    53 | loss: 97.6341713CurrentTrain: epoch  0, batch    54 | loss: 95.1561703CurrentTrain: epoch  0, batch    55 | loss: 80.6322863CurrentTrain: epoch  0, batch    56 | loss: 112.0677491CurrentTrain: epoch  0, batch    57 | loss: 140.8397585CurrentTrain: epoch  0, batch    58 | loss: 93.2294885CurrentTrain: epoch  0, batch    59 | loss: 95.4372793CurrentTrain: epoch  0, batch    60 | loss: 141.7555589CurrentTrain: epoch  0, batch    61 | loss: 94.1387967CurrentTrain: epoch  0, batch    62 | loss: 94.4421497CurrentTrain: epoch  0, batch    63 | loss: 94.7316259CurrentTrain: epoch  0, batch    64 | loss: 80.4366770CurrentTrain: epoch  0, batch    65 | loss: 81.4287250CurrentTrain: epoch  0, batch    66 | loss: 92.7940622CurrentTrain: epoch  0, batch    67 | loss: 79.4185997CurrentTrain: epoch  0, batch    68 | loss: 93.9165281CurrentTrain: epoch  0, batch    69 | loss: 76.3197690CurrentTrain: epoch  0, batch    70 | loss: 112.2930631CurrentTrain: epoch  0, batch    71 | loss: 81.3403128CurrentTrain: epoch  0, batch    72 | loss: 90.6622209CurrentTrain: epoch  0, batch    73 | loss: 92.2713804CurrentTrain: epoch  0, batch    74 | loss: 79.3641180CurrentTrain: epoch  0, batch    75 | loss: 77.1429024CurrentTrain: epoch  0, batch    76 | loss: 95.2851587CurrentTrain: epoch  0, batch    77 | loss: 90.7663540CurrentTrain: epoch  0, batch    78 | loss: 140.2376785CurrentTrain: epoch  0, batch    79 | loss: 77.3302738CurrentTrain: epoch  0, batch    80 | loss: 78.1110483CurrentTrain: epoch  0, batch    81 | loss: 112.4911400CurrentTrain: epoch  0, batch    82 | loss: 111.7974291CurrentTrain: epoch  0, batch    83 | loss: 107.4440213CurrentTrain: epoch  0, batch    84 | loss: 94.8416938CurrentTrain: epoch  0, batch    85 | loss: 128.7632877CurrentTrain: epoch  0, batch    86 | loss: 95.9285757CurrentTrain: epoch  0, batch    87 | loss: 92.1911188CurrentTrain: epoch  0, batch    88 | loss: 91.7599615CurrentTrain: epoch  0, batch    89 | loss: 112.2557337CurrentTrain: epoch  0, batch    90 | loss: 78.9493469CurrentTrain: epoch  0, batch    91 | loss: 109.4801142CurrentTrain: epoch  0, batch    92 | loss: 91.0312506CurrentTrain: epoch  0, batch    93 | loss: 91.4928848CurrentTrain: epoch  0, batch    94 | loss: 114.2737300CurrentTrain: epoch  0, batch    95 | loss: 87.1641030CurrentTrain: epoch  1, batch     0 | loss: 88.5895162CurrentTrain: epoch  1, batch     1 | loss: 92.3637553CurrentTrain: epoch  1, batch     2 | loss: 78.7953498CurrentTrain: epoch  1, batch     3 | loss: 109.9295147CurrentTrain: epoch  1, batch     4 | loss: 91.3835780CurrentTrain: epoch  1, batch     5 | loss: 110.6560668CurrentTrain: epoch  1, batch     6 | loss: 68.7920129CurrentTrain: epoch  1, batch     7 | loss: 88.0616185CurrentTrain: epoch  1, batch     8 | loss: 88.2579746CurrentTrain: epoch  1, batch     9 | loss: 93.1361290CurrentTrain: epoch  1, batch    10 | loss: 89.3216746CurrentTrain: epoch  1, batch    11 | loss: 91.0333080CurrentTrain: epoch  1, batch    12 | loss: 87.7599883CurrentTrain: epoch  1, batch    13 | loss: 91.0893485CurrentTrain: epoch  1, batch    14 | loss: 108.7495920CurrentTrain: epoch  1, batch    15 | loss: 77.3596481CurrentTrain: epoch  1, batch    16 | loss: 67.1853704CurrentTrain: epoch  1, batch    17 | loss: 67.7742177CurrentTrain: epoch  1, batch    18 | loss: 103.5792397CurrentTrain: epoch  1, batch    19 | loss: 88.5656090CurrentTrain: epoch  1, batch    20 | loss: 93.1255690CurrentTrain: epoch  1, batch    21 | loss: 78.0453991CurrentTrain: epoch  1, batch    22 | loss: 79.1244448CurrentTrain: epoch  1, batch    23 | loss: 87.4605595CurrentTrain: epoch  1, batch    24 | loss: 108.3464498CurrentTrain: epoch  1, batch    25 | loss: 89.5242974CurrentTrain: epoch  1, batch    26 | loss: 76.9392314CurrentTrain: epoch  1, batch    27 | loss: 91.1580587CurrentTrain: epoch  1, batch    28 | loss: 104.5157992CurrentTrain: epoch  1, batch    29 | loss: 110.9012514CurrentTrain: epoch  1, batch    30 | loss: 90.8963363CurrentTrain: epoch  1, batch    31 | loss: 75.5855812CurrentTrain: epoch  1, batch    32 | loss: 110.3100702CurrentTrain: epoch  1, batch    33 | loss: 137.3172729CurrentTrain: epoch  1, batch    34 | loss: 87.6708343CurrentTrain: epoch  1, batch    35 | loss: 88.9581822CurrentTrain: epoch  1, batch    36 | loss: 75.2371763CurrentTrain: epoch  1, batch    37 | loss: 63.6754770CurrentTrain: epoch  1, batch    38 | loss: 89.6704951CurrentTrain: epoch  1, batch    39 | loss: 104.1495834CurrentTrain: epoch  1, batch    40 | loss: 85.0396593CurrentTrain: epoch  1, batch    41 | loss: 73.1638939CurrentTrain: epoch  1, batch    42 | loss: 90.0328432CurrentTrain: epoch  1, batch    43 | loss: 73.7702428CurrentTrain: epoch  1, batch    44 | loss: 84.4165940CurrentTrain: epoch  1, batch    45 | loss: 88.2824170CurrentTrain: epoch  1, batch    46 | loss: 106.7713284CurrentTrain: epoch  1, batch    47 | loss: 134.3835539CurrentTrain: epoch  1, batch    48 | loss: 85.3423863CurrentTrain: epoch  1, batch    49 | loss: 140.3282145CurrentTrain: epoch  1, batch    50 | loss: 109.0805813CurrentTrain: epoch  1, batch    51 | loss: 73.2123122CurrentTrain: epoch  1, batch    52 | loss: 133.4700870CurrentTrain: epoch  1, batch    53 | loss: 65.3641853CurrentTrain: epoch  1, batch    54 | loss: 90.4706814CurrentTrain: epoch  1, batch    55 | loss: 88.8742568CurrentTrain: epoch  1, batch    56 | loss: 184.5791142CurrentTrain: epoch  1, batch    57 | loss: 62.5954668CurrentTrain: epoch  1, batch    58 | loss: 177.2867775CurrentTrain: epoch  1, batch    59 | loss: 109.6991057CurrentTrain: epoch  1, batch    60 | loss: 71.7878737CurrentTrain: epoch  1, batch    61 | loss: 89.7753301CurrentTrain: epoch  1, batch    62 | loss: 87.9213582CurrentTrain: epoch  1, batch    63 | loss: 75.2443130CurrentTrain: epoch  1, batch    64 | loss: 103.3672056CurrentTrain: epoch  1, batch    65 | loss: 88.5783893CurrentTrain: epoch  1, batch    66 | loss: 88.2743027CurrentTrain: epoch  1, batch    67 | loss: 88.7355989CurrentTrain: epoch  1, batch    68 | loss: 108.2936671CurrentTrain: epoch  1, batch    69 | loss: 90.5464553CurrentTrain: epoch  1, batch    70 | loss: 89.5818135CurrentTrain: epoch  1, batch    71 | loss: 74.8750426CurrentTrain: epoch  1, batch    72 | loss: 122.8814285CurrentTrain: epoch  1, batch    73 | loss: 60.3510449CurrentTrain: epoch  1, batch    74 | loss: 104.2008674CurrentTrain: epoch  1, batch    75 | loss: 77.0818234CurrentTrain: epoch  1, batch    76 | loss: 141.1871364CurrentTrain: epoch  1, batch    77 | loss: 87.8121428CurrentTrain: epoch  1, batch    78 | loss: 89.2697843CurrentTrain: epoch  1, batch    79 | loss: 90.9705916CurrentTrain: epoch  1, batch    80 | loss: 93.2851692CurrentTrain: epoch  1, batch    81 | loss: 91.6245890CurrentTrain: epoch  1, batch    82 | loss: 106.4344080CurrentTrain: epoch  1, batch    83 | loss: 94.3700625CurrentTrain: epoch  1, batch    84 | loss: 106.1941721CurrentTrain: epoch  1, batch    85 | loss: 107.3852442CurrentTrain: epoch  1, batch    86 | loss: 83.8113826CurrentTrain: epoch  1, batch    87 | loss: 83.9732203CurrentTrain: epoch  1, batch    88 | loss: 66.3529420CurrentTrain: epoch  1, batch    89 | loss: 108.5274627CurrentTrain: epoch  1, batch    90 | loss: 73.0058630CurrentTrain: epoch  1, batch    91 | loss: 135.0642966CurrentTrain: epoch  1, batch    92 | loss: 75.3199263CurrentTrain: epoch  1, batch    93 | loss: 107.2286557CurrentTrain: epoch  1, batch    94 | loss: 88.6586326CurrentTrain: epoch  1, batch    95 | loss: 150.6605023CurrentTrain: epoch  2, batch     0 | loss: 75.5898123CurrentTrain: epoch  2, batch     1 | loss: 86.5694544CurrentTrain: epoch  2, batch     2 | loss: 84.5386060CurrentTrain: epoch  2, batch     3 | loss: 106.1485522CurrentTrain: epoch  2, batch     4 | loss: 91.7687311CurrentTrain: epoch  2, batch     5 | loss: 65.9503843CurrentTrain: epoch  2, batch     6 | loss: 64.4155270CurrentTrain: epoch  2, batch     7 | loss: 73.3317022CurrentTrain: epoch  2, batch     8 | loss: 105.2077996CurrentTrain: epoch  2, batch     9 | loss: 136.4915290CurrentTrain: epoch  2, batch    10 | loss: 74.4979026CurrentTrain: epoch  2, batch    11 | loss: 180.9352895CurrentTrain: epoch  2, batch    12 | loss: 106.5447402CurrentTrain: epoch  2, batch    13 | loss: 67.1421092CurrentTrain: epoch  2, batch    14 | loss: 131.5367834CurrentTrain: epoch  2, batch    15 | loss: 83.7423463CurrentTrain: epoch  2, batch    16 | loss: 85.4277685CurrentTrain: epoch  2, batch    17 | loss: 82.0979212CurrentTrain: epoch  2, batch    18 | loss: 72.5748563CurrentTrain: epoch  2, batch    19 | loss: 101.0372080CurrentTrain: epoch  2, batch    20 | loss: 74.0327088CurrentTrain: epoch  2, batch    21 | loss: 107.5608866CurrentTrain: epoch  2, batch    22 | loss: 63.9656488CurrentTrain: epoch  2, batch    23 | loss: 73.8939035CurrentTrain: epoch  2, batch    24 | loss: 72.1975083CurrentTrain: epoch  2, batch    25 | loss: 130.6908693CurrentTrain: epoch  2, batch    26 | loss: 109.9159385CurrentTrain: epoch  2, batch    27 | loss: 133.6732144CurrentTrain: epoch  2, batch    28 | loss: 88.3991118CurrentTrain: epoch  2, batch    29 | loss: 105.6493040CurrentTrain: epoch  2, batch    30 | loss: 90.0681829CurrentTrain: epoch  2, batch    31 | loss: 103.6363299CurrentTrain: epoch  2, batch    32 | loss: 85.0946271CurrentTrain: epoch  2, batch    33 | loss: 70.6095652CurrentTrain: epoch  2, batch    34 | loss: 89.8515058CurrentTrain: epoch  2, batch    35 | loss: 89.1413606CurrentTrain: epoch  2, batch    36 | loss: 68.9822765CurrentTrain: epoch  2, batch    37 | loss: 103.6379815CurrentTrain: epoch  2, batch    38 | loss: 84.6145186CurrentTrain: epoch  2, batch    39 | loss: 74.6276460CurrentTrain: epoch  2, batch    40 | loss: 88.8282622CurrentTrain: epoch  2, batch    41 | loss: 76.4856194CurrentTrain: epoch  2, batch    42 | loss: 103.5427440CurrentTrain: epoch  2, batch    43 | loss: 129.2718450CurrentTrain: epoch  2, batch    44 | loss: 72.7994429CurrentTrain: epoch  2, batch    45 | loss: 84.3477478CurrentTrain: epoch  2, batch    46 | loss: 63.9021946CurrentTrain: epoch  2, batch    47 | loss: 100.6905573CurrentTrain: epoch  2, batch    48 | loss: 86.8112550CurrentTrain: epoch  2, batch    49 | loss: 88.9230105CurrentTrain: epoch  2, batch    50 | loss: 87.6545196CurrentTrain: epoch  2, batch    51 | loss: 106.9861474CurrentTrain: epoch  2, batch    52 | loss: 74.8161617CurrentTrain: epoch  2, batch    53 | loss: 131.5014049CurrentTrain: epoch  2, batch    54 | loss: 61.4370480CurrentTrain: epoch  2, batch    55 | loss: 70.8725469CurrentTrain: epoch  2, batch    56 | loss: 101.3813363CurrentTrain: epoch  2, batch    57 | loss: 88.1505469CurrentTrain: epoch  2, batch    58 | loss: 107.7038930CurrentTrain: epoch  2, batch    59 | loss: 75.2414209CurrentTrain: epoch  2, batch    60 | loss: 132.8718912CurrentTrain: epoch  2, batch    61 | loss: 83.5381453CurrentTrain: epoch  2, batch    62 | loss: 83.5821648CurrentTrain: epoch  2, batch    63 | loss: 72.4200667CurrentTrain: epoch  2, batch    64 | loss: 72.8164243CurrentTrain: epoch  2, batch    65 | loss: 83.7934070CurrentTrain: epoch  2, batch    66 | loss: 73.9834848CurrentTrain: epoch  2, batch    67 | loss: 81.8151359CurrentTrain: epoch  2, batch    68 | loss: 87.5827451CurrentTrain: epoch  2, batch    69 | loss: 103.1345935CurrentTrain: epoch  2, batch    70 | loss: 103.8102671CurrentTrain: epoch  2, batch    71 | loss: 65.0791342CurrentTrain: epoch  2, batch    72 | loss: 72.9117143CurrentTrain: epoch  2, batch    73 | loss: 82.3931516CurrentTrain: epoch  2, batch    74 | loss: 85.7088690CurrentTrain: epoch  2, batch    75 | loss: 74.6611513CurrentTrain: epoch  2, batch    76 | loss: 87.9210134CurrentTrain: epoch  2, batch    77 | loss: 126.6158844CurrentTrain: epoch  2, batch    78 | loss: 100.7290227CurrentTrain: epoch  2, batch    79 | loss: 104.0283964CurrentTrain: epoch  2, batch    80 | loss: 62.8469467CurrentTrain: epoch  2, batch    81 | loss: 88.0652842CurrentTrain: epoch  2, batch    82 | loss: 66.6990040CurrentTrain: epoch  2, batch    83 | loss: 83.2000288CurrentTrain: epoch  2, batch    84 | loss: 75.1697276CurrentTrain: epoch  2, batch    85 | loss: 95.4895822CurrentTrain: epoch  2, batch    86 | loss: 102.9321462CurrentTrain: epoch  2, batch    87 | loss: 101.5855854CurrentTrain: epoch  2, batch    88 | loss: 134.3973086CurrentTrain: epoch  2, batch    89 | loss: 74.1870295CurrentTrain: epoch  2, batch    90 | loss: 87.9798335CurrentTrain: epoch  2, batch    91 | loss: 83.9224824CurrentTrain: epoch  2, batch    92 | loss: 84.8642494CurrentTrain: epoch  2, batch    93 | loss: 88.2916430CurrentTrain: epoch  2, batch    94 | loss: 72.1517581CurrentTrain: epoch  2, batch    95 | loss: 88.2383482CurrentTrain: epoch  3, batch     0 | loss: 83.7611770CurrentTrain: epoch  3, batch     1 | loss: 85.5699678CurrentTrain: epoch  3, batch     2 | loss: 99.6146841CurrentTrain: epoch  3, batch     3 | loss: 85.9748512CurrentTrain: epoch  3, batch     4 | loss: 107.6775676CurrentTrain: epoch  3, batch     5 | loss: 61.6479718CurrentTrain: epoch  3, batch     6 | loss: 70.9266527CurrentTrain: epoch  3, batch     7 | loss: 71.1652659CurrentTrain: epoch  3, batch     8 | loss: 126.0212156CurrentTrain: epoch  3, batch     9 | loss: 101.1811752CurrentTrain: epoch  3, batch    10 | loss: 106.8977293CurrentTrain: epoch  3, batch    11 | loss: 104.6506471CurrentTrain: epoch  3, batch    12 | loss: 72.2777091CurrentTrain: epoch  3, batch    13 | loss: 102.5416145CurrentTrain: epoch  3, batch    14 | loss: 101.9127610CurrentTrain: epoch  3, batch    15 | loss: 68.5837531CurrentTrain: epoch  3, batch    16 | loss: 79.0029720CurrentTrain: epoch  3, batch    17 | loss: 82.2767897CurrentTrain: epoch  3, batch    18 | loss: 100.4951894CurrentTrain: epoch  3, batch    19 | loss: 103.7739931CurrentTrain: epoch  3, batch    20 | loss: 75.4540257CurrentTrain: epoch  3, batch    21 | loss: 65.7338522CurrentTrain: epoch  3, batch    22 | loss: 66.4215845CurrentTrain: epoch  3, batch    23 | loss: 124.7433240CurrentTrain: epoch  3, batch    24 | loss: 87.0417115CurrentTrain: epoch  3, batch    25 | loss: 75.1035434CurrentTrain: epoch  3, batch    26 | loss: 102.7119687CurrentTrain: epoch  3, batch    27 | loss: 104.5811644CurrentTrain: epoch  3, batch    28 | loss: 59.2733729CurrentTrain: epoch  3, batch    29 | loss: 69.5366809CurrentTrain: epoch  3, batch    30 | loss: 87.1271788CurrentTrain: epoch  3, batch    31 | loss: 99.0896053CurrentTrain: epoch  3, batch    32 | loss: 101.7542830CurrentTrain: epoch  3, batch    33 | loss: 69.0635415CurrentTrain: epoch  3, batch    34 | loss: 84.6207430CurrentTrain: epoch  3, batch    35 | loss: 56.2207143CurrentTrain: epoch  3, batch    36 | loss: 69.6581086CurrentTrain: epoch  3, batch    37 | loss: 134.1582862CurrentTrain: epoch  3, batch    38 | loss: 82.3911340CurrentTrain: epoch  3, batch    39 | loss: 74.4036631CurrentTrain: epoch  3, batch    40 | loss: 88.3038272CurrentTrain: epoch  3, batch    41 | loss: 85.9811498CurrentTrain: epoch  3, batch    42 | loss: 62.6423986CurrentTrain: epoch  3, batch    43 | loss: 86.8306725CurrentTrain: epoch  3, batch    44 | loss: 97.3227479CurrentTrain: epoch  3, batch    45 | loss: 103.2381187CurrentTrain: epoch  3, batch    46 | loss: 100.5451218CurrentTrain: epoch  3, batch    47 | loss: 60.6359428CurrentTrain: epoch  3, batch    48 | loss: 73.9337183CurrentTrain: epoch  3, batch    49 | loss: 73.8419209CurrentTrain: epoch  3, batch    50 | loss: 69.0189461CurrentTrain: epoch  3, batch    51 | loss: 97.8525485CurrentTrain: epoch  3, batch    52 | loss: 69.9141169CurrentTrain: epoch  3, batch    53 | loss: 86.1984279CurrentTrain: epoch  3, batch    54 | loss: 81.9207024CurrentTrain: epoch  3, batch    55 | loss: 103.5868348CurrentTrain: epoch  3, batch    56 | loss: 84.0718390CurrentTrain: epoch  3, batch    57 | loss: 133.5823370CurrentTrain: epoch  3, batch    58 | loss: 130.8994546CurrentTrain: epoch  3, batch    59 | loss: 129.2545444CurrentTrain: epoch  3, batch    60 | loss: 83.2916077CurrentTrain: epoch  3, batch    61 | loss: 82.0089152CurrentTrain: epoch  3, batch    62 | loss: 103.5464672CurrentTrain: epoch  3, batch    63 | loss: 132.4793969CurrentTrain: epoch  3, batch    64 | loss: 61.6536816CurrentTrain: epoch  3, batch    65 | loss: 73.6837422CurrentTrain: epoch  3, batch    66 | loss: 127.9744482CurrentTrain: epoch  3, batch    67 | loss: 86.9283658CurrentTrain: epoch  3, batch    68 | loss: 58.2792999CurrentTrain: epoch  3, batch    69 | loss: 103.7455739CurrentTrain: epoch  3, batch    70 | loss: 88.1240457CurrentTrain: epoch  3, batch    71 | loss: 68.9645845CurrentTrain: epoch  3, batch    72 | loss: 71.2297399CurrentTrain: epoch  3, batch    73 | loss: 83.4544801CurrentTrain: epoch  3, batch    74 | loss: 88.7136444CurrentTrain: epoch  3, batch    75 | loss: 72.6540073CurrentTrain: epoch  3, batch    76 | loss: 73.1255328CurrentTrain: epoch  3, batch    77 | loss: 71.5000494CurrentTrain: epoch  3, batch    78 | loss: 70.2445698CurrentTrain: epoch  3, batch    79 | loss: 108.9187112CurrentTrain: epoch  3, batch    80 | loss: 87.9919072CurrentTrain: epoch  3, batch    81 | loss: 79.3084620CurrentTrain: epoch  3, batch    82 | loss: 105.7136107CurrentTrain: epoch  3, batch    83 | loss: 101.8878373CurrentTrain: epoch  3, batch    84 | loss: 103.6436529CurrentTrain: epoch  3, batch    85 | loss: 104.7412450CurrentTrain: epoch  3, batch    86 | loss: 100.2883103CurrentTrain: epoch  3, batch    87 | loss: 104.0734735CurrentTrain: epoch  3, batch    88 | loss: 98.8950459CurrentTrain: epoch  3, batch    89 | loss: 60.7687605CurrentTrain: epoch  3, batch    90 | loss: 135.0618261CurrentTrain: epoch  3, batch    91 | loss: 102.2106433CurrentTrain: epoch  3, batch    92 | loss: 87.2778374CurrentTrain: epoch  3, batch    93 | loss: 84.0471527CurrentTrain: epoch  3, batch    94 | loss: 88.6127923CurrentTrain: epoch  3, batch    95 | loss: 70.5356953CurrentTrain: epoch  4, batch     0 | loss: 82.8210997CurrentTrain: epoch  4, batch     1 | loss: 70.2531142CurrentTrain: epoch  4, batch     2 | loss: 69.9548952CurrentTrain: epoch  4, batch     3 | loss: 127.7176206CurrentTrain: epoch  4, batch     4 | loss: 61.4869496CurrentTrain: epoch  4, batch     5 | loss: 72.5841794CurrentTrain: epoch  4, batch     6 | loss: 82.5558179CurrentTrain: epoch  4, batch     7 | loss: 83.3543565CurrentTrain: epoch  4, batch     8 | loss: 125.3865698CurrentTrain: epoch  4, batch     9 | loss: 69.3861989CurrentTrain: epoch  4, batch    10 | loss: 172.0768991CurrentTrain: epoch  4, batch    11 | loss: 126.9397307CurrentTrain: epoch  4, batch    12 | loss: 99.8981221CurrentTrain: epoch  4, batch    13 | loss: 105.3919198CurrentTrain: epoch  4, batch    14 | loss: 84.0328439CurrentTrain: epoch  4, batch    15 | loss: 65.9022641CurrentTrain: epoch  4, batch    16 | loss: 100.3581992CurrentTrain: epoch  4, batch    17 | loss: 70.7675744CurrentTrain: epoch  4, batch    18 | loss: 84.0051419CurrentTrain: epoch  4, batch    19 | loss: 68.2433629CurrentTrain: epoch  4, batch    20 | loss: 85.4953096CurrentTrain: epoch  4, batch    21 | loss: 80.9392884CurrentTrain: epoch  4, batch    22 | loss: 70.6648530CurrentTrain: epoch  4, batch    23 | loss: 101.1013903CurrentTrain: epoch  4, batch    24 | loss: 83.0840781CurrentTrain: epoch  4, batch    25 | loss: 99.7372448CurrentTrain: epoch  4, batch    26 | loss: 104.5817140CurrentTrain: epoch  4, batch    27 | loss: 66.4586403CurrentTrain: epoch  4, batch    28 | loss: 80.1323363CurrentTrain: epoch  4, batch    29 | loss: 99.4347909CurrentTrain: epoch  4, batch    30 | loss: 83.7139629CurrentTrain: epoch  4, batch    31 | loss: 80.8610957CurrentTrain: epoch  4, batch    32 | loss: 83.1825826CurrentTrain: epoch  4, batch    33 | loss: 99.4599278CurrentTrain: epoch  4, batch    34 | loss: 70.3537578CurrentTrain: epoch  4, batch    35 | loss: 133.0513382CurrentTrain: epoch  4, batch    36 | loss: 125.3951921CurrentTrain: epoch  4, batch    37 | loss: 106.1469495CurrentTrain: epoch  4, batch    38 | loss: 83.7253509CurrentTrain: epoch  4, batch    39 | loss: 104.8429869CurrentTrain: epoch  4, batch    40 | loss: 71.8991395CurrentTrain: epoch  4, batch    41 | loss: 69.4184071CurrentTrain: epoch  4, batch    42 | loss: 71.7528128CurrentTrain: epoch  4, batch    43 | loss: 83.5070768CurrentTrain: epoch  4, batch    44 | loss: 85.7142009CurrentTrain: epoch  4, batch    45 | loss: 58.0515982CurrentTrain: epoch  4, batch    46 | loss: 126.4320723CurrentTrain: epoch  4, batch    47 | loss: 81.9032105CurrentTrain: epoch  4, batch    48 | loss: 99.6748603CurrentTrain: epoch  4, batch    49 | loss: 81.7553328CurrentTrain: epoch  4, batch    50 | loss: 85.8664185CurrentTrain: epoch  4, batch    51 | loss: 99.9523368CurrentTrain: epoch  4, batch    52 | loss: 70.3286223CurrentTrain: epoch  4, batch    53 | loss: 86.7229371CurrentTrain: epoch  4, batch    54 | loss: 56.3412917CurrentTrain: epoch  4, batch    55 | loss: 63.5529106CurrentTrain: epoch  4, batch    56 | loss: 128.4790521CurrentTrain: epoch  4, batch    57 | loss: 96.1246054CurrentTrain: epoch  4, batch    58 | loss: 59.1637161CurrentTrain: epoch  4, batch    59 | loss: 73.1996066CurrentTrain: epoch  4, batch    60 | loss: 102.3656666CurrentTrain: epoch  4, batch    61 | loss: 69.7403913CurrentTrain: epoch  4, batch    62 | loss: 84.4690600CurrentTrain: epoch  4, batch    63 | loss: 98.9748633CurrentTrain: epoch  4, batch    64 | loss: 102.3972386CurrentTrain: epoch  4, batch    65 | loss: 97.8748628CurrentTrain: epoch  4, batch    66 | loss: 81.6635466CurrentTrain: epoch  4, batch    67 | loss: 81.5468058CurrentTrain: epoch  4, batch    68 | loss: 86.3559854CurrentTrain: epoch  4, batch    69 | loss: 89.1612544CurrentTrain: epoch  4, batch    70 | loss: 80.5153706CurrentTrain: epoch  4, batch    71 | loss: 70.5306245CurrentTrain: epoch  4, batch    72 | loss: 85.5963266CurrentTrain: epoch  4, batch    73 | loss: 70.6030607CurrentTrain: epoch  4, batch    74 | loss: 84.7195581CurrentTrain: epoch  4, batch    75 | loss: 60.9385261CurrentTrain: epoch  4, batch    76 | loss: 80.9943800CurrentTrain: epoch  4, batch    77 | loss: 104.3729568CurrentTrain: epoch  4, batch    78 | loss: 69.5262943CurrentTrain: epoch  4, batch    79 | loss: 100.0392265CurrentTrain: epoch  4, batch    80 | loss: 84.6719102CurrentTrain: epoch  4, batch    81 | loss: 88.4955386CurrentTrain: epoch  4, batch    82 | loss: 104.0383501CurrentTrain: epoch  4, batch    83 | loss: 81.2914973CurrentTrain: epoch  4, batch    84 | loss: 80.3749748CurrentTrain: epoch  4, batch    85 | loss: 70.5203285CurrentTrain: epoch  4, batch    86 | loss: 166.5206229CurrentTrain: epoch  4, batch    87 | loss: 73.7888879CurrentTrain: epoch  4, batch    88 | loss: 132.5498345CurrentTrain: epoch  4, batch    89 | loss: 72.0637225CurrentTrain: epoch  4, batch    90 | loss: 78.7480035CurrentTrain: epoch  4, batch    91 | loss: 69.8954978CurrentTrain: epoch  4, batch    92 | loss: 80.8016005CurrentTrain: epoch  4, batch    93 | loss: 135.0074689CurrentTrain: epoch  4, batch    94 | loss: 69.8345882CurrentTrain: epoch  4, batch    95 | loss: 69.8549701CurrentTrain: epoch  5, batch     0 | loss: 101.9468436CurrentTrain: epoch  5, batch     1 | loss: 60.8738638CurrentTrain: epoch  5, batch     2 | loss: 67.2703498CurrentTrain: epoch  5, batch     3 | loss: 83.3808835CurrentTrain: epoch  5, batch     4 | loss: 69.4209223CurrentTrain: epoch  5, batch     5 | loss: 103.2357323CurrentTrain: epoch  5, batch     6 | loss: 82.3727500CurrentTrain: epoch  5, batch     7 | loss: 79.5004909CurrentTrain: epoch  5, batch     8 | loss: 58.5421922CurrentTrain: epoch  5, batch     9 | loss: 97.1181854CurrentTrain: epoch  5, batch    10 | loss: 82.5470889CurrentTrain: epoch  5, batch    11 | loss: 101.4152454CurrentTrain: epoch  5, batch    12 | loss: 99.0134055CurrentTrain: epoch  5, batch    13 | loss: 82.8732579CurrentTrain: epoch  5, batch    14 | loss: 68.7978627CurrentTrain: epoch  5, batch    15 | loss: 103.5038522CurrentTrain: epoch  5, batch    16 | loss: 83.8664144CurrentTrain: epoch  5, batch    17 | loss: 80.7126773CurrentTrain: epoch  5, batch    18 | loss: 166.3826443CurrentTrain: epoch  5, batch    19 | loss: 78.8146171CurrentTrain: epoch  5, batch    20 | loss: 84.6842360CurrentTrain: epoch  5, batch    21 | loss: 97.8357500CurrentTrain: epoch  5, batch    22 | loss: 82.6911543CurrentTrain: epoch  5, batch    23 | loss: 78.2120502CurrentTrain: epoch  5, batch    24 | loss: 59.4717595CurrentTrain: epoch  5, batch    25 | loss: 99.8848700CurrentTrain: epoch  5, batch    26 | loss: 88.2739757CurrentTrain: epoch  5, batch    27 | loss: 61.8930684CurrentTrain: epoch  5, batch    28 | loss: 65.2289013CurrentTrain: epoch  5, batch    29 | loss: 99.7637990CurrentTrain: epoch  5, batch    30 | loss: 80.3149629CurrentTrain: epoch  5, batch    31 | loss: 67.6240687CurrentTrain: epoch  5, batch    32 | loss: 95.4838532CurrentTrain: epoch  5, batch    33 | loss: 84.2045316CurrentTrain: epoch  5, batch    34 | loss: 68.7557012CurrentTrain: epoch  5, batch    35 | loss: 63.5639754CurrentTrain: epoch  5, batch    36 | loss: 67.1674453CurrentTrain: epoch  5, batch    37 | loss: 83.6404669CurrentTrain: epoch  5, batch    38 | loss: 63.5600530CurrentTrain: epoch  5, batch    39 | loss: 66.7230406CurrentTrain: epoch  5, batch    40 | loss: 67.8584232CurrentTrain: epoch  5, batch    41 | loss: 79.3657413CurrentTrain: epoch  5, batch    42 | loss: 102.7679508CurrentTrain: epoch  5, batch    43 | loss: 105.2063262CurrentTrain: epoch  5, batch    44 | loss: 122.1848761CurrentTrain: epoch  5, batch    45 | loss: 71.4225891CurrentTrain: epoch  5, batch    46 | loss: 99.1454859CurrentTrain: epoch  5, batch    47 | loss: 59.6334977CurrentTrain: epoch  5, batch    48 | loss: 86.3636153CurrentTrain: epoch  5, batch    49 | loss: 101.7106569CurrentTrain: epoch  5, batch    50 | loss: 79.8262997CurrentTrain: epoch  5, batch    51 | loss: 67.4959140CurrentTrain: epoch  5, batch    52 | loss: 100.8342822CurrentTrain: epoch  5, batch    53 | loss: 63.3597675CurrentTrain: epoch  5, batch    54 | loss: 128.1595925CurrentTrain: epoch  5, batch    55 | loss: 98.2957839CurrentTrain: epoch  5, batch    56 | loss: 70.2468105CurrentTrain: epoch  5, batch    57 | loss: 83.5524475CurrentTrain: epoch  5, batch    58 | loss: 100.3053009CurrentTrain: epoch  5, batch    59 | loss: 71.6852778CurrentTrain: epoch  5, batch    60 | loss: 84.5413840CurrentTrain: epoch  5, batch    61 | loss: 79.4849179CurrentTrain: epoch  5, batch    62 | loss: 70.0367955CurrentTrain: epoch  5, batch    63 | loss: 98.8262968CurrentTrain: epoch  5, batch    64 | loss: 81.2451916CurrentTrain: epoch  5, batch    65 | loss: 82.1168524CurrentTrain: epoch  5, batch    66 | loss: 65.9515729CurrentTrain: epoch  5, batch    67 | loss: 94.0365651CurrentTrain: epoch  5, batch    68 | loss: 99.8073267CurrentTrain: epoch  5, batch    69 | loss: 63.1048459CurrentTrain: epoch  5, batch    70 | loss: 99.9723030CurrentTrain: epoch  5, batch    71 | loss: 58.8069257CurrentTrain: epoch  5, batch    72 | loss: 84.3604634CurrentTrain: epoch  5, batch    73 | loss: 55.4617745CurrentTrain: epoch  5, batch    74 | loss: 81.5546271CurrentTrain: epoch  5, batch    75 | loss: 64.1455765CurrentTrain: epoch  5, batch    76 | loss: 124.4542877CurrentTrain: epoch  5, batch    77 | loss: 83.0758101CurrentTrain: epoch  5, batch    78 | loss: 103.3915734CurrentTrain: epoch  5, batch    79 | loss: 80.0053908CurrentTrain: epoch  5, batch    80 | loss: 100.2157707CurrentTrain: epoch  5, batch    81 | loss: 101.3928930CurrentTrain: epoch  5, batch    82 | loss: 85.4078857CurrentTrain: epoch  5, batch    83 | loss: 174.9023769CurrentTrain: epoch  5, batch    84 | loss: 59.7895935CurrentTrain: epoch  5, batch    85 | loss: 66.2221462CurrentTrain: epoch  5, batch    86 | loss: 179.3113124CurrentTrain: epoch  5, batch    87 | loss: 84.6072484CurrentTrain: epoch  5, batch    88 | loss: 122.3287661CurrentTrain: epoch  5, batch    89 | loss: 65.6568616CurrentTrain: epoch  5, batch    90 | loss: 71.5711741CurrentTrain: epoch  5, batch    91 | loss: 129.0252561CurrentTrain: epoch  5, batch    92 | loss: 68.4578942CurrentTrain: epoch  5, batch    93 | loss: 100.7007005CurrentTrain: epoch  5, batch    94 | loss: 97.2325895CurrentTrain: epoch  5, batch    95 | loss: 110.1959245CurrentTrain: epoch  6, batch     0 | loss: 70.7931116CurrentTrain: epoch  6, batch     1 | loss: 98.6579908CurrentTrain: epoch  6, batch     2 | loss: 77.6172923CurrentTrain: epoch  6, batch     3 | loss: 69.6513335CurrentTrain: epoch  6, batch     4 | loss: 81.2637882CurrentTrain: epoch  6, batch     5 | loss: 97.3185115CurrentTrain: epoch  6, batch     6 | loss: 99.3168371CurrentTrain: epoch  6, batch     7 | loss: 121.3585508CurrentTrain: epoch  6, batch     8 | loss: 66.0557246CurrentTrain: epoch  6, batch     9 | loss: 53.0039091CurrentTrain: epoch  6, batch    10 | loss: 93.1846491CurrentTrain: epoch  6, batch    11 | loss: 82.0577266CurrentTrain: epoch  6, batch    12 | loss: 95.5924765CurrentTrain: epoch  6, batch    13 | loss: 97.1548638CurrentTrain: epoch  6, batch    14 | loss: 58.1602635CurrentTrain: epoch  6, batch    15 | loss: 81.3347750CurrentTrain: epoch  6, batch    16 | loss: 56.2818299CurrentTrain: epoch  6, batch    17 | loss: 70.0507030CurrentTrain: epoch  6, batch    18 | loss: 96.3212246CurrentTrain: epoch  6, batch    19 | loss: 79.0645643CurrentTrain: epoch  6, batch    20 | loss: 57.9389496CurrentTrain: epoch  6, batch    21 | loss: 75.3684474CurrentTrain: epoch  6, batch    22 | loss: 80.6637042CurrentTrain: epoch  6, batch    23 | loss: 97.1285858CurrentTrain: epoch  6, batch    24 | loss: 99.7112004CurrentTrain: epoch  6, batch    25 | loss: 95.5805482CurrentTrain: epoch  6, batch    26 | loss: 78.4927469CurrentTrain: epoch  6, batch    27 | loss: 95.5665658CurrentTrain: epoch  6, batch    28 | loss: 81.3354528CurrentTrain: epoch  6, batch    29 | loss: 69.0495385CurrentTrain: epoch  6, batch    30 | loss: 98.6660277CurrentTrain: epoch  6, batch    31 | loss: 72.7884832CurrentTrain: epoch  6, batch    32 | loss: 57.0426103CurrentTrain: epoch  6, batch    33 | loss: 64.4279808CurrentTrain: epoch  6, batch    34 | loss: 98.1447010CurrentTrain: epoch  6, batch    35 | loss: 65.1453164CurrentTrain: epoch  6, batch    36 | loss: 82.6551143CurrentTrain: epoch  6, batch    37 | loss: 58.6192593CurrentTrain: epoch  6, batch    38 | loss: 97.9908146CurrentTrain: epoch  6, batch    39 | loss: 82.6753712CurrentTrain: epoch  6, batch    40 | loss: 81.9752548CurrentTrain: epoch  6, batch    41 | loss: 129.4330266CurrentTrain: epoch  6, batch    42 | loss: 123.5833126CurrentTrain: epoch  6, batch    43 | loss: 62.4795261CurrentTrain: epoch  6, batch    44 | loss: 84.0476580CurrentTrain: epoch  6, batch    45 | loss: 97.4209787CurrentTrain: epoch  6, batch    46 | loss: 83.1519481CurrentTrain: epoch  6, batch    47 | loss: 101.8022829CurrentTrain: epoch  6, batch    48 | loss: 84.9889194CurrentTrain: epoch  6, batch    49 | loss: 96.6007978CurrentTrain: epoch  6, batch    50 | loss: 123.4658643CurrentTrain: epoch  6, batch    51 | loss: 79.1443218CurrentTrain: epoch  6, batch    52 | loss: 103.3549523CurrentTrain: epoch  6, batch    53 | loss: 98.9178350CurrentTrain: epoch  6, batch    54 | loss: 98.9914651CurrentTrain: epoch  6, batch    55 | loss: 98.5808336CurrentTrain: epoch  6, batch    56 | loss: 101.7720201CurrentTrain: epoch  6, batch    57 | loss: 169.6388643CurrentTrain: epoch  6, batch    58 | loss: 80.7721323CurrentTrain: epoch  6, batch    59 | loss: 73.4100871CurrentTrain: epoch  6, batch    60 | loss: 124.8919833CurrentTrain: epoch  6, batch    61 | loss: 80.3101023CurrentTrain: epoch  6, batch    62 | loss: 98.1632471CurrentTrain: epoch  6, batch    63 | loss: 68.2591364CurrentTrain: epoch  6, batch    64 | loss: 78.9570282CurrentTrain: epoch  6, batch    65 | loss: 69.9015516CurrentTrain: epoch  6, batch    66 | loss: 67.2847029CurrentTrain: epoch  6, batch    67 | loss: 70.3925150CurrentTrain: epoch  6, batch    68 | loss: 81.1653609CurrentTrain: epoch  6, batch    69 | loss: 77.0706446CurrentTrain: epoch  6, batch    70 | loss: 69.2258892CurrentTrain: epoch  6, batch    71 | loss: 64.3987183CurrentTrain: epoch  6, batch    72 | loss: 108.4032608CurrentTrain: epoch  6, batch    73 | loss: 100.7778770CurrentTrain: epoch  6, batch    74 | loss: 59.2442265CurrentTrain: epoch  6, batch    75 | loss: 99.3868261CurrentTrain: epoch  6, batch    76 | loss: 78.8159785CurrentTrain: epoch  6, batch    77 | loss: 77.2246726CurrentTrain: epoch  6, batch    78 | loss: 78.0918898CurrentTrain: epoch  6, batch    79 | loss: 71.6355307CurrentTrain: epoch  6, batch    80 | loss: 80.7965027CurrentTrain: epoch  6, batch    81 | loss: 98.4965477CurrentTrain: epoch  6, batch    82 | loss: 99.8505695CurrentTrain: epoch  6, batch    83 | loss: 54.4677102CurrentTrain: epoch  6, batch    84 | loss: 69.1205590CurrentTrain: epoch  6, batch    85 | loss: 96.5693027CurrentTrain: epoch  6, batch    86 | loss: 65.1589996CurrentTrain: epoch  6, batch    87 | loss: 66.0212118CurrentTrain: epoch  6, batch    88 | loss: 81.7348387CurrentTrain: epoch  6, batch    89 | loss: 78.4199106CurrentTrain: epoch  6, batch    90 | loss: 97.4942248CurrentTrain: epoch  6, batch    91 | loss: 80.6677206CurrentTrain: epoch  6, batch    92 | loss: 66.7508621CurrentTrain: epoch  6, batch    93 | loss: 99.7531956CurrentTrain: epoch  6, batch    94 | loss: 97.8695216CurrentTrain: epoch  6, batch    95 | loss: 80.6970655CurrentTrain: epoch  7, batch     0 | loss: 77.4509495CurrentTrain: epoch  7, batch     1 | loss: 68.0632972CurrentTrain: epoch  7, batch     2 | loss: 123.8603759CurrentTrain: epoch  7, batch     3 | loss: 80.7337946CurrentTrain: epoch  7, batch     4 | loss: 80.9058219CurrentTrain: epoch  7, batch     5 | loss: 77.6918789CurrentTrain: epoch  7, batch     6 | loss: 77.7285887CurrentTrain: epoch  7, batch     7 | loss: 64.4013498CurrentTrain: epoch  7, batch     8 | loss: 68.1498215CurrentTrain: epoch  7, batch     9 | loss: 79.2627748CurrentTrain: epoch  7, batch    10 | loss: 123.7875392CurrentTrain: epoch  7, batch    11 | loss: 83.2799640CurrentTrain: epoch  7, batch    12 | loss: 96.2821009CurrentTrain: epoch  7, batch    13 | loss: 97.7889044CurrentTrain: epoch  7, batch    14 | loss: 57.1526944CurrentTrain: epoch  7, batch    15 | loss: 68.7259867CurrentTrain: epoch  7, batch    16 | loss: 123.6352165CurrentTrain: epoch  7, batch    17 | loss: 82.2300394CurrentTrain: epoch  7, batch    18 | loss: 95.7431762CurrentTrain: epoch  7, batch    19 | loss: 76.7246106CurrentTrain: epoch  7, batch    20 | loss: 95.5370761CurrentTrain: epoch  7, batch    21 | loss: 76.2798398CurrentTrain: epoch  7, batch    22 | loss: 78.8622822CurrentTrain: epoch  7, batch    23 | loss: 80.4647170CurrentTrain: epoch  7, batch    24 | loss: 80.8606500CurrentTrain: epoch  7, batch    25 | loss: 63.7196336CurrentTrain: epoch  7, batch    26 | loss: 76.8118381CurrentTrain: epoch  7, batch    27 | loss: 81.0477522CurrentTrain: epoch  7, batch    28 | loss: 77.9755916CurrentTrain: epoch  7, batch    29 | loss: 58.2572787CurrentTrain: epoch  7, batch    30 | loss: 79.5834411CurrentTrain: epoch  7, batch    31 | loss: 124.5590236CurrentTrain: epoch  7, batch    32 | loss: 79.6893689CurrentTrain: epoch  7, batch    33 | loss: 100.9883846CurrentTrain: epoch  7, batch    34 | loss: 91.8696110CurrentTrain: epoch  7, batch    35 | loss: 95.6351047CurrentTrain: epoch  7, batch    36 | loss: 64.6389339CurrentTrain: epoch  7, batch    37 | loss: 78.6178971CurrentTrain: epoch  7, batch    38 | loss: 95.6158775CurrentTrain: epoch  7, batch    39 | loss: 79.8242501CurrentTrain: epoch  7, batch    40 | loss: 121.2434330CurrentTrain: epoch  7, batch    41 | loss: 103.4488996CurrentTrain: epoch  7, batch    42 | loss: 101.9209959CurrentTrain: epoch  7, batch    43 | loss: 81.6225824CurrentTrain: epoch  7, batch    44 | loss: 68.6078736CurrentTrain: epoch  7, batch    45 | loss: 74.0859033CurrentTrain: epoch  7, batch    46 | loss: 56.3747195CurrentTrain: epoch  7, batch    47 | loss: 70.5366976CurrentTrain: epoch  7, batch    48 | loss: 68.0483964CurrentTrain: epoch  7, batch    49 | loss: 68.6737641CurrentTrain: epoch  7, batch    50 | loss: 78.2664280CurrentTrain: epoch  7, batch    51 | loss: 98.4668124CurrentTrain: epoch  7, batch    52 | loss: 66.2441005CurrentTrain: epoch  7, batch    53 | loss: 75.6911879CurrentTrain: epoch  7, batch    54 | loss: 98.0846633CurrentTrain: epoch  7, batch    55 | loss: 67.6029590CurrentTrain: epoch  7, batch    56 | loss: 66.2720583CurrentTrain: epoch  7, batch    57 | loss: 64.9052164CurrentTrain: epoch  7, batch    58 | loss: 54.9927579CurrentTrain: epoch  7, batch    59 | loss: 127.2921936CurrentTrain: epoch  7, batch    60 | loss: 63.6054474CurrentTrain: epoch  7, batch    61 | loss: 68.5789735CurrentTrain: epoch  7, batch    62 | loss: 79.7236631CurrentTrain: epoch  7, batch    63 | loss: 120.3285045CurrentTrain: epoch  7, batch    64 | loss: 125.7487313CurrentTrain: epoch  7, batch    65 | loss: 99.2471686CurrentTrain: epoch  7, batch    66 | loss: 99.8080828CurrentTrain: epoch  7, batch    67 | loss: 65.4780720CurrentTrain: epoch  7, batch    68 | loss: 66.4428858CurrentTrain: epoch  7, batch    69 | loss: 97.0409488CurrentTrain: epoch  7, batch    70 | loss: 99.7206139CurrentTrain: epoch  7, batch    71 | loss: 77.9329179CurrentTrain: epoch  7, batch    72 | loss: 58.2531769CurrentTrain: epoch  7, batch    73 | loss: 79.5613357CurrentTrain: epoch  7, batch    74 | loss: 130.0551609CurrentTrain: epoch  7, batch    75 | loss: 96.2705845CurrentTrain: epoch  7, batch    76 | loss: 96.4606094CurrentTrain: epoch  7, batch    77 | loss: 129.4455964CurrentTrain: epoch  7, batch    78 | loss: 65.9467433CurrentTrain: epoch  7, batch    79 | loss: 123.8510182CurrentTrain: epoch  7, batch    80 | loss: 82.0386229CurrentTrain: epoch  7, batch    81 | loss: 65.1661415CurrentTrain: epoch  7, batch    82 | loss: 94.8290263CurrentTrain: epoch  7, batch    83 | loss: 66.1065642CurrentTrain: epoch  7, batch    84 | loss: 78.9923670CurrentTrain: epoch  7, batch    85 | loss: 68.2383250CurrentTrain: epoch  7, batch    86 | loss: 68.8152211CurrentTrain: epoch  7, batch    87 | loss: 99.2507799CurrentTrain: epoch  7, batch    88 | loss: 99.9770044CurrentTrain: epoch  7, batch    89 | loss: 75.5376456CurrentTrain: epoch  7, batch    90 | loss: 96.2092765CurrentTrain: epoch  7, batch    91 | loss: 75.0207221CurrentTrain: epoch  7, batch    92 | loss: 64.6945328CurrentTrain: epoch  7, batch    93 | loss: 128.1165821CurrentTrain: epoch  7, batch    94 | loss: 68.5623852CurrentTrain: epoch  7, batch    95 | loss: 80.9023575CurrentTrain: epoch  8, batch     0 | loss: 51.8365883CurrentTrain: epoch  8, batch     1 | loss: 126.2036735CurrentTrain: epoch  8, batch     2 | loss: 79.9995831CurrentTrain: epoch  8, batch     3 | loss: 90.7136633CurrentTrain: epoch  8, batch     4 | loss: 78.6510432CurrentTrain: epoch  8, batch     5 | loss: 65.2493155CurrentTrain: epoch  8, batch     6 | loss: 98.4184141CurrentTrain: epoch  8, batch     7 | loss: 78.5843801CurrentTrain: epoch  8, batch     8 | loss: 76.1443961CurrentTrain: epoch  8, batch     9 | loss: 120.6306870CurrentTrain: epoch  8, batch    10 | loss: 95.8277723CurrentTrain: epoch  8, batch    11 | loss: 96.2889076CurrentTrain: epoch  8, batch    12 | loss: 53.6108407CurrentTrain: epoch  8, batch    13 | loss: 56.7372121CurrentTrain: epoch  8, batch    14 | loss: 58.7633110CurrentTrain: epoch  8, batch    15 | loss: 78.7628169CurrentTrain: epoch  8, batch    16 | loss: 78.2294130CurrentTrain: epoch  8, batch    17 | loss: 61.8631179CurrentTrain: epoch  8, batch    18 | loss: 59.0495902CurrentTrain: epoch  8, batch    19 | loss: 68.0423557CurrentTrain: epoch  8, batch    20 | loss: 63.9772824CurrentTrain: epoch  8, batch    21 | loss: 80.5108518CurrentTrain: epoch  8, batch    22 | loss: 76.9013959CurrentTrain: epoch  8, batch    23 | loss: 56.3552391CurrentTrain: epoch  8, batch    24 | loss: 93.9672213CurrentTrain: epoch  8, batch    25 | loss: 98.3820199CurrentTrain: epoch  8, batch    26 | loss: 79.8282125CurrentTrain: epoch  8, batch    27 | loss: 93.1506646CurrentTrain: epoch  8, batch    28 | loss: 96.5980418CurrentTrain: epoch  8, batch    29 | loss: 95.9512269CurrentTrain: epoch  8, batch    30 | loss: 57.0370558CurrentTrain: epoch  8, batch    31 | loss: 67.6211756CurrentTrain: epoch  8, batch    32 | loss: 62.8408302CurrentTrain: epoch  8, batch    33 | loss: 66.6879642CurrentTrain: epoch  8, batch    34 | loss: 66.8572828CurrentTrain: epoch  8, batch    35 | loss: 70.3239073CurrentTrain: epoch  8, batch    36 | loss: 66.9551381CurrentTrain: epoch  8, batch    37 | loss: 57.4217089CurrentTrain: epoch  8, batch    38 | loss: 65.8719430CurrentTrain: epoch  8, batch    39 | loss: 95.4715093CurrentTrain: epoch  8, batch    40 | loss: 81.8294665CurrentTrain: epoch  8, batch    41 | loss: 80.3210902CurrentTrain: epoch  8, batch    42 | loss: 58.5799981CurrentTrain: epoch  8, batch    43 | loss: 67.4934068CurrentTrain: epoch  8, batch    44 | loss: 76.4120188CurrentTrain: epoch  8, batch    45 | loss: 67.7376589CurrentTrain: epoch  8, batch    46 | loss: 63.3305563CurrentTrain: epoch  8, batch    47 | loss: 90.1990864CurrentTrain: epoch  8, batch    48 | loss: 64.3967308CurrentTrain: epoch  8, batch    49 | loss: 97.0269888CurrentTrain: epoch  8, batch    50 | loss: 77.8646124CurrentTrain: epoch  8, batch    51 | loss: 69.4335812CurrentTrain: epoch  8, batch    52 | loss: 68.7027026CurrentTrain: epoch  8, batch    53 | loss: 72.5063305CurrentTrain: epoch  8, batch    54 | loss: 94.9948541CurrentTrain: epoch  8, batch    55 | loss: 79.4183215CurrentTrain: epoch  8, batch    56 | loss: 118.7790185CurrentTrain: epoch  8, batch    57 | loss: 126.7553920CurrentTrain: epoch  8, batch    58 | loss: 75.3768943CurrentTrain: epoch  8, batch    59 | loss: 66.5239196CurrentTrain: epoch  8, batch    60 | loss: 99.6065762CurrentTrain: epoch  8, batch    61 | loss: 99.7058534CurrentTrain: epoch  8, batch    62 | loss: 80.3958850CurrentTrain: epoch  8, batch    63 | loss: 94.7397682CurrentTrain: epoch  8, batch    64 | loss: 96.6557345CurrentTrain: epoch  8, batch    65 | loss: 76.1137492CurrentTrain: epoch  8, batch    66 | loss: 68.6915947CurrentTrain: epoch  8, batch    67 | loss: 79.6480219CurrentTrain: epoch  8, batch    68 | loss: 66.4288823CurrentTrain: epoch  8, batch    69 | loss: 78.1704227CurrentTrain: epoch  8, batch    70 | loss: 93.9552722CurrentTrain: epoch  8, batch    71 | loss: 69.2262527CurrentTrain: epoch  8, batch    72 | loss: 67.2628963CurrentTrain: epoch  8, batch    73 | loss: 125.3576002CurrentTrain: epoch  8, batch    74 | loss: 124.0659845CurrentTrain: epoch  8, batch    75 | loss: 97.9132734CurrentTrain: epoch  8, batch    76 | loss: 97.8640101CurrentTrain: epoch  8, batch    77 | loss: 118.5574094CurrentTrain: epoch  8, batch    78 | loss: 95.7638800CurrentTrain: epoch  8, batch    79 | loss: 72.7230910CurrentTrain: epoch  8, batch    80 | loss: 62.0302384CurrentTrain: epoch  8, batch    81 | loss: 97.0521873CurrentTrain: epoch  8, batch    82 | loss: 123.5158740CurrentTrain: epoch  8, batch    83 | loss: 95.4587373CurrentTrain: epoch  8, batch    84 | loss: 81.5643178CurrentTrain: epoch  8, batch    85 | loss: 127.0849572CurrentTrain: epoch  8, batch    86 | loss: 80.9939164CurrentTrain: epoch  8, batch    87 | loss: 66.0067095CurrentTrain: epoch  8, batch    88 | loss: 126.9414674CurrentTrain: epoch  8, batch    89 | loss: 69.3866918CurrentTrain: epoch  8, batch    90 | loss: 78.0241070CurrentTrain: epoch  8, batch    91 | loss: 66.8730896CurrentTrain: epoch  8, batch    92 | loss: 76.7048858CurrentTrain: epoch  8, batch    93 | loss: 63.7801065CurrentTrain: epoch  8, batch    94 | loss: 76.9953444CurrentTrain: epoch  8, batch    95 | loss: 81.1737615CurrentTrain: epoch  9, batch     0 | loss: 79.0718564CurrentTrain: epoch  9, batch     1 | loss: 69.4742293CurrentTrain: epoch  9, batch     2 | loss: 64.3313361CurrentTrain: epoch  9, batch     3 | loss: 80.9524840CurrentTrain: epoch  9, batch     4 | loss: 80.3858053CurrentTrain: epoch  9, batch     5 | loss: 94.5741140CurrentTrain: epoch  9, batch     6 | loss: 75.0380508CurrentTrain: epoch  9, batch     7 | loss: 54.1676878CurrentTrain: epoch  9, batch     8 | loss: 75.2998714CurrentTrain: epoch  9, batch     9 | loss: 97.9415250CurrentTrain: epoch  9, batch    10 | loss: 66.7254887CurrentTrain: epoch  9, batch    11 | loss: 54.6177926CurrentTrain: epoch  9, batch    12 | loss: 79.2045290CurrentTrain: epoch  9, batch    13 | loss: 93.0236122CurrentTrain: epoch  9, batch    14 | loss: 62.6444387CurrentTrain: epoch  9, batch    15 | loss: 94.5690353CurrentTrain: epoch  9, batch    16 | loss: 79.0296704CurrentTrain: epoch  9, batch    17 | loss: 73.8084171CurrentTrain: epoch  9, batch    18 | loss: 80.4357181CurrentTrain: epoch  9, batch    19 | loss: 76.4542023CurrentTrain: epoch  9, batch    20 | loss: 92.4665675CurrentTrain: epoch  9, batch    21 | loss: 65.4036353CurrentTrain: epoch  9, batch    22 | loss: 70.9649386CurrentTrain: epoch  9, batch    23 | loss: 81.3513601CurrentTrain: epoch  9, batch    24 | loss: 64.0170581CurrentTrain: epoch  9, batch    25 | loss: 100.6883983CurrentTrain: epoch  9, batch    26 | loss: 64.8313624CurrentTrain: epoch  9, batch    27 | loss: 75.9137363CurrentTrain: epoch  9, batch    28 | loss: 76.8798471CurrentTrain: epoch  9, batch    29 | loss: 73.9813146CurrentTrain: epoch  9, batch    30 | loss: 76.2217435CurrentTrain: epoch  9, batch    31 | loss: 72.2057716CurrentTrain: epoch  9, batch    32 | loss: 67.4697176CurrentTrain: epoch  9, batch    33 | loss: 76.5706677CurrentTrain: epoch  9, batch    34 | loss: 75.1348256CurrentTrain: epoch  9, batch    35 | loss: 77.7715859CurrentTrain: epoch  9, batch    36 | loss: 98.2794875CurrentTrain: epoch  9, batch    37 | loss: 171.1276577CurrentTrain: epoch  9, batch    38 | loss: 94.3853862CurrentTrain: epoch  9, batch    39 | loss: 80.7867907CurrentTrain: epoch  9, batch    40 | loss: 63.0187971CurrentTrain: epoch  9, batch    41 | loss: 80.0653441CurrentTrain: epoch  9, batch    42 | loss: 65.2246503CurrentTrain: epoch  9, batch    43 | loss: 79.5757044CurrentTrain: epoch  9, batch    44 | loss: 64.1687276CurrentTrain: epoch  9, batch    45 | loss: 93.3031817CurrentTrain: epoch  9, batch    46 | loss: 80.0212074CurrentTrain: epoch  9, batch    47 | loss: 65.1961580CurrentTrain: epoch  9, batch    48 | loss: 78.8639745CurrentTrain: epoch  9, batch    49 | loss: 70.2825000CurrentTrain: epoch  9, batch    50 | loss: 64.1242669CurrentTrain: epoch  9, batch    51 | loss: 78.1923858CurrentTrain: epoch  9, batch    52 | loss: 66.0794386CurrentTrain: epoch  9, batch    53 | loss: 126.1366830CurrentTrain: epoch  9, batch    54 | loss: 64.7362389CurrentTrain: epoch  9, batch    55 | loss: 123.4295718CurrentTrain: epoch  9, batch    56 | loss: 97.8352672CurrentTrain: epoch  9, batch    57 | loss: 77.2465258CurrentTrain: epoch  9, batch    58 | loss: 95.7423666CurrentTrain: epoch  9, batch    59 | loss: 92.2214114CurrentTrain: epoch  9, batch    60 | loss: 79.0552665CurrentTrain: epoch  9, batch    61 | loss: 84.4327693CurrentTrain: epoch  9, batch    62 | loss: 66.1320582CurrentTrain: epoch  9, batch    63 | loss: 75.3882680CurrentTrain: epoch  9, batch    64 | loss: 127.9119987CurrentTrain: epoch  9, batch    65 | loss: 96.3502044CurrentTrain: epoch  9, batch    66 | loss: 81.8559665CurrentTrain: epoch  9, batch    67 | loss: 95.4625590CurrentTrain: epoch  9, batch    68 | loss: 124.3959714CurrentTrain: epoch  9, batch    69 | loss: 93.9001929CurrentTrain: epoch  9, batch    70 | loss: 75.2755567CurrentTrain: epoch  9, batch    71 | loss: 68.2355507CurrentTrain: epoch  9, batch    72 | loss: 55.8540278CurrentTrain: epoch  9, batch    73 | loss: 68.0160974CurrentTrain: epoch  9, batch    74 | loss: 74.2393687CurrentTrain: epoch  9, batch    75 | loss: 81.3693959CurrentTrain: epoch  9, batch    76 | loss: 65.5952300CurrentTrain: epoch  9, batch    77 | loss: 119.9405328CurrentTrain: epoch  9, batch    78 | loss: 92.0345253CurrentTrain: epoch  9, batch    79 | loss: 52.7069353CurrentTrain: epoch  9, batch    80 | loss: 56.7913790CurrentTrain: epoch  9, batch    81 | loss: 58.7163763CurrentTrain: epoch  9, batch    82 | loss: 66.8723344CurrentTrain: epoch  9, batch    83 | loss: 65.9688714CurrentTrain: epoch  9, batch    84 | loss: 83.7204982CurrentTrain: epoch  9, batch    85 | loss: 70.4834762CurrentTrain: epoch  9, batch    86 | loss: 55.8143184CurrentTrain: epoch  9, batch    87 | loss: 76.5297797CurrentTrain: epoch  9, batch    88 | loss: 92.8648183CurrentTrain: epoch  9, batch    89 | loss: 66.0471379CurrentTrain: epoch  9, batch    90 | loss: 76.6884544CurrentTrain: epoch  9, batch    91 | loss: 69.2521816CurrentTrain: epoch  9, batch    92 | loss: 125.0765688CurrentTrain: epoch  9, batch    93 | loss: 79.5006248CurrentTrain: epoch  9, batch    94 | loss: 74.6557519CurrentTrain: epoch  9, batch    95 | loss: 102.5996692

F1 score per class: {32: np.float64(0.6217616580310881), 6: np.float64(0.8159203980099502), 19: np.float64(0.35294117647058826), 24: np.float64(0.7613636363636364), 26: np.float64(0.934010152284264), 29: np.float64(0.8544600938967136)}
Micro-average F1 score: 0.7850098619329389
Weighted-average F1 score: 0.7880956954938795
F1 score per class: {32: np.float64(0.625), 6: np.float64(0.782608695652174), 19: np.float64(0.28), 24: np.float64(0.7165775401069518), 26: np.float64(0.9292929292929293), 29: np.float64(0.864321608040201)}
Micro-average F1 score: 0.7554347826086957
Weighted-average F1 score: 0.7460408237043931
F1 score per class: {32: np.float64(0.6431718061674009), 6: np.float64(0.8), 19: np.float64(0.32558139534883723), 24: np.float64(0.7243243243243244), 26: np.float64(0.9346733668341709), 29: np.float64(0.87)}
Micro-average F1 score: 0.7728119180633147
Weighted-average F1 score: 0.7678463761710995

F1 score per class: {32: np.float64(0.6217616580310881), 6: np.float64(0.8159203980099502), 19: np.float64(0.35294117647058826), 24: np.float64(0.7613636363636364), 26: np.float64(0.934010152284264), 29: np.float64(0.8544600938967136)}
Micro-average F1 score: 0.7850098619329389
Weighted-average F1 score: 0.7880956954938795
F1 score per class: {32: np.float64(0.625), 6: np.float64(0.782608695652174), 19: np.float64(0.28), 24: np.float64(0.7165775401069518), 26: np.float64(0.9292929292929293), 29: np.float64(0.864321608040201)}
Micro-average F1 score: 0.7554347826086957
Weighted-average F1 score: 0.7460408237043931
F1 score per class: {32: np.float64(0.6431718061674009), 6: np.float64(0.8), 19: np.float64(0.32558139534883723), 24: np.float64(0.7243243243243244), 26: np.float64(0.9346733668341709), 29: np.float64(0.87)}
Micro-average F1 score: 0.7728119180633147
Weighted-average F1 score: 0.7678463761710995

F1 score per class: {32: np.float64(0.4580152671755725), 6: np.float64(0.7735849056603774), 19: np.float64(0.24), 24: np.float64(0.7052631578947368), 26: np.float64(0.8598130841121495), 29: np.float64(0.6618181818181819)}
Micro-average F1 score: 0.6616791354945969
Weighted-average F1 score: 0.6508475041370776
F1 score per class: {32: np.float64(0.42492917847025496), 6: np.float64(0.7258064516129032), 19: np.float64(0.1728395061728395), 24: np.float64(0.6536585365853659), 26: np.float64(0.8401826484018264), 29: np.float64(0.6991869918699187)}
Micro-average F1 score: 0.6168639053254438
Weighted-average F1 score: 0.5953387388427602
F1 score per class: {32: np.float64(0.44376899696048633), 6: np.float64(0.7489361702127659), 19: np.float64(0.2153846153846154), 24: np.float64(0.6633663366336634), 26: np.float64(0.8454545454545455), 29: np.float64(0.696)}
Micro-average F1 score: 0.6379707916986933
Weighted-average F1 score: 0.6211627994852246

F1 score per class: {32: np.float64(0.4580152671755725), 6: np.float64(0.7735849056603774), 19: np.float64(0.24), 24: np.float64(0.7052631578947368), 26: np.float64(0.8598130841121495), 29: np.float64(0.6618181818181819)}
Micro-average F1 score: 0.6616791354945969
Weighted-average F1 score: 0.6508475041370776
F1 score per class: {32: np.float64(0.42492917847025496), 6: np.float64(0.7258064516129032), 19: np.float64(0.1728395061728395), 24: np.float64(0.6536585365853659), 26: np.float64(0.8401826484018264), 29: np.float64(0.6991869918699187)}
Micro-average F1 score: 0.6168639053254438
Weighted-average F1 score: 0.5953387388427602
F1 score per class: {32: np.float64(0.44376899696048633), 6: np.float64(0.7489361702127659), 19: np.float64(0.2153846153846154), 24: np.float64(0.6633663366336634), 26: np.float64(0.8454545454545455), 29: np.float64(0.696)}
Micro-average F1 score: 0.6379707916986933
Weighted-average F1 score: 0.6211627994852246
cur_acc_wo_na:  ['0.7850']
his_acc_wo_na:  ['0.7850']
cur_acc des_wo_na:  ['0.7554']
his_acc des_wo_na:  ['0.7554']
cur_acc rrf_wo_na:  ['0.7728']
his_acc rrf_wo_na:  ['0.7728']
cur_acc_w_na:  ['0.6617']
his_acc_w_na:  ['0.6617']
cur_acc des_w_na:  ['0.6169']
his_acc des_w_na:  ['0.6169']
cur_acc rrf_w_na:  ['0.6380']
his_acc rrf_w_na:  ['0.6380']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 84.8909454CurrentTrain: epoch  0, batch     1 | loss: 149.1717318CurrentTrain: epoch  0, batch     2 | loss: 113.8553749CurrentTrain: epoch  0, batch     3 | loss: 90.9995049CurrentTrain: epoch  0, batch     4 | loss: 119.0081465CurrentTrain: epoch  1, batch     0 | loss: 90.8345334CurrentTrain: epoch  1, batch     1 | loss: 108.7640039CurrentTrain: epoch  1, batch     2 | loss: 77.4831904CurrentTrain: epoch  1, batch     3 | loss: 107.0098011CurrentTrain: epoch  1, batch     4 | loss: 59.3775108CurrentTrain: epoch  2, batch     0 | loss: 85.1444006CurrentTrain: epoch  2, batch     1 | loss: 127.3471308CurrentTrain: epoch  2, batch     2 | loss: 106.4886803CurrentTrain: epoch  2, batch     3 | loss: 89.7924939CurrentTrain: epoch  2, batch     4 | loss: 66.3985545CurrentTrain: epoch  3, batch     0 | loss: 106.3964615CurrentTrain: epoch  3, batch     1 | loss: 83.5435956CurrentTrain: epoch  3, batch     2 | loss: 103.8248969CurrentTrain: epoch  3, batch     3 | loss: 100.6806887CurrentTrain: epoch  3, batch     4 | loss: 85.1777350CurrentTrain: epoch  4, batch     0 | loss: 99.9010898CurrentTrain: epoch  4, batch     1 | loss: 71.0562105CurrentTrain: epoch  4, batch     2 | loss: 129.4721594CurrentTrain: epoch  4, batch     3 | loss: 69.4170975CurrentTrain: epoch  4, batch     4 | loss: 82.9729203CurrentTrain: epoch  5, batch     0 | loss: 68.6838428CurrentTrain: epoch  5, batch     1 | loss: 102.0951293CurrentTrain: epoch  5, batch     2 | loss: 101.1336587CurrentTrain: epoch  5, batch     3 | loss: 126.1869404CurrentTrain: epoch  5, batch     4 | loss: 58.7605773CurrentTrain: epoch  6, batch     0 | loss: 81.1184177CurrentTrain: epoch  6, batch     1 | loss: 68.6479225CurrentTrain: epoch  6, batch     2 | loss: 121.8752347CurrentTrain: epoch  6, batch     3 | loss: 81.3180840CurrentTrain: epoch  6, batch     4 | loss: 109.3103934CurrentTrain: epoch  7, batch     0 | loss: 100.2828389CurrentTrain: epoch  7, batch     1 | loss: 95.8218370CurrentTrain: epoch  7, batch     2 | loss: 125.4555459CurrentTrain: epoch  7, batch     3 | loss: 63.2641515CurrentTrain: epoch  7, batch     4 | loss: 75.3198765CurrentTrain: epoch  8, batch     0 | loss: 67.6934326CurrentTrain: epoch  8, batch     1 | loss: 97.1582987CurrentTrain: epoch  8, batch     2 | loss: 80.9871539CurrentTrain: epoch  8, batch     3 | loss: 80.0085629CurrentTrain: epoch  8, batch     4 | loss: 57.3971970CurrentTrain: epoch  9, batch     0 | loss: 81.0374848CurrentTrain: epoch  9, batch     1 | loss: 95.2521413CurrentTrain: epoch  9, batch     2 | loss: 74.9121645CurrentTrain: epoch  9, batch     3 | loss: 79.8698273CurrentTrain: epoch  9, batch     4 | loss: 59.3414249
MemoryTrain:  epoch  0, batch     0 | loss: 1.9021658MemoryTrain:  epoch  1, batch     0 | loss: 1.4665182MemoryTrain:  epoch  2, batch     0 | loss: 1.2125036MemoryTrain:  epoch  3, batch     0 | loss: 1.0168166MemoryTrain:  epoch  4, batch     0 | loss: 0.8534763MemoryTrain:  epoch  5, batch     0 | loss: 0.7426391MemoryTrain:  epoch  6, batch     0 | loss: 0.6295171MemoryTrain:  epoch  7, batch     0 | loss: 0.4695550MemoryTrain:  epoch  8, batch     0 | loss: 0.4777782MemoryTrain:  epoch  9, batch     0 | loss: 0.4256814

F1 score per class: {32: np.float64(0.9108910891089109), 5: np.float64(0.0), 6: np.float64(0.16216216216216217), 10: np.float64(0.6666666666666666), 16: np.float64(0.4444444444444444), 17: np.float64(0.0975609756097561), 18: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5474613686534217
Weighted-average F1 score: 0.6388978461883149
F1 score per class: {32: np.float64(0.7773279352226721), 5: np.float64(0.0), 6: np.float64(0.543046357615894), 10: np.float64(0.6206896551724138), 16: np.float64(0.25), 17: np.float64(0.45569620253164556), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5843071786310517
Weighted-average F1 score: 0.5579910884436536
F1 score per class: {32: np.float64(0.8230088495575221), 5: np.float64(0.0), 6: np.float64(0.4931506849315068), 10: np.float64(0.6428571428571429), 16: np.float64(0.25), 17: np.float64(0.375), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5854545454545454
Weighted-average F1 score: 0.5655961031583314

F1 score per class: {32: np.float64(0.9108910891089109), 5: np.float64(0.5983606557377049), 6: np.float64(0.1565217391304348), 10: np.float64(0.6415094339622641), 16: np.float64(0.16326530612244897), 17: np.float64(0.09302325581395349), 18: np.float64(0.8333333333333334), 19: np.float64(0.26666666666666666), 24: np.float64(0.6904761904761905), 26: np.float64(0.8865979381443299), 29: np.float64(0.8333333333333334)}
Micro-average F1 score: 0.6851119894598156
Weighted-average F1 score: 0.7183591724233288
F1 score per class: {32: np.float64(0.735632183908046), 5: np.float64(0.5714285714285714), 6: np.float64(0.48520710059171596), 10: np.float64(0.5901639344262295), 16: np.float64(0.10256410256410256), 17: np.float64(0.4090909090909091), 18: np.float64(0.7583333333333333), 19: np.float64(0.36363636363636365), 24: np.float64(0.7222222222222222), 26: np.float64(0.9064039408866995), 29: np.float64(0.8411214953271028)}
Micro-average F1 score: 0.6745495495495496
Weighted-average F1 score: 0.6676734237194998
F1 score per class: {32: np.float64(0.7982832618025751), 5: np.float64(0.5735849056603773), 6: np.float64(0.43636363636363634), 10: np.float64(0.6101694915254238), 16: np.float64(0.10526315789473684), 17: np.float64(0.34782608695652173), 18: np.float64(0.7946428571428571), 19: np.float64(0.38095238095238093), 24: np.float64(0.7262569832402235), 26: np.float64(0.9045226130653267), 29: np.float64(0.8411214953271028)}
Micro-average F1 score: 0.6864256075874333
Weighted-average F1 score: 0.6848188840967979

F1 score per class: {32: np.float64(0.8), 5: np.float64(0.0), 6: np.float64(0.15789473684210525), 10: np.float64(0.4722222222222222), 16: np.float64(0.24242424242424243), 17: np.float64(0.09523809523809523), 18: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.43508771929824563
Weighted-average F1 score: 0.450130040624133
F1 score per class: {32: np.float64(0.617363344051447), 5: np.float64(0.0), 6: np.float64(0.4685714285714286), 10: np.float64(0.3956043956043956), 16: np.float64(0.17391304347826086), 17: np.float64(0.27692307692307694), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.40792540792540793
Weighted-average F1 score: 0.3741014083026158
F1 score per class: {32: np.float64(0.6690647482014388), 5: np.float64(0.0), 6: np.float64(0.42857142857142855), 10: np.float64(0.4186046511627907), 16: np.float64(0.17391304347826086), 17: np.float64(0.22641509433962265), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.41229193341869397
Weighted-average F1 score: 0.3757141918929884

F1 score per class: {32: np.float64(0.7965367965367965), 5: np.float64(0.37823834196891193), 6: np.float64(0.1487603305785124), 10: np.float64(0.425), 16: np.float64(0.09876543209876543), 17: np.float64(0.08695652173913043), 18: np.float64(0.7727272727272727), 19: np.float64(0.18181818181818182), 24: np.float64(0.6304347826086957), 26: np.float64(0.7782805429864253), 29: np.float64(0.631578947368421)}
Micro-average F1 score: 0.5476566614007372
Weighted-average F1 score: 0.5486111231280837
F1 score per class: {32: np.float64(0.56973293768546), 5: np.float64(0.34234234234234234), 6: np.float64(0.3886255924170616), 10: np.float64(0.3564356435643564), 16: np.float64(0.06896551724137931), 17: np.float64(0.24), 18: np.float64(0.6691176470588235), 19: np.float64(0.1941747572815534), 24: np.float64(0.6403940886699507), 26: np.float64(0.7603305785123967), 29: np.float64(0.6498194945848376)}
Micro-average F1 score: 0.49958298582151794
Weighted-average F1 score: 0.481468096807819
F1 score per class: {32: np.float64(0.6348122866894198), 5: np.float64(0.3431151241534989), 6: np.float64(0.35294117647058826), 10: np.float64(0.375), 16: np.float64(0.06896551724137931), 17: np.float64(0.2033898305084746), 18: np.float64(0.726530612244898), 19: np.float64(0.21621621621621623), 24: np.float64(0.6532663316582915), 26: np.float64(0.7692307692307693), 29: np.float64(0.6405693950177936)}
Micro-average F1 score: 0.5158129175946548
Weighted-average F1 score: 0.4980464680755316
cur_acc_wo_na:  ['0.7850', '0.5475']
his_acc_wo_na:  ['0.7850', '0.6851']
cur_acc des_wo_na:  ['0.7554', '0.5843']
his_acc des_wo_na:  ['0.7554', '0.6745']
cur_acc rrf_wo_na:  ['0.7728', '0.5855']
his_acc rrf_wo_na:  ['0.7728', '0.6864']
cur_acc_w_na:  ['0.6617', '0.4351']
his_acc_w_na:  ['0.6617', '0.5477']
cur_acc des_w_na:  ['0.6169', '0.4079']
his_acc des_w_na:  ['0.6169', '0.4996']
cur_acc rrf_w_na:  ['0.6380', '0.4123']
his_acc rrf_w_na:  ['0.6380', '0.5158']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 99.0371148CurrentTrain: epoch  0, batch     1 | loss: 82.3824104CurrentTrain: epoch  0, batch     2 | loss: 80.5683792CurrentTrain: epoch  0, batch     3 | loss: 10.4728544CurrentTrain: epoch  1, batch     0 | loss: 76.6712876CurrentTrain: epoch  1, batch     1 | loss: 75.8306769CurrentTrain: epoch  1, batch     2 | loss: 70.9483848CurrentTrain: epoch  1, batch     3 | loss: 19.3102760CurrentTrain: epoch  2, batch     0 | loss: 66.5821502CurrentTrain: epoch  2, batch     1 | loss: 84.1897978CurrentTrain: epoch  2, batch     2 | loss: 100.2444469CurrentTrain: epoch  2, batch     3 | loss: 19.4988889CurrentTrain: epoch  3, batch     0 | loss: 67.5870316CurrentTrain: epoch  3, batch     1 | loss: 72.4655219CurrentTrain: epoch  3, batch     2 | loss: 81.5642438CurrentTrain: epoch  3, batch     3 | loss: 11.0629607CurrentTrain: epoch  4, batch     0 | loss: 65.8178808CurrentTrain: epoch  4, batch     1 | loss: 67.3662505CurrentTrain: epoch  4, batch     2 | loss: 68.7723064CurrentTrain: epoch  4, batch     3 | loss: 19.4227173CurrentTrain: epoch  5, batch     0 | loss: 64.2590116CurrentTrain: epoch  5, batch     1 | loss: 63.9373470CurrentTrain: epoch  5, batch     2 | loss: 68.9070945CurrentTrain: epoch  5, batch     3 | loss: 17.9744879CurrentTrain: epoch  6, batch     0 | loss: 65.7480506CurrentTrain: epoch  6, batch     1 | loss: 61.4323046CurrentTrain: epoch  6, batch     2 | loss: 65.6847702CurrentTrain: epoch  6, batch     3 | loss: 20.6740331CurrentTrain: epoch  7, batch     0 | loss: 58.8109559CurrentTrain: epoch  7, batch     1 | loss: 73.5656222CurrentTrain: epoch  7, batch     2 | loss: 95.9635420CurrentTrain: epoch  7, batch     3 | loss: 41.9502298CurrentTrain: epoch  8, batch     0 | loss: 62.9695795CurrentTrain: epoch  8, batch     1 | loss: 62.3831607CurrentTrain: epoch  8, batch     2 | loss: 62.5856858CurrentTrain: epoch  8, batch     3 | loss: 17.6697066CurrentTrain: epoch  9, batch     0 | loss: 75.9285517CurrentTrain: epoch  9, batch     1 | loss: 72.8586167CurrentTrain: epoch  9, batch     2 | loss: 72.6927645CurrentTrain: epoch  9, batch     3 | loss: 9.4915166
MemoryTrain:  epoch  0, batch     0 | loss: 1.2986554MemoryTrain:  epoch  1, batch     0 | loss: 1.0569225MemoryTrain:  epoch  2, batch     0 | loss: 0.9039883MemoryTrain:  epoch  3, batch     0 | loss: 0.7500886MemoryTrain:  epoch  4, batch     0 | loss: 0.5385674MemoryTrain:  epoch  5, batch     0 | loss: 0.5351281MemoryTrain:  epoch  6, batch     0 | loss: 0.4129514MemoryTrain:  epoch  7, batch     0 | loss: 0.3602193MemoryTrain:  epoch  8, batch     0 | loss: 0.2954213MemoryTrain:  epoch  9, batch     0 | loss: 0.2529068

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6), 7: np.float64(0.8727272727272727), 40: np.float64(0.0), 9: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.42105263157894735), 26: np.float64(0.4), 27: np.float64(0.0), 31: np.float64(0.22535211267605634)}
Micro-average F1 score: 0.3210702341137124
Weighted-average F1 score: 0.26330520560320414
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6), 7: np.float64(0.684931506849315), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.47619047619047616), 26: np.float64(0.18181818181818182), 27: np.float64(0.0), 31: np.float64(0.352)}
Micro-average F1 score: 0.35782747603833864
Weighted-average F1 score: 0.3050335088834435
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6666666666666666), 7: np.float64(0.75), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.5714285714285714), 26: np.float64(0.2857142857142857), 27: np.float64(0.0), 31: np.float64(0.3484848484848485)}
Micro-average F1 score: 0.38
Weighted-average F1 score: 0.31972955360052135

F1 score per class: {32: np.float64(0.8803827751196173), 5: np.float64(0.36046511627906974), 6: np.float64(0.049586776859504134), 7: np.float64(0.8727272727272727), 40: np.float64(0.272), 10: np.float64(0.5714285714285714), 9: np.float64(0.0), 16: np.float64(0.09090909090909091), 17: np.float64(0.624), 18: np.float64(0.1), 19: np.float64(0.7314285714285714), 24: np.float64(0.32), 26: np.float64(0.8602150537634409), 27: np.float64(0.2857142857142857), 29: np.float64(0.8275862068965517), 31: np.float64(0.09968847352024922)}
Micro-average F1 score: 0.5184436584133401
Weighted-average F1 score: 0.4795860377206062
F1 score per class: {32: np.float64(0.6643109540636042), 5: np.float64(0.3670886075949367), 6: np.float64(0.0410958904109589), 7: np.float64(0.6329113924050633), 40: np.float64(0.4125), 10: np.float64(0.53125), 9: np.float64(0.0), 16: np.float64(0.35135135135135137), 17: np.float64(0.6311787072243346), 18: np.float64(0.2702702702702703), 19: np.float64(0.7292817679558011), 24: np.float64(0.38461538461538464), 26: np.float64(0.8854166666666666), 27: np.float64(0.125), 29: np.float64(0.8514851485148515), 31: np.float64(0.2037037037037037)}
Micro-average F1 score: 0.5384615384615384
Weighted-average F1 score: 0.5094394177184285
F1 score per class: {32: np.float64(0.7666666666666667), 5: np.float64(0.33532934131736525), 6: np.float64(0.046153846153846156), 7: np.float64(0.75), 40: np.float64(0.34285714285714286), 10: np.float64(0.576271186440678), 9: np.float64(0.0), 16: np.float64(0.25925925925925924), 17: np.float64(0.6507936507936508), 18: np.float64(0.2222222222222222), 19: np.float64(0.7333333333333333), 24: np.float64(0.41379310344827586), 26: np.float64(0.8854166666666666), 27: np.float64(0.2), 29: np.float64(0.8390243902439024), 31: np.float64(0.19166666666666668)}
Micro-average F1 score: 0.5475475475475475
Weighted-average F1 score: 0.5222327887315451

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6), 7: np.float64(0.8), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.4), 26: np.float64(0.0), 27: np.float64(0.4), 29: np.float64(0.0), 31: np.float64(0.19393939393939394)}
Micro-average F1 score: 0.2807017543859649
Weighted-average F1 score: 0.23250930356193517
F1 score per class: {32: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.5813953488372093), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.45454545454545453), 26: np.float64(0.14285714285714285), 27: np.float64(0.0), 31: np.float64(0.3188405797101449)}
Micro-average F1 score: 0.30684931506849317
Weighted-average F1 score: 0.264971140697759
F1 score per class: {32: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.6666666666666666), 7: np.float64(0.6857142857142857), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.5454545454545454), 26: np.float64(0.0), 27: np.float64(0.2), 29: np.float64(0.0), 31: np.float64(0.3129251700680272)}
Micro-average F1 score: 0.3313953488372093
Weighted-average F1 score: 0.2785577155763491

F1 score per class: {32: np.float64(0.7301587301587301), 5: np.float64(0.24899598393574296), 6: np.float64(0.0273972602739726), 7: np.float64(0.7868852459016393), 40: np.float64(0.22666666666666666), 10: np.float64(0.3333333333333333), 9: np.float64(0.0), 16: np.float64(0.08695652173913043), 17: np.float64(0.5909090909090909), 18: np.float64(0.08695652173913043), 19: np.float64(0.6736842105263158), 24: np.float64(0.27586206896551724), 26: np.float64(0.7582938388625592), 27: np.float64(0.2222222222222222), 29: np.float64(0.6942148760330579), 31: np.float64(0.07785888077858881)}
Micro-average F1 score: 0.41404358353510895
Weighted-average F1 score: 0.37516177940533685
F1 score per class: {32: np.float64(0.49214659685863876), 5: np.float64(0.25327510917030566), 6: np.float64(0.023346303501945526), 7: np.float64(0.5154639175257731), 40: np.float64(0.32195121951219513), 10: np.float64(0.32075471698113206), 9: np.float64(0.0), 16: np.float64(0.23636363636363636), 17: np.float64(0.5845070422535211), 18: np.float64(0.18518518518518517), 19: np.float64(0.6534653465346535), 24: np.float64(0.3333333333333333), 26: np.float64(0.7623318385650224), 27: np.float64(0.08), 29: np.float64(0.6991869918699187), 31: np.float64(0.16730038022813687)}
Micro-average F1 score: 0.4158415841584158
Weighted-average F1 score: 0.38824827024371966
F1 score per class: {32: np.float64(0.5714285714285714), 5: np.float64(0.22764227642276422), 6: np.float64(0.025974025974025976), 7: np.float64(0.6575342465753424), 40: np.float64(0.2807017543859649), 10: np.float64(0.3434343434343434), 9: np.float64(0.0), 16: np.float64(0.1917808219178082), 17: np.float64(0.6119402985074627), 18: np.float64(0.17142857142857143), 19: np.float64(0.6567164179104478), 24: np.float64(0.34285714285714286), 26: np.float64(0.7727272727272727), 27: np.float64(0.11764705882352941), 29: np.float64(0.6907630522088354), 31: np.float64(0.1564625850340136)}
Micro-average F1 score: 0.42952493129171576
Weighted-average F1 score: 0.4025416396236929
cur_acc_wo_na:  ['0.7850', '0.5475', '0.3211']
his_acc_wo_na:  ['0.7850', '0.6851', '0.5184']
cur_acc des_wo_na:  ['0.7554', '0.5843', '0.3578']
his_acc des_wo_na:  ['0.7554', '0.6745', '0.5385']
cur_acc rrf_wo_na:  ['0.7728', '0.5855', '0.3800']
his_acc rrf_wo_na:  ['0.7728', '0.6864', '0.5475']
cur_acc_w_na:  ['0.6617', '0.4351', '0.2807']
his_acc_w_na:  ['0.6617', '0.5477', '0.4140']
cur_acc des_w_na:  ['0.6169', '0.4079', '0.3068']
his_acc des_w_na:  ['0.6169', '0.4996', '0.4158']
cur_acc rrf_w_na:  ['0.6380', '0.4123', '0.3314']
his_acc rrf_w_na:  ['0.6380', '0.5158', '0.4295']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 99.8638939CurrentTrain: epoch  0, batch     1 | loss: 94.4298093CurrentTrain: epoch  0, batch     2 | loss: 119.3349578CurrentTrain: epoch  0, batch     3 | loss: 93.5572950CurrentTrain: epoch  1, batch     0 | loss: 77.0911066CurrentTrain: epoch  1, batch     1 | loss: 75.4726023CurrentTrain: epoch  1, batch     2 | loss: 94.1212846CurrentTrain: epoch  1, batch     3 | loss: 91.0397025CurrentTrain: epoch  2, batch     0 | loss: 87.1310688CurrentTrain: epoch  2, batch     1 | loss: 71.4229600CurrentTrain: epoch  2, batch     2 | loss: 106.7027949CurrentTrain: epoch  2, batch     3 | loss: 71.1523802CurrentTrain: epoch  3, batch     0 | loss: 100.0154467CurrentTrain: epoch  3, batch     1 | loss: 84.0456521CurrentTrain: epoch  3, batch     2 | loss: 84.7094492CurrentTrain: epoch  3, batch     3 | loss: 81.2869143CurrentTrain: epoch  4, batch     0 | loss: 98.5467820CurrentTrain: epoch  4, batch     1 | loss: 100.5922696CurrentTrain: epoch  4, batch     2 | loss: 85.5481504CurrentTrain: epoch  4, batch     3 | loss: 53.7550296CurrentTrain: epoch  5, batch     0 | loss: 98.1863294CurrentTrain: epoch  5, batch     1 | loss: 78.9074735CurrentTrain: epoch  5, batch     2 | loss: 103.1074679CurrentTrain: epoch  5, batch     3 | loss: 64.5377283CurrentTrain: epoch  6, batch     0 | loss: 80.5592438CurrentTrain: epoch  6, batch     1 | loss: 78.1857169CurrentTrain: epoch  6, batch     2 | loss: 82.6922258CurrentTrain: epoch  6, batch     3 | loss: 77.9817520CurrentTrain: epoch  7, batch     0 | loss: 77.7651296CurrentTrain: epoch  7, batch     1 | loss: 96.1592371CurrentTrain: epoch  7, batch     2 | loss: 79.9525624CurrentTrain: epoch  7, batch     3 | loss: 67.0985780CurrentTrain: epoch  8, batch     0 | loss: 81.8900897CurrentTrain: epoch  8, batch     1 | loss: 76.8611603CurrentTrain: epoch  8, batch     2 | loss: 76.3236406CurrentTrain: epoch  8, batch     3 | loss: 54.5494230CurrentTrain: epoch  9, batch     0 | loss: 75.0168059CurrentTrain: epoch  9, batch     1 | loss: 65.8136703CurrentTrain: epoch  9, batch     2 | loss: 97.2860338CurrentTrain: epoch  9, batch     3 | loss: 78.5869827
MemoryTrain:  epoch  0, batch     0 | loss: 1.0378848MemoryTrain:  epoch  1, batch     0 | loss: 0.9118234MemoryTrain:  epoch  2, batch     0 | loss: 0.7317826MemoryTrain:  epoch  3, batch     0 | loss: 0.6248540MemoryTrain:  epoch  4, batch     0 | loss: 0.5353897MemoryTrain:  epoch  5, batch     0 | loss: 0.4083308MemoryTrain:  epoch  6, batch     0 | loss: 0.3831692MemoryTrain:  epoch  7, batch     0 | loss: 0.3381930MemoryTrain:  epoch  8, batch     0 | loss: 0.2894797MemoryTrain:  epoch  9, batch     0 | loss: 0.2580639

F1 score per class: {0: np.float64(0.8974358974358975), 4: np.float64(0.9424083769633508), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.2), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.4691358024691358), 23: np.float64(0.8275862068965517), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.6959847036328872
Weighted-average F1 score: 0.6010372029632197
F1 score per class: {0: np.float64(0.7865168539325843), 4: np.float64(0.9207920792079208), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.16), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.47619047619047616), 23: np.float64(0.7415730337078652), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.6059602649006622
Weighted-average F1 score: 0.5062599769206456
F1 score per class: {0: np.float64(0.875), 4: np.float64(0.9538461538461539), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.15384615384615385), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.4827586206896552), 23: np.float64(0.7586206896551724), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.6490299823633157
Weighted-average F1 score: 0.5442376489653645

F1 score per class: {0: np.float64(0.6140350877192983), 4: np.float64(0.9424083769633508), 5: np.float64(0.8401826484018264), 6: np.float64(0.27586206896551724), 7: np.float64(0.05172413793103448), 9: np.float64(0.78125), 10: np.float64(0.07079646017699115), 13: np.float64(0.031496062992125984), 16: np.float64(0.6557377049180327), 17: np.float64(0.0), 18: np.float64(0.18604651162790697), 19: np.float64(0.6527196652719666), 21: np.float64(0.30158730158730157), 23: np.float64(0.75), 24: np.float64(0.1), 26: np.float64(0.6589595375722543), 27: np.float64(0.35), 29: np.float64(0.8556701030927835), 31: np.float64(0.2222222222222222), 32: np.float64(0.8018867924528302), 40: np.float64(0.2066420664206642)}
Micro-average F1 score: 0.5344694035631293
Weighted-average F1 score: 0.5052973673122344
F1 score per class: {0: np.float64(0.5384615384615384), 4: np.float64(0.9073170731707317), 5: np.float64(0.5705705705705706), 6: np.float64(0.37777777777777777), 7: np.float64(0.048), 9: np.float64(0.6172839506172839), 10: np.float64(0.2857142857142857), 13: np.float64(0.028169014084507043), 16: np.float64(0.5054945054945055), 17: np.float64(0.0), 18: np.float64(0.35135135135135137), 19: np.float64(0.5424836601307189), 21: np.float64(0.3007518796992481), 23: np.float64(0.6470588235294118), 24: np.float64(0.08695652173913043), 26: np.float64(0.6914893617021277), 27: np.float64(0.2777777777777778), 29: np.float64(0.8472906403940886), 31: np.float64(0.07407407407407407), 32: np.float64(0.7798165137614679), 40: np.float64(0.17040358744394618)}
Micro-average F1 score: 0.49716383049716384
Weighted-average F1 score: 0.46473455229006316
F1 score per class: {0: np.float64(0.5833333333333334), 4: np.float64(0.9489795918367347), 5: np.float64(0.7159533073929961), 6: np.float64(0.37349397590361444), 7: np.float64(0.05172413793103448), 9: np.float64(0.7692307692307693), 10: np.float64(0.1793103448275862), 13: np.float64(0.025477707006369428), 16: np.float64(0.6285714285714286), 17: np.float64(0.0), 18: np.float64(0.34615384615384615), 19: np.float64(0.6014492753623188), 21: np.float64(0.302158273381295), 23: np.float64(0.673469387755102), 24: np.float64(0.09090909090909091), 26: np.float64(0.6914893617021277), 27: np.float64(0.2631578947368421), 29: np.float64(0.8514851485148515), 31: np.float64(0.1111111111111111), 32: np.float64(0.7798165137614679), 40: np.float64(0.15261044176706828)}
Micro-average F1 score: 0.5169582292038558
Weighted-average F1 score: 0.48026954818729195

F1 score per class: {0: np.float64(0.8235294117647058), 4: np.float64(0.8910891089108911), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.07547169811320754), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3619047619047619), 23: np.float64(0.7422680412371134), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5260115606936416
Weighted-average F1 score: 0.4193591034446161
F1 score per class: {0: np.float64(0.7291666666666666), 4: np.float64(0.8571428571428571), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.07017543859649122), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3508771929824561), 23: np.float64(0.6407766990291263), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4357142857142857
Weighted-average F1 score: 0.341874149337484
F1 score per class: {0: np.float64(0.8045977011494253), 4: np.float64(0.8942307692307693), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.05970149253731343), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.358974358974359), 23: np.float64(0.6534653465346535), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4773022049286641
Weighted-average F1 score: 0.3750766320442358

F1 score per class: {0: np.float64(0.445859872611465), 4: np.float64(0.8780487804878049), 5: np.float64(0.6456140350877193), 6: np.float64(0.20202020202020202), 7: np.float64(0.029556650246305417), 9: np.float64(0.7142857142857143), 10: np.float64(0.05714285714285714), 13: np.float64(0.015444015444015444), 16: np.float64(0.37037037037037035), 17: np.float64(0.0), 18: np.float64(0.1509433962264151), 19: np.float64(0.6070038910505836), 21: np.float64(0.20652173913043478), 23: np.float64(0.6153846153846154), 24: np.float64(0.08333333333333333), 26: np.float64(0.6), 27: np.float64(0.2), 29: np.float64(0.7155172413793104), 31: np.float64(0.15384615384615385), 32: np.float64(0.604982206405694), 40: np.float64(0.16231884057971013)}
Micro-average F1 score: 0.4048107949545321
Weighted-average F1 score: 0.3709807936788062
F1 score per class: {0: np.float64(0.3977272727272727), 4: np.float64(0.8266666666666667), 5: np.float64(0.3512014787430684), 6: np.float64(0.2490842490842491), 7: np.float64(0.027149321266968326), 9: np.float64(0.49504950495049505), 10: np.float64(0.18972332015810275), 13: np.float64(0.01486988847583643), 16: np.float64(0.2893081761006289), 17: np.float64(0.0), 18: np.float64(0.2), 19: np.float64(0.4598337950138504), 21: np.float64(0.19230769230769232), 23: np.float64(0.5238095238095238), 24: np.float64(0.07407407407407407), 26: np.float64(0.6190476190476191), 27: np.float64(0.18867924528301888), 29: np.float64(0.688), 31: np.float64(0.046511627906976744), 32: np.float64(0.6028368794326241), 40: np.float64(0.1292517006802721)}
Micro-average F1 score: 0.3528297418896519
Weighted-average F1 score: 0.32447016902402454
F1 score per class: {0: np.float64(0.4117647058823529), 4: np.float64(0.8732394366197183), 5: np.float64(0.456575682382134), 6: np.float64(0.2540983606557377), 7: np.float64(0.028985507246376812), 9: np.float64(0.684931506849315), 10: np.float64(0.13541666666666666), 13: np.float64(0.012861736334405145), 16: np.float64(0.3384615384615385), 17: np.float64(0.0), 18: np.float64(0.1956521739130435), 19: np.float64(0.5253164556962026), 21: np.float64(0.19444444444444445), 23: np.float64(0.5365853658536586), 24: np.float64(0.07692307692307693), 26: np.float64(0.6220095693779905), 27: np.float64(0.17857142857142858), 29: np.float64(0.6907630522088354), 31: np.float64(0.07407407407407407), 32: np.float64(0.6181818181818182), 40: np.float64(0.11550151975683891)}
Micro-average F1 score: 0.37309971656789487
Weighted-average F1 score: 0.3402973426437599
cur_acc_wo_na:  ['0.7850', '0.5475', '0.3211', '0.6960']
his_acc_wo_na:  ['0.7850', '0.6851', '0.5184', '0.5345']
cur_acc des_wo_na:  ['0.7554', '0.5843', '0.3578', '0.6060']
his_acc des_wo_na:  ['0.7554', '0.6745', '0.5385', '0.4972']
cur_acc rrf_wo_na:  ['0.7728', '0.5855', '0.3800', '0.6490']
his_acc rrf_wo_na:  ['0.7728', '0.6864', '0.5475', '0.5170']
cur_acc_w_na:  ['0.6617', '0.4351', '0.2807', '0.5260']
his_acc_w_na:  ['0.6617', '0.5477', '0.4140', '0.4048']
cur_acc des_w_na:  ['0.6169', '0.4079', '0.3068', '0.4357']
his_acc des_w_na:  ['0.6169', '0.4996', '0.4158', '0.3528']
cur_acc rrf_w_na:  ['0.6380', '0.4123', '0.3314', '0.4773']
his_acc rrf_w_na:  ['0.6380', '0.5158', '0.4295', '0.3731']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 97.1230851CurrentTrain: epoch  0, batch     1 | loss: 92.2196017CurrentTrain: epoch  0, batch     2 | loss: 96.1583601CurrentTrain: epoch  0, batch     3 | loss: 52.6419099CurrentTrain: epoch  1, batch     0 | loss: 75.5493899CurrentTrain: epoch  1, batch     1 | loss: 135.8699929CurrentTrain: epoch  1, batch     2 | loss: 72.5463396CurrentTrain: epoch  1, batch     3 | loss: 56.0027933CurrentTrain: epoch  2, batch     0 | loss: 128.3983803CurrentTrain: epoch  2, batch     1 | loss: 105.5106387CurrentTrain: epoch  2, batch     2 | loss: 70.0789945CurrentTrain: epoch  2, batch     3 | loss: 47.6559712CurrentTrain: epoch  3, batch     0 | loss: 79.9403252CurrentTrain: epoch  3, batch     1 | loss: 71.8655183CurrentTrain: epoch  3, batch     2 | loss: 82.0780249CurrentTrain: epoch  3, batch     3 | loss: 104.4384264CurrentTrain: epoch  4, batch     0 | loss: 79.4162906CurrentTrain: epoch  4, batch     1 | loss: 80.5287653CurrentTrain: epoch  4, batch     2 | loss: 77.4873874CurrentTrain: epoch  4, batch     3 | loss: 104.0501418CurrentTrain: epoch  5, batch     0 | loss: 82.1109620CurrentTrain: epoch  5, batch     1 | loss: 82.0563938CurrentTrain: epoch  5, batch     2 | loss: 78.0758963CurrentTrain: epoch  5, batch     3 | loss: 38.5491008CurrentTrain: epoch  6, batch     0 | loss: 80.2118111CurrentTrain: epoch  6, batch     1 | loss: 72.9539927CurrentTrain: epoch  6, batch     2 | loss: 82.0648760CurrentTrain: epoch  6, batch     3 | loss: 47.6405680CurrentTrain: epoch  7, batch     0 | loss: 95.8517376CurrentTrain: epoch  7, batch     1 | loss: 65.6881262CurrentTrain: epoch  7, batch     2 | loss: 62.5102179CurrentTrain: epoch  7, batch     3 | loss: 49.1023585CurrentTrain: epoch  8, batch     0 | loss: 118.8303607CurrentTrain: epoch  8, batch     1 | loss: 63.0470308CurrentTrain: epoch  8, batch     2 | loss: 94.4869920CurrentTrain: epoch  8, batch     3 | loss: 45.2572566CurrentTrain: epoch  9, batch     0 | loss: 95.7642934CurrentTrain: epoch  9, batch     1 | loss: 76.2494779CurrentTrain: epoch  9, batch     2 | loss: 62.2079602CurrentTrain: epoch  9, batch     3 | loss: 37.3724554
MemoryTrain:  epoch  0, batch     0 | loss: 0.8006718MemoryTrain:  epoch  1, batch     0 | loss: 0.6770859MemoryTrain:  epoch  2, batch     0 | loss: 0.5648879MemoryTrain:  epoch  3, batch     0 | loss: 0.4809404MemoryTrain:  epoch  4, batch     0 | loss: 0.4192909MemoryTrain:  epoch  5, batch     0 | loss: 0.3505080MemoryTrain:  epoch  6, batch     0 | loss: 0.2898302MemoryTrain:  epoch  7, batch     0 | loss: 0.2281195MemoryTrain:  epoch  8, batch     0 | loss: 0.2178291MemoryTrain:  epoch  9, batch     0 | loss: 0.2012418

F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.5161290322580645), 10: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 20: np.float64(0.8376068376068376), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8571428571428571), 32: np.float64(0.0), 33: np.float64(0.4), 36: np.float64(0.6470588235294118), 40: np.float64(0.0)}
Micro-average F1 score: 0.5611814345991561
Weighted-average F1 score: 0.4756015741467987
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.6624203821656051), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.7722772277227723), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7317073170731707), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.4), 36: np.float64(0.7401574803149606), 40: np.float64(0.0)}
Micro-average F1 score: 0.5346869712351946
Weighted-average F1 score: 0.42635596117327396
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.6533333333333333), 10: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.8113207547169812), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8108108108108109), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.34782608695652173), 36: np.float64(0.704), 40: np.float64(0.0)}
Micro-average F1 score: 0.5605786618444847
Weighted-average F1 score: 0.4583018226191176

F1 score per class: {0: np.float64(0.6538461538461539), 4: np.float64(0.9417989417989417), 5: np.float64(0.8266666666666667), 6: np.float64(0.3561643835616438), 7: np.float64(0.031746031746031744), 8: np.float64(0.38095238095238093), 9: np.float64(0.8620689655172413), 10: np.float64(0.037383177570093455), 13: np.float64(0.09090909090909091), 16: np.float64(0.6071428571428571), 17: np.float64(0.0), 18: np.float64(0.17777777777777778), 19: np.float64(0.6422764227642277), 20: np.float64(0.5568181818181818), 21: np.float64(0.27184466019417475), 23: np.float64(0.7216494845360825), 24: np.float64(0.09090909090909091), 26: np.float64(0.6483516483516484), 27: np.float64(0.3333333333333333), 29: np.float64(0.8472906403940886), 30: np.float64(0.8571428571428571), 31: np.float64(0.2), 32: np.float64(0.7685589519650655), 33: np.float64(0.18181818181818182), 36: np.float64(0.5409836065573771), 40: np.float64(0.2047244094488189)}
Micro-average F1 score: 0.541501976284585
Weighted-average F1 score: 0.5292712300217111
F1 score per class: {0: np.float64(0.5147058823529411), 4: np.float64(0.9253731343283582), 5: np.float64(0.5648414985590778), 6: np.float64(0.3717948717948718), 7: np.float64(0.031007751937984496), 8: np.float64(0.3180428134556575), 9: np.float64(0.6024096385542169), 10: np.float64(0.078125), 13: np.float64(0.12121212121212122), 16: np.float64(0.40384615384615385), 17: np.float64(0.0), 18: np.float64(0.25), 19: np.float64(0.5551839464882943), 20: np.float64(0.6341463414634146), 21: np.float64(0.2345679012345679), 23: np.float64(0.6326530612244898), 24: np.float64(0.13333333333333333), 26: np.float64(0.6568627450980392), 27: np.float64(0.2857142857142857), 29: np.float64(0.8275862068965517), 30: np.float64(0.4918032786885246), 31: np.float64(0.07142857142857142), 32: np.float64(0.7327586206896551), 33: np.float64(0.12345679012345678), 36: np.float64(0.5280898876404494), 40: np.float64(0.19138755980861244)}
Micro-average F1 score: 0.4743381955699622
Weighted-average F1 score: 0.45500416549053274
F1 score per class: {0: np.float64(0.5619834710743802), 4: np.float64(0.9583333333333334), 5: np.float64(0.7211895910780669), 6: np.float64(0.3717948717948718), 7: np.float64(0.03125), 8: np.float64(0.35766423357664234), 9: np.float64(0.7692307692307693), 10: np.float64(0.07874015748031496), 13: np.float64(0.09090909090909091), 16: np.float64(0.5405405405405406), 17: np.float64(0.0), 18: np.float64(0.24), 19: np.float64(0.5886524822695035), 20: np.float64(0.6277372262773723), 21: np.float64(0.23668639053254437), 23: np.float64(0.6595744680851063), 24: np.float64(0.07692307692307693), 26: np.float64(0.6666666666666666), 27: np.float64(0.25), 29: np.float64(0.8316831683168316), 30: np.float64(0.7142857142857143), 31: np.float64(0.13333333333333333), 32: np.float64(0.7327586206896551), 33: np.float64(0.10810810810810811), 36: np.float64(0.5269461077844312), 40: np.float64(0.17316017316017315)}
Micro-average F1 score: 0.5036347775516138
Weighted-average F1 score: 0.48225797345711674

F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.45390070921985815), 10: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.56), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8108108108108109), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.32), 36: np.float64(0.515625), 40: np.float64(0.0)}
Micro-average F1 score: 0.39820359281437123
Weighted-average F1 score: 0.33418166395374393
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.5), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5954198473282443), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.6976744186046512), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.2222222222222222), 36: np.float64(0.5802469135802469), 40: np.float64(0.0)}
Micro-average F1 score: 0.3619702176403207
Weighted-average F1 score: 0.29493889961066305
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.5051546391752577), 10: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.6142857142857143), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7692307692307693), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.19047619047619047), 36: np.float64(0.5605095541401274), 40: np.float64(0.0)}
Micro-average F1 score: 0.3865336658354115
Weighted-average F1 score: 0.3191012125595524

F1 score per class: {0: np.float64(0.4857142857142857), 4: np.float64(0.8855721393034826), 5: np.float64(0.6480836236933798), 6: np.float64(0.26666666666666666), 7: np.float64(0.017699115044247787), 8: np.float64(0.28444444444444444), 9: np.float64(0.7936507936507936), 10: np.float64(0.03669724770642202), 13: np.float64(0.0547945205479452), 16: np.float64(0.38636363636363635), 17: np.float64(0.0), 18: np.float64(0.14545454545454545), 19: np.float64(0.6007604562737643), 20: np.float64(0.2620320855614973), 21: np.float64(0.1958041958041958), 23: np.float64(0.5511811023622047), 24: np.float64(0.07692307692307693), 26: np.float64(0.5841584158415841), 27: np.float64(0.1935483870967742), 29: np.float64(0.6907630522088354), 30: np.float64(0.8108108108108109), 31: np.float64(0.125), 32: np.float64(0.56957928802589), 33: np.float64(0.1038961038961039), 36: np.float64(0.3626373626373626), 40: np.float64(0.1625)}
Micro-average F1 score: 0.4051256776737309
Weighted-average F1 score: 0.383468736187656
F1 score per class: {0: np.float64(0.3804347826086957), 4: np.float64(0.8611111111111112), 5: np.float64(0.36095764272559855), 6: np.float64(0.26244343891402716), 7: np.float64(0.016597510373443983), 8: np.float64(0.1863799283154122), 9: np.float64(0.49504950495049505), 10: np.float64(0.06944444444444445), 13: np.float64(0.07142857142857142), 16: np.float64(0.23595505617977527), 17: np.float64(0.0), 18: np.float64(0.16091954022988506), 19: np.float64(0.49700598802395207), 20: np.float64(0.4126984126984127), 21: np.float64(0.1589958158995816), 23: np.float64(0.4806201550387597), 24: np.float64(0.1), 26: np.float64(0.5583333333333333), 27: np.float64(0.19047619047619047), 29: np.float64(0.6461538461538462), 30: np.float64(0.39473684210526316), 31: np.float64(0.04081632653061224), 32: np.float64(0.5647840531561462), 33: np.float64(0.06802721088435375), 36: np.float64(0.3418181818181818), 40: np.float64(0.15267175572519084)}
Micro-average F1 score: 0.3368501822367159
Weighted-average F1 score: 0.31736069723620824
F1 score per class: {0: np.float64(0.40963855421686746), 4: np.float64(0.8975609756097561), 5: np.float64(0.4911392405063291), 6: np.float64(0.2648401826484018), 7: np.float64(0.016597510373443983), 8: np.float64(0.2149122807017544), 9: np.float64(0.704225352112676), 10: np.float64(0.07042253521126761), 13: np.float64(0.056338028169014086), 16: np.float64(0.291970802919708), 17: np.float64(0.0), 18: np.float64(0.14754098360655737), 19: np.float64(0.5372168284789643), 20: np.float64(0.3944954128440367), 21: np.float64(0.16), 23: np.float64(0.47692307692307695), 24: np.float64(0.058823529411764705), 26: np.float64(0.5877192982456141), 27: np.float64(0.16), 29: np.float64(0.6588235294117647), 30: np.float64(0.625), 31: np.float64(0.07407407407407407), 32: np.float64(0.5666666666666667), 33: np.float64(0.058394160583941604), 36: np.float64(0.350597609561753), 40: np.float64(0.1384083044982699)}
Micro-average F1 score: 0.36363636363636365
Weighted-average F1 score: 0.34138373221524015
cur_acc_wo_na:  ['0.7850', '0.5475', '0.3211', '0.6960', '0.5612']
his_acc_wo_na:  ['0.7850', '0.6851', '0.5184', '0.5345', '0.5415']
cur_acc des_wo_na:  ['0.7554', '0.5843', '0.3578', '0.6060', '0.5347']
his_acc des_wo_na:  ['0.7554', '0.6745', '0.5385', '0.4972', '0.4743']
cur_acc rrf_wo_na:  ['0.7728', '0.5855', '0.3800', '0.6490', '0.5606']
his_acc rrf_wo_na:  ['0.7728', '0.6864', '0.5475', '0.5170', '0.5036']
cur_acc_w_na:  ['0.6617', '0.4351', '0.2807', '0.5260', '0.3982']
his_acc_w_na:  ['0.6617', '0.5477', '0.4140', '0.4048', '0.4051']
cur_acc des_w_na:  ['0.6169', '0.4079', '0.3068', '0.4357', '0.3620']
his_acc des_w_na:  ['0.6169', '0.4996', '0.4158', '0.3528', '0.3369']
cur_acc rrf_w_na:  ['0.6380', '0.4123', '0.3314', '0.4773', '0.3865']
his_acc rrf_w_na:  ['0.6380', '0.5158', '0.4295', '0.3731', '0.3636']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 117.5947281CurrentTrain: epoch  0, batch     1 | loss: 102.2964162CurrentTrain: epoch  0, batch     2 | loss: 111.5470653CurrentTrain: epoch  0, batch     3 | loss: 89.7108949CurrentTrain: epoch  0, batch     4 | loss: 33.3891275CurrentTrain: epoch  1, batch     0 | loss: 94.8413772CurrentTrain: epoch  1, batch     1 | loss: 136.2159216CurrentTrain: epoch  1, batch     2 | loss: 86.6035753CurrentTrain: epoch  1, batch     3 | loss: 103.3949850CurrentTrain: epoch  1, batch     4 | loss: 19.5747610CurrentTrain: epoch  2, batch     0 | loss: 70.2487366CurrentTrain: epoch  2, batch     1 | loss: 87.5742381CurrentTrain: epoch  2, batch     2 | loss: 80.9302608CurrentTrain: epoch  2, batch     3 | loss: 173.8900226CurrentTrain: epoch  2, batch     4 | loss: 23.6927103CurrentTrain: epoch  3, batch     0 | loss: 98.1394270CurrentTrain: epoch  3, batch     1 | loss: 68.6772380CurrentTrain: epoch  3, batch     2 | loss: 82.9791167CurrentTrain: epoch  3, batch     3 | loss: 102.0754427CurrentTrain: epoch  3, batch     4 | loss: 23.2405968CurrentTrain: epoch  4, batch     0 | loss: 79.0286761CurrentTrain: epoch  4, batch     1 | loss: 97.9890928CurrentTrain: epoch  4, batch     2 | loss: 78.2579294CurrentTrain: epoch  4, batch     3 | loss: 81.0547293CurrentTrain: epoch  4, batch     4 | loss: 40.1861583CurrentTrain: epoch  5, batch     0 | loss: 98.4150247CurrentTrain: epoch  5, batch     1 | loss: 66.9283880CurrentTrain: epoch  5, batch     2 | loss: 95.7208544CurrentTrain: epoch  5, batch     3 | loss: 81.0872687CurrentTrain: epoch  5, batch     4 | loss: 25.5115974CurrentTrain: epoch  6, batch     0 | loss: 78.1956454CurrentTrain: epoch  6, batch     1 | loss: 64.8917109CurrentTrain: epoch  6, batch     2 | loss: 81.5242714CurrentTrain: epoch  6, batch     3 | loss: 69.5004415CurrentTrain: epoch  6, batch     4 | loss: 40.5736031CurrentTrain: epoch  7, batch     0 | loss: 90.7045246CurrentTrain: epoch  7, batch     1 | loss: 74.9138432CurrentTrain: epoch  7, batch     2 | loss: 124.7729415CurrentTrain: epoch  7, batch     3 | loss: 78.7954470CurrentTrain: epoch  7, batch     4 | loss: 15.7081265CurrentTrain: epoch  8, batch     0 | loss: 93.5456934CurrentTrain: epoch  8, batch     1 | loss: 76.4237118CurrentTrain: epoch  8, batch     2 | loss: 80.9438512CurrentTrain: epoch  8, batch     3 | loss: 94.2377102CurrentTrain: epoch  8, batch     4 | loss: 8.8827924CurrentTrain: epoch  9, batch     0 | loss: 94.3845141CurrentTrain: epoch  9, batch     1 | loss: 61.2216586CurrentTrain: epoch  9, batch     2 | loss: 120.1148873CurrentTrain: epoch  9, batch     3 | loss: 74.4055732CurrentTrain: epoch  9, batch     4 | loss: 23.4857035
MemoryTrain:  epoch  0, batch     0 | loss: 0.8424316MemoryTrain:  epoch  1, batch     0 | loss: 0.8569643MemoryTrain:  epoch  2, batch     0 | loss: 0.6580950MemoryTrain:  epoch  3, batch     0 | loss: 0.5450270MemoryTrain:  epoch  4, batch     0 | loss: 0.5229210MemoryTrain:  epoch  5, batch     0 | loss: 0.4037730MemoryTrain:  epoch  6, batch     0 | loss: 0.3759702MemoryTrain:  epoch  7, batch     0 | loss: 0.3418910MemoryTrain:  epoch  8, batch     0 | loss: 0.2931590MemoryTrain:  epoch  9, batch     0 | loss: 0.2597472

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.6666666666666666), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.4794520547945205), 12: np.float64(0.6198830409356725), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 28: np.float64(0.2857142857142857), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 39: np.float64(0.2), 40: np.float64(0.0)}
Micro-average F1 score: 0.4636363636363636
Weighted-average F1 score: 0.40151222080905274
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.4666666666666667), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.45112781954887216), 12: np.float64(0.5841584158415841), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 28: np.float64(0.3888888888888889), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 39: np.float64(0.37037037037037035), 40: np.float64(0.0)}
Micro-average F1 score: 0.38434163701067614
Weighted-average F1 score: 0.3072554344001298
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.56), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.5277777777777778), 12: np.float64(0.6096256684491979), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 28: np.float64(0.3684210526315789), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 39: np.float64(0.32), 40: np.float64(0.0)}
Micro-average F1 score: 0.44313725490196076
Weighted-average F1 score: 0.364692853228808

F1 score per class: {0: np.float64(0.6126126126126126), 2: np.float64(0.4), 4: np.float64(0.8255813953488372), 5: np.float64(0.8682926829268293), 6: np.float64(0.2835820895522388), 7: np.float64(0.018691588785046728), 8: np.float64(0.3157894736842105), 9: np.float64(0.8333333333333334), 10: np.float64(0.06896551724137931), 11: np.float64(0.22012578616352202), 12: np.float64(0.3581081081081081), 13: np.float64(0.14285714285714285), 16: np.float64(0.48), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.6374501992031872), 20: np.float64(0.6511627906976745), 21: np.float64(0.2972972972972973), 23: np.float64(0.7111111111111111), 24: np.float64(0.09523809523809523), 26: np.float64(0.5903614457831325), 27: np.float64(0.35294117647058826), 28: np.float64(0.10101010101010101), 29: np.float64(0.7916666666666666), 30: np.float64(0.8571428571428571), 31: np.float64(0.18181818181818182), 32: np.float64(0.7818181818181819), 33: np.float64(0.12121212121212122), 36: np.float64(0.029850746268656716), 39: np.float64(0.1111111111111111), 40: np.float64(0.2436548223350254)}
Micro-average F1 score: 0.4662612221256878
Weighted-average F1 score: 0.4577800160690341
F1 score per class: {0: np.float64(0.4342105263157895), 2: np.float64(0.2222222222222222), 4: np.float64(0.8542713567839196), 5: np.float64(0.6), 6: np.float64(0.34782608695652173), 7: np.float64(0.03225806451612903), 8: np.float64(0.32), 9: np.float64(0.5952380952380952), 10: np.float64(0.19718309859154928), 11: np.float64(0.2803738317757009), 12: np.float64(0.2443064182194617), 13: np.float64(0.0), 16: np.float64(0.4266666666666667), 17: np.float64(0.0), 18: np.float64(0.1794871794871795), 19: np.float64(0.546031746031746), 20: np.float64(0.6507936507936508), 21: np.float64(0.19138755980861244), 23: np.float64(0.6796116504854369), 24: np.float64(0.07407407407407407), 26: np.float64(0.6595744680851063), 27: np.float64(0.2777777777777778), 28: np.float64(0.16470588235294117), 29: np.float64(0.8020304568527918), 30: np.float64(0.4), 31: np.float64(0.07407407407407407), 32: np.float64(0.7172995780590717), 33: np.float64(0.13953488372093023), 36: np.float64(0.44), 39: np.float64(0.16393442622950818), 40: np.float64(0.13541666666666666)}
Micro-average F1 score: 0.41853178155774395
Weighted-average F1 score: 0.39456897169190586
F1 score per class: {0: np.float64(0.5147058823529411), 2: np.float64(0.2978723404255319), 4: np.float64(0.8924731182795699), 5: np.float64(0.7815126050420168), 6: np.float64(0.3312883435582822), 7: np.float64(0.032520325203252036), 8: np.float64(0.32098765432098764), 9: np.float64(0.6944444444444444), 10: np.float64(0.15037593984962405), 11: np.float64(0.28679245283018867), 12: np.float64(0.2857142857142857), 13: np.float64(0.0), 16: np.float64(0.4666666666666667), 17: np.float64(0.0), 18: np.float64(0.09523809523809523), 19: np.float64(0.5773195876288659), 20: np.float64(0.6259541984732825), 21: np.float64(0.23776223776223776), 23: np.float64(0.6938775510204082), 24: np.float64(0.08), 26: np.float64(0.6703296703296703), 27: np.float64(0.37209302325581395), 28: np.float64(0.14583333333333334), 29: np.float64(0.8102564102564103), 30: np.float64(0.6), 31: np.float64(0.1111111111111111), 32: np.float64(0.7053941908713693), 33: np.float64(0.15384615384615385), 36: np.float64(0.16), 39: np.float64(0.16326530612244897), 40: np.float64(0.14218009478672985)}
Micro-average F1 score: 0.44405768274490304
Weighted-average F1 score: 0.4254386849348543

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.42424242424242425), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.37433155080213903), 12: np.float64(0.5), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.16129032258064516), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 39: np.float64(0.16666666666666666), 40: np.float64(0.0)}
Micro-average F1 score: 0.3264
Weighted-average F1 score: 0.27984479260406764
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.3181818181818182), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.375), 12: np.float64(0.4609375), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.208955223880597), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.2631578947368421), 40: np.float64(0.0)}
Micro-average F1 score: 0.25263157894736843
Weighted-average F1 score: 0.20233767502987904
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.358974358974359), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.4222222222222222), 12: np.float64(0.4830508474576271), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.2), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.22857142857142856), 40: np.float64(0.0)}
Micro-average F1 score: 0.2942708333333333
Weighted-average F1 score: 0.24136355276486796

F1 score per class: {0: np.float64(0.4857142857142857), 2: np.float64(0.2222222222222222), 4: np.float64(0.7675675675675676), 5: np.float64(0.7355371900826446), 6: np.float64(0.2222222222222222), 7: np.float64(0.009615384615384616), 8: np.float64(0.2641509433962264), 9: np.float64(0.7692307692307693), 10: np.float64(0.064), 11: np.float64(0.14675052410901468), 12: np.float64(0.1737704918032787), 13: np.float64(0.0625), 16: np.float64(0.3157894736842105), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.6015037593984962), 20: np.float64(0.34285714285714286), 21: np.float64(0.19642857142857142), 23: np.float64(0.6037735849056604), 24: np.float64(0.08333333333333333), 26: np.float64(0.532608695652174), 27: np.float64(0.19672131147540983), 28: np.float64(0.056818181818181816), 29: np.float64(0.6816143497757847), 30: np.float64(0.7894736842105263), 31: np.float64(0.11764705882352941), 32: np.float64(0.5620915032679739), 33: np.float64(0.07692307692307693), 36: np.float64(0.028169014084507043), 39: np.float64(0.07547169811320754), 40: np.float64(0.19834710743801653)}
Micro-average F1 score: 0.33696107157806615
Weighted-average F1 score: 0.3130671241830171
F1 score per class: {0: np.float64(0.32038834951456313), 2: np.float64(0.14583333333333334), 4: np.float64(0.776255707762557), 5: np.float64(0.4050632911392405), 6: np.float64(0.2206896551724138), 7: np.float64(0.017316017316017316), 8: np.float64(0.18972332015810275), 9: np.float64(0.4807692307692308), 10: np.float64(0.14736842105263157), 11: np.float64(0.19672131147540983), 12: np.float64(0.1324354657687991), 13: np.float64(0.0), 16: np.float64(0.2807017543859649), 17: np.float64(0.0), 18: np.float64(0.10687022900763359), 19: np.float64(0.47645429362880887), 20: np.float64(0.38497652582159625), 21: np.float64(0.13559322033898305), 23: np.float64(0.5223880597014925), 24: np.float64(0.058823529411764705), 26: np.float64(0.5849056603773585), 27: np.float64(0.1724137931034483), 28: np.float64(0.0915032679738562), 29: np.float64(0.6556016597510373), 30: np.float64(0.29906542056074764), 31: np.float64(0.044444444444444446), 32: np.float64(0.5246913580246914), 33: np.float64(0.08333333333333333), 36: np.float64(0.35772357723577236), 39: np.float64(0.0847457627118644), 40: np.float64(0.11255411255411256)}
Micro-average F1 score: 0.2868978214176128
Weighted-average F1 score: 0.2660185059263795
F1 score per class: {0: np.float64(0.37037037037037035), 2: np.float64(0.18421052631578946), 4: np.float64(0.8341708542713567), 5: np.float64(0.5636363636363636), 6: np.float64(0.21862348178137653), 7: np.float64(0.017241379310344827), 8: np.float64(0.20207253886010362), 9: np.float64(0.625), 10: np.float64(0.11627906976744186), 11: np.float64(0.19387755102040816), 12: np.float64(0.14393939393939395), 13: np.float64(0.0), 16: np.float64(0.29473684210526313), 17: np.float64(0.0), 18: np.float64(0.07272727272727272), 19: np.float64(0.5201238390092879), 20: np.float64(0.36444444444444446), 21: np.float64(0.15454545454545454), 23: np.float64(0.5528455284552846), 24: np.float64(0.0625), 26: np.float64(0.5951219512195122), 27: np.float64(0.24242424242424243), 28: np.float64(0.07954545454545454), 29: np.float64(0.6666666666666666), 30: np.float64(0.5084745762711864), 31: np.float64(0.07142857142857142), 32: np.float64(0.5198776758409785), 33: np.float64(0.08695652173913043), 36: np.float64(0.13953488372093023), 39: np.float64(0.08421052631578947), 40: np.float64(0.11538461538461539)}
Micro-average F1 score: 0.30660944206008584
Weighted-average F1 score: 0.2842321223147283
cur_acc_wo_na:  ['0.7850', '0.5475', '0.3211', '0.6960', '0.5612', '0.4636']
his_acc_wo_na:  ['0.7850', '0.6851', '0.5184', '0.5345', '0.5415', '0.4663']
cur_acc des_wo_na:  ['0.7554', '0.5843', '0.3578', '0.6060', '0.5347', '0.3843']
his_acc des_wo_na:  ['0.7554', '0.6745', '0.5385', '0.4972', '0.4743', '0.4185']
cur_acc rrf_wo_na:  ['0.7728', '0.5855', '0.3800', '0.6490', '0.5606', '0.4431']
his_acc rrf_wo_na:  ['0.7728', '0.6864', '0.5475', '0.5170', '0.5036', '0.4441']
cur_acc_w_na:  ['0.6617', '0.4351', '0.2807', '0.5260', '0.3982', '0.3264']
his_acc_w_na:  ['0.6617', '0.5477', '0.4140', '0.4048', '0.4051', '0.3370']
cur_acc des_w_na:  ['0.6169', '0.4079', '0.3068', '0.4357', '0.3620', '0.2526']
his_acc des_w_na:  ['0.6169', '0.4996', '0.4158', '0.3528', '0.3369', '0.2869']
cur_acc rrf_w_na:  ['0.6380', '0.4123', '0.3314', '0.4773', '0.3865', '0.2943']
his_acc rrf_w_na:  ['0.6380', '0.5158', '0.4295', '0.3731', '0.3636', '0.3066']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 121.7077740CurrentTrain: epoch  0, batch     1 | loss: 101.5523633CurrentTrain: epoch  0, batch     2 | loss: 101.0333131CurrentTrain: epoch  0, batch     3 | loss: 93.8512721CurrentTrain: epoch  0, batch     4 | loss: 80.3255092CurrentTrain: epoch  1, batch     0 | loss: 75.4761155CurrentTrain: epoch  1, batch     1 | loss: 93.3467133CurrentTrain: epoch  1, batch     2 | loss: 90.1086984CurrentTrain: epoch  1, batch     3 | loss: 139.3090482CurrentTrain: epoch  1, batch     4 | loss: 49.1508205CurrentTrain: epoch  2, batch     0 | loss: 107.1510280CurrentTrain: epoch  2, batch     1 | loss: 104.7556558CurrentTrain: epoch  2, batch     2 | loss: 87.1200436CurrentTrain: epoch  2, batch     3 | loss: 71.8384449CurrentTrain: epoch  2, batch     4 | loss: 101.6010859CurrentTrain: epoch  3, batch     0 | loss: 100.9418269CurrentTrain: epoch  3, batch     1 | loss: 103.1823371CurrentTrain: epoch  3, batch     2 | loss: 83.9078748CurrentTrain: epoch  3, batch     3 | loss: 71.2256281CurrentTrain: epoch  3, batch     4 | loss: 56.0641253CurrentTrain: epoch  4, batch     0 | loss: 82.1855440CurrentTrain: epoch  4, batch     1 | loss: 79.2210917CurrentTrain: epoch  4, batch     2 | loss: 127.1364015CurrentTrain: epoch  4, batch     3 | loss: 83.1844970CurrentTrain: epoch  4, batch     4 | loss: 69.2593379CurrentTrain: epoch  5, batch     0 | loss: 100.7785609CurrentTrain: epoch  5, batch     1 | loss: 79.1470731CurrentTrain: epoch  5, batch     2 | loss: 99.7920533CurrentTrain: epoch  5, batch     3 | loss: 68.7062550CurrentTrain: epoch  5, batch     4 | loss: 55.5008391CurrentTrain: epoch  6, batch     0 | loss: 166.3920844CurrentTrain: epoch  6, batch     1 | loss: 68.1299311CurrentTrain: epoch  6, batch     2 | loss: 122.0319325CurrentTrain: epoch  6, batch     3 | loss: 66.3315052CurrentTrain: epoch  6, batch     4 | loss: 70.8501374CurrentTrain: epoch  7, batch     0 | loss: 97.5650558CurrentTrain: epoch  7, batch     1 | loss: 63.3263897CurrentTrain: epoch  7, batch     2 | loss: 95.9703412CurrentTrain: epoch  7, batch     3 | loss: 80.9403379CurrentTrain: epoch  7, batch     4 | loss: 71.4196118CurrentTrain: epoch  8, batch     0 | loss: 66.5865659CurrentTrain: epoch  8, batch     1 | loss: 76.8930944CurrentTrain: epoch  8, batch     2 | loss: 65.6767077CurrentTrain: epoch  8, batch     3 | loss: 163.2759312CurrentTrain: epoch  8, batch     4 | loss: 69.4389087CurrentTrain: epoch  9, batch     0 | loss: 76.4391784CurrentTrain: epoch  9, batch     1 | loss: 76.9182547CurrentTrain: epoch  9, batch     2 | loss: 121.8730266CurrentTrain: epoch  9, batch     3 | loss: 77.9637192CurrentTrain: epoch  9, batch     4 | loss: 66.6419120
MemoryTrain:  epoch  0, batch     0 | loss: 1.0728887MemoryTrain:  epoch  1, batch     0 | loss: 0.9726236MemoryTrain:  epoch  2, batch     0 | loss: 0.8351761MemoryTrain:  epoch  3, batch     0 | loss: 0.6922498MemoryTrain:  epoch  4, batch     0 | loss: 0.5152967MemoryTrain:  epoch  5, batch     0 | loss: 0.4602123MemoryTrain:  epoch  6, batch     0 | loss: 0.4126343MemoryTrain:  epoch  7, batch     0 | loss: 0.3572676MemoryTrain:  epoch  8, batch     0 | loss: 0.3404481MemoryTrain:  epoch  9, batch     0 | loss: 0.2844489

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.24539877300613497), 3: np.float64(0.7251461988304093), 7: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.10126582278481013), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.5560165975103735), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.75), 40: np.float64(0.0)}
Micro-average F1 score: 0.4222689075630252
Weighted-average F1 score: 0.37538641201960743
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.25287356321839083), 3: np.float64(0.6728971962616822), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0759493670886076), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5083612040133779), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.7540983606557377), 36: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3659147869674185
Weighted-average F1 score: 0.3216341945293159
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.25), 3: np.float64(0.6635071090047393), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.1348314606741573), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5494505494505495), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.7540983606557377), 40: np.float64(0.0)}
Micro-average F1 score: 0.3855633802816901
Weighted-average F1 score: 0.3377205570223116

F1 score per class: {0: np.float64(0.7532467532467533), 1: np.float64(0.19138755980861244), 2: np.float64(0.4827586206896552), 3: np.float64(0.512396694214876), 4: np.float64(0.7831325301204819), 5: np.float64(0.9045226130653267), 6: np.float64(0.26356589147286824), 7: np.float64(0.01680672268907563), 8: np.float64(0.25225225225225223), 9: np.float64(0.78125), 10: np.float64(0.06837606837606838), 11: np.float64(0.06936416184971098), 12: np.float64(0.3728813559322034), 13: np.float64(0.15384615384615385), 14: np.float64(0.08247422680412371), 16: np.float64(0.5), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5337837837837838), 20: np.float64(0.5673758865248227), 21: np.float64(0.0), 22: np.float64(0.47686832740213525), 23: np.float64(0.6666666666666666), 24: np.float64(0.0), 26: np.float64(0.6666666666666666), 27: np.float64(0.125), 28: np.float64(0.08130081300813008), 29: np.float64(0.78), 30: np.float64(0.8571428571428571), 31: np.float64(0.6666666666666666), 32: np.float64(0.640625), 33: np.float64(0.08), 34: np.float64(0.22429906542056074), 36: np.float64(0.24), 39: np.float64(0.10810810810810811), 40: np.float64(0.21296296296296297)}
Micro-average F1 score: 0.41563604240282687
Weighted-average F1 score: 0.40489914202641347
F1 score per class: {0: np.float64(0.4748201438848921), 1: np.float64(0.19047619047619047), 2: np.float64(0.2857142857142857), 3: np.float64(0.42729970326409494), 4: np.float64(0.8324324324324325), 5: np.float64(0.5740181268882175), 6: np.float64(0.42718446601941745), 7: np.float64(0.06382978723404255), 8: np.float64(0.33707865168539325), 9: np.float64(0.5376344086021505), 10: np.float64(0.20134228187919462), 11: np.float64(0.08121827411167512), 12: np.float64(0.2749326145552561), 13: np.float64(0.2), 14: np.float64(0.05454545454545454), 16: np.float64(0.5454545454545454), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.4632768361581921), 20: np.float64(0.6019417475728155), 21: np.float64(0.05660377358490566), 22: np.float64(0.40425531914893614), 23: np.float64(0.7222222222222222), 24: np.float64(0.06060606060606061), 26: np.float64(0.6666666666666666), 27: np.float64(0.0), 28: np.float64(0.11363636363636363), 29: np.float64(0.7817258883248731), 30: np.float64(0.4), 31: np.float64(0.07142857142857142), 32: np.float64(0.592057761732852), 33: np.float64(0.12), 34: np.float64(0.21800947867298578), 36: np.float64(0.5588235294117647), 39: np.float64(0.18867924528301888), 40: np.float64(0.20444444444444446)}
Micro-average F1 score: 0.3869845136593005
Weighted-average F1 score: 0.3723142453738245
F1 score per class: {0: np.float64(0.5945945945945946), 1: np.float64(0.1864406779661017), 2: np.float64(0.34146341463414637), 3: np.float64(0.41543026706231456), 4: np.float64(0.8505747126436781), 5: np.float64(0.7294117647058823), 6: np.float64(0.38823529411764707), 7: np.float64(0.056074766355140186), 8: np.float64(0.367816091954023), 9: np.float64(0.6944444444444444), 10: np.float64(0.16901408450704225), 11: np.float64(0.07582938388625593), 12: np.float64(0.3105590062111801), 13: np.float64(0.1111111111111111), 14: np.float64(0.0975609756097561), 16: np.float64(0.5423728813559322), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.4823529411764706), 20: np.float64(0.5486725663716814), 21: np.float64(0.02247191011235955), 22: np.float64(0.4437869822485207), 23: np.float64(0.72), 24: np.float64(0.07142857142857142), 26: np.float64(0.6772486772486772), 27: np.float64(0.0), 28: np.float64(0.09836065573770492), 29: np.float64(0.7777777777777778), 30: np.float64(0.6818181818181818), 31: np.float64(0.13333333333333333), 32: np.float64(0.5971223021582733), 33: np.float64(0.1111111111111111), 34: np.float64(0.2), 36: np.float64(0.37362637362637363), 39: np.float64(0.18604651162790697), 40: np.float64(0.18930041152263374)}
Micro-average F1 score: 0.39157188140965876
Weighted-average F1 score: 0.37203801879118203

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.13377926421404682), 2: np.float64(0.0), 3: np.float64(0.5714285714285714), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.09523809523809523), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.44224422442244227), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6114649681528662), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2838983050847458
Weighted-average F1 score: 0.24743412108296864
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.14193548387096774), 2: np.float64(0.0), 3: np.float64(0.45714285714285713), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.06741573033707865), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.390745501285347), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.5974025974025974), 36: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.23523093447905477
Weighted-average F1 score: 0.20945204486990565
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.13924050632911392), 2: np.float64(0.0), 3: np.float64(0.4560260586319218), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.12), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.42016806722689076), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.5974025974025974), 36: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2512908777969019
Weighted-average F1 score: 0.22297523666704966

F1 score per class: {0: np.float64(0.5631067961165048), 1: np.float64(0.10025062656641603), 2: np.float64(0.25925925925925924), 3: np.float64(0.32545931758530183), 4: np.float64(0.7386363636363636), 5: np.float64(0.7531380753138075), 6: np.float64(0.2111801242236025), 7: np.float64(0.008), 8: np.float64(0.21052631578947367), 9: np.float64(0.7246376811594203), 10: np.float64(0.05925925925925926), 11: np.float64(0.056074766355140186), 12: np.float64(0.1749502982107356), 13: np.float64(0.07692307692307693), 14: np.float64(0.07407407407407407), 16: np.float64(0.35294117647058826), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.48466257668711654), 20: np.float64(0.30303030303030304), 21: np.float64(0.0), 22: np.float64(0.3383838383838384), 23: np.float64(0.5742574257425742), 24: np.float64(0.0), 26: np.float64(0.5970149253731343), 27: np.float64(0.125), 28: np.float64(0.0423728813559322), 29: np.float64(0.6290322580645161), 30: np.float64(0.8108108108108109), 31: np.float64(0.2857142857142857), 32: np.float64(0.47126436781609193), 33: np.float64(0.05405405405405406), 34: np.float64(0.1285140562248996), 36: np.float64(0.20224719101123595), 39: np.float64(0.06349206349206349), 40: np.float64(0.17358490566037735)}
Micro-average F1 score: 0.28936039360393606
Weighted-average F1 score: 0.26850298575915404
F1 score per class: {0: np.float64(0.3548387096774194), 1: np.float64(0.10501193317422435), 2: np.float64(0.16470588235294117), 3: np.float64(0.24870466321243523), 4: np.float64(0.7738693467336684), 5: np.float64(0.37328094302554027), 6: np.float64(0.2619047619047619), 7: np.float64(0.03314917127071823), 8: np.float64(0.21226415094339623), 9: np.float64(0.4032258064516129), 10: np.float64(0.14285714285714285), 11: np.float64(0.06837606837606838), 12: np.float64(0.13076923076923078), 13: np.float64(0.08333333333333333), 14: np.float64(0.047244094488188976), 16: np.float64(0.36363636363636365), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.40294840294840295), 20: np.float64(0.34444444444444444), 21: np.float64(0.048), 22: np.float64(0.2820037105751391), 23: np.float64(0.5306122448979592), 24: np.float64(0.05), 26: np.float64(0.5871559633027523), 27: np.float64(0.0), 28: np.float64(0.062111801242236024), 29: np.float64(0.6234817813765182), 30: np.float64(0.2982456140350877), 31: np.float64(0.0392156862745098), 32: np.float64(0.41309823677581864), 33: np.float64(0.06382978723404255), 34: np.float64(0.12939521800281295), 36: np.float64(0.36538461538461536), 39: np.float64(0.09523809523809523), 40: np.float64(0.16370106761565836)}
Micro-average F1 score: 0.25722877631274577
Weighted-average F1 score: 0.24394859980274744
F1 score per class: {0: np.float64(0.4230769230769231), 1: np.float64(0.10138248847926268), 2: np.float64(0.1917808219178082), 3: np.float64(0.2422145328719723), 4: np.float64(0.7956989247311828), 5: np.float64(0.510989010989011), 6: np.float64(0.25680933852140075), 7: np.float64(0.027777777777777776), 8: np.float64(0.270042194092827), 9: np.float64(0.6329113924050633), 10: np.float64(0.11940298507462686), 11: np.float64(0.060836501901140684), 12: np.float64(0.13986013986013987), 13: np.float64(0.058823529411764705), 14: np.float64(0.0851063829787234), 16: np.float64(0.36363636363636365), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.4270833333333333), 20: np.float64(0.3054187192118227), 21: np.float64(0.020202020202020204), 22: np.float64(0.30425963488843816), 23: np.float64(0.5581395348837209), 24: np.float64(0.06060606060606061), 26: np.float64(0.5953488372093023), 27: np.float64(0.0), 28: np.float64(0.053811659192825115), 29: np.float64(0.6209677419354839), 30: np.float64(0.6122448979591837), 31: np.float64(0.07407407407407407), 32: np.float64(0.41919191919191917), 33: np.float64(0.07407407407407407), 34: np.float64(0.11932555123216602), 36: np.float64(0.2698412698412698), 39: np.float64(0.08888888888888889), 40: np.float64(0.15081967213114755)}
Micro-average F1 score: 0.26342197691921726
Weighted-average F1 score: 0.2455286792492513
cur_acc_wo_na:  ['0.7850', '0.5475', '0.3211', '0.6960', '0.5612', '0.4636', '0.4223']
his_acc_wo_na:  ['0.7850', '0.6851', '0.5184', '0.5345', '0.5415', '0.4663', '0.4156']
cur_acc des_wo_na:  ['0.7554', '0.5843', '0.3578', '0.6060', '0.5347', '0.3843', '0.3659']
his_acc des_wo_na:  ['0.7554', '0.6745', '0.5385', '0.4972', '0.4743', '0.4185', '0.3870']
cur_acc rrf_wo_na:  ['0.7728', '0.5855', '0.3800', '0.6490', '0.5606', '0.4431', '0.3856']
his_acc rrf_wo_na:  ['0.7728', '0.6864', '0.5475', '0.5170', '0.5036', '0.4441', '0.3916']
cur_acc_w_na:  ['0.6617', '0.4351', '0.2807', '0.5260', '0.3982', '0.3264', '0.2839']
his_acc_w_na:  ['0.6617', '0.5477', '0.4140', '0.4048', '0.4051', '0.3370', '0.2894']
cur_acc des_w_na:  ['0.6169', '0.4079', '0.3068', '0.4357', '0.3620', '0.2526', '0.2352']
his_acc des_w_na:  ['0.6169', '0.4996', '0.4158', '0.3528', '0.3369', '0.2869', '0.2572']
cur_acc rrf_w_na:  ['0.6380', '0.4123', '0.3314', '0.4773', '0.3865', '0.2943', '0.2513']
his_acc rrf_w_na:  ['0.6380', '0.5158', '0.4295', '0.3731', '0.3636', '0.3066', '0.2634']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 107.2098381CurrentTrain: epoch  0, batch     1 | loss: 118.7288536CurrentTrain: epoch  0, batch     2 | loss: 114.8236803CurrentTrain: epoch  0, batch     3 | loss: 55.6160675CurrentTrain: epoch  1, batch     0 | loss: 82.7929169CurrentTrain: epoch  1, batch     1 | loss: 110.8153022CurrentTrain: epoch  1, batch     2 | loss: 84.1912987CurrentTrain: epoch  1, batch     3 | loss: 75.8453612CurrentTrain: epoch  2, batch     0 | loss: 75.3247909CurrentTrain: epoch  2, batch     1 | loss: 88.1204137CurrentTrain: epoch  2, batch     2 | loss: 104.1686424CurrentTrain: epoch  2, batch     3 | loss: 55.9355575CurrentTrain: epoch  3, batch     0 | loss: 132.8476357CurrentTrain: epoch  3, batch     1 | loss: 67.4696342CurrentTrain: epoch  3, batch     2 | loss: 82.7019046CurrentTrain: epoch  3, batch     3 | loss: 66.3897978CurrentTrain: epoch  4, batch     0 | loss: 103.8297825CurrentTrain: epoch  4, batch     1 | loss: 126.5314265CurrentTrain: epoch  4, batch     2 | loss: 64.7431404CurrentTrain: epoch  4, batch     3 | loss: 46.7849373CurrentTrain: epoch  5, batch     0 | loss: 82.2403035CurrentTrain: epoch  5, batch     1 | loss: 74.3090778CurrentTrain: epoch  5, batch     2 | loss: 98.5017202CurrentTrain: epoch  5, batch     3 | loss: 65.8423305CurrentTrain: epoch  6, batch     0 | loss: 64.9879276CurrentTrain: epoch  6, batch     1 | loss: 68.9598431CurrentTrain: epoch  6, batch     2 | loss: 76.4234922CurrentTrain: epoch  6, batch     3 | loss: 68.4376309CurrentTrain: epoch  7, batch     0 | loss: 78.4527293CurrentTrain: epoch  7, batch     1 | loss: 97.3213288CurrentTrain: epoch  7, batch     2 | loss: 75.6972236CurrentTrain: epoch  7, batch     3 | loss: 44.5483339CurrentTrain: epoch  8, batch     0 | loss: 74.1549409CurrentTrain: epoch  8, batch     1 | loss: 77.3122790CurrentTrain: epoch  8, batch     2 | loss: 92.1479619CurrentTrain: epoch  8, batch     3 | loss: 81.6180112CurrentTrain: epoch  9, batch     0 | loss: 77.1565061CurrentTrain: epoch  9, batch     1 | loss: 76.0969874CurrentTrain: epoch  9, batch     2 | loss: 95.2006396CurrentTrain: epoch  9, batch     3 | loss: 49.2602589
MemoryTrain:  epoch  0, batch     0 | loss: 0.8851626MemoryTrain:  epoch  1, batch     0 | loss: 0.8287241MemoryTrain:  epoch  2, batch     0 | loss: 0.6934729MemoryTrain:  epoch  3, batch     0 | loss: 0.5412570MemoryTrain:  epoch  4, batch     0 | loss: 0.5217998MemoryTrain:  epoch  5, batch     0 | loss: 0.3861080MemoryTrain:  epoch  6, batch     0 | loss: 0.3289228MemoryTrain:  epoch  7, batch     0 | loss: 0.2875272MemoryTrain:  epoch  8, batch     0 | loss: 0.2723866MemoryTrain:  epoch  9, batch     0 | loss: 0.2541788

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.7058823529411765), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.3225806451612903), 28: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.6265060240963856), 37: np.float64(0.6530612244897959), 38: np.float64(0.7307692307692307), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3590733590733591
Weighted-average F1 score: 0.22261818221564433
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.631578947368421), 16: np.float64(0.0), 17: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.5405405405405406), 26: np.float64(0.0), 28: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.7835051546391752), 36: np.float64(0.0), 37: np.float64(0.5470085470085471), 38: np.float64(0.6545454545454545), 39: np.float64(0.0)}
Micro-average F1 score: 0.3890784982935154
Weighted-average F1 score: 0.26615468567227063
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.631578947368421), 17: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.4857142857142857), 28: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.7311827956989247), 36: np.float64(0.0), 37: np.float64(0.584070796460177), 38: np.float64(0.6545454545454545), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.39344262295081966
Weighted-average F1 score: 0.26944030049897827

F1 score per class: {0: np.float64(0.6666666666666666), 1: np.float64(0.175), 2: np.float64(0.56), 3: np.float64(0.27956989247311825), 4: np.float64(0.8047337278106509), 5: np.float64(0.774468085106383), 6: np.float64(0.25), 7: np.float64(0.045454545454545456), 8: np.float64(0.3008849557522124), 9: np.float64(0.7692307692307693), 10: np.float64(0.035398230088495575), 11: np.float64(0.13664596273291926), 12: np.float64(0.3111111111111111), 13: np.float64(0.09090909090909091), 14: np.float64(0.0851063829787234), 15: np.float64(0.24489795918367346), 16: np.float64(0.5283018867924528), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5015673981191222), 20: np.float64(0.3215434083601286), 21: np.float64(0.0), 22: np.float64(0.49264705882352944), 23: np.float64(0.7252747252747253), 24: np.float64(0.0), 25: np.float64(0.3225806451612903), 26: np.float64(0.6057142857142858), 27: np.float64(0.0), 28: np.float64(0.08849557522123894), 29: np.float64(0.7715736040609137), 30: np.float64(0.8571428571428571), 31: np.float64(0.2), 32: np.float64(0.5808823529411765), 33: np.float64(0.20689655172413793), 34: np.float64(0.19248826291079812), 35: np.float64(0.22807017543859648), 36: np.float64(0.029850746268656716), 37: np.float64(0.23357664233576642), 38: np.float64(0.18095238095238095), 39: np.float64(0.10309278350515463), 40: np.float64(0.2145922746781116)}
Micro-average F1 score: 0.3543586109142452
Weighted-average F1 score: 0.34043317102641946
F1 score per class: {0: np.float64(0.4520547945205479), 1: np.float64(0.1762114537444934), 2: np.float64(0.23728813559322035), 3: np.float64(0.40418118466898956), 4: np.float64(0.8297872340425532), 5: np.float64(0.49), 6: np.float64(0.38636363636363635), 7: np.float64(0.06060606060606061), 8: np.float64(0.34959349593495936), 9: np.float64(0.45045045045045046), 10: np.float64(0.20253164556962025), 11: np.float64(0.16374269005847952), 12: np.float64(0.2888086642599278), 13: np.float64(0.09090909090909091), 14: np.float64(0.0975609756097561), 15: np.float64(0.36363636363636365), 16: np.float64(0.5230769230769231), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.43783783783783786), 20: np.float64(0.4393939393939394), 21: np.float64(0.044444444444444446), 22: np.float64(0.43258426966292135), 23: np.float64(0.6728971962616822), 24: np.float64(0.08), 25: np.float64(0.5333333333333333), 26: np.float64(0.6494845360824743), 27: np.float64(0.0), 28: np.float64(0.10526315789473684), 29: np.float64(0.7668393782383419), 30: np.float64(0.4444444444444444), 31: np.float64(0.06666666666666667), 32: np.float64(0.60431654676259), 33: np.float64(0.11320754716981132), 34: np.float64(0.24054982817869416), 35: np.float64(0.3179916317991632), 36: np.float64(0.4158415841584158), 37: np.float64(0.15458937198067632), 38: np.float64(0.20454545454545456), 39: np.float64(0.08791208791208792), 40: np.float64(0.22580645161290322)}
Micro-average F1 score: 0.35886349598517603
Weighted-average F1 score: 0.3421594751437912
F1 score per class: {0: np.float64(0.5409836065573771), 1: np.float64(0.17796610169491525), 2: np.float64(0.34146341463414637), 3: np.float64(0.42696629213483145), 4: np.float64(0.8522727272727273), 5: np.float64(0.6438356164383562), 6: np.float64(0.2987012987012987), 7: np.float64(0.05714285714285714), 8: np.float64(0.33121019108280253), 9: np.float64(0.6756756756756757), 10: np.float64(0.12949640287769784), 11: np.float64(0.15469613259668508), 12: np.float64(0.3106060606060606), 13: np.float64(0.08333333333333333), 14: np.float64(0.10084033613445378), 15: np.float64(0.2926829268292683), 16: np.float64(0.5964912280701754), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.45251396648044695), 20: np.float64(0.43636363636363634), 21: np.float64(0.03076923076923077), 22: np.float64(0.4476744186046512), 23: np.float64(0.72), 24: np.float64(0.08333333333333333), 25: np.float64(0.4857142857142857), 26: np.float64(0.6596858638743456), 27: np.float64(0.0), 28: np.float64(0.1), 29: np.float64(0.7668393782383419), 30: np.float64(0.7272727272727273), 31: np.float64(0.1111111111111111), 32: np.float64(0.5894736842105263), 33: np.float64(0.11764705882352941), 34: np.float64(0.22429906542056074), 35: np.float64(0.2943722943722944), 36: np.float64(0.18181818181818182), 37: np.float64(0.17277486910994763), 38: np.float64(0.17647058823529413), 39: np.float64(0.07142857142857142), 40: np.float64(0.20689655172413793)}
Micro-average F1 score: 0.3638752052545156
Weighted-average F1 score: 0.34732828433494495

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.46153846153846156), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.3076923076923077), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.5473684210526316), 37: np.float64(0.5470085470085471), 38: np.float64(0.5066666666666667), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2327909887359199
Weighted-average F1 score: 0.1512736562270095
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.5), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.5128205128205128), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.6972477064220184), 36: np.float64(0.0), 37: np.float64(0.47058823529411764), 38: np.float64(0.5217391304347826), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2550335570469799
Weighted-average F1 score: 0.1701727424761752
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.48), 16: np.float64(0.0), 17: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.4594594594594595), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.6476190476190476), 36: np.float64(0.0), 37: np.float64(0.4925373134328358), 38: np.float64(0.45), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.25961538461538464
Weighted-average F1 score: 0.17769777792958247

F1 score per class: {0: np.float64(0.47058823529411764), 1: np.float64(0.09071274298056156), 2: np.float64(0.30434782608695654), 3: np.float64(0.19622641509433963), 4: np.float64(0.7513812154696132), 5: np.float64(0.5705329153605015), 6: np.float64(0.1951219512195122), 7: np.float64(0.022222222222222223), 8: np.float64(0.26153846153846155), 9: np.float64(0.704225352112676), 10: np.float64(0.028985507246376812), 11: np.float64(0.11578947368421053), 12: np.float64(0.1483050847457627), 13: np.float64(0.05), 14: np.float64(0.07547169811320754), 15: np.float64(0.12121212121212122), 16: np.float64(0.32941176470588235), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.43243243243243246), 20: np.float64(0.15267175572519084), 21: np.float64(0.0), 22: np.float64(0.3544973544973545), 23: np.float64(0.6055045871559633), 24: np.float64(0.0), 25: np.float64(0.30303030303030304), 26: np.float64(0.5326633165829145), 27: np.float64(0.0), 28: np.float64(0.04784688995215311), 29: np.float64(0.608), 30: np.float64(0.7894736842105263), 31: np.float64(0.10526315789473684), 32: np.float64(0.4103896103896104), 33: np.float64(0.1276595744680851), 34: np.float64(0.11815561959654179), 35: np.float64(0.14730878186968838), 36: np.float64(0.029850746268656716), 37: np.float64(0.1292929292929293), 38: np.float64(0.09921671018276762), 39: np.float64(0.05154639175257732), 40: np.float64(0.1694915254237288)}
Micro-average F1 score: 0.2352111019640127
Weighted-average F1 score: 0.216658073120875
F1 score per class: {0: np.float64(0.336734693877551), 1: np.float64(0.0954653937947494), 2: np.float64(0.1414141414141414), 3: np.float64(0.24166666666666667), 4: np.float64(0.7722772277227723), 5: np.float64(0.30866141732283464), 6: np.float64(0.24199288256227758), 7: np.float64(0.0297029702970297), 8: np.float64(0.215), 9: np.float64(0.32679738562091504), 10: np.float64(0.13445378151260504), 11: np.float64(0.1346153846153846), 12: np.float64(0.13793103448275862), 13: np.float64(0.05128205128205128), 14: np.float64(0.0784313725490196), 15: np.float64(0.27906976744186046), 16: np.float64(0.3333333333333333), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.3584070796460177), 20: np.float64(0.23387096774193547), 21: np.float64(0.035398230088495575), 22: np.float64(0.30078125), 23: np.float64(0.4931506849315068), 24: np.float64(0.07407407407407407), 25: np.float64(0.5063291139240507), 26: np.float64(0.5526315789473685), 27: np.float64(0.0), 28: np.float64(0.05982905982905983), 29: np.float64(0.5991902834008097), 30: np.float64(0.3018867924528302), 31: np.float64(0.03636363636363636), 32: np.float64(0.43410852713178294), 33: np.float64(0.06451612903225806), 34: np.float64(0.14861995753715498), 35: np.float64(0.20994475138121546), 36: np.float64(0.2857142857142857), 37: np.float64(0.0960960960960961), 38: np.float64(0.12244897959183673), 39: np.float64(0.048484848484848485), 40: np.float64(0.1693548387096774)}
Micro-average F1 score: 0.2366116880472409
Weighted-average F1 score: 0.22281814480776516
F1 score per class: {0: np.float64(0.38823529411764707), 1: np.float64(0.09567198177676538), 2: np.float64(0.1891891891891892), 3: np.float64(0.2638888888888889), 4: np.float64(0.8021390374331551), 5: np.float64(0.4423529411764706), 6: np.float64(0.20353982300884957), 7: np.float64(0.0273972602739726), 8: np.float64(0.24528301886792453), 9: np.float64(0.5882352941176471), 10: np.float64(0.09183673469387756), 11: np.float64(0.12173913043478261), 12: np.float64(0.14335664335664336), 13: np.float64(0.046511627906976744), 14: np.float64(0.08275862068965517), 15: np.float64(0.19047619047619047), 16: np.float64(0.37777777777777777), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.3829787234042553), 20: np.float64(0.23920265780730898), 21: np.float64(0.0273972602739726), 22: np.float64(0.308), 23: np.float64(0.5333333333333333), 24: np.float64(0.07692307692307693), 25: np.float64(0.4533333333333333), 26: np.float64(0.5701357466063348), 27: np.float64(0.0), 28: np.float64(0.054901960784313725), 29: np.float64(0.6016260162601627), 30: np.float64(0.64), 31: np.float64(0.06060606060606061), 32: np.float64(0.42105263157894735), 33: np.float64(0.07142857142857142), 34: np.float64(0.13584905660377358), 35: np.float64(0.18579234972677597), 36: np.float64(0.16279069767441862), 37: np.float64(0.10576923076923077), 38: np.float64(0.09944751381215469), 39: np.float64(0.03773584905660377), 40: np.float64(0.15613382899628253)}
Micro-average F1 score: 0.24207996504260432
Weighted-average F1 score: 0.22575428742967935
cur_acc_wo_na:  ['0.7850', '0.5475', '0.3211', '0.6960', '0.5612', '0.4636', '0.4223', '0.3591']
his_acc_wo_na:  ['0.7850', '0.6851', '0.5184', '0.5345', '0.5415', '0.4663', '0.4156', '0.3544']
cur_acc des_wo_na:  ['0.7554', '0.5843', '0.3578', '0.6060', '0.5347', '0.3843', '0.3659', '0.3891']
his_acc des_wo_na:  ['0.7554', '0.6745', '0.5385', '0.4972', '0.4743', '0.4185', '0.3870', '0.3589']
cur_acc rrf_wo_na:  ['0.7728', '0.5855', '0.3800', '0.6490', '0.5606', '0.4431', '0.3856', '0.3934']
his_acc rrf_wo_na:  ['0.7728', '0.6864', '0.5475', '0.5170', '0.5036', '0.4441', '0.3916', '0.3639']
cur_acc_w_na:  ['0.6617', '0.4351', '0.2807', '0.5260', '0.3982', '0.3264', '0.2839', '0.2328']
his_acc_w_na:  ['0.6617', '0.5477', '0.4140', '0.4048', '0.4051', '0.3370', '0.2894', '0.2352']
cur_acc des_w_na:  ['0.6169', '0.4079', '0.3068', '0.4357', '0.3620', '0.2526', '0.2352', '0.2550']
his_acc des_w_na:  ['0.6169', '0.4996', '0.4158', '0.3528', '0.3369', '0.2869', '0.2572', '0.2366']
cur_acc rrf_w_na:  ['0.6380', '0.4123', '0.3314', '0.4773', '0.3865', '0.2943', '0.2513', '0.2596']
his_acc rrf_w_na:  ['0.6380', '0.5158', '0.4295', '0.3731', '0.3636', '0.3066', '0.2634', '0.2421']
----------END
his_acc mean_wo_na:  [0.7644 0.6493 0.5578 0.5187 0.4585 0.4324 0.3961 0.3676]
his_acc des mean_wo_na:  [0.7499 0.6336 0.5445 0.4944 0.434  0.4112 0.3768 0.3536]
his_acc rrf mean_wo_na:  [0.7611 0.647  0.5558 0.5005 0.4416 0.4189 0.3816 0.3594]
his_acc mean_w_na:  [0.638  0.5142 0.4337 0.3881 0.3305 0.3166 0.2787 0.2575]
his_acc des mean_w_na:  [0.6097 0.4775 0.4048 0.3488 0.299  0.2848 0.254  0.2385]
his_acc rrf mean_w_na:  [0.624  0.4932 0.4196 0.3593 0.3084 0.2931 0.261  0.2452]
