#############params############
cuda
Task=Tacred, 5-shot
Encoding model: bert
pattern=hybridprompt
mem=1, margin=0.3, gen=0, gen_num=2
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
#############params############
cuda
Task=Tacred, 5-shot
Encoding model: bert
pattern=hybridprompt
mem=1, margin=0.3, gen=0, gen_num=2
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 127.7220815CurrentTrain: epoch  0, batch     1 | loss: 90.8537670CurrentTrain: epoch  0, batch     2 | loss: 78.5323921CurrentTrain: epoch  0, batch     3 | loss: 88.1128571CurrentTrain: epoch  0, batch     4 | loss: 87.4117280CurrentTrain: epoch  0, batch     5 | loss: 87.5333214CurrentTrain: epoch  0, batch     6 | loss: 102.3014731CurrentTrain: epoch  0, batch     7 | loss: 100.8056232CurrentTrain: epoch  0, batch     8 | loss: 86.0447957CurrentTrain: epoch  0, batch     9 | loss: 86.6402145CurrentTrain: epoch  0, batch    10 | loss: 77.1439328CurrentTrain: epoch  0, batch    11 | loss: 101.0717962CurrentTrain: epoch  0, batch    12 | loss: 99.3287881CurrentTrain: epoch  0, batch    13 | loss: 193.6430926CurrentTrain: epoch  0, batch    14 | loss: 100.5473317CurrentTrain: epoch  0, batch    15 | loss: 86.6449568CurrentTrain: epoch  0, batch    16 | loss: 86.5268141CurrentTrain: epoch  0, batch    17 | loss: 118.3328572CurrentTrain: epoch  0, batch    18 | loss: 99.6282163CurrentTrain: epoch  0, batch    19 | loss: 86.3030368CurrentTrain: epoch  0, batch    20 | loss: 146.9915411CurrentTrain: epoch  0, batch    21 | loss: 146.0146033CurrentTrain: epoch  0, batch    22 | loss: 193.6439938CurrentTrain: epoch  0, batch    23 | loss: 146.0423845CurrentTrain: epoch  0, batch    24 | loss: 99.5199866CurrentTrain: epoch  0, batch    25 | loss: 192.0097653CurrentTrain: epoch  0, batch    26 | loss: 86.0187017CurrentTrain: epoch  0, batch    27 | loss: 117.9216637CurrentTrain: epoch  0, batch    28 | loss: 145.0175038CurrentTrain: epoch  0, batch    29 | loss: 98.7948389CurrentTrain: epoch  0, batch    30 | loss: 145.8730963CurrentTrain: epoch  0, batch    31 | loss: 145.7998216CurrentTrain: epoch  0, batch    32 | loss: 117.3520937CurrentTrain: epoch  0, batch    33 | loss: 85.1911073CurrentTrain: epoch  0, batch    34 | loss: 146.7689917CurrentTrain: epoch  0, batch    35 | loss: 85.3717775CurrentTrain: epoch  0, batch    36 | loss: 84.9059110CurrentTrain: epoch  0, batch    37 | loss: 98.6630096CurrentTrain: epoch  0, batch    38 | loss: 97.9597963CurrentTrain: epoch  0, batch    39 | loss: 84.6973671CurrentTrain: epoch  0, batch    40 | loss: 117.2859446CurrentTrain: epoch  0, batch    41 | loss: 85.9399880CurrentTrain: epoch  0, batch    42 | loss: 84.7489946CurrentTrain: epoch  0, batch    43 | loss: 74.3029010CurrentTrain: epoch  0, batch    44 | loss: 97.7797129CurrentTrain: epoch  0, batch    45 | loss: 82.9831611CurrentTrain: epoch  0, batch    46 | loss: 114.9301514CurrentTrain: epoch  0, batch    47 | loss: 83.4750115CurrentTrain: epoch  0, batch    48 | loss: 97.0654257CurrentTrain: epoch  0, batch    49 | loss: 97.5463982CurrentTrain: epoch  0, batch    50 | loss: 97.1173311CurrentTrain: epoch  0, batch    51 | loss: 97.5744960CurrentTrain: epoch  0, batch    52 | loss: 96.5210653CurrentTrain: epoch  0, batch    53 | loss: 143.4349095CurrentTrain: epoch  0, batch    54 | loss: 115.8313110CurrentTrain: epoch  0, batch    55 | loss: 82.3607249CurrentTrain: epoch  0, batch    56 | loss: 83.7162996CurrentTrain: epoch  0, batch    57 | loss: 95.7088784CurrentTrain: epoch  0, batch    58 | loss: 94.7578587CurrentTrain: epoch  0, batch    59 | loss: 95.8697010CurrentTrain: epoch  0, batch    60 | loss: 93.7021047CurrentTrain: epoch  0, batch    61 | loss: 96.0936507CurrentTrain: epoch  0, batch    62 | loss: 83.0658204CurrentTrain: epoch  0, batch    63 | loss: 112.5762518CurrentTrain: epoch  0, batch    64 | loss: 94.8880371CurrentTrain: epoch  0, batch    65 | loss: 71.5070593CurrentTrain: epoch  0, batch    66 | loss: 91.2670019CurrentTrain: epoch  0, batch    67 | loss: 94.8744973CurrentTrain: epoch  0, batch    68 | loss: 82.7126615CurrentTrain: epoch  0, batch    69 | loss: 141.3598899CurrentTrain: epoch  0, batch    70 | loss: 118.0962400CurrentTrain: epoch  0, batch    71 | loss: 82.7629536CurrentTrain: epoch  0, batch    72 | loss: 96.8317535CurrentTrain: epoch  0, batch    73 | loss: 113.1297511CurrentTrain: epoch  0, batch    74 | loss: 142.8965795CurrentTrain: epoch  0, batch    75 | loss: 95.8275130CurrentTrain: epoch  0, batch    76 | loss: 110.3827453CurrentTrain: epoch  0, batch    77 | loss: 92.9402052CurrentTrain: epoch  0, batch    78 | loss: 112.1313197CurrentTrain: epoch  0, batch    79 | loss: 112.0232035CurrentTrain: epoch  0, batch    80 | loss: 79.7002386CurrentTrain: epoch  0, batch    81 | loss: 93.0355828CurrentTrain: epoch  0, batch    82 | loss: 111.7535893CurrentTrain: epoch  0, batch    83 | loss: 93.3605341CurrentTrain: epoch  0, batch    84 | loss: 108.7136492CurrentTrain: epoch  0, batch    85 | loss: 80.1620752CurrentTrain: epoch  0, batch    86 | loss: 136.3403675CurrentTrain: epoch  0, batch    87 | loss: 81.3434996CurrentTrain: epoch  0, batch    88 | loss: 80.1902484CurrentTrain: epoch  0, batch    89 | loss: 65.9283851CurrentTrain: epoch  0, batch    90 | loss: 92.6883445CurrentTrain: epoch  0, batch    91 | loss: 80.5605219CurrentTrain: epoch  0, batch    92 | loss: 89.9550952CurrentTrain: epoch  0, batch    93 | loss: 136.2417680CurrentTrain: epoch  0, batch    94 | loss: 79.4368533CurrentTrain: epoch  0, batch    95 | loss: 94.1028033CurrentTrain: epoch  1, batch     0 | loss: 79.1429669CurrentTrain: epoch  1, batch     1 | loss: 93.0247809CurrentTrain: epoch  1, batch     2 | loss: 79.0163414CurrentTrain: epoch  1, batch     3 | loss: 79.0209095CurrentTrain: epoch  1, batch     4 | loss: 87.7541311CurrentTrain: epoch  1, batch     5 | loss: 76.2606386CurrentTrain: epoch  1, batch     6 | loss: 94.2187478CurrentTrain: epoch  1, batch     7 | loss: 136.8310789CurrentTrain: epoch  1, batch     8 | loss: 69.3790603CurrentTrain: epoch  1, batch     9 | loss: 106.9774350CurrentTrain: epoch  1, batch    10 | loss: 90.8905436CurrentTrain: epoch  1, batch    11 | loss: 77.5357204CurrentTrain: epoch  1, batch    12 | loss: 76.0211653CurrentTrain: epoch  1, batch    13 | loss: 109.6709184CurrentTrain: epoch  1, batch    14 | loss: 105.1983362CurrentTrain: epoch  1, batch    15 | loss: 93.1846833CurrentTrain: epoch  1, batch    16 | loss: 134.8801358CurrentTrain: epoch  1, batch    17 | loss: 76.3148647CurrentTrain: epoch  1, batch    18 | loss: 86.3018538CurrentTrain: epoch  1, batch    19 | loss: 109.4442914CurrentTrain: epoch  1, batch    20 | loss: 139.8958346CurrentTrain: epoch  1, batch    21 | loss: 78.9517428CurrentTrain: epoch  1, batch    22 | loss: 75.3826283CurrentTrain: epoch  1, batch    23 | loss: 89.8832138CurrentTrain: epoch  1, batch    24 | loss: 134.8857564CurrentTrain: epoch  1, batch    25 | loss: 90.5308116CurrentTrain: epoch  1, batch    26 | loss: 65.7775832CurrentTrain: epoch  1, batch    27 | loss: 75.5091261CurrentTrain: epoch  1, batch    28 | loss: 64.9733965CurrentTrain: epoch  1, batch    29 | loss: 66.4604193CurrentTrain: epoch  1, batch    30 | loss: 91.9495896CurrentTrain: epoch  1, batch    31 | loss: 89.3838674CurrentTrain: epoch  1, batch    32 | loss: 110.9344328CurrentTrain: epoch  1, batch    33 | loss: 93.4560238CurrentTrain: epoch  1, batch    34 | loss: 104.0894502CurrentTrain: epoch  1, batch    35 | loss: 137.7108432CurrentTrain: epoch  1, batch    36 | loss: 77.8256685CurrentTrain: epoch  1, batch    37 | loss: 89.3017208CurrentTrain: epoch  1, batch    38 | loss: 92.1261048CurrentTrain: epoch  1, batch    39 | loss: 65.5486245CurrentTrain: epoch  1, batch    40 | loss: 73.0859956CurrentTrain: epoch  1, batch    41 | loss: 73.7284734CurrentTrain: epoch  1, batch    42 | loss: 80.6756952CurrentTrain: epoch  1, batch    43 | loss: 88.8225415CurrentTrain: epoch  1, batch    44 | loss: 135.9653326CurrentTrain: epoch  1, batch    45 | loss: 89.0180744CurrentTrain: epoch  1, batch    46 | loss: 108.8275860CurrentTrain: epoch  1, batch    47 | loss: 72.7471184CurrentTrain: epoch  1, batch    48 | loss: 91.0108875CurrentTrain: epoch  1, batch    49 | loss: 90.2786367CurrentTrain: epoch  1, batch    50 | loss: 88.3684180CurrentTrain: epoch  1, batch    51 | loss: 112.2827300CurrentTrain: epoch  1, batch    52 | loss: 111.3170320CurrentTrain: epoch  1, batch    53 | loss: 136.9346198CurrentTrain: epoch  1, batch    54 | loss: 79.1999905CurrentTrain: epoch  1, batch    55 | loss: 90.4883873CurrentTrain: epoch  1, batch    56 | loss: 88.1583225CurrentTrain: epoch  1, batch    57 | loss: 107.9655738CurrentTrain: epoch  1, batch    58 | loss: 90.4222978CurrentTrain: epoch  1, batch    59 | loss: 73.6062589CurrentTrain: epoch  1, batch    60 | loss: 87.4736655CurrentTrain: epoch  1, batch    61 | loss: 134.7719461CurrentTrain: epoch  1, batch    62 | loss: 140.0039162CurrentTrain: epoch  1, batch    63 | loss: 73.8148961CurrentTrain: epoch  1, batch    64 | loss: 88.5552007CurrentTrain: epoch  1, batch    65 | loss: 108.8201444CurrentTrain: epoch  1, batch    66 | loss: 66.6320474CurrentTrain: epoch  1, batch    67 | loss: 135.5569589CurrentTrain: epoch  1, batch    68 | loss: 72.5329299CurrentTrain: epoch  1, batch    69 | loss: 80.5790771CurrentTrain: epoch  1, batch    70 | loss: 72.7461847CurrentTrain: epoch  1, batch    71 | loss: 87.3252302CurrentTrain: epoch  1, batch    72 | loss: 108.6865097CurrentTrain: epoch  1, batch    73 | loss: 101.3689726CurrentTrain: epoch  1, batch    74 | loss: 106.1957457CurrentTrain: epoch  1, batch    75 | loss: 85.8196550CurrentTrain: epoch  1, batch    76 | loss: 92.7409466CurrentTrain: epoch  1, batch    77 | loss: 91.9555429CurrentTrain: epoch  1, batch    78 | loss: 85.3544729CurrentTrain: epoch  1, batch    79 | loss: 89.4683257CurrentTrain: epoch  1, batch    80 | loss: 67.0911222CurrentTrain: epoch  1, batch    81 | loss: 103.5734269CurrentTrain: epoch  1, batch    82 | loss: 75.3524268CurrentTrain: epoch  1, batch    83 | loss: 183.4092867CurrentTrain: epoch  1, batch    84 | loss: 106.4944708CurrentTrain: epoch  1, batch    85 | loss: 72.2608271CurrentTrain: epoch  1, batch    86 | loss: 66.1773024CurrentTrain: epoch  1, batch    87 | loss: 76.7558047CurrentTrain: epoch  1, batch    88 | loss: 109.5815370CurrentTrain: epoch  1, batch    89 | loss: 87.6933806CurrentTrain: epoch  1, batch    90 | loss: 76.2144519CurrentTrain: epoch  1, batch    91 | loss: 89.1836800CurrentTrain: epoch  1, batch    92 | loss: 88.6509461CurrentTrain: epoch  1, batch    93 | loss: 136.1138869CurrentTrain: epoch  1, batch    94 | loss: 92.5413507CurrentTrain: epoch  1, batch    95 | loss: 70.4866658CurrentTrain: epoch  2, batch     0 | loss: 63.4633098CurrentTrain: epoch  2, batch     1 | loss: 105.7368118CurrentTrain: epoch  2, batch     2 | loss: 87.9546061CurrentTrain: epoch  2, batch     3 | loss: 90.1068765CurrentTrain: epoch  2, batch     4 | loss: 137.6658622CurrentTrain: epoch  2, batch     5 | loss: 73.0990314CurrentTrain: epoch  2, batch     6 | loss: 131.3547898CurrentTrain: epoch  2, batch     7 | loss: 83.3046115CurrentTrain: epoch  2, batch     8 | loss: 107.0784879CurrentTrain: epoch  2, batch     9 | loss: 62.4952450CurrentTrain: epoch  2, batch    10 | loss: 101.0796931CurrentTrain: epoch  2, batch    11 | loss: 62.2289126CurrentTrain: epoch  2, batch    12 | loss: 65.4728160CurrentTrain: epoch  2, batch    13 | loss: 103.9472830CurrentTrain: epoch  2, batch    14 | loss: 107.7845101CurrentTrain: epoch  2, batch    15 | loss: 109.7401944CurrentTrain: epoch  2, batch    16 | loss: 83.4526651CurrentTrain: epoch  2, batch    17 | loss: 89.1495954CurrentTrain: epoch  2, batch    18 | loss: 85.8061097CurrentTrain: epoch  2, batch    19 | loss: 103.8104434CurrentTrain: epoch  2, batch    20 | loss: 74.6673806CurrentTrain: epoch  2, batch    21 | loss: 104.1491261CurrentTrain: epoch  2, batch    22 | loss: 75.1399246CurrentTrain: epoch  2, batch    23 | loss: 84.4782021CurrentTrain: epoch  2, batch    24 | loss: 83.4086524CurrentTrain: epoch  2, batch    25 | loss: 83.8499715CurrentTrain: epoch  2, batch    26 | loss: 88.7956152CurrentTrain: epoch  2, batch    27 | loss: 80.6821377CurrentTrain: epoch  2, batch    28 | loss: 106.0968266CurrentTrain: epoch  2, batch    29 | loss: 103.3705155CurrentTrain: epoch  2, batch    30 | loss: 88.7178713CurrentTrain: epoch  2, batch    31 | loss: 85.6052760CurrentTrain: epoch  2, batch    32 | loss: 77.4165059CurrentTrain: epoch  2, batch    33 | loss: 109.8571778CurrentTrain: epoch  2, batch    34 | loss: 106.9290625CurrentTrain: epoch  2, batch    35 | loss: 104.2080637CurrentTrain: epoch  2, batch    36 | loss: 87.8919282CurrentTrain: epoch  2, batch    37 | loss: 102.3097045CurrentTrain: epoch  2, batch    38 | loss: 72.6079286CurrentTrain: epoch  2, batch    39 | loss: 105.0300757CurrentTrain: epoch  2, batch    40 | loss: 61.6446638CurrentTrain: epoch  2, batch    41 | loss: 108.2886584CurrentTrain: epoch  2, batch    42 | loss: 103.9935896CurrentTrain: epoch  2, batch    43 | loss: 74.3707029CurrentTrain: epoch  2, batch    44 | loss: 84.6875300CurrentTrain: epoch  2, batch    45 | loss: 74.0963901CurrentTrain: epoch  2, batch    46 | loss: 88.4529904CurrentTrain: epoch  2, batch    47 | loss: 75.9096039CurrentTrain: epoch  2, batch    48 | loss: 132.7969806CurrentTrain: epoch  2, batch    49 | loss: 134.5012011CurrentTrain: epoch  2, batch    50 | loss: 71.2079723CurrentTrain: epoch  2, batch    51 | loss: 138.1367055CurrentTrain: epoch  2, batch    52 | loss: 73.5084339CurrentTrain: epoch  2, batch    53 | loss: 88.8806826CurrentTrain: epoch  2, batch    54 | loss: 106.7674333CurrentTrain: epoch  2, batch    55 | loss: 86.6584963CurrentTrain: epoch  2, batch    56 | loss: 84.9611096CurrentTrain: epoch  2, batch    57 | loss: 69.7430491CurrentTrain: epoch  2, batch    58 | loss: 76.2138674CurrentTrain: epoch  2, batch    59 | loss: 73.5382963CurrentTrain: epoch  2, batch    60 | loss: 86.5169683CurrentTrain: epoch  2, batch    61 | loss: 69.4141255CurrentTrain: epoch  2, batch    62 | loss: 83.5098702CurrentTrain: epoch  2, batch    63 | loss: 71.0163127CurrentTrain: epoch  2, batch    64 | loss: 70.6454187CurrentTrain: epoch  2, batch    65 | loss: 84.0823176CurrentTrain: epoch  2, batch    66 | loss: 137.0294522CurrentTrain: epoch  2, batch    67 | loss: 106.2393961CurrentTrain: epoch  2, batch    68 | loss: 71.8083975CurrentTrain: epoch  2, batch    69 | loss: 70.4371825CurrentTrain: epoch  2, batch    70 | loss: 89.8489276CurrentTrain: epoch  2, batch    71 | loss: 73.1203134CurrentTrain: epoch  2, batch    72 | loss: 185.4762149CurrentTrain: epoch  2, batch    73 | loss: 85.9117725CurrentTrain: epoch  2, batch    74 | loss: 84.5886976CurrentTrain: epoch  2, batch    75 | loss: 84.1333203CurrentTrain: epoch  2, batch    76 | loss: 103.3354243CurrentTrain: epoch  2, batch    77 | loss: 62.8983265CurrentTrain: epoch  2, batch    78 | loss: 88.5238066CurrentTrain: epoch  2, batch    79 | loss: 84.4302745CurrentTrain: epoch  2, batch    80 | loss: 71.1574474CurrentTrain: epoch  2, batch    81 | loss: 86.9617291CurrentTrain: epoch  2, batch    82 | loss: 107.3554352CurrentTrain: epoch  2, batch    83 | loss: 107.6274277CurrentTrain: epoch  2, batch    84 | loss: 75.0236745CurrentTrain: epoch  2, batch    85 | loss: 134.6869707CurrentTrain: epoch  2, batch    86 | loss: 61.6066712CurrentTrain: epoch  2, batch    87 | loss: 63.1303072CurrentTrain: epoch  2, batch    88 | loss: 64.8103332CurrentTrain: epoch  2, batch    89 | loss: 100.9763148CurrentTrain: epoch  2, batch    90 | loss: 85.4208509CurrentTrain: epoch  2, batch    91 | loss: 75.4495391CurrentTrain: epoch  2, batch    92 | loss: 74.1512195CurrentTrain: epoch  2, batch    93 | loss: 88.1906817CurrentTrain: epoch  2, batch    94 | loss: 86.5698235CurrentTrain: epoch  2, batch    95 | loss: 72.1637415CurrentTrain: epoch  3, batch     0 | loss: 86.3063992CurrentTrain: epoch  3, batch     1 | loss: 102.5932586CurrentTrain: epoch  3, batch     2 | loss: 86.7361085CurrentTrain: epoch  3, batch     3 | loss: 88.4704270CurrentTrain: epoch  3, batch     4 | loss: 82.1571262CurrentTrain: epoch  3, batch     5 | loss: 100.4267660CurrentTrain: epoch  3, batch     6 | loss: 81.8782020CurrentTrain: epoch  3, batch     7 | loss: 61.9005272CurrentTrain: epoch  3, batch     8 | loss: 74.3793400CurrentTrain: epoch  3, batch     9 | loss: 125.7092998CurrentTrain: epoch  3, batch    10 | loss: 74.8935262CurrentTrain: epoch  3, batch    11 | loss: 81.1958725CurrentTrain: epoch  3, batch    12 | loss: 103.7434880CurrentTrain: epoch  3, batch    13 | loss: 103.3126357CurrentTrain: epoch  3, batch    14 | loss: 84.7167128CurrentTrain: epoch  3, batch    15 | loss: 104.7373334CurrentTrain: epoch  3, batch    16 | loss: 100.0572734CurrentTrain: epoch  3, batch    17 | loss: 69.0516127CurrentTrain: epoch  3, batch    18 | loss: 72.6540423CurrentTrain: epoch  3, batch    19 | loss: 73.9276542CurrentTrain: epoch  3, batch    20 | loss: 106.1061653CurrentTrain: epoch  3, batch    21 | loss: 81.4207789CurrentTrain: epoch  3, batch    22 | loss: 106.0723841CurrentTrain: epoch  3, batch    23 | loss: 86.6700244CurrentTrain: epoch  3, batch    24 | loss: 72.6840790CurrentTrain: epoch  3, batch    25 | loss: 86.8822255CurrentTrain: epoch  3, batch    26 | loss: 103.9046155CurrentTrain: epoch  3, batch    27 | loss: 107.4420069CurrentTrain: epoch  3, batch    28 | loss: 104.8666779CurrentTrain: epoch  3, batch    29 | loss: 73.0003615CurrentTrain: epoch  3, batch    30 | loss: 89.3440586CurrentTrain: epoch  3, batch    31 | loss: 81.7727104CurrentTrain: epoch  3, batch    32 | loss: 83.0590073CurrentTrain: epoch  3, batch    33 | loss: 131.5467375CurrentTrain: epoch  3, batch    34 | loss: 85.4139772CurrentTrain: epoch  3, batch    35 | loss: 126.8503981CurrentTrain: epoch  3, batch    36 | loss: 60.3985350CurrentTrain: epoch  3, batch    37 | loss: 130.4108237CurrentTrain: epoch  3, batch    38 | loss: 67.0239118CurrentTrain: epoch  3, batch    39 | loss: 86.4331303CurrentTrain: epoch  3, batch    40 | loss: 82.2893020CurrentTrain: epoch  3, batch    41 | loss: 81.7247513CurrentTrain: epoch  3, batch    42 | loss: 87.4331997CurrentTrain: epoch  3, batch    43 | loss: 70.2550035CurrentTrain: epoch  3, batch    44 | loss: 65.4904100CurrentTrain: epoch  3, batch    45 | loss: 73.0062250CurrentTrain: epoch  3, batch    46 | loss: 103.4462046CurrentTrain: epoch  3, batch    47 | loss: 86.3613572CurrentTrain: epoch  3, batch    48 | loss: 131.0283102CurrentTrain: epoch  3, batch    49 | loss: 62.1635747CurrentTrain: epoch  3, batch    50 | loss: 73.6459344CurrentTrain: epoch  3, batch    51 | loss: 75.4154136CurrentTrain: epoch  3, batch    52 | loss: 133.3571180CurrentTrain: epoch  3, batch    53 | loss: 74.9668043CurrentTrain: epoch  3, batch    54 | loss: 104.8821651CurrentTrain: epoch  3, batch    55 | loss: 79.2336341CurrentTrain: epoch  3, batch    56 | loss: 72.9141982CurrentTrain: epoch  3, batch    57 | loss: 75.4122489CurrentTrain: epoch  3, batch    58 | loss: 84.4280919CurrentTrain: epoch  3, batch    59 | loss: 127.2484958CurrentTrain: epoch  3, batch    60 | loss: 86.3606168CurrentTrain: epoch  3, batch    61 | loss: 71.3181997CurrentTrain: epoch  3, batch    62 | loss: 79.8141637CurrentTrain: epoch  3, batch    63 | loss: 103.0517283CurrentTrain: epoch  3, batch    64 | loss: 81.5772097CurrentTrain: epoch  3, batch    65 | loss: 104.0652922CurrentTrain: epoch  3, batch    66 | loss: 105.1438355CurrentTrain: epoch  3, batch    67 | loss: 71.5221063CurrentTrain: epoch  3, batch    68 | loss: 84.4302801CurrentTrain: epoch  3, batch    69 | loss: 68.7495783CurrentTrain: epoch  3, batch    70 | loss: 83.7632950CurrentTrain: epoch  3, batch    71 | loss: 59.8892883CurrentTrain: epoch  3, batch    72 | loss: 74.2086931CurrentTrain: epoch  3, batch    73 | loss: 57.8042102CurrentTrain: epoch  3, batch    74 | loss: 86.9560377CurrentTrain: epoch  3, batch    75 | loss: 106.6521319CurrentTrain: epoch  3, batch    76 | loss: 96.9078245CurrentTrain: epoch  3, batch    77 | loss: 85.3908460CurrentTrain: epoch  3, batch    78 | loss: 128.9429918CurrentTrain: epoch  3, batch    79 | loss: 81.0959516CurrentTrain: epoch  3, batch    80 | loss: 103.0019002CurrentTrain: epoch  3, batch    81 | loss: 62.9450834CurrentTrain: epoch  3, batch    82 | loss: 109.7592402CurrentTrain: epoch  3, batch    83 | loss: 80.5348866CurrentTrain: epoch  3, batch    84 | loss: 71.5835728CurrentTrain: epoch  3, batch    85 | loss: 107.4225309CurrentTrain: epoch  3, batch    86 | loss: 72.3382689CurrentTrain: epoch  3, batch    87 | loss: 85.8928282CurrentTrain: epoch  3, batch    88 | loss: 68.6304847CurrentTrain: epoch  3, batch    89 | loss: 69.4889061CurrentTrain: epoch  3, batch    90 | loss: 97.2023327CurrentTrain: epoch  3, batch    91 | loss: 100.9376678CurrentTrain: epoch  3, batch    92 | loss: 75.0590572CurrentTrain: epoch  3, batch    93 | loss: 84.3951678CurrentTrain: epoch  3, batch    94 | loss: 106.2425463CurrentTrain: epoch  3, batch    95 | loss: 54.3190094CurrentTrain: epoch  4, batch     0 | loss: 80.9853863CurrentTrain: epoch  4, batch     1 | loss: 103.5994543CurrentTrain: epoch  4, batch     2 | loss: 98.9482350CurrentTrain: epoch  4, batch     3 | loss: 76.2773616CurrentTrain: epoch  4, batch     4 | loss: 131.7211485CurrentTrain: epoch  4, batch     5 | loss: 96.0808934CurrentTrain: epoch  4, batch     6 | loss: 71.7722704CurrentTrain: epoch  4, batch     7 | loss: 66.0371740CurrentTrain: epoch  4, batch     8 | loss: 103.8573851CurrentTrain: epoch  4, batch     9 | loss: 131.6617851CurrentTrain: epoch  4, batch    10 | loss: 103.2820615CurrentTrain: epoch  4, batch    11 | loss: 70.2007412CurrentTrain: epoch  4, batch    12 | loss: 82.4184455CurrentTrain: epoch  4, batch    13 | loss: 71.2516139CurrentTrain: epoch  4, batch    14 | loss: 80.8825955CurrentTrain: epoch  4, batch    15 | loss: 102.6258793CurrentTrain: epoch  4, batch    16 | loss: 100.8968209CurrentTrain: epoch  4, batch    17 | loss: 128.2134560CurrentTrain: epoch  4, batch    18 | loss: 79.5569275CurrentTrain: epoch  4, batch    19 | loss: 82.3672154CurrentTrain: epoch  4, batch    20 | loss: 77.4925696CurrentTrain: epoch  4, batch    21 | loss: 70.6568983CurrentTrain: epoch  4, batch    22 | loss: 105.4681934CurrentTrain: epoch  4, batch    23 | loss: 74.4510018CurrentTrain: epoch  4, batch    24 | loss: 93.2851733CurrentTrain: epoch  4, batch    25 | loss: 104.2724380CurrentTrain: epoch  4, batch    26 | loss: 84.9697705CurrentTrain: epoch  4, batch    27 | loss: 63.0030200CurrentTrain: epoch  4, batch    28 | loss: 96.7982039CurrentTrain: epoch  4, batch    29 | loss: 84.0197712CurrentTrain: epoch  4, batch    30 | loss: 85.0812432CurrentTrain: epoch  4, batch    31 | loss: 71.7909559CurrentTrain: epoch  4, batch    32 | loss: 95.0570507CurrentTrain: epoch  4, batch    33 | loss: 57.8615467CurrentTrain: epoch  4, batch    34 | loss: 101.2884722CurrentTrain: epoch  4, batch    35 | loss: 84.2403473CurrentTrain: epoch  4, batch    36 | loss: 72.4285692CurrentTrain: epoch  4, batch    37 | loss: 61.7599854CurrentTrain: epoch  4, batch    38 | loss: 83.7650512CurrentTrain: epoch  4, batch    39 | loss: 72.9707294CurrentTrain: epoch  4, batch    40 | loss: 82.8033698CurrentTrain: epoch  4, batch    41 | loss: 70.1930629CurrentTrain: epoch  4, batch    42 | loss: 86.1511761CurrentTrain: epoch  4, batch    43 | loss: 60.1942427CurrentTrain: epoch  4, batch    44 | loss: 68.1250290CurrentTrain: epoch  4, batch    45 | loss: 84.9135238CurrentTrain: epoch  4, batch    46 | loss: 72.3871674CurrentTrain: epoch  4, batch    47 | loss: 99.3681658CurrentTrain: epoch  4, batch    48 | loss: 75.3179585CurrentTrain: epoch  4, batch    49 | loss: 83.7869582CurrentTrain: epoch  4, batch    50 | loss: 79.8105114CurrentTrain: epoch  4, batch    51 | loss: 72.3001916CurrentTrain: epoch  4, batch    52 | loss: 81.7386320CurrentTrain: epoch  4, batch    53 | loss: 127.8398582CurrentTrain: epoch  4, batch    54 | loss: 82.9590439CurrentTrain: epoch  4, batch    55 | loss: 104.1293984CurrentTrain: epoch  4, batch    56 | loss: 131.7434623CurrentTrain: epoch  4, batch    57 | loss: 72.4333353CurrentTrain: epoch  4, batch    58 | loss: 128.0371827CurrentTrain: epoch  4, batch    59 | loss: 102.0708716CurrentTrain: epoch  4, batch    60 | loss: 83.0993818CurrentTrain: epoch  4, batch    61 | loss: 59.3668740CurrentTrain: epoch  4, batch    62 | loss: 58.2505360CurrentTrain: epoch  4, batch    63 | loss: 68.9806815CurrentTrain: epoch  4, batch    64 | loss: 85.5055168CurrentTrain: epoch  4, batch    65 | loss: 127.4753049CurrentTrain: epoch  4, batch    66 | loss: 72.1453125CurrentTrain: epoch  4, batch    67 | loss: 72.0223155CurrentTrain: epoch  4, batch    68 | loss: 101.9048384CurrentTrain: epoch  4, batch    69 | loss: 70.4165880CurrentTrain: epoch  4, batch    70 | loss: 93.3081856CurrentTrain: epoch  4, batch    71 | loss: 103.5107811CurrentTrain: epoch  4, batch    72 | loss: 66.7717100CurrentTrain: epoch  4, batch    73 | loss: 73.8690854CurrentTrain: epoch  4, batch    74 | loss: 131.4484037CurrentTrain: epoch  4, batch    75 | loss: 83.1985159CurrentTrain: epoch  4, batch    76 | loss: 131.4411342CurrentTrain: epoch  4, batch    77 | loss: 99.6431297CurrentTrain: epoch  4, batch    78 | loss: 69.9713216CurrentTrain: epoch  4, batch    79 | loss: 98.5171089CurrentTrain: epoch  4, batch    80 | loss: 71.5517849CurrentTrain: epoch  4, batch    81 | loss: 130.8326146CurrentTrain: epoch  4, batch    82 | loss: 79.6089496CurrentTrain: epoch  4, batch    83 | loss: 71.0464623CurrentTrain: epoch  4, batch    84 | loss: 76.0576579CurrentTrain: epoch  4, batch    85 | loss: 85.0497965CurrentTrain: epoch  4, batch    86 | loss: 108.0405794CurrentTrain: epoch  4, batch    87 | loss: 124.4941069CurrentTrain: epoch  4, batch    88 | loss: 102.5623210CurrentTrain: epoch  4, batch    89 | loss: 71.0794468CurrentTrain: epoch  4, batch    90 | loss: 121.1154688CurrentTrain: epoch  4, batch    91 | loss: 96.2113336CurrentTrain: epoch  4, batch    92 | loss: 86.4512494CurrentTrain: epoch  4, batch    93 | loss: 79.6214798CurrentTrain: epoch  4, batch    94 | loss: 90.1272404CurrentTrain: epoch  4, batch    95 | loss: 59.7497923CurrentTrain: epoch  5, batch     0 | loss: 80.6745227CurrentTrain: epoch  5, batch     1 | loss: 81.8086655CurrentTrain: epoch  5, batch     2 | loss: 99.1303264CurrentTrain: epoch  5, batch     3 | loss: 84.9263271CurrentTrain: epoch  5, batch     4 | loss: 78.6425256CurrentTrain: epoch  5, batch     5 | loss: 68.6597551CurrentTrain: epoch  5, batch     6 | loss: 127.9489345CurrentTrain: epoch  5, batch     7 | loss: 79.5123983CurrentTrain: epoch  5, batch     8 | loss: 80.6526808CurrentTrain: epoch  5, batch     9 | loss: 77.8829764CurrentTrain: epoch  5, batch    10 | loss: 71.4237225CurrentTrain: epoch  5, batch    11 | loss: 102.1171847CurrentTrain: epoch  5, batch    12 | loss: 129.7165721CurrentTrain: epoch  5, batch    13 | loss: 66.8749684CurrentTrain: epoch  5, batch    14 | loss: 97.7462600CurrentTrain: epoch  5, batch    15 | loss: 65.9297248CurrentTrain: epoch  5, batch    16 | loss: 82.2442827CurrentTrain: epoch  5, batch    17 | loss: 67.0855673CurrentTrain: epoch  5, batch    18 | loss: 83.5610194CurrentTrain: epoch  5, batch    19 | loss: 99.7338416CurrentTrain: epoch  5, batch    20 | loss: 81.9542177CurrentTrain: epoch  5, batch    21 | loss: 65.6476628CurrentTrain: epoch  5, batch    22 | loss: 83.5597551CurrentTrain: epoch  5, batch    23 | loss: 95.4622745CurrentTrain: epoch  5, batch    24 | loss: 59.1967271CurrentTrain: epoch  5, batch    25 | loss: 83.1572236CurrentTrain: epoch  5, batch    26 | loss: 102.5664171CurrentTrain: epoch  5, batch    27 | loss: 97.2368356CurrentTrain: epoch  5, batch    28 | loss: 129.3108396CurrentTrain: epoch  5, batch    29 | loss: 268.4045253CurrentTrain: epoch  5, batch    30 | loss: 72.1031464CurrentTrain: epoch  5, batch    31 | loss: 168.3049540CurrentTrain: epoch  5, batch    32 | loss: 66.6947672CurrentTrain: epoch  5, batch    33 | loss: 75.6692635CurrentTrain: epoch  5, batch    34 | loss: 79.9931539CurrentTrain: epoch  5, batch    35 | loss: 62.7920810CurrentTrain: epoch  5, batch    36 | loss: 126.9074592CurrentTrain: epoch  5, batch    37 | loss: 81.2714361CurrentTrain: epoch  5, batch    38 | loss: 93.6385324CurrentTrain: epoch  5, batch    39 | loss: 100.9736083CurrentTrain: epoch  5, batch    40 | loss: 79.8973455CurrentTrain: epoch  5, batch    41 | loss: 102.3364613CurrentTrain: epoch  5, batch    42 | loss: 130.1404135CurrentTrain: epoch  5, batch    43 | loss: 70.5246279CurrentTrain: epoch  5, batch    44 | loss: 68.2337667CurrentTrain: epoch  5, batch    45 | loss: 82.5058759CurrentTrain: epoch  5, batch    46 | loss: 84.5820862CurrentTrain: epoch  5, batch    47 | loss: 68.3367260CurrentTrain: epoch  5, batch    48 | loss: 64.2004497CurrentTrain: epoch  5, batch    49 | loss: 72.1309379CurrentTrain: epoch  5, batch    50 | loss: 60.7657902CurrentTrain: epoch  5, batch    51 | loss: 81.8810941CurrentTrain: epoch  5, batch    52 | loss: 83.5436822CurrentTrain: epoch  5, batch    53 | loss: 75.8996075CurrentTrain: epoch  5, batch    54 | loss: 85.8101942CurrentTrain: epoch  5, batch    55 | loss: 102.1574715CurrentTrain: epoch  5, batch    56 | loss: 130.4886322CurrentTrain: epoch  5, batch    57 | loss: 84.2959963CurrentTrain: epoch  5, batch    58 | loss: 84.6760417CurrentTrain: epoch  5, batch    59 | loss: 128.3671217CurrentTrain: epoch  5, batch    60 | loss: 100.7088695CurrentTrain: epoch  5, batch    61 | loss: 79.9438964CurrentTrain: epoch  5, batch    62 | loss: 100.0597946CurrentTrain: epoch  5, batch    63 | loss: 84.4062335CurrentTrain: epoch  5, batch    64 | loss: 56.3331679CurrentTrain: epoch  5, batch    65 | loss: 77.4520731CurrentTrain: epoch  5, batch    66 | loss: 78.7332477CurrentTrain: epoch  5, batch    67 | loss: 79.7066513CurrentTrain: epoch  5, batch    68 | loss: 64.0836808CurrentTrain: epoch  5, batch    69 | loss: 80.6194588CurrentTrain: epoch  5, batch    70 | loss: 100.6500363CurrentTrain: epoch  5, batch    71 | loss: 102.0757521CurrentTrain: epoch  5, batch    72 | loss: 100.5272394CurrentTrain: epoch  5, batch    73 | loss: 78.9365151CurrentTrain: epoch  5, batch    74 | loss: 65.0360053CurrentTrain: epoch  5, batch    75 | loss: 68.3666923CurrentTrain: epoch  5, batch    76 | loss: 128.7333965CurrentTrain: epoch  5, batch    77 | loss: 83.6649493CurrentTrain: epoch  5, batch    78 | loss: 78.4024812CurrentTrain: epoch  5, batch    79 | loss: 81.2464440CurrentTrain: epoch  5, batch    80 | loss: 97.2612769CurrentTrain: epoch  5, batch    81 | loss: 99.3011227CurrentTrain: epoch  5, batch    82 | loss: 81.6471189CurrentTrain: epoch  5, batch    83 | loss: 102.3657548CurrentTrain: epoch  5, batch    84 | loss: 97.8233337CurrentTrain: epoch  5, batch    85 | loss: 84.5554619CurrentTrain: epoch  5, batch    86 | loss: 102.3520334CurrentTrain: epoch  5, batch    87 | loss: 67.0705510CurrentTrain: epoch  5, batch    88 | loss: 103.6373263CurrentTrain: epoch  5, batch    89 | loss: 78.8837150CurrentTrain: epoch  5, batch    90 | loss: 80.0097772CurrentTrain: epoch  5, batch    91 | loss: 86.6649516CurrentTrain: epoch  5, batch    92 | loss: 81.9540979CurrentTrain: epoch  5, batch    93 | loss: 68.7924266CurrentTrain: epoch  5, batch    94 | loss: 125.3067875CurrentTrain: epoch  5, batch    95 | loss: 61.0104236CurrentTrain: epoch  6, batch     0 | loss: 58.0285483CurrentTrain: epoch  6, batch     1 | loss: 80.5255901CurrentTrain: epoch  6, batch     2 | loss: 77.4466225CurrentTrain: epoch  6, batch     3 | loss: 100.2792112CurrentTrain: epoch  6, batch     4 | loss: 127.9185764CurrentTrain: epoch  6, batch     5 | loss: 172.8123851CurrentTrain: epoch  6, batch     6 | loss: 83.2225628CurrentTrain: epoch  6, batch     7 | loss: 83.0557432CurrentTrain: epoch  6, batch     8 | loss: 99.0636325CurrentTrain: epoch  6, batch     9 | loss: 83.8784080CurrentTrain: epoch  6, batch    10 | loss: 124.5181339CurrentTrain: epoch  6, batch    11 | loss: 81.8828325CurrentTrain: epoch  6, batch    12 | loss: 102.1863033CurrentTrain: epoch  6, batch    13 | loss: 98.9878870CurrentTrain: epoch  6, batch    14 | loss: 59.6141346CurrentTrain: epoch  6, batch    15 | loss: 76.7902464CurrentTrain: epoch  6, batch    16 | loss: 67.2576822CurrentTrain: epoch  6, batch    17 | loss: 81.5501303CurrentTrain: epoch  6, batch    18 | loss: 66.6853755CurrentTrain: epoch  6, batch    19 | loss: 66.4584268CurrentTrain: epoch  6, batch    20 | loss: 67.8872057CurrentTrain: epoch  6, batch    21 | loss: 82.3840086CurrentTrain: epoch  6, batch    22 | loss: 83.3898971CurrentTrain: epoch  6, batch    23 | loss: 96.2104306CurrentTrain: epoch  6, batch    24 | loss: 100.0283077CurrentTrain: epoch  6, batch    25 | loss: 67.4106356CurrentTrain: epoch  6, batch    26 | loss: 67.1099163CurrentTrain: epoch  6, batch    27 | loss: 69.3563106CurrentTrain: epoch  6, batch    28 | loss: 72.5599840CurrentTrain: epoch  6, batch    29 | loss: 93.5648855CurrentTrain: epoch  6, batch    30 | loss: 99.2476849CurrentTrain: epoch  6, batch    31 | loss: 57.3862956CurrentTrain: epoch  6, batch    32 | loss: 97.3307588CurrentTrain: epoch  6, batch    33 | loss: 84.1560452CurrentTrain: epoch  6, batch    34 | loss: 97.4569582CurrentTrain: epoch  6, batch    35 | loss: 65.9271763CurrentTrain: epoch  6, batch    36 | loss: 67.2960368CurrentTrain: epoch  6, batch    37 | loss: 72.1648955CurrentTrain: epoch  6, batch    38 | loss: 99.3270311CurrentTrain: epoch  6, batch    39 | loss: 78.2624743CurrentTrain: epoch  6, batch    40 | loss: 67.4870741CurrentTrain: epoch  6, batch    41 | loss: 97.0838445CurrentTrain: epoch  6, batch    42 | loss: 77.5798073CurrentTrain: epoch  6, batch    43 | loss: 58.5892174CurrentTrain: epoch  6, batch    44 | loss: 55.8013667CurrentTrain: epoch  6, batch    45 | loss: 81.7154150CurrentTrain: epoch  6, batch    46 | loss: 78.3660384CurrentTrain: epoch  6, batch    47 | loss: 131.3556528CurrentTrain: epoch  6, batch    48 | loss: 72.1798671CurrentTrain: epoch  6, batch    49 | loss: 66.1486394CurrentTrain: epoch  6, batch    50 | loss: 99.6205376CurrentTrain: epoch  6, batch    51 | loss: 98.0702283CurrentTrain: epoch  6, batch    52 | loss: 124.3738779CurrentTrain: epoch  6, batch    53 | loss: 100.6010137CurrentTrain: epoch  6, batch    54 | loss: 82.3536488CurrentTrain: epoch  6, batch    55 | loss: 82.6704866CurrentTrain: epoch  6, batch    56 | loss: 103.0985324CurrentTrain: epoch  6, batch    57 | loss: 63.1737439CurrentTrain: epoch  6, batch    58 | loss: 99.9845359CurrentTrain: epoch  6, batch    59 | loss: 58.9483348CurrentTrain: epoch  6, batch    60 | loss: 79.7582926CurrentTrain: epoch  6, batch    61 | loss: 83.0239271CurrentTrain: epoch  6, batch    62 | loss: 101.4807124CurrentTrain: epoch  6, batch    63 | loss: 82.2640179CurrentTrain: epoch  6, batch    64 | loss: 79.8611993CurrentTrain: epoch  6, batch    65 | loss: 101.8652265CurrentTrain: epoch  6, batch    66 | loss: 81.4519894CurrentTrain: epoch  6, batch    67 | loss: 80.2055758CurrentTrain: epoch  6, batch    68 | loss: 100.9063514CurrentTrain: epoch  6, batch    69 | loss: 79.3306788CurrentTrain: epoch  6, batch    70 | loss: 99.2669222CurrentTrain: epoch  6, batch    71 | loss: 55.9382282CurrentTrain: epoch  6, batch    72 | loss: 68.0968491CurrentTrain: epoch  6, batch    73 | loss: 63.3333923CurrentTrain: epoch  6, batch    74 | loss: 101.4757785CurrentTrain: epoch  6, batch    75 | loss: 99.6075249CurrentTrain: epoch  6, batch    76 | loss: 55.9854620CurrentTrain: epoch  6, batch    77 | loss: 58.2229865CurrentTrain: epoch  6, batch    78 | loss: 98.4327784CurrentTrain: epoch  6, batch    79 | loss: 97.4154938CurrentTrain: epoch  6, batch    80 | loss: 79.9255155CurrentTrain: epoch  6, batch    81 | loss: 58.0740574CurrentTrain: epoch  6, batch    82 | loss: 71.7895947CurrentTrain: epoch  6, batch    83 | loss: 95.4469792CurrentTrain: epoch  6, batch    84 | loss: 81.4188430CurrentTrain: epoch  6, batch    85 | loss: 59.3320846CurrentTrain: epoch  6, batch    86 | loss: 79.5887120CurrentTrain: epoch  6, batch    87 | loss: 98.7523221CurrentTrain: epoch  6, batch    88 | loss: 87.8985232CurrentTrain: epoch  6, batch    89 | loss: 100.8642971CurrentTrain: epoch  6, batch    90 | loss: 98.3694579CurrentTrain: epoch  6, batch    91 | loss: 61.1862972CurrentTrain: epoch  6, batch    92 | loss: 80.0903657CurrentTrain: epoch  6, batch    93 | loss: 80.6275635CurrentTrain: epoch  6, batch    94 | loss: 69.4477658CurrentTrain: epoch  6, batch    95 | loss: 101.0926913CurrentTrain: epoch  7, batch     0 | loss: 79.3612473CurrentTrain: epoch  7, batch     1 | loss: 96.9225618CurrentTrain: epoch  7, batch     2 | loss: 82.4173433CurrentTrain: epoch  7, batch     3 | loss: 80.2137719CurrentTrain: epoch  7, batch     4 | loss: 78.8047184CurrentTrain: epoch  7, batch     5 | loss: 96.1178984CurrentTrain: epoch  7, batch     6 | loss: 81.4461917CurrentTrain: epoch  7, batch     7 | loss: 81.2173928CurrentTrain: epoch  7, batch     8 | loss: 67.1547060CurrentTrain: epoch  7, batch     9 | loss: 65.0344140CurrentTrain: epoch  7, batch    10 | loss: 65.8011680CurrentTrain: epoch  7, batch    11 | loss: 68.2550360CurrentTrain: epoch  7, batch    12 | loss: 98.4695288CurrentTrain: epoch  7, batch    13 | loss: 81.7307335CurrentTrain: epoch  7, batch    14 | loss: 80.8263493CurrentTrain: epoch  7, batch    15 | loss: 67.9985446CurrentTrain: epoch  7, batch    16 | loss: 102.9764813CurrentTrain: epoch  7, batch    17 | loss: 74.2828134CurrentTrain: epoch  7, batch    18 | loss: 67.6355244CurrentTrain: epoch  7, batch    19 | loss: 63.5488415CurrentTrain: epoch  7, batch    20 | loss: 75.3470036CurrentTrain: epoch  7, batch    21 | loss: 77.3439016CurrentTrain: epoch  7, batch    22 | loss: 100.3949188CurrentTrain: epoch  7, batch    23 | loss: 96.6912655CurrentTrain: epoch  7, batch    24 | loss: 66.7206551CurrentTrain: epoch  7, batch    25 | loss: 56.7848029CurrentTrain: epoch  7, batch    26 | loss: 80.2442812CurrentTrain: epoch  7, batch    27 | loss: 98.0535367CurrentTrain: epoch  7, batch    28 | loss: 67.5340859CurrentTrain: epoch  7, batch    29 | loss: 101.4257979CurrentTrain: epoch  7, batch    30 | loss: 80.8491086CurrentTrain: epoch  7, batch    31 | loss: 83.9846535CurrentTrain: epoch  7, batch    32 | loss: 120.5941501CurrentTrain: epoch  7, batch    33 | loss: 80.8983704CurrentTrain: epoch  7, batch    34 | loss: 85.2642433CurrentTrain: epoch  7, batch    35 | loss: 97.4015539CurrentTrain: epoch  7, batch    36 | loss: 79.4116719CurrentTrain: epoch  7, batch    37 | loss: 82.9116506CurrentTrain: epoch  7, batch    38 | loss: 81.7948030CurrentTrain: epoch  7, batch    39 | loss: 101.9942190CurrentTrain: epoch  7, batch    40 | loss: 79.3899171CurrentTrain: epoch  7, batch    41 | loss: 64.0333111CurrentTrain: epoch  7, batch    42 | loss: 94.6514773CurrentTrain: epoch  7, batch    43 | loss: 65.7873692CurrentTrain: epoch  7, batch    44 | loss: 78.3178179CurrentTrain: epoch  7, batch    45 | loss: 98.1378083CurrentTrain: epoch  7, batch    46 | loss: 71.4411856CurrentTrain: epoch  7, batch    47 | loss: 75.0975119CurrentTrain: epoch  7, batch    48 | loss: 123.2361459CurrentTrain: epoch  7, batch    49 | loss: 57.9413785CurrentTrain: epoch  7, batch    50 | loss: 91.9139345CurrentTrain: epoch  7, batch    51 | loss: 76.2048785CurrentTrain: epoch  7, batch    52 | loss: 68.0700510CurrentTrain: epoch  7, batch    53 | loss: 98.7091988CurrentTrain: epoch  7, batch    54 | loss: 65.7636128CurrentTrain: epoch  7, batch    55 | loss: 99.1070935CurrentTrain: epoch  7, batch    56 | loss: 94.7033843CurrentTrain: epoch  7, batch    57 | loss: 81.0331872CurrentTrain: epoch  7, batch    58 | loss: 79.6274456CurrentTrain: epoch  7, batch    59 | loss: 126.0019096CurrentTrain: epoch  7, batch    60 | loss: 65.5330007CurrentTrain: epoch  7, batch    61 | loss: 67.7920593CurrentTrain: epoch  7, batch    62 | loss: 120.0303506CurrentTrain: epoch  7, batch    63 | loss: 80.8687005CurrentTrain: epoch  7, batch    64 | loss: 62.5249892CurrentTrain: epoch  7, batch    65 | loss: 74.0571790CurrentTrain: epoch  7, batch    66 | loss: 80.3416963CurrentTrain: epoch  7, batch    67 | loss: 80.0359381CurrentTrain: epoch  7, batch    68 | loss: 63.0363299CurrentTrain: epoch  7, batch    69 | loss: 79.4632495CurrentTrain: epoch  7, batch    70 | loss: 69.8168947CurrentTrain: epoch  7, batch    71 | loss: 98.6149171CurrentTrain: epoch  7, batch    72 | loss: 66.7127869CurrentTrain: epoch  7, batch    73 | loss: 77.8712641CurrentTrain: epoch  7, batch    74 | loss: 55.8626314CurrentTrain: epoch  7, batch    75 | loss: 65.3502324CurrentTrain: epoch  7, batch    76 | loss: 69.9343707CurrentTrain: epoch  7, batch    77 | loss: 99.3205879CurrentTrain: epoch  7, batch    78 | loss: 85.6731357CurrentTrain: epoch  7, batch    79 | loss: 126.8696756CurrentTrain: epoch  7, batch    80 | loss: 69.3444529CurrentTrain: epoch  7, batch    81 | loss: 65.7685706CurrentTrain: epoch  7, batch    82 | loss: 78.9142836CurrentTrain: epoch  7, batch    83 | loss: 64.3529459CurrentTrain: epoch  7, batch    84 | loss: 79.1887108CurrentTrain: epoch  7, batch    85 | loss: 83.8223865CurrentTrain: epoch  7, batch    86 | loss: 66.0993495CurrentTrain: epoch  7, batch    87 | loss: 98.7963533CurrentTrain: epoch  7, batch    88 | loss: 92.8426287CurrentTrain: epoch  7, batch    89 | loss: 127.4437320CurrentTrain: epoch  7, batch    90 | loss: 79.9993446CurrentTrain: epoch  7, batch    91 | loss: 81.7937584CurrentTrain: epoch  7, batch    92 | loss: 100.2836044CurrentTrain: epoch  7, batch    93 | loss: 58.8830750CurrentTrain: epoch  7, batch    94 | loss: 59.4947318CurrentTrain: epoch  7, batch    95 | loss: 83.3126933CurrentTrain: epoch  8, batch     0 | loss: 68.6583862CurrentTrain: epoch  8, batch     1 | loss: 64.7857987CurrentTrain: epoch  8, batch     2 | loss: 93.9132325CurrentTrain: epoch  8, batch     3 | loss: 126.7154821CurrentTrain: epoch  8, batch     4 | loss: 80.5803057CurrentTrain: epoch  8, batch     5 | loss: 69.3430854CurrentTrain: epoch  8, batch     6 | loss: 81.8059801CurrentTrain: epoch  8, batch     7 | loss: 76.1481238CurrentTrain: epoch  8, batch     8 | loss: 66.7714711CurrentTrain: epoch  8, batch     9 | loss: 96.6985804CurrentTrain: epoch  8, batch    10 | loss: 74.9518421CurrentTrain: epoch  8, batch    11 | loss: 76.7784877CurrentTrain: epoch  8, batch    12 | loss: 76.9424723CurrentTrain: epoch  8, batch    13 | loss: 91.9006815CurrentTrain: epoch  8, batch    14 | loss: 77.2588937CurrentTrain: epoch  8, batch    15 | loss: 78.5823776CurrentTrain: epoch  8, batch    16 | loss: 93.9792824CurrentTrain: epoch  8, batch    17 | loss: 79.0600851CurrentTrain: epoch  8, batch    18 | loss: 97.9945859CurrentTrain: epoch  8, batch    19 | loss: 65.9117979CurrentTrain: epoch  8, batch    20 | loss: 76.9969658CurrentTrain: epoch  8, batch    21 | loss: 76.2334197CurrentTrain: epoch  8, batch    22 | loss: 92.0287195CurrentTrain: epoch  8, batch    23 | loss: 66.9042438CurrentTrain: epoch  8, batch    24 | loss: 63.9023237CurrentTrain: epoch  8, batch    25 | loss: 95.3512829CurrentTrain: epoch  8, batch    26 | loss: 64.2676528CurrentTrain: epoch  8, batch    27 | loss: 78.2858694CurrentTrain: epoch  8, batch    28 | loss: 66.4702849CurrentTrain: epoch  8, batch    29 | loss: 67.6312816CurrentTrain: epoch  8, batch    30 | loss: 102.2005790CurrentTrain: epoch  8, batch    31 | loss: 54.2201357CurrentTrain: epoch  8, batch    32 | loss: 168.8592563CurrentTrain: epoch  8, batch    33 | loss: 96.3961087CurrentTrain: epoch  8, batch    34 | loss: 94.5727464CurrentTrain: epoch  8, batch    35 | loss: 64.9140321CurrentTrain: epoch  8, batch    36 | loss: 94.0488805CurrentTrain: epoch  8, batch    37 | loss: 67.2537702CurrentTrain: epoch  8, batch    38 | loss: 77.7564314CurrentTrain: epoch  8, batch    39 | loss: 80.5665387CurrentTrain: epoch  8, batch    40 | loss: 80.4072053CurrentTrain: epoch  8, batch    41 | loss: 98.5768763CurrentTrain: epoch  8, batch    42 | loss: 79.0647192CurrentTrain: epoch  8, batch    43 | loss: 103.4471683CurrentTrain: epoch  8, batch    44 | loss: 123.2550211CurrentTrain: epoch  8, batch    45 | loss: 81.0548829CurrentTrain: epoch  8, batch    46 | loss: 64.6763069CurrentTrain: epoch  8, batch    47 | loss: 81.8245349CurrentTrain: epoch  8, batch    48 | loss: 64.5207740CurrentTrain: epoch  8, batch    49 | loss: 74.9433101CurrentTrain: epoch  8, batch    50 | loss: 94.8258554CurrentTrain: epoch  8, batch    51 | loss: 62.4996833CurrentTrain: epoch  8, batch    52 | loss: 79.3111690CurrentTrain: epoch  8, batch    53 | loss: 84.4577312CurrentTrain: epoch  8, batch    54 | loss: 97.2143292CurrentTrain: epoch  8, batch    55 | loss: 95.1794247CurrentTrain: epoch  8, batch    56 | loss: 68.8873922CurrentTrain: epoch  8, batch    57 | loss: 64.7420253CurrentTrain: epoch  8, batch    58 | loss: 79.4311909CurrentTrain: epoch  8, batch    59 | loss: 55.1620179CurrentTrain: epoch  8, batch    60 | loss: 122.7831324CurrentTrain: epoch  8, batch    61 | loss: 96.6715108CurrentTrain: epoch  8, batch    62 | loss: 56.7610273CurrentTrain: epoch  8, batch    63 | loss: 80.3844422CurrentTrain: epoch  8, batch    64 | loss: 78.6033253CurrentTrain: epoch  8, batch    65 | loss: 79.7515139CurrentTrain: epoch  8, batch    66 | loss: 73.2652312CurrentTrain: epoch  8, batch    67 | loss: 92.3692070CurrentTrain: epoch  8, batch    68 | loss: 94.9779279CurrentTrain: epoch  8, batch    69 | loss: 81.3768964CurrentTrain: epoch  8, batch    70 | loss: 94.5849987CurrentTrain: epoch  8, batch    71 | loss: 123.4947958CurrentTrain: epoch  8, batch    72 | loss: 75.7692891CurrentTrain: epoch  8, batch    73 | loss: 78.7274876CurrentTrain: epoch  8, batch    74 | loss: 96.8930488CurrentTrain: epoch  8, batch    75 | loss: 78.3388406CurrentTrain: epoch  8, batch    76 | loss: 56.6703406CurrentTrain: epoch  8, batch    77 | loss: 123.0012291CurrentTrain: epoch  8, batch    78 | loss: 63.8458191CurrentTrain: epoch  8, batch    79 | loss: 69.5010827CurrentTrain: epoch  8, batch    80 | loss: 93.5047947CurrentTrain: epoch  8, batch    81 | loss: 79.2669792CurrentTrain: epoch  8, batch    82 | loss: 67.3082187CurrentTrain: epoch  8, batch    83 | loss: 65.8483991CurrentTrain: epoch  8, batch    84 | loss: 126.1328015CurrentTrain: epoch  8, batch    85 | loss: 119.4044433CurrentTrain: epoch  8, batch    86 | loss: 98.1651399CurrentTrain: epoch  8, batch    87 | loss: 79.1561960CurrentTrain: epoch  8, batch    88 | loss: 52.0587424CurrentTrain: epoch  8, batch    89 | loss: 76.5812449CurrentTrain: epoch  8, batch    90 | loss: 76.0663243CurrentTrain: epoch  8, batch    91 | loss: 83.9208065CurrentTrain: epoch  8, batch    92 | loss: 80.1252564CurrentTrain: epoch  8, batch    93 | loss: 76.8307224CurrentTrain: epoch  8, batch    94 | loss: 98.4788087CurrentTrain: epoch  8, batch    95 | loss: 101.4704643CurrentTrain: epoch  9, batch     0 | loss: 66.4395980CurrentTrain: epoch  9, batch     1 | loss: 117.5247883CurrentTrain: epoch  9, batch     2 | loss: 75.3409004CurrentTrain: epoch  9, batch     3 | loss: 65.8748774CurrentTrain: epoch  9, batch     4 | loss: 77.8041773CurrentTrain: epoch  9, batch     5 | loss: 53.0747339CurrentTrain: epoch  9, batch     6 | loss: 98.8947429CurrentTrain: epoch  9, batch     7 | loss: 75.3573631CurrentTrain: epoch  9, batch     8 | loss: 95.6309817CurrentTrain: epoch  9, batch     9 | loss: 65.0729616CurrentTrain: epoch  9, batch    10 | loss: 98.6900743CurrentTrain: epoch  9, batch    11 | loss: 67.7658987CurrentTrain: epoch  9, batch    12 | loss: 92.3627878CurrentTrain: epoch  9, batch    13 | loss: 97.3016076CurrentTrain: epoch  9, batch    14 | loss: 96.5545088CurrentTrain: epoch  9, batch    15 | loss: 75.8355668CurrentTrain: epoch  9, batch    16 | loss: 127.9504894CurrentTrain: epoch  9, batch    17 | loss: 78.5529446CurrentTrain: epoch  9, batch    18 | loss: 77.6215751CurrentTrain: epoch  9, batch    19 | loss: 80.7654696CurrentTrain: epoch  9, batch    20 | loss: 64.7339414CurrentTrain: epoch  9, batch    21 | loss: 95.1906272CurrentTrain: epoch  9, batch    22 | loss: 66.9764689CurrentTrain: epoch  9, batch    23 | loss: 67.1099601CurrentTrain: epoch  9, batch    24 | loss: 123.0434251CurrentTrain: epoch  9, batch    25 | loss: 93.5309709CurrentTrain: epoch  9, batch    26 | loss: 61.5492059CurrentTrain: epoch  9, batch    27 | loss: 117.9222754CurrentTrain: epoch  9, batch    28 | loss: 64.7842902CurrentTrain: epoch  9, batch    29 | loss: 66.4130603CurrentTrain: epoch  9, batch    30 | loss: 64.3622077CurrentTrain: epoch  9, batch    31 | loss: 80.4372685CurrentTrain: epoch  9, batch    32 | loss: 94.4526824CurrentTrain: epoch  9, batch    33 | loss: 69.1856881CurrentTrain: epoch  9, batch    34 | loss: 61.9359751CurrentTrain: epoch  9, batch    35 | loss: 120.1263702CurrentTrain: epoch  9, batch    36 | loss: 81.2807071CurrentTrain: epoch  9, batch    37 | loss: 78.9746331CurrentTrain: epoch  9, batch    38 | loss: 81.3503330CurrentTrain: epoch  9, batch    39 | loss: 66.8053316CurrentTrain: epoch  9, batch    40 | loss: 62.3106658CurrentTrain: epoch  9, batch    41 | loss: 79.6870129CurrentTrain: epoch  9, batch    42 | loss: 61.8068544CurrentTrain: epoch  9, batch    43 | loss: 62.8775669CurrentTrain: epoch  9, batch    44 | loss: 124.0662471CurrentTrain: epoch  9, batch    45 | loss: 67.7009062CurrentTrain: epoch  9, batch    46 | loss: 81.0500265CurrentTrain: epoch  9, batch    47 | loss: 97.6978689CurrentTrain: epoch  9, batch    48 | loss: 78.2026900CurrentTrain: epoch  9, batch    49 | loss: 65.3794012CurrentTrain: epoch  9, batch    50 | loss: 73.8235777CurrentTrain: epoch  9, batch    51 | loss: 77.6719507CurrentTrain: epoch  9, batch    52 | loss: 67.0350442CurrentTrain: epoch  9, batch    53 | loss: 80.5811402CurrentTrain: epoch  9, batch    54 | loss: 66.8161578CurrentTrain: epoch  9, batch    55 | loss: 63.5195346CurrentTrain: epoch  9, batch    56 | loss: 81.4862300CurrentTrain: epoch  9, batch    57 | loss: 52.3657357CurrentTrain: epoch  9, batch    58 | loss: 92.7261644CurrentTrain: epoch  9, batch    59 | loss: 95.1690445CurrentTrain: epoch  9, batch    60 | loss: 71.7944204CurrentTrain: epoch  9, batch    61 | loss: 54.9637178CurrentTrain: epoch  9, batch    62 | loss: 96.3521452CurrentTrain: epoch  9, batch    63 | loss: 63.3814594CurrentTrain: epoch  9, batch    64 | loss: 56.1392330CurrentTrain: epoch  9, batch    65 | loss: 93.8349627CurrentTrain: epoch  9, batch    66 | loss: 94.4873552CurrentTrain: epoch  9, batch    67 | loss: 74.8041456CurrentTrain: epoch  9, batch    68 | loss: 123.5903251CurrentTrain: epoch  9, batch    69 | loss: 96.2063111CurrentTrain: epoch  9, batch    70 | loss: 77.0122206CurrentTrain: epoch  9, batch    71 | loss: 95.7933670CurrentTrain: epoch  9, batch    72 | loss: 64.3237196CurrentTrain: epoch  9, batch    73 | loss: 95.3389773CurrentTrain: epoch  9, batch    74 | loss: 127.8119371CurrentTrain: epoch  9, batch    75 | loss: 100.0367896CurrentTrain: epoch  9, batch    76 | loss: 94.5485710CurrentTrain: epoch  9, batch    77 | loss: 63.9284477CurrentTrain: epoch  9, batch    78 | loss: 123.8310437CurrentTrain: epoch  9, batch    79 | loss: 77.9897630CurrentTrain: epoch  9, batch    80 | loss: 55.6403459CurrentTrain: epoch  9, batch    81 | loss: 54.3967215CurrentTrain: epoch  9, batch    82 | loss: 99.6058998CurrentTrain: epoch  9, batch    83 | loss: 123.4088509CurrentTrain: epoch  9, batch    84 | loss: 123.9453384CurrentTrain: epoch  9, batch    85 | loss: 67.1311146CurrentTrain: epoch  9, batch    86 | loss: 75.8632441CurrentTrain: epoch  9, batch    87 | loss: 65.9821738CurrentTrain: epoch  9, batch    88 | loss: 127.3190588CurrentTrain: epoch  9, batch    89 | loss: 58.0431333CurrentTrain: epoch  9, batch    90 | loss: 80.2052439CurrentTrain: epoch  9, batch    91 | loss: 78.7016157CurrentTrain: epoch  9, batch    92 | loss: 54.6119842CurrentTrain: epoch  9, batch    93 | loss: 66.2920677CurrentTrain: epoch  9, batch    94 | loss: 91.5138019CurrentTrain: epoch  9, batch    95 | loss: 64.7858886

F1 score per class: {32: np.float64(0.5274725274725275), 6: np.float64(0.8333333333333334), 19: np.float64(0.375), 24: np.float64(0.7311827956989247), 26: np.float64(0.900523560209424), 29: np.float64(0.8090909090909091)}
Micro-average F1 score: 0.7527093596059113
Weighted-average F1 score: 0.7587317654315657
F1 score per class: {32: np.float64(0.6325581395348837), 6: np.float64(0.8165137614678899), 19: np.float64(0.23529411764705882), 24: np.float64(0.7253886010362695), 26: np.float64(0.9230769230769231), 29: np.float64(0.8252427184466019)}
Micro-average F1 score: 0.7488584474885844
Weighted-average F1 score: 0.733945739213338
F1 score per class: {32: np.float64(0.6310679611650486), 6: np.float64(0.8151658767772512), 19: np.float64(0.3137254901960784), 24: np.float64(0.7253886010362695), 26: np.float64(0.9230769230769231), 29: np.float64(0.8018867924528302)}
Micro-average F1 score: 0.7565543071161048
Weighted-average F1 score: 0.7503533195011607

F1 score per class: {32: np.float64(0.5274725274725275), 6: np.float64(0.8333333333333334), 19: np.float64(0.375), 24: np.float64(0.7311827956989247), 26: np.float64(0.900523560209424), 29: np.float64(0.8090909090909091)}
Micro-average F1 score: 0.7527093596059113
Weighted-average F1 score: 0.7587317654315657
F1 score per class: {32: np.float64(0.6325581395348837), 6: np.float64(0.8165137614678899), 19: np.float64(0.23529411764705882), 24: np.float64(0.7253886010362695), 26: np.float64(0.9230769230769231), 29: np.float64(0.8252427184466019)}
Micro-average F1 score: 0.7488584474885844
Weighted-average F1 score: 0.733945739213338
F1 score per class: {32: np.float64(0.6310679611650486), 6: np.float64(0.8151658767772512), 19: np.float64(0.3137254901960784), 24: np.float64(0.7253886010362695), 26: np.float64(0.9230769230769231), 29: np.float64(0.8018867924528302)}
Micro-average F1 score: 0.7565543071161048
Weighted-average F1 score: 0.7503533195011607

F1 score per class: {32: np.float64(0.3950617283950617), 6: np.float64(0.7906976744186046), 19: np.float64(0.25), 24: np.float64(0.6666666666666666), 26: np.float64(0.8229665071770335), 29: np.float64(0.5913621262458472)}
Micro-average F1 score: 0.6262295081967213
Weighted-average F1 score: 0.6165591591305962
F1 score per class: {32: np.float64(0.43729903536977494), 6: np.float64(0.7639484978540773), 19: np.float64(0.13333333333333333), 24: np.float64(0.6451612903225806), 26: np.float64(0.8333333333333334), 29: np.float64(0.6563706563706564)}
Micro-average F1 score: 0.6047197640117994
Weighted-average F1 score: 0.577552170256513
F1 score per class: {32: np.float64(0.44368600682593856), 6: np.float64(0.7644444444444445), 19: np.float64(0.18181818181818182), 24: np.float64(0.6481481481481481), 26: np.float64(0.8333333333333334), 29: np.float64(0.6367041198501873)}
Micro-average F1 score: 0.6191570881226054
Weighted-average F1 score: 0.5998674300725129

F1 score per class: {32: np.float64(0.3950617283950617), 6: np.float64(0.7906976744186046), 19: np.float64(0.25), 24: np.float64(0.6666666666666666), 26: np.float64(0.8229665071770335), 29: np.float64(0.5913621262458472)}
Micro-average F1 score: 0.6262295081967213
Weighted-average F1 score: 0.6165591591305962
F1 score per class: {32: np.float64(0.43729903536977494), 6: np.float64(0.7639484978540773), 19: np.float64(0.13333333333333333), 24: np.float64(0.6451612903225806), 26: np.float64(0.8333333333333334), 29: np.float64(0.6563706563706564)}
Micro-average F1 score: 0.6047197640117994
Weighted-average F1 score: 0.577552170256513
F1 score per class: {32: np.float64(0.44368600682593856), 6: np.float64(0.7644444444444445), 19: np.float64(0.18181818181818182), 24: np.float64(0.6481481481481481), 26: np.float64(0.8333333333333334), 29: np.float64(0.6367041198501873)}
Micro-average F1 score: 0.6191570881226054
Weighted-average F1 score: 0.5998674300725129
cur_acc_wo_na:  ['0.7527']
his_acc_wo_na:  ['0.7527']
cur_acc des_wo_na:  ['0.7489']
his_acc des_wo_na:  ['0.7489']
cur_acc rrf_wo_na:  ['0.7566']
his_acc rrf_wo_na:  ['0.7566']
cur_acc_w_na:  ['0.6262']
his_acc_w_na:  ['0.6262']
cur_acc des_w_na:  ['0.6047']
his_acc des_w_na:  ['0.6047']
cur_acc rrf_w_na:  ['0.6192']
his_acc rrf_w_na:  ['0.6192']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 83.5436404CurrentTrain: epoch  0, batch     1 | loss: 148.3951243CurrentTrain: epoch  0, batch     2 | loss: 110.8278941CurrentTrain: epoch  0, batch     3 | loss: 112.1156575CurrentTrain: epoch  0, batch     4 | loss: 24.3896984CurrentTrain: epoch  1, batch     0 | loss: 108.8777251CurrentTrain: epoch  1, batch     1 | loss: 87.6287169CurrentTrain: epoch  1, batch     2 | loss: 109.0053988CurrentTrain: epoch  1, batch     3 | loss: 85.5903542CurrentTrain: epoch  1, batch     4 | loss: 26.6524105CurrentTrain: epoch  2, batch     0 | loss: 134.4862150CurrentTrain: epoch  2, batch     1 | loss: 75.0579474CurrentTrain: epoch  2, batch     2 | loss: 86.3554332CurrentTrain: epoch  2, batch     3 | loss: 85.4148180CurrentTrain: epoch  2, batch     4 | loss: 18.9572741CurrentTrain: epoch  3, batch     0 | loss: 84.6831629CurrentTrain: epoch  3, batch     1 | loss: 85.0081217CurrentTrain: epoch  3, batch     2 | loss: 84.4281634CurrentTrain: epoch  3, batch     3 | loss: 103.3854852CurrentTrain: epoch  3, batch     4 | loss: 25.8762715CurrentTrain: epoch  4, batch     0 | loss: 86.3747188CurrentTrain: epoch  4, batch     1 | loss: 102.6632775CurrentTrain: epoch  4, batch     2 | loss: 68.5937306CurrentTrain: epoch  4, batch     3 | loss: 99.3598879CurrentTrain: epoch  4, batch     4 | loss: 13.9896468CurrentTrain: epoch  5, batch     0 | loss: 79.3990142CurrentTrain: epoch  5, batch     1 | loss: 80.5716413CurrentTrain: epoch  5, batch     2 | loss: 79.5737860CurrentTrain: epoch  5, batch     3 | loss: 128.4122244CurrentTrain: epoch  5, batch     4 | loss: 16.8358842CurrentTrain: epoch  6, batch     0 | loss: 78.7950921CurrentTrain: epoch  6, batch     1 | loss: 99.8553656CurrentTrain: epoch  6, batch     2 | loss: 79.9709242CurrentTrain: epoch  6, batch     3 | loss: 95.9287169CurrentTrain: epoch  6, batch     4 | loss: 24.0397118CurrentTrain: epoch  7, batch     0 | loss: 119.5654588CurrentTrain: epoch  7, batch     1 | loss: 91.4368350CurrentTrain: epoch  7, batch     2 | loss: 98.5011503CurrentTrain: epoch  7, batch     3 | loss: 78.7014461CurrentTrain: epoch  7, batch     4 | loss: 15.4623186CurrentTrain: epoch  8, batch     0 | loss: 93.3909924CurrentTrain: epoch  8, batch     1 | loss: 65.4499597CurrentTrain: epoch  8, batch     2 | loss: 80.0737596CurrentTrain: epoch  8, batch     3 | loss: 120.6273669CurrentTrain: epoch  8, batch     4 | loss: 15.0848571CurrentTrain: epoch  9, batch     0 | loss: 79.5068684CurrentTrain: epoch  9, batch     1 | loss: 75.8490664CurrentTrain: epoch  9, batch     2 | loss: 76.2953063CurrentTrain: epoch  9, batch     3 | loss: 65.9873877CurrentTrain: epoch  9, batch     4 | loss: 40.4917189
MemoryTrain:  epoch  0, batch     0 | loss: 2.2207089MemoryTrain:  epoch  1, batch     0 | loss: 1.8805935MemoryTrain:  epoch  2, batch     0 | loss: 1.5055514MemoryTrain:  epoch  3, batch     0 | loss: 1.2947636MemoryTrain:  epoch  4, batch     0 | loss: 0.9700795MemoryTrain:  epoch  5, batch     0 | loss: 0.8160780MemoryTrain:  epoch  6, batch     0 | loss: 0.6072968MemoryTrain:  epoch  7, batch     0 | loss: 0.4894360MemoryTrain:  epoch  8, batch     0 | loss: 0.5485669MemoryTrain:  epoch  9, batch     0 | loss: 0.4072181

F1 score per class: {32: np.float64(0.5882352941176471), 2: np.float64(0.0), 6: np.float64(0.6490066225165563), 39: np.float64(0.5542168674698795), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.32), 24: np.float64(0.0), 28: np.float64(0.37037037037037035)}
Micro-average F1 score: 0.5215311004784688
Weighted-average F1 score: 0.4644544102477943
F1 score per class: {32: np.float64(0.6956521739130435), 2: np.float64(0.0), 6: np.float64(0.5354330708661418), 39: np.float64(0.5748502994011976), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.4), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.42105263157894735)}
Micro-average F1 score: 0.47465437788018433
Weighted-average F1 score: 0.4001918763550563
F1 score per class: {32: np.float64(0.7), 2: np.float64(0.0), 6: np.float64(0.532258064516129), 39: np.float64(0.5882352941176471), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.35714285714285715), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.42424242424242425)}
Micro-average F1 score: 0.4892086330935252
Weighted-average F1 score: 0.42041022279938967

F1 score per class: {32: np.float64(0.5555555555555556), 2: np.float64(0.6255924170616114), 6: np.float64(0.5798816568047337), 39: np.float64(0.3607843137254902), 11: np.float64(0.7926267281105991), 12: np.float64(0.3684210526315789), 19: np.float64(0.7415730337078652), 24: np.float64(0.18604651162790697), 26: np.float64(0.8913043478260869), 28: np.float64(0.7679324894514767), 29: np.float64(0.3225806451612903)}
Micro-average F1 score: 0.6413662239089184
Weighted-average F1 score: 0.6248258307348586
F1 score per class: {32: np.float64(0.6153846153846154), 2: np.float64(0.6639004149377593), 6: np.float64(0.4927536231884058), 39: np.float64(0.375), 11: np.float64(0.7876106194690266), 12: np.float64(0.23880597014925373), 19: np.float64(0.7472527472527473), 24: np.float64(0.2702702702702703), 26: np.float64(0.8947368421052632), 28: np.float64(0.736), 29: np.float64(0.3333333333333333)}
Micro-average F1 score: 0.6321493076459964
Weighted-average F1 score: 0.616365607091952
F1 score per class: {32: np.float64(0.6363636363636364), 2: np.float64(0.6460176991150443), 6: np.float64(0.4852941176470588), 39: np.float64(0.38022813688212925), 11: np.float64(0.7892376681614349), 12: np.float64(0.3181818181818182), 19: np.float64(0.7513812154696132), 24: np.float64(0.21739130434782608), 26: np.float64(0.8888888888888888), 28: np.float64(0.736), 29: np.float64(0.3333333333333333)}
Micro-average F1 score: 0.6337854500616523
Weighted-average F1 score: 0.619501033038817

F1 score per class: {32: np.float64(0.4), 2: np.float64(0.0), 6: np.float64(0.5355191256830601), 39: np.float64(0.46), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.16666666666666666), 26: np.float64(0.0), 28: np.float64(0.24390243902439024)}
Micro-average F1 score: 0.3858407079646018
Weighted-average F1 score: 0.3367813568214333
F1 score per class: {32: np.float64(0.42105263157894735), 2: np.float64(0.0), 6: np.float64(0.4473684210526316), 39: np.float64(0.4873096446700508), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.20408163265306123), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.26229508196721313)}
Micro-average F1 score: 0.3416252072968491
Weighted-average F1 score: 0.2833498869463212
F1 score per class: {32: np.float64(0.5), 2: np.float64(0.0), 6: np.float64(0.43137254901960786), 39: np.float64(0.5), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.18181818181818182), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.24561403508771928)}
Micro-average F1 score: 0.3535528596187175
Weighted-average F1 score: 0.2978940607276564

F1 score per class: {32: np.float64(0.37037037037037035), 2: np.float64(0.4036697247706422), 6: np.float64(0.46445497630331756), 39: np.float64(0.23232323232323232), 11: np.float64(0.7350427350427351), 12: np.float64(0.25), 19: np.float64(0.6804123711340206), 24: np.float64(0.10666666666666667), 26: np.float64(0.8241206030150754), 28: np.float64(0.5531914893617021), 29: np.float64(0.18867924528301888)}
Micro-average F1 score: 0.4826273203236554
Weighted-average F1 score: 0.453756429926641
F1 score per class: {32: np.float64(0.35555555555555557), 2: np.float64(0.41237113402061853), 6: np.float64(0.4), 39: np.float64(0.25), 11: np.float64(0.7325102880658436), 12: np.float64(0.1391304347826087), 19: np.float64(0.6601941747572816), 24: np.float64(0.14925373134328357), 26: np.float64(0.821256038647343), 28: np.float64(0.5575757575757576), 29: np.float64(0.18181818181818182)}
Micro-average F1 score: 0.46812304948729383
Weighted-average F1 score: 0.4395520773379999
F1 score per class: {32: np.float64(0.4375), 2: np.float64(0.40782122905027934), 6: np.float64(0.38372093023255816), 39: np.float64(0.25316455696202533), 11: np.float64(0.7302904564315352), 12: np.float64(0.19444444444444445), 19: np.float64(0.6766169154228856), 24: np.float64(0.12195121951219512), 26: np.float64(0.8195121951219512), 28: np.float64(0.5525525525525525), 29: np.float64(0.175)}
Micro-average F1 score: 0.47351450944265316
Weighted-average F1 score: 0.4458672648739988
cur_acc_wo_na:  ['0.7527', '0.5215']
his_acc_wo_na:  ['0.7527', '0.6414']
cur_acc des_wo_na:  ['0.7489', '0.4747']
his_acc des_wo_na:  ['0.7489', '0.6321']
cur_acc rrf_wo_na:  ['0.7566', '0.4892']
his_acc rrf_wo_na:  ['0.7566', '0.6338']
cur_acc_w_na:  ['0.6262', '0.3858']
his_acc_w_na:  ['0.6262', '0.4826']
cur_acc des_w_na:  ['0.6047', '0.3416']
his_acc des_w_na:  ['0.6047', '0.4681']
cur_acc rrf_w_na:  ['0.6192', '0.3536']
his_acc rrf_w_na:  ['0.6192', '0.4735']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 116.2348215CurrentTrain: epoch  0, batch     1 | loss: 79.3506798CurrentTrain: epoch  0, batch     2 | loss: 117.1676556CurrentTrain: epoch  0, batch     3 | loss: 9.1088472CurrentTrain: epoch  1, batch     0 | loss: 76.6171678CurrentTrain: epoch  1, batch     1 | loss: 72.7452082CurrentTrain: epoch  1, batch     2 | loss: 85.0304503CurrentTrain: epoch  1, batch     3 | loss: 12.3767660CurrentTrain: epoch  2, batch     0 | loss: 70.0343685CurrentTrain: epoch  2, batch     1 | loss: 85.5389319CurrentTrain: epoch  2, batch     2 | loss: 73.5176978CurrentTrain: epoch  2, batch     3 | loss: 12.2795454CurrentTrain: epoch  3, batch     0 | loss: 123.2267025CurrentTrain: epoch  3, batch     1 | loss: 81.3461957CurrentTrain: epoch  3, batch     2 | loss: 63.3798973CurrentTrain: epoch  3, batch     3 | loss: 17.3932186CurrentTrain: epoch  4, batch     0 | loss: 125.8155199CurrentTrain: epoch  4, batch     1 | loss: 64.0998899CurrentTrain: epoch  4, batch     2 | loss: 66.4678166CurrentTrain: epoch  4, batch     3 | loss: 6.3485198CurrentTrain: epoch  5, batch     0 | loss: 63.9997764CurrentTrain: epoch  5, batch     1 | loss: 93.7346147CurrentTrain: epoch  5, batch     2 | loss: 76.8223282CurrentTrain: epoch  5, batch     3 | loss: 9.8727734CurrentTrain: epoch  6, batch     0 | loss: 65.7475452CurrentTrain: epoch  6, batch     1 | loss: 90.8229738CurrentTrain: epoch  6, batch     2 | loss: 74.5307456CurrentTrain: epoch  6, batch     3 | loss: 19.5704880CurrentTrain: epoch  7, batch     0 | loss: 71.3900377CurrentTrain: epoch  7, batch     1 | loss: 91.4953399CurrentTrain: epoch  7, batch     2 | loss: 73.4625492CurrentTrain: epoch  7, batch     3 | loss: 9.9432067CurrentTrain: epoch  8, batch     0 | loss: 95.9361864CurrentTrain: epoch  8, batch     1 | loss: 74.4156383CurrentTrain: epoch  8, batch     2 | loss: 57.0670510CurrentTrain: epoch  8, batch     3 | loss: 8.5415702CurrentTrain: epoch  9, batch     0 | loss: 63.5689141CurrentTrain: epoch  9, batch     1 | loss: 90.6816754CurrentTrain: epoch  9, batch     2 | loss: 60.7522988CurrentTrain: epoch  9, batch     3 | loss: 9.4587858
MemoryTrain:  epoch  0, batch     0 | loss: 1.1251294MemoryTrain:  epoch  1, batch     0 | loss: 0.8881175MemoryTrain:  epoch  2, batch     0 | loss: 0.7571608MemoryTrain:  epoch  3, batch     0 | loss: 0.6375444MemoryTrain:  epoch  4, batch     0 | loss: 0.5138337MemoryTrain:  epoch  5, batch     0 | loss: 0.3872830MemoryTrain:  epoch  6, batch     0 | loss: 0.3961406MemoryTrain:  epoch  7, batch     0 | loss: 0.3119077MemoryTrain:  epoch  8, batch     0 | loss: 0.2706553MemoryTrain:  epoch  9, batch     0 | loss: 0.2091677

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5714285714285714), 7: np.float64(0.847457627118644), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.3), 26: np.float64(0.6666666666666666), 27: np.float64(0.0), 31: np.float64(0.288)}
Micro-average F1 score: 0.35507246376811596
Weighted-average F1 score: 0.2980964537311053
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7246376811594203), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.3333333333333333), 26: np.float64(0.0), 27: np.float64(0.4), 28: np.float64(0.0), 31: np.float64(0.2545454545454545)}
Micro-average F1 score: 0.3028169014084507
Weighted-average F1 score: 0.26304115322018135
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7692307692307693), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.4), 26: np.float64(0.0), 27: np.float64(0.5), 28: np.float64(0.0), 31: np.float64(0.24778761061946902)}
Micro-average F1 score: 0.3176895306859206
Weighted-average F1 score: 0.27576958575384114

F1 score per class: {32: np.float64(0.4444444444444444), 2: np.float64(0.4691358024691358), 6: np.float64(0.05063291139240506), 7: np.float64(0.847457627118644), 40: np.float64(0.5850340136054422), 11: np.float64(0.20689655172413793), 12: np.float64(0.6345381526104418), 39: np.float64(0.24), 9: np.float64(0.6946107784431138), 19: np.float64(0.23076923076923078), 24: np.float64(0.2222222222222222), 26: np.float64(0.8603351955307262), 27: np.float64(0.2857142857142857), 28: np.float64(0.7876106194690266), 29: np.float64(0.38461538461538464), 31: np.float64(0.1469387755102041)}
Micro-average F1 score: 0.5152354570637119
Weighted-average F1 score: 0.48414211262840723
F1 score per class: {32: np.float64(0.5384615384615384), 2: np.float64(0.49710982658959535), 6: np.float64(0.0), 7: np.float64(0.684931506849315), 40: np.float64(0.4603174603174603), 9: np.float64(0.2594594594594595), 12: np.float64(0.5886524822695035), 11: np.float64(0.21621621621621623), 39: np.float64(0.7374301675977654), 19: np.float64(0.25), 24: np.float64(0.19607843137254902), 26: np.float64(0.8666666666666667), 27: np.float64(0.11764705882352941), 28: np.float64(0.7818181818181819), 29: np.float64(0.3125), 31: np.float64(0.15135135135135136)}
Micro-average F1 score: 0.5127371273712737
Weighted-average F1 score: 0.48904558015623645
F1 score per class: {32: np.float64(0.6), 2: np.float64(0.4827586206896552), 6: np.float64(0.0), 7: np.float64(0.746268656716418), 40: np.float64(0.4566929133858268), 11: np.float64(0.2485207100591716), 12: np.float64(0.6125461254612546), 39: np.float64(0.26666666666666666), 9: np.float64(0.7303370786516854), 19: np.float64(0.2857142857142857), 24: np.float64(0.2), 26: np.float64(0.8539325842696629), 27: np.float64(0.16666666666666666), 28: np.float64(0.7818181818181819), 29: np.float64(0.3125), 31: np.float64(0.14)}
Micro-average F1 score: 0.5152017689331122
Weighted-average F1 score: 0.4923529116960753

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.7936507936507936), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 11: np.float64(0.0), 19: np.float64(0.2857142857142857), 26: np.float64(0.0), 27: np.float64(0.6666666666666666), 28: np.float64(0.0), 31: np.float64(0.2535211267605634)}
Micro-average F1 score: 0.31210191082802546
Weighted-average F1 score: 0.26289011848870997
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6666666666666666), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 11: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.3333333333333333), 26: np.float64(0.0), 27: np.float64(0.25), 28: np.float64(0.0), 31: np.float64(0.23529411764705882)}
Micro-average F1 score: 0.26791277258566976
Weighted-average F1 score: 0.23107890499194844
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7246376811594203), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 11: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.38095238095238093), 26: np.float64(0.0), 27: np.float64(0.3333333333333333), 28: np.float64(0.0), 31: np.float64(0.22764227642276422)}
Micro-average F1 score: 0.28205128205128205
Weighted-average F1 score: 0.24273079734373482

F1 score per class: {32: np.float64(0.3076923076923077), 2: np.float64(0.3140495867768595), 6: np.float64(0.03305785123966942), 7: np.float64(0.7936507936507936), 40: np.float64(0.46994535519125685), 11: np.float64(0.17543859649122806), 12: np.float64(0.6007604562737643), 39: np.float64(0.20689655172413793), 9: np.float64(0.6408839779005525), 19: np.float64(0.1935483870967742), 24: np.float64(0.10309278350515463), 26: np.float64(0.8020833333333334), 27: np.float64(0.25), 28: np.float64(0.5933333333333334), 29: np.float64(0.20408163265306123), 31: np.float64(0.12)}
Micro-average F1 score: 0.4122340425531915
Weighted-average F1 score: 0.3799560765718405
F1 score per class: {32: np.float64(0.358974358974359), 2: np.float64(0.31851851851851853), 6: np.float64(0.0), 7: np.float64(0.6097560975609756), 40: np.float64(0.3790849673202614), 11: np.float64(0.2033898305084746), 12: np.float64(0.5496688741721855), 39: np.float64(0.16), 9: np.float64(0.6804123711340206), 19: np.float64(0.21428571428571427), 24: np.float64(0.0970873786407767), 26: np.float64(0.8041237113402062), 27: np.float64(0.08695652173913043), 28: np.float64(0.6164874551971327), 29: np.float64(0.15873015873015872), 31: np.float64(0.12612612612612611)}
Micro-average F1 score: 0.4067067927773001
Weighted-average F1 score: 0.37890230092494304
F1 score per class: {32: np.float64(0.42857142857142855), 2: np.float64(0.3146067415730337), 6: np.float64(0.0), 7: np.float64(0.684931506849315), 40: np.float64(0.3717948717948718), 11: np.float64(0.19811320754716982), 12: np.float64(0.5724137931034483), 39: np.float64(0.20512820512820512), 9: np.float64(0.6735751295336787), 19: np.float64(0.24242424242424243), 24: np.float64(0.0970873786407767), 26: np.float64(0.7958115183246073), 27: np.float64(0.125), 28: np.float64(0.6142857142857143), 29: np.float64(0.16129032258064516), 31: np.float64(0.11666666666666667)}
Micro-average F1 score: 0.4105726872246696
Weighted-average F1 score: 0.38243422063964033
cur_acc_wo_na:  ['0.7527', '0.5215', '0.3551']
his_acc_wo_na:  ['0.7527', '0.6414', '0.5152']
cur_acc des_wo_na:  ['0.7489', '0.4747', '0.3028']
his_acc des_wo_na:  ['0.7489', '0.6321', '0.5127']
cur_acc rrf_wo_na:  ['0.7566', '0.4892', '0.3177']
his_acc rrf_wo_na:  ['0.7566', '0.6338', '0.5152']
cur_acc_w_na:  ['0.6262', '0.3858', '0.3121']
his_acc_w_na:  ['0.6262', '0.4826', '0.4122']
cur_acc des_w_na:  ['0.6047', '0.3416', '0.2679']
his_acc des_w_na:  ['0.6047', '0.4681', '0.4067']
cur_acc rrf_w_na:  ['0.6192', '0.3536', '0.2821']
his_acc rrf_w_na:  ['0.6192', '0.4735', '0.4106']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 89.4764517CurrentTrain: epoch  0, batch     1 | loss: 93.7350764CurrentTrain: epoch  0, batch     2 | loss: 118.5766344CurrentTrain: epoch  0, batch     3 | loss: 130.8512731CurrentTrain: epoch  1, batch     0 | loss: 75.6158136CurrentTrain: epoch  1, batch     1 | loss: 107.7121417CurrentTrain: epoch  1, batch     2 | loss: 85.4453493CurrentTrain: epoch  1, batch     3 | loss: 75.8319632CurrentTrain: epoch  2, batch     0 | loss: 86.4403139CurrentTrain: epoch  2, batch     1 | loss: 72.6202983CurrentTrain: epoch  2, batch     2 | loss: 72.2006773CurrentTrain: epoch  2, batch     3 | loss: 88.9399872CurrentTrain: epoch  3, batch     0 | loss: 102.6322392CurrentTrain: epoch  3, batch     1 | loss: 82.5691659CurrentTrain: epoch  3, batch     2 | loss: 83.5701303CurrentTrain: epoch  3, batch     3 | loss: 57.2681890CurrentTrain: epoch  4, batch     0 | loss: 81.0635223CurrentTrain: epoch  4, batch     1 | loss: 97.7799682CurrentTrain: epoch  4, batch     2 | loss: 125.9106060CurrentTrain: epoch  4, batch     3 | loss: 51.1954474CurrentTrain: epoch  5, batch     0 | loss: 98.6240441CurrentTrain: epoch  5, batch     1 | loss: 76.6262166CurrentTrain: epoch  5, batch     2 | loss: 98.7626078CurrentTrain: epoch  5, batch     3 | loss: 44.1168282CurrentTrain: epoch  6, batch     0 | loss: 126.7219254CurrentTrain: epoch  6, batch     1 | loss: 88.2910430CurrentTrain: epoch  6, batch     2 | loss: 79.8021908CurrentTrain: epoch  6, batch     3 | loss: 63.3817177CurrentTrain: epoch  7, batch     0 | loss: 78.6815650CurrentTrain: epoch  7, batch     1 | loss: 62.7467353CurrentTrain: epoch  7, batch     2 | loss: 79.5706088CurrentTrain: epoch  7, batch     3 | loss: 52.5437099CurrentTrain: epoch  8, batch     0 | loss: 95.0704755CurrentTrain: epoch  8, batch     1 | loss: 65.9620420CurrentTrain: epoch  8, batch     2 | loss: 75.3725851CurrentTrain: epoch  8, batch     3 | loss: 64.4928992CurrentTrain: epoch  9, batch     0 | loss: 77.5472737CurrentTrain: epoch  9, batch     1 | loss: 93.1927637CurrentTrain: epoch  9, batch     2 | loss: 63.5828459CurrentTrain: epoch  9, batch     3 | loss: 79.7465550
MemoryTrain:  epoch  0, batch     0 | loss: 0.9633484MemoryTrain:  epoch  1, batch     0 | loss: 0.8280976MemoryTrain:  epoch  2, batch     0 | loss: 0.6790439MemoryTrain:  epoch  3, batch     0 | loss: 0.5637931MemoryTrain:  epoch  4, batch     0 | loss: 0.4550190MemoryTrain:  epoch  5, batch     0 | loss: 0.3779760MemoryTrain:  epoch  6, batch     0 | loss: 0.3174280MemoryTrain:  epoch  7, batch     0 | loss: 0.2865329MemoryTrain:  epoch  8, batch     0 | loss: 0.2535100MemoryTrain:  epoch  9, batch     0 | loss: 0.2248084

F1 score per class: {32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.8333333333333334), 6: np.float64(0.0), 11: np.float64(0.5974025974025974), 7: np.float64(0.0), 12: np.float64(0.0), 40: np.float64(0.0), 15: np.float64(0.7032967032967034), 19: np.float64(0.46766169154228854), 25: np.float64(0.5652173913043478), 27: np.float64(0.0), 28: np.float64(0.0)}
Micro-average F1 score: 0.5091649694501018
Weighted-average F1 score: 0.45119934925703686
F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.6956521739130435), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.7659574468085106), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.7706422018348624), 37: np.float64(0.5314685314685315), 38: np.float64(0.6122448979591837), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5387596899224806
Weighted-average F1 score: 0.4535872054040635
F1 score per class: {6: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.64), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.7472527472527473), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.7706422018348624), 37: np.float64(0.49101796407185627), 38: np.float64(0.5769230769230769), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5426356589147286
Weighted-average F1 score: 0.47563549476546546

F1 score per class: {2: np.float64(0.5454545454545454), 6: np.float64(0.4712041884816754), 7: np.float64(0.05194805194805195), 9: np.float64(0.8620689655172413), 11: np.float64(0.38181818181818183), 12: np.float64(0.1791044776119403), 15: np.float64(0.37037037037037035), 19: np.float64(0.6125461254612546), 24: np.float64(0.1), 25: np.float64(0.5974025974025974), 26: np.float64(0.7058823529411765), 27: np.float64(0.34782608695652173), 28: np.float64(0.2857142857142857), 29: np.float64(0.8817204301075269), 31: np.float64(0.2222222222222222), 32: np.float64(0.7215686274509804), 35: np.float64(0.48120300751879697), 37: np.float64(0.18613861386138614), 38: np.float64(0.40625), 39: np.float64(0.08), 40: np.float64(0.14678899082568808)}
Micro-average F1 score: 0.43904263275991023
Weighted-average F1 score: 0.40296417836112464
F1 score per class: {2: np.float64(0.45714285714285713), 6: np.float64(0.4205607476635514), 7: np.float64(0.047058823529411764), 9: np.float64(0.5882352941176471), 11: np.float64(0.5217391304347826), 12: np.float64(0.22110552763819097), 15: np.float64(0.32), 19: np.float64(0.54), 24: np.float64(0.22727272727272727), 25: np.float64(0.7659574468085106), 26: np.float64(0.7204301075268817), 27: np.float64(0.32558139534883723), 28: np.float64(0.22950819672131148), 29: np.float64(0.8704663212435233), 31: np.float64(0.1111111111111111), 32: np.float64(0.7250996015936255), 35: np.float64(0.4375), 37: np.float64(0.2459546925566343), 38: np.float64(0.47619047619047616), 39: np.float64(0.25), 40: np.float64(0.1564245810055866)}
Micro-average F1 score: 0.4597864768683274
Weighted-average F1 score: 0.43158447088770174
F1 score per class: {2: np.float64(0.5833333333333334), 6: np.float64(0.42105263157894735), 7: np.float64(0.05), 9: np.float64(0.7246376811594203), 11: np.float64(0.5135135135135135), 12: np.float64(0.20125786163522014), 15: np.float64(0.24615384615384617), 19: np.float64(0.5567010309278351), 24: np.float64(0.16666666666666666), 25: np.float64(0.7472527472527473), 26: np.float64(0.7282608695652174), 27: np.float64(0.3137254901960784), 28: np.float64(0.21875), 29: np.float64(0.8677248677248677), 31: np.float64(0.125), 32: np.float64(0.7250996015936255), 35: np.float64(0.43523316062176165), 37: np.float64(0.22589531680440772), 38: np.float64(0.43478260869565216), 39: np.float64(0.1951219512195122), 40: np.float64(0.13333333333333333)}
Micro-average F1 score: 0.45073450376209245
Weighted-average F1 score: 0.41882721959728103

F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.5714285714285714), 19: np.float64(0.0), 25: np.float64(0.5411764705882353), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.5517241379310345), 37: np.float64(0.3333333333333333), 38: np.float64(0.41935483870967744), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3531073446327684
Weighted-average F1 score: 0.30821434180822943
F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.43243243243243246), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.6486486486486487), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6086956521739131), 37: np.float64(0.4318181818181818), 38: np.float64(0.5357142857142857), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3888111888111888
Weighted-average F1 score: 0.3268353633774037
F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.4), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.6601941747572816), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.60431654676259), 37: np.float64(0.3813953488372093), 38: np.float64(0.5084745762711864), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.39436619718309857
Weighted-average F1 score: 0.341313850612777

F1 score per class: {2: np.float64(0.3157894736842105), 6: np.float64(0.30201342281879195), 7: np.float64(0.02962962962962963), 9: np.float64(0.7936507936507936), 11: np.float64(0.3652173913043478), 12: np.float64(0.14545454545454545), 15: np.float64(0.20833333333333334), 19: np.float64(0.5665529010238908), 24: np.float64(0.09090909090909091), 25: np.float64(0.5411764705882353), 26: np.float64(0.6382978723404256), 27: np.float64(0.21333333333333335), 28: np.float64(0.11864406779661017), 29: np.float64(0.7772511848341233), 31: np.float64(0.16666666666666666), 32: np.float64(0.5364431486880467), 35: np.float64(0.3076923076923077), 37: np.float64(0.09812108559498957), 38: np.float64(0.2524271844660194), 39: np.float64(0.05128205128205128), 40: np.float64(0.0975609756097561)}
Micro-average F1 score: 0.30156691497559723
Weighted-average F1 score: 0.26389231478395486
F1 score per class: {2: np.float64(0.26666666666666666), 6: np.float64(0.2694610778443114), 7: np.float64(0.02631578947368421), 9: np.float64(0.47619047619047616), 11: np.float64(0.42), 12: np.float64(0.1522491349480969), 15: np.float64(0.17204301075268819), 19: np.float64(0.48214285714285715), 24: np.float64(0.14705882352941177), 25: np.float64(0.6428571428571429), 26: np.float64(0.6442307692307693), 27: np.float64(0.22950819672131148), 28: np.float64(0.10218978102189781), 29: np.float64(0.7636363636363637), 31: np.float64(0.06896551724137931), 32: np.float64(0.5400593471810089), 35: np.float64(0.28), 37: np.float64(0.15353535353535352), 38: np.float64(0.3409090909090909), 39: np.float64(0.13333333333333333), 40: np.float64(0.11764705882352941)}
Micro-average F1 score: 0.3269230769230769
Weighted-average F1 score: 0.30010695001704596
F1 score per class: {2: np.float64(0.35), 6: np.float64(0.277602523659306), 7: np.float64(0.0273972602739726), 9: np.float64(0.6666666666666666), 11: np.float64(0.4245810055865922), 12: np.float64(0.15023474178403756), 15: np.float64(0.12903225806451613), 19: np.float64(0.5015479876160991), 24: np.float64(0.13333333333333333), 25: np.float64(0.6538461538461539), 26: np.float64(0.6568627450980392), 27: np.float64(0.21621621621621623), 28: np.float64(0.09655172413793103), 29: np.float64(0.7663551401869159), 31: np.float64(0.09090909090909091), 32: np.float64(0.5306122448979592), 35: np.float64(0.27722772277227725), 37: np.float64(0.13509060955518945), 38: np.float64(0.3), 39: np.float64(0.11428571428571428), 40: np.float64(0.0958904109589041)}
Micro-average F1 score: 0.3205095541401274
Weighted-average F1 score: 0.28941004169967294
cur_acc_wo_na:  ['0.7527', '0.5215', '0.3551', '0.5092']
his_acc_wo_na:  ['0.7527', '0.6414', '0.5152', '0.4390']
cur_acc des_wo_na:  ['0.7489', '0.4747', '0.3028', '0.5388']
his_acc des_wo_na:  ['0.7489', '0.6321', '0.5127', '0.4598']
cur_acc rrf_wo_na:  ['0.7566', '0.4892', '0.3177', '0.5426']
his_acc rrf_wo_na:  ['0.7566', '0.6338', '0.5152', '0.4507']
cur_acc_w_na:  ['0.6262', '0.3858', '0.3121', '0.3531']
his_acc_w_na:  ['0.6262', '0.4826', '0.4122', '0.3016']
cur_acc des_w_na:  ['0.6047', '0.3416', '0.2679', '0.3888']
his_acc des_w_na:  ['0.6047', '0.4681', '0.4067', '0.3269']
cur_acc rrf_w_na:  ['0.6192', '0.3536', '0.2821', '0.3944']
his_acc rrf_w_na:  ['0.6192', '0.4735', '0.4106', '0.3205']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 141.3133020CurrentTrain: epoch  0, batch     1 | loss: 104.7404373CurrentTrain: epoch  0, batch     2 | loss: 103.7881352CurrentTrain: epoch  0, batch     3 | loss: 114.7011086CurrentTrain: epoch  0, batch     4 | loss: 78.0730571CurrentTrain: epoch  1, batch     0 | loss: 91.5656509CurrentTrain: epoch  1, batch     1 | loss: 110.6450935CurrentTrain: epoch  1, batch     2 | loss: 77.4407463CurrentTrain: epoch  1, batch     3 | loss: 107.2232651CurrentTrain: epoch  1, batch     4 | loss: 105.2934999CurrentTrain: epoch  2, batch     0 | loss: 87.7907036CurrentTrain: epoch  2, batch     1 | loss: 88.9960965CurrentTrain: epoch  2, batch     2 | loss: 75.5770883CurrentTrain: epoch  2, batch     3 | loss: 86.0356215CurrentTrain: epoch  2, batch     4 | loss: 101.5528001CurrentTrain: epoch  3, batch     0 | loss: 68.8270788CurrentTrain: epoch  3, batch     1 | loss: 103.6777537CurrentTrain: epoch  3, batch     2 | loss: 88.1879835CurrentTrain: epoch  3, batch     3 | loss: 105.2442307CurrentTrain: epoch  3, batch     4 | loss: 149.0538377CurrentTrain: epoch  4, batch     0 | loss: 81.5065820CurrentTrain: epoch  4, batch     1 | loss: 104.0773895CurrentTrain: epoch  4, batch     2 | loss: 83.5052485CurrentTrain: epoch  4, batch     3 | loss: 82.9928648CurrentTrain: epoch  4, batch     4 | loss: 70.8223923CurrentTrain: epoch  5, batch     0 | loss: 128.7523360CurrentTrain: epoch  5, batch     1 | loss: 67.0872666CurrentTrain: epoch  5, batch     2 | loss: 99.1822689CurrentTrain: epoch  5, batch     3 | loss: 97.9189872CurrentTrain: epoch  5, batch     4 | loss: 71.0497229CurrentTrain: epoch  6, batch     0 | loss: 98.2856293CurrentTrain: epoch  6, batch     1 | loss: 70.8388098CurrentTrain: epoch  6, batch     2 | loss: 98.6874585CurrentTrain: epoch  6, batch     3 | loss: 99.0571497CurrentTrain: epoch  6, batch     4 | loss: 36.5407668CurrentTrain: epoch  7, batch     0 | loss: 95.4094741CurrentTrain: epoch  7, batch     1 | loss: 80.9735971CurrentTrain: epoch  7, batch     2 | loss: 79.1366649CurrentTrain: epoch  7, batch     3 | loss: 96.7576658CurrentTrain: epoch  7, batch     4 | loss: 53.4464321CurrentTrain: epoch  8, batch     0 | loss: 96.3116642CurrentTrain: epoch  8, batch     1 | loss: 67.4504483CurrentTrain: epoch  8, batch     2 | loss: 96.1565045CurrentTrain: epoch  8, batch     3 | loss: 74.9529327CurrentTrain: epoch  8, batch     4 | loss: 52.5600625CurrentTrain: epoch  9, batch     0 | loss: 76.4179643CurrentTrain: epoch  9, batch     1 | loss: 62.8502346CurrentTrain: epoch  9, batch     2 | loss: 80.3079858CurrentTrain: epoch  9, batch     3 | loss: 120.7187332CurrentTrain: epoch  9, batch     4 | loss: 71.3895024
MemoryTrain:  epoch  0, batch     0 | loss: 1.3510470MemoryTrain:  epoch  1, batch     0 | loss: 1.1642604MemoryTrain:  epoch  2, batch     0 | loss: 0.9642484MemoryTrain:  epoch  3, batch     0 | loss: 0.8396116MemoryTrain:  epoch  4, batch     0 | loss: 0.6739244MemoryTrain:  epoch  5, batch     0 | loss: 0.6135970MemoryTrain:  epoch  6, batch     0 | loss: 0.5451099MemoryTrain:  epoch  7, batch     0 | loss: 0.4317134MemoryTrain:  epoch  8, batch     0 | loss: 0.3260414MemoryTrain:  epoch  9, batch     0 | loss: 0.3000975

F1 score per class: {1: np.float64(0.18633540372670807), 3: np.float64(0.7189542483660131), 6: np.float64(0.0), 7: np.float64(0.0), 14: np.float64(0.12658227848101267), 19: np.float64(0.0), 22: np.float64(0.5448028673835126), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6709677419354839), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4
Weighted-average F1 score: 0.3565705060407532
F1 score per class: {1: np.float64(0.2222222222222222), 3: np.float64(0.6292134831460674), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.06060606060606061), 15: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.5367647058823529), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6451612903225806), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3415046491969569
Weighted-average F1 score: 0.29727238010796625
F1 score per class: {1: np.float64(0.2057142857142857), 3: np.float64(0.655367231638418), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 14: np.float64(0.061224489795918366), 19: np.float64(0.0), 22: np.float64(0.5352112676056338), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6451612903225806), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.35528596187175043
Weighted-average F1 score: 0.31369610645939444

F1 score per class: {1: np.float64(0.15228426395939088), 2: np.float64(0.4444444444444444), 3: np.float64(0.5238095238095238), 6: np.float64(0.38461538461538464), 7: np.float64(0.07407407407407407), 9: np.float64(0.7692307692307693), 11: np.float64(0.18556701030927836), 12: np.float64(0.017857142857142856), 14: np.float64(0.11363636363636363), 15: np.float64(0.7272727272727273), 19: np.float64(0.5527272727272727), 22: np.float64(0.44970414201183434), 24: np.float64(0.0), 25: np.float64(0.6153846153846154), 26: np.float64(0.7415730337078652), 27: np.float64(0.0), 28: np.float64(0.208955223880597), 29: np.float64(0.8449197860962567), 31: np.float64(0.25), 32: np.float64(0.5726141078838174), 34: np.float64(0.22559652928416485), 35: np.float64(0.17307692307692307), 37: np.float64(0.25120772946859904), 38: np.float64(0.3508771929824561), 39: np.float64(0.2), 40: np.float64(0.19895287958115182)}
Micro-average F1 score: 0.3822525597269625
Weighted-average F1 score: 0.3707191798142102
F1 score per class: {1: np.float64(0.16666666666666666), 2: np.float64(0.5), 3: np.float64(0.4117647058823529), 6: np.float64(0.4372093023255814), 7: np.float64(0.05970149253731343), 9: np.float64(0.5555555555555556), 11: np.float64(0.18), 12: np.float64(0.2391304347826087), 14: np.float64(0.0425531914893617), 15: np.float64(0.4444444444444444), 19: np.float64(0.5242718446601942), 22: np.float64(0.453416149068323), 24: np.float64(0.07142857142857142), 25: np.float64(0.7311827956989247), 26: np.float64(0.7362637362637363), 27: np.float64(0.0), 28: np.float64(0.14432989690721648), 29: np.float64(0.8601036269430051), 31: np.float64(0.06451612903225806), 32: np.float64(0.5714285714285714), 34: np.float64(0.2222222222222222), 35: np.float64(0.2111111111111111), 37: np.float64(0.16149068322981366), 38: np.float64(0.41975308641975306), 39: np.float64(0.14285714285714285), 40: np.float64(0.20618556701030927)}
Micro-average F1 score: 0.3709435846230654
Weighted-average F1 score: 0.3521681248788523
F1 score per class: {1: np.float64(0.1565217391304348), 2: np.float64(0.6666666666666666), 3: np.float64(0.43283582089552236), 6: np.float64(0.4639175257731959), 7: np.float64(0.05714285714285714), 9: np.float64(0.7142857142857143), 11: np.float64(0.18), 12: np.float64(0.12030075187969924), 14: np.float64(0.04580152671755725), 15: np.float64(0.5454545454545454), 19: np.float64(0.547945205479452), 22: np.float64(0.4355300859598854), 24: np.float64(0.0), 25: np.float64(0.7209302325581395), 26: np.float64(0.7362637362637363), 27: np.float64(0.0), 28: np.float64(0.16470588235294117), 29: np.float64(0.8541666666666666), 31: np.float64(0.08333333333333333), 32: np.float64(0.5661764705882353), 34: np.float64(0.21645021645021645), 35: np.float64(0.16766467065868262), 37: np.float64(0.1452513966480447), 38: np.float64(0.3888888888888889), 39: np.float64(0.2), 40: np.float64(0.20192307692307693)}
Micro-average F1 score: 0.36930208601596703
Weighted-average F1 score: 0.3515417970619595

F1 score per class: {1: np.float64(0.1079136690647482), 2: np.float64(0.0), 3: np.float64(0.6077348066298343), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.11904761904761904), 19: np.float64(0.0), 22: np.float64(0.41530054644808745), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.47706422018348627), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2771331058020478
Weighted-average F1 score: 0.24622816870022443
F1 score per class: {1: np.float64(0.125), 2: np.float64(0.0), 3: np.float64(0.47863247863247865), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.05), 15: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.4147727272727273), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.44642857142857145), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.22658440830061694
Weighted-average F1 score: 0.20147311985853655
F1 score per class: {1: np.float64(0.1157556270096463), 2: np.float64(0.0), 3: np.float64(0.4978540772532189), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.05309734513274336), 15: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.4053333333333333), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.45454545454545453), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2403282532239156
Weighted-average F1 score: 0.2166231469884433

F1 score per class: {1: np.float64(0.08547008547008547), 2: np.float64(0.27586206896551724), 3: np.float64(0.38869257950530034), 6: np.float64(0.2631578947368421), 7: np.float64(0.039473684210526314), 9: np.float64(0.6944444444444444), 11: np.float64(0.1836734693877551), 12: np.float64(0.01652892561983471), 14: np.float64(0.10204081632653061), 15: np.float64(0.5), 19: np.float64(0.5083612040133779), 22: np.float64(0.32), 24: np.float64(0.0), 25: np.float64(0.5581395348837209), 26: np.float64(0.676923076923077), 27: np.float64(0.0), 28: np.float64(0.11864406779661017), 29: np.float64(0.7314814814814815), 31: np.float64(0.16666666666666666), 32: np.float64(0.4437299035369775), 34: np.float64(0.13559322033898305), 35: np.float64(0.1276595744680851), 37: np.float64(0.16149068322981366), 38: np.float64(0.26666666666666666), 39: np.float64(0.13043478260869565), 40: np.float64(0.1450381679389313)}
Micro-average F1 score: 0.27705627705627706
Weighted-average F1 score: 0.2578136575318451
F1 score per class: {1: np.float64(0.09259259259259259), 2: np.float64(0.30434782608695654), 3: np.float64(0.2828282828282828), 6: np.float64(0.26628895184135976), 7: np.float64(0.036036036036036036), 9: np.float64(0.43859649122807015), 11: np.float64(0.16981132075471697), 12: np.float64(0.16730038022813687), 14: np.float64(0.03278688524590164), 15: np.float64(0.2608695652173913), 19: np.float64(0.47230320699708456), 22: np.float64(0.32662192393736017), 24: np.float64(0.06060606060606061), 25: np.float64(0.6071428571428571), 26: np.float64(0.6600985221674877), 27: np.float64(0.0), 28: np.float64(0.07777777777777778), 29: np.float64(0.7345132743362832), 31: np.float64(0.03389830508474576), 32: np.float64(0.4250681198910082), 34: np.float64(0.1364256480218281), 35: np.float64(0.1314878892733564), 37: np.float64(0.12264150943396226), 38: np.float64(0.2809917355371901), 39: np.float64(0.07407407407407407), 40: np.float64(0.16260162601626016)}
Micro-average F1 score: 0.26088483146067415
Weighted-average F1 score: 0.2429028166443418
F1 score per class: {1: np.float64(0.0861244019138756), 2: np.float64(0.3783783783783784), 3: np.float64(0.29743589743589743), 6: np.float64(0.2903225806451613), 7: np.float64(0.03333333333333333), 9: np.float64(0.6329113924050633), 11: np.float64(0.17142857142857143), 12: np.float64(0.10191082802547771), 14: np.float64(0.036585365853658534), 15: np.float64(0.35294117647058826), 19: np.float64(0.49230769230769234), 22: np.float64(0.30831643002028397), 24: np.float64(0.0), 25: np.float64(0.62), 26: np.float64(0.6666666666666666), 27: np.float64(0.0), 28: np.float64(0.0880503144654088), 29: np.float64(0.7321428571428571), 31: np.float64(0.06060606060606061), 32: np.float64(0.4230769230769231), 34: np.float64(0.13227513227513227), 35: np.float64(0.10606060606060606), 37: np.float64(0.10441767068273092), 38: np.float64(0.26666666666666666), 39: np.float64(0.10714285714285714), 40: np.float64(0.15730337078651685)}
Micro-average F1 score: 0.26258926936458526
Weighted-average F1 score: 0.2439146591213273
cur_acc_wo_na:  ['0.7527', '0.5215', '0.3551', '0.5092', '0.4000']
his_acc_wo_na:  ['0.7527', '0.6414', '0.5152', '0.4390', '0.3823']
cur_acc des_wo_na:  ['0.7489', '0.4747', '0.3028', '0.5388', '0.3415']
his_acc des_wo_na:  ['0.7489', '0.6321', '0.5127', '0.4598', '0.3709']
cur_acc rrf_wo_na:  ['0.7566', '0.4892', '0.3177', '0.5426', '0.3553']
his_acc rrf_wo_na:  ['0.7566', '0.6338', '0.5152', '0.4507', '0.3693']
cur_acc_w_na:  ['0.6262', '0.3858', '0.3121', '0.3531', '0.2771']
his_acc_w_na:  ['0.6262', '0.4826', '0.4122', '0.3016', '0.2771']
cur_acc des_w_na:  ['0.6047', '0.3416', '0.2679', '0.3888', '0.2266']
his_acc des_w_na:  ['0.6047', '0.4681', '0.4067', '0.3269', '0.2609']
cur_acc rrf_w_na:  ['0.6192', '0.3536', '0.2821', '0.3944', '0.2403']
his_acc rrf_w_na:  ['0.6192', '0.4735', '0.4106', '0.3205', '0.2626']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 88.4697140CurrentTrain: epoch  0, batch     1 | loss: 87.9760624CurrentTrain: epoch  0, batch     2 | loss: 150.3084161CurrentTrain: epoch  0, batch     3 | loss: 84.7163915CurrentTrain: epoch  1, batch     0 | loss: 134.1179545CurrentTrain: epoch  1, batch     1 | loss: 78.4462191CurrentTrain: epoch  1, batch     2 | loss: 88.9377926CurrentTrain: epoch  1, batch     3 | loss: 115.3816387CurrentTrain: epoch  2, batch     0 | loss: 108.2294129CurrentTrain: epoch  2, batch     1 | loss: 103.7740955CurrentTrain: epoch  2, batch     2 | loss: 73.6224656CurrentTrain: epoch  2, batch     3 | loss: 71.2319929CurrentTrain: epoch  3, batch     0 | loss: 85.5568401CurrentTrain: epoch  3, batch     1 | loss: 178.2860765CurrentTrain: epoch  3, batch     2 | loss: 70.1741813CurrentTrain: epoch  3, batch     3 | loss: 67.8759901CurrentTrain: epoch  4, batch     0 | loss: 100.9205326CurrentTrain: epoch  4, batch     1 | loss: 79.7318899CurrentTrain: epoch  4, batch     2 | loss: 83.6215196CurrentTrain: epoch  4, batch     3 | loss: 70.3044357CurrentTrain: epoch  5, batch     0 | loss: 78.5356093CurrentTrain: epoch  5, batch     1 | loss: 102.9668389CurrentTrain: epoch  5, batch     2 | loss: 82.5246086CurrentTrain: epoch  5, batch     3 | loss: 63.7076752CurrentTrain: epoch  6, batch     0 | loss: 124.3933814CurrentTrain: epoch  6, batch     1 | loss: 76.4202704CurrentTrain: epoch  6, batch     2 | loss: 81.6643179CurrentTrain: epoch  6, batch     3 | loss: 66.3643073CurrentTrain: epoch  7, batch     0 | loss: 68.9782060CurrentTrain: epoch  7, batch     1 | loss: 81.5620596CurrentTrain: epoch  7, batch     2 | loss: 80.1539497CurrentTrain: epoch  7, batch     3 | loss: 63.3550871CurrentTrain: epoch  8, batch     0 | loss: 66.4362916CurrentTrain: epoch  8, batch     1 | loss: 66.1131656CurrentTrain: epoch  8, batch     2 | loss: 78.0813497CurrentTrain: epoch  8, batch     3 | loss: 136.9032410CurrentTrain: epoch  9, batch     0 | loss: 64.4420164CurrentTrain: epoch  9, batch     1 | loss: 67.1636709CurrentTrain: epoch  9, batch     2 | loss: 79.4731739CurrentTrain: epoch  9, batch     3 | loss: 66.2049094
MemoryTrain:  epoch  0, batch     0 | loss: 1.1262271MemoryTrain:  epoch  1, batch     0 | loss: 0.9927539MemoryTrain:  epoch  2, batch     0 | loss: 0.8175349MemoryTrain:  epoch  3, batch     0 | loss: 0.6786928MemoryTrain:  epoch  4, batch     0 | loss: 0.6385647MemoryTrain:  epoch  5, batch     0 | loss: 0.5099788MemoryTrain:  epoch  6, batch     0 | loss: 0.4558319MemoryTrain:  epoch  7, batch     0 | loss: 0.4035497MemoryTrain:  epoch  8, batch     0 | loss: 0.3760730MemoryTrain:  epoch  9, batch     0 | loss: 0.3441077

F1 score per class: {0: np.float64(0.8089887640449438), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7951807228915663), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.3333333333333333), 19: np.float64(0.0), 21: np.float64(0.38095238095238093), 22: np.float64(0.0), 23: np.float64(0.8045977011494253), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5384615384615384
Weighted-average F1 score: 0.4087639908311871
F1 score per class: {0: np.float64(0.7291666666666666), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8222222222222222), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.23529411764705882), 14: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.47761194029850745), 22: np.float64(0.0), 23: np.float64(0.8), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4851190476190476
Weighted-average F1 score: 0.3610977220655356
F1 score per class: {0: np.float64(0.7422680412371134), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8390804597701149), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.2857142857142857), 14: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.46153846153846156), 22: np.float64(0.0), 23: np.float64(0.8), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5078369905956113
Weighted-average F1 score: 0.3810807960788315

F1 score per class: {0: np.float64(0.3850267379679144), 1: np.float64(0.17094017094017094), 2: np.float64(0.43478260869565216), 3: np.float64(0.5555555555555556), 4: np.float64(0.7951807228915663), 6: np.float64(0.39344262295081966), 7: np.float64(0.07547169811320754), 9: np.float64(0.7142857142857143), 11: np.float64(0.16666666666666666), 12: np.float64(0.0), 13: np.float64(0.04597701149425287), 14: np.float64(0.07792207792207792), 15: np.float64(0.6666666666666666), 19: np.float64(0.5448028673835126), 21: np.float64(0.14414414414414414), 22: np.float64(0.5142857142857142), 23: np.float64(0.6862745098039216), 24: np.float64(0.0), 25: np.float64(0.47058823529411764), 26: np.float64(0.703030303030303), 27: np.float64(0.0), 28: np.float64(0.21875), 29: np.float64(0.845360824742268), 31: np.float64(0.11764705882352941), 32: np.float64(0.5300353356890459), 34: np.float64(0.2111801242236025), 35: np.float64(0.12631578947368421), 37: np.float64(0.3484848484848485), 38: np.float64(0.32558139534883723), 39: np.float64(0.08333333333333333), 40: np.float64(0.22485207100591717)}
Micro-average F1 score: 0.39548577036310106
Weighted-average F1 score: 0.3799629371829073
F1 score per class: {0: np.float64(0.2966101694915254), 1: np.float64(0.17424242424242425), 2: np.float64(0.2553191489361702), 3: np.float64(0.3890784982935154), 4: np.float64(0.8131868131868132), 6: np.float64(0.4031620553359684), 7: np.float64(0.06060606060606061), 9: np.float64(0.42735042735042733), 11: np.float64(0.02247191011235955), 12: np.float64(0.18994413407821228), 13: np.float64(0.04040404040404041), 14: np.float64(0.036585365853658534), 15: np.float64(0.631578947368421), 19: np.float64(0.4953560371517028), 21: np.float64(0.15609756097560976), 22: np.float64(0.5145228215767634), 23: np.float64(0.7128712871287128), 24: np.float64(0.0), 25: np.float64(0.7692307692307693), 26: np.float64(0.7142857142857143), 27: np.float64(0.0), 28: np.float64(0.15625), 29: np.float64(0.8241206030150754), 31: np.float64(0.06451612903225806), 32: np.float64(0.5540540540540541), 34: np.float64(0.23809523809523808), 35: np.float64(0.18811881188118812), 37: np.float64(0.17391304347826086), 38: np.float64(0.45454545454545453), 39: np.float64(0.14285714285714285), 40: np.float64(0.21395348837209302)}
Micro-average F1 score: 0.3656224237427865
Weighted-average F1 score: 0.3416719973867022
F1 score per class: {0: np.float64(0.3037974683544304), 1: np.float64(0.16974169741697417), 2: np.float64(0.35294117647058826), 3: np.float64(0.40816326530612246), 4: np.float64(0.8390804597701149), 6: np.float64(0.43555555555555553), 7: np.float64(0.06666666666666667), 9: np.float64(0.704225352112676), 11: np.float64(0.02247191011235955), 12: np.float64(0.078125), 13: np.float64(0.041237113402061855), 14: np.float64(0.049586776859504134), 15: np.float64(0.631578947368421), 19: np.float64(0.5245901639344263), 21: np.float64(0.13513513513513514), 22: np.float64(0.5241935483870968), 23: np.float64(0.7272727272727273), 24: np.float64(0.0), 25: np.float64(0.6829268292682927), 26: np.float64(0.7111111111111111), 27: np.float64(0.0), 28: np.float64(0.136986301369863), 29: np.float64(0.8159203980099502), 31: np.float64(0.08695652173913043), 32: np.float64(0.5382059800664452), 34: np.float64(0.22573363431151242), 35: np.float64(0.18292682926829268), 37: np.float64(0.16417910447761194), 38: np.float64(0.45614035087719296), 39: np.float64(0.14814814814814814), 40: np.float64(0.1981981981981982)}
Micro-average F1 score: 0.3708010335917313
Weighted-average F1 score: 0.34819341413060934

F1 score per class: {0: np.float64(0.7578947368421053), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7719298245614035), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.14814814814814814), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.25396825396825395), 22: np.float64(0.0), 23: np.float64(0.7368421052631579), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.40273972602739727
Weighted-average F1 score: 0.28533250337171906
F1 score per class: {0: np.float64(0.6422018348623854), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7789473684210526), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.11764705882352941), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3368421052631579), 22: np.float64(0.0), 23: np.float64(0.6728971962616822), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.35473340587595215
Weighted-average F1 score: 0.2599245872480857
F1 score per class: {0: np.float64(0.6666666666666666), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8021978021978022), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.13333333333333333), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.32608695652173914), 22: np.float64(0.0), 23: np.float64(0.6792452830188679), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.37284234752589185
Weighted-average F1 score: 0.27182382510450803

F1 score per class: {0: np.float64(0.26181818181818184), 1: np.float64(0.09389671361502347), 2: np.float64(0.2564102564102564), 3: np.float64(0.40955631399317405), 4: np.float64(0.7586206896551724), 6: np.float64(0.2508710801393728), 7: np.float64(0.047058823529411764), 9: np.float64(0.6493506493506493), 11: np.float64(0.16494845360824742), 12: np.float64(0.0), 13: np.float64(0.022727272727272728), 14: np.float64(0.07317073170731707), 15: np.float64(0.48), 19: np.float64(0.5016501650165016), 21: np.float64(0.0898876404494382), 22: np.float64(0.3891891891891892), 23: np.float64(0.6086956521739131), 24: np.float64(0.0), 25: np.float64(0.4507042253521127), 26: np.float64(0.6408839779005525), 27: np.float64(0.0), 28: np.float64(0.14736842105263157), 29: np.float64(0.7192982456140351), 31: np.float64(0.06896551724137931), 32: np.float64(0.3768844221105528), 34: np.float64(0.12830188679245283), 35: np.float64(0.08955223880597014), 37: np.float64(0.23), 38: np.float64(0.25), 39: np.float64(0.058823529411764705), 40: np.float64(0.19895287958115182)}
Micro-average F1 score: 0.289044289044289
Weighted-average F1 score: 0.2661638779416769
F1 score per class: {0: np.float64(0.19444444444444445), 1: np.float64(0.0954356846473029), 2: np.float64(0.15789473684210525), 3: np.float64(0.2472885032537961), 4: np.float64(0.714975845410628), 6: np.float64(0.24), 7: np.float64(0.035398230088495575), 9: np.float64(0.33557046979865773), 11: np.float64(0.02247191011235955), 12: np.float64(0.14049586776859505), 13: np.float64(0.020100502512562814), 14: np.float64(0.02926829268292683), 15: np.float64(0.41379310344827586), 19: np.float64(0.43956043956043955), 21: np.float64(0.09696969696969697), 22: np.float64(0.4065573770491803), 23: np.float64(0.5538461538461539), 24: np.float64(0.0), 25: np.float64(0.6422018348623854), 26: np.float64(0.6435643564356436), 27: np.float64(0.0), 28: np.float64(0.10416666666666667), 29: np.float64(0.70995670995671), 31: np.float64(0.03389830508474576), 32: np.float64(0.4049382716049383), 34: np.float64(0.1440922190201729), 35: np.float64(0.11838006230529595), 37: np.float64(0.12698412698412698), 38: np.float64(0.32608695652173914), 39: np.float64(0.0784313725490196), 40: np.float64(0.1597222222222222)}
Micro-average F1 score: 0.2553987906708897
Weighted-average F1 score: 0.23409619704751047
F1 score per class: {0: np.float64(0.2011173184357542), 1: np.float64(0.09292929292929293), 2: np.float64(0.21428571428571427), 3: np.float64(0.26548672566371684), 4: np.float64(0.7849462365591398), 6: np.float64(0.2552083333333333), 7: np.float64(0.041237113402061855), 9: np.float64(0.625), 11: np.float64(0.02247191011235955), 12: np.float64(0.06329113924050633), 13: np.float64(0.02072538860103627), 14: np.float64(0.04), 15: np.float64(0.41379310344827586), 19: np.float64(0.46511627906976744), 21: np.float64(0.08620689655172414), 22: np.float64(0.40752351097178685), 23: np.float64(0.5853658536585366), 24: np.float64(0.0), 25: np.float64(0.5894736842105263), 26: np.float64(0.6432160804020101), 27: np.float64(0.0), 28: np.float64(0.09174311926605505), 29: np.float64(0.6949152542372882), 31: np.float64(0.04878048780487805), 32: np.float64(0.39416058394160586), 34: np.float64(0.1366120218579235), 35: np.float64(0.11278195488721804), 37: np.float64(0.11458333333333333), 38: np.float64(0.325), 39: np.float64(0.08163265306122448), 40: np.float64(0.15172413793103448)}
Micro-average F1 score: 0.2607115821347464
Weighted-average F1 score: 0.23815809381537492
cur_acc_wo_na:  ['0.7527', '0.5215', '0.3551', '0.5092', '0.4000', '0.5385']
his_acc_wo_na:  ['0.7527', '0.6414', '0.5152', '0.4390', '0.3823', '0.3955']
cur_acc des_wo_na:  ['0.7489', '0.4747', '0.3028', '0.5388', '0.3415', '0.4851']
his_acc des_wo_na:  ['0.7489', '0.6321', '0.5127', '0.4598', '0.3709', '0.3656']
cur_acc rrf_wo_na:  ['0.7566', '0.4892', '0.3177', '0.5426', '0.3553', '0.5078']
his_acc rrf_wo_na:  ['0.7566', '0.6338', '0.5152', '0.4507', '0.3693', '0.3708']
cur_acc_w_na:  ['0.6262', '0.3858', '0.3121', '0.3531', '0.2771', '0.4027']
his_acc_w_na:  ['0.6262', '0.4826', '0.4122', '0.3016', '0.2771', '0.2890']
cur_acc des_w_na:  ['0.6047', '0.3416', '0.2679', '0.3888', '0.2266', '0.3547']
his_acc des_w_na:  ['0.6047', '0.4681', '0.4067', '0.3269', '0.2609', '0.2554']
cur_acc rrf_w_na:  ['0.6192', '0.3536', '0.2821', '0.3944', '0.2403', '0.3728']
his_acc rrf_w_na:  ['0.6192', '0.4735', '0.4106', '0.3205', '0.2626', '0.2607']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 106.9259120CurrentTrain: epoch  0, batch     1 | loss: 93.4147595CurrentTrain: epoch  0, batch     2 | loss: 90.7245079CurrentTrain: epoch  0, batch     3 | loss: 85.7261158CurrentTrain: epoch  1, batch     0 | loss: 106.6999268CurrentTrain: epoch  1, batch     1 | loss: 89.0994144CurrentTrain: epoch  1, batch     2 | loss: 76.2793971CurrentTrain: epoch  1, batch     3 | loss: 49.3281252CurrentTrain: epoch  2, batch     0 | loss: 74.0660479CurrentTrain: epoch  2, batch     1 | loss: 82.1999311CurrentTrain: epoch  2, batch     2 | loss: 84.6037993CurrentTrain: epoch  2, batch     3 | loss: 59.8538211CurrentTrain: epoch  3, batch     0 | loss: 68.1301266CurrentTrain: epoch  3, batch     1 | loss: 82.6431226CurrentTrain: epoch  3, batch     2 | loss: 68.7602388CurrentTrain: epoch  3, batch     3 | loss: 58.0853421CurrentTrain: epoch  4, batch     0 | loss: 125.0689602CurrentTrain: epoch  4, batch     1 | loss: 81.3693718CurrentTrain: epoch  4, batch     2 | loss: 66.6367809CurrentTrain: epoch  4, batch     3 | loss: 47.1276680CurrentTrain: epoch  5, batch     0 | loss: 98.1437111CurrentTrain: epoch  5, batch     1 | loss: 70.2388713CurrentTrain: epoch  5, batch     2 | loss: 92.4915785CurrentTrain: epoch  5, batch     3 | loss: 44.6998928CurrentTrain: epoch  6, batch     0 | loss: 64.5066494CurrentTrain: epoch  6, batch     1 | loss: 99.2181246CurrentTrain: epoch  6, batch     2 | loss: 92.7835879CurrentTrain: epoch  6, batch     3 | loss: 55.6182208CurrentTrain: epoch  7, batch     0 | loss: 63.0248929CurrentTrain: epoch  7, batch     1 | loss: 75.5021244CurrentTrain: epoch  7, batch     2 | loss: 80.8545258CurrentTrain: epoch  7, batch     3 | loss: 46.1259645CurrentTrain: epoch  8, batch     0 | loss: 75.7601820CurrentTrain: epoch  8, batch     1 | loss: 75.6572635CurrentTrain: epoch  8, batch     2 | loss: 78.2429068CurrentTrain: epoch  8, batch     3 | loss: 55.8995284CurrentTrain: epoch  9, batch     0 | loss: 74.8754759CurrentTrain: epoch  9, batch     1 | loss: 74.2390358CurrentTrain: epoch  9, batch     2 | loss: 62.8114395CurrentTrain: epoch  9, batch     3 | loss: 72.3082496
MemoryTrain:  epoch  0, batch     0 | loss: 0.7566115MemoryTrain:  epoch  1, batch     0 | loss: 0.6489333MemoryTrain:  epoch  2, batch     0 | loss: 0.4991853MemoryTrain:  epoch  3, batch     0 | loss: 0.4497534MemoryTrain:  epoch  4, batch     0 | loss: 0.3611990MemoryTrain:  epoch  5, batch     0 | loss: 0.3403766MemoryTrain:  epoch  6, batch     0 | loss: 0.3522538MemoryTrain:  epoch  7, batch     0 | loss: 0.2688457MemoryTrain:  epoch  8, batch     0 | loss: 0.2442153MemoryTrain:  epoch  9, batch     0 | loss: 0.2493748

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.5611510791366906), 13: np.float64(0.0), 20: np.float64(0.6428571428571429), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8571428571428571), 32: np.float64(0.0), 33: np.float64(0.47058823529411764), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.43956043956043955), 37: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4393305439330544
Weighted-average F1 score: 0.32129272465871966
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.6075949367088608), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 20: np.float64(0.7102803738317757), 21: np.float64(0.0), 22: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8181818181818182), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.3333333333333333), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.7746478873239436), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.510236220472441
Weighted-average F1 score: 0.4111158122875369
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.6134969325153374), 9: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.6956521739130435), 22: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8780487804878049), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.3333333333333333), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.672566371681416), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4912891986062718
Weighted-average F1 score: 0.37901620130625335

F1 score per class: {0: np.float64(0.44171779141104295), 1: np.float64(0.19548872180451127), 2: np.float64(0.5), 3: np.float64(0.4460431654676259), 4: np.float64(0.8187134502923976), 6: np.float64(0.41530054644808745), 7: np.float64(0.04081632653061224), 8: np.float64(0.2671232876712329), 9: np.float64(0.7246376811594203), 11: np.float64(0.06593406593406594), 12: np.float64(0.0), 13: np.float64(0.12121212121212122), 14: np.float64(0.07692307692307693), 15: np.float64(0.6666666666666666), 19: np.float64(0.5150501672240803), 20: np.float64(0.5869565217391305), 21: np.float64(0.12403100775193798), 22: np.float64(0.5677966101694916), 23: np.float64(0.723404255319149), 24: np.float64(0.0), 25: np.float64(0.4117647058823529), 26: np.float64(0.6966292134831461), 27: np.float64(0.0), 28: np.float64(0.5263157894736842), 29: np.float64(0.8333333333333334), 30: np.float64(0.8571428571428571), 31: np.float64(0.09090909090909091), 32: np.float64(0.5454545454545454), 33: np.float64(0.11267605633802817), 34: np.float64(0.25308641975308643), 35: np.float64(0.16783216783216784), 36: np.float64(0.3883495145631068), 37: np.float64(0.30434782608695654), 38: np.float64(0.25), 39: np.float64(0.0), 40: np.float64(0.17777777777777778)}
Micro-average F1 score: 0.3976395823876532
Weighted-average F1 score: 0.38667809167067907
F1 score per class: {0: np.float64(0.25089605734767023), 1: np.float64(0.17490494296577946), 2: np.float64(0.2916666666666667), 3: np.float64(0.3898916967509025), 4: np.float64(0.8481675392670157), 6: np.float64(0.44642857142857145), 7: np.float64(0.04081632653061224), 8: np.float64(0.2594594594594595), 9: np.float64(0.43103448275862066), 11: np.float64(0.16), 12: np.float64(0.14772727272727273), 13: np.float64(0.08333333333333333), 14: np.float64(0.05172413793103448), 15: np.float64(0.46153846153846156), 19: np.float64(0.4628099173553719), 20: np.float64(0.4634146341463415), 21: np.float64(0.10576923076923077), 22: np.float64(0.5111111111111111), 23: np.float64(0.74), 24: np.float64(0.0), 25: np.float64(0.5882352941176471), 26: np.float64(0.7065217391304348), 27: np.float64(0.0), 28: np.float64(0.3076923076923077), 29: np.float64(0.8155339805825242), 30: np.float64(0.4090909090909091), 31: np.float64(0.03225806451612903), 32: np.float64(0.5236593059936908), 33: np.float64(0.08), 34: np.float64(0.29900332225913623), 35: np.float64(0.19834710743801653), 36: np.float64(0.4954954954954955), 37: np.float64(0.140625), 38: np.float64(0.43137254901960786), 39: np.float64(0.15384615384615385), 40: np.float64(0.1744186046511628)}
Micro-average F1 score: 0.37111190561315693
Weighted-average F1 score: 0.35347885249625594
F1 score per class: {0: np.float64(0.2723735408560311), 1: np.float64(0.1797752808988764), 2: np.float64(0.3333333333333333), 3: np.float64(0.4351851851851852), 4: np.float64(0.8950276243093923), 6: np.float64(0.43317972350230416), 7: np.float64(0.043478260869565216), 8: np.float64(0.26666666666666666), 9: np.float64(0.6756756756756757), 11: np.float64(0.14583333333333334), 12: np.float64(0.09302325581395349), 13: np.float64(0.06666666666666667), 14: np.float64(0.05357142857142857), 15: np.float64(0.5454545454545454), 19: np.float64(0.4772727272727273), 20: np.float64(0.5289256198347108), 21: np.float64(0.09523809523809523), 22: np.float64(0.5461538461538461), 23: np.float64(0.7578947368421053), 24: np.float64(0.0), 25: np.float64(0.575), 26: np.float64(0.7103825136612022), 27: np.float64(0.0), 28: np.float64(0.36363636363636365), 29: np.float64(0.8151658767772512), 30: np.float64(0.6206896551724138), 31: np.float64(0.05555555555555555), 32: np.float64(0.5295950155763239), 33: np.float64(0.0759493670886076), 34: np.float64(0.2727272727272727), 35: np.float64(0.17674418604651163), 36: np.float64(0.5170068027210885), 37: np.float64(0.15714285714285714), 38: np.float64(0.45), 39: np.float64(0.17391304347826086), 40: np.float64(0.17679558011049723)}
Micro-average F1 score: 0.3828725038402458
Weighted-average F1 score: 0.3624964907965804

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.46153846153846156), 9: np.float64(0.0), 13: np.float64(0.0), 20: np.float64(0.5192307692307693), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8108108108108109), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.3076923076923077), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.35714285714285715), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3201219512195122
Weighted-average F1 score: 0.24050699697758524
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.4423963133640553), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5467625899280576), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.782608695652174), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.2222222222222222), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.5789473684210527), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.34541577825159914
Weighted-average F1 score: 0.2872930449558292
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.4484304932735426), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5333333333333333), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8372093023255814), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.20689655172413793), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.5033112582781457), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.33137485311398357
Weighted-average F1 score: 0.26689636804086103

F1 score per class: {0: np.float64(0.291497975708502), 1: np.float64(0.10655737704918032), 2: np.float64(0.2702702702702703), 3: np.float64(0.3229166666666667), 4: np.float64(0.7821229050279329), 6: np.float64(0.2585034013605442), 7: np.float64(0.02666666666666667), 8: np.float64(0.16666666666666666), 9: np.float64(0.6493506493506493), 11: np.float64(0.06593406593406594), 12: np.float64(0.0), 13: np.float64(0.06779661016949153), 14: np.float64(0.06896551724137931), 15: np.float64(0.48), 19: np.float64(0.4652567975830816), 20: np.float64(0.3312883435582822), 21: np.float64(0.08205128205128205), 22: np.float64(0.4527027027027027), 23: np.float64(0.6476190476190476), 24: np.float64(0.0), 25: np.float64(0.3888888888888889), 26: np.float64(0.6262626262626263), 27: np.float64(0.0), 28: np.float64(0.2777777777777778), 29: np.float64(0.6995884773662552), 30: np.float64(0.7692307692307693), 31: np.float64(0.046511627906976744), 32: np.float64(0.38613861386138615), 33: np.float64(0.07407407407407407), 34: np.float64(0.15471698113207547), 35: np.float64(0.11650485436893204), 36: np.float64(0.28169014084507044), 37: np.float64(0.22459893048128343), 38: np.float64(0.21621621621621623), 39: np.float64(0.0), 40: np.float64(0.14479638009049775)}
Micro-average F1 score: 0.2887277521423863
Weighted-average F1 score: 0.2708587419304546
F1 score per class: {0: np.float64(0.1674641148325359), 1: np.float64(0.09643605870020965), 2: np.float64(0.1728395061728395), 3: np.float64(0.2488479262672811), 4: np.float64(0.7714285714285715), 6: np.float64(0.2638522427440633), 7: np.float64(0.02857142857142857), 8: np.float64(0.15141955835962145), 9: np.float64(0.3067484662576687), 11: np.float64(0.15384615384615385), 12: np.float64(0.1092436974789916), 13: np.float64(0.05405405405405406), 14: np.float64(0.043478260869565216), 15: np.float64(0.35294117647058826), 19: np.float64(0.3990498812351544), 20: np.float64(0.25675675675675674), 21: np.float64(0.06748466257668712), 22: np.float64(0.4046920821114369), 23: np.float64(0.5648854961832062), 24: np.float64(0.0), 25: np.float64(0.5319148936170213), 26: np.float64(0.6341463414634146), 27: np.float64(0.0), 28: np.float64(0.14814814814814814), 29: np.float64(0.6746987951807228), 30: np.float64(0.3), 31: np.float64(0.018518518518518517), 32: np.float64(0.38073394495412843), 33: np.float64(0.04878048780487805), 34: np.float64(0.1782178217821782), 35: np.float64(0.12903225806451613), 36: np.float64(0.32934131736526945), 37: np.float64(0.10404624277456648), 38: np.float64(0.29333333333333333), 39: np.float64(0.13333333333333333), 40: np.float64(0.13953488372093023)}
Micro-average F1 score: 0.25708978328173376
Weighted-average F1 score: 0.24046278921380648
F1 score per class: {0: np.float64(0.17902813299232737), 1: np.float64(0.09696969696969697), 2: np.float64(0.20689655172413793), 3: np.float64(0.28484848484848485), 4: np.float64(0.84375), 6: np.float64(0.26256983240223464), 7: np.float64(0.030303030303030304), 8: np.float64(0.15408320493066255), 9: np.float64(0.5813953488372093), 11: np.float64(0.14), 12: np.float64(0.0784313725490196), 13: np.float64(0.045454545454545456), 14: np.float64(0.04411764705882353), 15: np.float64(0.4), 19: np.float64(0.4221105527638191), 20: np.float64(0.27467811158798283), 21: np.float64(0.06006006006006006), 22: np.float64(0.43962848297213625), 23: np.float64(0.6050420168067226), 24: np.float64(0.0), 25: np.float64(0.5111111111111111), 26: np.float64(0.6403940886699507), 27: np.float64(0.0), 28: np.float64(0.1568627450980392), 29: np.float64(0.671875), 30: np.float64(0.4864864864864865), 31: np.float64(0.03076923076923077), 32: np.float64(0.38288288288288286), 33: np.float64(0.044444444444444446), 34: np.float64(0.16666666666666666), 35: np.float64(0.11209439528023599), 36: np.float64(0.3392857142857143), 37: np.float64(0.11458333333333333), 38: np.float64(0.29508196721311475), 39: np.float64(0.14814814814814814), 40: np.float64(0.13852813852813853)}
Micro-average F1 score: 0.2666844991306674
Weighted-average F1 score: 0.24685293913077633
cur_acc_wo_na:  ['0.7527', '0.5215', '0.3551', '0.5092', '0.4000', '0.5385', '0.4393']
his_acc_wo_na:  ['0.7527', '0.6414', '0.5152', '0.4390', '0.3823', '0.3955', '0.3976']
cur_acc des_wo_na:  ['0.7489', '0.4747', '0.3028', '0.5388', '0.3415', '0.4851', '0.5102']
his_acc des_wo_na:  ['0.7489', '0.6321', '0.5127', '0.4598', '0.3709', '0.3656', '0.3711']
cur_acc rrf_wo_na:  ['0.7566', '0.4892', '0.3177', '0.5426', '0.3553', '0.5078', '0.4913']
his_acc rrf_wo_na:  ['0.7566', '0.6338', '0.5152', '0.4507', '0.3693', '0.3708', '0.3829']
cur_acc_w_na:  ['0.6262', '0.3858', '0.3121', '0.3531', '0.2771', '0.4027', '0.3201']
his_acc_w_na:  ['0.6262', '0.4826', '0.4122', '0.3016', '0.2771', '0.2890', '0.2887']
cur_acc des_w_na:  ['0.6047', '0.3416', '0.2679', '0.3888', '0.2266', '0.3547', '0.3454']
his_acc des_w_na:  ['0.6047', '0.4681', '0.4067', '0.3269', '0.2609', '0.2554', '0.2571']
cur_acc rrf_w_na:  ['0.6192', '0.3536', '0.2821', '0.3944', '0.2403', '0.3728', '0.3314']
his_acc rrf_w_na:  ['0.6192', '0.4735', '0.4106', '0.3205', '0.2626', '0.2607', '0.2667']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 123.0297582CurrentTrain: epoch  0, batch     1 | loss: 144.4365660CurrentTrain: epoch  0, batch     2 | loss: 111.8028309CurrentTrain: epoch  0, batch     3 | loss: 83.9903957CurrentTrain: epoch  0, batch     4 | loss: 64.0332711CurrentTrain: epoch  1, batch     0 | loss: 90.2298494CurrentTrain: epoch  1, batch     1 | loss: 93.9874376CurrentTrain: epoch  1, batch     2 | loss: 110.6578374CurrentTrain: epoch  1, batch     3 | loss: 130.6012796CurrentTrain: epoch  1, batch     4 | loss: 112.4140840CurrentTrain: epoch  2, batch     0 | loss: 112.0582365CurrentTrain: epoch  2, batch     1 | loss: 129.3118428CurrentTrain: epoch  2, batch     2 | loss: 102.6604250CurrentTrain: epoch  2, batch     3 | loss: 104.9465889CurrentTrain: epoch  2, batch     4 | loss: 52.4905664CurrentTrain: epoch  3, batch     0 | loss: 81.6789590CurrentTrain: epoch  3, batch     1 | loss: 103.4111253CurrentTrain: epoch  3, batch     2 | loss: 83.7036692CurrentTrain: epoch  3, batch     3 | loss: 102.5719824CurrentTrain: epoch  3, batch     4 | loss: 88.5327473CurrentTrain: epoch  4, batch     0 | loss: 84.1225477CurrentTrain: epoch  4, batch     1 | loss: 70.0385588CurrentTrain: epoch  4, batch     2 | loss: 103.8842981CurrentTrain: epoch  4, batch     3 | loss: 80.6094771CurrentTrain: epoch  4, batch     4 | loss: 170.6836126CurrentTrain: epoch  5, batch     0 | loss: 81.1419784CurrentTrain: epoch  5, batch     1 | loss: 80.9494457CurrentTrain: epoch  5, batch     2 | loss: 82.2381161CurrentTrain: epoch  5, batch     3 | loss: 102.0374293CurrentTrain: epoch  5, batch     4 | loss: 51.4542469CurrentTrain: epoch  6, batch     0 | loss: 79.7906636CurrentTrain: epoch  6, batch     1 | loss: 83.8681275CurrentTrain: epoch  6, batch     2 | loss: 68.9655329CurrentTrain: epoch  6, batch     3 | loss: 96.7698946CurrentTrain: epoch  6, batch     4 | loss: 80.7947116CurrentTrain: epoch  7, batch     0 | loss: 95.6590859CurrentTrain: epoch  7, batch     1 | loss: 78.1350377CurrentTrain: epoch  7, batch     2 | loss: 128.6919230CurrentTrain: epoch  7, batch     3 | loss: 65.6864240CurrentTrain: epoch  7, batch     4 | loss: 61.5000065CurrentTrain: epoch  8, batch     0 | loss: 96.7319961CurrentTrain: epoch  8, batch     1 | loss: 78.9355989CurrentTrain: epoch  8, batch     2 | loss: 96.8103386CurrentTrain: epoch  8, batch     3 | loss: 76.9898011CurrentTrain: epoch  8, batch     4 | loss: 50.1208232CurrentTrain: epoch  9, batch     0 | loss: 95.9783285CurrentTrain: epoch  9, batch     1 | loss: 91.8496913CurrentTrain: epoch  9, batch     2 | loss: 74.7744882CurrentTrain: epoch  9, batch     3 | loss: 97.1015488CurrentTrain: epoch  9, batch     4 | loss: 59.1866530
MemoryTrain:  epoch  0, batch     0 | loss: 0.9672719MemoryTrain:  epoch  1, batch     0 | loss: 0.7925626MemoryTrain:  epoch  2, batch     0 | loss: 0.6366790MemoryTrain:  epoch  3, batch     0 | loss: 0.5465374MemoryTrain:  epoch  4, batch     0 | loss: 0.4237685MemoryTrain:  epoch  5, batch     0 | loss: 0.3906580MemoryTrain:  epoch  6, batch     0 | loss: 0.3698716MemoryTrain:  epoch  7, batch     0 | loss: 0.2794449MemoryTrain:  epoch  8, batch     0 | loss: 0.2762507MemoryTrain:  epoch  9, batch     0 | loss: 0.2593548

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.8975609756097561), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.42424242424242425), 11: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.7407407407407407), 17: np.float64(0.7142857142857143), 18: np.float64(0.25882352941176473), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5234899328859061
Weighted-average F1 score: 0.4424762367992282
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.6855123674911661), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.5675675675675675), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.7246376811594203), 17: np.float64(0.7058823529411765), 18: np.float64(0.19801980198019803), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4337899543378995
Weighted-average F1 score: 0.3654553370160102
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.735632183908046), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.5733333333333334), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.7076923076923077), 17: np.float64(0.7142857142857143), 18: np.float64(0.23448275862068965), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.46
Weighted-average F1 score: 0.38314550677014486

F1 score per class: {0: np.float64(0.49645390070921985), 1: np.float64(0.16535433070866143), 2: np.float64(0.5263157894736842), 3: np.float64(0.4142857142857143), 4: np.float64(0.8117647058823529), 5: np.float64(0.7244094488188977), 6: np.float64(0.3151515151515151), 7: np.float64(0.0), 8: np.float64(0.2892561983471074), 9: np.float64(0.6944444444444444), 10: np.float64(0.29015544041450775), 11: np.float64(0.06521739130434782), 12: np.float64(0.0), 13: np.float64(0.05714285714285714), 14: np.float64(0.05555555555555555), 15: np.float64(0.5882352941176471), 16: np.float64(0.6557377049180327), 17: np.float64(0.4), 18: np.float64(0.15492957746478872), 19: np.float64(0.5100671140939598), 20: np.float64(0.5154639175257731), 21: np.float64(0.14285714285714285), 22: np.float64(0.5432098765432098), 23: np.float64(0.7446808510638298), 24: np.float64(0.0), 25: np.float64(0.3582089552238806), 26: np.float64(0.6815642458100558), 27: np.float64(0.0), 28: np.float64(0.5), 29: np.float64(0.8195121951219512), 30: np.float64(0.7777777777777778), 31: np.float64(0.08695652173913043), 32: np.float64(0.5303030303030303), 33: np.float64(0.10526315789473684), 34: np.float64(0.2155688622754491), 35: np.float64(0.1694915254237288), 36: np.float64(0.2), 37: np.float64(0.2542372881355932), 38: np.float64(0.29411764705882354), 39: np.float64(0.21052631578947367), 40: np.float64(0.1927710843373494)}
Micro-average F1 score: 0.3965410747374923
Weighted-average F1 score: 0.39266776928781455
F1 score per class: {0: np.float64(0.2834008097165992), 1: np.float64(0.16730038022813687), 2: np.float64(0.3), 3: np.float64(0.3881856540084388), 4: np.float64(0.8527918781725888), 5: np.float64(0.47549019607843135), 6: np.float64(0.41767068273092367), 7: np.float64(0.03773584905660377), 8: np.float64(0.28), 9: np.float64(0.36764705882352944), 10: np.float64(0.39436619718309857), 11: np.float64(0.27184466019417475), 12: np.float64(0.18009478672985782), 13: np.float64(0.05714285714285714), 14: np.float64(0.04878048780487805), 15: np.float64(0.5454545454545454), 16: np.float64(0.5319148936170213), 17: np.float64(0.3), 18: np.float64(0.10869565217391304), 19: np.float64(0.44562334217506633), 20: np.float64(0.45348837209302323), 21: np.float64(0.16129032258064516), 22: np.float64(0.4944649446494465), 23: np.float64(0.6666666666666666), 24: np.float64(0.0), 25: np.float64(0.5411764705882353), 26: np.float64(0.6842105263157895), 27: np.float64(0.0), 28: np.float64(0.47058823529411764), 29: np.float64(0.8133971291866029), 30: np.float64(0.4), 31: np.float64(0.03571428571428571), 32: np.float64(0.5209003215434084), 33: np.float64(0.07894736842105263), 34: np.float64(0.28688524590163933), 35: np.float64(0.24793388429752067), 36: np.float64(0.5394736842105263), 37: np.float64(0.1437908496732026), 38: np.float64(0.46153846153846156), 39: np.float64(0.11428571428571428), 40: np.float64(0.13114754098360656)}
Micro-average F1 score: 0.36625637946562595
Weighted-average F1 score: 0.3468199300737828
F1 score per class: {0: np.float64(0.2987551867219917), 1: np.float64(0.1647940074906367), 2: np.float64(0.3225806451612903), 3: np.float64(0.4444444444444444), 4: np.float64(0.8764044943820225), 5: np.float64(0.5245901639344263), 6: np.float64(0.41739130434782606), 7: np.float64(0.04), 8: np.float64(0.28484848484848485), 9: np.float64(0.625), 10: np.float64(0.37719298245614036), 11: np.float64(0.22), 12: np.float64(0.14285714285714285), 13: np.float64(0.05714285714285714), 14: np.float64(0.05660377358490566), 15: np.float64(0.5714285714285714), 16: np.float64(0.5476190476190477), 17: np.float64(0.30303030303030304), 18: np.float64(0.1259259259259259), 19: np.float64(0.4563380281690141), 20: np.float64(0.546875), 21: np.float64(0.15204678362573099), 22: np.float64(0.5223880597014925), 23: np.float64(0.7), 24: np.float64(0.0), 25: np.float64(0.5), 26: np.float64(0.6914893617021277), 27: np.float64(0.0), 28: np.float64(0.42105263157894735), 29: np.float64(0.8207547169811321), 30: np.float64(0.6538461538461539), 31: np.float64(0.058823529411764705), 32: np.float64(0.5374149659863946), 33: np.float64(0.0821917808219178), 34: np.float64(0.22560975609756098), 35: np.float64(0.18947368421052632), 36: np.float64(0.5), 37: np.float64(0.15492957746478872), 38: np.float64(0.43137254901960786), 39: np.float64(0.18181818181818182), 40: np.float64(0.12060301507537688)}
Micro-average F1 score: 0.3794414146422079
Weighted-average F1 score: 0.3594573046123302

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.7076923076923077), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.4), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.5128205128205128), 17: np.float64(0.5), 18: np.float64(0.21359223300970873), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.35414301929625425
Weighted-average F1 score: 0.286683043346768
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.5145888594164456), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.5153374233128835), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.46296296296296297), 17: np.float64(0.48), 18: np.float64(0.15873015873015872), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2825278810408922
Weighted-average F1 score: 0.23660006264280856
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.5647058823529412), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.5149700598802395), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.4423076923076923), 17: np.float64(0.45454545454545453), 18: np.float64(0.18579234972677597), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.30413223140495865
Weighted-average F1 score: 0.2524603308101192

F1 score per class: {0: np.float64(0.319634703196347), 1: np.float64(0.08955223880597014), 2: np.float64(0.2857142857142857), 3: np.float64(0.29441624365482233), 4: np.float64(0.7666666666666667), 5: np.float64(0.48677248677248675), 6: np.float64(0.1984732824427481), 7: np.float64(0.0), 8: np.float64(0.18518518518518517), 9: np.float64(0.6172839506172839), 10: np.float64(0.22857142857142856), 11: np.float64(0.06521739130434782), 12: np.float64(0.0), 13: np.float64(0.03571428571428571), 14: np.float64(0.05), 15: np.float64(0.5), 16: np.float64(0.42105263157894735), 17: np.float64(0.25), 18: np.float64(0.11055276381909548), 19: np.float64(0.46060606060606063), 20: np.float64(0.26595744680851063), 21: np.float64(0.09859154929577464), 22: np.float64(0.416403785488959), 23: np.float64(0.6542056074766355), 24: np.float64(0.0), 25: np.float64(0.34782608695652173), 26: np.float64(0.6069651741293532), 27: np.float64(0.0), 28: np.float64(0.25), 29: np.float64(0.6640316205533597), 30: np.float64(0.7368421052631579), 31: np.float64(0.046511627906976744), 32: np.float64(0.4034582132564842), 33: np.float64(0.06593406593406594), 34: np.float64(0.12631578947368421), 35: np.float64(0.12195121951219512), 36: np.float64(0.16666666666666666), 37: np.float64(0.18633540372670807), 38: np.float64(0.23809523809523808), 39: np.float64(0.16666666666666666), 40: np.float64(0.1568627450980392)}
Micro-average F1 score: 0.28694874851013114
Weighted-average F1 score: 0.2741178735446217
F1 score per class: {0: np.float64(0.1891891891891892), 1: np.float64(0.09016393442622951), 2: np.float64(0.18461538461538463), 3: np.float64(0.24797843665768193), 4: np.float64(0.7636363636363637), 5: np.float64(0.2921686746987952), 6: np.float64(0.23370786516853934), 7: np.float64(0.023255813953488372), 8: np.float64(0.16666666666666666), 9: np.float64(0.26595744680851063), 10: np.float64(0.2916666666666667), 11: np.float64(0.25688073394495414), 12: np.float64(0.11014492753623188), 13: np.float64(0.03636363636363636), 14: np.float64(0.039735099337748346), 15: np.float64(0.41379310344827586), 16: np.float64(0.3184713375796178), 17: np.float64(0.1411764705882353), 18: np.float64(0.08), 19: np.float64(0.375), 20: np.float64(0.2565789473684211), 21: np.float64(0.10273972602739725), 22: np.float64(0.37640449438202245), 23: np.float64(0.4675324675324675), 24: np.float64(0.0), 25: np.float64(0.5), 26: np.float64(0.6018518518518519), 27: np.float64(0.0), 28: np.float64(0.1951219512195122), 29: np.float64(0.6415094339622641), 30: np.float64(0.288), 31: np.float64(0.021052631578947368), 32: np.float64(0.37850467289719625), 33: np.float64(0.045454545454545456), 34: np.float64(0.15695067264573992), 35: np.float64(0.16574585635359115), 36: np.float64(0.33884297520661155), 37: np.float64(0.1), 38: np.float64(0.2803738317757009), 39: np.float64(0.07272727272727272), 40: np.float64(0.09411764705882353)}
Micro-average F1 score: 0.24658918645780697
Weighted-average F1 score: 0.23202957389336742
F1 score per class: {0: np.float64(0.1956521739130435), 1: np.float64(0.08979591836734693), 2: np.float64(0.2), 3: np.float64(0.2968197879858657), 4: np.float64(0.8210526315789474), 5: np.float64(0.32597623089983024), 6: np.float64(0.23587223587223588), 7: np.float64(0.02531645569620253), 8: np.float64(0.17184643510054845), 9: np.float64(0.5376344086021505), 10: np.float64(0.27044025157232704), 11: np.float64(0.20754716981132076), 12: np.float64(0.10869565217391304), 13: np.float64(0.03636363636363636), 14: np.float64(0.045112781954887216), 15: np.float64(0.42857142857142855), 16: np.float64(0.31724137931034485), 17: np.float64(0.14285714285714285), 18: np.float64(0.09090909090909091), 19: np.float64(0.3894230769230769), 20: np.float64(0.2928870292887029), 21: np.float64(0.09811320754716982), 22: np.float64(0.39886039886039887), 23: np.float64(0.5185185185185185), 24: np.float64(0.0), 25: np.float64(0.4691358024691358), 26: np.float64(0.6161137440758294), 27: np.float64(0.0), 28: np.float64(0.18181818181818182), 29: np.float64(0.6444444444444445), 30: np.float64(0.5074626865671642), 31: np.float64(0.03389830508474576), 32: np.float64(0.3891625615763547), 33: np.float64(0.045112781954887216), 34: np.float64(0.13261648745519714), 35: np.float64(0.1254355400696864), 36: np.float64(0.3333333333333333), 37: np.float64(0.10377358490566038), 38: np.float64(0.26506024096385544), 39: np.float64(0.13333333333333333), 40: np.float64(0.08540925266903915)}
Micro-average F1 score: 0.2588208770149927
Weighted-average F1 score: 0.24220620326122566
cur_acc_wo_na:  ['0.7527', '0.5215', '0.3551', '0.5092', '0.4000', '0.5385', '0.4393', '0.5235']
his_acc_wo_na:  ['0.7527', '0.6414', '0.5152', '0.4390', '0.3823', '0.3955', '0.3976', '0.3965']
cur_acc des_wo_na:  ['0.7489', '0.4747', '0.3028', '0.5388', '0.3415', '0.4851', '0.5102', '0.4338']
his_acc des_wo_na:  ['0.7489', '0.6321', '0.5127', '0.4598', '0.3709', '0.3656', '0.3711', '0.3663']
cur_acc rrf_wo_na:  ['0.7566', '0.4892', '0.3177', '0.5426', '0.3553', '0.5078', '0.4913', '0.4600']
his_acc rrf_wo_na:  ['0.7566', '0.6338', '0.5152', '0.4507', '0.3693', '0.3708', '0.3829', '0.3794']
cur_acc_w_na:  ['0.6262', '0.3858', '0.3121', '0.3531', '0.2771', '0.4027', '0.3201', '0.3541']
his_acc_w_na:  ['0.6262', '0.4826', '0.4122', '0.3016', '0.2771', '0.2890', '0.2887', '0.2869']
cur_acc des_w_na:  ['0.6047', '0.3416', '0.2679', '0.3888', '0.2266', '0.3547', '0.3454', '0.2825']
his_acc des_w_na:  ['0.6047', '0.4681', '0.4067', '0.3269', '0.2609', '0.2554', '0.2571', '0.2466']
cur_acc rrf_w_na:  ['0.6192', '0.3536', '0.2821', '0.3944', '0.2403', '0.3728', '0.3314', '0.3041']
his_acc rrf_w_na:  ['0.6192', '0.4735', '0.4106', '0.3205', '0.2626', '0.2607', '0.2667', '0.2588']
--------Round  1
seed:  200
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 6 3 2 4 0 5 1]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 129.7528089CurrentTrain: epoch  0, batch     1 | loss: 89.8079110CurrentTrain: epoch  0, batch     2 | loss: 78.5067588CurrentTrain: epoch  0, batch     3 | loss: 120.6109242CurrentTrain: epoch  0, batch     4 | loss: 77.6800952CurrentTrain: epoch  0, batch     5 | loss: 148.4673567CurrentTrain: epoch  0, batch     6 | loss: 88.1462033CurrentTrain: epoch  0, batch     7 | loss: 100.0827582CurrentTrain: epoch  0, batch     8 | loss: 86.3163774CurrentTrain: epoch  0, batch     9 | loss: 119.1538339CurrentTrain: epoch  0, batch    10 | loss: 90.2354299CurrentTrain: epoch  0, batch    11 | loss: 100.1165170CurrentTrain: epoch  0, batch    12 | loss: 86.2371420CurrentTrain: epoch  0, batch    13 | loss: 145.8798494CurrentTrain: epoch  0, batch    14 | loss: 99.9984768CurrentTrain: epoch  0, batch    15 | loss: 100.5109528CurrentTrain: epoch  0, batch    16 | loss: 99.2668395CurrentTrain: epoch  0, batch    17 | loss: 75.9962448CurrentTrain: epoch  0, batch    18 | loss: 86.9984949CurrentTrain: epoch  0, batch    19 | loss: 99.2953868CurrentTrain: epoch  0, batch    20 | loss: 118.9839478CurrentTrain: epoch  0, batch    21 | loss: 119.4681551CurrentTrain: epoch  0, batch    22 | loss: 99.3535456CurrentTrain: epoch  0, batch    23 | loss: 99.0104017CurrentTrain: epoch  0, batch    24 | loss: 86.3479546CurrentTrain: epoch  0, batch    25 | loss: 117.6062072CurrentTrain: epoch  0, batch    26 | loss: 99.0878794CurrentTrain: epoch  0, batch    27 | loss: 98.9808818CurrentTrain: epoch  0, batch    28 | loss: 85.6927197CurrentTrain: epoch  0, batch    29 | loss: 98.6412265CurrentTrain: epoch  0, batch    30 | loss: 98.3251377CurrentTrain: epoch  0, batch    31 | loss: 117.3555477CurrentTrain: epoch  0, batch    32 | loss: 83.7066984CurrentTrain: epoch  0, batch    33 | loss: 98.2256706CurrentTrain: epoch  0, batch    34 | loss: 117.3555203CurrentTrain: epoch  0, batch    35 | loss: 99.4834832CurrentTrain: epoch  0, batch    36 | loss: 98.6423635CurrentTrain: epoch  0, batch    37 | loss: 97.9692025CurrentTrain: epoch  0, batch    38 | loss: 84.8209255CurrentTrain: epoch  0, batch    39 | loss: 97.7070556CurrentTrain: epoch  0, batch    40 | loss: 145.4375894CurrentTrain: epoch  0, batch    41 | loss: 98.8129117CurrentTrain: epoch  0, batch    42 | loss: 96.9284844CurrentTrain: epoch  0, batch    43 | loss: 96.8239939CurrentTrain: epoch  0, batch    44 | loss: 114.6367516CurrentTrain: epoch  0, batch    45 | loss: 116.1486269CurrentTrain: epoch  0, batch    46 | loss: 141.8273066CurrentTrain: epoch  0, batch    47 | loss: 93.7630493CurrentTrain: epoch  0, batch    48 | loss: 83.8802174CurrentTrain: epoch  0, batch    49 | loss: 96.2989832CurrentTrain: epoch  0, batch    50 | loss: 73.0496893CurrentTrain: epoch  0, batch    51 | loss: 116.2620842CurrentTrain: epoch  0, batch    52 | loss: 82.4094312CurrentTrain: epoch  0, batch    53 | loss: 81.4347282CurrentTrain: epoch  0, batch    54 | loss: 73.0990681CurrentTrain: epoch  0, batch    55 | loss: 191.7030016CurrentTrain: epoch  0, batch    56 | loss: 142.8432095CurrentTrain: epoch  0, batch    57 | loss: 191.7440929CurrentTrain: epoch  0, batch    58 | loss: 112.7345144CurrentTrain: epoch  0, batch    59 | loss: 115.7143294CurrentTrain: epoch  0, batch    60 | loss: 139.1958657CurrentTrain: epoch  0, batch    61 | loss: 71.4637321CurrentTrain: epoch  0, batch    62 | loss: 191.6324283CurrentTrain: epoch  0, batch    63 | loss: 113.0708030CurrentTrain: epoch  0, batch    64 | loss: 81.9867963CurrentTrain: epoch  0, batch    65 | loss: 94.6671145CurrentTrain: epoch  0, batch    66 | loss: 137.5325713CurrentTrain: epoch  0, batch    67 | loss: 94.8084335CurrentTrain: epoch  0, batch    68 | loss: 82.4165387CurrentTrain: epoch  0, batch    69 | loss: 142.1581889CurrentTrain: epoch  0, batch    70 | loss: 94.2384590CurrentTrain: epoch  0, batch    71 | loss: 79.1495629CurrentTrain: epoch  0, batch    72 | loss: 96.2669601CurrentTrain: epoch  0, batch    73 | loss: 94.8186895CurrentTrain: epoch  0, batch    74 | loss: 114.1004059CurrentTrain: epoch  0, batch    75 | loss: 112.0571414CurrentTrain: epoch  0, batch    76 | loss: 141.0552288CurrentTrain: epoch  0, batch    77 | loss: 111.2723386CurrentTrain: epoch  0, batch    78 | loss: 109.7510254CurrentTrain: epoch  0, batch    79 | loss: 91.4596372CurrentTrain: epoch  0, batch    80 | loss: 81.4394515CurrentTrain: epoch  0, batch    81 | loss: 78.7284524CurrentTrain: epoch  0, batch    82 | loss: 92.4486180CurrentTrain: epoch  0, batch    83 | loss: 82.1960404CurrentTrain: epoch  0, batch    84 | loss: 79.6114846CurrentTrain: epoch  0, batch    85 | loss: 111.4400760CurrentTrain: epoch  0, batch    86 | loss: 79.9979469CurrentTrain: epoch  0, batch    87 | loss: 111.2130747CurrentTrain: epoch  0, batch    88 | loss: 76.6425880CurrentTrain: epoch  0, batch    89 | loss: 112.4616617CurrentTrain: epoch  0, batch    90 | loss: 91.8926337CurrentTrain: epoch  0, batch    91 | loss: 91.8069254CurrentTrain: epoch  0, batch    92 | loss: 89.1976558CurrentTrain: epoch  0, batch    93 | loss: 95.6450718CurrentTrain: epoch  0, batch    94 | loss: 138.4119357CurrentTrain: epoch  0, batch    95 | loss: 113.6934911CurrentTrain: epoch  1, batch     0 | loss: 90.3357503CurrentTrain: epoch  1, batch     1 | loss: 76.1801634CurrentTrain: epoch  1, batch     2 | loss: 113.6471069CurrentTrain: epoch  1, batch     3 | loss: 75.3958241CurrentTrain: epoch  1, batch     4 | loss: 108.9106115CurrentTrain: epoch  1, batch     5 | loss: 108.8955784CurrentTrain: epoch  1, batch     6 | loss: 134.0138458CurrentTrain: epoch  1, batch     7 | loss: 136.4291144CurrentTrain: epoch  1, batch     8 | loss: 142.5191069CurrentTrain: epoch  1, batch     9 | loss: 111.5813951CurrentTrain: epoch  1, batch    10 | loss: 92.1688076CurrentTrain: epoch  1, batch    11 | loss: 74.2230738CurrentTrain: epoch  1, batch    12 | loss: 112.2741721CurrentTrain: epoch  1, batch    13 | loss: 80.9868831CurrentTrain: epoch  1, batch    14 | loss: 90.7485119CurrentTrain: epoch  1, batch    15 | loss: 91.3258744CurrentTrain: epoch  1, batch    16 | loss: 107.2874828CurrentTrain: epoch  1, batch    17 | loss: 87.9379063CurrentTrain: epoch  1, batch    18 | loss: 88.1789094CurrentTrain: epoch  1, batch    19 | loss: 77.4248504CurrentTrain: epoch  1, batch    20 | loss: 77.4304974CurrentTrain: epoch  1, batch    21 | loss: 134.8860208CurrentTrain: epoch  1, batch    22 | loss: 74.0004171CurrentTrain: epoch  1, batch    23 | loss: 89.3078263CurrentTrain: epoch  1, batch    24 | loss: 73.3838566CurrentTrain: epoch  1, batch    25 | loss: 86.7051798CurrentTrain: epoch  1, batch    26 | loss: 87.7804017CurrentTrain: epoch  1, batch    27 | loss: 107.2274467CurrentTrain: epoch  1, batch    28 | loss: 137.2728226CurrentTrain: epoch  1, batch    29 | loss: 80.2328328CurrentTrain: epoch  1, batch    30 | loss: 89.1136899CurrentTrain: epoch  1, batch    31 | loss: 89.6971813CurrentTrain: epoch  1, batch    32 | loss: 77.1709179CurrentTrain: epoch  1, batch    33 | loss: 67.4512655CurrentTrain: epoch  1, batch    34 | loss: 135.8957770CurrentTrain: epoch  1, batch    35 | loss: 109.9953427CurrentTrain: epoch  1, batch    36 | loss: 76.5673091CurrentTrain: epoch  1, batch    37 | loss: 109.5877422CurrentTrain: epoch  1, batch    38 | loss: 142.1092499CurrentTrain: epoch  1, batch    39 | loss: 89.7477411CurrentTrain: epoch  1, batch    40 | loss: 86.1271657CurrentTrain: epoch  1, batch    41 | loss: 90.7041745CurrentTrain: epoch  1, batch    42 | loss: 109.4746742CurrentTrain: epoch  1, batch    43 | loss: 78.1472068CurrentTrain: epoch  1, batch    44 | loss: 106.0512076CurrentTrain: epoch  1, batch    45 | loss: 108.3173746CurrentTrain: epoch  1, batch    46 | loss: 184.4068376CurrentTrain: epoch  1, batch    47 | loss: 89.9463047CurrentTrain: epoch  1, batch    48 | loss: 92.3423710CurrentTrain: epoch  1, batch    49 | loss: 87.6556049CurrentTrain: epoch  1, batch    50 | loss: 106.8175298CurrentTrain: epoch  1, batch    51 | loss: 91.9462386CurrentTrain: epoch  1, batch    52 | loss: 136.3682435CurrentTrain: epoch  1, batch    53 | loss: 86.3330210CurrentTrain: epoch  1, batch    54 | loss: 86.6315377CurrentTrain: epoch  1, batch    55 | loss: 90.7100057CurrentTrain: epoch  1, batch    56 | loss: 76.0320179CurrentTrain: epoch  1, batch    57 | loss: 73.4857736CurrentTrain: epoch  1, batch    58 | loss: 109.6310274CurrentTrain: epoch  1, batch    59 | loss: 105.3836669CurrentTrain: epoch  1, batch    60 | loss: 72.6667527CurrentTrain: epoch  1, batch    61 | loss: 63.6973677CurrentTrain: epoch  1, batch    62 | loss: 110.4437194CurrentTrain: epoch  1, batch    63 | loss: 114.1470229CurrentTrain: epoch  1, batch    64 | loss: 76.7073108CurrentTrain: epoch  1, batch    65 | loss: 87.5628728CurrentTrain: epoch  1, batch    66 | loss: 105.6433255CurrentTrain: epoch  1, batch    67 | loss: 71.7471256CurrentTrain: epoch  1, batch    68 | loss: 89.7850469CurrentTrain: epoch  1, batch    69 | loss: 76.1027206CurrentTrain: epoch  1, batch    70 | loss: 110.4713788CurrentTrain: epoch  1, batch    71 | loss: 74.3350441CurrentTrain: epoch  1, batch    72 | loss: 106.2201253CurrentTrain: epoch  1, batch    73 | loss: 82.9898257CurrentTrain: epoch  1, batch    74 | loss: 86.9767457CurrentTrain: epoch  1, batch    75 | loss: 75.1093991CurrentTrain: epoch  1, batch    76 | loss: 86.5642659CurrentTrain: epoch  1, batch    77 | loss: 71.3533886CurrentTrain: epoch  1, batch    78 | loss: 89.5773777CurrentTrain: epoch  1, batch    79 | loss: 105.4895068CurrentTrain: epoch  1, batch    80 | loss: 87.0714359CurrentTrain: epoch  1, batch    81 | loss: 106.0175459CurrentTrain: epoch  1, batch    82 | loss: 78.5636278CurrentTrain: epoch  1, batch    83 | loss: 86.1950391CurrentTrain: epoch  1, batch    84 | loss: 75.8197331CurrentTrain: epoch  1, batch    85 | loss: 77.2026319CurrentTrain: epoch  1, batch    86 | loss: 89.3235303CurrentTrain: epoch  1, batch    87 | loss: 75.9352813CurrentTrain: epoch  1, batch    88 | loss: 102.1899197CurrentTrain: epoch  1, batch    89 | loss: 87.4149477CurrentTrain: epoch  1, batch    90 | loss: 77.5000797CurrentTrain: epoch  1, batch    91 | loss: 89.8202298CurrentTrain: epoch  1, batch    92 | loss: 88.4055904CurrentTrain: epoch  1, batch    93 | loss: 85.2061117CurrentTrain: epoch  1, batch    94 | loss: 88.9210217CurrentTrain: epoch  1, batch    95 | loss: 72.3293935CurrentTrain: epoch  2, batch     0 | loss: 65.4265895CurrentTrain: epoch  2, batch     1 | loss: 63.2653452CurrentTrain: epoch  2, batch     2 | loss: 83.1708401CurrentTrain: epoch  2, batch     3 | loss: 74.2182730CurrentTrain: epoch  2, batch     4 | loss: 61.5131375CurrentTrain: epoch  2, batch     5 | loss: 105.0020435CurrentTrain: epoch  2, batch     6 | loss: 76.0270263CurrentTrain: epoch  2, batch     7 | loss: 87.2713557CurrentTrain: epoch  2, batch     8 | loss: 135.7594423CurrentTrain: epoch  2, batch     9 | loss: 85.9983337CurrentTrain: epoch  2, batch    10 | loss: 82.4153778CurrentTrain: epoch  2, batch    11 | loss: 74.3305052CurrentTrain: epoch  2, batch    12 | loss: 63.9270356CurrentTrain: epoch  2, batch    13 | loss: 103.8065176CurrentTrain: epoch  2, batch    14 | loss: 84.3972083CurrentTrain: epoch  2, batch    15 | loss: 103.0009458CurrentTrain: epoch  2, batch    16 | loss: 62.4748206CurrentTrain: epoch  2, batch    17 | loss: 102.8513620CurrentTrain: epoch  2, batch    18 | loss: 130.9775003CurrentTrain: epoch  2, batch    19 | loss: 85.9771162CurrentTrain: epoch  2, batch    20 | loss: 87.9878076CurrentTrain: epoch  2, batch    21 | loss: 103.4049546CurrentTrain: epoch  2, batch    22 | loss: 92.7898753CurrentTrain: epoch  2, batch    23 | loss: 62.3602035CurrentTrain: epoch  2, batch    24 | loss: 62.3365988CurrentTrain: epoch  2, batch    25 | loss: 87.0405413CurrentTrain: epoch  2, batch    26 | loss: 69.1066600CurrentTrain: epoch  2, batch    27 | loss: 83.6703237CurrentTrain: epoch  2, batch    28 | loss: 76.5567272CurrentTrain: epoch  2, batch    29 | loss: 87.0066677CurrentTrain: epoch  2, batch    30 | loss: 85.7845081CurrentTrain: epoch  2, batch    31 | loss: 85.8792311CurrentTrain: epoch  2, batch    32 | loss: 109.4961923CurrentTrain: epoch  2, batch    33 | loss: 132.1415080CurrentTrain: epoch  2, batch    34 | loss: 87.2699974CurrentTrain: epoch  2, batch    35 | loss: 88.4734985CurrentTrain: epoch  2, batch    36 | loss: 128.4167631CurrentTrain: epoch  2, batch    37 | loss: 102.6088094CurrentTrain: epoch  2, batch    38 | loss: 85.7015009CurrentTrain: epoch  2, batch    39 | loss: 106.4803874CurrentTrain: epoch  2, batch    40 | loss: 86.0061923CurrentTrain: epoch  2, batch    41 | loss: 70.6522067CurrentTrain: epoch  2, batch    42 | loss: 64.8043186CurrentTrain: epoch  2, batch    43 | loss: 69.4631588CurrentTrain: epoch  2, batch    44 | loss: 130.8565707CurrentTrain: epoch  2, batch    45 | loss: 91.1305641CurrentTrain: epoch  2, batch    46 | loss: 87.1667740CurrentTrain: epoch  2, batch    47 | loss: 83.7603018CurrentTrain: epoch  2, batch    48 | loss: 129.9081164CurrentTrain: epoch  2, batch    49 | loss: 63.6564385CurrentTrain: epoch  2, batch    50 | loss: 107.8699471CurrentTrain: epoch  2, batch    51 | loss: 87.2522449CurrentTrain: epoch  2, batch    52 | loss: 105.4670416CurrentTrain: epoch  2, batch    53 | loss: 63.6880601CurrentTrain: epoch  2, batch    54 | loss: 107.1431983CurrentTrain: epoch  2, batch    55 | loss: 86.3410404CurrentTrain: epoch  2, batch    56 | loss: 104.8158605CurrentTrain: epoch  2, batch    57 | loss: 84.2336789CurrentTrain: epoch  2, batch    58 | loss: 84.3126467CurrentTrain: epoch  2, batch    59 | loss: 103.4326709CurrentTrain: epoch  2, batch    60 | loss: 101.1694558CurrentTrain: epoch  2, batch    61 | loss: 106.9397619CurrentTrain: epoch  2, batch    62 | loss: 73.8442522CurrentTrain: epoch  2, batch    63 | loss: 86.0212193CurrentTrain: epoch  2, batch    64 | loss: 61.7041041CurrentTrain: epoch  2, batch    65 | loss: 104.7954565CurrentTrain: epoch  2, batch    66 | loss: 70.2758837CurrentTrain: epoch  2, batch    67 | loss: 90.1584730CurrentTrain: epoch  2, batch    68 | loss: 72.6474499CurrentTrain: epoch  2, batch    69 | loss: 75.7134306CurrentTrain: epoch  2, batch    70 | loss: 135.4541137CurrentTrain: epoch  2, batch    71 | loss: 70.5573883CurrentTrain: epoch  2, batch    72 | loss: 82.8938237CurrentTrain: epoch  2, batch    73 | loss: 133.1392737CurrentTrain: epoch  2, batch    74 | loss: 84.5049220CurrentTrain: epoch  2, batch    75 | loss: 74.1404417CurrentTrain: epoch  2, batch    76 | loss: 105.1769537CurrentTrain: epoch  2, batch    77 | loss: 88.3100103CurrentTrain: epoch  2, batch    78 | loss: 103.7424302CurrentTrain: epoch  2, batch    79 | loss: 74.2103219CurrentTrain: epoch  2, batch    80 | loss: 133.4270456CurrentTrain: epoch  2, batch    81 | loss: 72.3221170CurrentTrain: epoch  2, batch    82 | loss: 91.7437074CurrentTrain: epoch  2, batch    83 | loss: 77.5007181CurrentTrain: epoch  2, batch    84 | loss: 70.5100483CurrentTrain: epoch  2, batch    85 | loss: 86.4584787CurrentTrain: epoch  2, batch    86 | loss: 136.9686241CurrentTrain: epoch  2, batch    87 | loss: 107.0307688CurrentTrain: epoch  2, batch    88 | loss: 85.2266550CurrentTrain: epoch  2, batch    89 | loss: 84.8204226CurrentTrain: epoch  2, batch    90 | loss: 73.2869852CurrentTrain: epoch  2, batch    91 | loss: 88.2532558CurrentTrain: epoch  2, batch    92 | loss: 105.6134837CurrentTrain: epoch  2, batch    93 | loss: 136.1651905CurrentTrain: epoch  2, batch    94 | loss: 75.2966883CurrentTrain: epoch  2, batch    95 | loss: 109.2589847CurrentTrain: epoch  3, batch     0 | loss: 136.8798678CurrentTrain: epoch  3, batch     1 | loss: 69.6046977CurrentTrain: epoch  3, batch     2 | loss: 62.7116153CurrentTrain: epoch  3, batch     3 | loss: 70.8834173CurrentTrain: epoch  3, batch     4 | loss: 104.5099041CurrentTrain: epoch  3, batch     5 | loss: 71.6654919CurrentTrain: epoch  3, batch     6 | loss: 70.7924503CurrentTrain: epoch  3, batch     7 | loss: 129.1291130CurrentTrain: epoch  3, batch     8 | loss: 81.6172202CurrentTrain: epoch  3, batch     9 | loss: 61.2232156CurrentTrain: epoch  3, batch    10 | loss: 87.6973593CurrentTrain: epoch  3, batch    11 | loss: 100.1648659CurrentTrain: epoch  3, batch    12 | loss: 71.8082712CurrentTrain: epoch  3, batch    13 | loss: 104.5940424CurrentTrain: epoch  3, batch    14 | loss: 73.2616173CurrentTrain: epoch  3, batch    15 | loss: 71.6158013CurrentTrain: epoch  3, batch    16 | loss: 88.3211155CurrentTrain: epoch  3, batch    17 | loss: 72.1204838CurrentTrain: epoch  3, batch    18 | loss: 84.4213978CurrentTrain: epoch  3, batch    19 | loss: 105.8785379CurrentTrain: epoch  3, batch    20 | loss: 84.3054932CurrentTrain: epoch  3, batch    21 | loss: 89.2334787CurrentTrain: epoch  3, batch    22 | loss: 79.7705397CurrentTrain: epoch  3, batch    23 | loss: 128.8783663CurrentTrain: epoch  3, batch    24 | loss: 68.3154680CurrentTrain: epoch  3, batch    25 | loss: 101.9896063CurrentTrain: epoch  3, batch    26 | loss: 102.4787648CurrentTrain: epoch  3, batch    27 | loss: 60.3289878CurrentTrain: epoch  3, batch    28 | loss: 83.4404050CurrentTrain: epoch  3, batch    29 | loss: 72.2531554CurrentTrain: epoch  3, batch    30 | loss: 130.7541480CurrentTrain: epoch  3, batch    31 | loss: 103.8777418CurrentTrain: epoch  3, batch    32 | loss: 136.7944627CurrentTrain: epoch  3, batch    33 | loss: 101.1500620CurrentTrain: epoch  3, batch    34 | loss: 104.3416163CurrentTrain: epoch  3, batch    35 | loss: 83.1164987CurrentTrain: epoch  3, batch    36 | loss: 99.9389034CurrentTrain: epoch  3, batch    37 | loss: 70.1985799CurrentTrain: epoch  3, batch    38 | loss: 73.4537768CurrentTrain: epoch  3, batch    39 | loss: 86.1737747CurrentTrain: epoch  3, batch    40 | loss: 57.7320633CurrentTrain: epoch  3, batch    41 | loss: 61.6691061CurrentTrain: epoch  3, batch    42 | loss: 134.0855618CurrentTrain: epoch  3, batch    43 | loss: 90.2070760CurrentTrain: epoch  3, batch    44 | loss: 100.2207490CurrentTrain: epoch  3, batch    45 | loss: 56.9587128CurrentTrain: epoch  3, batch    46 | loss: 128.4687232CurrentTrain: epoch  3, batch    47 | loss: 99.9027100CurrentTrain: epoch  3, batch    48 | loss: 82.3566541CurrentTrain: epoch  3, batch    49 | loss: 82.1600062CurrentTrain: epoch  3, batch    50 | loss: 100.0549774CurrentTrain: epoch  3, batch    51 | loss: 69.2773430CurrentTrain: epoch  3, batch    52 | loss: 104.2170127CurrentTrain: epoch  3, batch    53 | loss: 71.4382371CurrentTrain: epoch  3, batch    54 | loss: 72.6001638CurrentTrain: epoch  3, batch    55 | loss: 102.6570690CurrentTrain: epoch  3, batch    56 | loss: 101.6963917CurrentTrain: epoch  3, batch    57 | loss: 84.5666460CurrentTrain: epoch  3, batch    58 | loss: 70.9595951CurrentTrain: epoch  3, batch    59 | loss: 102.7254597CurrentTrain: epoch  3, batch    60 | loss: 85.8944803CurrentTrain: epoch  3, batch    61 | loss: 85.9201331CurrentTrain: epoch  3, batch    62 | loss: 81.4808576CurrentTrain: epoch  3, batch    63 | loss: 83.0581382CurrentTrain: epoch  3, batch    64 | loss: 82.2103906CurrentTrain: epoch  3, batch    65 | loss: 63.7378645CurrentTrain: epoch  3, batch    66 | loss: 86.8482478CurrentTrain: epoch  3, batch    67 | loss: 70.2473621CurrentTrain: epoch  3, batch    68 | loss: 102.1238876CurrentTrain: epoch  3, batch    69 | loss: 61.6654180CurrentTrain: epoch  3, batch    70 | loss: 86.8744525CurrentTrain: epoch  3, batch    71 | loss: 94.9733331CurrentTrain: epoch  3, batch    72 | loss: 72.0381671CurrentTrain: epoch  3, batch    73 | loss: 86.0456124CurrentTrain: epoch  3, batch    74 | loss: 70.6968751CurrentTrain: epoch  3, batch    75 | loss: 80.2240879CurrentTrain: epoch  3, batch    76 | loss: 86.2455562CurrentTrain: epoch  3, batch    77 | loss: 89.7762058CurrentTrain: epoch  3, batch    78 | loss: 104.4903505CurrentTrain: epoch  3, batch    79 | loss: 100.9351722CurrentTrain: epoch  3, batch    80 | loss: 82.8492210CurrentTrain: epoch  3, batch    81 | loss: 100.5659621CurrentTrain: epoch  3, batch    82 | loss: 74.4595400CurrentTrain: epoch  3, batch    83 | loss: 132.3607495CurrentTrain: epoch  3, batch    84 | loss: 81.2879605CurrentTrain: epoch  3, batch    85 | loss: 86.3913138CurrentTrain: epoch  3, batch    86 | loss: 82.4711272CurrentTrain: epoch  3, batch    87 | loss: 107.1581799CurrentTrain: epoch  3, batch    88 | loss: 171.6705031CurrentTrain: epoch  3, batch    89 | loss: 89.2542512CurrentTrain: epoch  3, batch    90 | loss: 88.3233198CurrentTrain: epoch  3, batch    91 | loss: 103.7755208CurrentTrain: epoch  3, batch    92 | loss: 102.8844379CurrentTrain: epoch  3, batch    93 | loss: 97.9648730CurrentTrain: epoch  3, batch    94 | loss: 84.7467123CurrentTrain: epoch  3, batch    95 | loss: 73.3497963CurrentTrain: epoch  4, batch     0 | loss: 78.9484418CurrentTrain: epoch  4, batch     1 | loss: 97.3160937CurrentTrain: epoch  4, batch     2 | loss: 81.1507726CurrentTrain: epoch  4, batch     3 | loss: 69.6995115CurrentTrain: epoch  4, batch     4 | loss: 132.6269161CurrentTrain: epoch  4, batch     5 | loss: 128.0917009CurrentTrain: epoch  4, batch     6 | loss: 81.9160904CurrentTrain: epoch  4, batch     7 | loss: 82.8873473CurrentTrain: epoch  4, batch     8 | loss: 68.7423942CurrentTrain: epoch  4, batch     9 | loss: 103.0431673CurrentTrain: epoch  4, batch    10 | loss: 99.7524270CurrentTrain: epoch  4, batch    11 | loss: 100.4061283CurrentTrain: epoch  4, batch    12 | loss: 71.6706197CurrentTrain: epoch  4, batch    13 | loss: 76.1051010CurrentTrain: epoch  4, batch    14 | loss: 84.9077632CurrentTrain: epoch  4, batch    15 | loss: 58.2338850CurrentTrain: epoch  4, batch    16 | loss: 132.0781037CurrentTrain: epoch  4, batch    17 | loss: 70.9146494CurrentTrain: epoch  4, batch    18 | loss: 126.4382856CurrentTrain: epoch  4, batch    19 | loss: 99.1427433CurrentTrain: epoch  4, batch    20 | loss: 86.1598931CurrentTrain: epoch  4, batch    21 | loss: 82.0901925CurrentTrain: epoch  4, batch    22 | loss: 84.1179622CurrentTrain: epoch  4, batch    23 | loss: 77.7860011CurrentTrain: epoch  4, batch    24 | loss: 84.3047679CurrentTrain: epoch  4, batch    25 | loss: 85.2440605CurrentTrain: epoch  4, batch    26 | loss: 69.6704037CurrentTrain: epoch  4, batch    27 | loss: 81.9761587CurrentTrain: epoch  4, batch    28 | loss: 74.7552612CurrentTrain: epoch  4, batch    29 | loss: 85.4785596CurrentTrain: epoch  4, batch    30 | loss: 103.6112550CurrentTrain: epoch  4, batch    31 | loss: 68.5069988CurrentTrain: epoch  4, batch    32 | loss: 82.5200670CurrentTrain: epoch  4, batch    33 | loss: 82.3421884CurrentTrain: epoch  4, batch    34 | loss: 101.4313673CurrentTrain: epoch  4, batch    35 | loss: 65.9983330CurrentTrain: epoch  4, batch    36 | loss: 82.5624344CurrentTrain: epoch  4, batch    37 | loss: 96.8981060CurrentTrain: epoch  4, batch    38 | loss: 68.5729156CurrentTrain: epoch  4, batch    39 | loss: 70.6018751CurrentTrain: epoch  4, batch    40 | loss: 85.8046125CurrentTrain: epoch  4, batch    41 | loss: 80.7173516CurrentTrain: epoch  4, batch    42 | loss: 79.4235031CurrentTrain: epoch  4, batch    43 | loss: 82.5146307CurrentTrain: epoch  4, batch    44 | loss: 99.9358156CurrentTrain: epoch  4, batch    45 | loss: 72.2645188CurrentTrain: epoch  4, batch    46 | loss: 64.4646900CurrentTrain: epoch  4, batch    47 | loss: 79.3286883CurrentTrain: epoch  4, batch    48 | loss: 57.6803561CurrentTrain: epoch  4, batch    49 | loss: 82.2482091CurrentTrain: epoch  4, batch    50 | loss: 68.6532300CurrentTrain: epoch  4, batch    51 | loss: 84.5539900CurrentTrain: epoch  4, batch    52 | loss: 84.1281479CurrentTrain: epoch  4, batch    53 | loss: 85.1811079CurrentTrain: epoch  4, batch    54 | loss: 102.0812802CurrentTrain: epoch  4, batch    55 | loss: 100.2222849CurrentTrain: epoch  4, batch    56 | loss: 125.1037821CurrentTrain: epoch  4, batch    57 | loss: 68.1791463CurrentTrain: epoch  4, batch    58 | loss: 80.8368203CurrentTrain: epoch  4, batch    59 | loss: 71.2718962CurrentTrain: epoch  4, batch    60 | loss: 61.5803071CurrentTrain: epoch  4, batch    61 | loss: 87.1192277CurrentTrain: epoch  4, batch    62 | loss: 82.3459437CurrentTrain: epoch  4, batch    63 | loss: 70.5322800CurrentTrain: epoch  4, batch    64 | loss: 88.2083612CurrentTrain: epoch  4, batch    65 | loss: 82.5541328CurrentTrain: epoch  4, batch    66 | loss: 100.9815166CurrentTrain: epoch  4, batch    67 | loss: 70.6111706CurrentTrain: epoch  4, batch    68 | loss: 80.6900120CurrentTrain: epoch  4, batch    69 | loss: 106.9010318CurrentTrain: epoch  4, batch    70 | loss: 81.1090752CurrentTrain: epoch  4, batch    71 | loss: 135.1409638CurrentTrain: epoch  4, batch    72 | loss: 129.5684607CurrentTrain: epoch  4, batch    73 | loss: 100.1149943CurrentTrain: epoch  4, batch    74 | loss: 84.7402005CurrentTrain: epoch  4, batch    75 | loss: 84.7287343CurrentTrain: epoch  4, batch    76 | loss: 96.8983848CurrentTrain: epoch  4, batch    77 | loss: 97.3322871CurrentTrain: epoch  4, batch    78 | loss: 133.1591639CurrentTrain: epoch  4, batch    79 | loss: 126.3293941CurrentTrain: epoch  4, batch    80 | loss: 84.1362880CurrentTrain: epoch  4, batch    81 | loss: 79.4147722CurrentTrain: epoch  4, batch    82 | loss: 64.5318317CurrentTrain: epoch  4, batch    83 | loss: 101.9923669CurrentTrain: epoch  4, batch    84 | loss: 89.5501975CurrentTrain: epoch  4, batch    85 | loss: 102.8142000CurrentTrain: epoch  4, batch    86 | loss: 102.4159566CurrentTrain: epoch  4, batch    87 | loss: 71.6048392CurrentTrain: epoch  4, batch    88 | loss: 96.3782458CurrentTrain: epoch  4, batch    89 | loss: 102.4224235CurrentTrain: epoch  4, batch    90 | loss: 123.5346639CurrentTrain: epoch  4, batch    91 | loss: 83.0767547CurrentTrain: epoch  4, batch    92 | loss: 120.6246792CurrentTrain: epoch  4, batch    93 | loss: 102.5746770CurrentTrain: epoch  4, batch    94 | loss: 59.2064252CurrentTrain: epoch  4, batch    95 | loss: 70.1208408CurrentTrain: epoch  5, batch     0 | loss: 60.0356363CurrentTrain: epoch  5, batch     1 | loss: 100.1453223CurrentTrain: epoch  5, batch     2 | loss: 83.7496547CurrentTrain: epoch  5, batch     3 | loss: 99.1492465CurrentTrain: epoch  5, batch     4 | loss: 102.0919665CurrentTrain: epoch  5, batch     5 | loss: 81.9864621CurrentTrain: epoch  5, batch     6 | loss: 125.2724967CurrentTrain: epoch  5, batch     7 | loss: 80.8302744CurrentTrain: epoch  5, batch     8 | loss: 69.0843713CurrentTrain: epoch  5, batch     9 | loss: 56.3769350CurrentTrain: epoch  5, batch    10 | loss: 83.0013702CurrentTrain: epoch  5, batch    11 | loss: 124.1921911CurrentTrain: epoch  5, batch    12 | loss: 68.6629042CurrentTrain: epoch  5, batch    13 | loss: 103.3019108CurrentTrain: epoch  5, batch    14 | loss: 71.3769166CurrentTrain: epoch  5, batch    15 | loss: 99.0523026CurrentTrain: epoch  5, batch    16 | loss: 81.2420535CurrentTrain: epoch  5, batch    17 | loss: 71.6454250CurrentTrain: epoch  5, batch    18 | loss: 81.6969597CurrentTrain: epoch  5, batch    19 | loss: 83.1559488CurrentTrain: epoch  5, batch    20 | loss: 97.7014066CurrentTrain: epoch  5, batch    21 | loss: 70.0718469CurrentTrain: epoch  5, batch    22 | loss: 81.5257893CurrentTrain: epoch  5, batch    23 | loss: 99.4909026CurrentTrain: epoch  5, batch    24 | loss: 77.9334214CurrentTrain: epoch  5, batch    25 | loss: 64.0325498CurrentTrain: epoch  5, batch    26 | loss: 71.3191595CurrentTrain: epoch  5, batch    27 | loss: 102.4486273CurrentTrain: epoch  5, batch    28 | loss: 103.7628446CurrentTrain: epoch  5, batch    29 | loss: 80.9654821CurrentTrain: epoch  5, batch    30 | loss: 100.6329274CurrentTrain: epoch  5, batch    31 | loss: 70.0644950CurrentTrain: epoch  5, batch    32 | loss: 80.4768366CurrentTrain: epoch  5, batch    33 | loss: 69.2200396CurrentTrain: epoch  5, batch    34 | loss: 83.3177941CurrentTrain: epoch  5, batch    35 | loss: 79.4137789CurrentTrain: epoch  5, batch    36 | loss: 69.8838963CurrentTrain: epoch  5, batch    37 | loss: 101.9280206CurrentTrain: epoch  5, batch    38 | loss: 85.7512529CurrentTrain: epoch  5, batch    39 | loss: 95.4674055CurrentTrain: epoch  5, batch    40 | loss: 68.8625851CurrentTrain: epoch  5, batch    41 | loss: 102.1325981CurrentTrain: epoch  5, batch    42 | loss: 81.5267591CurrentTrain: epoch  5, batch    43 | loss: 76.9090423CurrentTrain: epoch  5, batch    44 | loss: 65.5413676CurrentTrain: epoch  5, batch    45 | loss: 64.1574953CurrentTrain: epoch  5, batch    46 | loss: 101.1639031CurrentTrain: epoch  5, batch    47 | loss: 129.5715037CurrentTrain: epoch  5, batch    48 | loss: 66.0102734CurrentTrain: epoch  5, batch    49 | loss: 69.3911096CurrentTrain: epoch  5, batch    50 | loss: 60.1823087CurrentTrain: epoch  5, batch    51 | loss: 99.4431566CurrentTrain: epoch  5, batch    52 | loss: 124.3293462CurrentTrain: epoch  5, batch    53 | loss: 69.2543544CurrentTrain: epoch  5, batch    54 | loss: 102.7014017CurrentTrain: epoch  5, batch    55 | loss: 96.0060359CurrentTrain: epoch  5, batch    56 | loss: 66.9262980CurrentTrain: epoch  5, batch    57 | loss: 100.1025211CurrentTrain: epoch  5, batch    58 | loss: 66.8138640CurrentTrain: epoch  5, batch    59 | loss: 72.0632727CurrentTrain: epoch  5, batch    60 | loss: 95.8793169CurrentTrain: epoch  5, batch    61 | loss: 62.0919662CurrentTrain: epoch  5, batch    62 | loss: 71.5519684CurrentTrain: epoch  5, batch    63 | loss: 82.8685219CurrentTrain: epoch  5, batch    64 | loss: 123.8349159CurrentTrain: epoch  5, batch    65 | loss: 66.6635404CurrentTrain: epoch  5, batch    66 | loss: 130.4383050CurrentTrain: epoch  5, batch    67 | loss: 69.3390052CurrentTrain: epoch  5, batch    68 | loss: 96.3099534CurrentTrain: epoch  5, batch    69 | loss: 77.9815008CurrentTrain: epoch  5, batch    70 | loss: 124.5423717CurrentTrain: epoch  5, batch    71 | loss: 94.3952066CurrentTrain: epoch  5, batch    72 | loss: 122.9003376CurrentTrain: epoch  5, batch    73 | loss: 73.0115710CurrentTrain: epoch  5, batch    74 | loss: 81.1225818CurrentTrain: epoch  5, batch    75 | loss: 71.4048551CurrentTrain: epoch  5, batch    76 | loss: 79.8881881CurrentTrain: epoch  5, batch    77 | loss: 66.5270448CurrentTrain: epoch  5, batch    78 | loss: 70.6494480CurrentTrain: epoch  5, batch    79 | loss: 68.3999415CurrentTrain: epoch  5, batch    80 | loss: 103.2536667CurrentTrain: epoch  5, batch    81 | loss: 84.0581618CurrentTrain: epoch  5, batch    82 | loss: 95.8613885CurrentTrain: epoch  5, batch    83 | loss: 81.2573261CurrentTrain: epoch  5, batch    84 | loss: 98.8625303CurrentTrain: epoch  5, batch    85 | loss: 123.4544723CurrentTrain: epoch  5, batch    86 | loss: 92.0890007CurrentTrain: epoch  5, batch    87 | loss: 83.3841329CurrentTrain: epoch  5, batch    88 | loss: 80.1231688CurrentTrain: epoch  5, batch    89 | loss: 82.1278432CurrentTrain: epoch  5, batch    90 | loss: 126.1724932CurrentTrain: epoch  5, batch    91 | loss: 96.1134960CurrentTrain: epoch  5, batch    92 | loss: 80.1218478CurrentTrain: epoch  5, batch    93 | loss: 98.0163603CurrentTrain: epoch  5, batch    94 | loss: 82.8374087CurrentTrain: epoch  5, batch    95 | loss: 85.4796576CurrentTrain: epoch  6, batch     0 | loss: 66.6942503CurrentTrain: epoch  6, batch     1 | loss: 68.7258740CurrentTrain: epoch  6, batch     2 | loss: 78.2209569CurrentTrain: epoch  6, batch     3 | loss: 69.4564932CurrentTrain: epoch  6, batch     4 | loss: 91.4418105CurrentTrain: epoch  6, batch     5 | loss: 65.5927813CurrentTrain: epoch  6, batch     6 | loss: 80.4077005CurrentTrain: epoch  6, batch     7 | loss: 79.9276135CurrentTrain: epoch  6, batch     8 | loss: 69.7095302CurrentTrain: epoch  6, batch     9 | loss: 100.4101406CurrentTrain: epoch  6, batch    10 | loss: 53.0873239CurrentTrain: epoch  6, batch    11 | loss: 127.7442291CurrentTrain: epoch  6, batch    12 | loss: 100.8419642CurrentTrain: epoch  6, batch    13 | loss: 67.4376356CurrentTrain: epoch  6, batch    14 | loss: 95.8983923CurrentTrain: epoch  6, batch    15 | loss: 65.2597800CurrentTrain: epoch  6, batch    16 | loss: 81.6787101CurrentTrain: epoch  6, batch    17 | loss: 104.3595081CurrentTrain: epoch  6, batch    18 | loss: 82.6099615CurrentTrain: epoch  6, batch    19 | loss: 80.8910812CurrentTrain: epoch  6, batch    20 | loss: 77.4686538CurrentTrain: epoch  6, batch    21 | loss: 82.5848324CurrentTrain: epoch  6, batch    22 | loss: 76.3901445CurrentTrain: epoch  6, batch    23 | loss: 77.8954168CurrentTrain: epoch  6, batch    24 | loss: 97.9285440CurrentTrain: epoch  6, batch    25 | loss: 80.5036949CurrentTrain: epoch  6, batch    26 | loss: 79.9602348CurrentTrain: epoch  6, batch    27 | loss: 129.0401539CurrentTrain: epoch  6, batch    28 | loss: 64.1648190CurrentTrain: epoch  6, batch    29 | loss: 81.9200840CurrentTrain: epoch  6, batch    30 | loss: 74.2652944CurrentTrain: epoch  6, batch    31 | loss: 66.6445022CurrentTrain: epoch  6, batch    32 | loss: 125.3396219CurrentTrain: epoch  6, batch    33 | loss: 79.6895335CurrentTrain: epoch  6, batch    34 | loss: 83.0056289CurrentTrain: epoch  6, batch    35 | loss: 99.0126627CurrentTrain: epoch  6, batch    36 | loss: 68.5974835CurrentTrain: epoch  6, batch    37 | loss: 90.1979102CurrentTrain: epoch  6, batch    38 | loss: 55.8952500CurrentTrain: epoch  6, batch    39 | loss: 103.1105780CurrentTrain: epoch  6, batch    40 | loss: 66.8893286CurrentTrain: epoch  6, batch    41 | loss: 61.4730150CurrentTrain: epoch  6, batch    42 | loss: 82.0011635CurrentTrain: epoch  6, batch    43 | loss: 58.2605511CurrentTrain: epoch  6, batch    44 | loss: 66.9863367CurrentTrain: epoch  6, batch    45 | loss: 99.1683830CurrentTrain: epoch  6, batch    46 | loss: 66.5069042CurrentTrain: epoch  6, batch    47 | loss: 100.9828600CurrentTrain: epoch  6, batch    48 | loss: 100.9325783CurrentTrain: epoch  6, batch    49 | loss: 99.8891569CurrentTrain: epoch  6, batch    50 | loss: 69.8354956CurrentTrain: epoch  6, batch    51 | loss: 68.9125668CurrentTrain: epoch  6, batch    52 | loss: 67.4797985CurrentTrain: epoch  6, batch    53 | loss: 128.1022803CurrentTrain: epoch  6, batch    54 | loss: 68.1822021CurrentTrain: epoch  6, batch    55 | loss: 95.2790676CurrentTrain: epoch  6, batch    56 | loss: 82.0600916CurrentTrain: epoch  6, batch    57 | loss: 82.7116252CurrentTrain: epoch  6, batch    58 | loss: 86.9420947CurrentTrain: epoch  6, batch    59 | loss: 78.7943653CurrentTrain: epoch  6, batch    60 | loss: 82.0261232CurrentTrain: epoch  6, batch    61 | loss: 68.4576634CurrentTrain: epoch  6, batch    62 | loss: 79.0657510CurrentTrain: epoch  6, batch    63 | loss: 82.8269426CurrentTrain: epoch  6, batch    64 | loss: 95.8544150CurrentTrain: epoch  6, batch    65 | loss: 64.5634200CurrentTrain: epoch  6, batch    66 | loss: 102.2272365CurrentTrain: epoch  6, batch    67 | loss: 97.7901786CurrentTrain: epoch  6, batch    68 | loss: 94.8946506CurrentTrain: epoch  6, batch    69 | loss: 94.1084500CurrentTrain: epoch  6, batch    70 | loss: 77.3292150CurrentTrain: epoch  6, batch    71 | loss: 66.2865469CurrentTrain: epoch  6, batch    72 | loss: 125.8353044CurrentTrain: epoch  6, batch    73 | loss: 96.1313932CurrentTrain: epoch  6, batch    74 | loss: 82.9725184CurrentTrain: epoch  6, batch    75 | loss: 98.6967271CurrentTrain: epoch  6, batch    76 | loss: 123.5871488CurrentTrain: epoch  6, batch    77 | loss: 84.2253748CurrentTrain: epoch  6, batch    78 | loss: 81.0988578CurrentTrain: epoch  6, batch    79 | loss: 80.6923438CurrentTrain: epoch  6, batch    80 | loss: 66.1209458CurrentTrain: epoch  6, batch    81 | loss: 103.1800706CurrentTrain: epoch  6, batch    82 | loss: 67.0828780CurrentTrain: epoch  6, batch    83 | loss: 97.1722711CurrentTrain: epoch  6, batch    84 | loss: 96.4631265CurrentTrain: epoch  6, batch    85 | loss: 76.2096339CurrentTrain: epoch  6, batch    86 | loss: 79.0150617CurrentTrain: epoch  6, batch    87 | loss: 102.9572382CurrentTrain: epoch  6, batch    88 | loss: 79.7551050CurrentTrain: epoch  6, batch    89 | loss: 61.2784127CurrentTrain: epoch  6, batch    90 | loss: 122.9608324CurrentTrain: epoch  6, batch    91 | loss: 101.5738265CurrentTrain: epoch  6, batch    92 | loss: 82.8730302CurrentTrain: epoch  6, batch    93 | loss: 76.2386854CurrentTrain: epoch  6, batch    94 | loss: 80.5265042CurrentTrain: epoch  6, batch    95 | loss: 67.5515539CurrentTrain: epoch  7, batch     0 | loss: 66.5364043CurrentTrain: epoch  7, batch     1 | loss: 76.3871224CurrentTrain: epoch  7, batch     2 | loss: 64.6293735CurrentTrain: epoch  7, batch     3 | loss: 80.2594788CurrentTrain: epoch  7, batch     4 | loss: 79.3840898CurrentTrain: epoch  7, batch     5 | loss: 98.2803643CurrentTrain: epoch  7, batch     6 | loss: 121.5967092CurrentTrain: epoch  7, batch     7 | loss: 76.5862243CurrentTrain: epoch  7, batch     8 | loss: 63.8104367CurrentTrain: epoch  7, batch     9 | loss: 66.9285117CurrentTrain: epoch  7, batch    10 | loss: 57.9918889CurrentTrain: epoch  7, batch    11 | loss: 78.4238075CurrentTrain: epoch  7, batch    12 | loss: 98.6304288CurrentTrain: epoch  7, batch    13 | loss: 56.1756884CurrentTrain: epoch  7, batch    14 | loss: 65.6043907CurrentTrain: epoch  7, batch    15 | loss: 76.6253799CurrentTrain: epoch  7, batch    16 | loss: 76.9623374CurrentTrain: epoch  7, batch    17 | loss: 67.3009143CurrentTrain: epoch  7, batch    18 | loss: 125.1512630CurrentTrain: epoch  7, batch    19 | loss: 93.1144495CurrentTrain: epoch  7, batch    20 | loss: 69.7283710CurrentTrain: epoch  7, batch    21 | loss: 68.9624330CurrentTrain: epoch  7, batch    22 | loss: 77.5367906CurrentTrain: epoch  7, batch    23 | loss: 98.7429161CurrentTrain: epoch  7, batch    24 | loss: 78.7602441CurrentTrain: epoch  7, batch    25 | loss: 79.4896490CurrentTrain: epoch  7, batch    26 | loss: 98.8839242CurrentTrain: epoch  7, batch    27 | loss: 120.6709296CurrentTrain: epoch  7, batch    28 | loss: 80.9564174CurrentTrain: epoch  7, batch    29 | loss: 92.1804625CurrentTrain: epoch  7, batch    30 | loss: 54.8856324CurrentTrain: epoch  7, batch    31 | loss: 82.4272008CurrentTrain: epoch  7, batch    32 | loss: 99.1635481CurrentTrain: epoch  7, batch    33 | loss: 78.5776686CurrentTrain: epoch  7, batch    34 | loss: 76.5451236CurrentTrain: epoch  7, batch    35 | loss: 123.9495805CurrentTrain: epoch  7, batch    36 | loss: 78.2903303CurrentTrain: epoch  7, batch    37 | loss: 79.0247151CurrentTrain: epoch  7, batch    38 | loss: 94.0448834CurrentTrain: epoch  7, batch    39 | loss: 68.7380453CurrentTrain: epoch  7, batch    40 | loss: 81.1625306CurrentTrain: epoch  7, batch    41 | loss: 117.3500625CurrentTrain: epoch  7, batch    42 | loss: 67.7024399CurrentTrain: epoch  7, batch    43 | loss: 95.6673744CurrentTrain: epoch  7, batch    44 | loss: 95.0941171CurrentTrain: epoch  7, batch    45 | loss: 78.0192178CurrentTrain: epoch  7, batch    46 | loss: 98.1652283CurrentTrain: epoch  7, batch    47 | loss: 100.5017933CurrentTrain: epoch  7, batch    48 | loss: 95.0575959CurrentTrain: epoch  7, batch    49 | loss: 71.4897108CurrentTrain: epoch  7, batch    50 | loss: 57.5912892CurrentTrain: epoch  7, batch    51 | loss: 95.2598993CurrentTrain: epoch  7, batch    52 | loss: 77.2969030CurrentTrain: epoch  7, batch    53 | loss: 82.9508459CurrentTrain: epoch  7, batch    54 | loss: 63.2434897CurrentTrain: epoch  7, batch    55 | loss: 77.1300917CurrentTrain: epoch  7, batch    56 | loss: 76.9178899CurrentTrain: epoch  7, batch    57 | loss: 95.5074300CurrentTrain: epoch  7, batch    58 | loss: 96.0821417CurrentTrain: epoch  7, batch    59 | loss: 74.8585049CurrentTrain: epoch  7, batch    60 | loss: 76.6030314CurrentTrain: epoch  7, batch    61 | loss: 81.0138922CurrentTrain: epoch  7, batch    62 | loss: 79.1528273CurrentTrain: epoch  7, batch    63 | loss: 98.1721948CurrentTrain: epoch  7, batch    64 | loss: 67.5959799CurrentTrain: epoch  7, batch    65 | loss: 77.6315120CurrentTrain: epoch  7, batch    66 | loss: 97.5426819CurrentTrain: epoch  7, batch    67 | loss: 98.0746969CurrentTrain: epoch  7, batch    68 | loss: 77.8751549CurrentTrain: epoch  7, batch    69 | loss: 66.0967883CurrentTrain: epoch  7, batch    70 | loss: 64.6623104CurrentTrain: epoch  7, batch    71 | loss: 59.0172478CurrentTrain: epoch  7, batch    72 | loss: 99.1286170CurrentTrain: epoch  7, batch    73 | loss: 77.6725389CurrentTrain: epoch  7, batch    74 | loss: 82.4871688CurrentTrain: epoch  7, batch    75 | loss: 76.9243393CurrentTrain: epoch  7, batch    76 | loss: 128.6588603CurrentTrain: epoch  7, batch    77 | loss: 67.3417590CurrentTrain: epoch  7, batch    78 | loss: 121.6666729CurrentTrain: epoch  7, batch    79 | loss: 82.1161654CurrentTrain: epoch  7, batch    80 | loss: 130.2018751CurrentTrain: epoch  7, batch    81 | loss: 56.8157569CurrentTrain: epoch  7, batch    82 | loss: 67.6115776CurrentTrain: epoch  7, batch    83 | loss: 55.4865607CurrentTrain: epoch  7, batch    84 | loss: 67.4409649CurrentTrain: epoch  7, batch    85 | loss: 124.5978513CurrentTrain: epoch  7, batch    86 | loss: 59.4578055CurrentTrain: epoch  7, batch    87 | loss: 127.0592190CurrentTrain: epoch  7, batch    88 | loss: 80.3636622CurrentTrain: epoch  7, batch    89 | loss: 78.7324268CurrentTrain: epoch  7, batch    90 | loss: 128.1544857CurrentTrain: epoch  7, batch    91 | loss: 79.4126159CurrentTrain: epoch  7, batch    92 | loss: 54.4459908CurrentTrain: epoch  7, batch    93 | loss: 90.1974319CurrentTrain: epoch  7, batch    94 | loss: 78.0235592CurrentTrain: epoch  7, batch    95 | loss: 145.0145235CurrentTrain: epoch  8, batch     0 | loss: 75.9868148CurrentTrain: epoch  8, batch     1 | loss: 66.6961860CurrentTrain: epoch  8, batch     2 | loss: 59.3653572CurrentTrain: epoch  8, batch     3 | loss: 78.1126870CurrentTrain: epoch  8, batch     4 | loss: 65.5078709CurrentTrain: epoch  8, batch     5 | loss: 77.7546530CurrentTrain: epoch  8, batch     6 | loss: 61.6543899CurrentTrain: epoch  8, batch     7 | loss: 81.1049638CurrentTrain: epoch  8, batch     8 | loss: 77.6858759CurrentTrain: epoch  8, batch     9 | loss: 57.3924506CurrentTrain: epoch  8, batch    10 | loss: 78.9943109CurrentTrain: epoch  8, batch    11 | loss: 62.0040795CurrentTrain: epoch  8, batch    12 | loss: 79.9936563CurrentTrain: epoch  8, batch    13 | loss: 94.8189484CurrentTrain: epoch  8, batch    14 | loss: 98.2212151CurrentTrain: epoch  8, batch    15 | loss: 64.7663967CurrentTrain: epoch  8, batch    16 | loss: 122.7958294CurrentTrain: epoch  8, batch    17 | loss: 80.3458537CurrentTrain: epoch  8, batch    18 | loss: 81.9361063CurrentTrain: epoch  8, batch    19 | loss: 113.9042467CurrentTrain: epoch  8, batch    20 | loss: 77.4496386CurrentTrain: epoch  8, batch    21 | loss: 82.0020465CurrentTrain: epoch  8, batch    22 | loss: 76.6573172CurrentTrain: epoch  8, batch    23 | loss: 95.3246578CurrentTrain: epoch  8, batch    24 | loss: 78.5267202CurrentTrain: epoch  8, batch    25 | loss: 79.5052910CurrentTrain: epoch  8, batch    26 | loss: 97.3262135CurrentTrain: epoch  8, batch    27 | loss: 79.1144937CurrentTrain: epoch  8, batch    28 | loss: 97.9411584CurrentTrain: epoch  8, batch    29 | loss: 77.8296329CurrentTrain: epoch  8, batch    30 | loss: 78.0146082CurrentTrain: epoch  8, batch    31 | loss: 59.0479354CurrentTrain: epoch  8, batch    32 | loss: 62.8080963CurrentTrain: epoch  8, batch    33 | loss: 119.0354134CurrentTrain: epoch  8, batch    34 | loss: 123.1704737CurrentTrain: epoch  8, batch    35 | loss: 94.6736111CurrentTrain: epoch  8, batch    36 | loss: 91.7281902CurrentTrain: epoch  8, batch    37 | loss: 80.3939966CurrentTrain: epoch  8, batch    38 | loss: 80.0767616CurrentTrain: epoch  8, batch    39 | loss: 81.6316554CurrentTrain: epoch  8, batch    40 | loss: 78.7395323CurrentTrain: epoch  8, batch    41 | loss: 78.8341308CurrentTrain: epoch  8, batch    42 | loss: 66.0968453CurrentTrain: epoch  8, batch    43 | loss: 126.1173346CurrentTrain: epoch  8, batch    44 | loss: 124.6632784CurrentTrain: epoch  8, batch    45 | loss: 61.1693598CurrentTrain: epoch  8, batch    46 | loss: 58.1683058CurrentTrain: epoch  8, batch    47 | loss: 79.0691383CurrentTrain: epoch  8, batch    48 | loss: 81.9956773CurrentTrain: epoch  8, batch    49 | loss: 69.4350170CurrentTrain: epoch  8, batch    50 | loss: 53.9243493CurrentTrain: epoch  8, batch    51 | loss: 93.1267656CurrentTrain: epoch  8, batch    52 | loss: 121.4166669CurrentTrain: epoch  8, batch    53 | loss: 76.4242682CurrentTrain: epoch  8, batch    54 | loss: 70.9633685CurrentTrain: epoch  8, batch    55 | loss: 65.2976884CurrentTrain: epoch  8, batch    56 | loss: 64.3699674CurrentTrain: epoch  8, batch    57 | loss: 77.6181394CurrentTrain: epoch  8, batch    58 | loss: 61.2146077CurrentTrain: epoch  8, batch    59 | loss: 84.0794914CurrentTrain: epoch  8, batch    60 | loss: 98.1522983CurrentTrain: epoch  8, batch    61 | loss: 66.1211731CurrentTrain: epoch  8, batch    62 | loss: 123.7853516CurrentTrain: epoch  8, batch    63 | loss: 69.0295458CurrentTrain: epoch  8, batch    64 | loss: 98.0062151CurrentTrain: epoch  8, batch    65 | loss: 56.1676774CurrentTrain: epoch  8, batch    66 | loss: 95.2255234CurrentTrain: epoch  8, batch    67 | loss: 96.7732199CurrentTrain: epoch  8, batch    68 | loss: 94.8891784CurrentTrain: epoch  8, batch    69 | loss: 95.4585413CurrentTrain: epoch  8, batch    70 | loss: 62.2683072CurrentTrain: epoch  8, batch    71 | loss: 52.3677992CurrentTrain: epoch  8, batch    72 | loss: 91.7828720CurrentTrain: epoch  8, batch    73 | loss: 77.6935458CurrentTrain: epoch  8, batch    74 | loss: 81.8484509CurrentTrain: epoch  8, batch    75 | loss: 98.5827394CurrentTrain: epoch  8, batch    76 | loss: 79.7426294CurrentTrain: epoch  8, batch    77 | loss: 98.4675450CurrentTrain: epoch  8, batch    78 | loss: 70.3264266CurrentTrain: epoch  8, batch    79 | loss: 74.9048596CurrentTrain: epoch  8, batch    80 | loss: 76.1911293CurrentTrain: epoch  8, batch    81 | loss: 80.2962523CurrentTrain: epoch  8, batch    82 | loss: 66.4502955CurrentTrain: epoch  8, batch    83 | loss: 169.5858142CurrentTrain: epoch  8, batch    84 | loss: 66.7676259CurrentTrain: epoch  8, batch    85 | loss: 78.7562670CurrentTrain: epoch  8, batch    86 | loss: 66.5558988CurrentTrain: epoch  8, batch    87 | loss: 64.9861895CurrentTrain: epoch  8, batch    88 | loss: 82.2684743CurrentTrain: epoch  8, batch    89 | loss: 93.0573897CurrentTrain: epoch  8, batch    90 | loss: 61.5938684CurrentTrain: epoch  8, batch    91 | loss: 82.6508356CurrentTrain: epoch  8, batch    92 | loss: 67.1992012CurrentTrain: epoch  8, batch    93 | loss: 100.8912825CurrentTrain: epoch  8, batch    94 | loss: 66.5219109CurrentTrain: epoch  8, batch    95 | loss: 79.4948609CurrentTrain: epoch  9, batch     0 | loss: 92.0985759CurrentTrain: epoch  9, batch     1 | loss: 63.0966856CurrentTrain: epoch  9, batch     2 | loss: 94.6039164CurrentTrain: epoch  9, batch     3 | loss: 56.7810178CurrentTrain: epoch  9, batch     4 | loss: 94.8179517CurrentTrain: epoch  9, batch     5 | loss: 63.4296129CurrentTrain: epoch  9, batch     6 | loss: 62.1753998CurrentTrain: epoch  9, batch     7 | loss: 96.0692368CurrentTrain: epoch  9, batch     8 | loss: 93.4034159CurrentTrain: epoch  9, batch     9 | loss: 81.1712127CurrentTrain: epoch  9, batch    10 | loss: 97.3504675CurrentTrain: epoch  9, batch    11 | loss: 122.2193704CurrentTrain: epoch  9, batch    12 | loss: 95.5348265CurrentTrain: epoch  9, batch    13 | loss: 94.1703378CurrentTrain: epoch  9, batch    14 | loss: 93.8544759CurrentTrain: epoch  9, batch    15 | loss: 65.8063101CurrentTrain: epoch  9, batch    16 | loss: 76.2136139CurrentTrain: epoch  9, batch    17 | loss: 127.4627309CurrentTrain: epoch  9, batch    18 | loss: 81.4172498CurrentTrain: epoch  9, batch    19 | loss: 93.2645893CurrentTrain: epoch  9, batch    20 | loss: 88.8544200CurrentTrain: epoch  9, batch    21 | loss: 59.7908996CurrentTrain: epoch  9, batch    22 | loss: 76.0055081CurrentTrain: epoch  9, batch    23 | loss: 99.1752597CurrentTrain: epoch  9, batch    24 | loss: 97.3287550CurrentTrain: epoch  9, batch    25 | loss: 95.7785108CurrentTrain: epoch  9, batch    26 | loss: 78.1922187CurrentTrain: epoch  9, batch    27 | loss: 66.6477970CurrentTrain: epoch  9, batch    28 | loss: 65.6990766CurrentTrain: epoch  9, batch    29 | loss: 79.8601497CurrentTrain: epoch  9, batch    30 | loss: 58.4776072CurrentTrain: epoch  9, batch    31 | loss: 94.8967659CurrentTrain: epoch  9, batch    32 | loss: 65.8435082CurrentTrain: epoch  9, batch    33 | loss: 76.0361663CurrentTrain: epoch  9, batch    34 | loss: 117.8488017CurrentTrain: epoch  9, batch    35 | loss: 78.1357201CurrentTrain: epoch  9, batch    36 | loss: 63.7089780CurrentTrain: epoch  9, batch    37 | loss: 168.6846110CurrentTrain: epoch  9, batch    38 | loss: 78.2998745CurrentTrain: epoch  9, batch    39 | loss: 74.4116905CurrentTrain: epoch  9, batch    40 | loss: 102.5166590CurrentTrain: epoch  9, batch    41 | loss: 67.1288114CurrentTrain: epoch  9, batch    42 | loss: 63.1602619CurrentTrain: epoch  9, batch    43 | loss: 57.1315830CurrentTrain: epoch  9, batch    44 | loss: 74.5470679CurrentTrain: epoch  9, batch    45 | loss: 67.4456535CurrentTrain: epoch  9, batch    46 | loss: 121.0013199CurrentTrain: epoch  9, batch    47 | loss: 128.6598061CurrentTrain: epoch  9, batch    48 | loss: 80.3936603CurrentTrain: epoch  9, batch    49 | loss: 66.4374293CurrentTrain: epoch  9, batch    50 | loss: 76.3074922CurrentTrain: epoch  9, batch    51 | loss: 71.4387470CurrentTrain: epoch  9, batch    52 | loss: 70.9919824CurrentTrain: epoch  9, batch    53 | loss: 92.9320142CurrentTrain: epoch  9, batch    54 | loss: 63.5410555CurrentTrain: epoch  9, batch    55 | loss: 79.0787701CurrentTrain: epoch  9, batch    56 | loss: 64.6051074CurrentTrain: epoch  9, batch    57 | loss: 76.2426448CurrentTrain: epoch  9, batch    58 | loss: 64.7050434CurrentTrain: epoch  9, batch    59 | loss: 73.5633220CurrentTrain: epoch  9, batch    60 | loss: 93.6692523CurrentTrain: epoch  9, batch    61 | loss: 94.9903920CurrentTrain: epoch  9, batch    62 | loss: 72.7368393CurrentTrain: epoch  9, batch    63 | loss: 95.7016026CurrentTrain: epoch  9, batch    64 | loss: 164.8018304CurrentTrain: epoch  9, batch    65 | loss: 78.9943982CurrentTrain: epoch  9, batch    66 | loss: 97.2961502CurrentTrain: epoch  9, batch    67 | loss: 77.2689858CurrentTrain: epoch  9, batch    68 | loss: 76.3493836CurrentTrain: epoch  9, batch    69 | loss: 66.2432074CurrentTrain: epoch  9, batch    70 | loss: 75.0621105CurrentTrain: epoch  9, batch    71 | loss: 72.9299002CurrentTrain: epoch  9, batch    72 | loss: 64.8132505CurrentTrain: epoch  9, batch    73 | loss: 62.8603834CurrentTrain: epoch  9, batch    74 | loss: 77.5593091CurrentTrain: epoch  9, batch    75 | loss: 57.8488849CurrentTrain: epoch  9, batch    76 | loss: 75.3054844CurrentTrain: epoch  9, batch    77 | loss: 63.7021743CurrentTrain: epoch  9, batch    78 | loss: 97.4021950CurrentTrain: epoch  9, batch    79 | loss: 76.7428248CurrentTrain: epoch  9, batch    80 | loss: 121.4885859CurrentTrain: epoch  9, batch    81 | loss: 75.7229775CurrentTrain: epoch  9, batch    82 | loss: 94.7769440CurrentTrain: epoch  9, batch    83 | loss: 62.7266501CurrentTrain: epoch  9, batch    84 | loss: 99.1821230CurrentTrain: epoch  9, batch    85 | loss: 66.1293444CurrentTrain: epoch  9, batch    86 | loss: 73.5795514CurrentTrain: epoch  9, batch    87 | loss: 82.6185230CurrentTrain: epoch  9, batch    88 | loss: 66.3763272CurrentTrain: epoch  9, batch    89 | loss: 171.4991672CurrentTrain: epoch  9, batch    90 | loss: 66.4632430CurrentTrain: epoch  9, batch    91 | loss: 74.6394767CurrentTrain: epoch  9, batch    92 | loss: 65.5101473CurrentTrain: epoch  9, batch    93 | loss: 77.9547924CurrentTrain: epoch  9, batch    94 | loss: 63.8155297CurrentTrain: epoch  9, batch    95 | loss: 81.0314875

F1 score per class: {32: np.float64(0.5054945054945055), 6: np.float64(0.8018433179723502), 19: np.float64(0.3333333333333333), 24: np.float64(0.7441860465116279), 26: np.float64(0.94), 29: np.float64(0.8177339901477833)}
Micro-average F1 score: 0.7524752475247525
Weighted-average F1 score: 0.7582809227385636
F1 score per class: {32: np.float64(0.6267281105990783), 6: np.float64(0.8157894736842105), 19: np.float64(0.25), 24: np.float64(0.7292817679558011), 26: np.float64(0.9292929292929293), 29: np.float64(0.8073394495412844)}
Micro-average F1 score: 0.7398230088495575
Weighted-average F1 score: 0.7200274949226628
F1 score per class: {32: np.float64(0.6296296296296297), 6: np.float64(0.8251121076233184), 19: np.float64(0.31746031746031744), 24: np.float64(0.7303370786516854), 26: np.float64(0.9292929292929293), 29: np.float64(0.8093023255813954)}
Micro-average F1 score: 0.757548032936871
Weighted-average F1 score: 0.7476840125353366

F1 score per class: {32: np.float64(0.5054945054945055), 6: np.float64(0.8018433179723502), 19: np.float64(0.3333333333333333), 24: np.float64(0.7441860465116279), 26: np.float64(0.94), 29: np.float64(0.8177339901477833)}
Micro-average F1 score: 0.7524752475247525
Weighted-average F1 score: 0.7582809227385636
F1 score per class: {32: np.float64(0.6267281105990783), 6: np.float64(0.8157894736842105), 19: np.float64(0.25), 24: np.float64(0.7292817679558011), 26: np.float64(0.9292929292929293), 29: np.float64(0.8073394495412844)}
Micro-average F1 score: 0.7398230088495575
Weighted-average F1 score: 0.7200274949226628
F1 score per class: {32: np.float64(0.6296296296296297), 6: np.float64(0.8251121076233184), 19: np.float64(0.31746031746031744), 24: np.float64(0.7303370786516854), 26: np.float64(0.9292929292929293), 29: np.float64(0.8093023255813954)}
Micro-average F1 score: 0.757548032936871
Weighted-average F1 score: 0.7476840125353366

F1 score per class: {32: np.float64(0.39148936170212767), 6: np.float64(0.7467811158798283), 19: np.float64(0.21052631578947367), 24: np.float64(0.6918918918918919), 26: np.float64(0.8623853211009175), 29: np.float64(0.6887966804979253)}
Micro-average F1 score: 0.6501283147989735
Weighted-average F1 score: 0.6422059742066366
F1 score per class: {32: np.float64(0.4503311258278146), 6: np.float64(0.7410358565737052), 19: np.float64(0.13836477987421383), 24: np.float64(0.6700507614213198), 26: np.float64(0.8440366972477065), 29: np.float64(0.6518518518518519)}
Micro-average F1 score: 0.5984251968503937
Weighted-average F1 score: 0.5663012567349538
F1 score per class: {32: np.float64(0.45182724252491696), 6: np.float64(0.7603305785123967), 19: np.float64(0.16806722689075632), 24: np.float64(0.6701030927835051), 26: np.float64(0.8440366972477065), 29: np.float64(0.6492537313432836)}
Micro-average F1 score: 0.61698956780924
Weighted-average F1 score: 0.5915287083431863

F1 score per class: {32: np.float64(0.39148936170212767), 6: np.float64(0.7467811158798283), 19: np.float64(0.21052631578947367), 24: np.float64(0.6918918918918919), 26: np.float64(0.8623853211009175), 29: np.float64(0.6887966804979253)}
Micro-average F1 score: 0.6501283147989735
Weighted-average F1 score: 0.6422059742066366
F1 score per class: {32: np.float64(0.4503311258278146), 6: np.float64(0.7410358565737052), 19: np.float64(0.13836477987421383), 24: np.float64(0.6700507614213198), 26: np.float64(0.8440366972477065), 29: np.float64(0.6518518518518519)}
Micro-average F1 score: 0.5984251968503937
Weighted-average F1 score: 0.5663012567349538
F1 score per class: {32: np.float64(0.45182724252491696), 6: np.float64(0.7603305785123967), 19: np.float64(0.16806722689075632), 24: np.float64(0.6701030927835051), 26: np.float64(0.8440366972477065), 29: np.float64(0.6492537313432836)}
Micro-average F1 score: 0.61698956780924
Weighted-average F1 score: 0.5915287083431863
cur_acc_wo_na:  ['0.7525']
his_acc_wo_na:  ['0.7525']
cur_acc des_wo_na:  ['0.7398']
his_acc des_wo_na:  ['0.7398']
cur_acc rrf_wo_na:  ['0.7575']
his_acc rrf_wo_na:  ['0.7575']
cur_acc_w_na:  ['0.6501']
his_acc_w_na:  ['0.6501']
cur_acc des_w_na:  ['0.5984']
his_acc des_w_na:  ['0.5984']
cur_acc rrf_w_na:  ['0.6170']
his_acc rrf_w_na:  ['0.6170']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 81.3789705CurrentTrain: epoch  0, batch     1 | loss: 97.2284181CurrentTrain: epoch  0, batch     2 | loss: 96.1598900CurrentTrain: epoch  0, batch     3 | loss: 67.1072359CurrentTrain: epoch  1, batch     0 | loss: 135.7705003CurrentTrain: epoch  1, batch     1 | loss: 70.7179570CurrentTrain: epoch  1, batch     2 | loss: 108.5659418CurrentTrain: epoch  1, batch     3 | loss: 62.9350017CurrentTrain: epoch  2, batch     0 | loss: 101.4104626CurrentTrain: epoch  2, batch     1 | loss: 88.3001303CurrentTrain: epoch  2, batch     2 | loss: 83.0301254CurrentTrain: epoch  2, batch     3 | loss: 61.0392543CurrentTrain: epoch  3, batch     0 | loss: 101.4174211CurrentTrain: epoch  3, batch     1 | loss: 67.6880338CurrentTrain: epoch  3, batch     2 | loss: 101.5106801CurrentTrain: epoch  3, batch     3 | loss: 59.3851083CurrentTrain: epoch  4, batch     0 | loss: 94.4752483CurrentTrain: epoch  4, batch     1 | loss: 96.5998752CurrentTrain: epoch  4, batch     2 | loss: 67.1751513CurrentTrain: epoch  4, batch     3 | loss: 78.7112268CurrentTrain: epoch  5, batch     0 | loss: 124.8077207CurrentTrain: epoch  5, batch     1 | loss: 80.2494627CurrentTrain: epoch  5, batch     2 | loss: 68.0265933CurrentTrain: epoch  5, batch     3 | loss: 43.8892398CurrentTrain: epoch  6, batch     0 | loss: 68.9589134CurrentTrain: epoch  6, batch     1 | loss: 67.0858219CurrentTrain: epoch  6, batch     2 | loss: 64.4784450CurrentTrain: epoch  6, batch     3 | loss: 101.5231953CurrentTrain: epoch  7, batch     0 | loss: 118.0003044CurrentTrain: epoch  7, batch     1 | loss: 77.0826737CurrentTrain: epoch  7, batch     2 | loss: 76.8753121CurrentTrain: epoch  7, batch     3 | loss: 45.6967069CurrentTrain: epoch  8, batch     0 | loss: 91.6193217CurrentTrain: epoch  8, batch     1 | loss: 114.2796643CurrentTrain: epoch  8, batch     2 | loss: 93.0212644CurrentTrain: epoch  8, batch     3 | loss: 37.8156208CurrentTrain: epoch  9, batch     0 | loss: 64.1515207CurrentTrain: epoch  9, batch     1 | loss: 63.3229166CurrentTrain: epoch  9, batch     2 | loss: 97.7941634CurrentTrain: epoch  9, batch     3 | loss: 53.4052837
MemoryTrain:  epoch  0, batch     0 | loss: 1.3172445MemoryTrain:  epoch  1, batch     0 | loss: 1.0772717MemoryTrain:  epoch  2, batch     0 | loss: 0.8649431MemoryTrain:  epoch  3, batch     0 | loss: 0.6841680MemoryTrain:  epoch  4, batch     0 | loss: 0.5306527MemoryTrain:  epoch  5, batch     0 | loss: 0.4880975MemoryTrain:  epoch  6, batch     0 | loss: 0.3932780MemoryTrain:  epoch  7, batch     0 | loss: 0.3850246MemoryTrain:  epoch  8, batch     0 | loss: 0.3437854MemoryTrain:  epoch  9, batch     0 | loss: 0.2822269

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.3387096774193548), 36: np.float64(0.0), 6: np.float64(0.6), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.8333333333333334), 26: np.float64(0.0), 29: np.float64(0.42857142857142855), 30: np.float64(0.6607142857142857)}
Micro-average F1 score: 0.4975124378109453
Weighted-average F1 score: 0.44450148669163947
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.6172839506172839), 36: np.float64(0.0), 6: np.float64(0.72), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.6296296296296297), 26: np.float64(0.0), 29: np.float64(0.47058823529411764), 30: np.float64(0.7581699346405228)}
Micro-average F1 score: 0.59245960502693
Weighted-average F1 score: 0.533562425651924
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.6103896103896104), 36: np.float64(0.0), 6: np.float64(0.723404255319149), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.7727272727272727), 26: np.float64(0.0), 29: np.float64(0.47058823529411764), 30: np.float64(0.7671232876712328)}
Micro-average F1 score: 0.6053639846743295
Weighted-average F1 score: 0.5395401581266415

F1 score per class: {32: np.float64(0.5573770491803278), 33: np.float64(0.2896551724137931), 36: np.float64(0.8193832599118943), 6: np.float64(0.5783132530120482), 8: np.float64(0.32558139534883723), 19: np.float64(0.7135135135135136), 20: np.float64(0.916256157635468), 24: np.float64(0.7317073170731707), 26: np.float64(0.7747747747747747), 29: np.float64(0.3333333333333333), 30: np.float64(0.6166666666666667)}
Micro-average F1 score: 0.6748299319727891
Weighted-average F1 score: 0.6866143815019395
F1 score per class: {32: np.float64(0.5843621399176955), 33: np.float64(0.4854368932038835), 36: np.float64(0.7392996108949417), 6: np.float64(0.6666666666666666), 8: np.float64(0.26865671641791045), 19: np.float64(0.6910994764397905), 20: np.float64(0.8878504672897196), 24: np.float64(0.3695652173913043), 26: np.float64(0.7610619469026548), 29: np.float64(0.3076923076923077), 30: np.float64(0.6373626373626373)}
Micro-average F1 score: 0.6479028697571744
Weighted-average F1 score: 0.6349991891152386
F1 score per class: {32: np.float64(0.5862068965517241), 33: np.float64(0.4895833333333333), 36: np.float64(0.7661290322580645), 6: np.float64(0.6938775510204082), 8: np.float64(0.3333333333333333), 19: np.float64(0.7021276595744681), 20: np.float64(0.892018779342723), 24: np.float64(0.5151515151515151), 26: np.float64(0.7543859649122807), 29: np.float64(0.25806451612903225), 30: np.float64(0.7)}
Micro-average F1 score: 0.6748538011695906
Weighted-average F1 score: 0.6680134656770799

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.31343283582089554), 36: np.float64(0.0), 6: np.float64(0.48), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.7692307692307693), 26: np.float64(0.0), 29: np.float64(0.42857142857142855), 30: np.float64(0.5103448275862069)}
Micro-average F1 score: 0.3929273084479371
Weighted-average F1 score: 0.34417090413002693
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.49019607843137253), 36: np.float64(0.0), 6: np.float64(0.5625), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.5151515151515151), 26: np.float64(0.0), 29: np.float64(0.47058823529411764), 30: np.float64(0.5)}
Micro-average F1 score: 0.4225352112676056
Weighted-average F1 score: 0.38537230594717226
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.48205128205128206), 36: np.float64(0.0), 6: np.float64(0.5528455284552846), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.723404255319149), 26: np.float64(0.0), 29: np.float64(0.4444444444444444), 30: np.float64(0.5114155251141552)}
Micro-average F1 score: 0.4340659340659341
Weighted-average F1 score: 0.39177704873193925

F1 score per class: {32: np.float64(0.41295546558704455), 33: np.float64(0.24561403508771928), 36: np.float64(0.7380952380952381), 6: np.float64(0.4247787610619469), 8: np.float64(0.2028985507246377), 19: np.float64(0.6346153846153846), 20: np.float64(0.8017241379310345), 24: np.float64(0.6666666666666666), 26: np.float64(0.5972222222222222), 29: np.float64(0.25), 30: np.float64(0.46540880503144655)}
Micro-average F1 score: 0.5486725663716814
Weighted-average F1 score: 0.5485553763018618
F1 score per class: {32: np.float64(0.39444444444444443), 33: np.float64(0.34965034965034963), 36: np.float64(0.6440677966101694), 6: np.float64(0.47058823529411764), 8: np.float64(0.1565217391304348), 19: np.float64(0.6082949308755761), 20: np.float64(0.7723577235772358), 24: np.float64(0.2764227642276423), 26: np.float64(0.5830508474576271), 29: np.float64(0.25), 30: np.float64(0.4172661870503597)}
Micro-average F1 score: 0.4891666666666667
Weighted-average F1 score: 0.4734621384045653
F1 score per class: {32: np.float64(0.40718562874251496), 33: np.float64(0.34306569343065696), 36: np.float64(0.662020905923345), 6: np.float64(0.4722222222222222), 8: np.float64(0.1782178217821782), 19: np.float64(0.616822429906542), 20: np.float64(0.7786885245901639), 24: np.float64(0.43037974683544306), 26: np.float64(0.581081081081081), 29: np.float64(0.21052631578947367), 30: np.float64(0.4497991967871486)}
Micro-average F1 score: 0.5106194690265486
Weighted-average F1 score: 0.4981761412072558
cur_acc_wo_na:  ['0.7525', '0.4975']
his_acc_wo_na:  ['0.7525', '0.6748']
cur_acc des_wo_na:  ['0.7398', '0.5925']
his_acc des_wo_na:  ['0.7398', '0.6479']
cur_acc rrf_wo_na:  ['0.7575', '0.6054']
his_acc rrf_wo_na:  ['0.7575', '0.6749']
cur_acc_w_na:  ['0.6501', '0.3929']
his_acc_w_na:  ['0.6501', '0.5487']
cur_acc des_w_na:  ['0.5984', '0.4225']
his_acc des_w_na:  ['0.5984', '0.4892']
cur_acc rrf_w_na:  ['0.6170', '0.4341']
his_acc rrf_w_na:  ['0.6170', '0.5106']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 104.3323560CurrentTrain: epoch  0, batch     1 | loss: 98.7929631CurrentTrain: epoch  0, batch     2 | loss: 90.3731590CurrentTrain: epoch  0, batch     3 | loss: 114.2988638CurrentTrain: epoch  0, batch     4 | loss: 21.8464497CurrentTrain: epoch  1, batch     0 | loss: 113.1128108CurrentTrain: epoch  1, batch     1 | loss: 72.7263016CurrentTrain: epoch  1, batch     2 | loss: 89.2707816CurrentTrain: epoch  1, batch     3 | loss: 86.0770592CurrentTrain: epoch  1, batch     4 | loss: 20.3115313CurrentTrain: epoch  2, batch     0 | loss: 86.2726253CurrentTrain: epoch  2, batch     1 | loss: 86.6263045CurrentTrain: epoch  2, batch     2 | loss: 82.3824093CurrentTrain: epoch  2, batch     3 | loss: 126.8072694CurrentTrain: epoch  2, batch     4 | loss: 43.7354531CurrentTrain: epoch  3, batch     0 | loss: 71.6075748CurrentTrain: epoch  3, batch     1 | loss: 70.6134435CurrentTrain: epoch  3, batch     2 | loss: 100.7618923CurrentTrain: epoch  3, batch     3 | loss: 100.0424624CurrentTrain: epoch  3, batch     4 | loss: 17.7631913CurrentTrain: epoch  4, batch     0 | loss: 86.2803343CurrentTrain: epoch  4, batch     1 | loss: 100.0205789CurrentTrain: epoch  4, batch     2 | loss: 80.5157385CurrentTrain: epoch  4, batch     3 | loss: 76.4966394CurrentTrain: epoch  4, batch     4 | loss: 24.7829801CurrentTrain: epoch  5, batch     0 | loss: 67.2702122CurrentTrain: epoch  5, batch     1 | loss: 96.6877105CurrentTrain: epoch  5, batch     2 | loss: 84.2889489CurrentTrain: epoch  5, batch     3 | loss: 70.2859044CurrentTrain: epoch  5, batch     4 | loss: 13.0474440CurrentTrain: epoch  6, batch     0 | loss: 95.5987721CurrentTrain: epoch  6, batch     1 | loss: 61.6758244CurrentTrain: epoch  6, batch     2 | loss: 80.4057030CurrentTrain: epoch  6, batch     3 | loss: 124.7076949CurrentTrain: epoch  6, batch     4 | loss: 25.4018140CurrentTrain: epoch  7, batch     0 | loss: 120.8462959CurrentTrain: epoch  7, batch     1 | loss: 123.2954052CurrentTrain: epoch  7, batch     2 | loss: 64.3852324CurrentTrain: epoch  7, batch     3 | loss: 64.8868624CurrentTrain: epoch  7, batch     4 | loss: 18.7267449CurrentTrain: epoch  8, batch     0 | loss: 76.0790997CurrentTrain: epoch  8, batch     1 | loss: 120.9488091CurrentTrain: epoch  8, batch     2 | loss: 61.9274096CurrentTrain: epoch  8, batch     3 | loss: 95.6975895CurrentTrain: epoch  8, batch     4 | loss: 24.2026525CurrentTrain: epoch  9, batch     0 | loss: 65.8393645CurrentTrain: epoch  9, batch     1 | loss: 119.0208760CurrentTrain: epoch  9, batch     2 | loss: 95.0520817CurrentTrain: epoch  9, batch     3 | loss: 77.1732516CurrentTrain: epoch  9, batch     4 | loss: 8.9118951
MemoryTrain:  epoch  0, batch     0 | loss: 1.4237369MemoryTrain:  epoch  1, batch     0 | loss: 1.1547194MemoryTrain:  epoch  2, batch     0 | loss: 0.8707154MemoryTrain:  epoch  3, batch     0 | loss: 0.7067124MemoryTrain:  epoch  4, batch     0 | loss: 0.5505839MemoryTrain:  epoch  5, batch     0 | loss: 0.4876229MemoryTrain:  epoch  6, batch     0 | loss: 0.4205085MemoryTrain:  epoch  7, batch     0 | loss: 0.4263756MemoryTrain:  epoch  8, batch     0 | loss: 0.3853281MemoryTrain:  epoch  9, batch     0 | loss: 0.3208865

F1 score per class: {32: np.float64(0.6666666666666666), 33: np.float64(0.0), 2: np.float64(0.0), 6: np.float64(0.5384615384615384), 39: np.float64(0.6631578947368421), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.3333333333333333), 20: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.45454545454545453)}
Micro-average F1 score: 0.5386416861826698
Weighted-average F1 score: 0.4868715966894104
F1 score per class: {32: np.float64(0.56), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.4838709677419355), 6: np.float64(0.6229508196721312), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.43478260869565216), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.5)}
Micro-average F1 score: 0.4279835390946502
Weighted-average F1 score: 0.32811240450161555
F1 score per class: {32: np.float64(0.6666666666666666), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.5079365079365079), 6: np.float64(0.6270270270270271), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.37037037037037035), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.5217391304347826)}
Micro-average F1 score: 0.47368421052631576
Weighted-average F1 score: 0.3895846996195556

F1 score per class: {32: np.float64(0.5833333333333334), 33: np.float64(0.5146198830409356), 2: np.float64(0.2926829268292683), 36: np.float64(0.3867403314917127), 6: np.float64(0.4117647058823529), 39: np.float64(0.7942583732057417), 8: np.float64(0.6067415730337079), 11: np.float64(0.3333333333333333), 12: np.float64(0.72), 19: np.float64(0.09433962264150944), 20: np.float64(0.851063829787234), 24: np.float64(0.8333333333333334), 26: np.float64(0.7183673469387755), 28: np.float64(0.375), 29: np.float64(0.3037974683544304), 30: np.float64(0.2702702702702703)}
Micro-average F1 score: 0.5476073014306857
Weighted-average F1 score: 0.5313414616776135
F1 score per class: {32: np.float64(0.3684210526315789), 33: np.float64(0.5851528384279476), 2: np.float64(0.3492063492063492), 36: np.float64(0.36585365853658536), 6: np.float64(0.3573667711598746), 39: np.float64(0.7468879668049793), 8: np.float64(0.5625), 11: np.float64(0.22535211267605634), 12: np.float64(0.7252747252747253), 19: np.float64(0.16129032258064516), 20: np.float64(0.8260869565217391), 24: np.float64(0.4594594594594595), 26: np.float64(0.704), 28: np.float64(0.3157894736842105), 29: np.float64(0.5925925925925926), 30: np.float64(0.24390243902439024)}
Micro-average F1 score: 0.5339055793991416
Weighted-average F1 score: 0.5104813719999505
F1 score per class: {32: np.float64(0.5384615384615384), 33: np.float64(0.5786802030456852), 2: np.float64(0.3541666666666667), 36: np.float64(0.3615819209039548), 6: np.float64(0.3483483483483483), 39: np.float64(0.7521367521367521), 8: np.float64(0.6), 11: np.float64(0.2545454545454545), 12: np.float64(0.7262569832402235), 19: np.float64(0.12048192771084337), 20: np.float64(0.8260869565217391), 24: np.float64(0.6938775510204082), 26: np.float64(0.6984126984126984), 28: np.float64(0.3333333333333333), 29: np.float64(0.5154639175257731), 30: np.float64(0.2926829268292683)}
Micro-average F1 score: 0.539193475305845
Weighted-average F1 score: 0.5155292572008744

F1 score per class: {32: np.float64(0.4375), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.45751633986928103), 6: np.float64(0.5316455696202531), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.14705882352941177), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.3333333333333333)}
Micro-average F1 score: 0.3898305084745763
Weighted-average F1 score: 0.3417610993923881
F1 score per class: {32: np.float64(0.35), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.39215686274509803), 6: np.float64(0.4956521739130435), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.2), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.43478260869565216)}
Micro-average F1 score: 0.2913165266106443
Weighted-average F1 score: 0.22846065083916745
F1 score per class: {32: np.float64(0.4), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.40764331210191085), 6: np.float64(0.49361702127659574), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.16666666666666666), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.4444444444444444)}
Micro-average F1 score: 0.32628398791540786
Weighted-average F1 score: 0.27000029537656145

F1 score per class: {32: np.float64(0.35), 33: np.float64(0.3728813559322034), 2: np.float64(0.24161073825503357), 36: np.float64(0.30837004405286345), 6: np.float64(0.22743682310469315), 39: np.float64(0.7443946188340808), 8: np.float64(0.421875), 11: np.float64(0.208955223880597), 12: np.float64(0.6596858638743456), 19: np.float64(0.04807692307692308), 20: np.float64(0.7729468599033816), 24: np.float64(0.7894736842105263), 26: np.float64(0.5333333333333333), 28: np.float64(0.3333333333333333), 29: np.float64(0.27586206896551724), 30: np.float64(0.136986301369863)}
Micro-average F1 score: 0.39985590778097985
Weighted-average F1 score: 0.36690080197701963
F1 score per class: {32: np.float64(0.19718309859154928), 33: np.float64(0.3806818181818182), 2: np.float64(0.2222222222222222), 36: np.float64(0.2843601895734597), 6: np.float64(0.20765027322404372), 39: np.float64(0.6666666666666666), 8: np.float64(0.39416058394160586), 11: np.float64(0.13559322033898305), 12: np.float64(0.6346153846153846), 19: np.float64(0.08130081300813008), 20: np.float64(0.7715736040609137), 24: np.float64(0.35051546391752575), 26: np.float64(0.5176470588235295), 28: np.float64(0.2608695652173913), 29: np.float64(0.463768115942029), 30: np.float64(0.1282051282051282)}
Micro-average F1 score: 0.37605804111245467
Weighted-average F1 score: 0.34829465486798833
F1 score per class: {32: np.float64(0.2692307692307692), 33: np.float64(0.3931034482758621), 2: np.float64(0.2463768115942029), 36: np.float64(0.27467811158798283), 6: np.float64(0.20350877192982456), 39: np.float64(0.6821705426356589), 8: np.float64(0.4090909090909091), 11: np.float64(0.14893617021276595), 12: np.float64(0.6532663316582915), 19: np.float64(0.0625), 20: np.float64(0.7715736040609137), 24: np.float64(0.6296296296296297), 26: np.float64(0.5161290322580645), 28: np.float64(0.2727272727272727), 29: np.float64(0.4132231404958678), 30: np.float64(0.15789473684210525)}
Micro-average F1 score: 0.38699186991869916
Weighted-average F1 score: 0.356789548044599
cur_acc_wo_na:  ['0.7525', '0.4975', '0.5386']
his_acc_wo_na:  ['0.7525', '0.6748', '0.5476']
cur_acc des_wo_na:  ['0.7398', '0.5925', '0.4280']
his_acc des_wo_na:  ['0.7398', '0.6479', '0.5339']
cur_acc rrf_wo_na:  ['0.7575', '0.6054', '0.4737']
his_acc rrf_wo_na:  ['0.7575', '0.6749', '0.5392']
cur_acc_w_na:  ['0.6501', '0.3929', '0.3898']
his_acc_w_na:  ['0.6501', '0.5487', '0.3999']
cur_acc des_w_na:  ['0.5984', '0.4225', '0.2913']
his_acc des_w_na:  ['0.5984', '0.4892', '0.3761']
cur_acc rrf_w_na:  ['0.6170', '0.4341', '0.3263']
his_acc rrf_w_na:  ['0.6170', '0.5106', '0.3870']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 87.5453698CurrentTrain: epoch  0, batch     1 | loss: 115.6045874CurrentTrain: epoch  0, batch     2 | loss: 118.9424326CurrentTrain: epoch  0, batch     3 | loss: 144.8641356CurrentTrain: epoch  0, batch     4 | loss: 91.4406094CurrentTrain: epoch  1, batch     0 | loss: 86.8951927CurrentTrain: epoch  1, batch     1 | loss: 96.1573418CurrentTrain: epoch  1, batch     2 | loss: 104.3523809CurrentTrain: epoch  1, batch     3 | loss: 130.8517699CurrentTrain: epoch  1, batch     4 | loss: 67.5617930CurrentTrain: epoch  2, batch     0 | loss: 86.4598399CurrentTrain: epoch  2, batch     1 | loss: 105.7545346CurrentTrain: epoch  2, batch     2 | loss: 85.1911731CurrentTrain: epoch  2, batch     3 | loss: 105.6791351CurrentTrain: epoch  2, batch     4 | loss: 83.8394298CurrentTrain: epoch  3, batch     0 | loss: 72.1170830CurrentTrain: epoch  3, batch     1 | loss: 84.9451834CurrentTrain: epoch  3, batch     2 | loss: 104.8338258CurrentTrain: epoch  3, batch     3 | loss: 84.7237319CurrentTrain: epoch  3, batch     4 | loss: 54.4625813CurrentTrain: epoch  4, batch     0 | loss: 100.5919332CurrentTrain: epoch  4, batch     1 | loss: 99.4216317CurrentTrain: epoch  4, batch     2 | loss: 71.0685593CurrentTrain: epoch  4, batch     3 | loss: 84.8159439CurrentTrain: epoch  4, batch     4 | loss: 64.7943093CurrentTrain: epoch  5, batch     0 | loss: 128.6901408CurrentTrain: epoch  5, batch     1 | loss: 81.1985054CurrentTrain: epoch  5, batch     2 | loss: 82.3644002CurrentTrain: epoch  5, batch     3 | loss: 98.5473896CurrentTrain: epoch  5, batch     4 | loss: 51.0036553CurrentTrain: epoch  6, batch     0 | loss: 77.1164716CurrentTrain: epoch  6, batch     1 | loss: 100.2080538CurrentTrain: epoch  6, batch     2 | loss: 96.6606830CurrentTrain: epoch  6, batch     3 | loss: 78.5180827CurrentTrain: epoch  6, batch     4 | loss: 105.4586570CurrentTrain: epoch  7, batch     0 | loss: 63.6623702CurrentTrain: epoch  7, batch     1 | loss: 98.9778467CurrentTrain: epoch  7, batch     2 | loss: 93.5164950CurrentTrain: epoch  7, batch     3 | loss: 97.4807752CurrentTrain: epoch  7, batch     4 | loss: 107.6203711CurrentTrain: epoch  8, batch     0 | loss: 62.6798511CurrentTrain: epoch  8, batch     1 | loss: 98.2958214CurrentTrain: epoch  8, batch     2 | loss: 67.7292612CurrentTrain: epoch  8, batch     3 | loss: 124.6762615CurrentTrain: epoch  8, batch     4 | loss: 75.8465309CurrentTrain: epoch  9, batch     0 | loss: 76.9537817CurrentTrain: epoch  9, batch     1 | loss: 78.5849745CurrentTrain: epoch  9, batch     2 | loss: 79.8819048CurrentTrain: epoch  9, batch     3 | loss: 121.5761771CurrentTrain: epoch  9, batch     4 | loss: 47.9403674
MemoryTrain:  epoch  0, batch     0 | loss: 1.1923663MemoryTrain:  epoch  1, batch     0 | loss: 1.2185558MemoryTrain:  epoch  2, batch     0 | loss: 0.9022283MemoryTrain:  epoch  3, batch     0 | loss: 0.6859357MemoryTrain:  epoch  4, batch     0 | loss: 0.6195937MemoryTrain:  epoch  5, batch     0 | loss: 0.5445548MemoryTrain:  epoch  6, batch     0 | loss: 0.4636217MemoryTrain:  epoch  7, batch     0 | loss: 0.4033384MemoryTrain:  epoch  8, batch     0 | loss: 0.4054282MemoryTrain:  epoch  9, batch     0 | loss: 0.2731291

F1 score per class: {32: np.float64(0.0), 2: np.float64(0.9090909090909091), 5: np.float64(0.0), 6: np.float64(0.5540540540540541), 39: np.float64(0.0), 10: np.float64(0.0), 12: np.float64(0.6875), 11: np.float64(0.8), 16: np.float64(0.4727272727272727), 17: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.6287744227353463
Weighted-average F1 score: 0.5657477163574726
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.7637795275590551), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.5695364238410596), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.7323943661971831), 17: np.float64(0.6666666666666666), 18: np.float64(0.5714285714285714), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.568081991215227
Weighted-average F1 score: 0.5050459870545845
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.7886178861788617), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.5806451612903226), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.7058823529411765), 17: np.float64(0.7058823529411765), 18: np.float64(0.5151515151515151), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5779816513761468
Weighted-average F1 score: 0.5145070831422477

F1 score per class: {2: np.float64(0.4166666666666667), 5: np.float64(0.8482142857142857), 6: np.float64(0.4276729559748428), 8: np.float64(0.09302325581395349), 10: np.float64(0.3445378151260504), 11: np.float64(0.21935483870967742), 12: np.float64(0.35294117647058826), 16: np.float64(0.5569620253164557), 17: np.float64(0.41379310344827586), 18: np.float64(0.2857142857142857), 19: np.float64(0.7727272727272727), 20: np.float64(0.47619047619047616), 24: np.float64(0.3333333333333333), 26: np.float64(0.7241379310344828), 28: np.float64(0.0970873786407767), 29: np.float64(0.837696335078534), 30: np.float64(0.8648648648648649), 32: np.float64(0.7091633466135459), 33: np.float64(0.35294117647058826), 36: np.float64(0.28205128205128205), 39: np.float64(0.14814814814814814)}
Micro-average F1 score: 0.5186934277843369
Weighted-average F1 score: 0.5252144352584593
F1 score per class: {2: np.float64(0.5), 5: np.float64(0.6510067114093959), 6: np.float64(0.551440329218107), 8: np.float64(0.27906976744186046), 10: np.float64(0.39814814814814814), 11: np.float64(0.20987654320987653), 12: np.float64(0.35714285714285715), 16: np.float64(0.6419753086419753), 17: np.float64(0.2553191489361702), 18: np.float64(0.2558139534883721), 19: np.float64(0.6946564885496184), 20: np.float64(0.5208333333333334), 24: np.float64(0.225), 26: np.float64(0.676923076923077), 28: np.float64(0.15384615384615385), 29: np.float64(0.8359788359788359), 30: np.float64(0.44155844155844154), 32: np.float64(0.6716417910447762), 33: np.float64(0.375), 36: np.float64(0.559322033898305), 39: np.float64(0.14634146341463414)}
Micro-average F1 score: 0.5027252324462969
Weighted-average F1 score: 0.49217372105015006
F1 score per class: {2: np.float64(0.5), 5: np.float64(0.6928571428571428), 6: np.float64(0.5136612021857924), 8: np.float64(0.21782178217821782), 10: np.float64(0.37344398340248963), 11: np.float64(0.21301775147928995), 12: np.float64(0.34911242603550297), 16: np.float64(0.6), 17: np.float64(0.27906976744186046), 18: np.float64(0.2518518518518518), 19: np.float64(0.7407407407407407), 20: np.float64(0.5217391304347826), 24: np.float64(0.2909090909090909), 26: np.float64(0.7058823529411765), 28: np.float64(0.09900990099009901), 29: np.float64(0.8359788359788359), 30: np.float64(0.6181818181818182), 32: np.float64(0.6544117647058824), 33: np.float64(0.3333333333333333), 36: np.float64(0.4716981132075472), 39: np.float64(0.15384615384615385)}
Micro-average F1 score: 0.5008460236886633
Weighted-average F1 score: 0.49080741290339397

F1 score per class: {2: np.float64(0.0), 5: np.float64(0.7251908396946565), 6: np.float64(0.0), 10: np.float64(0.4581005586592179), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.44), 17: np.float64(0.5714285714285714), 18: np.float64(0.30952380952380953), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.4164705882352941
Weighted-average F1 score: 0.3586683311313144
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.5527065527065527), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.455026455026455), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.4727272727272727), 17: np.float64(0.48), 18: np.float64(0.3333333333333333), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.35208711433756806
Weighted-average F1 score: 0.3104013894812926
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.5843373493975904), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.45226130653266333), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.4528301886792453), 17: np.float64(0.5), 18: np.float64(0.3008849557522124), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.36416184971098264
Weighted-average F1 score: 0.32168305168473155

F1 score per class: {2: np.float64(0.23255813953488372), 5: np.float64(0.6168831168831169), 6: np.float64(0.3076923076923077), 8: np.float64(0.09195402298850575), 10: np.float64(0.24773413897280966), 11: np.float64(0.18085106382978725), 12: np.float64(0.19004524886877827), 16: np.float64(0.32592592592592595), 17: np.float64(0.2222222222222222), 18: np.float64(0.16560509554140126), 19: np.float64(0.7024793388429752), 20: np.float64(0.35398230088495575), 24: np.float64(0.2222222222222222), 26: np.float64(0.6596858638743456), 28: np.float64(0.050761421319796954), 29: np.float64(0.7272727272727273), 30: np.float64(0.8205128205128205), 32: np.float64(0.541033434650456), 33: np.float64(0.2727272727272727), 36: np.float64(0.2222222222222222), 39: np.float64(0.07547169811320754)}
Micro-average F1 score: 0.37390070921985813
Weighted-average F1 score: 0.3584050300737367
F1 score per class: {2: np.float64(0.2692307692307692), 5: np.float64(0.39591836734693875), 6: np.float64(0.324455205811138), 8: np.float64(0.23841059602649006), 10: np.float64(0.26461538461538464), 11: np.float64(0.17894736842105263), 12: np.float64(0.18779342723004694), 16: np.float64(0.37142857142857144), 17: np.float64(0.1643835616438356), 18: np.float64(0.12941176470588237), 19: np.float64(0.5909090909090909), 20: np.float64(0.32679738562091504), 24: np.float64(0.13846153846153847), 26: np.float64(0.5739130434782609), 28: np.float64(0.07874015748031496), 29: np.float64(0.7523809523809524), 30: np.float64(0.35051546391752575), 32: np.float64(0.5084745762711864), 33: np.float64(0.2857142857142857), 36: np.float64(0.39285714285714285), 39: np.float64(0.07692307692307693)}
Micro-average F1 score: 0.33439965877585837
Weighted-average F1 score: 0.31805059908365496
F1 score per class: {2: np.float64(0.2545454545454545), 5: np.float64(0.4349775784753363), 6: np.float64(0.3443223443223443), 8: np.float64(0.2), 10: np.float64(0.24193548387096775), 11: np.float64(0.1836734693877551), 12: np.float64(0.18294573643410852), 16: np.float64(0.35036496350364965), 17: np.float64(0.16901408450704225), 18: np.float64(0.13127413127413126), 19: np.float64(0.6521739130434783), 20: np.float64(0.3287671232876712), 24: np.float64(0.18181818181818182), 26: np.float64(0.6197183098591549), 28: np.float64(0.05128205128205128), 29: np.float64(0.7596153846153846), 30: np.float64(0.53125), 32: np.float64(0.4930747922437673), 33: np.float64(0.2608695652173913), 36: np.float64(0.3333333333333333), 39: np.float64(0.07894736842105263)}
Micro-average F1 score: 0.3391384051329056
Weighted-average F1 score: 0.31989591861470984
cur_acc_wo_na:  ['0.7525', '0.4975', '0.5386', '0.6288']
his_acc_wo_na:  ['0.7525', '0.6748', '0.5476', '0.5187']
cur_acc des_wo_na:  ['0.7398', '0.5925', '0.4280', '0.5681']
his_acc des_wo_na:  ['0.7398', '0.6479', '0.5339', '0.5027']
cur_acc rrf_wo_na:  ['0.7575', '0.6054', '0.4737', '0.5780']
his_acc rrf_wo_na:  ['0.7575', '0.6749', '0.5392', '0.5008']
cur_acc_w_na:  ['0.6501', '0.3929', '0.3898', '0.4165']
his_acc_w_na:  ['0.6501', '0.5487', '0.3999', '0.3739']
cur_acc des_w_na:  ['0.5984', '0.4225', '0.2913', '0.3521']
his_acc des_w_na:  ['0.5984', '0.4892', '0.3761', '0.3344']
cur_acc rrf_w_na:  ['0.6170', '0.4341', '0.3263', '0.3642']
his_acc rrf_w_na:  ['0.6170', '0.5106', '0.3870', '0.3391']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 89.7890576CurrentTrain: epoch  0, batch     1 | loss: 101.4454526CurrentTrain: epoch  0, batch     2 | loss: 85.2153470CurrentTrain: epoch  0, batch     3 | loss: 143.3053020CurrentTrain: epoch  0, batch     4 | loss: 70.2342705CurrentTrain: epoch  1, batch     0 | loss: 82.8334744CurrentTrain: epoch  1, batch     1 | loss: 106.2266274CurrentTrain: epoch  1, batch     2 | loss: 178.6491741CurrentTrain: epoch  1, batch     3 | loss: 90.0657371CurrentTrain: epoch  1, batch     4 | loss: 60.3061244CurrentTrain: epoch  2, batch     0 | loss: 87.6973713CurrentTrain: epoch  2, batch     1 | loss: 89.1984503CurrentTrain: epoch  2, batch     2 | loss: 88.9114538CurrentTrain: epoch  2, batch     3 | loss: 103.2081602CurrentTrain: epoch  2, batch     4 | loss: 74.5447495CurrentTrain: epoch  3, batch     0 | loss: 69.2839271CurrentTrain: epoch  3, batch     1 | loss: 71.4750924CurrentTrain: epoch  3, batch     2 | loss: 88.6042134CurrentTrain: epoch  3, batch     3 | loss: 87.1853955CurrentTrain: epoch  3, batch     4 | loss: 146.5088498CurrentTrain: epoch  4, batch     0 | loss: 84.0971406CurrentTrain: epoch  4, batch     1 | loss: 83.5488311CurrentTrain: epoch  4, batch     2 | loss: 83.6802723CurrentTrain: epoch  4, batch     3 | loss: 83.0158371CurrentTrain: epoch  4, batch     4 | loss: 69.1974556CurrentTrain: epoch  5, batch     0 | loss: 83.1246212CurrentTrain: epoch  5, batch     1 | loss: 129.3247307CurrentTrain: epoch  5, batch     2 | loss: 97.4858301CurrentTrain: epoch  5, batch     3 | loss: 67.2756215CurrentTrain: epoch  5, batch     4 | loss: 48.5214553CurrentTrain: epoch  6, batch     0 | loss: 79.6607203CurrentTrain: epoch  6, batch     1 | loss: 83.5638141CurrentTrain: epoch  6, batch     2 | loss: 68.3256768CurrentTrain: epoch  6, batch     3 | loss: 81.0700296CurrentTrain: epoch  6, batch     4 | loss: 55.0351981CurrentTrain: epoch  7, batch     0 | loss: 77.7126114CurrentTrain: epoch  7, batch     1 | loss: 80.6226297CurrentTrain: epoch  7, batch     2 | loss: 81.7826877CurrentTrain: epoch  7, batch     3 | loss: 68.4948953CurrentTrain: epoch  7, batch     4 | loss: 68.0481852CurrentTrain: epoch  8, batch     0 | loss: 93.7693537CurrentTrain: epoch  8, batch     1 | loss: 123.7007803CurrentTrain: epoch  8, batch     2 | loss: 119.3052947CurrentTrain: epoch  8, batch     3 | loss: 66.3791456CurrentTrain: epoch  8, batch     4 | loss: 50.5486902CurrentTrain: epoch  9, batch     0 | loss: 67.6611085CurrentTrain: epoch  9, batch     1 | loss: 81.6972479CurrentTrain: epoch  9, batch     2 | loss: 76.0519039CurrentTrain: epoch  9, batch     3 | loss: 94.7860904CurrentTrain: epoch  9, batch     4 | loss: 68.2042257
MemoryTrain:  epoch  0, batch     0 | loss: 1.1556572MemoryTrain:  epoch  1, batch     0 | loss: 1.0015247MemoryTrain:  epoch  2, batch     0 | loss: 0.7940505MemoryTrain:  epoch  3, batch     0 | loss: 0.6891463MemoryTrain:  epoch  4, batch     0 | loss: 0.5764753MemoryTrain:  epoch  5, batch     0 | loss: 0.5337440MemoryTrain:  epoch  6, batch     0 | loss: 0.4303485MemoryTrain:  epoch  7, batch     0 | loss: 0.3609386MemoryTrain:  epoch  8, batch     0 | loss: 0.3187617MemoryTrain:  epoch  9, batch     0 | loss: 0.2760920

F1 score per class: {32: np.float64(0.21176470588235294), 1: np.float64(0.6802030456852792), 34: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.1111111111111111), 12: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.43137254901960786), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.6285714285714286)}
Micro-average F1 score: 0.3747534516765286
Weighted-average F1 score: 0.3432311934913641
F1 score per class: {1: np.float64(0.2391304347826087), 3: np.float64(0.6192468619246861), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.09271523178807947), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.4292237442922374), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6351351351351351)}
Micro-average F1 score: 0.33560477001703576
Weighted-average F1 score: 0.2997555559076099
F1 score per class: {1: np.float64(0.25136612021857924), 3: np.float64(0.6577777777777778), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.09230769230769231), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.43089430894308944), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6442953020134228)}
Micro-average F1 score: 0.36138175376439324
Weighted-average F1 score: 0.3292027525502298

F1 score per class: {1: np.float64(0.1782178217821782), 2: np.float64(0.5), 3: np.float64(0.5193798449612403), 5: np.float64(0.8355555555555556), 6: np.float64(0.4642857142857143), 8: np.float64(0.0898876404494382), 10: np.float64(0.3595505617977528), 11: np.float64(0.12030075187969924), 12: np.float64(0.3418803418803419), 14: np.float64(0.0916030534351145), 16: np.float64(0.575), 17: np.float64(0.42857142857142855), 18: np.float64(0.07142857142857142), 19: np.float64(0.6538461538461539), 20: np.float64(0.45569620253164556), 22: np.float64(0.3583061889250814), 24: np.float64(0.0), 26: np.float64(0.7111111111111111), 28: np.float64(0.08571428571428572), 29: np.float64(0.8181818181818182), 30: np.float64(0.918918918918919), 32: np.float64(0.6377952755905512), 33: np.float64(0.2857142857142857), 34: np.float64(0.16955684007707128), 36: np.float64(0.21333333333333335), 39: np.float64(0.21428571428571427)}
Micro-average F1 score: 0.41208791208791207
Weighted-average F1 score: 0.3961191518632936
F1 score per class: {1: np.float64(0.1981981981981982), 2: np.float64(0.45161290322580644), 3: np.float64(0.4228571428571429), 5: np.float64(0.6783216783216783), 6: np.float64(0.5101214574898786), 8: np.float64(0.3181818181818182), 10: np.float64(0.4187725631768953), 11: np.float64(0.11510791366906475), 12: np.float64(0.3151515151515151), 14: np.float64(0.06140350877192982), 16: np.float64(0.6329113924050633), 17: np.float64(0.3), 18: np.float64(0.1348314606741573), 19: np.float64(0.5825242718446602), 20: np.float64(0.5116279069767442), 22: np.float64(0.36293436293436293), 24: np.float64(0.13333333333333333), 26: np.float64(0.6836734693877551), 28: np.float64(0.1), 29: np.float64(0.7684210526315789), 30: np.float64(0.5230769230769231), 32: np.float64(0.5602605863192183), 33: np.float64(0.375), 34: np.float64(0.18875502008032127), 36: np.float64(0.5370370370370371), 39: np.float64(0.14634146341463414)}
Micro-average F1 score: 0.40171306209850105
Weighted-average F1 score: 0.3831887496340493
F1 score per class: {1: np.float64(0.2119815668202765), 2: np.float64(0.5), 3: np.float64(0.47435897435897434), 5: np.float64(0.7211895910780669), 6: np.float64(0.51), 8: np.float64(0.22641509433962265), 10: np.float64(0.3972602739726027), 11: np.float64(0.11851851851851852), 12: np.float64(0.3167701863354037), 14: np.float64(0.06936416184971098), 16: np.float64(0.6172839506172839), 17: np.float64(0.32432432432432434), 18: np.float64(0.13333333333333333), 19: np.float64(0.6040268456375839), 20: np.float64(0.49411764705882355), 22: np.float64(0.3464052287581699), 24: np.float64(0.0), 26: np.float64(0.7096774193548387), 28: np.float64(0.08264462809917356), 29: np.float64(0.7684210526315789), 30: np.float64(0.7555555555555555), 32: np.float64(0.5833333333333334), 33: np.float64(0.4), 34: np.float64(0.1801125703564728), 36: np.float64(0.36363636363636365), 39: np.float64(0.1951219512195122)}
Micro-average F1 score: 0.4040268456375839
Weighted-average F1 score: 0.38688498673864646

F1 score per class: {1: np.float64(0.11960132890365449), 2: np.float64(0.0), 3: np.float64(0.49814126394052044), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.10344827586206896), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.32934131736526945), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.4512820512820513)}
Micro-average F1 score: 0.24934383202099739
Weighted-average F1 score: 0.22838401373804273
F1 score per class: {1: np.float64(0.13253012048192772), 2: np.float64(0.0), 3: np.float64(0.4088397790055249), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.07567567567567568), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.34686346863468637), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.47)}
Micro-average F1 score: 0.21696035242290748
Weighted-average F1 score: 0.1964803625695734
F1 score per class: {1: np.float64(0.1393939393939394), 2: np.float64(0.0), 3: np.float64(0.4525993883792049), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.07894736842105263), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.33865814696485624), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.47761194029850745)}
Micro-average F1 score: 0.23570190641247835
Weighted-average F1 score: 0.21593970357677458

F1 score per class: {1: np.float64(0.09651474530831099), 2: np.float64(0.26666666666666666), 3: np.float64(0.3228915662650602), 5: np.float64(0.5911949685534591), 6: np.float64(0.3046875), 8: np.float64(0.08695652173913043), 10: np.float64(0.2467866323907455), 11: np.float64(0.11347517730496454), 12: np.float64(0.17391304347826086), 14: np.float64(0.07947019867549669), 16: np.float64(0.35658914728682173), 17: np.float64(0.27906976744186046), 18: np.float64(0.05405405405405406), 19: np.float64(0.584192439862543), 20: np.float64(0.3302752293577982), 22: np.float64(0.2564102564102564), 24: np.float64(0.0), 26: np.float64(0.6432160804020101), 28: np.float64(0.04460966542750929), 29: np.float64(0.7012987012987013), 30: np.float64(0.8717948717948718), 32: np.float64(0.49240121580547114), 33: np.float64(0.25), 34: np.float64(0.09649122807017543), 36: np.float64(0.17391304347826086), 39: np.float64(0.10714285714285714)}
Micro-average F1 score: 0.28080326752893126
Weighted-average F1 score: 0.26218449283262235
F1 score per class: {1: np.float64(0.10501193317422435), 2: np.float64(0.2413793103448276), 3: np.float64(0.24222585924713586), 5: np.float64(0.4136460554371002), 6: np.float64(0.29439252336448596), 8: np.float64(0.25609756097560976), 10: np.float64(0.27488151658767773), 11: np.float64(0.10596026490066225), 12: np.float64(0.1582952815829528), 14: np.float64(0.04827586206896552), 16: np.float64(0.3597122302158273), 17: np.float64(0.1791044776119403), 18: np.float64(0.08955223880597014), 19: np.float64(0.48257372654155495), 20: np.float64(0.32116788321167883), 22: np.float64(0.2678062678062678), 24: np.float64(0.10714285714285714), 26: np.float64(0.5726495726495726), 28: np.float64(0.05154639175257732), 29: np.float64(0.6790697674418604), 30: np.float64(0.4358974358974359), 32: np.float64(0.4075829383886256), 33: np.float64(0.3), 34: np.float64(0.10892236384704519), 36: np.float64(0.3717948717948718), 39: np.float64(0.07142857142857142)}
Micro-average F1 score: 0.26084538375973304
Weighted-average F1 score: 0.24668711425182357
F1 score per class: {1: np.float64(0.1108433734939759), 2: np.float64(0.28), 3: np.float64(0.2756052141527002), 5: np.float64(0.45647058823529413), 6: np.float64(0.3167701863354037), 8: np.float64(0.1951219512195122), 10: np.float64(0.2538293216630197), 11: np.float64(0.1111111111111111), 12: np.float64(0.15813953488372093), 14: np.float64(0.05687203791469194), 16: np.float64(0.35714285714285715), 17: np.float64(0.19047619047619047), 18: np.float64(0.08695652173913043), 19: np.float64(0.5232558139534884), 20: np.float64(0.3181818181818182), 22: np.float64(0.24651162790697675), 24: np.float64(0.0), 26: np.float64(0.6027397260273972), 28: np.float64(0.04310344827586207), 29: np.float64(0.6822429906542056), 30: np.float64(0.723404255319149), 32: np.float64(0.42), 33: np.float64(0.3333333333333333), 34: np.float64(0.10344827586206896), 36: np.float64(0.27350427350427353), 39: np.float64(0.0975609756097561)}
Micro-average F1 score: 0.26399649174097356
Weighted-average F1 score: 0.24842173885832064
cur_acc_wo_na:  ['0.7525', '0.4975', '0.5386', '0.6288', '0.3748']
his_acc_wo_na:  ['0.7525', '0.6748', '0.5476', '0.5187', '0.4121']
cur_acc des_wo_na:  ['0.7398', '0.5925', '0.4280', '0.5681', '0.3356']
his_acc des_wo_na:  ['0.7398', '0.6479', '0.5339', '0.5027', '0.4017']
cur_acc rrf_wo_na:  ['0.7575', '0.6054', '0.4737', '0.5780', '0.3614']
his_acc rrf_wo_na:  ['0.7575', '0.6749', '0.5392', '0.5008', '0.4040']
cur_acc_w_na:  ['0.6501', '0.3929', '0.3898', '0.4165', '0.2493']
his_acc_w_na:  ['0.6501', '0.5487', '0.3999', '0.3739', '0.2808']
cur_acc des_w_na:  ['0.5984', '0.4225', '0.2913', '0.3521', '0.2170']
his_acc des_w_na:  ['0.5984', '0.4892', '0.3761', '0.3344', '0.2608']
cur_acc rrf_w_na:  ['0.6170', '0.4341', '0.3263', '0.3642', '0.2357']
his_acc rrf_w_na:  ['0.6170', '0.5106', '0.3870', '0.3391', '0.2640']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 86.6368795CurrentTrain: epoch  0, batch     1 | loss: 102.6988983CurrentTrain: epoch  0, batch     2 | loss: 75.4075615CurrentTrain: epoch  0, batch     3 | loss: 16.8250142CurrentTrain: epoch  1, batch     0 | loss: 80.5227294CurrentTrain: epoch  1, batch     1 | loss: 72.8614146CurrentTrain: epoch  1, batch     2 | loss: 103.0138893CurrentTrain: epoch  1, batch     3 | loss: 13.9689778CurrentTrain: epoch  2, batch     0 | loss: 72.7530572CurrentTrain: epoch  2, batch     1 | loss: 66.7288684CurrentTrain: epoch  2, batch     2 | loss: 86.3629654CurrentTrain: epoch  2, batch     3 | loss: 11.9654700CurrentTrain: epoch  3, batch     0 | loss: 80.8932292CurrentTrain: epoch  3, batch     1 | loss: 67.2458055CurrentTrain: epoch  3, batch     2 | loss: 96.9856140CurrentTrain: epoch  3, batch     3 | loss: 20.4945758CurrentTrain: epoch  4, batch     0 | loss: 82.8535325CurrentTrain: epoch  4, batch     1 | loss: 66.1349619CurrentTrain: epoch  4, batch     2 | loss: 63.2900082CurrentTrain: epoch  4, batch     3 | loss: 6.7936422CurrentTrain: epoch  5, batch     0 | loss: 63.2050436CurrentTrain: epoch  5, batch     1 | loss: 78.3666250CurrentTrain: epoch  5, batch     2 | loss: 76.3792047CurrentTrain: epoch  5, batch     3 | loss: 21.4651506CurrentTrain: epoch  6, batch     0 | loss: 65.2461271CurrentTrain: epoch  6, batch     1 | loss: 66.6260810CurrentTrain: epoch  6, batch     2 | loss: 64.5053523CurrentTrain: epoch  6, batch     3 | loss: 4.6977934CurrentTrain: epoch  7, batch     0 | loss: 61.8019925CurrentTrain: epoch  7, batch     1 | loss: 64.9022248CurrentTrain: epoch  7, batch     2 | loss: 65.8757414CurrentTrain: epoch  7, batch     3 | loss: 19.2499725CurrentTrain: epoch  8, batch     0 | loss: 63.1829430CurrentTrain: epoch  8, batch     1 | loss: 61.5644697CurrentTrain: epoch  8, batch     2 | loss: 74.9278203CurrentTrain: epoch  8, batch     3 | loss: 21.0603277CurrentTrain: epoch  9, batch     0 | loss: 62.6977474CurrentTrain: epoch  9, batch     1 | loss: 61.6101055CurrentTrain: epoch  9, batch     2 | loss: 61.2015351CurrentTrain: epoch  9, batch     3 | loss: 15.7749958
MemoryTrain:  epoch  0, batch     0 | loss: 0.7439023MemoryTrain:  epoch  1, batch     0 | loss: 0.6260586MemoryTrain:  epoch  2, batch     0 | loss: 0.5539798MemoryTrain:  epoch  3, batch     0 | loss: 0.4405244MemoryTrain:  epoch  4, batch     0 | loss: 0.3496708MemoryTrain:  epoch  5, batch     0 | loss: 0.3017140MemoryTrain:  epoch  6, batch     0 | loss: 0.2426228MemoryTrain:  epoch  7, batch     0 | loss: 0.2273392MemoryTrain:  epoch  8, batch     0 | loss: 0.2073243MemoryTrain:  epoch  9, batch     0 | loss: 0.1867454

F1 score per class: {32: np.float64(0.0), 1: np.float64(0.0), 34: np.float64(0.8), 3: np.float64(0.8064516129032258), 7: np.float64(0.0), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.2857142857142857), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.3246753246753247)}
Micro-average F1 score: 0.3303303303303303
Weighted-average F1 score: 0.2848534585167373
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7272727272727273), 9: np.float64(0.6756756756756757), 10: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.16666666666666666), 32: np.float64(0.0), 34: np.float64(0.0), 40: np.float64(0.54421768707483)}
Micro-average F1 score: 0.41420118343195267
Weighted-average F1 score: 0.3636425568823528
F1 score per class: {32: np.float64(0.0), 1: np.float64(0.0), 34: np.float64(0.7272727272727273), 3: np.float64(0.6944444444444444), 7: np.float64(0.0), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.2222222222222222), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.5466666666666666)}
Micro-average F1 score: 0.4303030303030303
Weighted-average F1 score: 0.38282547699214364

F1 score per class: {1: np.float64(0.13333333333333333), 2: np.float64(0.5217391304347826), 3: np.float64(0.5551020408163265), 5: np.float64(0.8), 6: np.float64(0.07547169811320754), 7: np.float64(0.050314465408805034), 8: np.float64(0.07058823529411765), 9: np.float64(0.7692307692307693), 10: np.float64(0.29347826086956524), 11: np.float64(0.13636363636363635), 12: np.float64(0.05673758865248227), 14: np.float64(0.042105263157894736), 16: np.float64(0.5945945945945946), 17: np.float64(0.42857142857142855), 18: np.float64(0.08571428571428572), 19: np.float64(0.5853658536585366), 20: np.float64(0.5747126436781609), 22: np.float64(0.3502824858757062), 24: np.float64(0.0), 26: np.float64(0.6588235294117647), 27: np.float64(0.0), 28: np.float64(0.09836065573770492), 29: np.float64(0.7457627118644068), 30: np.float64(0.8648648648648649), 31: np.float64(0.08), 32: np.float64(0.6299212598425197), 33: np.float64(0.4), 34: np.float64(0.19902912621359223), 36: np.float64(0.21621621621621623), 39: np.float64(0.09090909090909091), 40: np.float64(0.08680555555555555)}
Micro-average F1 score: 0.3294547113848962
Weighted-average F1 score: 0.3048779426980308
F1 score per class: {1: np.float64(0.16964285714285715), 2: np.float64(0.4117647058823529), 3: np.float64(0.5367647058823529), 5: np.float64(0.5981308411214953), 6: np.float64(0.2857142857142857), 7: np.float64(0.056338028169014086), 8: np.float64(0.2777777777777778), 9: np.float64(0.42735042735042733), 10: np.float64(0.3333333333333333), 11: np.float64(0.1), 12: np.float64(0.22009569377990432), 14: np.float64(0.0670391061452514), 16: np.float64(0.5641025641025641), 17: np.float64(0.4166666666666667), 18: np.float64(0.10101010101010101), 19: np.float64(0.5473684210526316), 20: np.float64(0.5591397849462365), 22: np.float64(0.3643724696356275), 24: np.float64(0.12121212121212122), 26: np.float64(0.6844919786096256), 27: np.float64(0.0), 28: np.float64(0.09803921568627451), 29: np.float64(0.7209302325581395), 30: np.float64(0.7906976744186046), 31: np.float64(0.03389830508474576), 32: np.float64(0.6093189964157706), 33: np.float64(0.375), 34: np.float64(0.20568927789934355), 36: np.float64(0.5048543689320388), 39: np.float64(0.14285714285714285), 40: np.float64(0.26490066225165565)}
Micro-average F1 score: 0.3671021632041122
Weighted-average F1 score: 0.34843583151930835
F1 score per class: {1: np.float64(0.15789473684210525), 2: np.float64(0.5185185185185185), 3: np.float64(0.5433962264150943), 5: np.float64(0.6552901023890785), 6: np.float64(0.18181818181818182), 7: np.float64(0.05228758169934641), 8: np.float64(0.13043478260869565), 9: np.float64(0.5154639175257731), 10: np.float64(0.3111111111111111), 11: np.float64(0.1016949152542373), 12: np.float64(0.19095477386934673), 14: np.float64(0.08450704225352113), 16: np.float64(0.5789473684210527), 17: np.float64(0.4444444444444444), 18: np.float64(0.12345679012345678), 19: np.float64(0.582089552238806), 20: np.float64(0.5617977528089888), 22: np.float64(0.37383177570093457), 24: np.float64(0.09523809523809523), 26: np.float64(0.6961325966850829), 27: np.float64(0.0), 28: np.float64(0.10810810810810811), 29: np.float64(0.7251461988304093), 30: np.float64(0.8947368421052632), 31: np.float64(0.05), 32: np.float64(0.6064981949458483), 33: np.float64(0.4), 34: np.float64(0.18947368421052632), 36: np.float64(0.3373493975903614), 39: np.float64(0.14285714285714285), 40: np.float64(0.23563218390804597)}
Micro-average F1 score: 0.35803826698922364
Weighted-average F1 score: 0.34085076119939395

F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.8), 9: np.float64(0.746268656716418), 10: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.25), 32: np.float64(0.0), 34: np.float64(0.0), 40: np.float64(0.25906735751295334)}
Micro-average F1 score: 0.2644230769230769
Weighted-average F1 score: 0.22675640600825267
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6153846153846154), 9: np.float64(0.5376344086021505), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.125), 32: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 40: np.float64(0.49079754601226994)}
Micro-average F1 score: 0.32407407407407407
Weighted-average F1 score: 0.2808816011653668
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7272727272727273), 9: np.float64(0.625), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.15384615384615385), 32: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 40: np.float64(0.4880952380952381)}
Micro-average F1 score: 0.34549878345498786
Weighted-average F1 score: 0.298368578671609

F1 score per class: {1: np.float64(0.07575757575757576), 2: np.float64(0.2926829268292683), 3: np.float64(0.3460559796437659), 5: np.float64(0.5911949685534591), 6: np.float64(0.07017543859649122), 7: np.float64(0.025157232704402517), 8: np.float64(0.06896551724137931), 9: np.float64(0.6410256410256411), 10: np.float64(0.23893805309734514), 11: np.float64(0.12244897959183673), 12: np.float64(0.04145077720207254), 14: np.float64(0.03225806451612903), 16: np.float64(0.3697478991596639), 17: np.float64(0.2857142857142857), 18: np.float64(0.05405405405405406), 19: np.float64(0.555984555984556), 20: np.float64(0.373134328358209), 22: np.float64(0.28703703703703703), 24: np.float64(0.0), 26: np.float64(0.6021505376344086), 27: np.float64(0.0), 28: np.float64(0.0502092050209205), 29: np.float64(0.6700507614213198), 30: np.float64(0.8205128205128205), 31: np.float64(0.05263157894736842), 32: np.float64(0.48338368580060426), 33: np.float64(0.375), 34: np.float64(0.12257100149476831), 36: np.float64(0.1839080459770115), 39: np.float64(0.05714285714285714), 40: np.float64(0.0641025641025641)}
Micro-average F1 score: 0.23753906892581017
Weighted-average F1 score: 0.21479946742572548
F1 score per class: {1: np.float64(0.09405940594059406), 2: np.float64(0.22580645161290322), 3: np.float64(0.31670281995661603), 5: np.float64(0.3713733075435203), 6: np.float64(0.22857142857142856), 7: np.float64(0.026936026936026935), 8: np.float64(0.24793388429752067), 9: np.float64(0.30120481927710846), 10: np.float64(0.25806451612903225), 11: np.float64(0.09302325581395349), 12: np.float64(0.13529411764705881), 14: np.float64(0.056338028169014086), 16: np.float64(0.352), 17: np.float64(0.24390243902439024), 18: np.float64(0.0641025641025641), 19: np.float64(0.4984025559105431), 20: np.float64(0.33121019108280253), 22: np.float64(0.26785714285714285), 24: np.float64(0.10526315789473684), 26: np.float64(0.5818181818181818), 27: np.float64(0.0), 28: np.float64(0.04739336492890995), 29: np.float64(0.656084656084656), 30: np.float64(0.723404255319149), 31: np.float64(0.0196078431372549), 32: np.float64(0.46070460704607047), 33: np.float64(0.3157894736842105), 34: np.float64(0.12352168199737187), 36: np.float64(0.3561643835616438), 39: np.float64(0.08333333333333333), 40: np.float64(0.20408163265306123)}
Micro-average F1 score: 0.2519847103793002
Weighted-average F1 score: 0.23493948245283575
F1 score per class: {1: np.float64(0.08737864077669903), 2: np.float64(0.2916666666666667), 3: np.float64(0.32432432432432434), 5: np.float64(0.41379310344827586), 6: np.float64(0.16296296296296298), 7: np.float64(0.024691358024691357), 8: np.float64(0.125), 9: np.float64(0.3968253968253968), 10: np.float64(0.2413793103448276), 11: np.float64(0.09523809523809523), 12: np.float64(0.12063492063492064), 14: np.float64(0.0694980694980695), 16: np.float64(0.36065573770491804), 17: np.float64(0.25), 18: np.float64(0.07575757575757576), 19: np.float64(0.5512367491166078), 20: np.float64(0.33783783783783783), 22: np.float64(0.2846975088967972), 24: np.float64(0.08), 26: np.float64(0.6331658291457286), 27: np.float64(0.0), 28: np.float64(0.05240174672489083), 29: np.float64(0.6631016042780749), 30: np.float64(0.85), 31: np.float64(0.028985507246376812), 32: np.float64(0.4540540540540541), 33: np.float64(0.3157894736842105), 34: np.float64(0.11349306431273644), 36: np.float64(0.2641509433962264), 39: np.float64(0.08695652173913043), 40: np.float64(0.17672413793103448)}
Micro-average F1 score: 0.24836003051106026
Weighted-average F1 score: 0.2300391147021715
cur_acc_wo_na:  ['0.7525', '0.4975', '0.5386', '0.6288', '0.3748', '0.3303']
his_acc_wo_na:  ['0.7525', '0.6748', '0.5476', '0.5187', '0.4121', '0.3295']
cur_acc des_wo_na:  ['0.7398', '0.5925', '0.4280', '0.5681', '0.3356', '0.4142']
his_acc des_wo_na:  ['0.7398', '0.6479', '0.5339', '0.5027', '0.4017', '0.3671']
cur_acc rrf_wo_na:  ['0.7575', '0.6054', '0.4737', '0.5780', '0.3614', '0.4303']
his_acc rrf_wo_na:  ['0.7575', '0.6749', '0.5392', '0.5008', '0.4040', '0.3580']
cur_acc_w_na:  ['0.6501', '0.3929', '0.3898', '0.4165', '0.2493', '0.2644']
his_acc_w_na:  ['0.6501', '0.5487', '0.3999', '0.3739', '0.2808', '0.2375']
cur_acc des_w_na:  ['0.5984', '0.4225', '0.2913', '0.3521', '0.2170', '0.3241']
his_acc des_w_na:  ['0.5984', '0.4892', '0.3761', '0.3344', '0.2608', '0.2520']
cur_acc rrf_w_na:  ['0.6170', '0.4341', '0.3263', '0.3642', '0.2357', '0.3455']
his_acc rrf_w_na:  ['0.6170', '0.5106', '0.3870', '0.3391', '0.2640', '0.2484']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 97.8009444CurrentTrain: epoch  0, batch     1 | loss: 86.6000295CurrentTrain: epoch  0, batch     2 | loss: 86.2883309CurrentTrain: epoch  0, batch     3 | loss: 75.0538052CurrentTrain: epoch  1, batch     0 | loss: 78.2692851CurrentTrain: epoch  1, batch     1 | loss: 90.0995669CurrentTrain: epoch  1, batch     2 | loss: 88.7412303CurrentTrain: epoch  1, batch     3 | loss: 69.3068634CurrentTrain: epoch  2, batch     0 | loss: 71.1180405CurrentTrain: epoch  2, batch     1 | loss: 71.2094343CurrentTrain: epoch  2, batch     2 | loss: 84.3272751CurrentTrain: epoch  2, batch     3 | loss: 89.6733248CurrentTrain: epoch  3, batch     0 | loss: 79.7076927CurrentTrain: epoch  3, batch     1 | loss: 67.1287715CurrentTrain: epoch  3, batch     2 | loss: 102.4236200CurrentTrain: epoch  3, batch     3 | loss: 48.3876993CurrentTrain: epoch  4, batch     0 | loss: 76.6797316CurrentTrain: epoch  4, batch     1 | loss: 78.3721611CurrentTrain: epoch  4, batch     2 | loss: 97.1531129CurrentTrain: epoch  4, batch     3 | loss: 57.7296690CurrentTrain: epoch  5, batch     0 | loss: 64.9816751CurrentTrain: epoch  5, batch     1 | loss: 96.8864405CurrentTrain: epoch  5, batch     2 | loss: 79.0475287CurrentTrain: epoch  5, batch     3 | loss: 85.7581721CurrentTrain: epoch  6, batch     0 | loss: 63.7098473CurrentTrain: epoch  6, batch     1 | loss: 100.6915945CurrentTrain: epoch  6, batch     2 | loss: 80.8298486CurrentTrain: epoch  6, batch     3 | loss: 44.5581604CurrentTrain: epoch  7, batch     0 | loss: 78.1626809CurrentTrain: epoch  7, batch     1 | loss: 76.3960220CurrentTrain: epoch  7, batch     2 | loss: 66.1669334CurrentTrain: epoch  7, batch     3 | loss: 64.0764839CurrentTrain: epoch  8, batch     0 | loss: 119.7781363CurrentTrain: epoch  8, batch     1 | loss: 77.9534963CurrentTrain: epoch  8, batch     2 | loss: 67.1738668CurrentTrain: epoch  8, batch     3 | loss: 66.3902629CurrentTrain: epoch  9, batch     0 | loss: 62.9716615CurrentTrain: epoch  9, batch     1 | loss: 74.0608816CurrentTrain: epoch  9, batch     2 | loss: 79.7125145CurrentTrain: epoch  9, batch     3 | loss: 53.0044816
MemoryTrain:  epoch  0, batch     0 | loss: 0.8918639MemoryTrain:  epoch  1, batch     0 | loss: 0.7840947MemoryTrain:  epoch  2, batch     0 | loss: 0.6198459MemoryTrain:  epoch  3, batch     0 | loss: 0.5470059MemoryTrain:  epoch  4, batch     0 | loss: 0.4580335MemoryTrain:  epoch  5, batch     0 | loss: 0.3959545MemoryTrain:  epoch  6, batch     0 | loss: 0.3431121MemoryTrain:  epoch  7, batch     0 | loss: 0.3113308MemoryTrain:  epoch  8, batch     0 | loss: 0.2780239MemoryTrain:  epoch  9, batch     0 | loss: 0.2159246

F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.8571428571428571), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 25: np.float64(0.4411764705882353), 26: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.8380952380952381), 37: np.float64(0.5818181818181818), 38: np.float64(0.6521739130434783), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4904051172707889
Weighted-average F1 score: 0.38274096022693194
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.8181818181818182), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.475), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.7572815533980582), 36: np.float64(0.0), 37: np.float64(0.5254237288135594), 38: np.float64(0.6938775510204082), 40: np.float64(0.0)}
Micro-average F1 score: 0.40421792618629176
Weighted-average F1 score: 0.2922359441236301
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.782608695652174), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 25: np.float64(0.4675324675324675), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.7547169811320755), 37: np.float64(0.512396694214876), 38: np.float64(0.6808510638297872), 40: np.float64(0.0)}
Micro-average F1 score: 0.4214417744916821
Weighted-average F1 score: 0.31636478604096324

F1 score per class: {1: np.float64(0.1440677966101695), 2: np.float64(0.42857142857142855), 3: np.float64(0.358974358974359), 5: np.float64(0.7272727272727273), 6: np.float64(0.11214953271028037), 7: np.float64(0.052980132450331126), 8: np.float64(0.09195402298850575), 9: np.float64(0.7692307692307693), 10: np.float64(0.2613065326633166), 11: np.float64(0.128), 12: np.float64(0.1590909090909091), 14: np.float64(0.06622516556291391), 15: np.float64(0.33962264150943394), 16: np.float64(0.5925925925925926), 17: np.float64(0.0), 18: np.float64(0.06896551724137931), 19: np.float64(0.5702127659574469), 20: np.float64(0.5185185185185185), 22: np.float64(0.32748538011695905), 24: np.float64(0.0), 25: np.float64(0.4411764705882353), 26: np.float64(0.6781609195402298), 27: np.float64(0.0), 28: np.float64(0.09917355371900827), 29: np.float64(0.75), 30: np.float64(0.918918918918919), 31: np.float64(0.06060606060606061), 32: np.float64(0.596078431372549), 33: np.float64(0.375), 34: np.float64(0.21818181818181817), 35: np.float64(0.2829581993569132), 36: np.float64(0.0), 37: np.float64(0.1702127659574468), 38: np.float64(0.2727272727272727), 39: np.float64(0.0), 40: np.float64(0.1535181236673774)}
Micro-average F1 score: 0.32014757122361137
Weighted-average F1 score: 0.3054161656070673
F1 score per class: {1: np.float64(0.15447154471544716), 2: np.float64(0.4117647058823529), 3: np.float64(0.4318181818181818), 5: np.float64(0.5730994152046783), 6: np.float64(0.2987012987012987), 7: np.float64(0.06015037593984962), 8: np.float64(0.25862068965517243), 9: np.float64(0.3968253968253968), 10: np.float64(0.31390134529147984), 11: np.float64(0.13008130081300814), 12: np.float64(0.21782178217821782), 14: np.float64(0.072), 15: np.float64(0.42857142857142855), 16: np.float64(0.52), 17: np.float64(0.2222222222222222), 18: np.float64(0.13636363636363635), 19: np.float64(0.48484848484848486), 20: np.float64(0.4634146341463415), 22: np.float64(0.32599118942731276), 24: np.float64(0.1), 25: np.float64(0.4523809523809524), 26: np.float64(0.6735751295336787), 27: np.float64(0.0), 28: np.float64(0.09900990099009901), 29: np.float64(0.782608695652174), 30: np.float64(0.6666666666666666), 31: np.float64(0.03125), 32: np.float64(0.6181818181818182), 33: np.float64(0.35294117647058826), 34: np.float64(0.25089605734767023), 35: np.float64(0.3), 36: np.float64(0.3404255319148936), 37: np.float64(0.15776081424936386), 38: np.float64(0.3238095238095238), 39: np.float64(0.0), 40: np.float64(0.23411371237458195)}
Micro-average F1 score: 0.33623600497600853
Weighted-average F1 score: 0.3192041172347788
F1 score per class: {1: np.float64(0.16194331983805668), 2: np.float64(0.4666666666666667), 3: np.float64(0.4935064935064935), 5: np.float64(0.6105919003115264), 6: np.float64(0.21138211382113822), 7: np.float64(0.05555555555555555), 8: np.float64(0.10752688172043011), 9: np.float64(0.5882352941176471), 10: np.float64(0.3181818181818182), 11: np.float64(0.13008130081300814), 12: np.float64(0.23469387755102042), 14: np.float64(0.09716599190283401), 15: np.float64(0.391304347826087), 16: np.float64(0.5050505050505051), 17: np.float64(0.23529411764705882), 18: np.float64(0.12195121951219512), 19: np.float64(0.5211726384364821), 20: np.float64(0.5), 22: np.float64(0.34285714285714286), 24: np.float64(0.0), 25: np.float64(0.45569620253164556), 26: np.float64(0.7032967032967034), 27: np.float64(0.0), 28: np.float64(0.10526315789473684), 29: np.float64(0.782608695652174), 30: np.float64(0.8717948717948718), 31: np.float64(0.041666666666666664), 32: np.float64(0.610909090909091), 33: np.float64(0.35294117647058826), 34: np.float64(0.22545454545454546), 35: np.float64(0.27586206896551724), 36: np.float64(0.2564102564102564), 37: np.float64(0.14385150812064965), 38: np.float64(0.29357798165137616), 39: np.float64(0.0), 40: np.float64(0.2023121387283237)}
Micro-average F1 score: 0.3357261181667587
Weighted-average F1 score: 0.31864103802120736

F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.6), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 25: np.float64(0.4225352112676056), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.7096774193548387), 37: np.float64(0.4740740740740741), 38: np.float64(0.45454545454545453), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3377386196769457
Weighted-average F1 score: 0.25971438219848036
F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.6206896551724138), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.4470588235294118), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.6782608695652174), 36: np.float64(0.0), 37: np.float64(0.42758620689655175), 38: np.float64(0.5), 40: np.float64(0.0)}
Micro-average F1 score: 0.2798053527980535
Weighted-average F1 score: 0.2033809466394964
F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.5806451612903226), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 25: np.float64(0.4444444444444444), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.6666666666666666), 36: np.float64(0.0), 37: np.float64(0.4161073825503356), 38: np.float64(0.49230769230769234), 40: np.float64(0.0)}
Micro-average F1 score: 0.2930591259640103
Weighted-average F1 score: 0.21894519746681135

F1 score per class: {1: np.float64(0.07906976744186046), 2: np.float64(0.24489795918367346), 3: np.float64(0.2557077625570776), 5: np.float64(0.5378151260504201), 6: np.float64(0.10344827586206896), 7: np.float64(0.025078369905956112), 8: np.float64(0.08888888888888889), 9: np.float64(0.6666666666666666), 10: np.float64(0.21311475409836064), 11: np.float64(0.1111111111111111), 12: np.float64(0.09427609427609428), 14: np.float64(0.05128205128205128), 15: np.float64(0.20930232558139536), 16: np.float64(0.3310344827586207), 17: np.float64(0.0), 18: np.float64(0.05405405405405406), 19: np.float64(0.5338645418326693), 20: np.float64(0.34146341463414637), 22: np.float64(0.2679425837320574), 24: np.float64(0.0), 25: np.float64(0.4225352112676056), 26: np.float64(0.6113989637305699), 27: np.float64(0.0), 28: np.float64(0.047244094488188976), 29: np.float64(0.6666666666666666), 30: np.float64(0.8717948717948718), 31: np.float64(0.03389830508474576), 32: np.float64(0.4720496894409938), 33: np.float64(0.3157894736842105), 34: np.float64(0.11960132890365449), 35: np.float64(0.1682600382409178), 36: np.float64(0.0), 37: np.float64(0.10423452768729642), 38: np.float64(0.12605042016806722), 39: np.float64(0.0), 40: np.float64(0.10557184750733138)}
Micro-average F1 score: 0.22027922718939502
Weighted-average F1 score: 0.20054634785300454
F1 score per class: {1: np.float64(0.08189655172413793), 2: np.float64(0.22580645161290322), 3: np.float64(0.28078817733990147), 5: np.float64(0.3912175648702595), 6: np.float64(0.23834196891191708), 7: np.float64(0.02909090909090909), 8: np.float64(0.22388059701492538), 9: np.float64(0.2808988764044944), 10: np.float64(0.23026315789473684), 11: np.float64(0.12307692307692308), 12: np.float64(0.12087912087912088), 14: np.float64(0.05572755417956656), 15: np.float64(0.27692307692307694), 16: np.float64(0.3151515151515151), 17: np.float64(0.12903225806451613), 18: np.float64(0.09090909090909091), 19: np.float64(0.4289544235924933), 20: np.float64(0.2714285714285714), 22: np.float64(0.24262295081967214), 24: np.float64(0.08333333333333333), 25: np.float64(0.40425531914893614), 26: np.float64(0.5752212389380531), 27: np.float64(0.0), 28: np.float64(0.043478260869565216), 29: np.float64(0.6792452830188679), 30: np.float64(0.6071428571428571), 31: np.float64(0.017094017094017096), 32: np.float64(0.46703296703296704), 33: np.float64(0.2727272727272727), 34: np.float64(0.15151515151515152), 35: np.float64(0.18932038834951456), 36: np.float64(0.25196850393700787), 37: np.float64(0.09627329192546584), 38: np.float64(0.1574074074074074), 39: np.float64(0.0), 40: np.float64(0.15873015873015872)}
Micro-average F1 score: 0.22715812222355625
Weighted-average F1 score: 0.21186430112906976
F1 score per class: {1: np.float64(0.087527352297593), 2: np.float64(0.27450980392156865), 3: np.float64(0.3352941176470588), 5: np.float64(0.421505376344086), 6: np.float64(0.18571428571428572), 7: np.float64(0.025974025974025976), 8: np.float64(0.10204081632653061), 9: np.float64(0.45871559633027525), 10: np.float64(0.2422145328719723), 11: np.float64(0.12403100775193798), 12: np.float64(0.12777777777777777), 14: np.float64(0.0761904761904762), 15: np.float64(0.23376623376623376), 16: np.float64(0.3105590062111801), 17: np.float64(0.15384615384615385), 18: np.float64(0.07194244604316546), 19: np.float64(0.4804804804804805), 20: np.float64(0.2962962962962963), 22: np.float64(0.26373626373626374), 24: np.float64(0.0), 25: np.float64(0.4090909090909091), 26: np.float64(0.624390243902439), 27: np.float64(0.0), 28: np.float64(0.047619047619047616), 29: np.float64(0.6824644549763034), 30: np.float64(0.8292682926829268), 31: np.float64(0.024096385542168676), 32: np.float64(0.46408839779005523), 33: np.float64(0.2727272727272727), 34: np.float64(0.13507625272331156), 35: np.float64(0.16985138004246284), 36: np.float64(0.21052631578947367), 37: np.float64(0.0893371757925072), 38: np.float64(0.14349775784753363), 39: np.float64(0.0), 40: np.float64(0.1364522417153996)}
Micro-average F1 score: 0.22814258911819887
Weighted-average F1 score: 0.2107638978448004
cur_acc_wo_na:  ['0.7525', '0.4975', '0.5386', '0.6288', '0.3748', '0.3303', '0.4904']
his_acc_wo_na:  ['0.7525', '0.6748', '0.5476', '0.5187', '0.4121', '0.3295', '0.3201']
cur_acc des_wo_na:  ['0.7398', '0.5925', '0.4280', '0.5681', '0.3356', '0.4142', '0.4042']
his_acc des_wo_na:  ['0.7398', '0.6479', '0.5339', '0.5027', '0.4017', '0.3671', '0.3362']
cur_acc rrf_wo_na:  ['0.7575', '0.6054', '0.4737', '0.5780', '0.3614', '0.4303', '0.4214']
his_acc rrf_wo_na:  ['0.7575', '0.6749', '0.5392', '0.5008', '0.4040', '0.3580', '0.3357']
cur_acc_w_na:  ['0.6501', '0.3929', '0.3898', '0.4165', '0.2493', '0.2644', '0.3377']
his_acc_w_na:  ['0.6501', '0.5487', '0.3999', '0.3739', '0.2808', '0.2375', '0.2203']
cur_acc des_w_na:  ['0.5984', '0.4225', '0.2913', '0.3521', '0.2170', '0.3241', '0.2798']
his_acc des_w_na:  ['0.5984', '0.4892', '0.3761', '0.3344', '0.2608', '0.2520', '0.2272']
cur_acc rrf_w_na:  ['0.6170', '0.4341', '0.3263', '0.3642', '0.2357', '0.3455', '0.2931']
his_acc rrf_w_na:  ['0.6170', '0.5106', '0.3870', '0.3391', '0.2640', '0.2484', '0.2281']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 96.9783819CurrentTrain: epoch  0, batch     1 | loss: 153.1335959CurrentTrain: epoch  0, batch     2 | loss: 85.6663080CurrentTrain: epoch  0, batch     3 | loss: 80.5669009CurrentTrain: epoch  1, batch     0 | loss: 90.2350123CurrentTrain: epoch  1, batch     1 | loss: 81.4720644CurrentTrain: epoch  1, batch     2 | loss: 79.0819876CurrentTrain: epoch  1, batch     3 | loss: 71.6163452CurrentTrain: epoch  2, batch     0 | loss: 110.9328033CurrentTrain: epoch  2, batch     1 | loss: 75.8451309CurrentTrain: epoch  2, batch     2 | loss: 83.4048955CurrentTrain: epoch  2, batch     3 | loss: 85.4399501CurrentTrain: epoch  3, batch     0 | loss: 106.4406698CurrentTrain: epoch  3, batch     1 | loss: 88.2846635CurrentTrain: epoch  3, batch     2 | loss: 79.1188765CurrentTrain: epoch  3, batch     3 | loss: 66.0604833CurrentTrain: epoch  4, batch     0 | loss: 81.1135911CurrentTrain: epoch  4, batch     1 | loss: 98.0920405CurrentTrain: epoch  4, batch     2 | loss: 129.2481035CurrentTrain: epoch  4, batch     3 | loss: 66.7402001CurrentTrain: epoch  5, batch     0 | loss: 77.8833685CurrentTrain: epoch  5, batch     1 | loss: 81.5440861CurrentTrain: epoch  5, batch     2 | loss: 86.4679762CurrentTrain: epoch  5, batch     3 | loss: 76.6501004CurrentTrain: epoch  6, batch     0 | loss: 101.2104647CurrentTrain: epoch  6, batch     1 | loss: 67.9875245CurrentTrain: epoch  6, batch     2 | loss: 77.4354186CurrentTrain: epoch  6, batch     3 | loss: 64.8607696CurrentTrain: epoch  7, batch     0 | loss: 81.6527362CurrentTrain: epoch  7, batch     1 | loss: 66.4157729CurrentTrain: epoch  7, batch     2 | loss: 76.3676608CurrentTrain: epoch  7, batch     3 | loss: 80.0778305CurrentTrain: epoch  8, batch     0 | loss: 102.2922668CurrentTrain: epoch  8, batch     1 | loss: 77.3104309CurrentTrain: epoch  8, batch     2 | loss: 78.9710464CurrentTrain: epoch  8, batch     3 | loss: 59.5481672CurrentTrain: epoch  9, batch     0 | loss: 66.1029137CurrentTrain: epoch  9, batch     1 | loss: 74.6899249CurrentTrain: epoch  9, batch     2 | loss: 98.9750204CurrentTrain: epoch  9, batch     3 | loss: 76.0037136
MemoryTrain:  epoch  0, batch     0 | loss: 0.9089125MemoryTrain:  epoch  1, batch     0 | loss: 0.8213144MemoryTrain:  epoch  2, batch     0 | loss: 0.6342161MemoryTrain:  epoch  3, batch     0 | loss: 0.4932525MemoryTrain:  epoch  4, batch     0 | loss: 0.4328891MemoryTrain:  epoch  5, batch     0 | loss: 0.3810847MemoryTrain:  epoch  6, batch     0 | loss: 0.3322844MemoryTrain:  epoch  7, batch     0 | loss: 0.3306809MemoryTrain:  epoch  8, batch     0 | loss: 0.2622612MemoryTrain:  epoch  9, batch     0 | loss: 0.2446803

F1 score per class: {0: np.float64(0.8767123287671232), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.93048128342246), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.23529411764705882), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.35), 23: np.float64(0.8297872340425532), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.6600790513833992
Weighted-average F1 score: 0.5506540031648082
F1 score per class: {0: np.float64(0.7472527472527473), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8307692307692308), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.14814814814814814), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.5230769230769231), 22: np.float64(0.0), 23: np.float64(0.7317073170731707), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5022970903522205
Weighted-average F1 score: 0.383206364933397
F1 score per class: {0: np.float64(0.8354430379746836), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8723404255319149), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.15384615384615385), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.5161290322580645), 22: np.float64(0.0), 23: np.float64(0.7294117647058823), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5457570715474209
Weighted-average F1 score: 0.4168057252791023

F1 score per class: {0: np.float64(0.48484848484848486), 1: np.float64(0.14893617021276595), 2: np.float64(0.35294117647058826), 3: np.float64(0.3708609271523179), 4: np.float64(0.925531914893617), 5: np.float64(0.7966101694915254), 6: np.float64(0.10909090909090909), 7: np.float64(0.04285714285714286), 8: np.float64(0.047058823529411764), 9: np.float64(0.7575757575757576), 10: np.float64(0.1793103448275862), 11: np.float64(0.140625), 12: np.float64(0.015384615384615385), 13: np.float64(0.02962962962962963), 14: np.float64(0.022727272727272728), 15: np.float64(0.45161290322580644), 16: np.float64(0.6470588235294118), 17: np.float64(0.0), 18: np.float64(0.07142857142857142), 19: np.float64(0.5327102803738317), 20: np.float64(0.5365853658536586), 21: np.float64(0.08187134502923976), 22: np.float64(0.1), 23: np.float64(0.7222222222222222), 24: np.float64(0.0), 25: np.float64(0.44776119402985076), 26: np.float64(0.6783625730994152), 27: np.float64(0.0), 28: np.float64(0.1095890410958904), 29: np.float64(0.7526881720430108), 30: np.float64(0.918918918918919), 31: np.float64(0.08695652173913043), 32: np.float64(0.5949820788530465), 33: np.float64(0.375), 34: np.float64(0.26865671641791045), 35: np.float64(0.34854771784232363), 36: np.float64(0.0), 37: np.float64(0.24545454545454545), 38: np.float64(0.34210526315789475), 39: np.float64(0.0), 40: np.float64(0.2422145328719723)}
Micro-average F1 score: 0.366814066119183
Weighted-average F1 score: 0.36791840043157664
F1 score per class: {0: np.float64(0.22972972972972974), 1: np.float64(0.1694915254237288), 2: np.float64(0.2413793103448276), 3: np.float64(0.38661710037174724), 4: np.float64(0.8059701492537313), 5: np.float64(0.5962732919254659), 6: np.float64(0.23448275862068965), 7: np.float64(0.046242774566473986), 8: np.float64(0.25210084033613445), 9: np.float64(0.43859649122807015), 10: np.float64(0.24752475247524752), 11: np.float64(0.1322314049586777), 12: np.float64(0.12359550561797752), 13: np.float64(0.018433179723502304), 14: np.float64(0.04878048780487805), 15: np.float64(0.46153846153846156), 16: np.float64(0.5925925925925926), 17: np.float64(0.3333333333333333), 18: np.float64(0.19047619047619047), 19: np.float64(0.5050505050505051), 20: np.float64(0.5052631578947369), 21: np.float64(0.14847161572052403), 22: np.float64(0.24598930481283424), 23: np.float64(0.631578947368421), 24: np.float64(0.0), 25: np.float64(0.49411764705882355), 26: np.float64(0.6310679611650486), 27: np.float64(0.0), 28: np.float64(0.09523809523809523), 29: np.float64(0.783068783068783), 30: np.float64(0.68), 31: np.float64(0.08), 32: np.float64(0.5771812080536913), 33: np.float64(0.375), 34: np.float64(0.3153153153153153), 35: np.float64(0.2724252491694352), 36: np.float64(0.3333333333333333), 37: np.float64(0.20945945945945946), 38: np.float64(0.2903225806451613), 39: np.float64(0.0), 40: np.float64(0.3037037037037037)}
Micro-average F1 score: 0.3415182153747392
Weighted-average F1 score: 0.32223942507795544
F1 score per class: {0: np.float64(0.3113207547169811), 1: np.float64(0.1694915254237288), 2: np.float64(0.2857142857142857), 3: np.float64(0.41818181818181815), 4: np.float64(0.8586387434554974), 5: np.float64(0.6981818181818182), 6: np.float64(0.1875), 7: np.float64(0.04678362573099415), 8: np.float64(0.06896551724137931), 9: np.float64(0.625), 10: np.float64(0.24242424242424243), 11: np.float64(0.12403100775193798), 12: np.float64(0.10404624277456648), 13: np.float64(0.018867924528301886), 14: np.float64(0.047619047619047616), 15: np.float64(0.45161290322580644), 16: np.float64(0.6), 17: np.float64(0.26666666666666666), 18: np.float64(0.14084507042253522), 19: np.float64(0.5494505494505495), 20: np.float64(0.5168539325842697), 21: np.float64(0.12903225806451613), 22: np.float64(0.16666666666666666), 23: np.float64(0.6138613861386139), 24: np.float64(0.0), 25: np.float64(0.4931506849315068), 26: np.float64(0.6455026455026455), 27: np.float64(0.0), 28: np.float64(0.10526315789473684), 29: np.float64(0.7724867724867724), 30: np.float64(0.8292682926829268), 31: np.float64(0.06060606060606061), 32: np.float64(0.5838926174496645), 33: np.float64(0.375), 34: np.float64(0.3033175355450237), 35: np.float64(0.2867132867132867), 36: np.float64(0.1917808219178082), 37: np.float64(0.19243986254295534), 38: np.float64(0.2807017543859649), 39: np.float64(0.0), 40: np.float64(0.2827586206896552)}
Micro-average F1 score: 0.3449706187348773
Weighted-average F1 score: 0.32840538074751546

F1 score per class: {0: np.float64(0.8533333333333334), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8877551020408163), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.11764705882352941), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.30434782608695654), 23: np.float64(0.7289719626168224), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5015015015015015
Weighted-average F1 score: 0.3797454177506302
F1 score per class: {0: np.float64(0.6666666666666666), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7941176470588235), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.07547169811320754), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.3695652173913043), 22: np.float64(0.0), 23: np.float64(0.594059405940594), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3557483731019523
Weighted-average F1 score: 0.2623460061517757
F1 score per class: {0: np.float64(0.7857142857142857), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8324873096446701), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.07407407407407407), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.35555555555555557), 22: np.float64(0.0), 23: np.float64(0.5904761904761905), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3854289071680376
Weighted-average F1 score: 0.2797699951174816

F1 score per class: {0: np.float64(0.3368421052631579), 1: np.float64(0.08045977011494253), 2: np.float64(0.21428571428571427), 3: np.float64(0.2692307692307692), 4: np.float64(0.8613861386138614), 5: np.float64(0.6372881355932203), 6: np.float64(0.10256410256410256), 7: np.float64(0.021897810218978103), 8: np.float64(0.0449438202247191), 9: np.float64(0.6666666666666666), 10: np.float64(0.16560509554140126), 11: np.float64(0.11842105263157894), 12: np.float64(0.011976047904191617), 13: np.float64(0.013793103448275862), 14: np.float64(0.01904761904761905), 15: np.float64(0.22580645161290322), 16: np.float64(0.411214953271028), 17: np.float64(0.0), 18: np.float64(0.04819277108433735), 19: np.float64(0.5), 20: np.float64(0.3120567375886525), 21: np.float64(0.058333333333333334), 22: np.float64(0.08955223880597014), 23: np.float64(0.5611510791366906), 24: np.float64(0.0), 25: np.float64(0.43478260869565216), 26: np.float64(0.6105263157894737), 27: np.float64(0.0), 28: np.float64(0.058823529411764705), 29: np.float64(0.6511627906976745), 30: np.float64(0.85), 31: np.float64(0.05128205128205128), 32: np.float64(0.4474393530997305), 33: np.float64(0.3333333333333333), 34: np.float64(0.16822429906542055), 35: np.float64(0.21761658031088082), 36: np.float64(0.0), 37: np.float64(0.16718266253869968), 38: np.float64(0.18181818181818182), 39: np.float64(0.0), 40: np.float64(0.20648967551622419)}
Micro-average F1 score: 0.2689516751582523
Weighted-average F1 score: 0.25431991882776894
F1 score per class: {0: np.float64(0.15011037527593818), 1: np.float64(0.09111617312072894), 2: np.float64(0.14736842105263157), 3: np.float64(0.24413145539906103), 4: np.float64(0.7105263157894737), 5: np.float64(0.41379310344827586), 6: np.float64(0.19653179190751446), 7: np.float64(0.02197802197802198), 8: np.float64(0.21428571428571427), 9: np.float64(0.3333333333333333), 10: np.float64(0.18115942028985507), 11: np.float64(0.128), 12: np.float64(0.08058608058608059), 13: np.float64(0.009070294784580499), 14: np.float64(0.0410958904109589), 15: np.float64(0.32432432432432434), 16: np.float64(0.3356643356643357), 17: np.float64(0.2), 18: np.float64(0.1092896174863388), 19: np.float64(0.44510385756676557), 20: np.float64(0.26666666666666666), 21: np.float64(0.10461538461538461), 22: np.float64(0.1908713692946058), 23: np.float64(0.47619047619047616), 24: np.float64(0.0), 25: np.float64(0.4666666666666667), 26: np.float64(0.5327868852459017), 27: np.float64(0.0), 28: np.float64(0.043795620437956206), 29: np.float64(0.6607142857142857), 30: np.float64(0.576271186440678), 31: np.float64(0.041237113402061855), 32: np.float64(0.41545893719806765), 33: np.float64(0.3), 34: np.float64(0.1794871794871795), 35: np.float64(0.17012448132780084), 36: np.float64(0.2564102564102564), 37: np.float64(0.1316348195329087), 38: np.float64(0.15859030837004406), 39: np.float64(0.0), 40: np.float64(0.23098591549295774)}
Micro-average F1 score: 0.23163165342331554
Weighted-average F1 score: 0.2141119675983165
F1 score per class: {0: np.float64(0.1981981981981982), 1: np.float64(0.09029345372460497), 2: np.float64(0.1728395061728395), 3: np.float64(0.27380952380952384), 4: np.float64(0.780952380952381), 5: np.float64(0.4948453608247423), 6: np.float64(0.16783216783216784), 7: np.float64(0.022099447513812154), 8: np.float64(0.06451612903225806), 9: np.float64(0.5154639175257731), 10: np.float64(0.1927710843373494), 11: np.float64(0.11940298507462686), 12: np.float64(0.06741573033707865), 13: np.float64(0.0091324200913242), 14: np.float64(0.04054054054054054), 15: np.float64(0.2978723404255319), 16: np.float64(0.3404255319148936), 17: np.float64(0.16666666666666666), 18: np.float64(0.07751937984496124), 19: np.float64(0.4983388704318937), 20: np.float64(0.2754491017964072), 21: np.float64(0.0903954802259887), 22: np.float64(0.13559322033898305), 23: np.float64(0.46616541353383456), 24: np.float64(0.0), 25: np.float64(0.4444444444444444), 26: np.float64(0.5674418604651162), 27: np.float64(0.0), 28: np.float64(0.049079754601226995), 29: np.float64(0.6517857142857143), 30: np.float64(0.7727272727272727), 31: np.float64(0.03076923076923077), 32: np.float64(0.4233576642335766), 33: np.float64(0.2857142857142857), 34: np.float64(0.1679790026246719), 35: np.float64(0.17634408602150536), 36: np.float64(0.15730337078651685), 37: np.float64(0.11764705882352941), 38: np.float64(0.14814814814814814), 39: np.float64(0.0), 40: np.float64(0.21750663129973474)}
Micro-average F1 score: 0.23496174220129487
Weighted-average F1 score: 0.21617756396768395
cur_acc_wo_na:  ['0.7525', '0.4975', '0.5386', '0.6288', '0.3748', '0.3303', '0.4904', '0.6601']
his_acc_wo_na:  ['0.7525', '0.6748', '0.5476', '0.5187', '0.4121', '0.3295', '0.3201', '0.3668']
cur_acc des_wo_na:  ['0.7398', '0.5925', '0.4280', '0.5681', '0.3356', '0.4142', '0.4042', '0.5023']
his_acc des_wo_na:  ['0.7398', '0.6479', '0.5339', '0.5027', '0.4017', '0.3671', '0.3362', '0.3415']
cur_acc rrf_wo_na:  ['0.7575', '0.6054', '0.4737', '0.5780', '0.3614', '0.4303', '0.4214', '0.5458']
his_acc rrf_wo_na:  ['0.7575', '0.6749', '0.5392', '0.5008', '0.4040', '0.3580', '0.3357', '0.3450']
cur_acc_w_na:  ['0.6501', '0.3929', '0.3898', '0.4165', '0.2493', '0.2644', '0.3377', '0.5015']
his_acc_w_na:  ['0.6501', '0.5487', '0.3999', '0.3739', '0.2808', '0.2375', '0.2203', '0.2690']
cur_acc des_w_na:  ['0.5984', '0.4225', '0.2913', '0.3521', '0.2170', '0.3241', '0.2798', '0.3557']
his_acc des_w_na:  ['0.5984', '0.4892', '0.3761', '0.3344', '0.2608', '0.2520', '0.2272', '0.2316']
cur_acc rrf_w_na:  ['0.6170', '0.4341', '0.3263', '0.3642', '0.2357', '0.3455', '0.2931', '0.3854']
his_acc rrf_w_na:  ['0.6170', '0.5106', '0.3870', '0.3391', '0.2640', '0.2484', '0.2281', '0.2350']
--------Round  2
seed:  300
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 2 3 1 5 6 0 4]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 84.9187680CurrentTrain: epoch  0, batch     1 | loss: 80.0199978CurrentTrain: epoch  0, batch     2 | loss: 102.9457867CurrentTrain: epoch  0, batch     3 | loss: 102.5281812CurrentTrain: epoch  0, batch     4 | loss: 87.8082038CurrentTrain: epoch  0, batch     5 | loss: 119.6328846CurrentTrain: epoch  0, batch     6 | loss: 100.7057848CurrentTrain: epoch  0, batch     7 | loss: 119.5316946CurrentTrain: epoch  0, batch     8 | loss: 86.4099428CurrentTrain: epoch  0, batch     9 | loss: 119.0478053CurrentTrain: epoch  0, batch    10 | loss: 86.2000083CurrentTrain: epoch  0, batch    11 | loss: 86.7335103CurrentTrain: epoch  0, batch    12 | loss: 86.6683440CurrentTrain: epoch  0, batch    13 | loss: 119.0058283CurrentTrain: epoch  0, batch    14 | loss: 147.1399947CurrentTrain: epoch  0, batch    15 | loss: 118.1817342CurrentTrain: epoch  0, batch    16 | loss: 118.7256320CurrentTrain: epoch  0, batch    17 | loss: 99.7998787CurrentTrain: epoch  0, batch    18 | loss: 146.1597182CurrentTrain: epoch  0, batch    19 | loss: 100.2008405CurrentTrain: epoch  0, batch    20 | loss: 76.3631628CurrentTrain: epoch  0, batch    21 | loss: 88.1269900CurrentTrain: epoch  0, batch    22 | loss: 86.9986979CurrentTrain: epoch  0, batch    23 | loss: 117.9520208CurrentTrain: epoch  0, batch    24 | loss: 117.1197408CurrentTrain: epoch  0, batch    25 | loss: 117.7597435CurrentTrain: epoch  0, batch    26 | loss: 85.2126467CurrentTrain: epoch  0, batch    27 | loss: 193.2707986CurrentTrain: epoch  0, batch    28 | loss: 99.2459605CurrentTrain: epoch  0, batch    29 | loss: 99.6039982CurrentTrain: epoch  0, batch    30 | loss: 99.2192926CurrentTrain: epoch  0, batch    31 | loss: 85.5366719CurrentTrain: epoch  0, batch    32 | loss: 118.3739336CurrentTrain: epoch  0, batch    33 | loss: 84.9945147CurrentTrain: epoch  0, batch    34 | loss: 98.7332437CurrentTrain: epoch  0, batch    35 | loss: 98.7354712CurrentTrain: epoch  0, batch    36 | loss: 117.7523000CurrentTrain: epoch  0, batch    37 | loss: 97.3122916CurrentTrain: epoch  0, batch    38 | loss: 98.3881965CurrentTrain: epoch  0, batch    39 | loss: 116.4831429CurrentTrain: epoch  0, batch    40 | loss: 84.6533132CurrentTrain: epoch  0, batch    41 | loss: 98.6010665CurrentTrain: epoch  0, batch    42 | loss: 146.7404844CurrentTrain: epoch  0, batch    43 | loss: 117.3025780CurrentTrain: epoch  0, batch    44 | loss: 98.1511438CurrentTrain: epoch  0, batch    45 | loss: 97.8169316CurrentTrain: epoch  0, batch    46 | loss: 84.4188934CurrentTrain: epoch  0, batch    47 | loss: 97.1033893CurrentTrain: epoch  0, batch    48 | loss: 97.2299848CurrentTrain: epoch  0, batch    49 | loss: 97.0385384CurrentTrain: epoch  0, batch    50 | loss: 85.0370591CurrentTrain: epoch  0, batch    51 | loss: 116.9927158CurrentTrain: epoch  0, batch    52 | loss: 73.3928127CurrentTrain: epoch  0, batch    53 | loss: 116.9571940CurrentTrain: epoch  0, batch    54 | loss: 95.5225839CurrentTrain: epoch  0, batch    55 | loss: 114.5598693CurrentTrain: epoch  0, batch    56 | loss: 143.7436872CurrentTrain: epoch  0, batch    57 | loss: 71.1116787CurrentTrain: epoch  0, batch    58 | loss: 114.4533783CurrentTrain: epoch  0, batch    59 | loss: 80.4369899CurrentTrain: epoch  0, batch    60 | loss: 114.1338427CurrentTrain: epoch  0, batch    61 | loss: 96.4346030CurrentTrain: epoch  0, batch    62 | loss: 96.1101344CurrentTrain: epoch  0, batch    63 | loss: 70.9212957CurrentTrain: epoch  0, batch    64 | loss: 114.6551841CurrentTrain: epoch  0, batch    65 | loss: 92.4424030CurrentTrain: epoch  0, batch    66 | loss: 95.9603015CurrentTrain: epoch  0, batch    67 | loss: 139.3209380CurrentTrain: epoch  0, batch    68 | loss: 111.4751610CurrentTrain: epoch  0, batch    69 | loss: 81.9943567CurrentTrain: epoch  0, batch    70 | loss: 78.2724608CurrentTrain: epoch  0, batch    71 | loss: 80.4069571CurrentTrain: epoch  0, batch    72 | loss: 115.8023918CurrentTrain: epoch  0, batch    73 | loss: 95.2705197CurrentTrain: epoch  0, batch    74 | loss: 77.8411118CurrentTrain: epoch  0, batch    75 | loss: 93.6180981CurrentTrain: epoch  0, batch    76 | loss: 70.7540690CurrentTrain: epoch  0, batch    77 | loss: 94.6750404CurrentTrain: epoch  0, batch    78 | loss: 81.8651312CurrentTrain: epoch  0, batch    79 | loss: 114.6223229CurrentTrain: epoch  0, batch    80 | loss: 94.2405031CurrentTrain: epoch  0, batch    81 | loss: 93.6410476CurrentTrain: epoch  0, batch    82 | loss: 82.1762737CurrentTrain: epoch  0, batch    83 | loss: 89.1485009CurrentTrain: epoch  0, batch    84 | loss: 111.7065455CurrentTrain: epoch  0, batch    85 | loss: 92.9460665CurrentTrain: epoch  0, batch    86 | loss: 91.2194019CurrentTrain: epoch  0, batch    87 | loss: 111.3348521CurrentTrain: epoch  0, batch    88 | loss: 94.1209001CurrentTrain: epoch  0, batch    89 | loss: 111.1485501CurrentTrain: epoch  0, batch    90 | loss: 92.2612666CurrentTrain: epoch  0, batch    91 | loss: 78.5373034CurrentTrain: epoch  0, batch    92 | loss: 80.0321534CurrentTrain: epoch  0, batch    93 | loss: 94.5647958CurrentTrain: epoch  0, batch    94 | loss: 92.5733715CurrentTrain: epoch  0, batch    95 | loss: 118.3621051CurrentTrain: epoch  1, batch     0 | loss: 78.9228737CurrentTrain: epoch  1, batch     1 | loss: 78.1657952CurrentTrain: epoch  1, batch     2 | loss: 111.0768248CurrentTrain: epoch  1, batch     3 | loss: 79.2540233CurrentTrain: epoch  1, batch     4 | loss: 76.5699507CurrentTrain: epoch  1, batch     5 | loss: 106.9430451CurrentTrain: epoch  1, batch     6 | loss: 93.6112853CurrentTrain: epoch  1, batch     7 | loss: 75.9547245CurrentTrain: epoch  1, batch     8 | loss: 80.8373291CurrentTrain: epoch  1, batch     9 | loss: 93.3472458CurrentTrain: epoch  1, batch    10 | loss: 107.4986456CurrentTrain: epoch  1, batch    11 | loss: 113.2953634CurrentTrain: epoch  1, batch    12 | loss: 108.4406167CurrentTrain: epoch  1, batch    13 | loss: 110.4963574CurrentTrain: epoch  1, batch    14 | loss: 91.5597817CurrentTrain: epoch  1, batch    15 | loss: 142.9413528CurrentTrain: epoch  1, batch    16 | loss: 90.0609537CurrentTrain: epoch  1, batch    17 | loss: 102.9715133CurrentTrain: epoch  1, batch    18 | loss: 106.5502714CurrentTrain: epoch  1, batch    19 | loss: 89.4109092CurrentTrain: epoch  1, batch    20 | loss: 187.7264850CurrentTrain: epoch  1, batch    21 | loss: 110.1700712CurrentTrain: epoch  1, batch    22 | loss: 92.9429841CurrentTrain: epoch  1, batch    23 | loss: 103.7653189CurrentTrain: epoch  1, batch    24 | loss: 108.4744270CurrentTrain: epoch  1, batch    25 | loss: 89.4047909CurrentTrain: epoch  1, batch    26 | loss: 82.2454916CurrentTrain: epoch  1, batch    27 | loss: 66.8348464CurrentTrain: epoch  1, batch    28 | loss: 108.2702464CurrentTrain: epoch  1, batch    29 | loss: 74.8754869CurrentTrain: epoch  1, batch    30 | loss: 77.3433907CurrentTrain: epoch  1, batch    31 | loss: 89.9106480CurrentTrain: epoch  1, batch    32 | loss: 67.6085770CurrentTrain: epoch  1, batch    33 | loss: 76.4854437CurrentTrain: epoch  1, batch    34 | loss: 88.8955461CurrentTrain: epoch  1, batch    35 | loss: 93.2559821CurrentTrain: epoch  1, batch    36 | loss: 89.1636775CurrentTrain: epoch  1, batch    37 | loss: 78.6018890CurrentTrain: epoch  1, batch    38 | loss: 67.8970456CurrentTrain: epoch  1, batch    39 | loss: 73.2994371CurrentTrain: epoch  1, batch    40 | loss: 84.9412825CurrentTrain: epoch  1, batch    41 | loss: 109.6932071CurrentTrain: epoch  1, batch    42 | loss: 83.2756015CurrentTrain: epoch  1, batch    43 | loss: 108.5010209CurrentTrain: epoch  1, batch    44 | loss: 75.3883550CurrentTrain: epoch  1, batch    45 | loss: 108.3164640CurrentTrain: epoch  1, batch    46 | loss: 68.0391929CurrentTrain: epoch  1, batch    47 | loss: 75.6114312CurrentTrain: epoch  1, batch    48 | loss: 91.7684472CurrentTrain: epoch  1, batch    49 | loss: 107.2803004CurrentTrain: epoch  1, batch    50 | loss: 71.3606671CurrentTrain: epoch  1, batch    51 | loss: 74.7292344CurrentTrain: epoch  1, batch    52 | loss: 110.3555907CurrentTrain: epoch  1, batch    53 | loss: 106.5467716CurrentTrain: epoch  1, batch    54 | loss: 86.8778319CurrentTrain: epoch  1, batch    55 | loss: 138.0379230CurrentTrain: epoch  1, batch    56 | loss: 90.7027720CurrentTrain: epoch  1, batch    57 | loss: 110.6900310CurrentTrain: epoch  1, batch    58 | loss: 183.6951403CurrentTrain: epoch  1, batch    59 | loss: 90.0884658CurrentTrain: epoch  1, batch    60 | loss: 110.0601142CurrentTrain: epoch  1, batch    61 | loss: 64.7704020CurrentTrain: epoch  1, batch    62 | loss: 77.7362049CurrentTrain: epoch  1, batch    63 | loss: 105.9092590CurrentTrain: epoch  1, batch    64 | loss: 91.3131416CurrentTrain: epoch  1, batch    65 | loss: 103.0146802CurrentTrain: epoch  1, batch    66 | loss: 72.8639752CurrentTrain: epoch  1, batch    67 | loss: 83.9035524CurrentTrain: epoch  1, batch    68 | loss: 133.9061239CurrentTrain: epoch  1, batch    69 | loss: 92.1952920CurrentTrain: epoch  1, batch    70 | loss: 90.4634047CurrentTrain: epoch  1, batch    71 | loss: 98.6597649CurrentTrain: epoch  1, batch    72 | loss: 86.1980486CurrentTrain: epoch  1, batch    73 | loss: 75.3433401CurrentTrain: epoch  1, batch    74 | loss: 106.4896761CurrentTrain: epoch  1, batch    75 | loss: 87.9031349CurrentTrain: epoch  1, batch    76 | loss: 108.8321786CurrentTrain: epoch  1, batch    77 | loss: 102.2471991CurrentTrain: epoch  1, batch    78 | loss: 77.7934646CurrentTrain: epoch  1, batch    79 | loss: 90.1687432CurrentTrain: epoch  1, batch    80 | loss: 84.5106785CurrentTrain: epoch  1, batch    81 | loss: 108.9240967CurrentTrain: epoch  1, batch    82 | loss: 68.7766548CurrentTrain: epoch  1, batch    83 | loss: 106.6141602CurrentTrain: epoch  1, batch    84 | loss: 89.4327633CurrentTrain: epoch  1, batch    85 | loss: 137.4611188CurrentTrain: epoch  1, batch    86 | loss: 73.4128484CurrentTrain: epoch  1, batch    87 | loss: 61.8503200CurrentTrain: epoch  1, batch    88 | loss: 106.3032757CurrentTrain: epoch  1, batch    89 | loss: 137.6625488CurrentTrain: epoch  1, batch    90 | loss: 87.4430696CurrentTrain: epoch  1, batch    91 | loss: 89.3248795CurrentTrain: epoch  1, batch    92 | loss: 76.1917987CurrentTrain: epoch  1, batch    93 | loss: 75.3208128CurrentTrain: epoch  1, batch    94 | loss: 72.8066071CurrentTrain: epoch  1, batch    95 | loss: 74.6633052CurrentTrain: epoch  2, batch     0 | loss: 85.6064551CurrentTrain: epoch  2, batch     1 | loss: 88.9057306CurrentTrain: epoch  2, batch     2 | loss: 80.4744261CurrentTrain: epoch  2, batch     3 | loss: 63.1033162CurrentTrain: epoch  2, batch     4 | loss: 130.4483595CurrentTrain: epoch  2, batch     5 | loss: 72.1619352CurrentTrain: epoch  2, batch     6 | loss: 61.8403367CurrentTrain: epoch  2, batch     7 | loss: 102.5130586CurrentTrain: epoch  2, batch     8 | loss: 87.6357733CurrentTrain: epoch  2, batch     9 | loss: 107.6659611CurrentTrain: epoch  2, batch    10 | loss: 82.8687193CurrentTrain: epoch  2, batch    11 | loss: 107.6357641CurrentTrain: epoch  2, batch    12 | loss: 136.1557813CurrentTrain: epoch  2, batch    13 | loss: 135.9702613CurrentTrain: epoch  2, batch    14 | loss: 87.3018961CurrentTrain: epoch  2, batch    15 | loss: 102.6446839CurrentTrain: epoch  2, batch    16 | loss: 103.3554768CurrentTrain: epoch  2, batch    17 | loss: 74.1889636CurrentTrain: epoch  2, batch    18 | loss: 86.0282541CurrentTrain: epoch  2, batch    19 | loss: 104.3227185CurrentTrain: epoch  2, batch    20 | loss: 179.1843438CurrentTrain: epoch  2, batch    21 | loss: 100.6139113CurrentTrain: epoch  2, batch    22 | loss: 107.1666314CurrentTrain: epoch  2, batch    23 | loss: 137.6222322CurrentTrain: epoch  2, batch    24 | loss: 103.7953910CurrentTrain: epoch  2, batch    25 | loss: 65.1412316CurrentTrain: epoch  2, batch    26 | loss: 88.5473470CurrentTrain: epoch  2, batch    27 | loss: 72.2189493CurrentTrain: epoch  2, batch    28 | loss: 91.9821312CurrentTrain: epoch  2, batch    29 | loss: 81.8659824CurrentTrain: epoch  2, batch    30 | loss: 132.3415939CurrentTrain: epoch  2, batch    31 | loss: 80.3978489CurrentTrain: epoch  2, batch    32 | loss: 87.9495289CurrentTrain: epoch  2, batch    33 | loss: 73.3368328CurrentTrain: epoch  2, batch    34 | loss: 89.5250966CurrentTrain: epoch  2, batch    35 | loss: 74.5142940CurrentTrain: epoch  2, batch    36 | loss: 72.5944885CurrentTrain: epoch  2, batch    37 | loss: 87.5894005CurrentTrain: epoch  2, batch    38 | loss: 86.8281474CurrentTrain: epoch  2, batch    39 | loss: 136.6667772CurrentTrain: epoch  2, batch    40 | loss: 104.5131707CurrentTrain: epoch  2, batch    41 | loss: 106.9705088CurrentTrain: epoch  2, batch    42 | loss: 88.1962908CurrentTrain: epoch  2, batch    43 | loss: 70.8012395CurrentTrain: epoch  2, batch    44 | loss: 103.4079318CurrentTrain: epoch  2, batch    45 | loss: 131.0749274CurrentTrain: epoch  2, batch    46 | loss: 86.3593537CurrentTrain: epoch  2, batch    47 | loss: 82.0319899CurrentTrain: epoch  2, batch    48 | loss: 85.9992950CurrentTrain: epoch  2, batch    49 | loss: 178.1464759CurrentTrain: epoch  2, batch    50 | loss: 102.4764324CurrentTrain: epoch  2, batch    51 | loss: 104.6856191CurrentTrain: epoch  2, batch    52 | loss: 89.2265607CurrentTrain: epoch  2, batch    53 | loss: 88.2655870CurrentTrain: epoch  2, batch    54 | loss: 72.0637605CurrentTrain: epoch  2, batch    55 | loss: 85.3955180CurrentTrain: epoch  2, batch    56 | loss: 67.1171657CurrentTrain: epoch  2, batch    57 | loss: 134.9995006CurrentTrain: epoch  2, batch    58 | loss: 99.7150360CurrentTrain: epoch  2, batch    59 | loss: 76.0900483CurrentTrain: epoch  2, batch    60 | loss: 89.9009322CurrentTrain: epoch  2, batch    61 | loss: 84.0521359CurrentTrain: epoch  2, batch    62 | loss: 74.5948803CurrentTrain: epoch  2, batch    63 | loss: 85.5638968CurrentTrain: epoch  2, batch    64 | loss: 102.6077637CurrentTrain: epoch  2, batch    65 | loss: 86.2695115CurrentTrain: epoch  2, batch    66 | loss: 70.7369723CurrentTrain: epoch  2, batch    67 | loss: 83.4644466CurrentTrain: epoch  2, batch    68 | loss: 93.1707416CurrentTrain: epoch  2, batch    69 | loss: 108.9922210CurrentTrain: epoch  2, batch    70 | loss: 84.5651040CurrentTrain: epoch  2, batch    71 | loss: 136.2230053CurrentTrain: epoch  2, batch    72 | loss: 132.1700038CurrentTrain: epoch  2, batch    73 | loss: 84.6280866CurrentTrain: epoch  2, batch    74 | loss: 90.7061886CurrentTrain: epoch  2, batch    75 | loss: 91.8032020CurrentTrain: epoch  2, batch    76 | loss: 74.3617085CurrentTrain: epoch  2, batch    77 | loss: 88.0308298CurrentTrain: epoch  2, batch    78 | loss: 84.5649495CurrentTrain: epoch  2, batch    79 | loss: 88.7130879CurrentTrain: epoch  2, batch    80 | loss: 81.8583659CurrentTrain: epoch  2, batch    81 | loss: 70.9799822CurrentTrain: epoch  2, batch    82 | loss: 104.2557124CurrentTrain: epoch  2, batch    83 | loss: 74.1203531CurrentTrain: epoch  2, batch    84 | loss: 87.1544194CurrentTrain: epoch  2, batch    85 | loss: 72.5205542CurrentTrain: epoch  2, batch    86 | loss: 83.9902723CurrentTrain: epoch  2, batch    87 | loss: 84.1808322CurrentTrain: epoch  2, batch    88 | loss: 102.2988097CurrentTrain: epoch  2, batch    89 | loss: 57.8576763CurrentTrain: epoch  2, batch    90 | loss: 103.8698260CurrentTrain: epoch  2, batch    91 | loss: 70.7552888CurrentTrain: epoch  2, batch    92 | loss: 83.6515087CurrentTrain: epoch  2, batch    93 | loss: 81.0948433CurrentTrain: epoch  2, batch    94 | loss: 180.0812864CurrentTrain: epoch  2, batch    95 | loss: 60.4186372CurrentTrain: epoch  3, batch     0 | loss: 86.2143892CurrentTrain: epoch  3, batch     1 | loss: 72.1530087CurrentTrain: epoch  3, batch     2 | loss: 135.5888700CurrentTrain: epoch  3, batch     3 | loss: 59.3420650CurrentTrain: epoch  3, batch     4 | loss: 63.8453039CurrentTrain: epoch  3, batch     5 | loss: 105.9889817CurrentTrain: epoch  3, batch     6 | loss: 70.2954143CurrentTrain: epoch  3, batch     7 | loss: 102.5183058CurrentTrain: epoch  3, batch     8 | loss: 103.9965604CurrentTrain: epoch  3, batch     9 | loss: 103.1832396CurrentTrain: epoch  3, batch    10 | loss: 85.0610809CurrentTrain: epoch  3, batch    11 | loss: 85.6140011CurrentTrain: epoch  3, batch    12 | loss: 63.0994240CurrentTrain: epoch  3, batch    13 | loss: 133.5824973CurrentTrain: epoch  3, batch    14 | loss: 133.6877214CurrentTrain: epoch  3, batch    15 | loss: 71.2522777CurrentTrain: epoch  3, batch    16 | loss: 100.0414891CurrentTrain: epoch  3, batch    17 | loss: 106.2754160CurrentTrain: epoch  3, batch    18 | loss: 85.0325789CurrentTrain: epoch  3, batch    19 | loss: 100.3384852CurrentTrain: epoch  3, batch    20 | loss: 69.5516438CurrentTrain: epoch  3, batch    21 | loss: 99.2016656CurrentTrain: epoch  3, batch    22 | loss: 102.7044106CurrentTrain: epoch  3, batch    23 | loss: 103.7721826CurrentTrain: epoch  3, batch    24 | loss: 102.6938916CurrentTrain: epoch  3, batch    25 | loss: 90.3810193CurrentTrain: epoch  3, batch    26 | loss: 83.8842810CurrentTrain: epoch  3, batch    27 | loss: 88.6369750CurrentTrain: epoch  3, batch    28 | loss: 67.0207829CurrentTrain: epoch  3, batch    29 | loss: 103.8462483CurrentTrain: epoch  3, batch    30 | loss: 130.3714842CurrentTrain: epoch  3, batch    31 | loss: 62.1041057CurrentTrain: epoch  3, batch    32 | loss: 103.7189331CurrentTrain: epoch  3, batch    33 | loss: 81.8340451CurrentTrain: epoch  3, batch    34 | loss: 100.8048508CurrentTrain: epoch  3, batch    35 | loss: 76.0969252CurrentTrain: epoch  3, batch    36 | loss: 70.9747807CurrentTrain: epoch  3, batch    37 | loss: 71.7116818CurrentTrain: epoch  3, batch    38 | loss: 100.6367419CurrentTrain: epoch  3, batch    39 | loss: 58.6647078CurrentTrain: epoch  3, batch    40 | loss: 70.7779005CurrentTrain: epoch  3, batch    41 | loss: 84.7773107CurrentTrain: epoch  3, batch    42 | loss: 70.0825198CurrentTrain: epoch  3, batch    43 | loss: 106.9617342CurrentTrain: epoch  3, batch    44 | loss: 100.7326708CurrentTrain: epoch  3, batch    45 | loss: 105.9118365CurrentTrain: epoch  3, batch    46 | loss: 61.2167380CurrentTrain: epoch  3, batch    47 | loss: 63.7930122CurrentTrain: epoch  3, batch    48 | loss: 76.0032855CurrentTrain: epoch  3, batch    49 | loss: 69.0455539CurrentTrain: epoch  3, batch    50 | loss: 62.4040086CurrentTrain: epoch  3, batch    51 | loss: 72.6846526CurrentTrain: epoch  3, batch    52 | loss: 66.6585247CurrentTrain: epoch  3, batch    53 | loss: 82.4189406CurrentTrain: epoch  3, batch    54 | loss: 85.7594801CurrentTrain: epoch  3, batch    55 | loss: 60.9886238CurrentTrain: epoch  3, batch    56 | loss: 82.6129423CurrentTrain: epoch  3, batch    57 | loss: 97.8323468CurrentTrain: epoch  3, batch    58 | loss: 103.9060521CurrentTrain: epoch  3, batch    59 | loss: 88.3049752CurrentTrain: epoch  3, batch    60 | loss: 80.9882820CurrentTrain: epoch  3, batch    61 | loss: 68.0954322CurrentTrain: epoch  3, batch    62 | loss: 73.5961023CurrentTrain: epoch  3, batch    63 | loss: 138.7921113CurrentTrain: epoch  3, batch    64 | loss: 70.1938282CurrentTrain: epoch  3, batch    65 | loss: 127.8182683CurrentTrain: epoch  3, batch    66 | loss: 127.1717312CurrentTrain: epoch  3, batch    67 | loss: 85.3421917CurrentTrain: epoch  3, batch    68 | loss: 72.8889864CurrentTrain: epoch  3, batch    69 | loss: 86.1293925CurrentTrain: epoch  3, batch    70 | loss: 101.9107673CurrentTrain: epoch  3, batch    71 | loss: 101.2256448CurrentTrain: epoch  3, batch    72 | loss: 81.2580240CurrentTrain: epoch  3, batch    73 | loss: 71.0257091CurrentTrain: epoch  3, batch    74 | loss: 86.4858933CurrentTrain: epoch  3, batch    75 | loss: 103.4222723CurrentTrain: epoch  3, batch    76 | loss: 69.9015918CurrentTrain: epoch  3, batch    77 | loss: 68.2240171CurrentTrain: epoch  3, batch    78 | loss: 104.7125686CurrentTrain: epoch  3, batch    79 | loss: 86.0327808CurrentTrain: epoch  3, batch    80 | loss: 104.1392615CurrentTrain: epoch  3, batch    81 | loss: 72.8347273CurrentTrain: epoch  3, batch    82 | loss: 73.8940077CurrentTrain: epoch  3, batch    83 | loss: 74.9250734CurrentTrain: epoch  3, batch    84 | loss: 70.6368429CurrentTrain: epoch  3, batch    85 | loss: 104.5971026CurrentTrain: epoch  3, batch    86 | loss: 64.0629620CurrentTrain: epoch  3, batch    87 | loss: 88.0133036CurrentTrain: epoch  3, batch    88 | loss: 127.0942776CurrentTrain: epoch  3, batch    89 | loss: 87.2213349CurrentTrain: epoch  3, batch    90 | loss: 70.9083805CurrentTrain: epoch  3, batch    91 | loss: 71.0231950CurrentTrain: epoch  3, batch    92 | loss: 71.5069981CurrentTrain: epoch  3, batch    93 | loss: 69.6827127CurrentTrain: epoch  3, batch    94 | loss: 106.3563597CurrentTrain: epoch  3, batch    95 | loss: 67.9737990CurrentTrain: epoch  4, batch     0 | loss: 68.9332581CurrentTrain: epoch  4, batch     1 | loss: 101.1843479CurrentTrain: epoch  4, batch     2 | loss: 68.4922565CurrentTrain: epoch  4, batch     3 | loss: 85.6676139CurrentTrain: epoch  4, batch     4 | loss: 61.3575186CurrentTrain: epoch  4, batch     5 | loss: 69.7208468CurrentTrain: epoch  4, batch     6 | loss: 85.8995799CurrentTrain: epoch  4, batch     7 | loss: 80.9636453CurrentTrain: epoch  4, batch     8 | loss: 69.8731680CurrentTrain: epoch  4, batch     9 | loss: 76.0524122CurrentTrain: epoch  4, batch    10 | loss: 74.3471868CurrentTrain: epoch  4, batch    11 | loss: 78.8929010CurrentTrain: epoch  4, batch    12 | loss: 74.7149163CurrentTrain: epoch  4, batch    13 | loss: 128.2672298CurrentTrain: epoch  4, batch    14 | loss: 103.2154676CurrentTrain: epoch  4, batch    15 | loss: 85.6016361CurrentTrain: epoch  4, batch    16 | loss: 81.8224147CurrentTrain: epoch  4, batch    17 | loss: 85.0798813CurrentTrain: epoch  4, batch    18 | loss: 100.1936607CurrentTrain: epoch  4, batch    19 | loss: 126.8591471CurrentTrain: epoch  4, batch    20 | loss: 79.7392493CurrentTrain: epoch  4, batch    21 | loss: 126.8301836CurrentTrain: epoch  4, batch    22 | loss: 70.7165237CurrentTrain: epoch  4, batch    23 | loss: 86.0857222CurrentTrain: epoch  4, batch    24 | loss: 82.5255891CurrentTrain: epoch  4, batch    25 | loss: 68.7262147CurrentTrain: epoch  4, batch    26 | loss: 76.8119620CurrentTrain: epoch  4, batch    27 | loss: 84.6546614CurrentTrain: epoch  4, batch    28 | loss: 103.6156419CurrentTrain: epoch  4, batch    29 | loss: 68.4381114CurrentTrain: epoch  4, batch    30 | loss: 95.9095186CurrentTrain: epoch  4, batch    31 | loss: 71.6259544CurrentTrain: epoch  4, batch    32 | loss: 101.2613779CurrentTrain: epoch  4, batch    33 | loss: 62.0492703CurrentTrain: epoch  4, batch    34 | loss: 96.6760560CurrentTrain: epoch  4, batch    35 | loss: 88.9463329CurrentTrain: epoch  4, batch    36 | loss: 129.6432856CurrentTrain: epoch  4, batch    37 | loss: 104.0502438CurrentTrain: epoch  4, batch    38 | loss: 103.4922886CurrentTrain: epoch  4, batch    39 | loss: 100.4866692CurrentTrain: epoch  4, batch    40 | loss: 84.7356255CurrentTrain: epoch  4, batch    41 | loss: 82.1345446CurrentTrain: epoch  4, batch    42 | loss: 96.7387676CurrentTrain: epoch  4, batch    43 | loss: 103.0650463CurrentTrain: epoch  4, batch    44 | loss: 133.1900503CurrentTrain: epoch  4, batch    45 | loss: 82.5923726CurrentTrain: epoch  4, batch    46 | loss: 83.2175224CurrentTrain: epoch  4, batch    47 | loss: 105.0973148CurrentTrain: epoch  4, batch    48 | loss: 129.2194130CurrentTrain: epoch  4, batch    49 | loss: 81.9334316CurrentTrain: epoch  4, batch    50 | loss: 92.4832556CurrentTrain: epoch  4, batch    51 | loss: 127.3180426CurrentTrain: epoch  4, batch    52 | loss: 83.0916447CurrentTrain: epoch  4, batch    53 | loss: 69.7500246CurrentTrain: epoch  4, batch    54 | loss: 62.1106298CurrentTrain: epoch  4, batch    55 | loss: 102.2040190CurrentTrain: epoch  4, batch    56 | loss: 79.6338769CurrentTrain: epoch  4, batch    57 | loss: 74.6783709CurrentTrain: epoch  4, batch    58 | loss: 67.1744478CurrentTrain: epoch  4, batch    59 | loss: 101.4580943CurrentTrain: epoch  4, batch    60 | loss: 71.3905120CurrentTrain: epoch  4, batch    61 | loss: 83.7969959CurrentTrain: epoch  4, batch    62 | loss: 81.9659493CurrentTrain: epoch  4, batch    63 | loss: 81.6062960CurrentTrain: epoch  4, batch    64 | loss: 71.0625486CurrentTrain: epoch  4, batch    65 | loss: 68.7212532CurrentTrain: epoch  4, batch    66 | loss: 102.0595308CurrentTrain: epoch  4, batch    67 | loss: 80.9077787CurrentTrain: epoch  4, batch    68 | loss: 61.1046259CurrentTrain: epoch  4, batch    69 | loss: 127.5378105CurrentTrain: epoch  4, batch    70 | loss: 81.1631030CurrentTrain: epoch  4, batch    71 | loss: 127.7667516CurrentTrain: epoch  4, batch    72 | loss: 58.9062090CurrentTrain: epoch  4, batch    73 | loss: 125.5857809CurrentTrain: epoch  4, batch    74 | loss: 61.6232505CurrentTrain: epoch  4, batch    75 | loss: 73.2076209CurrentTrain: epoch  4, batch    76 | loss: 68.9041693CurrentTrain: epoch  4, batch    77 | loss: 105.7266502CurrentTrain: epoch  4, batch    78 | loss: 104.8570421CurrentTrain: epoch  4, batch    79 | loss: 83.2246743CurrentTrain: epoch  4, batch    80 | loss: 74.3914286CurrentTrain: epoch  4, batch    81 | loss: 104.1094490CurrentTrain: epoch  4, batch    82 | loss: 77.6897045CurrentTrain: epoch  4, batch    83 | loss: 101.0293298CurrentTrain: epoch  4, batch    84 | loss: 71.7603939CurrentTrain: epoch  4, batch    85 | loss: 99.5569609CurrentTrain: epoch  4, batch    86 | loss: 105.1171762CurrentTrain: epoch  4, batch    87 | loss: 99.2804760CurrentTrain: epoch  4, batch    88 | loss: 101.3488893CurrentTrain: epoch  4, batch    89 | loss: 100.4288354CurrentTrain: epoch  4, batch    90 | loss: 97.9127800CurrentTrain: epoch  4, batch    91 | loss: 85.7177909CurrentTrain: epoch  4, batch    92 | loss: 101.5454511CurrentTrain: epoch  4, batch    93 | loss: 67.6340998CurrentTrain: epoch  4, batch    94 | loss: 70.9509900CurrentTrain: epoch  4, batch    95 | loss: 66.4492787CurrentTrain: epoch  5, batch     0 | loss: 100.0169736CurrentTrain: epoch  5, batch     1 | loss: 69.2915955CurrentTrain: epoch  5, batch     2 | loss: 97.1082009CurrentTrain: epoch  5, batch     3 | loss: 120.5350220CurrentTrain: epoch  5, batch     4 | loss: 70.2778576CurrentTrain: epoch  5, batch     5 | loss: 94.4158301CurrentTrain: epoch  5, batch     6 | loss: 101.7324816CurrentTrain: epoch  5, batch     7 | loss: 84.0966856CurrentTrain: epoch  5, batch     8 | loss: 65.9521082CurrentTrain: epoch  5, batch     9 | loss: 58.8978339CurrentTrain: epoch  5, batch    10 | loss: 101.0459471CurrentTrain: epoch  5, batch    11 | loss: 99.3390724CurrentTrain: epoch  5, batch    12 | loss: 66.5089964CurrentTrain: epoch  5, batch    13 | loss: 94.8129622CurrentTrain: epoch  5, batch    14 | loss: 105.0886377CurrentTrain: epoch  5, batch    15 | loss: 68.7233204CurrentTrain: epoch  5, batch    16 | loss: 127.3262942CurrentTrain: epoch  5, batch    17 | loss: 79.8398705CurrentTrain: epoch  5, batch    18 | loss: 96.6940286CurrentTrain: epoch  5, batch    19 | loss: 104.8881687CurrentTrain: epoch  5, batch    20 | loss: 85.6949525CurrentTrain: epoch  5, batch    21 | loss: 78.2721995CurrentTrain: epoch  5, batch    22 | loss: 82.5129993CurrentTrain: epoch  5, batch    23 | loss: 79.7751832CurrentTrain: epoch  5, batch    24 | loss: 68.0665498CurrentTrain: epoch  5, batch    25 | loss: 99.6560655CurrentTrain: epoch  5, batch    26 | loss: 78.7723923CurrentTrain: epoch  5, batch    27 | loss: 67.1537607CurrentTrain: epoch  5, batch    28 | loss: 128.5811201CurrentTrain: epoch  5, batch    29 | loss: 70.5825330CurrentTrain: epoch  5, batch    30 | loss: 92.4868286CurrentTrain: epoch  5, batch    31 | loss: 80.2063870CurrentTrain: epoch  5, batch    32 | loss: 71.7297199CurrentTrain: epoch  5, batch    33 | loss: 91.8943310CurrentTrain: epoch  5, batch    34 | loss: 99.0620253CurrentTrain: epoch  5, batch    35 | loss: 57.2591452CurrentTrain: epoch  5, batch    36 | loss: 67.9142557CurrentTrain: epoch  5, batch    37 | loss: 126.9054566CurrentTrain: epoch  5, batch    38 | loss: 79.5116401CurrentTrain: epoch  5, batch    39 | loss: 65.0786482CurrentTrain: epoch  5, batch    40 | loss: 132.1740963CurrentTrain: epoch  5, batch    41 | loss: 80.7521856CurrentTrain: epoch  5, batch    42 | loss: 82.8895727CurrentTrain: epoch  5, batch    43 | loss: 65.2064972CurrentTrain: epoch  5, batch    44 | loss: 101.8790298CurrentTrain: epoch  5, batch    45 | loss: 79.5771527CurrentTrain: epoch  5, batch    46 | loss: 69.7270983CurrentTrain: epoch  5, batch    47 | loss: 70.1280274CurrentTrain: epoch  5, batch    48 | loss: 103.7968930CurrentTrain: epoch  5, batch    49 | loss: 54.4950756CurrentTrain: epoch  5, batch    50 | loss: 95.4896600CurrentTrain: epoch  5, batch    51 | loss: 73.0208414CurrentTrain: epoch  5, batch    52 | loss: 85.3262779CurrentTrain: epoch  5, batch    53 | loss: 84.2548726CurrentTrain: epoch  5, batch    54 | loss: 83.0161371CurrentTrain: epoch  5, batch    55 | loss: 124.0918742CurrentTrain: epoch  5, batch    56 | loss: 178.5398353CurrentTrain: epoch  5, batch    57 | loss: 68.7353845CurrentTrain: epoch  5, batch    58 | loss: 82.4863989CurrentTrain: epoch  5, batch    59 | loss: 84.6439482CurrentTrain: epoch  5, batch    60 | loss: 64.0809167CurrentTrain: epoch  5, batch    61 | loss: 97.7976339CurrentTrain: epoch  5, batch    62 | loss: 97.5253569CurrentTrain: epoch  5, batch    63 | loss: 68.6429985CurrentTrain: epoch  5, batch    64 | loss: 80.1595171CurrentTrain: epoch  5, batch    65 | loss: 171.3119560CurrentTrain: epoch  5, batch    66 | loss: 80.9074459CurrentTrain: epoch  5, batch    67 | loss: 102.3528028CurrentTrain: epoch  5, batch    68 | loss: 67.8398479CurrentTrain: epoch  5, batch    69 | loss: 81.3692327CurrentTrain: epoch  5, batch    70 | loss: 73.9227341CurrentTrain: epoch  5, batch    71 | loss: 171.3429288CurrentTrain: epoch  5, batch    72 | loss: 58.6197838CurrentTrain: epoch  5, batch    73 | loss: 98.9809513CurrentTrain: epoch  5, batch    74 | loss: 70.1271364CurrentTrain: epoch  5, batch    75 | loss: 72.7642039CurrentTrain: epoch  5, batch    76 | loss: 69.6802829CurrentTrain: epoch  5, batch    77 | loss: 66.9076921CurrentTrain: epoch  5, batch    78 | loss: 71.4103323CurrentTrain: epoch  5, batch    79 | loss: 59.8034842CurrentTrain: epoch  5, batch    80 | loss: 94.2618678CurrentTrain: epoch  5, batch    81 | loss: 72.1536494CurrentTrain: epoch  5, batch    82 | loss: 77.5125053CurrentTrain: epoch  5, batch    83 | loss: 70.7292434CurrentTrain: epoch  5, batch    84 | loss: 97.6540171CurrentTrain: epoch  5, batch    85 | loss: 103.1404907CurrentTrain: epoch  5, batch    86 | loss: 83.8233958CurrentTrain: epoch  5, batch    87 | loss: 86.0338432CurrentTrain: epoch  5, batch    88 | loss: 83.4272116CurrentTrain: epoch  5, batch    89 | loss: 79.5251458CurrentTrain: epoch  5, batch    90 | loss: 84.4635826CurrentTrain: epoch  5, batch    91 | loss: 102.4258097CurrentTrain: epoch  5, batch    92 | loss: 85.3297310CurrentTrain: epoch  5, batch    93 | loss: 71.6525717CurrentTrain: epoch  5, batch    94 | loss: 97.9951802CurrentTrain: epoch  5, batch    95 | loss: 69.7957073CurrentTrain: epoch  6, batch     0 | loss: 100.5834923CurrentTrain: epoch  6, batch     1 | loss: 75.5085189CurrentTrain: epoch  6, batch     2 | loss: 82.7177292CurrentTrain: epoch  6, batch     3 | loss: 77.6529890CurrentTrain: epoch  6, batch     4 | loss: 79.1078312CurrentTrain: epoch  6, batch     5 | loss: 98.0521600CurrentTrain: epoch  6, batch     6 | loss: 84.3705341CurrentTrain: epoch  6, batch     7 | loss: 81.4758831CurrentTrain: epoch  6, batch     8 | loss: 99.6313156CurrentTrain: epoch  6, batch     9 | loss: 121.1122752CurrentTrain: epoch  6, batch    10 | loss: 81.1846748CurrentTrain: epoch  6, batch    11 | loss: 102.1618417CurrentTrain: epoch  6, batch    12 | loss: 81.8360045CurrentTrain: epoch  6, batch    13 | loss: 81.8840704CurrentTrain: epoch  6, batch    14 | loss: 64.1455569CurrentTrain: epoch  6, batch    15 | loss: 122.7564891CurrentTrain: epoch  6, batch    16 | loss: 94.9994170CurrentTrain: epoch  6, batch    17 | loss: 117.5358416CurrentTrain: epoch  6, batch    18 | loss: 129.7029019CurrentTrain: epoch  6, batch    19 | loss: 68.7787974CurrentTrain: epoch  6, batch    20 | loss: 173.8693961CurrentTrain: epoch  6, batch    21 | loss: 83.8957356CurrentTrain: epoch  6, batch    22 | loss: 78.4739270CurrentTrain: epoch  6, batch    23 | loss: 100.3988022CurrentTrain: epoch  6, batch    24 | loss: 64.8915781CurrentTrain: epoch  6, batch    25 | loss: 102.0119964CurrentTrain: epoch  6, batch    26 | loss: 66.4110201CurrentTrain: epoch  6, batch    27 | loss: 62.7527726CurrentTrain: epoch  6, batch    28 | loss: 78.4973962CurrentTrain: epoch  6, batch    29 | loss: 126.1286741CurrentTrain: epoch  6, batch    30 | loss: 70.9037841CurrentTrain: epoch  6, batch    31 | loss: 67.9883705CurrentTrain: epoch  6, batch    32 | loss: 70.3272151CurrentTrain: epoch  6, batch    33 | loss: 128.4358970CurrentTrain: epoch  6, batch    34 | loss: 82.4988444CurrentTrain: epoch  6, batch    35 | loss: 64.5610278CurrentTrain: epoch  6, batch    36 | loss: 101.2256462CurrentTrain: epoch  6, batch    37 | loss: 123.0051404CurrentTrain: epoch  6, batch    38 | loss: 101.6159464CurrentTrain: epoch  6, batch    39 | loss: 68.2595231CurrentTrain: epoch  6, batch    40 | loss: 98.4296189CurrentTrain: epoch  6, batch    41 | loss: 100.4534495CurrentTrain: epoch  6, batch    42 | loss: 59.2331587CurrentTrain: epoch  6, batch    43 | loss: 77.6637213CurrentTrain: epoch  6, batch    44 | loss: 77.8846805CurrentTrain: epoch  6, batch    45 | loss: 56.5111229CurrentTrain: epoch  6, batch    46 | loss: 69.6973305CurrentTrain: epoch  6, batch    47 | loss: 76.0167986CurrentTrain: epoch  6, batch    48 | loss: 67.8032384CurrentTrain: epoch  6, batch    49 | loss: 124.8305434CurrentTrain: epoch  6, batch    50 | loss: 120.0494580CurrentTrain: epoch  6, batch    51 | loss: 60.6214282CurrentTrain: epoch  6, batch    52 | loss: 65.4090936CurrentTrain: epoch  6, batch    53 | loss: 66.9591898CurrentTrain: epoch  6, batch    54 | loss: 83.1371921CurrentTrain: epoch  6, batch    55 | loss: 121.9978537CurrentTrain: epoch  6, batch    56 | loss: 123.7620425CurrentTrain: epoch  6, batch    57 | loss: 81.9403734CurrentTrain: epoch  6, batch    58 | loss: 97.0714650CurrentTrain: epoch  6, batch    59 | loss: 99.7946535CurrentTrain: epoch  6, batch    60 | loss: 101.9287428CurrentTrain: epoch  6, batch    61 | loss: 68.1344229CurrentTrain: epoch  6, batch    62 | loss: 75.5100076CurrentTrain: epoch  6, batch    63 | loss: 80.1606575CurrentTrain: epoch  6, batch    64 | loss: 77.0884916CurrentTrain: epoch  6, batch    65 | loss: 101.7752746CurrentTrain: epoch  6, batch    66 | loss: 79.0446720CurrentTrain: epoch  6, batch    67 | loss: 93.3193465CurrentTrain: epoch  6, batch    68 | loss: 83.2457858CurrentTrain: epoch  6, batch    69 | loss: 95.3638588CurrentTrain: epoch  6, batch    70 | loss: 99.1390589CurrentTrain: epoch  6, batch    71 | loss: 94.6749222CurrentTrain: epoch  6, batch    72 | loss: 55.7308716CurrentTrain: epoch  6, batch    73 | loss: 84.3192769CurrentTrain: epoch  6, batch    74 | loss: 101.8232718CurrentTrain: epoch  6, batch    75 | loss: 71.3245312CurrentTrain: epoch  6, batch    76 | loss: 81.1858805CurrentTrain: epoch  6, batch    77 | loss: 103.2484208CurrentTrain: epoch  6, batch    78 | loss: 99.6184949CurrentTrain: epoch  6, batch    79 | loss: 96.9495200CurrentTrain: epoch  6, batch    80 | loss: 98.0062475CurrentTrain: epoch  6, batch    81 | loss: 71.8327182CurrentTrain: epoch  6, batch    82 | loss: 79.6863568CurrentTrain: epoch  6, batch    83 | loss: 66.1606076CurrentTrain: epoch  6, batch    84 | loss: 97.1439363CurrentTrain: epoch  6, batch    85 | loss: 75.4839017CurrentTrain: epoch  6, batch    86 | loss: 97.6594861CurrentTrain: epoch  6, batch    87 | loss: 98.8742100CurrentTrain: epoch  6, batch    88 | loss: 120.0962544CurrentTrain: epoch  6, batch    89 | loss: 72.3155278CurrentTrain: epoch  6, batch    90 | loss: 63.5402031CurrentTrain: epoch  6, batch    91 | loss: 122.1626365CurrentTrain: epoch  6, batch    92 | loss: 66.6824096CurrentTrain: epoch  6, batch    93 | loss: 64.8905535CurrentTrain: epoch  6, batch    94 | loss: 64.7521455CurrentTrain: epoch  6, batch    95 | loss: 108.9295021CurrentTrain: epoch  7, batch     0 | loss: 62.4944585CurrentTrain: epoch  7, batch     1 | loss: 68.1101516CurrentTrain: epoch  7, batch     2 | loss: 124.3277746CurrentTrain: epoch  7, batch     3 | loss: 96.8695715CurrentTrain: epoch  7, batch     4 | loss: 121.5019434CurrentTrain: epoch  7, batch     5 | loss: 80.8884680CurrentTrain: epoch  7, batch     6 | loss: 77.2469626CurrentTrain: epoch  7, batch     7 | loss: 94.7609611CurrentTrain: epoch  7, batch     8 | loss: 53.7139173CurrentTrain: epoch  7, batch     9 | loss: 64.5933618CurrentTrain: epoch  7, batch    10 | loss: 119.8303191CurrentTrain: epoch  7, batch    11 | loss: 125.7981193CurrentTrain: epoch  7, batch    12 | loss: 77.1259603CurrentTrain: epoch  7, batch    13 | loss: 81.0686611CurrentTrain: epoch  7, batch    14 | loss: 54.5888366CurrentTrain: epoch  7, batch    15 | loss: 98.8305753CurrentTrain: epoch  7, batch    16 | loss: 65.4431599CurrentTrain: epoch  7, batch    17 | loss: 103.6925103CurrentTrain: epoch  7, batch    18 | loss: 65.8697199CurrentTrain: epoch  7, batch    19 | loss: 94.9740044CurrentTrain: epoch  7, batch    20 | loss: 97.7044522CurrentTrain: epoch  7, batch    21 | loss: 82.4242073CurrentTrain: epoch  7, batch    22 | loss: 95.1527475CurrentTrain: epoch  7, batch    23 | loss: 82.2128776CurrentTrain: epoch  7, batch    24 | loss: 122.0918761CurrentTrain: epoch  7, batch    25 | loss: 75.2752048CurrentTrain: epoch  7, batch    26 | loss: 82.5427478CurrentTrain: epoch  7, batch    27 | loss: 56.9933426CurrentTrain: epoch  7, batch    28 | loss: 56.4933806CurrentTrain: epoch  7, batch    29 | loss: 63.6712000CurrentTrain: epoch  7, batch    30 | loss: 97.4812206CurrentTrain: epoch  7, batch    31 | loss: 68.4072237CurrentTrain: epoch  7, batch    32 | loss: 94.7609755CurrentTrain: epoch  7, batch    33 | loss: 96.7051342CurrentTrain: epoch  7, batch    34 | loss: 98.7419203CurrentTrain: epoch  7, batch    35 | loss: 81.1264889CurrentTrain: epoch  7, batch    36 | loss: 76.8215156CurrentTrain: epoch  7, batch    37 | loss: 62.8082797CurrentTrain: epoch  7, batch    38 | loss: 77.5339162CurrentTrain: epoch  7, batch    39 | loss: 76.4916515CurrentTrain: epoch  7, batch    40 | loss: 129.9335071CurrentTrain: epoch  7, batch    41 | loss: 79.2635186CurrentTrain: epoch  7, batch    42 | loss: 78.9853084CurrentTrain: epoch  7, batch    43 | loss: 126.6209142CurrentTrain: epoch  7, batch    44 | loss: 56.7359206CurrentTrain: epoch  7, batch    45 | loss: 103.1347638CurrentTrain: epoch  7, batch    46 | loss: 63.9499513CurrentTrain: epoch  7, batch    47 | loss: 79.8363312CurrentTrain: epoch  7, batch    48 | loss: 81.6584761CurrentTrain: epoch  7, batch    49 | loss: 125.4486293CurrentTrain: epoch  7, batch    50 | loss: 100.2107157CurrentTrain: epoch  7, batch    51 | loss: 102.3567724CurrentTrain: epoch  7, batch    52 | loss: 75.9712948CurrentTrain: epoch  7, batch    53 | loss: 122.6889222CurrentTrain: epoch  7, batch    54 | loss: 80.7400586CurrentTrain: epoch  7, batch    55 | loss: 81.2847098CurrentTrain: epoch  7, batch    56 | loss: 65.0529072CurrentTrain: epoch  7, batch    57 | loss: 125.0384701CurrentTrain: epoch  7, batch    58 | loss: 68.7352864CurrentTrain: epoch  7, batch    59 | loss: 80.8979325CurrentTrain: epoch  7, batch    60 | loss: 93.6276762CurrentTrain: epoch  7, batch    61 | loss: 78.5570939CurrentTrain: epoch  7, batch    62 | loss: 97.2638837CurrentTrain: epoch  7, batch    63 | loss: 80.5294189CurrentTrain: epoch  7, batch    64 | loss: 56.8273560CurrentTrain: epoch  7, batch    65 | loss: 77.7716383CurrentTrain: epoch  7, batch    66 | loss: 68.2855845CurrentTrain: epoch  7, batch    67 | loss: 82.5378312CurrentTrain: epoch  7, batch    68 | loss: 78.9174423CurrentTrain: epoch  7, batch    69 | loss: 99.6071499CurrentTrain: epoch  7, batch    70 | loss: 80.3303340CurrentTrain: epoch  7, batch    71 | loss: 55.0093663CurrentTrain: epoch  7, batch    72 | loss: 77.6989392CurrentTrain: epoch  7, batch    73 | loss: 78.5739142CurrentTrain: epoch  7, batch    74 | loss: 123.8065860CurrentTrain: epoch  7, batch    75 | loss: 95.0803448CurrentTrain: epoch  7, batch    76 | loss: 80.2054125CurrentTrain: epoch  7, batch    77 | loss: 58.7653603CurrentTrain: epoch  7, batch    78 | loss: 260.6005144CurrentTrain: epoch  7, batch    79 | loss: 81.2092292CurrentTrain: epoch  7, batch    80 | loss: 78.2167291CurrentTrain: epoch  7, batch    81 | loss: 62.2487986CurrentTrain: epoch  7, batch    82 | loss: 102.3795599CurrentTrain: epoch  7, batch    83 | loss: 77.2339873CurrentTrain: epoch  7, batch    84 | loss: 80.9479920CurrentTrain: epoch  7, batch    85 | loss: 78.2152821CurrentTrain: epoch  7, batch    86 | loss: 126.9945924CurrentTrain: epoch  7, batch    87 | loss: 98.9808880CurrentTrain: epoch  7, batch    88 | loss: 123.4769648CurrentTrain: epoch  7, batch    89 | loss: 78.6914240CurrentTrain: epoch  7, batch    90 | loss: 79.8530634CurrentTrain: epoch  7, batch    91 | loss: 126.3566667CurrentTrain: epoch  7, batch    92 | loss: 125.7045447CurrentTrain: epoch  7, batch    93 | loss: 64.5608116CurrentTrain: epoch  7, batch    94 | loss: 51.9783234CurrentTrain: epoch  7, batch    95 | loss: 101.4198265CurrentTrain: epoch  8, batch     0 | loss: 99.9826772CurrentTrain: epoch  8, batch     1 | loss: 98.0053060CurrentTrain: epoch  8, batch     2 | loss: 79.3276265CurrentTrain: epoch  8, batch     3 | loss: 64.4714872CurrentTrain: epoch  8, batch     4 | loss: 67.5413552CurrentTrain: epoch  8, batch     5 | loss: 93.0502577CurrentTrain: epoch  8, batch     6 | loss: 77.9567777CurrentTrain: epoch  8, batch     7 | loss: 126.9600276CurrentTrain: epoch  8, batch     8 | loss: 66.4228629CurrentTrain: epoch  8, batch     9 | loss: 62.8322971CurrentTrain: epoch  8, batch    10 | loss: 59.3765623CurrentTrain: epoch  8, batch    11 | loss: 64.0405996CurrentTrain: epoch  8, batch    12 | loss: 64.3753921CurrentTrain: epoch  8, batch    13 | loss: 170.8753885CurrentTrain: epoch  8, batch    14 | loss: 78.9882501CurrentTrain: epoch  8, batch    15 | loss: 78.8653879CurrentTrain: epoch  8, batch    16 | loss: 125.8155971CurrentTrain: epoch  8, batch    17 | loss: 96.9775343CurrentTrain: epoch  8, batch    18 | loss: 97.6951354CurrentTrain: epoch  8, batch    19 | loss: 65.8174324CurrentTrain: epoch  8, batch    20 | loss: 54.0243706CurrentTrain: epoch  8, batch    21 | loss: 63.6430835CurrentTrain: epoch  8, batch    22 | loss: 125.0343953CurrentTrain: epoch  8, batch    23 | loss: 75.9066108CurrentTrain: epoch  8, batch    24 | loss: 97.9244062CurrentTrain: epoch  8, batch    25 | loss: 65.4020747CurrentTrain: epoch  8, batch    26 | loss: 95.2583234CurrentTrain: epoch  8, batch    27 | loss: 121.2603313CurrentTrain: epoch  8, batch    28 | loss: 81.0143112CurrentTrain: epoch  8, batch    29 | loss: 91.7391208CurrentTrain: epoch  8, batch    30 | loss: 68.6032465CurrentTrain: epoch  8, batch    31 | loss: 124.8600234CurrentTrain: epoch  8, batch    32 | loss: 125.0096220CurrentTrain: epoch  8, batch    33 | loss: 92.5609110CurrentTrain: epoch  8, batch    34 | loss: 126.8169324CurrentTrain: epoch  8, batch    35 | loss: 120.5476147CurrentTrain: epoch  8, batch    36 | loss: 77.3011336CurrentTrain: epoch  8, batch    37 | loss: 94.9326654CurrentTrain: epoch  8, batch    38 | loss: 124.5265747CurrentTrain: epoch  8, batch    39 | loss: 79.6504215CurrentTrain: epoch  8, batch    40 | loss: 78.0742579CurrentTrain: epoch  8, batch    41 | loss: 62.5780526CurrentTrain: epoch  8, batch    42 | loss: 168.2802829CurrentTrain: epoch  8, batch    43 | loss: 94.7483686CurrentTrain: epoch  8, batch    44 | loss: 95.6300326CurrentTrain: epoch  8, batch    45 | loss: 78.7965417CurrentTrain: epoch  8, batch    46 | loss: 80.1735391CurrentTrain: epoch  8, batch    47 | loss: 123.6746676CurrentTrain: epoch  8, batch    48 | loss: 77.3989382CurrentTrain: epoch  8, batch    49 | loss: 67.3138807CurrentTrain: epoch  8, batch    50 | loss: 67.8375420CurrentTrain: epoch  8, batch    51 | loss: 67.4648151CurrentTrain: epoch  8, batch    52 | loss: 63.9666915CurrentTrain: epoch  8, batch    53 | loss: 103.0668886CurrentTrain: epoch  8, batch    54 | loss: 96.9496439CurrentTrain: epoch  8, batch    55 | loss: 78.5424631CurrentTrain: epoch  8, batch    56 | loss: 80.9893559CurrentTrain: epoch  8, batch    57 | loss: 90.1263866CurrentTrain: epoch  8, batch    58 | loss: 95.1984128CurrentTrain: epoch  8, batch    59 | loss: 120.7706228CurrentTrain: epoch  8, batch    60 | loss: 76.1690606CurrentTrain: epoch  8, batch    61 | loss: 99.8799203CurrentTrain: epoch  8, batch    62 | loss: 63.7013625CurrentTrain: epoch  8, batch    63 | loss: 67.8071107CurrentTrain: epoch  8, batch    64 | loss: 77.2489180CurrentTrain: epoch  8, batch    65 | loss: 96.2358149CurrentTrain: epoch  8, batch    66 | loss: 65.1994491CurrentTrain: epoch  8, batch    67 | loss: 76.4272960CurrentTrain: epoch  8, batch    68 | loss: 78.0737614CurrentTrain: epoch  8, batch    69 | loss: 68.1694621CurrentTrain: epoch  8, batch    70 | loss: 72.1215485CurrentTrain: epoch  8, batch    71 | loss: 66.4880723CurrentTrain: epoch  8, batch    72 | loss: 129.2790578CurrentTrain: epoch  8, batch    73 | loss: 66.1192862CurrentTrain: epoch  8, batch    74 | loss: 75.4356336CurrentTrain: epoch  8, batch    75 | loss: 99.3062332CurrentTrain: epoch  8, batch    76 | loss: 79.3980635CurrentTrain: epoch  8, batch    77 | loss: 66.6453262CurrentTrain: epoch  8, batch    78 | loss: 63.7438519CurrentTrain: epoch  8, batch    79 | loss: 53.7526864CurrentTrain: epoch  8, batch    80 | loss: 78.5242340CurrentTrain: epoch  8, batch    81 | loss: 64.5082936CurrentTrain: epoch  8, batch    82 | loss: 65.6640509CurrentTrain: epoch  8, batch    83 | loss: 63.9964658CurrentTrain: epoch  8, batch    84 | loss: 96.2009669CurrentTrain: epoch  8, batch    85 | loss: 78.1955572CurrentTrain: epoch  8, batch    86 | loss: 56.3988477CurrentTrain: epoch  8, batch    87 | loss: 77.2512634CurrentTrain: epoch  8, batch    88 | loss: 80.0958681CurrentTrain: epoch  8, batch    89 | loss: 66.7538833CurrentTrain: epoch  8, batch    90 | loss: 125.8858731CurrentTrain: epoch  8, batch    91 | loss: 63.6284398CurrentTrain: epoch  8, batch    92 | loss: 67.5816655CurrentTrain: epoch  8, batch    93 | loss: 98.3612445CurrentTrain: epoch  8, batch    94 | loss: 98.5549856CurrentTrain: epoch  8, batch    95 | loss: 81.9824595CurrentTrain: epoch  9, batch     0 | loss: 118.9279391CurrentTrain: epoch  9, batch     1 | loss: 79.2219288CurrentTrain: epoch  9, batch     2 | loss: 67.4980687CurrentTrain: epoch  9, batch     3 | loss: 120.2699858CurrentTrain: epoch  9, batch     4 | loss: 164.0242082CurrentTrain: epoch  9, batch     5 | loss: 97.4060844CurrentTrain: epoch  9, batch     6 | loss: 102.7177284CurrentTrain: epoch  9, batch     7 | loss: 64.0700708CurrentTrain: epoch  9, batch     8 | loss: 80.0938299CurrentTrain: epoch  9, batch     9 | loss: 80.6908291CurrentTrain: epoch  9, batch    10 | loss: 66.6457801CurrentTrain: epoch  9, batch    11 | loss: 78.1136117CurrentTrain: epoch  9, batch    12 | loss: 65.5467758CurrentTrain: epoch  9, batch    13 | loss: 78.8261291CurrentTrain: epoch  9, batch    14 | loss: 93.0537637CurrentTrain: epoch  9, batch    15 | loss: 56.6240090CurrentTrain: epoch  9, batch    16 | loss: 124.2469189CurrentTrain: epoch  9, batch    17 | loss: 122.1476844CurrentTrain: epoch  9, batch    18 | loss: 73.2323096CurrentTrain: epoch  9, batch    19 | loss: 96.0173801CurrentTrain: epoch  9, batch    20 | loss: 77.7063778CurrentTrain: epoch  9, batch    21 | loss: 95.6870178CurrentTrain: epoch  9, batch    22 | loss: 74.5293465CurrentTrain: epoch  9, batch    23 | loss: 91.0124698CurrentTrain: epoch  9, batch    24 | loss: 94.8546873CurrentTrain: epoch  9, batch    25 | loss: 97.9330240CurrentTrain: epoch  9, batch    26 | loss: 80.4779371CurrentTrain: epoch  9, batch    27 | loss: 167.7097487CurrentTrain: epoch  9, batch    28 | loss: 66.6175852CurrentTrain: epoch  9, batch    29 | loss: 93.4800146CurrentTrain: epoch  9, batch    30 | loss: 76.5244163CurrentTrain: epoch  9, batch    31 | loss: 73.0564118CurrentTrain: epoch  9, batch    32 | loss: 74.6880917CurrentTrain: epoch  9, batch    33 | loss: 76.3717334CurrentTrain: epoch  9, batch    34 | loss: 65.7662774CurrentTrain: epoch  9, batch    35 | loss: 65.4088932CurrentTrain: epoch  9, batch    36 | loss: 77.5586732CurrentTrain: epoch  9, batch    37 | loss: 65.6159066CurrentTrain: epoch  9, batch    38 | loss: 74.5810189CurrentTrain: epoch  9, batch    39 | loss: 98.8696014CurrentTrain: epoch  9, batch    40 | loss: 79.8237445CurrentTrain: epoch  9, batch    41 | loss: 74.7187113CurrentTrain: epoch  9, batch    42 | loss: 75.0605179CurrentTrain: epoch  9, batch    43 | loss: 66.8439543CurrentTrain: epoch  9, batch    44 | loss: 52.5452375CurrentTrain: epoch  9, batch    45 | loss: 65.5551446CurrentTrain: epoch  9, batch    46 | loss: 80.5639120CurrentTrain: epoch  9, batch    47 | loss: 57.1730288CurrentTrain: epoch  9, batch    48 | loss: 75.8715822CurrentTrain: epoch  9, batch    49 | loss: 73.8814036CurrentTrain: epoch  9, batch    50 | loss: 66.6988516CurrentTrain: epoch  9, batch    51 | loss: 68.2794500CurrentTrain: epoch  9, batch    52 | loss: 96.3108795CurrentTrain: epoch  9, batch    53 | loss: 97.6596115CurrentTrain: epoch  9, batch    54 | loss: 73.7022213CurrentTrain: epoch  9, batch    55 | loss: 77.0425786CurrentTrain: epoch  9, batch    56 | loss: 124.8094060CurrentTrain: epoch  9, batch    57 | loss: 75.8881004CurrentTrain: epoch  9, batch    58 | loss: 96.5190240CurrentTrain: epoch  9, batch    59 | loss: 74.0819977CurrentTrain: epoch  9, batch    60 | loss: 53.3939850CurrentTrain: epoch  9, batch    61 | loss: 77.0436206CurrentTrain: epoch  9, batch    62 | loss: 75.1789247CurrentTrain: epoch  9, batch    63 | loss: 98.2111976CurrentTrain: epoch  9, batch    64 | loss: 118.2173464CurrentTrain: epoch  9, batch    65 | loss: 123.7898548CurrentTrain: epoch  9, batch    66 | loss: 121.9579741CurrentTrain: epoch  9, batch    67 | loss: 78.8625305CurrentTrain: epoch  9, batch    68 | loss: 74.6856991CurrentTrain: epoch  9, batch    69 | loss: 62.8769108CurrentTrain: epoch  9, batch    70 | loss: 74.3202001CurrentTrain: epoch  9, batch    71 | loss: 66.0026353CurrentTrain: epoch  9, batch    72 | loss: 78.1125238CurrentTrain: epoch  9, batch    73 | loss: 116.9784925CurrentTrain: epoch  9, batch    74 | loss: 56.2928393CurrentTrain: epoch  9, batch    75 | loss: 62.5000615CurrentTrain: epoch  9, batch    76 | loss: 77.2537134CurrentTrain: epoch  9, batch    77 | loss: 62.4640060CurrentTrain: epoch  9, batch    78 | loss: 68.4496007CurrentTrain: epoch  9, batch    79 | loss: 56.5448043CurrentTrain: epoch  9, batch    80 | loss: 92.5918192CurrentTrain: epoch  9, batch    81 | loss: 97.7745409CurrentTrain: epoch  9, batch    82 | loss: 67.8297084CurrentTrain: epoch  9, batch    83 | loss: 67.4896126CurrentTrain: epoch  9, batch    84 | loss: 74.6088671CurrentTrain: epoch  9, batch    85 | loss: 81.4703788CurrentTrain: epoch  9, batch    86 | loss: 57.6601542CurrentTrain: epoch  9, batch    87 | loss: 121.8771339CurrentTrain: epoch  9, batch    88 | loss: 52.7315632CurrentTrain: epoch  9, batch    89 | loss: 56.4952778CurrentTrain: epoch  9, batch    90 | loss: 68.0296712CurrentTrain: epoch  9, batch    91 | loss: 118.3028924CurrentTrain: epoch  9, batch    92 | loss: 124.5225923CurrentTrain: epoch  9, batch    93 | loss: 61.2773439CurrentTrain: epoch  9, batch    94 | loss: 81.5258137CurrentTrain: epoch  9, batch    95 | loss: 108.6643540

F1 score per class: {32: np.float64(0.5573770491803278), 6: np.float64(0.827906976744186), 19: np.float64(0.35294117647058826), 24: np.float64(0.745945945945946), 26: np.float64(0.9292929292929293), 29: np.float64(0.8272727272727273)}
Micro-average F1 score: 0.7690821256038647
Weighted-average F1 score: 0.7753723326497441
F1 score per class: {32: np.float64(0.5870646766169154), 6: np.float64(0.7863247863247863), 19: np.float64(0.21052631578947367), 24: np.float64(0.7570621468926554), 26: np.float64(0.94), 29: np.float64(0.8235294117647058)}
Micro-average F1 score: 0.7412082957619477
Weighted-average F1 score: 0.7255709376580087
F1 score per class: {32: np.float64(0.5841584158415841), 6: np.float64(0.8), 19: np.float64(0.3076923076923077), 24: np.float64(0.7570621468926554), 26: np.float64(0.94), 29: np.float64(0.8272727272727273)}
Micro-average F1 score: 0.7602230483271375
Weighted-average F1 score: 0.7555774363097522

F1 score per class: {32: np.float64(0.5573770491803278), 6: np.float64(0.827906976744186), 19: np.float64(0.35294117647058826), 24: np.float64(0.745945945945946), 26: np.float64(0.9292929292929293), 29: np.float64(0.8272727272727273)}
Micro-average F1 score: 0.7690821256038647
Weighted-average F1 score: 0.7753723326497441
F1 score per class: {32: np.float64(0.5870646766169154), 6: np.float64(0.7863247863247863), 19: np.float64(0.21052631578947367), 24: np.float64(0.7570621468926554), 26: np.float64(0.94), 29: np.float64(0.8235294117647058)}
Micro-average F1 score: 0.7412082957619477
Weighted-average F1 score: 0.7255709376580087
F1 score per class: {32: np.float64(0.5841584158415841), 6: np.float64(0.8), 19: np.float64(0.3076923076923077), 24: np.float64(0.7570621468926554), 26: np.float64(0.94), 29: np.float64(0.8272727272727273)}
Micro-average F1 score: 0.7602230483271375
Weighted-average F1 score: 0.7555774363097522

F1 score per class: {32: np.float64(0.4063745019920319), 6: np.float64(0.7705627705627706), 19: np.float64(0.2), 24: np.float64(0.6831683168316832), 26: np.float64(0.8518518518518519), 29: np.float64(0.6476868327402135)}
Micro-average F1 score: 0.6414182111200645
Weighted-average F1 score: 0.6313078459227454
F1 score per class: {32: np.float64(0.4290909090909091), 6: np.float64(0.7215686274509804), 19: np.float64(0.12030075187969924), 24: np.float64(0.6979166666666666), 26: np.float64(0.8663594470046083), 29: np.float64(0.6275862068965518)}
Micro-average F1 score: 0.6035242290748899
Weighted-average F1 score: 0.5753345980511775
F1 score per class: {32: np.float64(0.427536231884058), 6: np.float64(0.7468879668049793), 19: np.float64(0.15841584158415842), 24: np.float64(0.6979166666666666), 26: np.float64(0.8663594470046083), 29: np.float64(0.6341463414634146)}
Micro-average F1 score: 0.6225266362252664
Weighted-average F1 score: 0.6003314691823022

F1 score per class: {32: np.float64(0.4063745019920319), 6: np.float64(0.7705627705627706), 19: np.float64(0.2), 24: np.float64(0.6831683168316832), 26: np.float64(0.8518518518518519), 29: np.float64(0.6476868327402135)}
Micro-average F1 score: 0.6414182111200645
Weighted-average F1 score: 0.6313078459227454
F1 score per class: {32: np.float64(0.4290909090909091), 6: np.float64(0.7215686274509804), 19: np.float64(0.12030075187969924), 24: np.float64(0.6979166666666666), 26: np.float64(0.8663594470046083), 29: np.float64(0.6275862068965518)}
Micro-average F1 score: 0.6035242290748899
Weighted-average F1 score: 0.5753345980511775
F1 score per class: {32: np.float64(0.427536231884058), 6: np.float64(0.7468879668049793), 19: np.float64(0.15841584158415842), 24: np.float64(0.6979166666666666), 26: np.float64(0.8663594470046083), 29: np.float64(0.6341463414634146)}
Micro-average F1 score: 0.6225266362252664
Weighted-average F1 score: 0.6003314691823022
cur_acc_wo_na:  ['0.7691']
his_acc_wo_na:  ['0.7691']
cur_acc des_wo_na:  ['0.7412']
his_acc des_wo_na:  ['0.7412']
cur_acc rrf_wo_na:  ['0.7602']
his_acc rrf_wo_na:  ['0.7602']
cur_acc_w_na:  ['0.6414']
his_acc_w_na:  ['0.6414']
cur_acc des_w_na:  ['0.6035']
his_acc des_w_na:  ['0.6035']
cur_acc rrf_w_na:  ['0.6225']
his_acc rrf_w_na:  ['0.6225']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 93.8844011CurrentTrain: epoch  0, batch     1 | loss: 119.7822313CurrentTrain: epoch  0, batch     2 | loss: 117.7084975CurrentTrain: epoch  0, batch     3 | loss: 118.6842523CurrentTrain: epoch  0, batch     4 | loss: 59.0231842CurrentTrain: epoch  1, batch     0 | loss: 89.9190109CurrentTrain: epoch  1, batch     1 | loss: 106.4413959CurrentTrain: epoch  1, batch     2 | loss: 111.1866841CurrentTrain: epoch  1, batch     3 | loss: 86.6651745CurrentTrain: epoch  1, batch     4 | loss: 88.6774673CurrentTrain: epoch  2, batch     0 | loss: 86.6959753CurrentTrain: epoch  2, batch     1 | loss: 105.8598688CurrentTrain: epoch  2, batch     2 | loss: 106.1019131CurrentTrain: epoch  2, batch     3 | loss: 84.6101869CurrentTrain: epoch  2, batch     4 | loss: 83.3554809CurrentTrain: epoch  3, batch     0 | loss: 266.2157589CurrentTrain: epoch  3, batch     1 | loss: 83.1399362CurrentTrain: epoch  3, batch     2 | loss: 83.9828141CurrentTrain: epoch  3, batch     3 | loss: 104.3525573CurrentTrain: epoch  3, batch     4 | loss: 54.3604776CurrentTrain: epoch  4, batch     0 | loss: 72.9340812CurrentTrain: epoch  4, batch     1 | loss: 97.4382170CurrentTrain: epoch  4, batch     2 | loss: 128.4192664CurrentTrain: epoch  4, batch     3 | loss: 84.1352195CurrentTrain: epoch  4, batch     4 | loss: 82.1997482CurrentTrain: epoch  5, batch     0 | loss: 103.2448701CurrentTrain: epoch  5, batch     1 | loss: 82.9029421CurrentTrain: epoch  5, batch     2 | loss: 122.5804856CurrentTrain: epoch  5, batch     3 | loss: 79.7563340CurrentTrain: epoch  5, batch     4 | loss: 77.9163249CurrentTrain: epoch  6, batch     0 | loss: 78.8820348CurrentTrain: epoch  6, batch     1 | loss: 124.6366082CurrentTrain: epoch  6, batch     2 | loss: 79.2996542CurrentTrain: epoch  6, batch     3 | loss: 124.1659845CurrentTrain: epoch  6, batch     4 | loss: 63.2207132CurrentTrain: epoch  7, batch     0 | loss: 67.7138977CurrentTrain: epoch  7, batch     1 | loss: 99.3107752CurrentTrain: epoch  7, batch     2 | loss: 65.4953166CurrentTrain: epoch  7, batch     3 | loss: 82.2765149CurrentTrain: epoch  7, batch     4 | loss: 161.4571730CurrentTrain: epoch  8, batch     0 | loss: 66.5028977CurrentTrain: epoch  8, batch     1 | loss: 124.7570874CurrentTrain: epoch  8, batch     2 | loss: 68.1079314CurrentTrain: epoch  8, batch     3 | loss: 79.1225763CurrentTrain: epoch  8, batch     4 | loss: 72.9631591CurrentTrain: epoch  9, batch     0 | loss: 64.3732319CurrentTrain: epoch  9, batch     1 | loss: 80.8019851CurrentTrain: epoch  9, batch     2 | loss: 78.4412959CurrentTrain: epoch  9, batch     3 | loss: 96.8697907CurrentTrain: epoch  9, batch     4 | loss: 76.5816719
MemoryTrain:  epoch  0, batch     0 | loss: 2.0243127MemoryTrain:  epoch  1, batch     0 | loss: 1.6569589MemoryTrain:  epoch  2, batch     0 | loss: 1.5422153MemoryTrain:  epoch  3, batch     0 | loss: 1.1144036MemoryTrain:  epoch  4, batch     0 | loss: 0.9197836MemoryTrain:  epoch  5, batch     0 | loss: 0.8522366MemoryTrain:  epoch  6, batch     0 | loss: 0.6662020MemoryTrain:  epoch  7, batch     0 | loss: 0.4859887MemoryTrain:  epoch  8, batch     0 | loss: 0.3784992MemoryTrain:  epoch  9, batch     0 | loss: 0.3034889

F1 score per class: {32: np.float64(0.8761904761904762), 5: np.float64(0.0), 6: np.float64(0.11320754716981132), 10: np.float64(0.5957446808510638), 16: np.float64(0.2), 17: np.float64(0.2222222222222222), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5209713024282561
Weighted-average F1 score: 0.6167550000916221
F1 score per class: {32: np.float64(0.7196969696969697), 5: np.float64(0.0), 6: np.float64(0.5138888888888888), 10: np.float64(0.576271186440678), 16: np.float64(0.36363636363636365), 17: np.float64(0.53125), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5590682196339434
Weighted-average F1 score: 0.53053631161682
F1 score per class: {32: np.float64(0.7916666666666666), 5: np.float64(0.0), 6: np.float64(0.4393939393939394), 10: np.float64(0.5614035087719298), 16: np.float64(0.36363636363636365), 17: np.float64(0.45901639344262296), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5683060109289617
Weighted-average F1 score: 0.5560274736288541

F1 score per class: {32: np.float64(0.8761904761904762), 5: np.float64(0.5633802816901409), 6: np.float64(0.11320754716981132), 10: np.float64(0.5957446808510638), 16: np.float64(0.13333333333333333), 17: np.float64(0.20408163265306123), 18: np.float64(0.7818930041152263), 19: np.float64(0.3404255319148936), 24: np.float64(0.7513227513227513), 26: np.float64(0.898989898989899), 29: np.float64(0.7896995708154506)}
Micro-average F1 score: 0.687741935483871
Weighted-average F1 score: 0.7351595589450544
F1 score per class: {32: np.float64(0.6761565836298933), 5: np.float64(0.5625), 6: np.float64(0.4625), 10: np.float64(0.5483870967741935), 16: np.float64(0.17391304347826086), 17: np.float64(0.4788732394366197), 18: np.float64(0.7106227106227107), 19: np.float64(0.23376623376623376), 24: np.float64(0.7329842931937173), 26: np.float64(0.8878048780487805), 29: np.float64(0.7401574803149606)}
Micro-average F1 score: 0.6501922020867655
Weighted-average F1 score: 0.6492545988875525
F1 score per class: {32: np.float64(0.7630522088353414), 5: np.float64(0.5726872246696035), 6: np.float64(0.4084507042253521), 10: np.float64(0.5423728813559322), 16: np.float64(0.19047619047619047), 17: np.float64(0.42424242424242425), 18: np.float64(0.7384615384615385), 19: np.float64(0.2903225806451613), 24: np.float64(0.7329842931937173), 26: np.float64(0.8878048780487805), 29: np.float64(0.7560975609756098)}
Micro-average F1 score: 0.6712962962962963
Weighted-average F1 score: 0.6800191765047746

F1 score per class: {32: np.float64(0.7634854771784232), 5: np.float64(0.0), 6: np.float64(0.11214953271028037), 10: np.float64(0.3835616438356164), 16: np.float64(0.2), 17: np.float64(0.15873015873015872), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.4068965517241379
Weighted-average F1 score: 0.42518629547054365
F1 score per class: {32: np.float64(0.5444126074498568), 5: np.float64(0.0), 6: np.float64(0.42528735632183906), 10: np.float64(0.38202247191011235), 16: np.float64(0.2), 17: np.float64(0.38636363636363635), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.4014336917562724
Weighted-average F1 score: 0.37695877882365864
F1 score per class: {32: np.float64(0.5993690851735016), 5: np.float64(0.0), 6: np.float64(0.3815789473684211), 10: np.float64(0.367816091954023), 16: np.float64(0.21052631578947367), 17: np.float64(0.35443037974683544), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.41379310344827586
Weighted-average F1 score: 0.39301684747792653

F1 score per class: {32: np.float64(0.757201646090535), 5: np.float64(0.3715170278637771), 6: np.float64(0.11009174311926606), 10: np.float64(0.36363636363636365), 16: np.float64(0.09523809523809523), 17: np.float64(0.14285714285714285), 18: np.float64(0.7116104868913857), 19: np.float64(0.19047619047619047), 24: np.float64(0.6543778801843319), 26: np.float64(0.8018018018018018), 29: np.float64(0.6013071895424836)}
Micro-average F1 score: 0.5497679216090768
Weighted-average F1 score: 0.5630818366551288
F1 score per class: {32: np.float64(0.4935064935064935), 5: np.float64(0.358974358974359), 6: np.float64(0.3490566037735849), 10: np.float64(0.35051546391752575), 16: np.float64(0.10526315789473684), 17: np.float64(0.3300970873786408), 18: np.float64(0.6258064516129033), 19: np.float64(0.1258741258741259), 24: np.float64(0.6511627906976745), 26: np.float64(0.7489711934156379), 29: np.float64(0.5513196480938416)}
Micro-average F1 score: 0.4856439704675964
Weighted-average F1 score: 0.4745608802647373
F1 score per class: {32: np.float64(0.5571847507331378), 5: np.float64(0.37037037037037035), 6: np.float64(0.32222222222222224), 10: np.float64(0.3333333333333333), 16: np.float64(0.11428571428571428), 17: np.float64(0.30434782608695654), 18: np.float64(0.6552901023890785), 19: np.float64(0.15126050420168066), 24: np.float64(0.6511627906976745), 26: np.float64(0.7679324894514767), 29: np.float64(0.5619335347432024)}
Micro-average F1 score: 0.5065502183406113
Weighted-average F1 score: 0.498915938415685
cur_acc_wo_na:  ['0.7691', '0.5210']
his_acc_wo_na:  ['0.7691', '0.6877']
cur_acc des_wo_na:  ['0.7412', '0.5591']
his_acc des_wo_na:  ['0.7412', '0.6502']
cur_acc rrf_wo_na:  ['0.7602', '0.5683']
his_acc rrf_wo_na:  ['0.7602', '0.6713']
cur_acc_w_na:  ['0.6414', '0.4069']
his_acc_w_na:  ['0.6414', '0.5498']
cur_acc des_w_na:  ['0.6035', '0.4014']
his_acc des_w_na:  ['0.6035', '0.4856']
cur_acc rrf_w_na:  ['0.6225', '0.4138']
his_acc rrf_w_na:  ['0.6225', '0.5066']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 81.3454379CurrentTrain: epoch  0, batch     1 | loss: 97.1776971CurrentTrain: epoch  0, batch     2 | loss: 113.8003479CurrentTrain: epoch  0, batch     3 | loss: 79.4721014CurrentTrain: epoch  0, batch     4 | loss: 41.0285153CurrentTrain: epoch  1, batch     0 | loss: 91.7020806CurrentTrain: epoch  1, batch     1 | loss: 78.6591894CurrentTrain: epoch  1, batch     2 | loss: 91.1153858CurrentTrain: epoch  1, batch     3 | loss: 86.3678432CurrentTrain: epoch  1, batch     4 | loss: 39.2815180CurrentTrain: epoch  2, batch     0 | loss: 100.8934172CurrentTrain: epoch  2, batch     1 | loss: 88.4682612CurrentTrain: epoch  2, batch     2 | loss: 102.9778023CurrentTrain: epoch  2, batch     3 | loss: 67.5967596CurrentTrain: epoch  2, batch     4 | loss: 25.2280866CurrentTrain: epoch  3, batch     0 | loss: 84.9678643CurrentTrain: epoch  3, batch     1 | loss: 72.5332556CurrentTrain: epoch  3, batch     2 | loss: 101.1216984CurrentTrain: epoch  3, batch     3 | loss: 81.7088247CurrentTrain: epoch  3, batch     4 | loss: 13.2424847CurrentTrain: epoch  4, batch     0 | loss: 101.0638734CurrentTrain: epoch  4, batch     1 | loss: 79.7277354CurrentTrain: epoch  4, batch     2 | loss: 65.0095355CurrentTrain: epoch  4, batch     3 | loss: 81.9289034CurrentTrain: epoch  4, batch     4 | loss: 40.8226545CurrentTrain: epoch  5, batch     0 | loss: 79.7294636CurrentTrain: epoch  5, batch     1 | loss: 95.6016907CurrentTrain: epoch  5, batch     2 | loss: 94.8299444CurrentTrain: epoch  5, batch     3 | loss: 78.2686770CurrentTrain: epoch  5, batch     4 | loss: 40.7242208CurrentTrain: epoch  6, batch     0 | loss: 65.5239291CurrentTrain: epoch  6, batch     1 | loss: 80.4922895CurrentTrain: epoch  6, batch     2 | loss: 77.4321568CurrentTrain: epoch  6, batch     3 | loss: 98.7640806CurrentTrain: epoch  6, batch     4 | loss: 16.0356906CurrentTrain: epoch  7, batch     0 | loss: 95.3925073CurrentTrain: epoch  7, batch     1 | loss: 97.1280491CurrentTrain: epoch  7, batch     2 | loss: 70.3644899CurrentTrain: epoch  7, batch     3 | loss: 122.1715395CurrentTrain: epoch  7, batch     4 | loss: 23.5903567CurrentTrain: epoch  8, batch     0 | loss: 96.4134665CurrentTrain: epoch  8, batch     1 | loss: 90.3998554CurrentTrain: epoch  8, batch     2 | loss: 64.4997662CurrentTrain: epoch  8, batch     3 | loss: 65.9178840CurrentTrain: epoch  8, batch     4 | loss: 24.5662057CurrentTrain: epoch  9, batch     0 | loss: 77.5131396CurrentTrain: epoch  9, batch     1 | loss: 74.7764285CurrentTrain: epoch  9, batch     2 | loss: 75.0126910CurrentTrain: epoch  9, batch     3 | loss: 78.0058599CurrentTrain: epoch  9, batch     4 | loss: 25.2964067
MemoryTrain:  epoch  0, batch     0 | loss: 1.2839300MemoryTrain:  epoch  1, batch     0 | loss: 1.1945650MemoryTrain:  epoch  2, batch     0 | loss: 0.8394793MemoryTrain:  epoch  3, batch     0 | loss: 0.6684623MemoryTrain:  epoch  4, batch     0 | loss: 0.6215465MemoryTrain:  epoch  5, batch     0 | loss: 0.4691771MemoryTrain:  epoch  6, batch     0 | loss: 0.4254911MemoryTrain:  epoch  7, batch     0 | loss: 0.3655197MemoryTrain:  epoch  8, batch     0 | loss: 0.3232439MemoryTrain:  epoch  9, batch     0 | loss: 0.2682586

F1 score per class: {32: np.float64(0.6), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.5401459854014599), 39: np.float64(0.5068493150684932), 11: np.float64(0.0), 12: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.25), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.3225806451612903)}
Micro-average F1 score: 0.43373493975903615
Weighted-average F1 score: 0.3564596568651232
F1 score per class: {32: np.float64(0.5384615384615384), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.5217391304347826), 11: np.float64(0.6532663316582915), 12: np.float64(0.0), 10: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.24), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.23529411764705882)}
Micro-average F1 score: 0.43223443223443225
Weighted-average F1 score: 0.35076468459540466
F1 score per class: {32: np.float64(0.6), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.5616438356164384), 11: np.float64(0.6486486486486487), 12: np.float64(0.0), 10: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.23076923076923078), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.22857142857142856)}
Micro-average F1 score: 0.46062992125984253
Weighted-average F1 score: 0.37807724482607163

F1 score per class: {32: np.float64(0.5217391304347826), 2: np.float64(0.8878048780487805), 5: np.float64(0.5170731707317073), 6: np.float64(0.11320754716981132), 39: np.float64(0.387434554973822), 11: np.float64(0.3645320197044335), 12: np.float64(0.35), 10: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.7829787234042553), 18: np.float64(0.35), 19: np.float64(0.7431693989071039), 24: np.float64(0.09259259259259259), 26: np.float64(0.8556149732620321), 28: np.float64(0.71875), 29: np.float64(0.2222222222222222)}
Micro-average F1 score: 0.5637325637325638
Weighted-average F1 score: 0.5762149943843587
F1 score per class: {32: np.float64(0.45161290322580644), 2: np.float64(0.6859205776173285), 5: np.float64(0.5509433962264151), 6: np.float64(0.375), 39: np.float64(0.4161849710982659), 10: np.float64(0.37681159420289856), 12: np.float64(0.5769230769230769), 11: np.float64(0.0), 16: np.float64(0.35294117647058826), 17: np.float64(0.7559055118110236), 18: np.float64(0.24390243902439024), 19: np.float64(0.7368421052631579), 24: np.float64(0.125), 26: np.float64(0.8526315789473684), 28: np.float64(0.5875), 29: np.float64(0.19047619047619047)}
Micro-average F1 score: 0.543461237274863
Weighted-average F1 score: 0.5300014948742967
F1 score per class: {32: np.float64(0.5217391304347826), 2: np.float64(0.7704918032786885), 5: np.float64(0.5511111111111111), 6: np.float64(0.26356589147286824), 39: np.float64(0.41414141414141414), 11: np.float64(0.40816326530612246), 12: np.float64(0.56), 10: np.float64(0.0), 16: np.float64(0.18867924528301888), 17: np.float64(0.75), 18: np.float64(0.36363636363636365), 19: np.float64(0.7446808510638298), 24: np.float64(0.10344827586206896), 26: np.float64(0.8571428571428571), 28: np.float64(0.6394557823129252), 29: np.float64(0.17777777777777778)}
Micro-average F1 score: 0.5574324324324325
Weighted-average F1 score: 0.551111207008185

F1 score per class: {32: np.float64(0.4), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.45962732919254656), 11: np.float64(0.42528735632183906), 12: np.float64(0.0), 10: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.12345679012345678), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.18867924528301888)}
Micro-average F1 score: 0.30560271646859083
Weighted-average F1 score: 0.24268890714573535
F1 score per class: {32: np.float64(0.358974358974359), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.4675324675324675), 11: np.float64(0.5158730158730159), 12: np.float64(0.0), 10: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.13333333333333333), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.16)}
Micro-average F1 score: 0.2964824120603015
Weighted-average F1 score: 0.23697123981352755
F1 score per class: {32: np.float64(0.375), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.48520710059171596), 11: np.float64(0.5128205128205128), 12: np.float64(0.0), 10: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.12121212121212122), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.14814814814814814)}
Micro-average F1 score: 0.3183673469387755
Weighted-average F1 score: 0.2589165752366408

F1 score per class: {32: np.float64(0.34285714285714286), 2: np.float64(0.7583333333333333), 5: np.float64(0.3212121212121212), 6: np.float64(0.10909090909090909), 39: np.float64(0.26714801444043323), 11: np.float64(0.19786096256684493), 12: np.float64(0.2916666666666667), 10: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.7215686274509804), 18: np.float64(0.23333333333333334), 19: np.float64(0.6699507389162561), 24: np.float64(0.04878048780487805), 26: np.float64(0.7729468599033816), 28: np.float64(0.5443786982248521), 29: np.float64(0.11494252873563218)}
Micro-average F1 score: 0.4128214159915463
Weighted-average F1 score: 0.3948091982852803
F1 score per class: {32: np.float64(0.25), 2: np.float64(0.46116504854368934), 5: np.float64(0.3173913043478261), 6: np.float64(0.2764976958525346), 39: np.float64(0.32432432432432434), 10: np.float64(0.203125), 12: np.float64(0.379746835443038), 11: np.float64(0.0), 16: np.float64(0.17777777777777778), 17: np.float64(0.6808510638297872), 18: np.float64(0.145985401459854), 19: np.float64(0.6511627906976745), 24: np.float64(0.0670391061452514), 26: np.float64(0.7677725118483413), 28: np.float64(0.432183908045977), 29: np.float64(0.10666666666666667)}
Micro-average F1 score: 0.36836518046709127
Weighted-average F1 score: 0.34684826166716326
F1 score per class: {32: np.float64(0.26666666666666666), 2: np.float64(0.5310734463276836), 5: np.float64(0.32545931758530183), 6: np.float64(0.23448275862068965), 39: np.float64(0.29818181818181816), 10: np.float64(0.20797227036395147), 12: np.float64(0.42424242424242425), 11: np.float64(0.0), 16: np.float64(0.1111111111111111), 17: np.float64(0.6808510638297872), 18: np.float64(0.20408163265306123), 19: np.float64(0.6572769953051644), 24: np.float64(0.0547945205479452), 26: np.float64(0.7714285714285715), 28: np.float64(0.47474747474747475), 29: np.float64(0.0963855421686747)}
Micro-average F1 score: 0.3830528148578062
Weighted-average F1 score: 0.361993918289459
cur_acc_wo_na:  ['0.7691', '0.5210', '0.4337']
his_acc_wo_na:  ['0.7691', '0.6877', '0.5637']
cur_acc des_wo_na:  ['0.7412', '0.5591', '0.4322']
his_acc des_wo_na:  ['0.7412', '0.6502', '0.5435']
cur_acc rrf_wo_na:  ['0.7602', '0.5683', '0.4606']
his_acc rrf_wo_na:  ['0.7602', '0.6713', '0.5574']
cur_acc_w_na:  ['0.6414', '0.4069', '0.3056']
his_acc_w_na:  ['0.6414', '0.5498', '0.4128']
cur_acc des_w_na:  ['0.6035', '0.4014', '0.2965']
his_acc des_w_na:  ['0.6035', '0.4856', '0.3684']
cur_acc rrf_w_na:  ['0.6225', '0.4138', '0.3184']
his_acc rrf_w_na:  ['0.6225', '0.5066', '0.3831']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 114.1210899CurrentTrain: epoch  0, batch     1 | loss: 122.5110968CurrentTrain: epoch  0, batch     2 | loss: 99.6797117CurrentTrain: epoch  0, batch     3 | loss: 102.1184418CurrentTrain: epoch  1, batch     0 | loss: 92.8560239CurrentTrain: epoch  1, batch     1 | loss: 81.3872718CurrentTrain: epoch  1, batch     2 | loss: 105.3933211CurrentTrain: epoch  1, batch     3 | loss: 80.7251885CurrentTrain: epoch  2, batch     0 | loss: 106.5489140CurrentTrain: epoch  2, batch     1 | loss: 85.2285538CurrentTrain: epoch  2, batch     2 | loss: 91.4924835CurrentTrain: epoch  2, batch     3 | loss: 84.8003001CurrentTrain: epoch  3, batch     0 | loss: 105.0262907CurrentTrain: epoch  3, batch     1 | loss: 102.4376095CurrentTrain: epoch  3, batch     2 | loss: 87.9283818CurrentTrain: epoch  3, batch     3 | loss: 77.5344341CurrentTrain: epoch  4, batch     0 | loss: 101.6496769CurrentTrain: epoch  4, batch     1 | loss: 85.2484467CurrentTrain: epoch  4, batch     2 | loss: 83.1678771CurrentTrain: epoch  4, batch     3 | loss: 68.2901781CurrentTrain: epoch  5, batch     0 | loss: 81.8927463CurrentTrain: epoch  5, batch     1 | loss: 122.9616484CurrentTrain: epoch  5, batch     2 | loss: 99.8726899CurrentTrain: epoch  5, batch     3 | loss: 58.6985305CurrentTrain: epoch  6, batch     0 | loss: 65.3227569CurrentTrain: epoch  6, batch     1 | loss: 83.9341146CurrentTrain: epoch  6, batch     2 | loss: 78.9584420CurrentTrain: epoch  6, batch     3 | loss: 142.5284000CurrentTrain: epoch  7, batch     0 | loss: 99.9018739CurrentTrain: epoch  7, batch     1 | loss: 97.3448689CurrentTrain: epoch  7, batch     2 | loss: 78.6911765CurrentTrain: epoch  7, batch     3 | loss: 78.3601415CurrentTrain: epoch  8, batch     0 | loss: 67.4700666CurrentTrain: epoch  8, batch     1 | loss: 67.1135961CurrentTrain: epoch  8, batch     2 | loss: 81.7740526CurrentTrain: epoch  8, batch     3 | loss: 79.3429932CurrentTrain: epoch  9, batch     0 | loss: 65.6212827CurrentTrain: epoch  9, batch     1 | loss: 62.8005050CurrentTrain: epoch  9, batch     2 | loss: 170.2591624CurrentTrain: epoch  9, batch     3 | loss: 101.8593460
MemoryTrain:  epoch  0, batch     0 | loss: 1.2090809MemoryTrain:  epoch  1, batch     0 | loss: 1.0364443MemoryTrain:  epoch  2, batch     0 | loss: 0.8328260MemoryTrain:  epoch  3, batch     0 | loss: 0.6853479MemoryTrain:  epoch  4, batch     0 | loss: 0.6236252MemoryTrain:  epoch  5, batch     0 | loss: 0.5820021MemoryTrain:  epoch  6, batch     0 | loss: 0.5012110MemoryTrain:  epoch  7, batch     0 | loss: 0.4493746MemoryTrain:  epoch  8, batch     0 | loss: 0.3820179MemoryTrain:  epoch  9, batch     0 | loss: 0.3760496

F1 score per class: {0: np.float64(0.9014084507042254), 2: np.float64(0.0), 4: np.float64(0.8636363636363636), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.3076923076923077), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.5569620253164557), 23: np.float64(0.8), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.6495049504950495
Weighted-average F1 score: 0.5329121636387215
F1 score per class: {0: np.float64(0.8), 2: np.float64(0.0), 4: np.float64(0.8541666666666666), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.36363636363636365), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.4489795918367347), 23: np.float64(0.6987951807228916), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5416666666666666
Weighted-average F1 score: 0.4316916105797941
F1 score per class: {0: np.float64(0.8571428571428571), 2: np.float64(0.0), 4: np.float64(0.8695652173913043), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.3333333333333333), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.43564356435643564), 23: np.float64(0.725), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5665529010238908
Weighted-average F1 score: 0.44831304749963846

F1 score per class: {0: np.float64(0.810126582278481), 2: np.float64(0.45161290322580644), 4: np.float64(0.8587570621468926), 5: np.float64(0.8611111111111112), 6: np.float64(0.5248868778280543), 10: np.float64(0.12844036697247707), 11: np.float64(0.357487922705314), 12: np.float64(0.34444444444444444), 13: np.float64(0.046511627906976744), 16: np.float64(0.3684210526315789), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.7580645161290323), 21: np.float64(0.30344827586206896), 23: np.float64(0.7710843373493976), 24: np.float64(0.09523809523809523), 26: np.float64(0.7262569832402235), 28: np.float64(0.12244897959183673), 29: np.float64(0.8512820512820513), 32: np.float64(0.6865671641791045), 39: np.float64(0.20408163265306123)}
Micro-average F1 score: 0.5667678300455236
Weighted-average F1 score: 0.564530816009598
F1 score per class: {0: np.float64(0.576271186440678), 2: np.float64(0.3181818181818182), 4: np.float64(0.8159203980099502), 5: np.float64(0.6552901023890785), 6: np.float64(0.5142857142857142), 10: np.float64(0.3558282208588957), 11: np.float64(0.42328042328042326), 12: np.float64(0.3333333333333333), 13: np.float64(0.10526315789473684), 16: np.float64(0.5084745762711864), 17: np.float64(0.0), 18: np.float64(0.36363636363636365), 19: np.float64(0.7063197026022305), 21: np.float64(0.20465116279069767), 23: np.float64(0.6823529411764706), 24: np.float64(0.32), 26: np.float64(0.6934673366834171), 28: np.float64(0.11764705882352941), 29: np.float64(0.8247422680412371), 32: np.float64(0.6), 39: np.float64(0.18461538461538463)}
Micro-average F1 score: 0.527306967984934
Weighted-average F1 score: 0.5077886739374456
F1 score per class: {0: np.float64(0.7021276595744681), 2: np.float64(0.3783783783783784), 4: np.float64(0.8602150537634409), 5: np.float64(0.7569721115537849), 6: np.float64(0.5296442687747036), 10: np.float64(0.2677165354330709), 11: np.float64(0.4), 12: np.float64(0.3463203463203463), 13: np.float64(0.06153846153846154), 16: np.float64(0.5652173913043478), 17: np.float64(0.0), 18: np.float64(0.2033898305084746), 19: np.float64(0.7116104868913857), 21: np.float64(0.19469026548672566), 23: np.float64(0.6987951807228916), 24: np.float64(0.32), 26: np.float64(0.7046632124352331), 28: np.float64(0.11627906976744186), 29: np.float64(0.8247422680412371), 32: np.float64(0.6143790849673203), 39: np.float64(0.1935483870967742)}
Micro-average F1 score: 0.5348837209302325
Weighted-average F1 score: 0.5125049042741091

F1 score per class: {0: np.float64(0.8767123287671232), 2: np.float64(0.0), 4: np.float64(0.8306010928961749), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.16666666666666666), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3893805309734513), 23: np.float64(0.7441860465116279), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.4932330827067669
Weighted-average F1 score: 0.36993406868863393
F1 score per class: {0: np.float64(0.7472527472527473), 2: np.float64(0.0), 4: np.float64(0.8078817733990148), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.2857142857142857), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.32592592592592595), 23: np.float64(0.6304347826086957), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.3912037037037037
Weighted-average F1 score: 0.2925477656783588
F1 score per class: {0: np.float64(0.8148148148148148), 2: np.float64(0.0), 4: np.float64(0.8333333333333334), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.2), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3188405797101449), 23: np.float64(0.6590909090909091), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.4139650872817955
Weighted-average F1 score: 0.3035346869763424

F1 score per class: {0: np.float64(0.7272727272727273), 2: np.float64(0.2978723404255319), 4: np.float64(0.8), 5: np.float64(0.6863468634686347), 6: np.float64(0.3036649214659686), 10: np.float64(0.1206896551724138), 11: np.float64(0.24104234527687296), 12: np.float64(0.19314641744548286), 13: np.float64(0.024691358024691357), 16: np.float64(0.30434782608695654), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.6666666666666666), 21: np.float64(0.1774193548387097), 23: np.float64(0.6881720430107527), 24: np.float64(0.07142857142857142), 26: np.float64(0.6598984771573604), 28: np.float64(0.08108108108108109), 29: np.float64(0.751131221719457), 32: np.float64(0.4842105263157895), 39: np.float64(0.10204081632653061)}
Micro-average F1 score: 0.41225165562913907
Weighted-average F1 score: 0.3873533855057989
F1 score per class: {0: np.float64(0.4689655172413793), 2: np.float64(0.20588235294117646), 4: np.float64(0.703862660944206), 5: np.float64(0.42290748898678415), 6: np.float64(0.2891566265060241), 10: np.float64(0.2555066079295154), 11: np.float64(0.35555555555555557), 12: np.float64(0.18454935622317598), 13: np.float64(0.06779661016949153), 16: np.float64(0.32967032967032966), 17: np.float64(0.0), 18: np.float64(0.17177914110429449), 19: np.float64(0.6148867313915858), 21: np.float64(0.1317365269461078), 23: np.float64(0.5979381443298969), 24: np.float64(0.21052631578947367), 26: np.float64(0.6026200873362445), 28: np.float64(0.06289308176100629), 29: np.float64(0.7174887892376681), 32: np.float64(0.4085106382978723), 39: np.float64(0.0967741935483871)}
Micro-average F1 score: 0.36253776435045315
Weighted-average F1 score: 0.3396466462166349
F1 score per class: {0: np.float64(0.6), 2: np.float64(0.23333333333333334), 4: np.float64(0.7804878048780488), 5: np.float64(0.5), 6: np.float64(0.30385487528344673), 10: np.float64(0.21794871794871795), 11: np.float64(0.2896551724137931), 12: np.float64(0.1864801864801865), 13: np.float64(0.034782608695652174), 16: np.float64(0.4), 17: np.float64(0.0), 18: np.float64(0.12244897959183673), 19: np.float64(0.6188925081433225), 21: np.float64(0.12394366197183099), 23: np.float64(0.6105263157894737), 24: np.float64(0.2222222222222222), 26: np.float64(0.6181818181818182), 28: np.float64(0.06289308176100629), 29: np.float64(0.7111111111111111), 32: np.float64(0.42152466367713004), 39: np.float64(0.09523809523809523)}
Micro-average F1 score: 0.37139561707035756
Weighted-average F1 score: 0.34470798923861334
cur_acc_wo_na:  ['0.7691', '0.5210', '0.4337', '0.6495']
his_acc_wo_na:  ['0.7691', '0.6877', '0.5637', '0.5668']
cur_acc des_wo_na:  ['0.7412', '0.5591', '0.4322', '0.5417']
his_acc des_wo_na:  ['0.7412', '0.6502', '0.5435', '0.5273']
cur_acc rrf_wo_na:  ['0.7602', '0.5683', '0.4606', '0.5666']
his_acc rrf_wo_na:  ['0.7602', '0.6713', '0.5574', '0.5349']
cur_acc_w_na:  ['0.6414', '0.4069', '0.3056', '0.4932']
his_acc_w_na:  ['0.6414', '0.5498', '0.4128', '0.4123']
cur_acc des_w_na:  ['0.6035', '0.4014', '0.2965', '0.3912']
his_acc des_w_na:  ['0.6035', '0.4856', '0.3684', '0.3625']
cur_acc rrf_w_na:  ['0.6225', '0.4138', '0.3184', '0.4140']
his_acc rrf_w_na:  ['0.6225', '0.5066', '0.3831', '0.3714']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 76.4583250CurrentTrain: epoch  0, batch     1 | loss: 115.7849081CurrentTrain: epoch  0, batch     2 | loss: 93.6944738CurrentTrain: epoch  0, batch     3 | loss: 78.7083450CurrentTrain: epoch  1, batch     0 | loss: 90.9604068CurrentTrain: epoch  1, batch     1 | loss: 73.9763865CurrentTrain: epoch  1, batch     2 | loss: 134.6124673CurrentTrain: epoch  1, batch     3 | loss: 55.4482380CurrentTrain: epoch  2, batch     0 | loss: 100.2970284CurrentTrain: epoch  2, batch     1 | loss: 79.6896415CurrentTrain: epoch  2, batch     2 | loss: 71.4826926CurrentTrain: epoch  2, batch     3 | loss: 73.1958190CurrentTrain: epoch  3, batch     0 | loss: 84.0007896CurrentTrain: epoch  3, batch     1 | loss: 79.6805912CurrentTrain: epoch  3, batch     2 | loss: 82.4355728CurrentTrain: epoch  3, batch     3 | loss: 85.4717090CurrentTrain: epoch  4, batch     0 | loss: 80.7778599CurrentTrain: epoch  4, batch     1 | loss: 84.9701698CurrentTrain: epoch  4, batch     2 | loss: 68.4142076CurrentTrain: epoch  4, batch     3 | loss: 52.8818159CurrentTrain: epoch  5, batch     0 | loss: 80.0808044CurrentTrain: epoch  5, batch     1 | loss: 75.2175948CurrentTrain: epoch  5, batch     2 | loss: 80.5305719CurrentTrain: epoch  5, batch     3 | loss: 68.8951690CurrentTrain: epoch  6, batch     0 | loss: 72.9658420CurrentTrain: epoch  6, batch     1 | loss: 67.5876406CurrentTrain: epoch  6, batch     2 | loss: 100.1657354CurrentTrain: epoch  6, batch     3 | loss: 53.9492736CurrentTrain: epoch  7, batch     0 | loss: 76.3690642CurrentTrain: epoch  7, batch     1 | loss: 78.9507739CurrentTrain: epoch  7, batch     2 | loss: 94.5210453CurrentTrain: epoch  7, batch     3 | loss: 63.2933968CurrentTrain: epoch  8, batch     0 | loss: 95.6891013CurrentTrain: epoch  8, batch     1 | loss: 64.1320490CurrentTrain: epoch  8, batch     2 | loss: 74.5358447CurrentTrain: epoch  8, batch     3 | loss: 64.3424247CurrentTrain: epoch  9, batch     0 | loss: 77.2508690CurrentTrain: epoch  9, batch     1 | loss: 77.1602859CurrentTrain: epoch  9, batch     2 | loss: 79.7478241CurrentTrain: epoch  9, batch     3 | loss: 46.3875139
MemoryTrain:  epoch  0, batch     0 | loss: 1.0490634MemoryTrain:  epoch  1, batch     0 | loss: 0.9676529MemoryTrain:  epoch  2, batch     0 | loss: 0.8184535MemoryTrain:  epoch  3, batch     0 | loss: 0.6920364MemoryTrain:  epoch  4, batch     0 | loss: 0.5807405MemoryTrain:  epoch  5, batch     0 | loss: 0.4980000MemoryTrain:  epoch  6, batch     0 | loss: 0.4358854MemoryTrain:  epoch  7, batch     0 | loss: 0.3495835MemoryTrain:  epoch  8, batch     0 | loss: 0.3135103MemoryTrain:  epoch  9, batch     0 | loss: 0.2704245

F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.7777777777777778), 17: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.42424242424242425), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.410958904109589), 37: np.float64(0.6019417475728155), 38: np.float64(0.6521739130434783), 39: np.float64(0.0)}
Micro-average F1 score: 0.39518072289156625
Weighted-average F1 score: 0.2748847552917794
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.7058823529411765), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5714285714285714), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.76), 37: np.float64(0.603448275862069), 38: np.float64(0.7586206896551724), 39: np.float64(0.0)}
Micro-average F1 score: 0.45640074211502785
Weighted-average F1 score: 0.3343746002787975
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.631578947368421), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5789473684210527), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6590909090909091), 37: np.float64(0.625), 38: np.float64(0.7407407407407407), 39: np.float64(0.0)}
Micro-average F1 score: 0.45714285714285713
Weighted-average F1 score: 0.33122688672679573

F1 score per class: {0: np.float64(0.8333333333333334), 2: np.float64(0.4), 4: np.float64(0.8304093567251462), 5: np.float64(0.7966101694915254), 6: np.float64(0.4642857142857143), 10: np.float64(0.11320754716981132), 11: np.float64(0.15757575757575756), 12: np.float64(0.21794871794871795), 13: np.float64(0.0392156862745098), 15: np.float64(0.25), 16: np.float64(0.3783783783783784), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.7272727272727273), 21: np.float64(0.27419354838709675), 23: np.float64(0.7560975609756098), 24: np.float64(0.24), 25: np.float64(0.42424242424242425), 26: np.float64(0.7142857142857143), 28: np.float64(0.21428571428571427), 29: np.float64(0.8484848484848485), 32: np.float64(0.6548042704626335), 35: np.float64(0.27522935779816515), 37: np.float64(0.17222222222222222), 38: np.float64(0.32967032967032966), 39: np.float64(0.08333333333333333)}
Micro-average F1 score: 0.47339108910891087
Weighted-average F1 score: 0.4582996217938661
F1 score per class: {0: np.float64(0.5811965811965812), 2: np.float64(0.2641509433962264), 4: np.float64(0.8210526315789474), 5: np.float64(0.5663716814159292), 6: np.float64(0.4626334519572954), 10: np.float64(0.2804878048780488), 11: np.float64(0.29333333333333333), 12: np.float64(0.30943396226415093), 13: np.float64(0.04040404040404041), 15: np.float64(0.35294117647058826), 16: np.float64(0.45454545454545453), 17: np.float64(0.0), 18: np.float64(0.2376237623762376), 19: np.float64(0.6992481203007519), 21: np.float64(0.16806722689075632), 23: np.float64(0.7021276595744681), 24: np.float64(0.3333333333333333), 25: np.float64(0.5641025641025641), 26: np.float64(0.6926829268292682), 28: np.float64(0.1509433962264151), 29: np.float64(0.8374384236453202), 32: np.float64(0.657439446366782), 35: np.float64(0.41304347826086957), 37: np.float64(0.1728395061728395), 38: np.float64(0.3142857142857143), 39: np.float64(0.1875)}
Micro-average F1 score: 0.45374449339207046
Weighted-average F1 score: 0.425284601296657
F1 score per class: {0: np.float64(0.7058823529411765), 2: np.float64(0.30434782608695654), 4: np.float64(0.8524590163934426), 5: np.float64(0.6859205776173285), 6: np.float64(0.4961832061068702), 10: np.float64(0.21875), 11: np.float64(0.26143790849673204), 12: np.float64(0.3170731707317073), 13: np.float64(0.034482758620689655), 15: np.float64(0.3157894736842105), 16: np.float64(0.425531914893617), 17: np.float64(0.0), 18: np.float64(0.034482758620689655), 19: np.float64(0.696969696969697), 21: np.float64(0.19387755102040816), 23: np.float64(0.7032967032967034), 24: np.float64(0.3333333333333333), 25: np.float64(0.5789473684210527), 26: np.float64(0.717948717948718), 28: np.float64(0.14814814814814814), 29: np.float64(0.835820895522388), 32: np.float64(0.6438356164383562), 35: np.float64(0.3741935483870968), 37: np.float64(0.17114914425427874), 38: np.float64(0.29850746268656714), 39: np.float64(0.15789473684210525)}
Micro-average F1 score: 0.4630021141649049
Weighted-average F1 score: 0.434038858028273

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.6086956521739131), 17: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.3888888888888889), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.35294117647058826), 37: np.float64(0.46616541353383456), 38: np.float64(0.5084745762711864), 39: np.float64(0.0)}
Micro-average F1 score: 0.296028880866426
Weighted-average F1 score: 0.21950030682270635
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.6), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.4888888888888889), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.59375), 37: np.float64(0.5035971223021583), 38: np.float64(0.5432098765432098), 39: np.float64(0.0)}
Micro-average F1 score: 0.3153846153846154
Weighted-average F1 score: 0.23984598254997996
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.5217391304347826), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5057471264367817), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.5178571428571429), 37: np.float64(0.5035971223021583), 38: np.float64(0.5555555555555556), 39: np.float64(0.0)}
Micro-average F1 score: 0.3177304964539007
Weighted-average F1 score: 0.23869377170940514

F1 score per class: {0: np.float64(0.7142857142857143), 2: np.float64(0.25925925925925924), 4: np.float64(0.7845303867403315), 5: np.float64(0.6596491228070176), 6: np.float64(0.2810810810810811), 10: np.float64(0.11214953271028037), 11: np.float64(0.1306532663316583), 12: np.float64(0.13709677419354838), 13: np.float64(0.021621621621621623), 15: np.float64(0.15384615384615385), 16: np.float64(0.28), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.6470588235294118), 21: np.float64(0.17346938775510204), 23: np.float64(0.6813186813186813), 24: np.float64(0.15789473684210525), 25: np.float64(0.3835616438356164), 26: np.float64(0.6310679611650486), 28: np.float64(0.14634146341463414), 29: np.float64(0.702928870292887), 32: np.float64(0.4946236559139785), 35: np.float64(0.17543859649122806), 37: np.float64(0.09904153354632587), 38: np.float64(0.20689655172413793), 39: np.float64(0.05405405405405406)}
Micro-average F1 score: 0.345372460496614
Weighted-average F1 score: 0.3177163301668235
F1 score per class: {0: np.float64(0.4657534246575342), 2: np.float64(0.15730337078651685), 4: np.float64(0.7464114832535885), 5: np.float64(0.38247011952191234), 6: np.float64(0.26), 10: np.float64(0.2072072072072072), 11: np.float64(0.2430939226519337), 12: np.float64(0.1659919028340081), 13: np.float64(0.025), 15: np.float64(0.20689655172413793), 16: np.float64(0.297029702970297), 17: np.float64(0.0), 18: np.float64(0.14634146341463414), 19: np.float64(0.6), 21: np.float64(0.1078167115902965), 23: np.float64(0.5739130434782609), 24: np.float64(0.18867924528301888), 25: np.float64(0.4444444444444444), 26: np.float64(0.5819672131147541), 28: np.float64(0.07142857142857142), 29: np.float64(0.6746031746031746), 32: np.float64(0.48346055979643765), 35: np.float64(0.2508250825082508), 37: np.float64(0.10903426791277258), 38: np.float64(0.17054263565891473), 39: np.float64(0.11538461538461539)}
Micro-average F1 score: 0.30690283065717594
Weighted-average F1 score: 0.2830711439276079
F1 score per class: {0: np.float64(0.5825242718446602), 2: np.float64(0.2), 4: np.float64(0.8041237113402062), 5: np.float64(0.47029702970297027), 6: np.float64(0.2838427947598253), 10: np.float64(0.18791946308724833), 11: np.float64(0.2094240837696335), 12: np.float64(0.1652542372881356), 13: np.float64(0.021164021164021163), 15: np.float64(0.1875), 16: np.float64(0.3076923076923077), 17: np.float64(0.0), 18: np.float64(0.023809523809523808), 19: np.float64(0.5974025974025974), 21: np.float64(0.11838006230529595), 23: np.float64(0.6037735849056604), 24: np.float64(0.2), 25: np.float64(0.4731182795698925), 26: np.float64(0.611353711790393), 28: np.float64(0.07207207207207207), 29: np.float64(0.6746987951807228), 32: np.float64(0.47837150127226463), 35: np.float64(0.23577235772357724), 37: np.float64(0.10401188707280833), 38: np.float64(0.15810276679841898), 39: np.float64(0.1)}
Micro-average F1 score: 0.31596032461677187
Weighted-average F1 score: 0.2884652172695631
cur_acc_wo_na:  ['0.7691', '0.5210', '0.4337', '0.6495', '0.3952']
his_acc_wo_na:  ['0.7691', '0.6877', '0.5637', '0.5668', '0.4734']
cur_acc des_wo_na:  ['0.7412', '0.5591', '0.4322', '0.5417', '0.4564']
his_acc des_wo_na:  ['0.7412', '0.6502', '0.5435', '0.5273', '0.4537']
cur_acc rrf_wo_na:  ['0.7602', '0.5683', '0.4606', '0.5666', '0.4571']
his_acc rrf_wo_na:  ['0.7602', '0.6713', '0.5574', '0.5349', '0.4630']
cur_acc_w_na:  ['0.6414', '0.4069', '0.3056', '0.4932', '0.2960']
his_acc_w_na:  ['0.6414', '0.5498', '0.4128', '0.4123', '0.3454']
cur_acc des_w_na:  ['0.6035', '0.4014', '0.2965', '0.3912', '0.3154']
his_acc des_w_na:  ['0.6035', '0.4856', '0.3684', '0.3625', '0.3069']
cur_acc rrf_w_na:  ['0.6225', '0.4138', '0.3184', '0.4140', '0.3177']
his_acc rrf_w_na:  ['0.6225', '0.5066', '0.3831', '0.3714', '0.3160']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 97.2973802CurrentTrain: epoch  0, batch     1 | loss: 99.0455380CurrentTrain: epoch  0, batch     2 | loss: 77.7189520CurrentTrain: epoch  0, batch     3 | loss: 58.9246922CurrentTrain: epoch  1, batch     0 | loss: 74.4368863CurrentTrain: epoch  1, batch     1 | loss: 75.1575089CurrentTrain: epoch  1, batch     2 | loss: 84.3101949CurrentTrain: epoch  1, batch     3 | loss: 53.7990923CurrentTrain: epoch  2, batch     0 | loss: 70.9718566CurrentTrain: epoch  2, batch     1 | loss: 104.0982945CurrentTrain: epoch  2, batch     2 | loss: 85.7554755CurrentTrain: epoch  2, batch     3 | loss: 50.4188851CurrentTrain: epoch  3, batch     0 | loss: 69.4186436CurrentTrain: epoch  3, batch     1 | loss: 101.6638148CurrentTrain: epoch  3, batch     2 | loss: 81.9107902CurrentTrain: epoch  3, batch     3 | loss: 48.6546758CurrentTrain: epoch  4, batch     0 | loss: 68.3087992CurrentTrain: epoch  4, batch     1 | loss: 80.9386558CurrentTrain: epoch  4, batch     2 | loss: 66.9909191CurrentTrain: epoch  4, batch     3 | loss: 105.9198112CurrentTrain: epoch  5, batch     0 | loss: 92.1220557CurrentTrain: epoch  5, batch     1 | loss: 79.1848414CurrentTrain: epoch  5, batch     2 | loss: 99.0742319CurrentTrain: epoch  5, batch     3 | loss: 47.1555296CurrentTrain: epoch  6, batch     0 | loss: 79.8347130CurrentTrain: epoch  6, batch     1 | loss: 95.2114658CurrentTrain: epoch  6, batch     2 | loss: 67.2175403CurrentTrain: epoch  6, batch     3 | loss: 52.0021372CurrentTrain: epoch  7, batch     0 | loss: 77.6085808CurrentTrain: epoch  7, batch     1 | loss: 80.9785427CurrentTrain: epoch  7, batch     2 | loss: 60.6717763CurrentTrain: epoch  7, batch     3 | loss: 58.6930024CurrentTrain: epoch  8, batch     0 | loss: 92.4994382CurrentTrain: epoch  8, batch     1 | loss: 91.9139313CurrentTrain: epoch  8, batch     2 | loss: 88.6828086CurrentTrain: epoch  8, batch     3 | loss: 46.8931858CurrentTrain: epoch  9, batch     0 | loss: 75.0736195CurrentTrain: epoch  9, batch     1 | loss: 98.0649020CurrentTrain: epoch  9, batch     2 | loss: 91.5066617CurrentTrain: epoch  9, batch     3 | loss: 35.1069803
MemoryTrain:  epoch  0, batch     0 | loss: 0.8372809MemoryTrain:  epoch  1, batch     0 | loss: 0.8330865MemoryTrain:  epoch  2, batch     0 | loss: 0.6592912MemoryTrain:  epoch  3, batch     0 | loss: 0.4943814MemoryTrain:  epoch  4, batch     0 | loss: 0.4647941MemoryTrain:  epoch  5, batch     0 | loss: 0.3786154MemoryTrain:  epoch  6, batch     0 | loss: 0.3649441MemoryTrain:  epoch  7, batch     0 | loss: 0.3018604MemoryTrain:  epoch  8, batch     0 | loss: 0.2651986MemoryTrain:  epoch  9, batch     0 | loss: 0.2341557

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.46956521739130436), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.8672566371681416), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8947368421052632), 32: np.float64(0.0), 33: np.float64(0.35294117647058826), 35: np.float64(0.0), 36: np.float64(0.6017699115044248), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.52
Weighted-average F1 score: 0.42577766499537617
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.6933333333333334), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.7636363636363637), 21: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8095238095238095), 32: np.float64(0.0), 33: np.float64(0.3333333333333333), 35: np.float64(0.0), 36: np.float64(0.723404255319149), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.515625
Weighted-average F1 score: 0.40540669062335816
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.6666666666666666), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.75), 21: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.85), 32: np.float64(0.0), 33: np.float64(0.3333333333333333), 35: np.float64(0.0), 36: np.float64(0.6771653543307087), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.512396694214876
Weighted-average F1 score: 0.4037177003944025

F1 score per class: {0: np.float64(0.7654320987654321), 2: np.float64(0.3888888888888889), 4: np.float64(0.8439306358381503), 5: np.float64(0.7966101694915254), 6: np.float64(0.48412698412698413), 8: np.float64(0.3103448275862069), 10: np.float64(0.14678899082568808), 11: np.float64(0.18181818181818182), 12: np.float64(0.21301775147928995), 13: np.float64(0.05970149253731343), 15: np.float64(0.3333333333333333), 16: np.float64(0.18181818181818182), 17: np.float64(0.0), 18: np.float64(0.044444444444444446), 19: np.float64(0.7619047619047619), 20: np.float64(0.41702127659574467), 21: np.float64(0.23880597014925373), 23: np.float64(0.7126436781609196), 24: np.float64(0.16), 25: np.float64(0.3225806451612903), 26: np.float64(0.6984126984126984), 28: np.float64(0.14285714285714285), 29: np.float64(0.8316831683168316), 30: np.float64(0.8717948717948718), 32: np.float64(0.6190476190476191), 33: np.float64(0.13953488372093023), 35: np.float64(0.34285714285714286), 36: np.float64(0.2982456140350877), 37: np.float64(0.3103448275862069), 38: np.float64(0.48484848484848486), 39: np.float64(0.17647058823529413)}
Micro-average F1 score: 0.4855112083105522
Weighted-average F1 score: 0.4910228743266131
F1 score per class: {0: np.float64(0.544), 2: np.float64(0.20588235294117646), 4: np.float64(0.8306010928961749), 5: np.float64(0.5380434782608695), 6: np.float64(0.48398576512455516), 8: np.float64(0.32), 10: np.float64(0.32432432432432434), 11: np.float64(0.24675324675324675), 12: np.float64(0.26548672566371684), 13: np.float64(0.0975609756097561), 15: np.float64(0.3333333333333333), 16: np.float64(0.5263157894736842), 17: np.float64(0.0), 18: np.float64(0.2), 19: np.float64(0.7072243346007605), 20: np.float64(0.4117647058823529), 21: np.float64(0.19801980198019803), 23: np.float64(0.7083333333333334), 24: np.float64(0.358974358974359), 25: np.float64(0.4155844155844156), 26: np.float64(0.6732673267326733), 28: np.float64(0.14285714285714285), 29: np.float64(0.8356807511737089), 30: np.float64(0.5151515151515151), 32: np.float64(0.6245847176079734), 33: np.float64(0.12), 35: np.float64(0.3786407766990291), 36: np.float64(0.3072289156626506), 37: np.float64(0.24161073825503357), 38: np.float64(0.23404255319148937), 39: np.float64(0.14492753623188406)}
Micro-average F1 score: 0.44203502919099247
Weighted-average F1 score: 0.424911996675029
F1 score per class: {0: np.float64(0.6804123711340206), 2: np.float64(0.24561403508771928), 4: np.float64(0.8603351955307262), 5: np.float64(0.6903914590747331), 6: np.float64(0.4859154929577465), 8: np.float64(0.32786885245901637), 10: np.float64(0.2937062937062937), 11: np.float64(0.26666666666666666), 12: np.float64(0.26785714285714285), 13: np.float64(0.07272727272727272), 15: np.float64(0.2608695652173913), 16: np.float64(0.46153846153846156), 17: np.float64(0.0), 18: np.float64(0.15384615384615385), 19: np.float64(0.7121212121212122), 20: np.float64(0.39069767441860465), 21: np.float64(0.225), 23: np.float64(0.7272727272727273), 24: np.float64(0.25806451612903225), 25: np.float64(0.37142857142857144), 26: np.float64(0.6802030456852792), 28: np.float64(0.13636363636363635), 29: np.float64(0.839622641509434), 30: np.float64(0.6938775510204082), 32: np.float64(0.618421052631579), 33: np.float64(0.12), 35: np.float64(0.36024844720496896), 36: np.float64(0.2895622895622896), 37: np.float64(0.24516129032258063), 38: np.float64(0.2923076923076923), 39: np.float64(0.15384615384615385)}
Micro-average F1 score: 0.45863309352517984
Weighted-average F1 score: 0.44228587209234976

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.4251968503937008), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5697674418604651), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.85), 32: np.float64(0.0), 33: np.float64(0.35294117647058826), 35: np.float64(0.0), 36: np.float64(0.4689655172413793), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.3523035230352303
Weighted-average F1 score: 0.28364405557896966
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.5683060109289617), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5283018867924528), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7083333333333334), 32: np.float64(0.0), 33: np.float64(0.3), 35: np.float64(0.0), 36: np.float64(0.5573770491803278), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.33
Weighted-average F1 score: 0.26254056261212827
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.5681818181818182), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5121951219512195), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7555555555555555), 32: np.float64(0.0), 33: np.float64(0.3333333333333333), 35: np.float64(0.0), 36: np.float64(0.5149700598802395), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.33769063180827885
Weighted-average F1 score: 0.26828018918135205

F1 score per class: {0: np.float64(0.5794392523364486), 2: np.float64(0.23728813559322035), 4: np.float64(0.7978142076502732), 5: np.float64(0.6550522648083623), 6: np.float64(0.291866028708134), 8: np.float64(0.20074349442379183), 10: np.float64(0.1391304347826087), 11: np.float64(0.14345991561181434), 12: np.float64(0.1232876712328767), 13: np.float64(0.03076923076923077), 15: np.float64(0.20689655172413793), 16: np.float64(0.16666666666666666), 17: np.float64(0.0), 18: np.float64(0.03333333333333333), 19: np.float64(0.6743295019157088), 20: np.float64(0.1952191235059761), 21: np.float64(0.2), 23: np.float64(0.6526315789473685), 24: np.float64(0.11428571428571428), 25: np.float64(0.30303030303030304), 26: np.float64(0.6139534883720931), 28: np.float64(0.09090909090909091), 29: np.float64(0.6857142857142857), 30: np.float64(0.8095238095238095), 32: np.float64(0.4595959595959596), 33: np.float64(0.10526315789473684), 35: np.float64(0.23076923076923078), 36: np.float64(0.20987654320987653), 37: np.float64(0.21686746987951808), 38: np.float64(0.27350427350427353), 39: np.float64(0.125)}
Micro-average F1 score: 0.3476218438050499
Weighted-average F1 score: 0.3311475969009832
F1 score per class: {0: np.float64(0.40236686390532544), 2: np.float64(0.14), 4: np.float64(0.7715736040609137), 5: np.float64(0.33277310924369746), 6: np.float64(0.2809917355371901), 8: np.float64(0.18024263431542462), 10: np.float64(0.2376237623762376), 11: np.float64(0.20212765957446807), 12: np.float64(0.15), 13: np.float64(0.06060606060606061), 15: np.float64(0.1935483870967742), 16: np.float64(0.37037037037037035), 17: np.float64(0.0), 18: np.float64(0.14432989690721648), 19: np.float64(0.6220735785953178), 20: np.float64(0.2048780487804878), 21: np.float64(0.12903225806451613), 23: np.float64(0.5666666666666667), 24: np.float64(0.21875), 25: np.float64(0.3902439024390244), 26: np.float64(0.5690376569037657), 28: np.float64(0.08108108108108109), 29: np.float64(0.6742424242424242), 30: np.float64(0.3953488372093023), 32: np.float64(0.4519230769230769), 33: np.float64(0.08823529411764706), 35: np.float64(0.22478386167146974), 36: np.float64(0.20773930753564154), 37: np.float64(0.13846153846153847), 38: np.float64(0.1345565749235474), 39: np.float64(0.07575757575757576)}
Micro-average F1 score: 0.2931821324851335
Weighted-average F1 score: 0.27495209539354626
F1 score per class: {0: np.float64(0.5196850393700787), 2: np.float64(0.1686746987951807), 4: np.float64(0.806282722513089), 5: np.float64(0.49363867684478374), 6: np.float64(0.2839506172839506), 8: np.float64(0.19083969465648856), 10: np.float64(0.22826086956521738), 11: np.float64(0.1991701244813278), 12: np.float64(0.14925373134328357), 13: np.float64(0.043010752688172046), 15: np.float64(0.1518987341772152), 16: np.float64(0.32142857142857145), 17: np.float64(0.0), 18: np.float64(0.11428571428571428), 19: np.float64(0.6287625418060201), 20: np.float64(0.18876404494382024), 21: np.float64(0.13636363636363635), 23: np.float64(0.6213592233009708), 24: np.float64(0.17391304347826086), 25: np.float64(0.35135135135135137), 26: np.float64(0.5726495726495726), 28: np.float64(0.0821917808219178), 29: np.float64(0.6793893129770993), 30: np.float64(0.576271186440678), 32: np.float64(0.44028103044496486), 33: np.float64(0.08823529411764706), 35: np.float64(0.2283464566929134), 36: np.float64(0.19861431870669746), 37: np.float64(0.15637860082304528), 38: np.float64(0.16170212765957448), 39: np.float64(0.08620689655172414)}
Micro-average F1 score: 0.3097479501973884
Weighted-average F1 score: 0.28956357175068415
cur_acc_wo_na:  ['0.7691', '0.5210', '0.4337', '0.6495', '0.3952', '0.5200']
his_acc_wo_na:  ['0.7691', '0.6877', '0.5637', '0.5668', '0.4734', '0.4855']
cur_acc des_wo_na:  ['0.7412', '0.5591', '0.4322', '0.5417', '0.4564', '0.5156']
his_acc des_wo_na:  ['0.7412', '0.6502', '0.5435', '0.5273', '0.4537', '0.4420']
cur_acc rrf_wo_na:  ['0.7602', '0.5683', '0.4606', '0.5666', '0.4571', '0.5124']
his_acc rrf_wo_na:  ['0.7602', '0.6713', '0.5574', '0.5349', '0.4630', '0.4586']
cur_acc_w_na:  ['0.6414', '0.4069', '0.3056', '0.4932', '0.2960', '0.3523']
his_acc_w_na:  ['0.6414', '0.5498', '0.4128', '0.4123', '0.3454', '0.3476']
cur_acc des_w_na:  ['0.6035', '0.4014', '0.2965', '0.3912', '0.3154', '0.3300']
his_acc des_w_na:  ['0.6035', '0.4856', '0.3684', '0.3625', '0.3069', '0.2932']
cur_acc rrf_w_na:  ['0.6225', '0.4138', '0.3184', '0.4140', '0.3177', '0.3377']
his_acc rrf_w_na:  ['0.6225', '0.5066', '0.3831', '0.3714', '0.3160', '0.3097']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 106.2850541CurrentTrain: epoch  0, batch     1 | loss: 84.2261683CurrentTrain: epoch  0, batch     2 | loss: 92.9365156CurrentTrain: epoch  0, batch     3 | loss: 13.1333279CurrentTrain: epoch  1, batch     0 | loss: 72.5906891CurrentTrain: epoch  1, batch     1 | loss: 75.8194305CurrentTrain: epoch  1, batch     2 | loss: 111.6089150CurrentTrain: epoch  1, batch     3 | loss: 23.9960625CurrentTrain: epoch  2, batch     0 | loss: 71.8937607CurrentTrain: epoch  2, batch     1 | loss: 82.2803722CurrentTrain: epoch  2, batch     2 | loss: 71.1783373CurrentTrain: epoch  2, batch     3 | loss: 20.5414155CurrentTrain: epoch  3, batch     0 | loss: 82.8762831CurrentTrain: epoch  3, batch     1 | loss: 79.8590535CurrentTrain: epoch  3, batch     2 | loss: 95.6334271CurrentTrain: epoch  3, batch     3 | loss: 22.0757894CurrentTrain: epoch  4, batch     0 | loss: 78.3842712CurrentTrain: epoch  4, batch     1 | loss: 71.2848834CurrentTrain: epoch  4, batch     2 | loss: 67.0534983CurrentTrain: epoch  4, batch     3 | loss: 5.4541167CurrentTrain: epoch  5, batch     0 | loss: 66.5714674CurrentTrain: epoch  5, batch     1 | loss: 75.8743123CurrentTrain: epoch  5, batch     2 | loss: 78.2066164CurrentTrain: epoch  5, batch     3 | loss: 19.2887913CurrentTrain: epoch  6, batch     0 | loss: 69.7219499CurrentTrain: epoch  6, batch     1 | loss: 63.1131080CurrentTrain: epoch  6, batch     2 | loss: 79.8653214CurrentTrain: epoch  6, batch     3 | loss: 4.1148581CurrentTrain: epoch  7, batch     0 | loss: 76.7977444CurrentTrain: epoch  7, batch     1 | loss: 81.2295252CurrentTrain: epoch  7, batch     2 | loss: 61.1973154CurrentTrain: epoch  7, batch     3 | loss: 17.6344841CurrentTrain: epoch  8, batch     0 | loss: 60.7985435CurrentTrain: epoch  8, batch     1 | loss: 93.9890954CurrentTrain: epoch  8, batch     2 | loss: 76.3433441CurrentTrain: epoch  8, batch     3 | loss: 5.3993638CurrentTrain: epoch  9, batch     0 | loss: 62.3350861CurrentTrain: epoch  9, batch     1 | loss: 66.3895657CurrentTrain: epoch  9, batch     2 | loss: 62.0451462CurrentTrain: epoch  9, batch     3 | loss: 6.0363681
MemoryTrain:  epoch  0, batch     0 | loss: 0.8003816MemoryTrain:  epoch  1, batch     0 | loss: 0.6267757MemoryTrain:  epoch  2, batch     0 | loss: 0.5393939MemoryTrain:  epoch  3, batch     0 | loss: 0.4314789MemoryTrain:  epoch  4, batch     0 | loss: 0.3534298MemoryTrain:  epoch  5, batch     0 | loss: 0.3367899MemoryTrain:  epoch  6, batch     0 | loss: 0.2658268MemoryTrain:  epoch  7, batch     0 | loss: 0.2197266MemoryTrain:  epoch  8, batch     0 | loss: 0.1803017MemoryTrain:  epoch  9, batch     0 | loss: 0.1718164

F1 score per class: {0: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6666666666666666), 37: np.float64(0.0), 6: np.float64(0.9433962264150944), 7: np.float64(0.0), 40: np.float64(0.0), 9: np.float64(0.0), 8: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.5517241379310345), 19: np.float64(0.6666666666666666), 21: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.20437956204379562)}
Micro-average F1 score: 0.3227848101265823
Weighted-average F1 score: 0.2561129080913828
F1 score per class: {0: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.75), 8: np.float64(0.0), 9: np.float64(0.6410256410256411), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.5384615384615384), 31: np.float64(0.6666666666666666), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.3252032520325203)}
Micro-average F1 score: 0.3227665706051873
Weighted-average F1 score: 0.26238703374158207
F1 score per class: {0: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.75), 8: np.float64(0.0), 9: np.float64(0.8620689655172413), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.6428571428571429), 30: np.float64(0.0), 31: np.float64(0.6666666666666666), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.31007751937984496)}
Micro-average F1 score: 0.3504531722054381
Weighted-average F1 score: 0.2721680156140372

F1 score per class: {0: np.float64(0.6521739130434783), 2: np.float64(0.375), 4: np.float64(0.7804878048780488), 5: np.float64(0.8), 6: np.float64(0.38323353293413176), 7: np.float64(0.04477611940298507), 8: np.float64(0.2803738317757009), 9: np.float64(0.9433962264150944), 10: np.float64(0.07692307692307693), 11: np.float64(0.2131979695431472), 12: np.float64(0.30120481927710846), 13: np.float64(0.05194805194805195), 15: np.float64(0.41025641025641024), 16: np.float64(0.3684210526315789), 17: np.float64(0.0), 18: np.float64(0.06896551724137931), 19: np.float64(0.5984848484848485), 20: np.float64(0.4072398190045249), 21: np.float64(0.03773584905660377), 23: np.float64(0.7058823529411765), 24: np.float64(0.09523809523809523), 25: np.float64(0.3125), 26: np.float64(0.5548387096774193), 27: np.float64(0.3076923076923077), 28: np.float64(0.11428571428571428), 29: np.float64(0.8275862068965517), 30: np.float64(0.8571428571428571), 31: np.float64(0.4), 32: np.float64(0.6717557251908397), 33: np.float64(0.1875), 35: np.float64(0.3333333333333333), 36: np.float64(0.4129032258064516), 37: np.float64(0.3697478991596639), 38: np.float64(0.32653061224489793), 39: np.float64(0.09523809523809523), 40: np.float64(0.08259587020648967)}
Micro-average F1 score: 0.4271203656678517
Weighted-average F1 score: 0.4122090477915759
F1 score per class: {0: np.float64(0.5483870967741935), 2: np.float64(0.2153846153846154), 4: np.float64(0.797752808988764), 5: np.float64(0.5414364640883977), 6: np.float64(0.411214953271028), 7: np.float64(0.06382978723404255), 8: np.float64(0.3459915611814346), 9: np.float64(0.5102040816326531), 10: np.float64(0.20869565217391303), 11: np.float64(0.3023255813953488), 12: np.float64(0.21468926553672316), 13: np.float64(0.029850746268656716), 15: np.float64(0.3076923076923077), 16: np.float64(0.45614035087719296), 17: np.float64(0.0), 18: np.float64(0.12643678160919541), 19: np.float64(0.5347222222222222), 20: np.float64(0.40186915887850466), 21: np.float64(0.19718309859154928), 23: np.float64(0.6136363636363636), 24: np.float64(0.25), 25: np.float64(0.44155844155844154), 26: np.float64(0.6532663316582915), 27: np.float64(0.30434782608695654), 28: np.float64(0.14814814814814814), 29: np.float64(0.8181818181818182), 30: np.float64(0.7619047619047619), 31: np.float64(0.11764705882352941), 32: np.float64(0.6743295019157088), 33: np.float64(0.1276595744680851), 35: np.float64(0.4720496894409938), 36: np.float64(0.5076142131979695), 37: np.float64(0.25675675675675674), 38: np.float64(0.32142857142857145), 39: np.float64(0.20689655172413793), 40: np.float64(0.15151515151515152)}
Micro-average F1 score: 0.4191666666666667
Weighted-average F1 score: 0.4018484865792189
F1 score per class: {0: np.float64(0.5862068965517241), 2: np.float64(0.30434782608695654), 4: np.float64(0.8390804597701149), 5: np.float64(0.6736842105263158), 6: np.float64(0.40375586854460094), 7: np.float64(0.061855670103092786), 8: np.float64(0.3803680981595092), 9: np.float64(0.8333333333333334), 10: np.float64(0.21052631578947367), 11: np.float64(0.2885572139303483), 12: np.float64(0.19101123595505617), 13: np.float64(0.05970149253731343), 15: np.float64(0.27906976744186046), 16: np.float64(0.41025641025641024), 17: np.float64(0.0), 18: np.float64(0.1839080459770115), 19: np.float64(0.56), 20: np.float64(0.39461883408071746), 21: np.float64(0.1782178217821782), 23: np.float64(0.5853658536585366), 24: np.float64(0.15384615384615385), 25: np.float64(0.4444444444444444), 26: np.float64(0.6564102564102564), 27: np.float64(0.33962264150943394), 28: np.float64(0.12121212121212122), 29: np.float64(0.8241206030150754), 30: np.float64(0.8205128205128205), 31: np.float64(0.2), 32: np.float64(0.6446886446886447), 33: np.float64(0.11538461538461539), 35: np.float64(0.3937007874015748), 36: np.float64(0.3827751196172249), 37: np.float64(0.23225806451612904), 38: np.float64(0.3855421686746988), 39: np.float64(0.20689655172413793), 40: np.float64(0.1388888888888889)}
Micro-average F1 score: 0.429117052347787
Weighted-average F1 score: 0.41151913659508904

F1 score per class: {0: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5454545454545454), 8: np.float64(0.0), 9: np.float64(0.8928571428571429), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.5), 31: np.float64(0.6666666666666666), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.15819209039548024)}
Micro-average F1 score: 0.255
Weighted-average F1 score: 0.20093722404970482
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5454545454545454), 8: np.float64(0.0), 9: np.float64(0.5681818181818182), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.5), 28: np.float64(0.0), 31: np.float64(0.6666666666666666), 32: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.25477707006369427)}
Micro-average F1 score: 0.24507658643326038
Weighted-average F1 score: 0.20216275773275644
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5454545454545454), 8: np.float64(0.0), 9: np.float64(0.7936507936507936), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.5806451612903226), 30: np.float64(0.0), 31: np.float64(0.6666666666666666), 32: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.24242424242424243)}
Micro-average F1 score: 0.2691415313225058
Weighted-average F1 score: 0.21221210638123228

F1 score per class: {0: np.float64(0.5042016806722689), 2: np.float64(0.23076923076923078), 4: np.float64(0.7441860465116279), 5: np.float64(0.6416382252559727), 6: np.float64(0.25098039215686274), 7: np.float64(0.027906976744186046), 8: np.float64(0.24), 9: np.float64(0.8928571428571429), 10: np.float64(0.07407407407407407), 11: np.float64(0.16279069767441862), 12: np.float64(0.16666666666666666), 13: np.float64(0.027777777777777776), 15: np.float64(0.2711864406779661), 16: np.float64(0.2857142857142857), 17: np.float64(0.0), 18: np.float64(0.04597701149425287), 19: np.float64(0.5467128027681661), 20: np.float64(0.18442622950819673), 21: np.float64(0.03389830508474576), 23: np.float64(0.6451612903225806), 24: np.float64(0.07142857142857142), 25: np.float64(0.29411764705882354), 26: np.float64(0.48863636363636365), 27: np.float64(0.21052631578947367), 28: np.float64(0.07692307692307693), 29: np.float64(0.6970954356846473), 30: np.float64(0.8108108108108109), 31: np.float64(0.2), 32: np.float64(0.4971751412429379), 33: np.float64(0.14634146341463414), 35: np.float64(0.24615384615384617), 36: np.float64(0.29767441860465116), 37: np.float64(0.27848101265822783), 38: np.float64(0.2077922077922078), 39: np.float64(0.08), 40: np.float64(0.05982905982905983)}
Micro-average F1 score: 0.3122911251392499
Weighted-average F1 score: 0.28880313988697204
F1 score per class: {0: np.float64(0.43312101910828027), 2: np.float64(0.15053763440860216), 4: np.float64(0.7513227513227513), 5: np.float64(0.3361921097770154), 6: np.float64(0.24376731301939059), 7: np.float64(0.0379746835443038), 8: np.float64(0.21866666666666668), 9: np.float64(0.42735042735042733), 10: np.float64(0.17142857142857143), 11: np.float64(0.23853211009174313), 12: np.float64(0.13013698630136986), 13: np.float64(0.018018018018018018), 15: np.float64(0.2), 16: np.float64(0.3058823529411765), 17: np.float64(0.0), 18: np.float64(0.08979591836734693), 19: np.float64(0.48427672955974843), 20: np.float64(0.19413092550790068), 21: np.float64(0.12844036697247707), 23: np.float64(0.5), 24: np.float64(0.17777777777777778), 25: np.float64(0.40476190476190477), 26: np.float64(0.5531914893617021), 27: np.float64(0.21212121212121213), 28: np.float64(0.08247422680412371), 29: np.float64(0.6666666666666666), 30: np.float64(0.6956521739130435), 31: np.float64(0.07142857142857142), 32: np.float64(0.5), 33: np.float64(0.08955223880597014), 35: np.float64(0.3064516129032258), 36: np.float64(0.35714285714285715), 37: np.float64(0.1532258064516129), 38: np.float64(0.17475728155339806), 39: np.float64(0.12), 40: np.float64(0.10869565217391304)}
Micro-average F1 score: 0.2894547547115523
Weighted-average F1 score: 0.27146076014493203
F1 score per class: {0: np.float64(0.46258503401360546), 2: np.float64(0.2), 4: np.float64(0.7891891891891892), 5: np.float64(0.4444444444444444), 6: np.float64(0.24022346368715083), 7: np.float64(0.03550295857988166), 8: np.float64(0.26956521739130435), 9: np.float64(0.746268656716418), 10: np.float64(0.17777777777777778), 11: np.float64(0.21804511278195488), 12: np.float64(0.11724137931034483), 13: np.float64(0.02962962962962963), 15: np.float64(0.1791044776119403), 16: np.float64(0.32), 17: np.float64(0.0), 18: np.float64(0.11347517730496454), 19: np.float64(0.5133333333333333), 20: np.float64(0.18763326226012794), 21: np.float64(0.1267605633802817), 23: np.float64(0.5217391304347826), 24: np.float64(0.1111111111111111), 25: np.float64(0.42105263157894735), 26: np.float64(0.5638766519823789), 27: np.float64(0.23376623376623376), 28: np.float64(0.07692307692307693), 29: np.float64(0.6748971193415638), 30: np.float64(0.7619047619047619), 31: np.float64(0.1111111111111111), 32: np.float64(0.47696476964769646), 33: np.float64(0.08108108108108109), 35: np.float64(0.26455026455026454), 36: np.float64(0.27586206896551724), 37: np.float64(0.15789473684210525), 38: np.float64(0.2064516129032258), 39: np.float64(0.1276595744680851), 40: np.float64(0.09925558312655088)}
Micro-average F1 score: 0.3014996053670087
Weighted-average F1 score: 0.28045120962022274
cur_acc_wo_na:  ['0.7691', '0.5210', '0.4337', '0.6495', '0.3952', '0.5200', '0.3228']
his_acc_wo_na:  ['0.7691', '0.6877', '0.5637', '0.5668', '0.4734', '0.4855', '0.4271']
cur_acc des_wo_na:  ['0.7412', '0.5591', '0.4322', '0.5417', '0.4564', '0.5156', '0.3228']
his_acc des_wo_na:  ['0.7412', '0.6502', '0.5435', '0.5273', '0.4537', '0.4420', '0.4192']
cur_acc rrf_wo_na:  ['0.7602', '0.5683', '0.4606', '0.5666', '0.4571', '0.5124', '0.3505']
his_acc rrf_wo_na:  ['0.7602', '0.6713', '0.5574', '0.5349', '0.4630', '0.4586', '0.4291']
cur_acc_w_na:  ['0.6414', '0.4069', '0.3056', '0.4932', '0.2960', '0.3523', '0.2550']
his_acc_w_na:  ['0.6414', '0.5498', '0.4128', '0.4123', '0.3454', '0.3476', '0.3123']
cur_acc des_w_na:  ['0.6035', '0.4014', '0.2965', '0.3912', '0.3154', '0.3300', '0.2451']
his_acc des_w_na:  ['0.6035', '0.4856', '0.3684', '0.3625', '0.3069', '0.2932', '0.2895']
cur_acc rrf_w_na:  ['0.6225', '0.4138', '0.3184', '0.4140', '0.3177', '0.3377', '0.2691']
his_acc rrf_w_na:  ['0.6225', '0.5066', '0.3831', '0.3714', '0.3160', '0.3097', '0.3015']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 103.0764018CurrentTrain: epoch  0, batch     1 | loss: 102.1696147CurrentTrain: epoch  0, batch     2 | loss: 87.5947770CurrentTrain: epoch  0, batch     3 | loss: 116.3153387CurrentTrain: epoch  0, batch     4 | loss: 63.9491720CurrentTrain: epoch  1, batch     0 | loss: 94.3964671CurrentTrain: epoch  1, batch     1 | loss: 88.8744243CurrentTrain: epoch  1, batch     2 | loss: 77.5736010CurrentTrain: epoch  1, batch     3 | loss: 136.8786563CurrentTrain: epoch  1, batch     4 | loss: 81.3633584CurrentTrain: epoch  2, batch     0 | loss: 89.3024179CurrentTrain: epoch  2, batch     1 | loss: 106.1753659CurrentTrain: epoch  2, batch     2 | loss: 74.6984433CurrentTrain: epoch  2, batch     3 | loss: 105.1827201CurrentTrain: epoch  2, batch     4 | loss: 49.6325808CurrentTrain: epoch  3, batch     0 | loss: 107.8019813CurrentTrain: epoch  3, batch     1 | loss: 86.6615942CurrentTrain: epoch  3, batch     2 | loss: 72.1874486CurrentTrain: epoch  3, batch     3 | loss: 69.0826753CurrentTrain: epoch  3, batch     4 | loss: 71.6344360CurrentTrain: epoch  4, batch     0 | loss: 68.9050262CurrentTrain: epoch  4, batch     1 | loss: 100.6358849CurrentTrain: epoch  4, batch     2 | loss: 104.7541457CurrentTrain: epoch  4, batch     3 | loss: 126.7636675CurrentTrain: epoch  4, batch     4 | loss: 39.8318338CurrentTrain: epoch  5, batch     0 | loss: 80.7427627CurrentTrain: epoch  5, batch     1 | loss: 102.1824420CurrentTrain: epoch  5, batch     2 | loss: 80.2307463CurrentTrain: epoch  5, batch     3 | loss: 82.6787644CurrentTrain: epoch  5, batch     4 | loss: 55.6358378CurrentTrain: epoch  6, batch     0 | loss: 84.5395447CurrentTrain: epoch  6, batch     1 | loss: 68.8381226CurrentTrain: epoch  6, batch     2 | loss: 69.0823527CurrentTrain: epoch  6, batch     3 | loss: 80.5482365CurrentTrain: epoch  6, batch     4 | loss: 95.6606704CurrentTrain: epoch  7, batch     0 | loss: 76.8748764CurrentTrain: epoch  7, batch     1 | loss: 81.9570405CurrentTrain: epoch  7, batch     2 | loss: 95.4834556CurrentTrain: epoch  7, batch     3 | loss: 94.4076470CurrentTrain: epoch  7, batch     4 | loss: 94.8824999CurrentTrain: epoch  8, batch     0 | loss: 97.4133681CurrentTrain: epoch  8, batch     1 | loss: 96.3662688CurrentTrain: epoch  8, batch     2 | loss: 122.6132229CurrentTrain: epoch  8, batch     3 | loss: 90.0243052CurrentTrain: epoch  8, batch     4 | loss: 44.0383317CurrentTrain: epoch  9, batch     0 | loss: 94.3263638CurrentTrain: epoch  9, batch     1 | loss: 78.8201897CurrentTrain: epoch  9, batch     2 | loss: 65.7992097CurrentTrain: epoch  9, batch     3 | loss: 95.7132194CurrentTrain: epoch  9, batch     4 | loss: 67.6327338
MemoryTrain:  epoch  0, batch     0 | loss: 1.0518483MemoryTrain:  epoch  1, batch     0 | loss: 0.9593095MemoryTrain:  epoch  2, batch     0 | loss: 0.7889471MemoryTrain:  epoch  3, batch     0 | loss: 0.6181258MemoryTrain:  epoch  4, batch     0 | loss: 0.5177611MemoryTrain:  epoch  5, batch     0 | loss: 0.4335966MemoryTrain:  epoch  6, batch     0 | loss: 0.3671915MemoryTrain:  epoch  7, batch     0 | loss: 0.3410568MemoryTrain:  epoch  8, batch     0 | loss: 0.3045954MemoryTrain:  epoch  9, batch     0 | loss: 0.2494102

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.21839080459770116), 3: np.float64(0.6235294117647059), 6: np.float64(0.0), 11: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.05405405405405406), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.5579399141630901), 23: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6371681415929203), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.34577603143418467
Weighted-average F1 score: 0.29195822559662854
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.23655913978494625), 3: np.float64(0.5747126436781609), 6: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.06060606060606061), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5758754863813229), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6666666666666666), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3270024772914946
Weighted-average F1 score: 0.27701978111230235
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.23404255319148937), 3: np.float64(0.5942857142857143), 6: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.04918032786885246), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.5737051792828686), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6714285714285714), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.34057341442224154
Weighted-average F1 score: 0.29161191757848864

F1 score per class: {0: np.float64(0.6597938144329897), 1: np.float64(0.16593886462882096), 2: np.float64(0.4), 3: np.float64(0.36177474402730375), 4: np.float64(0.75), 5: np.float64(0.8363636363636363), 6: np.float64(0.2714285714285714), 7: np.float64(0.0425531914893617), 8: np.float64(0.13636363636363635), 9: np.float64(0.8846153846153846), 10: np.float64(0.05825242718446602), 11: np.float64(0.1411764705882353), 12: np.float64(0.18181818181818182), 13: np.float64(0.07547169811320754), 14: np.float64(0.028708133971291867), 15: np.float64(0.631578947368421), 16: np.float64(0.06451612903225806), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5421245421245421), 20: np.float64(0.4838709677419355), 21: np.float64(0.0), 22: np.float64(0.44673539518900346), 23: np.float64(0.7526881720430108), 24: np.float64(0.0), 25: np.float64(0.3225806451612903), 26: np.float64(0.6134969325153374), 27: np.float64(0.0), 28: np.float64(0.18181818181818182), 29: np.float64(0.7857142857142857), 30: np.float64(0.8484848484848485), 31: np.float64(0.2222222222222222), 32: np.float64(0.5374149659863946), 33: np.float64(0.25), 34: np.float64(0.16475972540045766), 35: np.float64(0.11904761904761904), 36: np.float64(0.4158415841584158), 37: np.float64(0.35789473684210527), 38: np.float64(0.16666666666666666), 39: np.float64(0.0), 40: np.float64(0.10289389067524116)}
Micro-average F1 score: 0.36185525789684125
Weighted-average F1 score: 0.35098261963362243
F1 score per class: {0: np.float64(0.4594594594594595), 1: np.float64(0.1746031746031746), 2: np.float64(0.2641509433962264), 3: np.float64(0.33222591362126247), 4: np.float64(0.7906976744186046), 5: np.float64(0.5423728813559322), 6: np.float64(0.39800995024875624), 7: np.float64(0.06315789473684211), 8: np.float64(0.32673267326732675), 9: np.float64(0.42016806722689076), 10: np.float64(0.07692307692307693), 11: np.float64(0.145985401459854), 12: np.float64(0.2553191489361702), 13: np.float64(0.05405405405405406), 14: np.float64(0.03550295857988166), 15: np.float64(0.3870967741935484), 16: np.float64(0.4489795918367347), 17: np.float64(0.0), 18: np.float64(0.0759493670886076), 19: np.float64(0.48484848484848486), 20: np.float64(0.4263959390862944), 21: np.float64(0.03076923076923077), 22: np.float64(0.43529411764705883), 23: np.float64(0.66), 24: np.float64(0.0), 25: np.float64(0.3888888888888889), 26: np.float64(0.673469387755102), 27: np.float64(0.0), 28: np.float64(0.11940298507462686), 29: np.float64(0.8137254901960784), 30: np.float64(0.7727272727272727), 31: np.float64(0.045454545454545456), 32: np.float64(0.5015105740181269), 33: np.float64(0.16216216216216217), 34: np.float64(0.1568), 35: np.float64(0.20689655172413793), 36: np.float64(0.44660194174757284), 37: np.float64(0.1414141414141414), 38: np.float64(0.22916666666666666), 39: np.float64(0.1), 40: np.float64(0.1414141414141414)}
Micro-average F1 score: 0.348395337697589
Weighted-average F1 score: 0.3356686859029666
F1 score per class: {0: np.float64(0.5271317829457365), 1: np.float64(0.17391304347826086), 2: np.float64(0.2727272727272727), 3: np.float64(0.32298136645962733), 4: np.float64(0.7976190476190477), 5: np.float64(0.7272727272727273), 6: np.float64(0.387434554973822), 7: np.float64(0.061224489795918366), 8: np.float64(0.3492063492063492), 9: np.float64(0.8771929824561403), 10: np.float64(0.07692307692307693), 11: np.float64(0.1282051282051282), 12: np.float64(0.25136612021857924), 13: np.float64(0.09090909090909091), 14: np.float64(0.02564102564102564), 15: np.float64(0.4), 16: np.float64(0.3684210526315789), 17: np.float64(0.0), 18: np.float64(0.05263157894736842), 19: np.float64(0.5163398692810458), 20: np.float64(0.41545893719806765), 21: np.float64(0.0), 22: np.float64(0.4376899696048632), 23: np.float64(0.7111111111111111), 24: np.float64(0.0), 25: np.float64(0.4117647058823529), 26: np.float64(0.6947368421052632), 27: np.float64(0.0), 28: np.float64(0.12903225806451613), 29: np.float64(0.801980198019802), 30: np.float64(0.918918918918919), 31: np.float64(0.1), 32: np.float64(0.50625), 33: np.float64(0.1875), 34: np.float64(0.16291161178509533), 35: np.float64(0.20869565217391303), 36: np.float64(0.43037974683544306), 37: np.float64(0.16842105263157894), 38: np.float64(0.1728395061728395), 39: np.float64(0.09523809523809523), 40: np.float64(0.12844036697247707)}
Micro-average F1 score: 0.35710620831195483
Weighted-average F1 score: 0.33808718994036285

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.12179487179487179), 2: np.float64(0.0), 3: np.float64(0.4818181818181818), 5: np.float64(0.0), 6: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.04285714285714286), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.4482758620689655), 23: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.4864864864864865), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2359249329758713
Weighted-average F1 score: 0.20268968573641302
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.13622291021671826), 2: np.float64(0.0), 3: np.float64(0.4132231404958678), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.04878048780487805), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.4484848484848485), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.47804878048780486), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.21674876847290642
Weighted-average F1 score: 0.18999753127398025
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.13538461538461538), 2: np.float64(0.0), 3: np.float64(0.42276422764227645), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0392156862745098), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.44036697247706424), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.4845360824742268), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.22515795519816198
Weighted-average F1 score: 0.19904066947324875

F1 score per class: {0: np.float64(0.4740740740740741), 1: np.float64(0.08941176470588236), 2: np.float64(0.23076923076923078), 3: np.float64(0.24766355140186916), 4: np.float64(0.7142857142857143), 5: np.float64(0.6618705035971223), 6: np.float64(0.19), 7: np.float64(0.027210884353741496), 8: np.float64(0.13043478260869565), 9: np.float64(0.8363636363636363), 10: np.float64(0.05660377358490566), 11: np.float64(0.13186813186813187), 12: np.float64(0.10526315789473684), 13: np.float64(0.041237113402061855), 14: np.float64(0.02158273381294964), 15: np.float64(0.42857142857142855), 16: np.float64(0.0625), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.4983164983164983), 20: np.float64(0.2222222222222222), 21: np.float64(0.0), 22: np.float64(0.31862745098039214), 23: np.float64(0.6796116504854369), 24: np.float64(0.0), 25: np.float64(0.30303030303030304), 26: np.float64(0.5405405405405406), 27: np.float64(0.0), 28: np.float64(0.12121212121212122), 29: np.float64(0.6470588235294118), 30: np.float64(0.8), 31: np.float64(0.11764705882352941), 32: np.float64(0.39012345679012345), 33: np.float64(0.1875), 34: np.float64(0.10572687224669604), 35: np.float64(0.09174311926605505), 36: np.float64(0.3157894736842105), 37: np.float64(0.2786885245901639), 38: np.float64(0.13043478260869565), 39: np.float64(0.0), 40: np.float64(0.07289293849658314)}
Micro-average F1 score: 0.26231884057971017
Weighted-average F1 score: 0.24430340353978183
F1 score per class: {0: np.float64(0.3333333333333333), 1: np.float64(0.09649122807017543), 2: np.float64(0.16279069767441862), 3: np.float64(0.20618556701030927), 4: np.float64(0.7391304347826086), 5: np.float64(0.32597623089983024), 6: np.float64(0.2359882005899705), 7: np.float64(0.038461538461538464), 8: np.float64(0.21926910299003322), 9: np.float64(0.33112582781456956), 10: np.float64(0.07142857142857142), 11: np.float64(0.13986013986013987), 12: np.float64(0.14414414414414414), 13: np.float64(0.0273972602739726), 14: np.float64(0.027649769585253458), 15: np.float64(0.2727272727272727), 16: np.float64(0.3142857142857143), 17: np.float64(0.0), 18: np.float64(0.049586776859504134), 19: np.float64(0.4289544235924933), 20: np.float64(0.21374045801526717), 21: np.float64(0.028169014084507043), 22: np.float64(0.3014256619144603), 23: np.float64(0.49624060150375937), 24: np.float64(0.0), 25: np.float64(0.358974358974359), 26: np.float64(0.5689655172413793), 27: np.float64(0.0), 28: np.float64(0.06349206349206349), 29: np.float64(0.6509803921568628), 30: np.float64(0.6666666666666666), 31: np.float64(0.023529411764705882), 32: np.float64(0.35853131749460043), 33: np.float64(0.10909090909090909), 34: np.float64(0.09898989898989899), 35: np.float64(0.14423076923076922), 36: np.float64(0.26512968299711814), 37: np.float64(0.11382113821138211), 38: np.float64(0.13414634146341464), 39: np.float64(0.058823529411764705), 40: np.float64(0.09929078014184398)}
Micro-average F1 score: 0.23619831132279714
Weighted-average F1 score: 0.22379117938160298
F1 score per class: {0: np.float64(0.38202247191011235), 1: np.float64(0.09691629955947137), 2: np.float64(0.17647058823529413), 3: np.float64(0.2047244094488189), 4: np.float64(0.7486033519553073), 5: np.float64(0.5092838196286472), 6: np.float64(0.2364217252396166), 7: np.float64(0.03592814371257485), 8: np.float64(0.2732919254658385), 9: np.float64(0.8064516129032258), 10: np.float64(0.06956521739130435), 11: np.float64(0.12195121951219512), 12: np.float64(0.14330218068535824), 13: np.float64(0.037383177570093455), 14: np.float64(0.020066889632107024), 15: np.float64(0.26666666666666666), 16: np.float64(0.2978723404255319), 17: np.float64(0.0), 18: np.float64(0.03418803418803419), 19: np.float64(0.46607669616519176), 20: np.float64(0.19413092550790068), 21: np.float64(0.0), 22: np.float64(0.2987551867219917), 23: np.float64(0.5765765765765766), 24: np.float64(0.0), 25: np.float64(0.3888888888888889), 26: np.float64(0.5945945945945946), 27: np.float64(0.0), 28: np.float64(0.07920792079207921), 29: np.float64(0.6403162055335968), 30: np.float64(0.85), 31: np.float64(0.04878048780487805), 32: np.float64(0.3584070796460177), 33: np.float64(0.13043478260869565), 34: np.float64(0.10184182015167931), 35: np.float64(0.14906832298136646), 36: np.float64(0.2527881040892193), 37: np.float64(0.1322314049586777), 38: np.float64(0.10526315789473684), 39: np.float64(0.07142857142857142), 40: np.float64(0.09051724137931035)}
Micro-average F1 score: 0.24582057923239933
Weighted-average F1 score: 0.227924261264643
cur_acc_wo_na:  ['0.7691', '0.5210', '0.4337', '0.6495', '0.3952', '0.5200', '0.3228', '0.3458']
his_acc_wo_na:  ['0.7691', '0.6877', '0.5637', '0.5668', '0.4734', '0.4855', '0.4271', '0.3619']
cur_acc des_wo_na:  ['0.7412', '0.5591', '0.4322', '0.5417', '0.4564', '0.5156', '0.3228', '0.3270']
his_acc des_wo_na:  ['0.7412', '0.6502', '0.5435', '0.5273', '0.4537', '0.4420', '0.4192', '0.3484']
cur_acc rrf_wo_na:  ['0.7602', '0.5683', '0.4606', '0.5666', '0.4571', '0.5124', '0.3505', '0.3406']
his_acc rrf_wo_na:  ['0.7602', '0.6713', '0.5574', '0.5349', '0.4630', '0.4586', '0.4291', '0.3571']
cur_acc_w_na:  ['0.6414', '0.4069', '0.3056', '0.4932', '0.2960', '0.3523', '0.2550', '0.2359']
his_acc_w_na:  ['0.6414', '0.5498', '0.4128', '0.4123', '0.3454', '0.3476', '0.3123', '0.2623']
cur_acc des_w_na:  ['0.6035', '0.4014', '0.2965', '0.3912', '0.3154', '0.3300', '0.2451', '0.2167']
his_acc des_w_na:  ['0.6035', '0.4856', '0.3684', '0.3625', '0.3069', '0.2932', '0.2895', '0.2362']
cur_acc rrf_w_na:  ['0.6225', '0.4138', '0.3184', '0.4140', '0.3177', '0.3377', '0.2691', '0.2252']
his_acc rrf_w_na:  ['0.6225', '0.5066', '0.3831', '0.3714', '0.3160', '0.3097', '0.3015', '0.2458']
--------Round  3
seed:  400
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 0 1 2 5 3 4 6]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 110.2881408CurrentTrain: epoch  0, batch     1 | loss: 200.4501703CurrentTrain: epoch  0, batch     2 | loss: 121.2643890CurrentTrain: epoch  0, batch     3 | loss: 102.2740993CurrentTrain: epoch  0, batch     4 | loss: 87.3742756CurrentTrain: epoch  0, batch     5 | loss: 89.3988367CurrentTrain: epoch  0, batch     6 | loss: 77.9242297CurrentTrain: epoch  0, batch     7 | loss: 119.6406817CurrentTrain: epoch  0, batch     8 | loss: 118.1666075CurrentTrain: epoch  0, batch     9 | loss: 119.2832441CurrentTrain: epoch  0, batch    10 | loss: 147.6955525CurrentTrain: epoch  0, batch    11 | loss: 118.9807344CurrentTrain: epoch  0, batch    12 | loss: 100.5061261CurrentTrain: epoch  0, batch    13 | loss: 147.0250235CurrentTrain: epoch  0, batch    14 | loss: 118.0496389CurrentTrain: epoch  0, batch    15 | loss: 87.0369627CurrentTrain: epoch  0, batch    16 | loss: 100.0643783CurrentTrain: epoch  0, batch    17 | loss: 86.5537442CurrentTrain: epoch  0, batch    18 | loss: 100.3460766CurrentTrain: epoch  0, batch    19 | loss: 118.1000583CurrentTrain: epoch  0, batch    20 | loss: 86.2426830CurrentTrain: epoch  0, batch    21 | loss: 145.6901120CurrentTrain: epoch  0, batch    22 | loss: 75.7429608CurrentTrain: epoch  0, batch    23 | loss: 99.2006028CurrentTrain: epoch  0, batch    24 | loss: 117.8581358CurrentTrain: epoch  0, batch    25 | loss: 98.9183290CurrentTrain: epoch  0, batch    26 | loss: 86.3062819CurrentTrain: epoch  0, batch    27 | loss: 85.8851825CurrentTrain: epoch  0, batch    28 | loss: 117.4298165CurrentTrain: epoch  0, batch    29 | loss: 98.6016425CurrentTrain: epoch  0, batch    30 | loss: 117.9629917CurrentTrain: epoch  0, batch    31 | loss: 75.5564439CurrentTrain: epoch  0, batch    32 | loss: 116.5358972CurrentTrain: epoch  0, batch    33 | loss: 117.8195853CurrentTrain: epoch  0, batch    34 | loss: 84.5616043CurrentTrain: epoch  0, batch    35 | loss: 144.8483801CurrentTrain: epoch  0, batch    36 | loss: 98.5846977CurrentTrain: epoch  0, batch    37 | loss: 98.1870545CurrentTrain: epoch  0, batch    38 | loss: 84.5961954CurrentTrain: epoch  0, batch    39 | loss: 97.6271461CurrentTrain: epoch  0, batch    40 | loss: 97.2902527CurrentTrain: epoch  0, batch    41 | loss: 97.0364292CurrentTrain: epoch  0, batch    42 | loss: 115.0473903CurrentTrain: epoch  0, batch    43 | loss: 145.0333101CurrentTrain: epoch  0, batch    44 | loss: 97.9342011CurrentTrain: epoch  0, batch    45 | loss: 117.1089596CurrentTrain: epoch  0, batch    46 | loss: 114.9091801CurrentTrain: epoch  0, batch    47 | loss: 95.2666876CurrentTrain: epoch  0, batch    48 | loss: 117.6410066CurrentTrain: epoch  0, batch    49 | loss: 96.7329349CurrentTrain: epoch  0, batch    50 | loss: 81.8785893CurrentTrain: epoch  0, batch    51 | loss: 97.9568146CurrentTrain: epoch  0, batch    52 | loss: 72.5353804CurrentTrain: epoch  0, batch    53 | loss: 84.4438073CurrentTrain: epoch  0, batch    54 | loss: 141.3781548CurrentTrain: epoch  0, batch    55 | loss: 83.7017649CurrentTrain: epoch  0, batch    56 | loss: 95.6652163CurrentTrain: epoch  0, batch    57 | loss: 115.6977992CurrentTrain: epoch  0, batch    58 | loss: 188.9622332CurrentTrain: epoch  0, batch    59 | loss: 142.0038656CurrentTrain: epoch  0, batch    60 | loss: 95.1924530CurrentTrain: epoch  0, batch    61 | loss: 92.8267099CurrentTrain: epoch  0, batch    62 | loss: 191.1139850CurrentTrain: epoch  0, batch    63 | loss: 114.0301618CurrentTrain: epoch  0, batch    64 | loss: 81.4071547CurrentTrain: epoch  0, batch    65 | loss: 80.8235405CurrentTrain: epoch  0, batch    66 | loss: 113.6217650CurrentTrain: epoch  0, batch    67 | loss: 112.6935092CurrentTrain: epoch  0, batch    68 | loss: 94.2902952CurrentTrain: epoch  0, batch    69 | loss: 140.8175390CurrentTrain: epoch  0, batch    70 | loss: 90.5743589CurrentTrain: epoch  0, batch    71 | loss: 69.6322559CurrentTrain: epoch  0, batch    72 | loss: 115.0130219CurrentTrain: epoch  0, batch    73 | loss: 92.9354824CurrentTrain: epoch  0, batch    74 | loss: 95.2651714CurrentTrain: epoch  0, batch    75 | loss: 96.8048269CurrentTrain: epoch  0, batch    76 | loss: 79.5999846CurrentTrain: epoch  0, batch    77 | loss: 77.1028388CurrentTrain: epoch  0, batch    78 | loss: 71.2210779CurrentTrain: epoch  0, batch    79 | loss: 95.0423412CurrentTrain: epoch  0, batch    80 | loss: 80.2679860CurrentTrain: epoch  0, batch    81 | loss: 79.0096110CurrentTrain: epoch  0, batch    82 | loss: 80.4991476CurrentTrain: epoch  0, batch    83 | loss: 67.8921696CurrentTrain: epoch  0, batch    84 | loss: 95.6147689CurrentTrain: epoch  0, batch    85 | loss: 109.1481121CurrentTrain: epoch  0, batch    86 | loss: 81.3408439CurrentTrain: epoch  0, batch    87 | loss: 94.9496809CurrentTrain: epoch  0, batch    88 | loss: 91.8759410CurrentTrain: epoch  0, batch    89 | loss: 137.2863546CurrentTrain: epoch  0, batch    90 | loss: 142.1620753CurrentTrain: epoch  0, batch    91 | loss: 111.7227129CurrentTrain: epoch  0, batch    92 | loss: 77.1848387CurrentTrain: epoch  0, batch    93 | loss: 79.8912701CurrentTrain: epoch  0, batch    94 | loss: 85.9951529CurrentTrain: epoch  0, batch    95 | loss: 95.1037907CurrentTrain: epoch  1, batch     0 | loss: 67.3470938CurrentTrain: epoch  1, batch     1 | loss: 79.8374586CurrentTrain: epoch  1, batch     2 | loss: 66.7043028CurrentTrain: epoch  1, batch     3 | loss: 108.8896333CurrentTrain: epoch  1, batch     4 | loss: 75.8090124CurrentTrain: epoch  1, batch     5 | loss: 88.5857043CurrentTrain: epoch  1, batch     6 | loss: 108.0534660CurrentTrain: epoch  1, batch     7 | loss: 88.8937974CurrentTrain: epoch  1, batch     8 | loss: 65.5824310CurrentTrain: epoch  1, batch     9 | loss: 78.3100373CurrentTrain: epoch  1, batch    10 | loss: 86.6833893CurrentTrain: epoch  1, batch    11 | loss: 140.5077296CurrentTrain: epoch  1, batch    12 | loss: 78.2267090CurrentTrain: epoch  1, batch    13 | loss: 109.4229663CurrentTrain: epoch  1, batch    14 | loss: 77.9245673CurrentTrain: epoch  1, batch    15 | loss: 92.0102850CurrentTrain: epoch  1, batch    16 | loss: 89.7786102CurrentTrain: epoch  1, batch    17 | loss: 89.8431166CurrentTrain: epoch  1, batch    18 | loss: 91.4495171CurrentTrain: epoch  1, batch    19 | loss: 109.4902861CurrentTrain: epoch  1, batch    20 | loss: 70.2339530CurrentTrain: epoch  1, batch    21 | loss: 74.6860394CurrentTrain: epoch  1, batch    22 | loss: 141.7593283CurrentTrain: epoch  1, batch    23 | loss: 137.1363016CurrentTrain: epoch  1, batch    24 | loss: 75.5580918CurrentTrain: epoch  1, batch    25 | loss: 79.2560308CurrentTrain: epoch  1, batch    26 | loss: 108.9155013CurrentTrain: epoch  1, batch    27 | loss: 75.4606246CurrentTrain: epoch  1, batch    28 | loss: 78.4653704CurrentTrain: epoch  1, batch    29 | loss: 134.9977741CurrentTrain: epoch  1, batch    30 | loss: 77.7971516CurrentTrain: epoch  1, batch    31 | loss: 76.5384433CurrentTrain: epoch  1, batch    32 | loss: 92.5620876CurrentTrain: epoch  1, batch    33 | loss: 74.3283734CurrentTrain: epoch  1, batch    34 | loss: 90.2472411CurrentTrain: epoch  1, batch    35 | loss: 136.3503626CurrentTrain: epoch  1, batch    36 | loss: 137.3309989CurrentTrain: epoch  1, batch    37 | loss: 191.1226642CurrentTrain: epoch  1, batch    38 | loss: 88.8599280CurrentTrain: epoch  1, batch    39 | loss: 77.9920791CurrentTrain: epoch  1, batch    40 | loss: 90.7710753CurrentTrain: epoch  1, batch    41 | loss: 78.9921602CurrentTrain: epoch  1, batch    42 | loss: 88.0238193CurrentTrain: epoch  1, batch    43 | loss: 67.3302859CurrentTrain: epoch  1, batch    44 | loss: 139.1379437CurrentTrain: epoch  1, batch    45 | loss: 108.1269595CurrentTrain: epoch  1, batch    46 | loss: 136.7635118CurrentTrain: epoch  1, batch    47 | loss: 75.7158388CurrentTrain: epoch  1, batch    48 | loss: 73.4613459CurrentTrain: epoch  1, batch    49 | loss: 107.7844189CurrentTrain: epoch  1, batch    50 | loss: 73.1814343CurrentTrain: epoch  1, batch    51 | loss: 77.9073457CurrentTrain: epoch  1, batch    52 | loss: 137.0305175CurrentTrain: epoch  1, batch    53 | loss: 90.7816508CurrentTrain: epoch  1, batch    54 | loss: 92.5695341CurrentTrain: epoch  1, batch    55 | loss: 133.8783275CurrentTrain: epoch  1, batch    56 | loss: 103.7683211CurrentTrain: epoch  1, batch    57 | loss: 66.9677075CurrentTrain: epoch  1, batch    58 | loss: 107.6198015CurrentTrain: epoch  1, batch    59 | loss: 83.0185232CurrentTrain: epoch  1, batch    60 | loss: 65.2875248CurrentTrain: epoch  1, batch    61 | loss: 68.0319157CurrentTrain: epoch  1, batch    62 | loss: 89.8734974CurrentTrain: epoch  1, batch    63 | loss: 76.1762534CurrentTrain: epoch  1, batch    64 | loss: 76.4050803CurrentTrain: epoch  1, batch    65 | loss: 92.2446486CurrentTrain: epoch  1, batch    66 | loss: 65.7394992CurrentTrain: epoch  1, batch    67 | loss: 108.3860113CurrentTrain: epoch  1, batch    68 | loss: 62.1752884CurrentTrain: epoch  1, batch    69 | loss: 110.5913501CurrentTrain: epoch  1, batch    70 | loss: 139.5524633CurrentTrain: epoch  1, batch    71 | loss: 69.8729583CurrentTrain: epoch  1, batch    72 | loss: 140.7264590CurrentTrain: epoch  1, batch    73 | loss: 138.9524942CurrentTrain: epoch  1, batch    74 | loss: 66.9300905CurrentTrain: epoch  1, batch    75 | loss: 66.5153131CurrentTrain: epoch  1, batch    76 | loss: 76.7268534CurrentTrain: epoch  1, batch    77 | loss: 79.0221042CurrentTrain: epoch  1, batch    78 | loss: 108.8937049CurrentTrain: epoch  1, batch    79 | loss: 87.2354609CurrentTrain: epoch  1, batch    80 | loss: 70.4878152CurrentTrain: epoch  1, batch    81 | loss: 134.5722371CurrentTrain: epoch  1, batch    82 | loss: 76.6700300CurrentTrain: epoch  1, batch    83 | loss: 104.4791788CurrentTrain: epoch  1, batch    84 | loss: 71.7802243CurrentTrain: epoch  1, batch    85 | loss: 88.0601097CurrentTrain: epoch  1, batch    86 | loss: 90.4341197CurrentTrain: epoch  1, batch    87 | loss: 87.7001208CurrentTrain: epoch  1, batch    88 | loss: 100.3308438CurrentTrain: epoch  1, batch    89 | loss: 85.7675293CurrentTrain: epoch  1, batch    90 | loss: 105.5244935CurrentTrain: epoch  1, batch    91 | loss: 91.2600042CurrentTrain: epoch  1, batch    92 | loss: 86.0501031CurrentTrain: epoch  1, batch    93 | loss: 104.6065491CurrentTrain: epoch  1, batch    94 | loss: 85.3752532CurrentTrain: epoch  1, batch    95 | loss: 62.1356864CurrentTrain: epoch  2, batch     0 | loss: 99.8206042CurrentTrain: epoch  2, batch     1 | loss: 75.1577209CurrentTrain: epoch  2, batch     2 | loss: 69.8664877CurrentTrain: epoch  2, batch     3 | loss: 61.3922028CurrentTrain: epoch  2, batch     4 | loss: 99.5570106CurrentTrain: epoch  2, batch     5 | loss: 107.4084437CurrentTrain: epoch  2, batch     6 | loss: 85.5250034CurrentTrain: epoch  2, batch     7 | loss: 73.0709277CurrentTrain: epoch  2, batch     8 | loss: 72.6035895CurrentTrain: epoch  2, batch     9 | loss: 104.1375735CurrentTrain: epoch  2, batch    10 | loss: 73.9223068CurrentTrain: epoch  2, batch    11 | loss: 89.2307178CurrentTrain: epoch  2, batch    12 | loss: 70.5373577CurrentTrain: epoch  2, batch    13 | loss: 73.4205940CurrentTrain: epoch  2, batch    14 | loss: 107.6448030CurrentTrain: epoch  2, batch    15 | loss: 65.2069696CurrentTrain: epoch  2, batch    16 | loss: 66.1408319CurrentTrain: epoch  2, batch    17 | loss: 178.6956212CurrentTrain: epoch  2, batch    18 | loss: 83.5637262CurrentTrain: epoch  2, batch    19 | loss: 109.4908037CurrentTrain: epoch  2, batch    20 | loss: 86.0793051CurrentTrain: epoch  2, batch    21 | loss: 98.7880407CurrentTrain: epoch  2, batch    22 | loss: 69.5916472CurrentTrain: epoch  2, batch    23 | loss: 73.1822916CurrentTrain: epoch  2, batch    24 | loss: 71.6663766CurrentTrain: epoch  2, batch    25 | loss: 74.8683138CurrentTrain: epoch  2, batch    26 | loss: 104.9514419CurrentTrain: epoch  2, batch    27 | loss: 63.0767415CurrentTrain: epoch  2, batch    28 | loss: 106.6815210CurrentTrain: epoch  2, batch    29 | loss: 72.0297744CurrentTrain: epoch  2, batch    30 | loss: 99.6855174CurrentTrain: epoch  2, batch    31 | loss: 107.8324029CurrentTrain: epoch  2, batch    32 | loss: 81.3094597CurrentTrain: epoch  2, batch    33 | loss: 74.4465009CurrentTrain: epoch  2, batch    34 | loss: 88.2061006CurrentTrain: epoch  2, batch    35 | loss: 89.6337770CurrentTrain: epoch  2, batch    36 | loss: 84.2000104CurrentTrain: epoch  2, batch    37 | loss: 134.6034163CurrentTrain: epoch  2, batch    38 | loss: 71.8367321CurrentTrain: epoch  2, batch    39 | loss: 103.8566828CurrentTrain: epoch  2, batch    40 | loss: 85.5933846CurrentTrain: epoch  2, batch    41 | loss: 75.6510973CurrentTrain: epoch  2, batch    42 | loss: 72.9652425CurrentTrain: epoch  2, batch    43 | loss: 71.2521994CurrentTrain: epoch  2, batch    44 | loss: 110.7026847CurrentTrain: epoch  2, batch    45 | loss: 85.0020410CurrentTrain: epoch  2, batch    46 | loss: 109.9812916CurrentTrain: epoch  2, batch    47 | loss: 108.6131659CurrentTrain: epoch  2, batch    48 | loss: 104.2882381CurrentTrain: epoch  2, batch    49 | loss: 106.6205828CurrentTrain: epoch  2, batch    50 | loss: 76.8229240CurrentTrain: epoch  2, batch    51 | loss: 74.9428521CurrentTrain: epoch  2, batch    52 | loss: 88.1307465CurrentTrain: epoch  2, batch    53 | loss: 83.3404736CurrentTrain: epoch  2, batch    54 | loss: 106.1359154CurrentTrain: epoch  2, batch    55 | loss: 86.3077037CurrentTrain: epoch  2, batch    56 | loss: 134.3071945CurrentTrain: epoch  2, batch    57 | loss: 105.8133341CurrentTrain: epoch  2, batch    58 | loss: 86.9456553CurrentTrain: epoch  2, batch    59 | loss: 87.8365567CurrentTrain: epoch  2, batch    60 | loss: 99.5620203CurrentTrain: epoch  2, batch    61 | loss: 122.7692772CurrentTrain: epoch  2, batch    62 | loss: 86.4241445CurrentTrain: epoch  2, batch    63 | loss: 87.5224998CurrentTrain: epoch  2, batch    64 | loss: 88.8789228CurrentTrain: epoch  2, batch    65 | loss: 88.1138519CurrentTrain: epoch  2, batch    66 | loss: 106.7203458CurrentTrain: epoch  2, batch    67 | loss: 104.6949623CurrentTrain: epoch  2, batch    68 | loss: 134.9671200CurrentTrain: epoch  2, batch    69 | loss: 107.3827331CurrentTrain: epoch  2, batch    70 | loss: 64.0235490CurrentTrain: epoch  2, batch    71 | loss: 100.0516880CurrentTrain: epoch  2, batch    72 | loss: 177.5665102CurrentTrain: epoch  2, batch    73 | loss: 88.3501990CurrentTrain: epoch  2, batch    74 | loss: 84.6362123CurrentTrain: epoch  2, batch    75 | loss: 72.4851251CurrentTrain: epoch  2, batch    76 | loss: 101.3492596CurrentTrain: epoch  2, batch    77 | loss: 82.6981898CurrentTrain: epoch  2, batch    78 | loss: 73.4210876CurrentTrain: epoch  2, batch    79 | loss: 106.4199782CurrentTrain: epoch  2, batch    80 | loss: 181.1571847CurrentTrain: epoch  2, batch    81 | loss: 86.4744897CurrentTrain: epoch  2, batch    82 | loss: 87.8923381CurrentTrain: epoch  2, batch    83 | loss: 59.4943287CurrentTrain: epoch  2, batch    84 | loss: 87.5630436CurrentTrain: epoch  2, batch    85 | loss: 61.2366736CurrentTrain: epoch  2, batch    86 | loss: 82.3743635CurrentTrain: epoch  2, batch    87 | loss: 99.9218039CurrentTrain: epoch  2, batch    88 | loss: 125.2189736CurrentTrain: epoch  2, batch    89 | loss: 135.1487757CurrentTrain: epoch  2, batch    90 | loss: 129.8421205CurrentTrain: epoch  2, batch    91 | loss: 107.3069842CurrentTrain: epoch  2, batch    92 | loss: 109.1053942CurrentTrain: epoch  2, batch    93 | loss: 110.4513240CurrentTrain: epoch  2, batch    94 | loss: 73.0728706CurrentTrain: epoch  2, batch    95 | loss: 72.7589407CurrentTrain: epoch  3, batch     0 | loss: 60.2951601CurrentTrain: epoch  3, batch     1 | loss: 63.6037508CurrentTrain: epoch  3, batch     2 | loss: 70.9321917CurrentTrain: epoch  3, batch     3 | loss: 86.7532652CurrentTrain: epoch  3, batch     4 | loss: 68.8715934CurrentTrain: epoch  3, batch     5 | loss: 83.8463893CurrentTrain: epoch  3, batch     6 | loss: 107.4754480CurrentTrain: epoch  3, batch     7 | loss: 81.9598768CurrentTrain: epoch  3, batch     8 | loss: 61.1659073CurrentTrain: epoch  3, batch     9 | loss: 108.4422801CurrentTrain: epoch  3, batch    10 | loss: 85.0396285CurrentTrain: epoch  3, batch    11 | loss: 97.1801435CurrentTrain: epoch  3, batch    12 | loss: 87.8670903CurrentTrain: epoch  3, batch    13 | loss: 108.1425281CurrentTrain: epoch  3, batch    14 | loss: 87.5932298CurrentTrain: epoch  3, batch    15 | loss: 105.3574605CurrentTrain: epoch  3, batch    16 | loss: 105.2341552CurrentTrain: epoch  3, batch    17 | loss: 73.5407187CurrentTrain: epoch  3, batch    18 | loss: 83.2249631CurrentTrain: epoch  3, batch    19 | loss: 85.8645361CurrentTrain: epoch  3, batch    20 | loss: 73.5972426CurrentTrain: epoch  3, batch    21 | loss: 68.1975097CurrentTrain: epoch  3, batch    22 | loss: 102.4389606CurrentTrain: epoch  3, batch    23 | loss: 176.7473745CurrentTrain: epoch  3, batch    24 | loss: 82.9495332CurrentTrain: epoch  3, batch    25 | loss: 105.5634788CurrentTrain: epoch  3, batch    26 | loss: 98.4554051CurrentTrain: epoch  3, batch    27 | loss: 131.8137455CurrentTrain: epoch  3, batch    28 | loss: 67.9228914CurrentTrain: epoch  3, batch    29 | loss: 102.3149783CurrentTrain: epoch  3, batch    30 | loss: 86.2960635CurrentTrain: epoch  3, batch    31 | loss: 67.9458921CurrentTrain: epoch  3, batch    32 | loss: 103.0308611CurrentTrain: epoch  3, batch    33 | loss: 84.9096920CurrentTrain: epoch  3, batch    34 | loss: 72.2355950CurrentTrain: epoch  3, batch    35 | loss: 63.3654255CurrentTrain: epoch  3, batch    36 | loss: 87.5901916CurrentTrain: epoch  3, batch    37 | loss: 67.5802335CurrentTrain: epoch  3, batch    38 | loss: 105.6188020CurrentTrain: epoch  3, batch    39 | loss: 84.0481945CurrentTrain: epoch  3, batch    40 | loss: 100.9695722CurrentTrain: epoch  3, batch    41 | loss: 82.4675525CurrentTrain: epoch  3, batch    42 | loss: 84.7248254CurrentTrain: epoch  3, batch    43 | loss: 84.4092278CurrentTrain: epoch  3, batch    44 | loss: 72.2682777CurrentTrain: epoch  3, batch    45 | loss: 84.3515803CurrentTrain: epoch  3, batch    46 | loss: 67.9915200CurrentTrain: epoch  3, batch    47 | loss: 80.8125850CurrentTrain: epoch  3, batch    48 | loss: 75.3690289CurrentTrain: epoch  3, batch    49 | loss: 105.5966302CurrentTrain: epoch  3, batch    50 | loss: 83.8172706CurrentTrain: epoch  3, batch    51 | loss: 85.5763926CurrentTrain: epoch  3, batch    52 | loss: 103.1504374CurrentTrain: epoch  3, batch    53 | loss: 61.0205574CurrentTrain: epoch  3, batch    54 | loss: 68.1387619CurrentTrain: epoch  3, batch    55 | loss: 81.4123653CurrentTrain: epoch  3, batch    56 | loss: 71.9804927CurrentTrain: epoch  3, batch    57 | loss: 104.5735432CurrentTrain: epoch  3, batch    58 | loss: 173.5809870CurrentTrain: epoch  3, batch    59 | loss: 81.8827015CurrentTrain: epoch  3, batch    60 | loss: 102.3049665CurrentTrain: epoch  3, batch    61 | loss: 100.3889472CurrentTrain: epoch  3, batch    62 | loss: 133.5634241CurrentTrain: epoch  3, batch    63 | loss: 86.6509692CurrentTrain: epoch  3, batch    64 | loss: 68.7895748CurrentTrain: epoch  3, batch    65 | loss: 73.2551705CurrentTrain: epoch  3, batch    66 | loss: 68.1622287CurrentTrain: epoch  3, batch    67 | loss: 130.9818381CurrentTrain: epoch  3, batch    68 | loss: 102.0809954CurrentTrain: epoch  3, batch    69 | loss: 107.6288421CurrentTrain: epoch  3, batch    70 | loss: 68.6759143CurrentTrain: epoch  3, batch    71 | loss: 73.5177644CurrentTrain: epoch  3, batch    72 | loss: 83.2881781CurrentTrain: epoch  3, batch    73 | loss: 100.7064647CurrentTrain: epoch  3, batch    74 | loss: 61.1726102CurrentTrain: epoch  3, batch    75 | loss: 72.5687624CurrentTrain: epoch  3, batch    76 | loss: 127.1635772CurrentTrain: epoch  3, batch    77 | loss: 70.2841971CurrentTrain: epoch  3, batch    78 | loss: 79.9965405CurrentTrain: epoch  3, batch    79 | loss: 83.4533006CurrentTrain: epoch  3, batch    80 | loss: 88.4302918CurrentTrain: epoch  3, batch    81 | loss: 73.7049236CurrentTrain: epoch  3, batch    82 | loss: 57.7173781CurrentTrain: epoch  3, batch    83 | loss: 85.3098386CurrentTrain: epoch  3, batch    84 | loss: 105.6622589CurrentTrain: epoch  3, batch    85 | loss: 79.6670037CurrentTrain: epoch  3, batch    86 | loss: 85.7945853CurrentTrain: epoch  3, batch    87 | loss: 89.4660767CurrentTrain: epoch  3, batch    88 | loss: 86.2971397CurrentTrain: epoch  3, batch    89 | loss: 131.0769604CurrentTrain: epoch  3, batch    90 | loss: 64.0047721CurrentTrain: epoch  3, batch    91 | loss: 103.9589453CurrentTrain: epoch  3, batch    92 | loss: 74.6849341CurrentTrain: epoch  3, batch    93 | loss: 67.0128090CurrentTrain: epoch  3, batch    94 | loss: 72.5356227CurrentTrain: epoch  3, batch    95 | loss: 74.5774253CurrentTrain: epoch  4, batch     0 | loss: 85.3915190CurrentTrain: epoch  4, batch     1 | loss: 86.3827584CurrentTrain: epoch  4, batch     2 | loss: 61.1597890CurrentTrain: epoch  4, batch     3 | loss: 133.3750995CurrentTrain: epoch  4, batch     4 | loss: 83.4598726CurrentTrain: epoch  4, batch     5 | loss: 83.0732702CurrentTrain: epoch  4, batch     6 | loss: 72.8736615CurrentTrain: epoch  4, batch     7 | loss: 67.4775942CurrentTrain: epoch  4, batch     8 | loss: 86.6387348CurrentTrain: epoch  4, batch     9 | loss: 64.7566888CurrentTrain: epoch  4, batch    10 | loss: 84.4783937CurrentTrain: epoch  4, batch    11 | loss: 82.4834087CurrentTrain: epoch  4, batch    12 | loss: 68.2952395CurrentTrain: epoch  4, batch    13 | loss: 123.3092816CurrentTrain: epoch  4, batch    14 | loss: 82.6516293CurrentTrain: epoch  4, batch    15 | loss: 76.1727922CurrentTrain: epoch  4, batch    16 | loss: 101.3259284CurrentTrain: epoch  4, batch    17 | loss: 84.6992536CurrentTrain: epoch  4, batch    18 | loss: 59.2695936CurrentTrain: epoch  4, batch    19 | loss: 69.4416825CurrentTrain: epoch  4, batch    20 | loss: 67.0706649CurrentTrain: epoch  4, batch    21 | loss: 57.5080267CurrentTrain: epoch  4, batch    22 | loss: 83.3395410CurrentTrain: epoch  4, batch    23 | loss: 92.2021112CurrentTrain: epoch  4, batch    24 | loss: 132.0250433CurrentTrain: epoch  4, batch    25 | loss: 70.4724885CurrentTrain: epoch  4, batch    26 | loss: 96.3112703CurrentTrain: epoch  4, batch    27 | loss: 78.9522842CurrentTrain: epoch  4, batch    28 | loss: 84.0614981CurrentTrain: epoch  4, batch    29 | loss: 128.2055931CurrentTrain: epoch  4, batch    30 | loss: 82.8752725CurrentTrain: epoch  4, batch    31 | loss: 101.3656254CurrentTrain: epoch  4, batch    32 | loss: 94.7450056CurrentTrain: epoch  4, batch    33 | loss: 101.4174501CurrentTrain: epoch  4, batch    34 | loss: 103.1654870CurrentTrain: epoch  4, batch    35 | loss: 82.4535132CurrentTrain: epoch  4, batch    36 | loss: 85.8403979CurrentTrain: epoch  4, batch    37 | loss: 81.3829968CurrentTrain: epoch  4, batch    38 | loss: 129.7256792CurrentTrain: epoch  4, batch    39 | loss: 87.0332511CurrentTrain: epoch  4, batch    40 | loss: 103.0872536CurrentTrain: epoch  4, batch    41 | loss: 84.8337180CurrentTrain: epoch  4, batch    42 | loss: 77.1610795CurrentTrain: epoch  4, batch    43 | loss: 129.7556220CurrentTrain: epoch  4, batch    44 | loss: 83.5245033CurrentTrain: epoch  4, batch    45 | loss: 101.3533607CurrentTrain: epoch  4, batch    46 | loss: 94.1800707CurrentTrain: epoch  4, batch    47 | loss: 70.7366050CurrentTrain: epoch  4, batch    48 | loss: 79.8613627CurrentTrain: epoch  4, batch    49 | loss: 82.5894654CurrentTrain: epoch  4, batch    50 | loss: 83.2888928CurrentTrain: epoch  4, batch    51 | loss: 101.9470282CurrentTrain: epoch  4, batch    52 | loss: 76.0166652CurrentTrain: epoch  4, batch    53 | loss: 71.0134321CurrentTrain: epoch  4, batch    54 | loss: 102.2585972CurrentTrain: epoch  4, batch    55 | loss: 80.1287908CurrentTrain: epoch  4, batch    56 | loss: 81.6006968CurrentTrain: epoch  4, batch    57 | loss: 86.0928811CurrentTrain: epoch  4, batch    58 | loss: 64.3260305CurrentTrain: epoch  4, batch    59 | loss: 80.6958022CurrentTrain: epoch  4, batch    60 | loss: 108.9394380CurrentTrain: epoch  4, batch    61 | loss: 70.7019075CurrentTrain: epoch  4, batch    62 | loss: 81.7963110CurrentTrain: epoch  4, batch    63 | loss: 84.6285103CurrentTrain: epoch  4, batch    64 | loss: 95.9675740CurrentTrain: epoch  4, batch    65 | loss: 70.2704404CurrentTrain: epoch  4, batch    66 | loss: 83.2136357CurrentTrain: epoch  4, batch    67 | loss: 79.0230983CurrentTrain: epoch  4, batch    68 | loss: 84.9597749CurrentTrain: epoch  4, batch    69 | loss: 88.5865784CurrentTrain: epoch  4, batch    70 | loss: 70.5231148CurrentTrain: epoch  4, batch    71 | loss: 97.6188157CurrentTrain: epoch  4, batch    72 | loss: 81.2871664CurrentTrain: epoch  4, batch    73 | loss: 72.2726357CurrentTrain: epoch  4, batch    74 | loss: 86.5696262CurrentTrain: epoch  4, batch    75 | loss: 67.2564219CurrentTrain: epoch  4, batch    76 | loss: 105.3525876CurrentTrain: epoch  4, batch    77 | loss: 70.2161611CurrentTrain: epoch  4, batch    78 | loss: 127.5180872CurrentTrain: epoch  4, batch    79 | loss: 71.8490382CurrentTrain: epoch  4, batch    80 | loss: 83.8645378CurrentTrain: epoch  4, batch    81 | loss: 77.4806463CurrentTrain: epoch  4, batch    82 | loss: 65.5774581CurrentTrain: epoch  4, batch    83 | loss: 81.5596010CurrentTrain: epoch  4, batch    84 | loss: 100.1039498CurrentTrain: epoch  4, batch    85 | loss: 67.8264197CurrentTrain: epoch  4, batch    86 | loss: 173.5641219CurrentTrain: epoch  4, batch    87 | loss: 102.0372516CurrentTrain: epoch  4, batch    88 | loss: 81.9587609CurrentTrain: epoch  4, batch    89 | loss: 70.3871296CurrentTrain: epoch  4, batch    90 | loss: 84.2891884CurrentTrain: epoch  4, batch    91 | loss: 69.6501263CurrentTrain: epoch  4, batch    92 | loss: 98.9243448CurrentTrain: epoch  4, batch    93 | loss: 79.9125088CurrentTrain: epoch  4, batch    94 | loss: 84.3513454CurrentTrain: epoch  4, batch    95 | loss: 85.2033400CurrentTrain: epoch  5, batch     0 | loss: 64.5870735CurrentTrain: epoch  5, batch     1 | loss: 80.0834629CurrentTrain: epoch  5, batch     2 | loss: 70.1382567CurrentTrain: epoch  5, batch     3 | loss: 82.3765388CurrentTrain: epoch  5, batch     4 | loss: 99.1046434CurrentTrain: epoch  5, batch     5 | loss: 167.1437934CurrentTrain: epoch  5, batch     6 | loss: 130.0944522CurrentTrain: epoch  5, batch     7 | loss: 96.0848614CurrentTrain: epoch  5, batch     8 | loss: 82.7317385CurrentTrain: epoch  5, batch     9 | loss: 170.7896318CurrentTrain: epoch  5, batch    10 | loss: 95.9882508CurrentTrain: epoch  5, batch    11 | loss: 64.9031936CurrentTrain: epoch  5, batch    12 | loss: 99.0208929CurrentTrain: epoch  5, batch    13 | loss: 79.9959585CurrentTrain: epoch  5, batch    14 | loss: 84.7670580CurrentTrain: epoch  5, batch    15 | loss: 79.6990762CurrentTrain: epoch  5, batch    16 | loss: 85.5517728CurrentTrain: epoch  5, batch    17 | loss: 84.3852429CurrentTrain: epoch  5, batch    18 | loss: 81.3687950CurrentTrain: epoch  5, batch    19 | loss: 76.4575266CurrentTrain: epoch  5, batch    20 | loss: 84.3721564CurrentTrain: epoch  5, batch    21 | loss: 101.8199774CurrentTrain: epoch  5, batch    22 | loss: 96.1619690CurrentTrain: epoch  5, batch    23 | loss: 81.1084455CurrentTrain: epoch  5, batch    24 | loss: 102.6126718CurrentTrain: epoch  5, batch    25 | loss: 57.8030352CurrentTrain: epoch  5, batch    26 | loss: 71.3746172CurrentTrain: epoch  5, batch    27 | loss: 82.2635222CurrentTrain: epoch  5, batch    28 | loss: 64.1695942CurrentTrain: epoch  5, batch    29 | loss: 66.2471245CurrentTrain: epoch  5, batch    30 | loss: 56.9367631CurrentTrain: epoch  5, batch    31 | loss: 67.0069011CurrentTrain: epoch  5, batch    32 | loss: 72.7955941CurrentTrain: epoch  5, batch    33 | loss: 81.9859021CurrentTrain: epoch  5, batch    34 | loss: 77.4022105CurrentTrain: epoch  5, batch    35 | loss: 80.0696689CurrentTrain: epoch  5, batch    36 | loss: 93.0760237CurrentTrain: epoch  5, batch    37 | loss: 99.2559162CurrentTrain: epoch  5, batch    38 | loss: 83.6504488CurrentTrain: epoch  5, batch    39 | loss: 69.0865496CurrentTrain: epoch  5, batch    40 | loss: 58.8764941CurrentTrain: epoch  5, batch    41 | loss: 121.8263882CurrentTrain: epoch  5, batch    42 | loss: 88.8541872CurrentTrain: epoch  5, batch    43 | loss: 81.6075193CurrentTrain: epoch  5, batch    44 | loss: 95.7517124CurrentTrain: epoch  5, batch    45 | loss: 99.5297480CurrentTrain: epoch  5, batch    46 | loss: 83.5434804CurrentTrain: epoch  5, batch    47 | loss: 55.9330379CurrentTrain: epoch  5, batch    48 | loss: 81.6498381CurrentTrain: epoch  5, batch    49 | loss: 96.8261708CurrentTrain: epoch  5, batch    50 | loss: 84.7683342CurrentTrain: epoch  5, batch    51 | loss: 84.8445512CurrentTrain: epoch  5, batch    52 | loss: 97.9809560CurrentTrain: epoch  5, batch    53 | loss: 126.7028322CurrentTrain: epoch  5, batch    54 | loss: 83.7133892CurrentTrain: epoch  5, batch    55 | loss: 81.1626857CurrentTrain: epoch  5, batch    56 | loss: 82.7176132CurrentTrain: epoch  5, batch    57 | loss: 69.0986531CurrentTrain: epoch  5, batch    58 | loss: 99.5199159CurrentTrain: epoch  5, batch    59 | loss: 129.1787995CurrentTrain: epoch  5, batch    60 | loss: 80.0136610CurrentTrain: epoch  5, batch    61 | loss: 90.2404780CurrentTrain: epoch  5, batch    62 | loss: 98.3325513CurrentTrain: epoch  5, batch    63 | loss: 70.4690251CurrentTrain: epoch  5, batch    64 | loss: 83.5242288CurrentTrain: epoch  5, batch    65 | loss: 78.6947369CurrentTrain: epoch  5, batch    66 | loss: 69.6295812CurrentTrain: epoch  5, batch    67 | loss: 81.2471394CurrentTrain: epoch  5, batch    68 | loss: 71.6623240CurrentTrain: epoch  5, batch    69 | loss: 79.0996112CurrentTrain: epoch  5, batch    70 | loss: 100.1518357CurrentTrain: epoch  5, batch    71 | loss: 82.8907717CurrentTrain: epoch  5, batch    72 | loss: 67.5050794CurrentTrain: epoch  5, batch    73 | loss: 98.9874990CurrentTrain: epoch  5, batch    74 | loss: 78.0099141CurrentTrain: epoch  5, batch    75 | loss: 123.7387190CurrentTrain: epoch  5, batch    76 | loss: 60.7463676CurrentTrain: epoch  5, batch    77 | loss: 123.5623355CurrentTrain: epoch  5, batch    78 | loss: 98.5901416CurrentTrain: epoch  5, batch    79 | loss: 81.1604019CurrentTrain: epoch  5, batch    80 | loss: 79.5608250CurrentTrain: epoch  5, batch    81 | loss: 85.0986605CurrentTrain: epoch  5, batch    82 | loss: 69.5412368CurrentTrain: epoch  5, batch    83 | loss: 96.9275420CurrentTrain: epoch  5, batch    84 | loss: 81.7938350CurrentTrain: epoch  5, batch    85 | loss: 67.2171671CurrentTrain: epoch  5, batch    86 | loss: 83.5646057CurrentTrain: epoch  5, batch    87 | loss: 97.2925157CurrentTrain: epoch  5, batch    88 | loss: 130.8481294CurrentTrain: epoch  5, batch    89 | loss: 65.3729365CurrentTrain: epoch  5, batch    90 | loss: 79.8682091CurrentTrain: epoch  5, batch    91 | loss: 68.6390588CurrentTrain: epoch  5, batch    92 | loss: 101.1843213CurrentTrain: epoch  5, batch    93 | loss: 57.1588118CurrentTrain: epoch  5, batch    94 | loss: 70.5102692CurrentTrain: epoch  5, batch    95 | loss: 84.3208637CurrentTrain: epoch  6, batch     0 | loss: 77.5771597CurrentTrain: epoch  6, batch     1 | loss: 82.0484083CurrentTrain: epoch  6, batch     2 | loss: 96.6747771CurrentTrain: epoch  6, batch     3 | loss: 68.1614335CurrentTrain: epoch  6, batch     4 | loss: 56.5327905CurrentTrain: epoch  6, batch     5 | loss: 76.8682663CurrentTrain: epoch  6, batch     6 | loss: 80.9046432CurrentTrain: epoch  6, batch     7 | loss: 78.5187999CurrentTrain: epoch  6, batch     8 | loss: 82.2041133CurrentTrain: epoch  6, batch     9 | loss: 98.6211274CurrentTrain: epoch  6, batch    10 | loss: 68.5051611CurrentTrain: epoch  6, batch    11 | loss: 60.2243531CurrentTrain: epoch  6, batch    12 | loss: 119.9380262CurrentTrain: epoch  6, batch    13 | loss: 81.3244632CurrentTrain: epoch  6, batch    14 | loss: 96.3108110CurrentTrain: epoch  6, batch    15 | loss: 70.1800112CurrentTrain: epoch  6, batch    16 | loss: 55.8145847CurrentTrain: epoch  6, batch    17 | loss: 79.2195444CurrentTrain: epoch  6, batch    18 | loss: 65.8565085CurrentTrain: epoch  6, batch    19 | loss: 97.1263112CurrentTrain: epoch  6, batch    20 | loss: 62.3936655CurrentTrain: epoch  6, batch    21 | loss: 78.3681409CurrentTrain: epoch  6, batch    22 | loss: 67.7861173CurrentTrain: epoch  6, batch    23 | loss: 57.8327137CurrentTrain: epoch  6, batch    24 | loss: 84.7572547CurrentTrain: epoch  6, batch    25 | loss: 58.6826496CurrentTrain: epoch  6, batch    26 | loss: 56.9198251CurrentTrain: epoch  6, batch    27 | loss: 80.5766271CurrentTrain: epoch  6, batch    28 | loss: 65.4459327CurrentTrain: epoch  6, batch    29 | loss: 94.3757484CurrentTrain: epoch  6, batch    30 | loss: 80.1169381CurrentTrain: epoch  6, batch    31 | loss: 66.9439492CurrentTrain: epoch  6, batch    32 | loss: 128.5280095CurrentTrain: epoch  6, batch    33 | loss: 77.5529908CurrentTrain: epoch  6, batch    34 | loss: 100.7178422CurrentTrain: epoch  6, batch    35 | loss: 58.0900357CurrentTrain: epoch  6, batch    36 | loss: 82.3346580CurrentTrain: epoch  6, batch    37 | loss: 61.0659122CurrentTrain: epoch  6, batch    38 | loss: 80.0357236CurrentTrain: epoch  6, batch    39 | loss: 97.9423125CurrentTrain: epoch  6, batch    40 | loss: 82.4381527CurrentTrain: epoch  6, batch    41 | loss: 79.8306892CurrentTrain: epoch  6, batch    42 | loss: 104.9529254CurrentTrain: epoch  6, batch    43 | loss: 79.3926649CurrentTrain: epoch  6, batch    44 | loss: 98.3831243CurrentTrain: epoch  6, batch    45 | loss: 123.3665412CurrentTrain: epoch  6, batch    46 | loss: 82.9554775CurrentTrain: epoch  6, batch    47 | loss: 173.1903308CurrentTrain: epoch  6, batch    48 | loss: 171.8275270CurrentTrain: epoch  6, batch    49 | loss: 173.4953340CurrentTrain: epoch  6, batch    50 | loss: 58.2049516CurrentTrain: epoch  6, batch    51 | loss: 82.8063292CurrentTrain: epoch  6, batch    52 | loss: 94.4160295CurrentTrain: epoch  6, batch    53 | loss: 99.0074826CurrentTrain: epoch  6, batch    54 | loss: 66.5912506CurrentTrain: epoch  6, batch    55 | loss: 59.0967991CurrentTrain: epoch  6, batch    56 | loss: 77.6224073CurrentTrain: epoch  6, batch    57 | loss: 83.0740842CurrentTrain: epoch  6, batch    58 | loss: 64.4496545CurrentTrain: epoch  6, batch    59 | loss: 100.5810263CurrentTrain: epoch  6, batch    60 | loss: 70.6088657CurrentTrain: epoch  6, batch    61 | loss: 79.6389341CurrentTrain: epoch  6, batch    62 | loss: 99.8016907CurrentTrain: epoch  6, batch    63 | loss: 57.2980766CurrentTrain: epoch  6, batch    64 | loss: 82.4126939CurrentTrain: epoch  6, batch    65 | loss: 56.1926013CurrentTrain: epoch  6, batch    66 | loss: 69.8815572CurrentTrain: epoch  6, batch    67 | loss: 68.3925726CurrentTrain: epoch  6, batch    68 | loss: 66.4845926CurrentTrain: epoch  6, batch    69 | loss: 62.7263168CurrentTrain: epoch  6, batch    70 | loss: 78.4690156CurrentTrain: epoch  6, batch    71 | loss: 81.8235506CurrentTrain: epoch  6, batch    72 | loss: 103.1819618CurrentTrain: epoch  6, batch    73 | loss: 54.9308588CurrentTrain: epoch  6, batch    74 | loss: 128.5959723CurrentTrain: epoch  6, batch    75 | loss: 67.6359958CurrentTrain: epoch  6, batch    76 | loss: 85.2121092CurrentTrain: epoch  6, batch    77 | loss: 98.3048465CurrentTrain: epoch  6, batch    78 | loss: 82.7245634CurrentTrain: epoch  6, batch    79 | loss: 79.5959504CurrentTrain: epoch  6, batch    80 | loss: 66.6485987CurrentTrain: epoch  6, batch    81 | loss: 103.8888635CurrentTrain: epoch  6, batch    82 | loss: 76.2727089CurrentTrain: epoch  6, batch    83 | loss: 177.2996572CurrentTrain: epoch  6, batch    84 | loss: 81.7595678CurrentTrain: epoch  6, batch    85 | loss: 81.2946532CurrentTrain: epoch  6, batch    86 | loss: 125.8520612CurrentTrain: epoch  6, batch    87 | loss: 80.0038659CurrentTrain: epoch  6, batch    88 | loss: 55.9854613CurrentTrain: epoch  6, batch    89 | loss: 69.2175482CurrentTrain: epoch  6, batch    90 | loss: 75.9584622CurrentTrain: epoch  6, batch    91 | loss: 97.5274813CurrentTrain: epoch  6, batch    92 | loss: 80.6766096CurrentTrain: epoch  6, batch    93 | loss: 98.7897467CurrentTrain: epoch  6, batch    94 | loss: 54.1561129CurrentTrain: epoch  6, batch    95 | loss: 82.2193854CurrentTrain: epoch  7, batch     0 | loss: 65.6556006CurrentTrain: epoch  7, batch     1 | loss: 55.4724732CurrentTrain: epoch  7, batch     2 | loss: 98.1676224CurrentTrain: epoch  7, batch     3 | loss: 95.3377515CurrentTrain: epoch  7, batch     4 | loss: 79.3135106CurrentTrain: epoch  7, batch     5 | loss: 77.2728600CurrentTrain: epoch  7, batch     6 | loss: 72.6053037CurrentTrain: epoch  7, batch     7 | loss: 96.4724678CurrentTrain: epoch  7, batch     8 | loss: 122.5177161CurrentTrain: epoch  7, batch     9 | loss: 79.9561230CurrentTrain: epoch  7, batch    10 | loss: 76.3327466CurrentTrain: epoch  7, batch    11 | loss: 97.1781315CurrentTrain: epoch  7, batch    12 | loss: 57.2860598CurrentTrain: epoch  7, batch    13 | loss: 80.2848280CurrentTrain: epoch  7, batch    14 | loss: 65.6442427CurrentTrain: epoch  7, batch    15 | loss: 81.0528075CurrentTrain: epoch  7, batch    16 | loss: 77.7741240CurrentTrain: epoch  7, batch    17 | loss: 99.5444479CurrentTrain: epoch  7, batch    18 | loss: 75.8889096CurrentTrain: epoch  7, batch    19 | loss: 93.9202004CurrentTrain: epoch  7, batch    20 | loss: 98.3823111CurrentTrain: epoch  7, batch    21 | loss: 126.5295260CurrentTrain: epoch  7, batch    22 | loss: 96.4063031CurrentTrain: epoch  7, batch    23 | loss: 69.1395395CurrentTrain: epoch  7, batch    24 | loss: 57.7883065CurrentTrain: epoch  7, batch    25 | loss: 84.8901937CurrentTrain: epoch  7, batch    26 | loss: 96.3081428CurrentTrain: epoch  7, batch    27 | loss: 98.5865061CurrentTrain: epoch  7, batch    28 | loss: 66.6749247CurrentTrain: epoch  7, batch    29 | loss: 99.5444926CurrentTrain: epoch  7, batch    30 | loss: 66.4065527CurrentTrain: epoch  7, batch    31 | loss: 57.5807997CurrentTrain: epoch  7, batch    32 | loss: 127.3595316CurrentTrain: epoch  7, batch    33 | loss: 64.1659678CurrentTrain: epoch  7, batch    34 | loss: 63.8217964CurrentTrain: epoch  7, batch    35 | loss: 124.0681618CurrentTrain: epoch  7, batch    36 | loss: 100.0660071CurrentTrain: epoch  7, batch    37 | loss: 59.2192426CurrentTrain: epoch  7, batch    38 | loss: 54.4451923CurrentTrain: epoch  7, batch    39 | loss: 94.5668337CurrentTrain: epoch  7, batch    40 | loss: 81.9084093CurrentTrain: epoch  7, batch    41 | loss: 66.9465169CurrentTrain: epoch  7, batch    42 | loss: 93.2290408CurrentTrain: epoch  7, batch    43 | loss: 100.4087464CurrentTrain: epoch  7, batch    44 | loss: 99.4752293CurrentTrain: epoch  7, batch    45 | loss: 64.8391233CurrentTrain: epoch  7, batch    46 | loss: 67.2011225CurrentTrain: epoch  7, batch    47 | loss: 99.0373347CurrentTrain: epoch  7, batch    48 | loss: 64.3872083CurrentTrain: epoch  7, batch    49 | loss: 68.7460740CurrentTrain: epoch  7, batch    50 | loss: 99.2795202CurrentTrain: epoch  7, batch    51 | loss: 101.7851185CurrentTrain: epoch  7, batch    52 | loss: 65.7001544CurrentTrain: epoch  7, batch    53 | loss: 124.7386496CurrentTrain: epoch  7, batch    54 | loss: 58.9280737CurrentTrain: epoch  7, batch    55 | loss: 55.8362497CurrentTrain: epoch  7, batch    56 | loss: 59.3466450CurrentTrain: epoch  7, batch    57 | loss: 79.9067988CurrentTrain: epoch  7, batch    58 | loss: 66.0363962CurrentTrain: epoch  7, batch    59 | loss: 80.6487483CurrentTrain: epoch  7, batch    60 | loss: 81.0841815CurrentTrain: epoch  7, batch    61 | loss: 78.0851470CurrentTrain: epoch  7, batch    62 | loss: 59.9201390CurrentTrain: epoch  7, batch    63 | loss: 79.6162604CurrentTrain: epoch  7, batch    64 | loss: 97.9405362CurrentTrain: epoch  7, batch    65 | loss: 97.1470399CurrentTrain: epoch  7, batch    66 | loss: 76.6034100CurrentTrain: epoch  7, batch    67 | loss: 92.1466533CurrentTrain: epoch  7, batch    68 | loss: 100.3813583CurrentTrain: epoch  7, batch    69 | loss: 98.4042604CurrentTrain: epoch  7, batch    70 | loss: 65.6046035CurrentTrain: epoch  7, batch    71 | loss: 99.2430117CurrentTrain: epoch  7, batch    72 | loss: 78.1257468CurrentTrain: epoch  7, batch    73 | loss: 79.4607202CurrentTrain: epoch  7, batch    74 | loss: 93.6987375CurrentTrain: epoch  7, batch    75 | loss: 68.8355813CurrentTrain: epoch  7, batch    76 | loss: 77.3043059CurrentTrain: epoch  7, batch    77 | loss: 97.7307247CurrentTrain: epoch  7, batch    78 | loss: 97.1919584CurrentTrain: epoch  7, batch    79 | loss: 83.4504540CurrentTrain: epoch  7, batch    80 | loss: 65.7101257CurrentTrain: epoch  7, batch    81 | loss: 82.1985493CurrentTrain: epoch  7, batch    82 | loss: 99.7943683CurrentTrain: epoch  7, batch    83 | loss: 64.8768173CurrentTrain: epoch  7, batch    84 | loss: 65.1126098CurrentTrain: epoch  7, batch    85 | loss: 98.7045088CurrentTrain: epoch  7, batch    86 | loss: 78.5244542CurrentTrain: epoch  7, batch    87 | loss: 97.5722039CurrentTrain: epoch  7, batch    88 | loss: 100.7800393CurrentTrain: epoch  7, batch    89 | loss: 93.3085399CurrentTrain: epoch  7, batch    90 | loss: 79.1755971CurrentTrain: epoch  7, batch    91 | loss: 99.8671110CurrentTrain: epoch  7, batch    92 | loss: 77.1925647CurrentTrain: epoch  7, batch    93 | loss: 79.8273904CurrentTrain: epoch  7, batch    94 | loss: 93.1683885CurrentTrain: epoch  7, batch    95 | loss: 62.6879073CurrentTrain: epoch  8, batch     0 | loss: 79.0196182CurrentTrain: epoch  8, batch     1 | loss: 67.8064471CurrentTrain: epoch  8, batch     2 | loss: 69.3255216CurrentTrain: epoch  8, batch     3 | loss: 125.0568370CurrentTrain: epoch  8, batch     4 | loss: 76.2190017CurrentTrain: epoch  8, batch     5 | loss: 75.3462899CurrentTrain: epoch  8, batch     6 | loss: 62.3139069CurrentTrain: epoch  8, batch     7 | loss: 55.9175999CurrentTrain: epoch  8, batch     8 | loss: 57.2770185CurrentTrain: epoch  8, batch     9 | loss: 67.7704389CurrentTrain: epoch  8, batch    10 | loss: 98.1038504CurrentTrain: epoch  8, batch    11 | loss: 66.3010995CurrentTrain: epoch  8, batch    12 | loss: 80.6143590CurrentTrain: epoch  8, batch    13 | loss: 80.0074269CurrentTrain: epoch  8, batch    14 | loss: 80.5800801CurrentTrain: epoch  8, batch    15 | loss: 118.4325576CurrentTrain: epoch  8, batch    16 | loss: 123.0657992CurrentTrain: epoch  8, batch    17 | loss: 60.1360650CurrentTrain: epoch  8, batch    18 | loss: 65.0490554CurrentTrain: epoch  8, batch    19 | loss: 54.3654077CurrentTrain: epoch  8, batch    20 | loss: 64.4238377CurrentTrain: epoch  8, batch    21 | loss: 94.3643292CurrentTrain: epoch  8, batch    22 | loss: 77.9376870CurrentTrain: epoch  8, batch    23 | loss: 94.7699145CurrentTrain: epoch  8, batch    24 | loss: 125.3449016CurrentTrain: epoch  8, batch    25 | loss: 63.4103445CurrentTrain: epoch  8, batch    26 | loss: 76.2293767CurrentTrain: epoch  8, batch    27 | loss: 51.7034083CurrentTrain: epoch  8, batch    28 | loss: 77.8381808CurrentTrain: epoch  8, batch    29 | loss: 65.2633155CurrentTrain: epoch  8, batch    30 | loss: 126.9889281CurrentTrain: epoch  8, batch    31 | loss: 93.9993437CurrentTrain: epoch  8, batch    32 | loss: 75.6983160CurrentTrain: epoch  8, batch    33 | loss: 79.2840619CurrentTrain: epoch  8, batch    34 | loss: 78.4697114CurrentTrain: epoch  8, batch    35 | loss: 63.3010269CurrentTrain: epoch  8, batch    36 | loss: 76.2771866CurrentTrain: epoch  8, batch    37 | loss: 68.2981276CurrentTrain: epoch  8, batch    38 | loss: 73.3370852CurrentTrain: epoch  8, batch    39 | loss: 101.8970321CurrentTrain: epoch  8, batch    40 | loss: 67.9187362CurrentTrain: epoch  8, batch    41 | loss: 118.8088106CurrentTrain: epoch  8, batch    42 | loss: 81.8167648CurrentTrain: epoch  8, batch    43 | loss: 57.5022979CurrentTrain: epoch  8, batch    44 | loss: 56.3676690CurrentTrain: epoch  8, batch    45 | loss: 82.7930486CurrentTrain: epoch  8, batch    46 | loss: 123.7560973CurrentTrain: epoch  8, batch    47 | loss: 100.5343344CurrentTrain: epoch  8, batch    48 | loss: 54.1387236CurrentTrain: epoch  8, batch    49 | loss: 66.8051647CurrentTrain: epoch  8, batch    50 | loss: 59.9676069CurrentTrain: epoch  8, batch    51 | loss: 66.6636376CurrentTrain: epoch  8, batch    52 | loss: 76.6895202CurrentTrain: epoch  8, batch    53 | loss: 64.3979527CurrentTrain: epoch  8, batch    54 | loss: 91.3495152CurrentTrain: epoch  8, batch    55 | loss: 264.2950016CurrentTrain: epoch  8, batch    56 | loss: 77.7687784CurrentTrain: epoch  8, batch    57 | loss: 115.9114838CurrentTrain: epoch  8, batch    58 | loss: 76.2008763CurrentTrain: epoch  8, batch    59 | loss: 64.8565375CurrentTrain: epoch  8, batch    60 | loss: 80.4878050CurrentTrain: epoch  8, batch    61 | loss: 65.2157065CurrentTrain: epoch  8, batch    62 | loss: 78.2083676CurrentTrain: epoch  8, batch    63 | loss: 95.6437523CurrentTrain: epoch  8, batch    64 | loss: 77.8296907CurrentTrain: epoch  8, batch    65 | loss: 123.0076704CurrentTrain: epoch  8, batch    66 | loss: 81.8711989CurrentTrain: epoch  8, batch    67 | loss: 75.9232280CurrentTrain: epoch  8, batch    68 | loss: 123.7729656CurrentTrain: epoch  8, batch    69 | loss: 59.9429539CurrentTrain: epoch  8, batch    70 | loss: 125.6040758CurrentTrain: epoch  8, batch    71 | loss: 77.8089161CurrentTrain: epoch  8, batch    72 | loss: 61.8100124CurrentTrain: epoch  8, batch    73 | loss: 92.4869609CurrentTrain: epoch  8, batch    74 | loss: 81.5267608CurrentTrain: epoch  8, batch    75 | loss: 95.9206140CurrentTrain: epoch  8, batch    76 | loss: 65.4267927CurrentTrain: epoch  8, batch    77 | loss: 97.4000195CurrentTrain: epoch  8, batch    78 | loss: 168.3262909CurrentTrain: epoch  8, batch    79 | loss: 75.1340469CurrentTrain: epoch  8, batch    80 | loss: 124.0499465CurrentTrain: epoch  8, batch    81 | loss: 73.3347601CurrentTrain: epoch  8, batch    82 | loss: 66.9865810CurrentTrain: epoch  8, batch    83 | loss: 73.9861456CurrentTrain: epoch  8, batch    84 | loss: 96.9878818CurrentTrain: epoch  8, batch    85 | loss: 78.3786010CurrentTrain: epoch  8, batch    86 | loss: 124.2146005CurrentTrain: epoch  8, batch    87 | loss: 76.8899223CurrentTrain: epoch  8, batch    88 | loss: 70.4012176CurrentTrain: epoch  8, batch    89 | loss: 81.4444192CurrentTrain: epoch  8, batch    90 | loss: 96.1873973CurrentTrain: epoch  8, batch    91 | loss: 80.2294884CurrentTrain: epoch  8, batch    92 | loss: 77.7721006CurrentTrain: epoch  8, batch    93 | loss: 97.7633419CurrentTrain: epoch  8, batch    94 | loss: 79.6747231CurrentTrain: epoch  8, batch    95 | loss: 53.5626082CurrentTrain: epoch  9, batch     0 | loss: 77.0852124CurrentTrain: epoch  9, batch     1 | loss: 80.4420003CurrentTrain: epoch  9, batch     2 | loss: 97.3459706CurrentTrain: epoch  9, batch     3 | loss: 123.0990540CurrentTrain: epoch  9, batch     4 | loss: 66.3191077CurrentTrain: epoch  9, batch     5 | loss: 63.4336205CurrentTrain: epoch  9, batch     6 | loss: 64.5620127CurrentTrain: epoch  9, batch     7 | loss: 56.2825677CurrentTrain: epoch  9, batch     8 | loss: 63.1625688CurrentTrain: epoch  9, batch     9 | loss: 94.9490831CurrentTrain: epoch  9, batch    10 | loss: 93.5627736CurrentTrain: epoch  9, batch    11 | loss: 55.5705061CurrentTrain: epoch  9, batch    12 | loss: 98.4532205CurrentTrain: epoch  9, batch    13 | loss: 62.2677691CurrentTrain: epoch  9, batch    14 | loss: 76.0326755CurrentTrain: epoch  9, batch    15 | loss: 169.0706320CurrentTrain: epoch  9, batch    16 | loss: 68.5475631CurrentTrain: epoch  9, batch    17 | loss: 74.4764930CurrentTrain: epoch  9, batch    18 | loss: 62.3414365CurrentTrain: epoch  9, batch    19 | loss: 164.4181167CurrentTrain: epoch  9, batch    20 | loss: 66.8208482CurrentTrain: epoch  9, batch    21 | loss: 94.4009671CurrentTrain: epoch  9, batch    22 | loss: 58.5197024CurrentTrain: epoch  9, batch    23 | loss: 89.8447599CurrentTrain: epoch  9, batch    24 | loss: 76.9073982CurrentTrain: epoch  9, batch    25 | loss: 80.8525094CurrentTrain: epoch  9, batch    26 | loss: 66.1544020CurrentTrain: epoch  9, batch    27 | loss: 123.9814630CurrentTrain: epoch  9, batch    28 | loss: 74.7425728CurrentTrain: epoch  9, batch    29 | loss: 93.4520631CurrentTrain: epoch  9, batch    30 | loss: 77.5086523CurrentTrain: epoch  9, batch    31 | loss: 61.4788184CurrentTrain: epoch  9, batch    32 | loss: 99.9228627CurrentTrain: epoch  9, batch    33 | loss: 99.9141718CurrentTrain: epoch  9, batch    34 | loss: 72.3897430CurrentTrain: epoch  9, batch    35 | loss: 124.5011666CurrentTrain: epoch  9, batch    36 | loss: 61.4645445CurrentTrain: epoch  9, batch    37 | loss: 79.2561912CurrentTrain: epoch  9, batch    38 | loss: 67.9091273CurrentTrain: epoch  9, batch    39 | loss: 76.9654372CurrentTrain: epoch  9, batch    40 | loss: 91.2950694CurrentTrain: epoch  9, batch    41 | loss: 59.3805095CurrentTrain: epoch  9, batch    42 | loss: 92.4105096CurrentTrain: epoch  9, batch    43 | loss: 94.3773472CurrentTrain: epoch  9, batch    44 | loss: 122.9062459CurrentTrain: epoch  9, batch    45 | loss: 74.6463004CurrentTrain: epoch  9, batch    46 | loss: 81.2232041CurrentTrain: epoch  9, batch    47 | loss: 99.1992929CurrentTrain: epoch  9, batch    48 | loss: 126.1435116CurrentTrain: epoch  9, batch    49 | loss: 75.5838743CurrentTrain: epoch  9, batch    50 | loss: 79.1468290CurrentTrain: epoch  9, batch    51 | loss: 57.0197061CurrentTrain: epoch  9, batch    52 | loss: 64.6093497CurrentTrain: epoch  9, batch    53 | loss: 67.6106404CurrentTrain: epoch  9, batch    54 | loss: 98.2121024CurrentTrain: epoch  9, batch    55 | loss: 57.6617724CurrentTrain: epoch  9, batch    56 | loss: 96.6613627CurrentTrain: epoch  9, batch    57 | loss: 62.1098901CurrentTrain: epoch  9, batch    58 | loss: 69.0216145CurrentTrain: epoch  9, batch    59 | loss: 90.1501823CurrentTrain: epoch  9, batch    60 | loss: 62.2961590CurrentTrain: epoch  9, batch    61 | loss: 75.2286801CurrentTrain: epoch  9, batch    62 | loss: 75.1537482CurrentTrain: epoch  9, batch    63 | loss: 74.7038702CurrentTrain: epoch  9, batch    64 | loss: 64.3997302CurrentTrain: epoch  9, batch    65 | loss: 53.7453494CurrentTrain: epoch  9, batch    66 | loss: 92.0887409CurrentTrain: epoch  9, batch    67 | loss: 75.5517476CurrentTrain: epoch  9, batch    68 | loss: 78.6214321CurrentTrain: epoch  9, batch    69 | loss: 77.0216831CurrentTrain: epoch  9, batch    70 | loss: 66.1161781CurrentTrain: epoch  9, batch    71 | loss: 124.7558934CurrentTrain: epoch  9, batch    72 | loss: 120.9707890CurrentTrain: epoch  9, batch    73 | loss: 95.8885162CurrentTrain: epoch  9, batch    74 | loss: 77.0217739CurrentTrain: epoch  9, batch    75 | loss: 90.0076520CurrentTrain: epoch  9, batch    76 | loss: 76.7846850CurrentTrain: epoch  9, batch    77 | loss: 57.9256089CurrentTrain: epoch  9, batch    78 | loss: 75.6440973CurrentTrain: epoch  9, batch    79 | loss: 67.9447523CurrentTrain: epoch  9, batch    80 | loss: 77.2173155CurrentTrain: epoch  9, batch    81 | loss: 65.1971056CurrentTrain: epoch  9, batch    82 | loss: 69.2767458CurrentTrain: epoch  9, batch    83 | loss: 75.9492562CurrentTrain: epoch  9, batch    84 | loss: 95.5158769CurrentTrain: epoch  9, batch    85 | loss: 101.7305398CurrentTrain: epoch  9, batch    86 | loss: 66.2817656CurrentTrain: epoch  9, batch    87 | loss: 64.8491549CurrentTrain: epoch  9, batch    88 | loss: 94.7519903CurrentTrain: epoch  9, batch    89 | loss: 78.2243146CurrentTrain: epoch  9, batch    90 | loss: 80.5225312CurrentTrain: epoch  9, batch    91 | loss: 64.5785940CurrentTrain: epoch  9, batch    92 | loss: 78.2174178CurrentTrain: epoch  9, batch    93 | loss: 78.6828375CurrentTrain: epoch  9, batch    94 | loss: 78.7596507CurrentTrain: epoch  9, batch    95 | loss: 81.9864184

F1 score per class: {32: np.float64(0.5863874345549738), 6: np.float64(0.8110599078341014), 19: np.float64(0.3888888888888889), 24: np.float64(0.73224043715847), 26: np.float64(0.9333333333333333), 29: np.float64(0.8557692307692307)}
Micro-average F1 score: 0.7728155339805826
Weighted-average F1 score: 0.7756268860058381
F1 score per class: {32: np.float64(0.6454545454545455), 6: np.float64(0.7876106194690266), 19: np.float64(0.2692307692307692), 24: np.float64(0.7351351351351352), 26: np.float64(0.9458128078817734), 29: np.float64(0.8269230769230769)}
Micro-average F1 score: 0.7623400365630713
Weighted-average F1 score: 0.7553128952560597
F1 score per class: {32: np.float64(0.6572769953051644), 6: np.float64(0.7892376681614349), 19: np.float64(0.30434782608695654), 24: np.float64(0.7391304347826086), 26: np.float64(0.9504950495049505), 29: np.float64(0.8325358851674641)}
Micro-average F1 score: 0.7725162488393686
Weighted-average F1 score: 0.7686120498001298

F1 score per class: {32: np.float64(0.5863874345549738), 6: np.float64(0.8110599078341014), 19: np.float64(0.3888888888888889), 24: np.float64(0.73224043715847), 26: np.float64(0.9333333333333333), 29: np.float64(0.8557692307692307)}
Micro-average F1 score: 0.7728155339805826
Weighted-average F1 score: 0.7756268860058381
F1 score per class: {32: np.float64(0.6454545454545455), 6: np.float64(0.7876106194690266), 19: np.float64(0.2692307692307692), 24: np.float64(0.7351351351351352), 26: np.float64(0.9458128078817734), 29: np.float64(0.8269230769230769)}
Micro-average F1 score: 0.7623400365630713
Weighted-average F1 score: 0.7553128952560597
F1 score per class: {32: np.float64(0.6572769953051644), 6: np.float64(0.7892376681614349), 19: np.float64(0.30434782608695654), 24: np.float64(0.7391304347826086), 26: np.float64(0.9504950495049505), 29: np.float64(0.8325358851674641)}
Micro-average F1 score: 0.7725162488393686
Weighted-average F1 score: 0.7686120498001298

F1 score per class: {32: np.float64(0.4426877470355731), 6: np.float64(0.7457627118644068), 19: np.float64(0.208955223880597), 24: np.float64(0.6767676767676768), 26: np.float64(0.8625592417061612), 29: np.float64(0.6793893129770993)}
Micro-average F1 score: 0.6487367563162184
Weighted-average F1 score: 0.6368436346051588
F1 score per class: {32: np.float64(0.44654088050314467), 6: np.float64(0.714859437751004), 19: np.float64(0.1414141414141414), 24: np.float64(0.6766169154228856), 26: np.float64(0.8571428571428571), 29: np.float64(0.6564885496183206)}
Micro-average F1 score: 0.6164079822616408
Weighted-average F1 score: 0.594358899893083
F1 score per class: {32: np.float64(0.45454545454545453), 6: np.float64(0.7154471544715447), 19: np.float64(0.16279069767441862), 24: np.float64(0.6834170854271356), 26: np.float64(0.8687782805429864), 29: np.float64(0.6615969581749049)}
Micro-average F1 score: 0.6288737717309146
Weighted-average F1 score: 0.6095543777958481

F1 score per class: {32: np.float64(0.4426877470355731), 6: np.float64(0.7457627118644068), 19: np.float64(0.208955223880597), 24: np.float64(0.6767676767676768), 26: np.float64(0.8625592417061612), 29: np.float64(0.6793893129770993)}
Micro-average F1 score: 0.6487367563162184
Weighted-average F1 score: 0.6368436346051588
F1 score per class: {32: np.float64(0.44654088050314467), 6: np.float64(0.714859437751004), 19: np.float64(0.1414141414141414), 24: np.float64(0.6766169154228856), 26: np.float64(0.8571428571428571), 29: np.float64(0.6564885496183206)}
Micro-average F1 score: 0.6164079822616408
Weighted-average F1 score: 0.594358899893083
F1 score per class: {32: np.float64(0.45454545454545453), 6: np.float64(0.7154471544715447), 19: np.float64(0.16279069767441862), 24: np.float64(0.6834170854271356), 26: np.float64(0.8687782805429864), 29: np.float64(0.6615969581749049)}
Micro-average F1 score: 0.6288737717309146
Weighted-average F1 score: 0.6095543777958481
cur_acc_wo_na:  ['0.7728']
his_acc_wo_na:  ['0.7728']
cur_acc des_wo_na:  ['0.7623']
his_acc des_wo_na:  ['0.7623']
cur_acc rrf_wo_na:  ['0.7725']
his_acc rrf_wo_na:  ['0.7725']
cur_acc_w_na:  ['0.6487']
his_acc_w_na:  ['0.6487']
cur_acc des_w_na:  ['0.6164']
his_acc des_w_na:  ['0.6164']
cur_acc rrf_w_na:  ['0.6289']
his_acc rrf_w_na:  ['0.6289']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 81.5856491CurrentTrain: epoch  0, batch     1 | loss: 147.2237665CurrentTrain: epoch  0, batch     2 | loss: 76.1059019CurrentTrain: epoch  0, batch     3 | loss: 11.6010411CurrentTrain: epoch  1, batch     0 | loss: 85.5341336CurrentTrain: epoch  1, batch     1 | loss: 84.2078159CurrentTrain: epoch  1, batch     2 | loss: 84.6676626CurrentTrain: epoch  1, batch     3 | loss: 13.4411455CurrentTrain: epoch  2, batch     0 | loss: 70.9922236CurrentTrain: epoch  2, batch     1 | loss: 80.6100198CurrentTrain: epoch  2, batch     2 | loss: 70.4746020CurrentTrain: epoch  2, batch     3 | loss: 10.2044084CurrentTrain: epoch  3, batch     0 | loss: 80.1995033CurrentTrain: epoch  3, batch     1 | loss: 84.9037037CurrentTrain: epoch  3, batch     2 | loss: 66.0714745CurrentTrain: epoch  3, batch     3 | loss: 20.9149538CurrentTrain: epoch  4, batch     0 | loss: 80.2535880CurrentTrain: epoch  4, batch     1 | loss: 77.7280522CurrentTrain: epoch  4, batch     2 | loss: 76.2046821CurrentTrain: epoch  4, batch     3 | loss: 17.3735483CurrentTrain: epoch  5, batch     0 | loss: 78.1320201CurrentTrain: epoch  5, batch     1 | loss: 64.6021632CurrentTrain: epoch  5, batch     2 | loss: 66.7335419CurrentTrain: epoch  5, batch     3 | loss: 10.1422798CurrentTrain: epoch  6, batch     0 | loss: 65.5435326CurrentTrain: epoch  6, batch     1 | loss: 62.8941532CurrentTrain: epoch  6, batch     2 | loss: 64.8385386CurrentTrain: epoch  6, batch     3 | loss: 16.9924259CurrentTrain: epoch  7, batch     0 | loss: 64.5547144CurrentTrain: epoch  7, batch     1 | loss: 74.3654646CurrentTrain: epoch  7, batch     2 | loss: 89.7813010CurrentTrain: epoch  7, batch     3 | loss: 18.9353828CurrentTrain: epoch  8, batch     0 | loss: 60.2014681CurrentTrain: epoch  8, batch     1 | loss: 119.0248942CurrentTrain: epoch  8, batch     2 | loss: 62.8725426CurrentTrain: epoch  8, batch     3 | loss: 9.1495304CurrentTrain: epoch  9, batch     0 | loss: 62.1465438CurrentTrain: epoch  9, batch     1 | loss: 61.8419760CurrentTrain: epoch  9, batch     2 | loss: 75.9243971CurrentTrain: epoch  9, batch     3 | loss: 5.3758151
MemoryTrain:  epoch  0, batch     0 | loss: 2.0649283MemoryTrain:  epoch  1, batch     0 | loss: 1.7857315MemoryTrain:  epoch  2, batch     0 | loss: 1.5710185MemoryTrain:  epoch  3, batch     0 | loss: 1.2446939MemoryTrain:  epoch  4, batch     0 | loss: 1.0677661MemoryTrain:  epoch  5, batch     0 | loss: 0.9280548MemoryTrain:  epoch  6, batch     0 | loss: 0.7073654MemoryTrain:  epoch  7, batch     0 | loss: 0.5827239MemoryTrain:  epoch  8, batch     0 | loss: 0.5149052MemoryTrain:  epoch  9, batch     0 | loss: 0.4559878

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6666666666666666), 7: np.float64(0.7741935483870968), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.5), 26: np.float64(0.0), 27: np.float64(0.5), 29: np.float64(0.0), 31: np.float64(0.14754098360655737)}
Micro-average F1 score: 0.2828282828282828
Weighted-average F1 score: 0.23499916679429644
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6666666666666666), 7: np.float64(0.684931506849315), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.5714285714285714), 26: np.float64(0.0), 27: np.float64(0.8), 29: np.float64(0.0), 31: np.float64(0.21978021978021978)}
Micro-average F1 score: 0.3205574912891986
Weighted-average F1 score: 0.2710105266760584
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6666666666666666), 7: np.float64(0.746268656716418), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.47619047619047616), 26: np.float64(0.0), 27: np.float64(0.5), 29: np.float64(0.0), 31: np.float64(0.20618556701030927)}
Micro-average F1 score: 0.30985915492957744
Weighted-average F1 score: 0.2591328637933093

F1 score per class: {32: np.float64(0.42105263157894735), 6: np.float64(0.05), 7: np.float64(0.7741935483870968), 40: np.float64(0.6148409893992933), 9: np.float64(0.2962962962962963), 19: np.float64(0.6987951807228916), 24: np.float64(0.3448275862068966), 26: np.float64(0.93), 27: np.float64(0.2857142857142857), 29: np.float64(0.8269230769230769), 31: np.float64(0.06896551724137931)}
Micro-average F1 score: 0.5306930693069307
Weighted-average F1 score: 0.4749519866156842
F1 score per class: {32: np.float64(0.45751633986928103), 6: np.float64(0.06818181818181818), 7: np.float64(0.6329113924050633), 40: np.float64(0.5641025641025641), 9: np.float64(0.20833333333333334), 19: np.float64(0.723404255319149), 24: np.float64(0.375), 26: np.float64(0.9313725490196079), 27: np.float64(0.4), 29: np.float64(0.7960199004975125), 31: np.float64(0.13333333333333333)}
Micro-average F1 score: 0.5692832764505119
Weighted-average F1 score: 0.5419809929880927
F1 score per class: {32: np.float64(0.46153846153846156), 6: np.float64(0.06976744186046512), 7: np.float64(0.746268656716418), 40: np.float64(0.5686274509803921), 9: np.float64(0.2222222222222222), 19: np.float64(0.7351351351351352), 24: np.float64(0.30303030303030304), 26: np.float64(0.9405940594059405), 27: np.float64(0.25), 29: np.float64(0.7960199004975125), 31: np.float64(0.11627906976744186)}
Micro-average F1 score: 0.5702479338842975
Weighted-average F1 score: 0.5386711052155446

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.7272727272727273), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.45454545454545453), 26: np.float64(0.0), 27: np.float64(0.5), 29: np.float64(0.0), 31: np.float64(0.11920529801324503)}
Micro-average F1 score: 0.2420749279538905
Weighted-average F1 score: 0.2041882314030795
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.6024096385542169), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.5217391304347826), 26: np.float64(0.0), 27: np.float64(0.6666666666666666), 29: np.float64(0.0), 31: np.float64(0.20408163265306123)}
Micro-average F1 score: 0.2822085889570552
Weighted-average F1 score: 0.24454649220847496
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.6944444444444444), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.4166666666666667), 26: np.float64(0.0), 27: np.float64(0.4), 29: np.float64(0.0), 31: np.float64(0.18181818181818182)}
Micro-average F1 score: 0.2724458204334365
Weighted-average F1 score: 0.2337997196848872

F1 score per class: {32: np.float64(0.3004694835680751), 6: np.float64(0.03), 7: np.float64(0.7272727272727273), 40: np.float64(0.5780730897009967), 9: np.float64(0.24242424242424243), 19: np.float64(0.651685393258427), 24: np.float64(0.25), 26: np.float64(0.8532110091743119), 27: np.float64(0.2), 29: np.float64(0.6417910447761194), 31: np.float64(0.05142857142857143)}
Micro-average F1 score: 0.42834310069259457
Weighted-average F1 score: 0.37823865688541114
F1 score per class: {32: np.float64(0.32710280373831774), 6: np.float64(0.041379310344827586), 7: np.float64(0.5263157894736842), 40: np.float64(0.5176470588235295), 9: np.float64(0.13157894736842105), 19: np.float64(0.6666666666666666), 24: np.float64(0.27906976744186046), 26: np.float64(0.8482142857142857), 27: np.float64(0.2857142857142857), 29: np.float64(0.6274509803921569), 31: np.float64(0.11494252873563218)}
Micro-average F1 score: 0.4674887892376682
Weighted-average F1 score: 0.44011880627919897
F1 score per class: {32: np.float64(0.3287671232876712), 6: np.float64(0.04054054054054054), 7: np.float64(0.6944444444444444), 40: np.float64(0.5240963855421686), 9: np.float64(0.14285714285714285), 19: np.float64(0.6868686868686869), 24: np.float64(0.21739130434782608), 26: np.float64(0.8597285067873304), 27: np.float64(0.18181818181818182), 29: np.float64(0.625), 31: np.float64(0.09523809523809523)}
Micro-average F1 score: 0.46806105144149235
Weighted-average F1 score: 0.43540750142953283
cur_acc_wo_na:  ['0.7728', '0.2828']
his_acc_wo_na:  ['0.7728', '0.5307']
cur_acc des_wo_na:  ['0.7623', '0.3206']
his_acc des_wo_na:  ['0.7623', '0.5693']
cur_acc rrf_wo_na:  ['0.7725', '0.3099']
his_acc rrf_wo_na:  ['0.7725', '0.5702']
cur_acc_w_na:  ['0.6487', '0.2421']
his_acc_w_na:  ['0.6487', '0.4283']
cur_acc des_w_na:  ['0.6164', '0.2822']
his_acc des_w_na:  ['0.6164', '0.4675']
cur_acc rrf_w_na:  ['0.6289', '0.2724']
his_acc rrf_w_na:  ['0.6289', '0.4681']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 102.7740469CurrentTrain: epoch  0, batch     1 | loss: 105.0298123CurrentTrain: epoch  0, batch     2 | loss: 89.9345645CurrentTrain: epoch  0, batch     3 | loss: 94.6734783CurrentTrain: epoch  1, batch     0 | loss: 82.7009404CurrentTrain: epoch  1, batch     1 | loss: 107.5190993CurrentTrain: epoch  1, batch     2 | loss: 78.6241112CurrentTrain: epoch  1, batch     3 | loss: 144.8782201CurrentTrain: epoch  2, batch     0 | loss: 92.7071851CurrentTrain: epoch  2, batch     1 | loss: 130.1229957CurrentTrain: epoch  2, batch     2 | loss: 87.5878310CurrentTrain: epoch  2, batch     3 | loss: 67.9473640CurrentTrain: epoch  3, batch     0 | loss: 72.1615974CurrentTrain: epoch  3, batch     1 | loss: 133.5874904CurrentTrain: epoch  3, batch     2 | loss: 72.7275072CurrentTrain: epoch  3, batch     3 | loss: 58.7764602CurrentTrain: epoch  4, batch     0 | loss: 84.3193204CurrentTrain: epoch  4, batch     1 | loss: 86.0626905CurrentTrain: epoch  4, batch     2 | loss: 70.1589824CurrentTrain: epoch  4, batch     3 | loss: 84.8859864CurrentTrain: epoch  5, batch     0 | loss: 83.1649234CurrentTrain: epoch  5, batch     1 | loss: 78.8270074CurrentTrain: epoch  5, batch     2 | loss: 84.0806099CurrentTrain: epoch  5, batch     3 | loss: 78.5437358CurrentTrain: epoch  6, batch     0 | loss: 82.4698301CurrentTrain: epoch  6, batch     1 | loss: 95.6862029CurrentTrain: epoch  6, batch     2 | loss: 96.6022020CurrentTrain: epoch  6, batch     3 | loss: 65.0586405CurrentTrain: epoch  7, batch     0 | loss: 67.8716101CurrentTrain: epoch  7, batch     1 | loss: 97.8919205CurrentTrain: epoch  7, batch     2 | loss: 82.6768353CurrentTrain: epoch  7, batch     3 | loss: 61.2280964CurrentTrain: epoch  8, batch     0 | loss: 64.5072902CurrentTrain: epoch  8, batch     1 | loss: 95.5729090CurrentTrain: epoch  8, batch     2 | loss: 100.8474028CurrentTrain: epoch  8, batch     3 | loss: 77.0698151CurrentTrain: epoch  9, batch     0 | loss: 75.8482670CurrentTrain: epoch  9, batch     1 | loss: 121.0168242CurrentTrain: epoch  9, batch     2 | loss: 95.7323785CurrentTrain: epoch  9, batch     3 | loss: 53.6778595
MemoryTrain:  epoch  0, batch     0 | loss: 1.5583382MemoryTrain:  epoch  1, batch     0 | loss: 1.3294551MemoryTrain:  epoch  2, batch     0 | loss: 1.1107227MemoryTrain:  epoch  3, batch     0 | loss: 0.8925567MemoryTrain:  epoch  4, batch     0 | loss: 0.7039781MemoryTrain:  epoch  5, batch     0 | loss: 0.6189302MemoryTrain:  epoch  6, batch     0 | loss: 0.4998488MemoryTrain:  epoch  7, batch     0 | loss: 0.3994913MemoryTrain:  epoch  8, batch     0 | loss: 0.3953593MemoryTrain:  epoch  9, batch     0 | loss: 0.3512922

F1 score per class: {0: np.float64(0.9), 32: np.float64(0.9368421052631579), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.1), 40: np.float64(0.0), 13: np.float64(0.42990654205607476), 19: np.float64(0.7710843373493976), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.6408450704225352
Weighted-average F1 score: 0.5372061000417362
F1 score per class: {0: np.float64(0.7346938775510204), 32: np.float64(0.9543147208121827), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.14285714285714285), 9: np.float64(0.0), 13: np.float64(0.5681818181818182), 19: np.float64(0.6585365853658537), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.6184873949579832
Weighted-average F1 score: 0.5229485676247381
F1 score per class: {0: np.float64(0.7912087912087912), 32: np.float64(0.9533678756476683), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.14285714285714285), 9: np.float64(0.0), 13: np.float64(0.5434782608695652), 19: np.float64(0.6585365853658537), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.6286701208981001
Weighted-average F1 score: 0.5316856708832047

F1 score per class: {32: np.float64(0.6153846153846154), 0: np.float64(0.9368421052631579), 4: np.float64(0.4731182795698925), 6: np.float64(0.07792207792207792), 7: np.float64(0.78125), 40: np.float64(0.047058823529411764), 9: np.float64(0.6234817813765182), 13: np.float64(0.19742489270386265), 19: np.float64(0.735632183908046), 21: np.float64(0.08695652173913043), 23: np.float64(0.7126436781609196), 24: np.float64(0.37037037037037035), 26: np.float64(0.912621359223301), 27: np.float64(0.5), 29: np.float64(0.7478260869565218), 31: np.float64(0.2233502538071066)}
Micro-average F1 score: 0.5607824871914299
Weighted-average F1 score: 0.5068550593714134
F1 score per class: {32: np.float64(0.46153846153846156), 0: np.float64(0.9543147208121827), 4: np.float64(0.45871559633027525), 6: np.float64(0.08), 7: np.float64(0.625), 40: np.float64(0.07407407407407407), 9: np.float64(0.55625), 13: np.float64(0.2994011976047904), 19: np.float64(0.6136363636363636), 21: np.float64(0.06896551724137931), 23: np.float64(0.6766169154228856), 24: np.float64(0.29411764705882354), 26: np.float64(0.8826291079812206), 27: np.float64(0.4444444444444444), 29: np.float64(0.7445887445887446), 31: np.float64(0.15294117647058825)}
Micro-average F1 score: 0.5530776092774309
Weighted-average F1 score: 0.5209460821665609
F1 score per class: {32: np.float64(0.5217391304347826), 0: np.float64(0.9533678756476683), 4: np.float64(0.4857142857142857), 6: np.float64(0.08823529411764706), 7: np.float64(0.7575757575757576), 40: np.float64(0.06666666666666667), 9: np.float64(0.6033898305084746), 13: np.float64(0.26881720430107525), 19: np.float64(0.627906976744186), 21: np.float64(0.07142857142857142), 23: np.float64(0.6903553299492385), 24: np.float64(0.35714285714285715), 26: np.float64(0.892018779342723), 27: np.float64(0.2857142857142857), 29: np.float64(0.74235807860262), 31: np.float64(0.14285714285714285)}
Micro-average F1 score: 0.565416285452882
Weighted-average F1 score: 0.5288189713207833

F1 score per class: {0: np.float64(0.8674698795180723), 32: np.float64(0.8944723618090452), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.043478260869565216), 40: np.float64(0.0), 13: np.float64(0.3262411347517731), 19: np.float64(0.6808510638297872), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.48148148148148145
Weighted-average F1 score: 0.37336849215536194
F1 score per class: {0: np.float64(0.6666666666666666), 32: np.float64(0.8909952606635071), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.06451612903225806), 9: np.float64(0.0), 13: np.float64(0.423728813559322), 19: np.float64(0.5806451612903226), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.4628930817610063
Weighted-average F1 score: 0.37127880142754294
F1 score per class: {0: np.float64(0.7272727272727273), 32: np.float64(0.8932038834951457), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.0625), 9: np.float64(0.0), 13: np.float64(0.4065040650406504), 19: np.float64(0.574468085106383), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.4702842377260982
Weighted-average F1 score: 0.37519204824031477

F1 score per class: {32: np.float64(0.48322147651006714), 0: np.float64(0.89), 4: np.float64(0.30985915492957744), 6: np.float64(0.05263157894736842), 7: np.float64(0.7246376811594203), 40: np.float64(0.018604651162790697), 9: np.float64(0.5833333333333334), 13: np.float64(0.12672176308539945), 19: np.float64(0.64), 21: np.float64(0.07407407407407407), 23: np.float64(0.656084656084656), 24: np.float64(0.23809523809523808), 26: np.float64(0.8103448275862069), 27: np.float64(0.3333333333333333), 29: np.float64(0.5276073619631901), 31: np.float64(0.19130434782608696)}
Micro-average F1 score: 0.4284697508896797
Weighted-average F1 score: 0.3764498481693953
F1 score per class: {32: np.float64(0.3317972350230415), 0: np.float64(0.8867924528301887), 4: np.float64(0.29239766081871343), 6: np.float64(0.048), 7: np.float64(0.5263157894736842), 40: np.float64(0.03076923076923077), 9: np.float64(0.49859943977591037), 13: np.float64(0.18796992481203006), 19: np.float64(0.5346534653465347), 21: np.float64(0.05405405405405406), 23: np.float64(0.6181818181818182), 24: np.float64(0.20833333333333334), 26: np.float64(0.7673469387755102), 27: np.float64(0.26666666666666666), 29: np.float64(0.5259938837920489), 31: np.float64(0.12322274881516587)}
Micro-average F1 score: 0.4206241519674355
Weighted-average F1 score: 0.3870060396503033
F1 score per class: {32: np.float64(0.38095238095238093), 0: np.float64(0.8888888888888888), 4: np.float64(0.31384615384615383), 6: np.float64(0.05172413793103448), 7: np.float64(0.704225352112676), 40: np.float64(0.02702702702702703), 9: np.float64(0.5493827160493827), 13: np.float64(0.1724137931034483), 19: np.float64(0.5346534653465347), 21: np.float64(0.05714285714285714), 23: np.float64(0.6384976525821596), 24: np.float64(0.24390243902439024), 26: np.float64(0.7786885245901639), 27: np.float64(0.18181818181818182), 29: np.float64(0.5279503105590062), 31: np.float64(0.11403508771929824)}
Micro-average F1 score: 0.431413612565445
Weighted-average F1 score: 0.3927892977404547
cur_acc_wo_na:  ['0.7728', '0.2828', '0.6408']
his_acc_wo_na:  ['0.7728', '0.5307', '0.5608']
cur_acc des_wo_na:  ['0.7623', '0.3206', '0.6185']
his_acc des_wo_na:  ['0.7623', '0.5693', '0.5531']
cur_acc rrf_wo_na:  ['0.7725', '0.3099', '0.6287']
his_acc rrf_wo_na:  ['0.7725', '0.5702', '0.5654']
cur_acc_w_na:  ['0.6487', '0.2421', '0.4815']
his_acc_w_na:  ['0.6487', '0.4283', '0.4285']
cur_acc des_w_na:  ['0.6164', '0.2822', '0.4629']
his_acc des_w_na:  ['0.6164', '0.4675', '0.4206']
cur_acc rrf_w_na:  ['0.6289', '0.2724', '0.4703']
his_acc rrf_w_na:  ['0.6289', '0.4681', '0.4314']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 112.6647827CurrentTrain: epoch  0, batch     1 | loss: 117.0764333CurrentTrain: epoch  0, batch     2 | loss: 144.2671410CurrentTrain: epoch  0, batch     3 | loss: 139.4139396CurrentTrain: epoch  0, batch     4 | loss: 52.0733561CurrentTrain: epoch  1, batch     0 | loss: 114.0067242CurrentTrain: epoch  1, batch     1 | loss: 134.4713941CurrentTrain: epoch  1, batch     2 | loss: 92.6711549CurrentTrain: epoch  1, batch     3 | loss: 86.7567205CurrentTrain: epoch  1, batch     4 | loss: 82.0740787CurrentTrain: epoch  2, batch     0 | loss: 135.3525459CurrentTrain: epoch  2, batch     1 | loss: 84.5262160CurrentTrain: epoch  2, batch     2 | loss: 85.9597453CurrentTrain: epoch  2, batch     3 | loss: 86.4132588CurrentTrain: epoch  2, batch     4 | loss: 64.3867300CurrentTrain: epoch  3, batch     0 | loss: 83.3651750CurrentTrain: epoch  3, batch     1 | loss: 81.0865844CurrentTrain: epoch  3, batch     2 | loss: 134.7585661CurrentTrain: epoch  3, batch     3 | loss: 80.3920622CurrentTrain: epoch  3, batch     4 | loss: 117.2328102CurrentTrain: epoch  4, batch     0 | loss: 128.0644395CurrentTrain: epoch  4, batch     1 | loss: 81.1447019CurrentTrain: epoch  4, batch     2 | loss: 98.2358201CurrentTrain: epoch  4, batch     3 | loss: 129.8697132CurrentTrain: epoch  4, batch     4 | loss: 62.1273564CurrentTrain: epoch  5, batch     0 | loss: 104.1269998CurrentTrain: epoch  5, batch     1 | loss: 96.5433406CurrentTrain: epoch  5, batch     2 | loss: 95.0529810CurrentTrain: epoch  5, batch     3 | loss: 99.2611717CurrentTrain: epoch  5, batch     4 | loss: 106.1418056CurrentTrain: epoch  6, batch     0 | loss: 78.0849503CurrentTrain: epoch  6, batch     1 | loss: 100.5049517CurrentTrain: epoch  6, batch     2 | loss: 124.5939158CurrentTrain: epoch  6, batch     3 | loss: 78.6345338CurrentTrain: epoch  6, batch     4 | loss: 60.8571688CurrentTrain: epoch  7, batch     0 | loss: 82.4967503CurrentTrain: epoch  7, batch     1 | loss: 65.8370583CurrentTrain: epoch  7, batch     2 | loss: 81.6466663CurrentTrain: epoch  7, batch     3 | loss: 80.9147750CurrentTrain: epoch  7, batch     4 | loss: 59.2233655CurrentTrain: epoch  8, batch     0 | loss: 123.4866888CurrentTrain: epoch  8, batch     1 | loss: 91.4267173CurrentTrain: epoch  8, batch     2 | loss: 79.5541912CurrentTrain: epoch  8, batch     3 | loss: 64.9579444CurrentTrain: epoch  8, batch     4 | loss: 107.0592427CurrentTrain: epoch  9, batch     0 | loss: 94.6127897CurrentTrain: epoch  9, batch     1 | loss: 167.0551511CurrentTrain: epoch  9, batch     2 | loss: 73.4690911CurrentTrain: epoch  9, batch     3 | loss: 93.7315095CurrentTrain: epoch  9, batch     4 | loss: 47.7107098
MemoryTrain:  epoch  0, batch     0 | loss: 1.0158877MemoryTrain:  epoch  1, batch     0 | loss: 0.8750908MemoryTrain:  epoch  2, batch     0 | loss: 0.6611236MemoryTrain:  epoch  3, batch     0 | loss: 0.5765515MemoryTrain:  epoch  4, batch     0 | loss: 0.4632680MemoryTrain:  epoch  5, batch     0 | loss: 0.4000731MemoryTrain:  epoch  6, batch     0 | loss: 0.3252423MemoryTrain:  epoch  7, batch     0 | loss: 0.2633256MemoryTrain:  epoch  8, batch     0 | loss: 0.2435059MemoryTrain:  epoch  9, batch     0 | loss: 0.2009073

F1 score per class: {0: np.float64(0.0), 32: np.float64(0.8761904761904762), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.3875968992248062), 40: np.float64(0.0), 10: np.float64(0.7037037037037037), 13: np.float64(0.0), 16: np.float64(0.375), 17: np.float64(0.0), 18: np.float64(0.0), 23: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5742574257425742
Weighted-average F1 score: 0.5617255517351993
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.7392996108949417), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.4122137404580153), 13: np.float64(0.0), 16: np.float64(0.6774193548387096), 17: np.float64(0.5), 18: np.float64(0.5365853658536586), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5358851674641149
Weighted-average F1 score: 0.5019157426864891
F1 score per class: {0: np.float64(0.0), 32: np.float64(0.7630522088353414), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.3969465648854962), 10: np.float64(0.0), 9: np.float64(0.711864406779661), 13: np.float64(0.36363636363636365), 16: np.float64(0.5066666666666667), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5516074450084603
Weighted-average F1 score: 0.5289676078893095

F1 score per class: {0: np.float64(0.6481481481481481), 4: np.float64(0.8636363636363636), 5: np.float64(0.8598130841121495), 6: np.float64(0.49214659685863876), 7: np.float64(0.07142857142857142), 9: np.float64(0.704225352112676), 10: np.float64(0.3472222222222222), 13: np.float64(0.125), 16: np.float64(0.6229508196721312), 17: np.float64(0.0), 18: np.float64(0.36), 19: np.float64(0.6190476190476191), 21: np.float64(0.352), 23: np.float64(0.7551020408163265), 24: np.float64(0.0), 26: np.float64(0.6867469879518072), 27: np.float64(0.32653061224489793), 29: np.float64(0.8811881188118812), 31: np.float64(0.0), 32: np.float64(0.783410138248848), 40: np.float64(0.17674418604651163)}
Micro-average F1 score: 0.5900974025974026
Weighted-average F1 score: 0.5709068714809996
F1 score per class: {0: np.float64(0.5255474452554745), 4: np.float64(0.9430051813471503), 5: np.float64(0.6643356643356644), 6: np.float64(0.4421052631578947), 7: np.float64(0.10909090909090909), 9: np.float64(0.5681818181818182), 10: np.float64(0.38028169014084506), 13: np.float64(0.1111111111111111), 16: np.float64(0.5833333333333334), 17: np.float64(0.23076923076923078), 18: np.float64(0.4583333333333333), 19: np.float64(0.5109034267912772), 21: np.float64(0.24615384615384617), 23: np.float64(0.6597938144329897), 24: np.float64(0.07692307692307693), 26: np.float64(0.6842105263157895), 27: np.float64(0.3018867924528302), 29: np.float64(0.8571428571428571), 31: np.float64(0.2222222222222222), 32: np.float64(0.730593607305936), 40: np.float64(0.15384615384615385)}
Micro-average F1 score: 0.5422285308729595
Weighted-average F1 score: 0.5207288307610695
F1 score per class: {0: np.float64(0.5950413223140496), 4: np.float64(0.9361702127659575), 5: np.float64(0.7037037037037037), 6: np.float64(0.4574468085106383), 7: np.float64(0.10526315789473684), 9: np.float64(0.6578947368421053), 10: np.float64(0.36363636363636365), 13: np.float64(0.10526315789473684), 16: np.float64(0.6176470588235294), 17: np.float64(0.21052631578947367), 18: np.float64(0.4634146341463415), 19: np.float64(0.574468085106383), 21: np.float64(0.24731182795698925), 23: np.float64(0.7021276595744681), 24: np.float64(0.08), 26: np.float64(0.6888888888888889), 27: np.float64(0.3076923076923077), 29: np.float64(0.875), 31: np.float64(0.2857142857142857), 32: np.float64(0.7476635514018691), 40: np.float64(0.1382488479262673)}
Micro-average F1 score: 0.5593471810089021
Weighted-average F1 score: 0.5353815739597261

F1 score per class: {32: np.float64(0.0), 0: np.float64(0.0), 4: np.float64(0.7540983606557377), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.32894736842105265), 10: np.float64(0.0), 9: np.float64(0.4691358024691358), 13: np.float64(0.0), 16: np.float64(0.225), 17: np.float64(0.0), 18: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.4252199413489736
Weighted-average F1 score: 0.39235554930602684
F1 score per class: {0: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.5588235294117647), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.3375), 13: np.float64(0.0), 16: np.float64(0.45652173913043476), 17: np.float64(0.3), 18: np.float64(0.2972972972972973), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3620689655172414
Weighted-average F1 score: 0.33584661792164183
F1 score per class: {0: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.5775075987841946), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.325), 13: np.float64(0.0), 16: np.float64(0.47191011235955055), 17: np.float64(0.21052631578947367), 18: np.float64(0.2992125984251969), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3773148148148148
Weighted-average F1 score: 0.35480669007985804

F1 score per class: {0: np.float64(0.5035971223021583), 4: np.float64(0.8128342245989305), 5: np.float64(0.7389558232931727), 6: np.float64(0.3321554770318021), 7: np.float64(0.04597701149425287), 9: np.float64(0.6493506493506493), 10: np.float64(0.2717391304347826), 13: np.float64(0.0784313725490196), 16: np.float64(0.3838383838383838), 17: np.float64(0.0), 18: np.float64(0.21428571428571427), 19: np.float64(0.5652173913043478), 21: np.float64(0.22797927461139897), 23: np.float64(0.6666666666666666), 24: np.float64(0.0), 26: np.float64(0.6333333333333333), 27: np.float64(0.2077922077922078), 29: np.float64(0.7542372881355932), 31: np.float64(0.0), 32: np.float64(0.5821917808219178), 40: np.float64(0.15019762845849802)}
Micro-average F1 score: 0.467524115755627
Weighted-average F1 score: 0.4430051218716512
F1 score per class: {0: np.float64(0.3870967741935484), 4: np.float64(0.875), 5: np.float64(0.46116504854368934), 6: np.float64(0.28668941979522183), 7: np.float64(0.06818181818181818), 9: np.float64(0.45871559633027525), 10: np.float64(0.2857142857142857), 13: np.float64(0.08), 16: np.float64(0.37168141592920356), 17: np.float64(0.13953488372093023), 18: np.float64(0.24581005586592178), 19: np.float64(0.44086021505376344), 21: np.float64(0.15946843853820597), 23: np.float64(0.5714285714285714), 24: np.float64(0.0625), 26: np.float64(0.6161137440758294), 27: np.float64(0.18181818181818182), 29: np.float64(0.703125), 31: np.float64(0.15384615384615385), 32: np.float64(0.5594405594405595), 40: np.float64(0.12345679012345678)}
Micro-average F1 score: 0.40649108805533385
Weighted-average F1 score: 0.3849128826100544
F1 score per class: {0: np.float64(0.44171779141104295), 4: np.float64(0.8712871287128713), 5: np.float64(0.4896907216494845), 6: np.float64(0.2975778546712803), 7: np.float64(0.06741573033707865), 9: np.float64(0.5952380952380952), 10: np.float64(0.27225130890052357), 13: np.float64(0.07692307692307693), 16: np.float64(0.38181818181818183), 17: np.float64(0.11764705882352941), 18: np.float64(0.2676056338028169), 19: np.float64(0.49390243902439024), 21: np.float64(0.15862068965517243), 23: np.float64(0.6055045871559633), 24: np.float64(0.06666666666666667), 26: np.float64(0.6358974358974359), 27: np.float64(0.1839080459770115), 29: np.float64(0.7368421052631579), 31: np.float64(0.25), 32: np.float64(0.5714285714285714), 40: np.float64(0.11029411764705882)}
Micro-average F1 score: 0.42312008978675647
Weighted-average F1 score: 0.3986819629074407
cur_acc_wo_na:  ['0.7728', '0.2828', '0.6408', '0.5743']
his_acc_wo_na:  ['0.7728', '0.5307', '0.5608', '0.5901']
cur_acc des_wo_na:  ['0.7623', '0.3206', '0.6185', '0.5359']
his_acc des_wo_na:  ['0.7623', '0.5693', '0.5531', '0.5422']
cur_acc rrf_wo_na:  ['0.7725', '0.3099', '0.6287', '0.5516']
his_acc rrf_wo_na:  ['0.7725', '0.5702', '0.5654', '0.5593']
cur_acc_w_na:  ['0.6487', '0.2421', '0.4815', '0.4252']
his_acc_w_na:  ['0.6487', '0.4283', '0.4285', '0.4675']
cur_acc des_w_na:  ['0.6164', '0.2822', '0.4629', '0.3621']
his_acc des_w_na:  ['0.6164', '0.4675', '0.4206', '0.4065']
cur_acc rrf_w_na:  ['0.6289', '0.2724', '0.4703', '0.3773']
his_acc rrf_w_na:  ['0.6289', '0.4681', '0.4314', '0.4231']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 78.3750433CurrentTrain: epoch  0, batch     1 | loss: 100.3006075CurrentTrain: epoch  0, batch     2 | loss: 95.8276066CurrentTrain: epoch  0, batch     3 | loss: 61.8761975CurrentTrain: epoch  1, batch     0 | loss: 84.4546513CurrentTrain: epoch  1, batch     1 | loss: 91.0821140CurrentTrain: epoch  1, batch     2 | loss: 75.6517856CurrentTrain: epoch  1, batch     3 | loss: 50.2531613CurrentTrain: epoch  2, batch     0 | loss: 71.0915213CurrentTrain: epoch  2, batch     1 | loss: 68.8224101CurrentTrain: epoch  2, batch     2 | loss: 100.1643277CurrentTrain: epoch  2, batch     3 | loss: 120.9031474CurrentTrain: epoch  3, batch     0 | loss: 68.3940456CurrentTrain: epoch  3, batch     1 | loss: 79.3790804CurrentTrain: epoch  3, batch     2 | loss: 71.7224297CurrentTrain: epoch  3, batch     3 | loss: 89.4403429CurrentTrain: epoch  4, batch     0 | loss: 69.5867359CurrentTrain: epoch  4, batch     1 | loss: 82.7722453CurrentTrain: epoch  4, batch     2 | loss: 69.9749225CurrentTrain: epoch  4, batch     3 | loss: 44.4369266CurrentTrain: epoch  5, batch     0 | loss: 65.7016818CurrentTrain: epoch  5, batch     1 | loss: 82.4535306CurrentTrain: epoch  5, batch     2 | loss: 95.5750082CurrentTrain: epoch  5, batch     3 | loss: 52.6513039CurrentTrain: epoch  6, batch     0 | loss: 79.1305271CurrentTrain: epoch  6, batch     1 | loss: 78.8123145CurrentTrain: epoch  6, batch     2 | loss: 65.6944600CurrentTrain: epoch  6, batch     3 | loss: 65.5616609CurrentTrain: epoch  7, batch     0 | loss: 78.4315956CurrentTrain: epoch  7, batch     1 | loss: 96.1633312CurrentTrain: epoch  7, batch     2 | loss: 91.8573564CurrentTrain: epoch  7, batch     3 | loss: 49.9005773CurrentTrain: epoch  8, batch     0 | loss: 63.0816341CurrentTrain: epoch  8, batch     1 | loss: 79.5274683CurrentTrain: epoch  8, batch     2 | loss: 64.4519983CurrentTrain: epoch  8, batch     3 | loss: 64.6806903CurrentTrain: epoch  9, batch     0 | loss: 96.5082063CurrentTrain: epoch  9, batch     1 | loss: 62.0385911CurrentTrain: epoch  9, batch     2 | loss: 66.5937073CurrentTrain: epoch  9, batch     3 | loss: 59.1981418
MemoryTrain:  epoch  0, batch     0 | loss: 0.8897410MemoryTrain:  epoch  1, batch     0 | loss: 0.7310819MemoryTrain:  epoch  2, batch     0 | loss: 0.6187722MemoryTrain:  epoch  3, batch     0 | loss: 0.5438463MemoryTrain:  epoch  4, batch     0 | loss: 0.4532924MemoryTrain:  epoch  5, batch     0 | loss: 0.3631614MemoryTrain:  epoch  6, batch     0 | loss: 0.3165193MemoryTrain:  epoch  7, batch     0 | loss: 0.2583919MemoryTrain:  epoch  8, batch     0 | loss: 0.2292902MemoryTrain:  epoch  9, batch     0 | loss: 0.2085651

F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.6086956521739131), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.45714285714285713), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6436781609195402), 37: np.float64(0.6491228070175439), 38: np.float64(0.30303030303030304), 40: np.float64(0.0)}
Micro-average F1 score: 0.42369020501138954
Weighted-average F1 score: 0.3188311419917422
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.6666666666666666), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5897435897435898), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6434782608695652), 37: np.float64(0.6785714285714286), 38: np.float64(0.5909090909090909), 40: np.float64(0.0)}
Micro-average F1 score: 0.45525291828793774
Weighted-average F1 score: 0.34054164569513923
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.7368421052631579), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.5822784810126582), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6306306306306306), 37: np.float64(0.6440677966101694), 38: np.float64(0.5), 40: np.float64(0.0)}
Micro-average F1 score: 0.4529058116232465
Weighted-average F1 score: 0.34747271132865054

F1 score per class: {0: np.float64(0.6732673267326733), 4: np.float64(0.8950276243093923), 5: np.float64(0.714828897338403), 6: np.float64(0.5), 7: np.float64(0.08), 9: np.float64(0.7142857142857143), 10: np.float64(0.39080459770114945), 13: np.float64(0.07272727272727272), 15: np.float64(0.25), 16: np.float64(0.6666666666666666), 17: np.float64(0.3333333333333333), 18: np.float64(0.25), 19: np.float64(0.5714285714285714), 21: np.float64(0.2), 23: np.float64(0.8275862068965517), 24: np.float64(0.08695652173913043), 25: np.float64(0.45714285714285713), 26: np.float64(0.7272727272727273), 27: np.float64(0.27586206896551724), 29: np.float64(0.8679245283018868), 31: np.float64(0.0), 32: np.float64(0.7264957264957265), 35: np.float64(0.3835616438356164), 37: np.float64(0.275092936802974), 38: np.float64(0.2857142857142857), 40: np.float64(0.18947368421052632)}
Micro-average F1 score: 0.5260545905707196
Weighted-average F1 score: 0.49955405885884285
F1 score per class: {0: np.float64(0.5333333333333333), 4: np.float64(0.9381443298969072), 5: np.float64(0.5974842767295597), 6: np.float64(0.48068669527896996), 7: np.float64(0.08695652173913043), 9: np.float64(0.4854368932038835), 10: np.float64(0.5), 13: np.float64(0.12903225806451613), 15: np.float64(0.4444444444444444), 16: np.float64(0.4897959183673469), 17: np.float64(0.0), 18: np.float64(0.3652173913043478), 19: np.float64(0.48295454545454547), 21: np.float64(0.17647058823529413), 23: np.float64(0.6458333333333334), 24: np.float64(0.15789473684210525), 25: np.float64(0.5897435897435898), 26: np.float64(0.6296296296296297), 27: np.float64(0.2545454545454545), 29: np.float64(0.8303571428571429), 31: np.float64(0.0), 32: np.float64(0.7346938775510204), 35: np.float64(0.3217391304347826), 37: np.float64(0.33043478260869563), 38: np.float64(0.45614035087719296), 40: np.float64(0.20689655172413793)}
Micro-average F1 score: 0.5050340136054422
Weighted-average F1 score: 0.48371724323933063
F1 score per class: {0: np.float64(0.6050420168067226), 4: np.float64(0.9528795811518325), 5: np.float64(0.6143790849673203), 6: np.float64(0.48068669527896996), 7: np.float64(0.08823529411764706), 9: np.float64(0.6756756756756757), 10: np.float64(0.4878048780487805), 13: np.float64(0.1111111111111111), 15: np.float64(0.4117647058823529), 16: np.float64(0.6153846153846154), 17: np.float64(0.0), 18: np.float64(0.379746835443038), 19: np.float64(0.5345911949685535), 21: np.float64(0.17142857142857143), 23: np.float64(0.6966292134831461), 24: np.float64(0.07407407407407407), 25: np.float64(0.5822784810126582), 26: np.float64(0.6598984771573604), 27: np.float64(0.2711864406779661), 29: np.float64(0.8378378378378378), 31: np.float64(0.0), 32: np.float64(0.743801652892562), 35: np.float64(0.33653846153846156), 37: np.float64(0.2714285714285714), 38: np.float64(0.40816326530612246), 40: np.float64(0.189873417721519)}
Micro-average F1 score: 0.5155455059355568
Weighted-average F1 score: 0.4908325715897487

F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.45161290322580644), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.4266666666666667), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.5283018867924528), 37: np.float64(0.5211267605633803), 38: np.float64(0.2777777777777778), 40: np.float64(0.0)}
Micro-average F1 score: 0.3163265306122449
Weighted-average F1 score: 0.24110704047307388
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.5217391304347826), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.5138888888888888), 37: np.float64(0.5801526717557252), 38: np.float64(0.4727272727272727), 40: np.float64(0.0)}
Micro-average F1 score: 0.31536388140161725
Weighted-average F1 score: 0.23757625031536356
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.56), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.5287356321839081), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.5147058823529411), 37: np.float64(0.5390070921985816), 38: np.float64(0.4444444444444444), 40: np.float64(0.0)}
Micro-average F1 score: 0.3265895953757225
Weighted-average F1 score: 0.24820952576390518

F1 score per class: {0: np.float64(0.5483870967741935), 4: np.float64(0.8393782383419689), 5: np.float64(0.5481049562682215), 6: np.float64(0.31976744186046513), 7: np.float64(0.048), 9: np.float64(0.6578947368421053), 10: np.float64(0.2821576763485477), 13: np.float64(0.04040404040404041), 15: np.float64(0.12962962962962962), 16: np.float64(0.39655172413793105), 17: np.float64(0.19047619047619047), 18: np.float64(0.16666666666666666), 19: np.float64(0.4968944099378882), 21: np.float64(0.13496932515337423), 23: np.float64(0.72), 24: np.float64(0.07142857142857142), 25: np.float64(0.4266666666666667), 26: np.float64(0.649746192893401), 27: np.float64(0.15841584158415842), 29: np.float64(0.6917293233082706), 31: np.float64(0.0), 32: np.float64(0.5723905723905723), 35: np.float64(0.2413793103448276), 37: np.float64(0.14919354838709678), 38: np.float64(0.2127659574468085), 40: np.float64(0.1592920353982301)}
Micro-average F1 score: 0.3831036819516603
Weighted-average F1 score: 0.35360381330018975
F1 score per class: {0: np.float64(0.3829787234042553), 4: np.float64(0.8708133971291866), 5: np.float64(0.37254901960784315), 6: np.float64(0.3076923076923077), 7: np.float64(0.046511627906976744), 9: np.float64(0.37593984962406013), 10: np.float64(0.3388704318936877), 13: np.float64(0.08163265306122448), 15: np.float64(0.2926829268292683), 16: np.float64(0.2823529411764706), 17: np.float64(0.0), 18: np.float64(0.21105527638190955), 19: np.float64(0.3953488372093023), 21: np.float64(0.1111111111111111), 23: np.float64(0.5210084033613446), 24: np.float64(0.10714285714285714), 25: np.float64(0.4791666666666667), 26: np.float64(0.5506072874493927), 27: np.float64(0.1320754716981132), 29: np.float64(0.636986301369863), 31: np.float64(0.0), 32: np.float64(0.547112462006079), 35: np.float64(0.19576719576719576), 37: np.float64(0.19895287958115182), 38: np.float64(0.2826086956521739), 40: np.float64(0.15789473684210525)}
Micro-average F1 score: 0.34992458521870284
Weighted-average F1 score: 0.3303509229185487
F1 score per class: {0: np.float64(0.43902439024390244), 4: np.float64(0.896551724137931), 5: np.float64(0.41318681318681316), 6: np.float64(0.3076923076923077), 7: np.float64(0.04838709677419355), 9: np.float64(0.6097560975609756), 10: np.float64(0.3333333333333333), 13: np.float64(0.06896551724137931), 15: np.float64(0.23333333333333334), 16: np.float64(0.34285714285714286), 17: np.float64(0.0), 18: np.float64(0.20408163265306123), 19: np.float64(0.4381443298969072), 21: np.float64(0.10869565217391304), 23: np.float64(0.5961538461538461), 24: np.float64(0.05714285714285714), 25: np.float64(0.5227272727272727), 26: np.float64(0.5909090909090909), 27: np.float64(0.14285714285714285), 29: np.float64(0.6526315789473685), 31: np.float64(0.0), 32: np.float64(0.5538461538461539), 35: np.float64(0.20833333333333334), 37: np.float64(0.1655773420479303), 38: np.float64(0.28169014084507044), 40: np.float64(0.14563106796116504)}
Micro-average F1 score: 0.3634914308489438
Weighted-average F1 score: 0.33957979647331504
cur_acc_wo_na:  ['0.7728', '0.2828', '0.6408', '0.5743', '0.4237']
his_acc_wo_na:  ['0.7728', '0.5307', '0.5608', '0.5901', '0.5261']
cur_acc des_wo_na:  ['0.7623', '0.3206', '0.6185', '0.5359', '0.4553']
his_acc des_wo_na:  ['0.7623', '0.5693', '0.5531', '0.5422', '0.5050']
cur_acc rrf_wo_na:  ['0.7725', '0.3099', '0.6287', '0.5516', '0.4529']
his_acc rrf_wo_na:  ['0.7725', '0.5702', '0.5654', '0.5593', '0.5155']
cur_acc_w_na:  ['0.6487', '0.2421', '0.4815', '0.4252', '0.3163']
his_acc_w_na:  ['0.6487', '0.4283', '0.4285', '0.4675', '0.3831']
cur_acc des_w_na:  ['0.6164', '0.2822', '0.4629', '0.3621', '0.3154']
his_acc des_w_na:  ['0.6164', '0.4675', '0.4206', '0.4065', '0.3499']
cur_acc rrf_w_na:  ['0.6289', '0.2724', '0.4703', '0.3773', '0.3266']
his_acc rrf_w_na:  ['0.6289', '0.4681', '0.4314', '0.4231', '0.3635']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 145.2690392CurrentTrain: epoch  0, batch     1 | loss: 81.8210202CurrentTrain: epoch  0, batch     2 | loss: 96.2733040CurrentTrain: epoch  0, batch     3 | loss: 111.9925591CurrentTrain: epoch  0, batch     4 | loss: 20.5622872CurrentTrain: epoch  1, batch     0 | loss: 134.9331788CurrentTrain: epoch  1, batch     1 | loss: 101.8642951CurrentTrain: epoch  1, batch     2 | loss: 77.8878888CurrentTrain: epoch  1, batch     3 | loss: 87.2593654CurrentTrain: epoch  1, batch     4 | loss: 26.7881771CurrentTrain: epoch  2, batch     0 | loss: 105.2918993CurrentTrain: epoch  2, batch     1 | loss: 83.0355484CurrentTrain: epoch  2, batch     2 | loss: 129.6497609CurrentTrain: epoch  2, batch     3 | loss: 71.0769228CurrentTrain: epoch  2, batch     4 | loss: 18.4813197CurrentTrain: epoch  3, batch     0 | loss: 82.3418226CurrentTrain: epoch  3, batch     1 | loss: 82.5118270CurrentTrain: epoch  3, batch     2 | loss: 101.4533374CurrentTrain: epoch  3, batch     3 | loss: 67.9876641CurrentTrain: epoch  3, batch     4 | loss: 39.5465946CurrentTrain: epoch  4, batch     0 | loss: 69.5751135CurrentTrain: epoch  4, batch     1 | loss: 98.3498104CurrentTrain: epoch  4, batch     2 | loss: 66.8404869CurrentTrain: epoch  4, batch     3 | loss: 97.8292948CurrentTrain: epoch  4, batch     4 | loss: 26.3875081CurrentTrain: epoch  5, batch     0 | loss: 84.5821505CurrentTrain: epoch  5, batch     1 | loss: 96.5332115CurrentTrain: epoch  5, batch     2 | loss: 77.5303354CurrentTrain: epoch  5, batch     3 | loss: 63.5261653CurrentTrain: epoch  5, batch     4 | loss: 40.6395183CurrentTrain: epoch  6, batch     0 | loss: 95.8029996CurrentTrain: epoch  6, batch     1 | loss: 95.7605389CurrentTrain: epoch  6, batch     2 | loss: 78.6709046CurrentTrain: epoch  6, batch     3 | loss: 77.2869834CurrentTrain: epoch  6, batch     4 | loss: 22.8132280CurrentTrain: epoch  7, batch     0 | loss: 66.6497926CurrentTrain: epoch  7, batch     1 | loss: 79.9795258CurrentTrain: epoch  7, batch     2 | loss: 77.8622431CurrentTrain: epoch  7, batch     3 | loss: 92.6511216CurrentTrain: epoch  7, batch     4 | loss: 23.3231327CurrentTrain: epoch  8, batch     0 | loss: 78.6009237CurrentTrain: epoch  8, batch     1 | loss: 79.1180749CurrentTrain: epoch  8, batch     2 | loss: 76.6959995CurrentTrain: epoch  8, batch     3 | loss: 63.1278893CurrentTrain: epoch  8, batch     4 | loss: 39.4409191CurrentTrain: epoch  9, batch     0 | loss: 75.1933862CurrentTrain: epoch  9, batch     1 | loss: 77.2128054CurrentTrain: epoch  9, batch     2 | loss: 92.4772197CurrentTrain: epoch  9, batch     3 | loss: 77.0802455CurrentTrain: epoch  9, batch     4 | loss: 38.8888778
MemoryTrain:  epoch  0, batch     0 | loss: 0.9329837MemoryTrain:  epoch  1, batch     0 | loss: 0.9050194MemoryTrain:  epoch  2, batch     0 | loss: 0.6967226MemoryTrain:  epoch  3, batch     0 | loss: 0.5649315MemoryTrain:  epoch  4, batch     0 | loss: 0.5404540MemoryTrain:  epoch  5, batch     0 | loss: 0.4680991MemoryTrain:  epoch  6, batch     0 | loss: 0.4200706MemoryTrain:  epoch  7, batch     0 | loss: 0.3679282MemoryTrain:  epoch  8, batch     0 | loss: 0.3072027MemoryTrain:  epoch  9, batch     0 | loss: 0.2669061

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.5), 5: np.float64(0.0), 6: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.352), 12: np.float64(0.5443786982248521), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 28: np.float64(0.4117647058823529), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.21739130434782608), 40: np.float64(0.0)}
Micro-average F1 score: 0.3473053892215569
Weighted-average F1 score: 0.2757040222325759
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.45161290322580644), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.5147058823529411), 12: np.float64(0.5895953757225434), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.3076923076923077), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.20689655172413793), 40: np.float64(0.0)}
Micro-average F1 score: 0.3371900826446281
Weighted-average F1 score: 0.23399932245072066
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.4827586206896552), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.5390070921985816), 12: np.float64(0.6067415730337079), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.27906976744186046), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.23529411764705882), 40: np.float64(0.0)}
Micro-average F1 score: 0.3879003558718861
Weighted-average F1 score: 0.2916084991555494

F1 score per class: {0: np.float64(0.6476190476190476), 2: np.float64(0.16279069767441862), 4: np.float64(0.7012987012987013), 5: np.float64(0.775), 6: np.float64(0.4385026737967914), 7: np.float64(0.02857142857142857), 9: np.float64(0.6944444444444444), 10: np.float64(0.2714285714285714), 11: np.float64(0.1825726141078838), 12: np.float64(0.3262411347517731), 13: np.float64(0.05263157894736842), 15: np.float64(0.208955223880597), 16: np.float64(0.6571428571428571), 17: np.float64(0.0), 18: np.float64(0.047619047619047616), 19: np.float64(0.6053639846743295), 21: np.float64(0.3076923076923077), 23: np.float64(0.7640449438202247), 24: np.float64(0.08695652173913043), 25: np.float64(0.463768115942029), 26: np.float64(0.7209302325581395), 27: np.float64(0.2903225806451613), 28: np.float64(0.12844036697247707), 29: np.float64(0.8431372549019608), 31: np.float64(0.0), 32: np.float64(0.701195219123506), 35: np.float64(0.2975206611570248), 37: np.float64(0.3409090909090909), 38: np.float64(0.2535211267605634), 39: np.float64(0.06896551724137931), 40: np.float64(0.2222222222222222)}
Micro-average F1 score: 0.4433262711864407
Weighted-average F1 score: 0.4117750132307898
F1 score per class: {0: np.float64(0.41379310344827586), 2: np.float64(0.14432989690721648), 4: np.float64(0.8457142857142858), 5: np.float64(0.6114649681528662), 6: np.float64(0.4083333333333333), 7: np.float64(0.061224489795918366), 9: np.float64(0.45045045045045046), 10: np.float64(0.3877551020408163), 11: np.float64(0.319634703196347), 12: np.float64(0.3227848101265823), 13: np.float64(0.038461538461538464), 15: np.float64(0.35294117647058826), 16: np.float64(0.6419753086419753), 17: np.float64(0.0), 18: np.float64(0.0594059405940594), 19: np.float64(0.4941860465116279), 21: np.float64(0.20512820512820512), 23: np.float64(0.6530612244897959), 24: np.float64(0.058823529411764705), 25: np.float64(0.56), 26: np.float64(0.673469387755102), 27: np.float64(0.2727272727272727), 28: np.float64(0.12121212121212122), 29: np.float64(0.8217821782178217), 31: np.float64(0.0), 32: np.float64(0.656934306569343), 35: np.float64(0.31020408163265306), 37: np.float64(0.3103448275862069), 38: np.float64(0.30985915492957744), 39: np.float64(0.08450704225352113), 40: np.float64(0.2222222222222222)}
Micro-average F1 score: 0.428377153218495
Weighted-average F1 score: 0.40316528173329735
F1 score per class: {0: np.float64(0.6101694915254238), 2: np.float64(0.13592233009708737), 4: np.float64(0.8095238095238095), 5: np.float64(0.6810035842293907), 6: np.float64(0.46153846153846156), 7: np.float64(0.07407407407407407), 9: np.float64(0.6756756756756757), 10: np.float64(0.36363636363636365), 11: np.float64(0.33480176211453744), 12: np.float64(0.33540372670807456), 13: np.float64(0.029411764705882353), 15: np.float64(0.2857142857142857), 16: np.float64(0.6944444444444444), 17: np.float64(0.0), 18: np.float64(0.07692307692307693), 19: np.float64(0.5704697986577181), 21: np.float64(0.22058823529411764), 23: np.float64(0.6222222222222222), 24: np.float64(0.07407407407407407), 25: np.float64(0.5405405405405406), 26: np.float64(0.6770833333333334), 27: np.float64(0.2647058823529412), 28: np.float64(0.10256410256410256), 29: np.float64(0.8217821782178217), 31: np.float64(0.0), 32: np.float64(0.6793893129770993), 35: np.float64(0.35428571428571426), 37: np.float64(0.3050847457627119), 38: np.float64(0.32), 39: np.float64(0.09195402298850575), 40: np.float64(0.19653179190751446)}
Micro-average F1 score: 0.4482509047044632
Weighted-average F1 score: 0.41985452609908075

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.2641509433962264), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.2857142857142857), 12: np.float64(0.44878048780487806), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.1917808219178082), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.1111111111111111), 40: np.float64(0.0)}
Micro-average F1 score: 0.232
Weighted-average F1 score: 0.18552153193067986
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.2222222222222222), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.4117647058823529), 12: np.float64(0.5024630541871922), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.13953488372093023), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.13043478260869565), 40: np.float64(0.0)}
Micro-average F1 score: 0.2210184182015168
Weighted-average F1 score: 0.1599091398257735
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.22950819672131148), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.4393063583815029), 12: np.float64(0.5167464114832536), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.13043478260869565), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.14545454545454545), 40: np.float64(0.0)}
Micro-average F1 score: 0.2543757292882147
Weighted-average F1 score: 0.19203915932034077

F1 score per class: {0: np.float64(0.5151515151515151), 2: np.float64(0.08333333333333333), 4: np.float64(0.6625766871165644), 5: np.float64(0.6283783783783784), 6: np.float64(0.2867132867132867), 7: np.float64(0.015873015873015872), 9: np.float64(0.6329113924050633), 10: np.float64(0.2389937106918239), 11: np.float64(0.12429378531073447), 12: np.float64(0.16), 13: np.float64(0.03225806451612903), 15: np.float64(0.12280701754385964), 16: np.float64(0.40707964601769914), 17: np.float64(0.0), 18: np.float64(0.03389830508474576), 19: np.float64(0.5505226480836237), 21: np.float64(0.2), 23: np.float64(0.6666666666666666), 24: np.float64(0.06896551724137931), 25: np.float64(0.4444444444444444), 26: np.float64(0.6458333333333334), 27: np.float64(0.16363636363636364), 28: np.float64(0.05907172995780591), 29: np.float64(0.6771653543307087), 31: np.float64(0.0), 32: np.float64(0.5285285285285285), 35: np.float64(0.18947368421052632), 37: np.float64(0.2727272727272727), 38: np.float64(0.16822429906542055), 39: np.float64(0.03571428571428571), 40: np.float64(0.19004524886877827)}
Micro-average F1 score: 0.3097132284921369
Weighted-average F1 score: 0.2762103909226953
F1 score per class: {0: np.float64(0.288), 2: np.float64(0.0748663101604278), 4: np.float64(0.8), 5: np.float64(0.38247011952191234), 6: np.float64(0.2396088019559902), 7: np.float64(0.03333333333333333), 9: np.float64(0.3424657534246575), 10: np.float64(0.26666666666666666), 11: np.float64(0.20833333333333334), 12: np.float64(0.1705685618729097), 13: np.float64(0.0273972602739726), 15: np.float64(0.22641509433962265), 16: np.float64(0.36363636363636365), 17: np.float64(0.0), 18: np.float64(0.04580152671755725), 19: np.float64(0.425), 21: np.float64(0.128), 23: np.float64(0.5), 24: np.float64(0.0425531914893617), 25: np.float64(0.4883720930232558), 26: np.float64(0.5919282511210763), 27: np.float64(0.14754098360655737), 28: np.float64(0.05429864253393665), 29: np.float64(0.664), 31: np.float64(0.0), 32: np.float64(0.4580152671755725), 35: np.float64(0.1890547263681592), 37: np.float64(0.24324324324324326), 38: np.float64(0.24175824175824176), 39: np.float64(0.043478260869565216), 40: np.float64(0.16842105263157894)}
Micro-average F1 score: 0.28688524590163933
Weighted-average F1 score: 0.26535451791563464
F1 score per class: {0: np.float64(0.43636363636363634), 2: np.float64(0.07035175879396985), 4: np.float64(0.768361581920904), 5: np.float64(0.46228710462287104), 6: np.float64(0.271356783919598), 7: np.float64(0.039473684210526314), 9: np.float64(0.5813953488372093), 10: np.float64(0.2777777777777778), 11: np.float64(0.22686567164179106), 12: np.float64(0.1758957654723127), 13: np.float64(0.019801980198019802), 15: np.float64(0.1728395061728395), 16: np.float64(0.4), 17: np.float64(0.0), 18: np.float64(0.05714285714285714), 19: np.float64(0.5044510385756676), 21: np.float64(0.1388888888888889), 23: np.float64(0.5384615384615384), 24: np.float64(0.05714285714285714), 25: np.float64(0.49382716049382713), 26: np.float64(0.6018518518518519), 27: np.float64(0.14285714285714285), 28: np.float64(0.047058823529411764), 29: np.float64(0.664), 31: np.float64(0.0), 32: np.float64(0.489010989010989), 35: np.float64(0.2222222222222222), 37: np.float64(0.23529411764705882), 38: np.float64(0.23529411764705882), 39: np.float64(0.049689440993788817), 40: np.float64(0.1559633027522936)}
Micro-average F1 score: 0.30574296527892053
Weighted-average F1 score: 0.279666097484584
cur_acc_wo_na:  ['0.7728', '0.2828', '0.6408', '0.5743', '0.4237', '0.3473']
his_acc_wo_na:  ['0.7728', '0.5307', '0.5608', '0.5901', '0.5261', '0.4433']
cur_acc des_wo_na:  ['0.7623', '0.3206', '0.6185', '0.5359', '0.4553', '0.3372']
his_acc des_wo_na:  ['0.7623', '0.5693', '0.5531', '0.5422', '0.5050', '0.4284']
cur_acc rrf_wo_na:  ['0.7725', '0.3099', '0.6287', '0.5516', '0.4529', '0.3879']
his_acc rrf_wo_na:  ['0.7725', '0.5702', '0.5654', '0.5593', '0.5155', '0.4483']
cur_acc_w_na:  ['0.6487', '0.2421', '0.4815', '0.4252', '0.3163', '0.2320']
his_acc_w_na:  ['0.6487', '0.4283', '0.4285', '0.4675', '0.3831', '0.3097']
cur_acc des_w_na:  ['0.6164', '0.2822', '0.4629', '0.3621', '0.3154', '0.2210']
his_acc des_w_na:  ['0.6164', '0.4675', '0.4206', '0.4065', '0.3499', '0.2869']
cur_acc rrf_w_na:  ['0.6289', '0.2724', '0.4703', '0.3773', '0.3266', '0.2544']
his_acc rrf_w_na:  ['0.6289', '0.4681', '0.4314', '0.4231', '0.3635', '0.3057']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 90.6669117CurrentTrain: epoch  0, batch     1 | loss: 98.1312363CurrentTrain: epoch  0, batch     2 | loss: 196.3943744CurrentTrain: epoch  0, batch     3 | loss: 88.4416979CurrentTrain: epoch  0, batch     4 | loss: 81.3363489CurrentTrain: epoch  1, batch     0 | loss: 77.0662984CurrentTrain: epoch  1, batch     1 | loss: 99.7902312CurrentTrain: epoch  1, batch     2 | loss: 106.1020946CurrentTrain: epoch  1, batch     3 | loss: 107.5566022CurrentTrain: epoch  1, batch     4 | loss: 51.2008108CurrentTrain: epoch  2, batch     0 | loss: 107.3734033CurrentTrain: epoch  2, batch     1 | loss: 75.4966054CurrentTrain: epoch  2, batch     2 | loss: 71.1991762CurrentTrain: epoch  2, batch     3 | loss: 88.0957648CurrentTrain: epoch  2, batch     4 | loss: 61.1828060CurrentTrain: epoch  3, batch     0 | loss: 104.7079592CurrentTrain: epoch  3, batch     1 | loss: 85.3343581CurrentTrain: epoch  3, batch     2 | loss: 98.8252301CurrentTrain: epoch  3, batch     3 | loss: 100.1910091CurrentTrain: epoch  3, batch     4 | loss: 99.0669970CurrentTrain: epoch  4, batch     0 | loss: 99.9216878CurrentTrain: epoch  4, batch     1 | loss: 125.1698037CurrentTrain: epoch  4, batch     2 | loss: 82.2432515CurrentTrain: epoch  4, batch     3 | loss: 73.0116578CurrentTrain: epoch  4, batch     4 | loss: 55.3261039CurrentTrain: epoch  5, batch     0 | loss: 81.0650853CurrentTrain: epoch  5, batch     1 | loss: 79.6730924CurrentTrain: epoch  5, batch     2 | loss: 82.7357705CurrentTrain: epoch  5, batch     3 | loss: 124.1670782CurrentTrain: epoch  5, batch     4 | loss: 55.0930848CurrentTrain: epoch  6, batch     0 | loss: 79.8222407CurrentTrain: epoch  6, batch     1 | loss: 97.8930762CurrentTrain: epoch  6, batch     2 | loss: 169.1589953CurrentTrain: epoch  6, batch     3 | loss: 68.7216966CurrentTrain: epoch  6, batch     4 | loss: 49.4550507CurrentTrain: epoch  7, batch     0 | loss: 77.3034735CurrentTrain: epoch  7, batch     1 | loss: 97.2783883CurrentTrain: epoch  7, batch     2 | loss: 99.2749160CurrentTrain: epoch  7, batch     3 | loss: 80.5888190CurrentTrain: epoch  7, batch     4 | loss: 52.5811307CurrentTrain: epoch  8, batch     0 | loss: 94.8621320CurrentTrain: epoch  8, batch     1 | loss: 68.6473827CurrentTrain: epoch  8, batch     2 | loss: 95.8250619CurrentTrain: epoch  8, batch     3 | loss: 94.1500898CurrentTrain: epoch  8, batch     4 | loss: 67.5205146CurrentTrain: epoch  9, batch     0 | loss: 79.7048383CurrentTrain: epoch  9, batch     1 | loss: 79.1893120CurrentTrain: epoch  9, batch     2 | loss: 96.8628366CurrentTrain: epoch  9, batch     3 | loss: 77.0431448CurrentTrain: epoch  9, batch     4 | loss: 42.6353439
MemoryTrain:  epoch  0, batch     0 | loss: 1.1967392MemoryTrain:  epoch  1, batch     0 | loss: 1.0938395MemoryTrain:  epoch  2, batch     0 | loss: 0.8654333MemoryTrain:  epoch  3, batch     0 | loss: 0.7126973MemoryTrain:  epoch  4, batch     0 | loss: 0.6174730MemoryTrain:  epoch  5, batch     0 | loss: 0.5137054MemoryTrain:  epoch  6, batch     0 | loss: 0.4319852MemoryTrain:  epoch  7, batch     0 | loss: 0.3905481MemoryTrain:  epoch  8, batch     0 | loss: 0.3644147MemoryTrain:  epoch  9, batch     0 | loss: 0.2936272

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.2831050228310502), 2: np.float64(0.0), 3: np.float64(0.5952380952380952), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.17073170731707318), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5655737704918032), 23: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.5825242718446602), 35: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3603082851637765
Weighted-average F1 score: 0.3072694637864961
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.25125628140703515), 2: np.float64(0.0), 3: np.float64(0.5714285714285714), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.13333333333333333), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5469387755102041), 23: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.672566371681416), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3100252737994945
Weighted-average F1 score: 0.2489761683658562
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.2571428571428571), 2: np.float64(0.0), 3: np.float64(0.5698324022346368), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.16842105263157894), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5433070866141733), 23: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6842105263157895), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3368055555555556
Weighted-average F1 score: 0.28127943687333795

F1 score per class: {0: np.float64(0.673469387755102), 1: np.float64(0.19935691318327975), 2: np.float64(0.14583333333333334), 3: np.float64(0.3546099290780142), 4: np.float64(0.6013986013986014), 5: np.float64(0.7966101694915254), 6: np.float64(0.4205607476635514), 7: np.float64(0.02857142857142857), 9: np.float64(0.7575757575757576), 10: np.float64(0.29850746268656714), 11: np.float64(0.10144927536231885), 12: np.float64(0.27636363636363637), 13: np.float64(0.06060606060606061), 14: np.float64(0.10606060606060606), 15: np.float64(0.35294117647058826), 16: np.float64(0.6545454545454545), 17: np.float64(0.0), 18: np.float64(0.03508771929824561), 19: np.float64(0.5692307692307692), 21: np.float64(0.05263157894736842), 22: np.float64(0.5073529411764706), 23: np.float64(0.8), 24: np.float64(0.0), 25: np.float64(0.45714285714285713), 26: np.float64(0.7011494252873564), 27: np.float64(0.0), 28: np.float64(0.112), 29: np.float64(0.7960199004975125), 31: np.float64(0.0), 32: np.float64(0.5931558935361216), 34: np.float64(0.2564102564102564), 35: np.float64(0.1592920353982301), 37: np.float64(0.24), 38: np.float64(0.3076923076923077), 39: np.float64(0.1282051282051282), 40: np.float64(0.23529411764705882)}
Micro-average F1 score: 0.39696905914544306
Weighted-average F1 score: 0.3772162817317685
F1 score per class: {0: np.float64(0.41379310344827586), 1: np.float64(0.18115942028985507), 2: np.float64(0.1320754716981132), 3: np.float64(0.36923076923076925), 4: np.float64(0.6967741935483871), 5: np.float64(0.6134185303514377), 6: np.float64(0.39823008849557523), 7: np.float64(0.025), 9: np.float64(0.45045045045045046), 10: np.float64(0.3660130718954248), 11: np.float64(0.13793103448275862), 12: np.float64(0.2605633802816901), 13: np.float64(0.0392156862745098), 14: np.float64(0.09090909090909091), 15: np.float64(0.42857142857142855), 16: np.float64(0.7384615384615385), 17: np.float64(0.0), 18: np.float64(0.176), 19: np.float64(0.4797687861271676), 21: np.float64(0.14285714285714285), 22: np.float64(0.46048109965635736), 23: np.float64(0.693069306930693), 24: np.float64(0.08163265306122448), 25: np.float64(0.5333333333333333), 26: np.float64(0.6798029556650246), 27: np.float64(0.0), 28: np.float64(0.12962962962962962), 29: np.float64(0.7860696517412935), 31: np.float64(0.0), 32: np.float64(0.5530546623794212), 34: np.float64(0.2704626334519573), 35: np.float64(0.16346153846153846), 37: np.float64(0.2268041237113402), 38: np.float64(0.2222222222222222), 39: np.float64(0.13793103448275862), 40: np.float64(0.19767441860465115)}
Micro-average F1 score: 0.3781038374717833
Weighted-average F1 score: 0.36129016531848906
F1 score per class: {0: np.float64(0.5034965034965035), 1: np.float64(0.18120805369127516), 2: np.float64(0.1346153846153846), 3: np.float64(0.3388704318936877), 4: np.float64(0.6577181208053692), 5: np.float64(0.6737588652482269), 6: np.float64(0.44541484716157204), 7: np.float64(0.029850746268656716), 9: np.float64(0.684931506849315), 10: np.float64(0.3150684931506849), 11: np.float64(0.12698412698412698), 12: np.float64(0.2698961937716263), 13: np.float64(0.0392156862745098), 14: np.float64(0.10526315789473684), 15: np.float64(0.375), 16: np.float64(0.7457627118644068), 17: np.float64(0.0), 18: np.float64(0.042105263157894736), 19: np.float64(0.5139318885448917), 21: np.float64(0.09302325581395349), 22: np.float64(0.44805194805194803), 23: np.float64(0.6666666666666666), 24: np.float64(0.06060606060606061), 25: np.float64(0.5405405405405406), 26: np.float64(0.6871794871794872), 27: np.float64(0.0), 28: np.float64(0.11965811965811966), 29: np.float64(0.79), 31: np.float64(0.0), 32: np.float64(0.5589225589225589), 34: np.float64(0.2727272727272727), 35: np.float64(0.15584415584415584), 37: np.float64(0.2222222222222222), 38: np.float64(0.2631578947368421), 39: np.float64(0.12903225806451613), 40: np.float64(0.18497109826589594)}
Micro-average F1 score: 0.3821359223300971
Weighted-average F1 score: 0.36528427290618526

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.15938303341902313), 2: np.float64(0.0), 3: np.float64(0.44052863436123346), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.1308411214953271), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.4726027397260274), 23: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.4838709677419355), 35: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.24113475177304963
Weighted-average F1 score: 0.20602522498412448
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.14084507042253522), 2: np.float64(0.0), 3: np.float64(0.4507042253521127), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.10714285714285714), 15: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.44518272425249167), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.5547445255474452), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.20444444444444446
Weighted-average F1 score: 0.16689978857194193
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.14516129032258066), 2: np.float64(0.0), 3: np.float64(0.42677824267782427), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.13008130081300814), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.4437299035369775), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.5611510791366906), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2222222222222222
Weighted-average F1 score: 0.18768050389850507

F1 score per class: {0: np.float64(0.4925373134328358), 1: np.float64(0.1076388888888889), 2: np.float64(0.09032258064516129), 3: np.float64(0.2178649237472767), 4: np.float64(0.5695364238410596), 5: np.float64(0.6351351351351351), 6: np.float64(0.2459016393442623), 7: np.float64(0.016260162601626018), 9: np.float64(0.684931506849315), 10: np.float64(0.2564102564102564), 11: np.float64(0.07567567567567568), 12: np.float64(0.13996316758747698), 13: np.float64(0.035398230088495575), 14: np.float64(0.06167400881057269), 15: np.float64(0.21052631578947367), 16: np.float64(0.4675324675324675), 17: np.float64(0.0), 18: np.float64(0.023529411764705882), 19: np.float64(0.5103448275862069), 21: np.float64(0.046511627906976744), 22: np.float64(0.4011627906976744), 23: np.float64(0.6972477064220184), 24: np.float64(0.0), 25: np.float64(0.4266666666666667), 26: np.float64(0.6288659793814433), 27: np.float64(0.0), 28: np.float64(0.05555555555555555), 29: np.float64(0.6477732793522267), 31: np.float64(0.0), 32: np.float64(0.4431818181818182), 34: np.float64(0.15706806282722513), 35: np.float64(0.1232876712328767), 37: np.float64(0.20454545454545456), 38: np.float64(0.21052631578947367), 39: np.float64(0.06535947712418301), 40: np.float64(0.19771863117870722)}
Micro-average F1 score: 0.274088068594681
Weighted-average F1 score: 0.24983680818025347
F1 score per class: {0: np.float64(0.28346456692913385), 1: np.float64(0.09784735812133072), 2: np.float64(0.08235294117647059), 3: np.float64(0.2436548223350254), 4: np.float64(0.6545454545454545), 5: np.float64(0.37065637065637064), 6: np.float64(0.2356020942408377), 7: np.float64(0.012987012987012988), 9: np.float64(0.3225806451612903), 10: np.float64(0.27053140096618356), 11: np.float64(0.1103448275862069), 12: np.float64(0.13553113553113552), 13: np.float64(0.025), 14: np.float64(0.06593406593406594), 15: np.float64(0.2727272727272727), 16: np.float64(0.4485981308411215), 17: np.float64(0.0), 18: np.float64(0.1164021164021164), 19: np.float64(0.4223918575063613), 21: np.float64(0.10526315789473684), 22: np.float64(0.33668341708542715), 23: np.float64(0.5303030303030303), 24: np.float64(0.058823529411764705), 25: np.float64(0.4444444444444444), 26: np.float64(0.592274678111588), 27: np.float64(0.0), 28: np.float64(0.06140350877192982), 29: np.float64(0.6422764227642277), 31: np.float64(0.0), 32: np.float64(0.38826185101580135), 34: np.float64(0.16344086021505377), 35: np.float64(0.11074918566775244), 37: np.float64(0.171875), 38: np.float64(0.17204301075268819), 39: np.float64(0.07207207207207207), 40: np.float64(0.1642512077294686)}
Micro-average F1 score: 0.255205688166582
Weighted-average F1 score: 0.23925630562433145
F1 score per class: {0: np.float64(0.3582089552238806), 1: np.float64(0.09872029250457039), 2: np.float64(0.08333333333333333), 3: np.float64(0.21428571428571427), 4: np.float64(0.620253164556962), 5: np.float64(0.4408352668213457), 6: np.float64(0.26356589147286824), 7: np.float64(0.014814814814814815), 9: np.float64(0.5813953488372093), 10: np.float64(0.25), 11: np.float64(0.09696969696969697), 12: np.float64(0.13829787234042554), 13: np.float64(0.022222222222222223), 14: np.float64(0.07339449541284404), 15: np.float64(0.23076923076923078), 16: np.float64(0.5238095238095238), 17: np.float64(0.0), 18: np.float64(0.030534351145038167), 19: np.float64(0.4547945205479452), 21: np.float64(0.06349206349206349), 22: np.float64(0.33906633906633904), 23: np.float64(0.5740740740740741), 24: np.float64(0.045454545454545456), 25: np.float64(0.4819277108433735), 26: np.float64(0.6118721461187214), 27: np.float64(0.0), 28: np.float64(0.058091286307053944), 29: np.float64(0.6475409836065574), 31: np.float64(0.0), 32: np.float64(0.40487804878048783), 34: np.float64(0.1598360655737705), 35: np.float64(0.10434782608695652), 37: np.float64(0.16393442622950818), 38: np.float64(0.18867924528301888), 39: np.float64(0.07017543859649122), 40: np.float64(0.15384615384615385)}
Micro-average F1 score: 0.2600079270709473
Weighted-average F1 score: 0.24154015996176278
cur_acc_wo_na:  ['0.7728', '0.2828', '0.6408', '0.5743', '0.4237', '0.3473', '0.3603']
his_acc_wo_na:  ['0.7728', '0.5307', '0.5608', '0.5901', '0.5261', '0.4433', '0.3970']
cur_acc des_wo_na:  ['0.7623', '0.3206', '0.6185', '0.5359', '0.4553', '0.3372', '0.3100']
his_acc des_wo_na:  ['0.7623', '0.5693', '0.5531', '0.5422', '0.5050', '0.4284', '0.3781']
cur_acc rrf_wo_na:  ['0.7725', '0.3099', '0.6287', '0.5516', '0.4529', '0.3879', '0.3368']
his_acc rrf_wo_na:  ['0.7725', '0.5702', '0.5654', '0.5593', '0.5155', '0.4483', '0.3821']
cur_acc_w_na:  ['0.6487', '0.2421', '0.4815', '0.4252', '0.3163', '0.2320', '0.2411']
his_acc_w_na:  ['0.6487', '0.4283', '0.4285', '0.4675', '0.3831', '0.3097', '0.2741']
cur_acc des_w_na:  ['0.6164', '0.2822', '0.4629', '0.3621', '0.3154', '0.2210', '0.2044']
his_acc des_w_na:  ['0.6164', '0.4675', '0.4206', '0.4065', '0.3499', '0.2869', '0.2552']
cur_acc rrf_w_na:  ['0.6289', '0.2724', '0.4703', '0.3773', '0.3266', '0.2544', '0.2222']
his_acc rrf_w_na:  ['0.6289', '0.4681', '0.4314', '0.4231', '0.3635', '0.3057', '0.2600']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 95.8962694CurrentTrain: epoch  0, batch     1 | loss: 82.5600635CurrentTrain: epoch  0, batch     2 | loss: 82.4359961CurrentTrain: epoch  0, batch     3 | loss: 62.6074372CurrentTrain: epoch  1, batch     0 | loss: 86.0895571CurrentTrain: epoch  1, batch     1 | loss: 86.0093825CurrentTrain: epoch  1, batch     2 | loss: 107.3976922CurrentTrain: epoch  1, batch     3 | loss: 55.1795348CurrentTrain: epoch  2, batch     0 | loss: 87.6219672CurrentTrain: epoch  2, batch     1 | loss: 80.9011546CurrentTrain: epoch  2, batch     2 | loss: 102.7451263CurrentTrain: epoch  2, batch     3 | loss: 49.2761023CurrentTrain: epoch  3, batch     0 | loss: 66.7110655CurrentTrain: epoch  3, batch     1 | loss: 71.2366120CurrentTrain: epoch  3, batch     2 | loss: 132.1589080CurrentTrain: epoch  3, batch     3 | loss: 47.7924954CurrentTrain: epoch  4, batch     0 | loss: 84.9465681CurrentTrain: epoch  4, batch     1 | loss: 78.4432525CurrentTrain: epoch  4, batch     2 | loss: 64.7767995CurrentTrain: epoch  4, batch     3 | loss: 59.2713447CurrentTrain: epoch  5, batch     0 | loss: 77.2258142CurrentTrain: epoch  5, batch     1 | loss: 81.2885590CurrentTrain: epoch  5, batch     2 | loss: 62.6270782CurrentTrain: epoch  5, batch     3 | loss: 62.7319436CurrentTrain: epoch  6, batch     0 | loss: 64.4862737CurrentTrain: epoch  6, batch     1 | loss: 95.1385635CurrentTrain: epoch  6, batch     2 | loss: 65.9733982CurrentTrain: epoch  6, batch     3 | loss: 46.3844592CurrentTrain: epoch  7, batch     0 | loss: 61.3395741CurrentTrain: epoch  7, batch     1 | loss: 92.4053248CurrentTrain: epoch  7, batch     2 | loss: 94.7456520CurrentTrain: epoch  7, batch     3 | loss: 57.4576969CurrentTrain: epoch  8, batch     0 | loss: 77.4374653CurrentTrain: epoch  8, batch     1 | loss: 93.8319912CurrentTrain: epoch  8, batch     2 | loss: 60.3361378CurrentTrain: epoch  8, batch     3 | loss: 71.7914015CurrentTrain: epoch  9, batch     0 | loss: 76.1419480CurrentTrain: epoch  9, batch     1 | loss: 71.3818589CurrentTrain: epoch  9, batch     2 | loss: 71.8898072CurrentTrain: epoch  9, batch     3 | loss: 101.5856141
MemoryTrain:  epoch  0, batch     0 | loss: 0.7430917MemoryTrain:  epoch  1, batch     0 | loss: 0.6634378MemoryTrain:  epoch  2, batch     0 | loss: 0.5119204MemoryTrain:  epoch  3, batch     0 | loss: 0.4123484MemoryTrain:  epoch  4, batch     0 | loss: 0.3845548MemoryTrain:  epoch  5, batch     0 | loss: 0.3162041MemoryTrain:  epoch  6, batch     0 | loss: 0.3011526MemoryTrain:  epoch  7, batch     0 | loss: 0.2632060MemoryTrain:  epoch  8, batch     0 | loss: 0.2287008MemoryTrain:  epoch  9, batch     0 | loss: 0.1846804

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.45454545454545453), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.8598130841121495), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8947368421052632), 32: np.float64(0.0), 33: np.float64(0.42857142857142855), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.41379310344827586), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.43253968253968256
Weighted-average F1 score: 0.3140193446809164
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.625), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.8598130841121495), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.9230769230769231), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.42105263157894735), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.6271186440677966), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.47540983606557374
Weighted-average F1 score: 0.3413858112497082
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.5853658536585366), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.8545454545454545), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.9230769230769231), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.5), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.616822429906542), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.48013816925734026
Weighted-average F1 score: 0.34681370516066284

F1 score per class: {0: np.float64(0.5964912280701754), 1: np.float64(0.19701492537313434), 2: np.float64(0.16470588235294117), 3: np.float64(0.42677824267782427), 4: np.float64(0.7341772151898734), 5: np.float64(0.7982832618025751), 6: np.float64(0.4018264840182648), 7: np.float64(0.03225806451612903), 8: np.float64(0.25125628140703515), 9: np.float64(0.7142857142857143), 10: np.float64(0.25675675675675674), 11: np.float64(0.08139534883720931), 12: np.float64(0.2222222222222222), 13: np.float64(0.0425531914893617), 14: np.float64(0.08333333333333333), 15: np.float64(0.3076923076923077), 16: np.float64(0.6557377049180327), 17: np.float64(0.0), 18: np.float64(0.08450704225352113), 19: np.float64(0.5519713261648745), 20: np.float64(0.4717948717948718), 21: np.float64(0.0), 22: np.float64(0.5511111111111111), 23: np.float64(0.7608695652173914), 24: np.float64(0.0), 25: np.float64(0.36923076923076925), 26: np.float64(0.6888888888888889), 27: np.float64(0.0), 28: np.float64(0.23809523809523808), 29: np.float64(0.782608695652174), 30: np.float64(0.8947368421052632), 31: np.float64(0.18181818181818182), 32: np.float64(0.5524475524475524), 33: np.float64(0.17142857142857143), 34: np.float64(0.3426294820717131), 35: np.float64(0.13533834586466165), 36: np.float64(0.3564356435643564), 37: np.float64(0.29333333333333333), 38: np.float64(0.20512820512820512), 39: np.float64(0.16393442622950818), 40: np.float64(0.22413793103448276)}
Micro-average F1 score: 0.4023713903231976
Weighted-average F1 score: 0.3905721100532658
F1 score per class: {0: np.float64(0.3116883116883117), 1: np.float64(0.18181818181818182), 2: np.float64(0.10144927536231885), 3: np.float64(0.3619047619047619), 4: np.float64(0.7484662576687117), 5: np.float64(0.5384615384615384), 6: np.float64(0.39790575916230364), 7: np.float64(0.027777777777777776), 8: np.float64(0.2888086642599278), 9: np.float64(0.42735042735042733), 10: np.float64(0.32044198895027626), 11: np.float64(0.1037037037037037), 12: np.float64(0.22627737226277372), 13: np.float64(0.044444444444444446), 14: np.float64(0.10909090909090909), 15: np.float64(0.3), 16: np.float64(0.7164179104477612), 17: np.float64(0.0), 18: np.float64(0.12643678160919541), 19: np.float64(0.425), 20: np.float64(0.4972972972972973), 21: np.float64(0.14492753623188406), 22: np.float64(0.4391691394658754), 23: np.float64(0.6666666666666666), 24: np.float64(0.0784313725490196), 25: np.float64(0.48), 26: np.float64(0.6476190476190476), 27: np.float64(0.0), 28: np.float64(0.18867924528301888), 29: np.float64(0.7962962962962963), 30: np.float64(0.5901639344262295), 31: np.float64(0.06896551724137931), 32: np.float64(0.5161290322580645), 33: np.float64(0.15384615384615385), 34: np.float64(0.32967032967032966), 35: np.float64(0.20363636363636364), 36: np.float64(0.4378698224852071), 37: np.float64(0.20202020202020202), 38: np.float64(0.36065573770491804), 39: np.float64(0.2127659574468085), 40: np.float64(0.18543046357615894)}
Micro-average F1 score: 0.3660377358490566
Weighted-average F1 score: 0.352417810033846
F1 score per class: {0: np.float64(0.39779005524861877), 1: np.float64(0.18618618618618618), 2: np.float64(0.11382113821138211), 3: np.float64(0.34285714285714286), 4: np.float64(0.75), 5: np.float64(0.632258064516129), 6: np.float64(0.3886255924170616), 7: np.float64(0.030303030303030304), 8: np.float64(0.314410480349345), 9: np.float64(0.684931506849315), 10: np.float64(0.2976190476190476), 11: np.float64(0.0915032679738562), 12: np.float64(0.2246376811594203), 13: np.float64(0.0425531914893617), 14: np.float64(0.11842105263157894), 15: np.float64(0.2553191489361702), 16: np.float64(0.71875), 17: np.float64(0.0), 18: np.float64(0.1111111111111111), 19: np.float64(0.46831955922865015), 20: np.float64(0.47959183673469385), 21: np.float64(0.19718309859154928), 22: np.float64(0.5093632958801498), 23: np.float64(0.6521739130434783), 24: np.float64(0.0425531914893617), 25: np.float64(0.4507042253521127), 26: np.float64(0.6532663316582915), 27: np.float64(0.0), 28: np.float64(0.18867924528301888), 29: np.float64(0.8037383177570093), 30: np.float64(0.7058823529411765), 31: np.float64(0.08695652173913043), 32: np.float64(0.5165562913907285), 33: np.float64(0.19607843137254902), 34: np.float64(0.3044982698961938), 35: np.float64(0.14659685863874344), 36: np.float64(0.4782608695652174), 37: np.float64(0.2127659574468085), 38: np.float64(0.33962264150943394), 39: np.float64(0.17857142857142858), 40: np.float64(0.15469613259668508)}
Micro-average F1 score: 0.3760427093760427
Weighted-average F1 score: 0.3602919384750482

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.373134328358209), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.6174496644295302), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.85), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.35294117647058826), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.3564356435643564), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2934051144010767
Weighted-average F1 score: 0.2165561173972001
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.5405405405405406), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.6174496644295302), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8571428571428571), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.3076923076923077), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.4713375796178344), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2998965873836608
Weighted-average F1 score: 0.22023821251618864
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.5034965034965035), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.6025641025641025), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8780487804878049), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.37037037037037035), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.4583333333333333), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.305159165751921
Weighted-average F1 score: 0.2259872364337931

F1 score per class: {0: np.float64(0.43870967741935485), 1: np.float64(0.10819672131147541), 2: np.float64(0.1076923076923077), 3: np.float64(0.2749326145552561), 4: np.float64(0.6946107784431138), 5: np.float64(0.6241610738255033), 6: np.float64(0.23036649214659685), 7: np.float64(0.02), 8: np.float64(0.14836795252225518), 9: np.float64(0.625), 10: np.float64(0.22093023255813954), 11: np.float64(0.06666666666666667), 12: np.float64(0.12403100775193798), 13: np.float64(0.02531645569620253), 14: np.float64(0.05319148936170213), 15: np.float64(0.2), 16: np.float64(0.449438202247191), 17: np.float64(0.0), 18: np.float64(0.05825242718446602), 19: np.float64(0.4797507788161994), 20: np.float64(0.22885572139303484), 21: np.float64(0.0), 22: np.float64(0.484375), 23: np.float64(0.6730769230769231), 24: np.float64(0.0), 25: np.float64(0.3582089552238806), 26: np.float64(0.6048780487804878), 27: np.float64(0.0), 28: np.float64(0.136986301369863), 29: np.float64(0.6254826254826255), 30: np.float64(0.7906976744186046), 31: np.float64(0.11764705882352941), 32: np.float64(0.4020356234096692), 33: np.float64(0.10714285714285714), 34: np.float64(0.1857451403887689), 35: np.float64(0.1005586592178771), 36: np.float64(0.23684210526315788), 37: np.float64(0.21359223300970873), 38: np.float64(0.15384615384615385), 39: np.float64(0.08620689655172414), 40: np.float64(0.19117647058823528)}
Micro-average F1 score: 0.2782700700965481
Weighted-average F1 score: 0.25973063535374147
F1 score per class: {0: np.float64(0.22018348623853212), 1: np.float64(0.0994671403197158), 2: np.float64(0.06140350877192982), 3: np.float64(0.2222222222222222), 4: np.float64(0.7011494252873564), 5: np.float64(0.31160572337042924), 6: np.float64(0.24675324675324675), 7: np.float64(0.014814814814814815), 8: np.float64(0.16632016632016633), 9: np.float64(0.30864197530864196), 10: np.float64(0.22745098039215686), 11: np.float64(0.08917197452229299), 12: np.float64(0.1169811320754717), 13: np.float64(0.03125), 14: np.float64(0.08450704225352113), 15: np.float64(0.23076923076923078), 16: np.float64(0.42105263157894735), 17: np.float64(0.0), 18: np.float64(0.08560311284046693), 19: np.float64(0.35343035343035345), 20: np.float64(0.24083769633507854), 21: np.float64(0.09615384615384616), 22: np.float64(0.3394495412844037), 23: np.float64(0.4861111111111111), 24: np.float64(0.05555555555555555), 25: np.float64(0.45), 26: np.float64(0.5551020408163265), 27: np.float64(0.0), 28: np.float64(0.09009009009009009), 29: np.float64(0.63003663003663), 30: np.float64(0.4235294117647059), 31: np.float64(0.038461538461538464), 32: np.float64(0.37037037037037035), 33: np.float64(0.09090909090909091), 34: np.float64(0.19230769230769232), 35: np.float64(0.13333333333333333), 36: np.float64(0.2690909090909091), 37: np.float64(0.14925373134328357), 38: np.float64(0.21782178217821782), 39: np.float64(0.1111111111111111), 40: np.float64(0.14659685863874344)}
Micro-average F1 score: 0.24146872731044497
Weighted-average F1 score: 0.2292532949145675
F1 score per class: {0: np.float64(0.27169811320754716), 1: np.float64(0.10130718954248366), 2: np.float64(0.06896551724137931), 3: np.float64(0.21158690176322417), 4: np.float64(0.7100591715976331), 5: np.float64(0.4109014675052411), 6: np.float64(0.23976608187134502), 7: np.float64(0.015625), 8: np.float64(0.17777777777777778), 9: np.float64(0.5681818181818182), 10: np.float64(0.22026431718061673), 11: np.float64(0.07692307692307693), 12: np.float64(0.1150278293135436), 13: np.float64(0.030303030303030304), 14: np.float64(0.08653846153846154), 15: np.float64(0.18181818181818182), 16: np.float64(0.44660194174757284), 17: np.float64(0.0), 18: np.float64(0.0782122905027933), 19: np.float64(0.4028436018957346), 20: np.float64(0.22541966426858512), 21: np.float64(0.1308411214953271), 22: np.float64(0.4059701492537313), 23: np.float64(0.5454545454545454), 24: np.float64(0.03333333333333333), 25: np.float64(0.4266666666666667), 26: np.float64(0.5603448275862069), 27: np.float64(0.0), 28: np.float64(0.09803921568627451), 29: np.float64(0.6346863468634686), 30: np.float64(0.5538461538461539), 31: np.float64(0.05263157894736842), 32: np.float64(0.36879432624113473), 33: np.float64(0.11494252873563218), 34: np.float64(0.17254901960784313), 35: np.float64(0.10071942446043165), 36: np.float64(0.28448275862068967), 37: np.float64(0.14925373134328357), 38: np.float64(0.21176470588235294), 39: np.float64(0.09345794392523364), 40: np.float64(0.12612612612612611)}
Micro-average F1 score: 0.25038880248833595
Weighted-average F1 score: 0.2353931377207274
cur_acc_wo_na:  ['0.7728', '0.2828', '0.6408', '0.5743', '0.4237', '0.3473', '0.3603', '0.4325']
his_acc_wo_na:  ['0.7728', '0.5307', '0.5608', '0.5901', '0.5261', '0.4433', '0.3970', '0.4024']
cur_acc des_wo_na:  ['0.7623', '0.3206', '0.6185', '0.5359', '0.4553', '0.3372', '0.3100', '0.4754']
his_acc des_wo_na:  ['0.7623', '0.5693', '0.5531', '0.5422', '0.5050', '0.4284', '0.3781', '0.3660']
cur_acc rrf_wo_na:  ['0.7725', '0.3099', '0.6287', '0.5516', '0.4529', '0.3879', '0.3368', '0.4801']
his_acc rrf_wo_na:  ['0.7725', '0.5702', '0.5654', '0.5593', '0.5155', '0.4483', '0.3821', '0.3760']
cur_acc_w_na:  ['0.6487', '0.2421', '0.4815', '0.4252', '0.3163', '0.2320', '0.2411', '0.2934']
his_acc_w_na:  ['0.6487', '0.4283', '0.4285', '0.4675', '0.3831', '0.3097', '0.2741', '0.2783']
cur_acc des_w_na:  ['0.6164', '0.2822', '0.4629', '0.3621', '0.3154', '0.2210', '0.2044', '0.2999']
his_acc des_w_na:  ['0.6164', '0.4675', '0.4206', '0.4065', '0.3499', '0.2869', '0.2552', '0.2415']
cur_acc rrf_w_na:  ['0.6289', '0.2724', '0.4703', '0.3773', '0.3266', '0.2544', '0.2222', '0.3052']
his_acc rrf_w_na:  ['0.6289', '0.4681', '0.4314', '0.4231', '0.3635', '0.3057', '0.2600', '0.2504']
--------Round  4
seed:  500
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 5 6 4 2 1 3 0]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 128.2793996CurrentTrain: epoch  0, batch     1 | loss: 81.2739894CurrentTrain: epoch  0, batch     2 | loss: 123.0037855CurrentTrain: epoch  0, batch     3 | loss: 101.9660600CurrentTrain: epoch  0, batch     4 | loss: 101.4356778CurrentTrain: epoch  0, batch     5 | loss: 87.3018636CurrentTrain: epoch  0, batch     6 | loss: 118.9738277CurrentTrain: epoch  0, batch     7 | loss: 99.8740276CurrentTrain: epoch  0, batch     8 | loss: 146.8281385CurrentTrain: epoch  0, batch     9 | loss: 100.2788278CurrentTrain: epoch  0, batch    10 | loss: 118.1309823CurrentTrain: epoch  0, batch    11 | loss: 118.6467762CurrentTrain: epoch  0, batch    12 | loss: 100.3979412CurrentTrain: epoch  0, batch    13 | loss: 119.2788435CurrentTrain: epoch  0, batch    14 | loss: 99.8968966CurrentTrain: epoch  0, batch    15 | loss: 192.8905503CurrentTrain: epoch  0, batch    16 | loss: 119.0957843CurrentTrain: epoch  0, batch    17 | loss: 118.7640077CurrentTrain: epoch  0, batch    18 | loss: 117.7209256CurrentTrain: epoch  0, batch    19 | loss: 99.5949751CurrentTrain: epoch  0, batch    20 | loss: 86.7138715CurrentTrain: epoch  0, batch    21 | loss: 87.5965159CurrentTrain: epoch  0, batch    22 | loss: 99.0166024CurrentTrain: epoch  0, batch    23 | loss: 98.7207699CurrentTrain: epoch  0, batch    24 | loss: 85.5605155CurrentTrain: epoch  0, batch    25 | loss: 116.6559864CurrentTrain: epoch  0, batch    26 | loss: 98.2898751CurrentTrain: epoch  0, batch    27 | loss: 76.0110047CurrentTrain: epoch  0, batch    28 | loss: 117.6017444CurrentTrain: epoch  0, batch    29 | loss: 85.5206788CurrentTrain: epoch  0, batch    30 | loss: 117.4472373CurrentTrain: epoch  0, batch    31 | loss: 85.0785083CurrentTrain: epoch  0, batch    32 | loss: 75.2077010CurrentTrain: epoch  0, batch    33 | loss: 192.0368068CurrentTrain: epoch  0, batch    34 | loss: 84.1994244CurrentTrain: epoch  0, batch    35 | loss: 85.4524903CurrentTrain: epoch  0, batch    36 | loss: 117.4126905CurrentTrain: epoch  0, batch    37 | loss: 74.6573206CurrentTrain: epoch  0, batch    38 | loss: 96.6465419CurrentTrain: epoch  0, batch    39 | loss: 97.0284733CurrentTrain: epoch  0, batch    40 | loss: 97.1396713CurrentTrain: epoch  0, batch    41 | loss: 73.5307142CurrentTrain: epoch  0, batch    42 | loss: 190.5210964CurrentTrain: epoch  0, batch    43 | loss: 74.0887302CurrentTrain: epoch  0, batch    44 | loss: 114.4805100CurrentTrain: epoch  0, batch    45 | loss: 83.1138853CurrentTrain: epoch  0, batch    46 | loss: 96.8998645CurrentTrain: epoch  0, batch    47 | loss: 115.0444820CurrentTrain: epoch  0, batch    48 | loss: 83.0797361CurrentTrain: epoch  0, batch    49 | loss: 95.7589977CurrentTrain: epoch  0, batch    50 | loss: 94.5574482CurrentTrain: epoch  0, batch    51 | loss: 115.6963577CurrentTrain: epoch  0, batch    52 | loss: 83.1907747CurrentTrain: epoch  0, batch    53 | loss: 83.8346218CurrentTrain: epoch  0, batch    54 | loss: 96.9127421CurrentTrain: epoch  0, batch    55 | loss: 81.5910344CurrentTrain: epoch  0, batch    56 | loss: 81.4348046CurrentTrain: epoch  0, batch    57 | loss: 111.8013207CurrentTrain: epoch  0, batch    58 | loss: 112.9476915CurrentTrain: epoch  0, batch    59 | loss: 142.7209524CurrentTrain: epoch  0, batch    60 | loss: 94.3068525CurrentTrain: epoch  0, batch    61 | loss: 94.5386165CurrentTrain: epoch  0, batch    62 | loss: 93.1474474CurrentTrain: epoch  0, batch    63 | loss: 78.4581856CurrentTrain: epoch  0, batch    64 | loss: 95.1640112CurrentTrain: epoch  0, batch    65 | loss: 91.0178149CurrentTrain: epoch  0, batch    66 | loss: 80.1935737CurrentTrain: epoch  0, batch    67 | loss: 70.5178653CurrentTrain: epoch  0, batch    68 | loss: 78.2152578CurrentTrain: epoch  0, batch    69 | loss: 96.6756380CurrentTrain: epoch  0, batch    70 | loss: 113.5340980CurrentTrain: epoch  0, batch    71 | loss: 111.7688736CurrentTrain: epoch  0, batch    72 | loss: 76.4754176CurrentTrain: epoch  0, batch    73 | loss: 107.2961198CurrentTrain: epoch  0, batch    74 | loss: 75.2413355CurrentTrain: epoch  0, batch    75 | loss: 94.0633634CurrentTrain: epoch  0, batch    76 | loss: 141.5950906CurrentTrain: epoch  0, batch    77 | loss: 186.8627886CurrentTrain: epoch  0, batch    78 | loss: 79.9053487CurrentTrain: epoch  0, batch    79 | loss: 79.9142768CurrentTrain: epoch  0, batch    80 | loss: 138.3148778CurrentTrain: epoch  0, batch    81 | loss: 80.9683481CurrentTrain: epoch  0, batch    82 | loss: 142.6086587CurrentTrain: epoch  0, batch    83 | loss: 188.4803646CurrentTrain: epoch  0, batch    84 | loss: 82.5834033CurrentTrain: epoch  0, batch    85 | loss: 68.3636188CurrentTrain: epoch  0, batch    86 | loss: 89.7629179CurrentTrain: epoch  0, batch    87 | loss: 66.3248880CurrentTrain: epoch  0, batch    88 | loss: 113.4804551CurrentTrain: epoch  0, batch    89 | loss: 78.4120638CurrentTrain: epoch  0, batch    90 | loss: 91.4260653CurrentTrain: epoch  0, batch    91 | loss: 110.7093849CurrentTrain: epoch  0, batch    92 | loss: 94.3406952CurrentTrain: epoch  0, batch    93 | loss: 113.1283713CurrentTrain: epoch  0, batch    94 | loss: 87.2420037CurrentTrain: epoch  0, batch    95 | loss: 77.0341462CurrentTrain: epoch  1, batch     0 | loss: 81.0735648CurrentTrain: epoch  1, batch     1 | loss: 91.1906277CurrentTrain: epoch  1, batch     2 | loss: 68.8481272CurrentTrain: epoch  1, batch     3 | loss: 139.4923596CurrentTrain: epoch  1, batch     4 | loss: 111.1340827CurrentTrain: epoch  1, batch     5 | loss: 91.3228228CurrentTrain: epoch  1, batch     6 | loss: 138.4551725CurrentTrain: epoch  1, batch     7 | loss: 75.4479472CurrentTrain: epoch  1, batch     8 | loss: 89.8927784CurrentTrain: epoch  1, batch     9 | loss: 91.5588478CurrentTrain: epoch  1, batch    10 | loss: 87.9280383CurrentTrain: epoch  1, batch    11 | loss: 90.2637187CurrentTrain: epoch  1, batch    12 | loss: 184.7855560CurrentTrain: epoch  1, batch    13 | loss: 78.7005848CurrentTrain: epoch  1, batch    14 | loss: 73.7347199CurrentTrain: epoch  1, batch    15 | loss: 92.1894861CurrentTrain: epoch  1, batch    16 | loss: 66.2740938CurrentTrain: epoch  1, batch    17 | loss: 77.8361699CurrentTrain: epoch  1, batch    18 | loss: 62.6113176CurrentTrain: epoch  1, batch    19 | loss: 109.4812789CurrentTrain: epoch  1, batch    20 | loss: 85.1949729CurrentTrain: epoch  1, batch    21 | loss: 91.3261495CurrentTrain: epoch  1, batch    22 | loss: 74.0504072CurrentTrain: epoch  1, batch    23 | loss: 109.6904035CurrentTrain: epoch  1, batch    24 | loss: 92.8018196CurrentTrain: epoch  1, batch    25 | loss: 103.1961733CurrentTrain: epoch  1, batch    26 | loss: 101.0339405CurrentTrain: epoch  1, batch    27 | loss: 89.6128948CurrentTrain: epoch  1, batch    28 | loss: 91.0871427CurrentTrain: epoch  1, batch    29 | loss: 89.0153165CurrentTrain: epoch  1, batch    30 | loss: 88.5041342CurrentTrain: epoch  1, batch    31 | loss: 106.6659245CurrentTrain: epoch  1, batch    32 | loss: 75.8463385CurrentTrain: epoch  1, batch    33 | loss: 106.1430216CurrentTrain: epoch  1, batch    34 | loss: 88.1049702CurrentTrain: epoch  1, batch    35 | loss: 87.5825037CurrentTrain: epoch  1, batch    36 | loss: 77.6760454CurrentTrain: epoch  1, batch    37 | loss: 85.2230914CurrentTrain: epoch  1, batch    38 | loss: 66.9068938CurrentTrain: epoch  1, batch    39 | loss: 108.9125061CurrentTrain: epoch  1, batch    40 | loss: 106.8579627CurrentTrain: epoch  1, batch    41 | loss: 106.8094887CurrentTrain: epoch  1, batch    42 | loss: 89.5998079CurrentTrain: epoch  1, batch    43 | loss: 87.0454210CurrentTrain: epoch  1, batch    44 | loss: 90.2452318CurrentTrain: epoch  1, batch    45 | loss: 134.9430418CurrentTrain: epoch  1, batch    46 | loss: 83.1950194CurrentTrain: epoch  1, batch    47 | loss: 104.0289307CurrentTrain: epoch  1, batch    48 | loss: 108.6678223CurrentTrain: epoch  1, batch    49 | loss: 108.2402638CurrentTrain: epoch  1, batch    50 | loss: 78.1207033CurrentTrain: epoch  1, batch    51 | loss: 112.0911422CurrentTrain: epoch  1, batch    52 | loss: 86.3654064CurrentTrain: epoch  1, batch    53 | loss: 92.1609331CurrentTrain: epoch  1, batch    54 | loss: 139.8068063CurrentTrain: epoch  1, batch    55 | loss: 83.5342387CurrentTrain: epoch  1, batch    56 | loss: 70.2761941CurrentTrain: epoch  1, batch    57 | loss: 106.3731300CurrentTrain: epoch  1, batch    58 | loss: 88.0989318CurrentTrain: epoch  1, batch    59 | loss: 85.0934085CurrentTrain: epoch  1, batch    60 | loss: 71.2925465CurrentTrain: epoch  1, batch    61 | loss: 90.3571170CurrentTrain: epoch  1, batch    62 | loss: 104.2114767CurrentTrain: epoch  1, batch    63 | loss: 86.6157472CurrentTrain: epoch  1, batch    64 | loss: 86.4885584CurrentTrain: epoch  1, batch    65 | loss: 76.6995869CurrentTrain: epoch  1, batch    66 | loss: 89.5924768CurrentTrain: epoch  1, batch    67 | loss: 74.8201929CurrentTrain: epoch  1, batch    68 | loss: 76.1742300CurrentTrain: epoch  1, batch    69 | loss: 108.0726979CurrentTrain: epoch  1, batch    70 | loss: 105.6060971CurrentTrain: epoch  1, batch    71 | loss: 74.6096208CurrentTrain: epoch  1, batch    72 | loss: 182.8727646CurrentTrain: epoch  1, batch    73 | loss: 65.3283673CurrentTrain: epoch  1, batch    74 | loss: 75.7646763CurrentTrain: epoch  1, batch    75 | loss: 106.3668534CurrentTrain: epoch  1, batch    76 | loss: 107.0662706CurrentTrain: epoch  1, batch    77 | loss: 105.7303133CurrentTrain: epoch  1, batch    78 | loss: 104.1599188CurrentTrain: epoch  1, batch    79 | loss: 73.8111685CurrentTrain: epoch  1, batch    80 | loss: 92.1722456CurrentTrain: epoch  1, batch    81 | loss: 63.9720386CurrentTrain: epoch  1, batch    82 | loss: 77.7086196CurrentTrain: epoch  1, batch    83 | loss: 74.2514213CurrentTrain: epoch  1, batch    84 | loss: 84.5596568CurrentTrain: epoch  1, batch    85 | loss: 106.4338341CurrentTrain: epoch  1, batch    86 | loss: 92.9703762CurrentTrain: epoch  1, batch    87 | loss: 89.4400552CurrentTrain: epoch  1, batch    88 | loss: 108.6037848CurrentTrain: epoch  1, batch    89 | loss: 184.9038244CurrentTrain: epoch  1, batch    90 | loss: 87.3029025CurrentTrain: epoch  1, batch    91 | loss: 137.8006797CurrentTrain: epoch  1, batch    92 | loss: 108.8132919CurrentTrain: epoch  1, batch    93 | loss: 72.0526842CurrentTrain: epoch  1, batch    94 | loss: 103.7576460CurrentTrain: epoch  1, batch    95 | loss: 75.2853186CurrentTrain: epoch  2, batch     0 | loss: 105.5053086CurrentTrain: epoch  2, batch     1 | loss: 131.2262643CurrentTrain: epoch  2, batch     2 | loss: 88.2660253CurrentTrain: epoch  2, batch     3 | loss: 110.8716150CurrentTrain: epoch  2, batch     4 | loss: 87.4804460CurrentTrain: epoch  2, batch     5 | loss: 90.7803065CurrentTrain: epoch  2, batch     6 | loss: 85.9610319CurrentTrain: epoch  2, batch     7 | loss: 88.3004352CurrentTrain: epoch  2, batch     8 | loss: 86.7563686CurrentTrain: epoch  2, batch     9 | loss: 69.2157280CurrentTrain: epoch  2, batch    10 | loss: 103.4535850CurrentTrain: epoch  2, batch    11 | loss: 65.9709442CurrentTrain: epoch  2, batch    12 | loss: 134.9427475CurrentTrain: epoch  2, batch    13 | loss: 72.4967482CurrentTrain: epoch  2, batch    14 | loss: 72.2464311CurrentTrain: epoch  2, batch    15 | loss: 71.9732855CurrentTrain: epoch  2, batch    16 | loss: 104.5672588CurrentTrain: epoch  2, batch    17 | loss: 87.3683618CurrentTrain: epoch  2, batch    18 | loss: 107.2875029CurrentTrain: epoch  2, batch    19 | loss: 84.5507707CurrentTrain: epoch  2, batch    20 | loss: 104.5646696CurrentTrain: epoch  2, batch    21 | loss: 87.2613335CurrentTrain: epoch  2, batch    22 | loss: 137.8139814CurrentTrain: epoch  2, batch    23 | loss: 102.0577621CurrentTrain: epoch  2, batch    24 | loss: 88.7754139CurrentTrain: epoch  2, batch    25 | loss: 104.4741986CurrentTrain: epoch  2, batch    26 | loss: 106.4346801CurrentTrain: epoch  2, batch    27 | loss: 89.5957110CurrentTrain: epoch  2, batch    28 | loss: 91.4678380CurrentTrain: epoch  2, batch    29 | loss: 108.4844244CurrentTrain: epoch  2, batch    30 | loss: 73.6249072CurrentTrain: epoch  2, batch    31 | loss: 77.5719656CurrentTrain: epoch  2, batch    32 | loss: 86.0101569CurrentTrain: epoch  2, batch    33 | loss: 75.0718100CurrentTrain: epoch  2, batch    34 | loss: 88.9309347CurrentTrain: epoch  2, batch    35 | loss: 106.6003387CurrentTrain: epoch  2, batch    36 | loss: 84.8837213CurrentTrain: epoch  2, batch    37 | loss: 70.4753446CurrentTrain: epoch  2, batch    38 | loss: 64.3808195CurrentTrain: epoch  2, batch    39 | loss: 71.2351356CurrentTrain: epoch  2, batch    40 | loss: 84.8274847CurrentTrain: epoch  2, batch    41 | loss: 86.7158214CurrentTrain: epoch  2, batch    42 | loss: 85.8560315CurrentTrain: epoch  2, batch    43 | loss: 87.3751597CurrentTrain: epoch  2, batch    44 | loss: 88.7673709CurrentTrain: epoch  2, batch    45 | loss: 85.6794965CurrentTrain: epoch  2, batch    46 | loss: 84.0663085CurrentTrain: epoch  2, batch    47 | loss: 131.3225142CurrentTrain: epoch  2, batch    48 | loss: 133.1343573CurrentTrain: epoch  2, batch    49 | loss: 68.1002307CurrentTrain: epoch  2, batch    50 | loss: 63.1775526CurrentTrain: epoch  2, batch    51 | loss: 72.7101754CurrentTrain: epoch  2, batch    52 | loss: 73.2509302CurrentTrain: epoch  2, batch    53 | loss: 69.5091320CurrentTrain: epoch  2, batch    54 | loss: 82.7699066CurrentTrain: epoch  2, batch    55 | loss: 103.1724798CurrentTrain: epoch  2, batch    56 | loss: 71.9707130CurrentTrain: epoch  2, batch    57 | loss: 102.9371613CurrentTrain: epoch  2, batch    58 | loss: 132.2369036CurrentTrain: epoch  2, batch    59 | loss: 70.8019958CurrentTrain: epoch  2, batch    60 | loss: 88.2897670CurrentTrain: epoch  2, batch    61 | loss: 88.6337396CurrentTrain: epoch  2, batch    62 | loss: 71.1609187CurrentTrain: epoch  2, batch    63 | loss: 74.9526593CurrentTrain: epoch  2, batch    64 | loss: 79.7181344CurrentTrain: epoch  2, batch    65 | loss: 60.3069740CurrentTrain: epoch  2, batch    66 | loss: 102.3680803CurrentTrain: epoch  2, batch    67 | loss: 71.7940848CurrentTrain: epoch  2, batch    68 | loss: 88.5963678CurrentTrain: epoch  2, batch    69 | loss: 87.0547134CurrentTrain: epoch  2, batch    70 | loss: 90.2530801CurrentTrain: epoch  2, batch    71 | loss: 128.8149229CurrentTrain: epoch  2, batch    72 | loss: 60.3958457CurrentTrain: epoch  2, batch    73 | loss: 103.7763790CurrentTrain: epoch  2, batch    74 | loss: 61.1485771CurrentTrain: epoch  2, batch    75 | loss: 85.9929333CurrentTrain: epoch  2, batch    76 | loss: 68.9887010CurrentTrain: epoch  2, batch    77 | loss: 64.5169591CurrentTrain: epoch  2, batch    78 | loss: 132.8582491CurrentTrain: epoch  2, batch    79 | loss: 104.5853692CurrentTrain: epoch  2, batch    80 | loss: 63.1505676CurrentTrain: epoch  2, batch    81 | loss: 77.3892145CurrentTrain: epoch  2, batch    82 | loss: 63.2207898CurrentTrain: epoch  2, batch    83 | loss: 84.6431770CurrentTrain: epoch  2, batch    84 | loss: 104.5650017CurrentTrain: epoch  2, batch    85 | loss: 70.2566716CurrentTrain: epoch  2, batch    86 | loss: 65.4542496CurrentTrain: epoch  2, batch    87 | loss: 83.7270311CurrentTrain: epoch  2, batch    88 | loss: 137.1586345CurrentTrain: epoch  2, batch    89 | loss: 74.8282426CurrentTrain: epoch  2, batch    90 | loss: 105.8422608CurrentTrain: epoch  2, batch    91 | loss: 106.8743396CurrentTrain: epoch  2, batch    92 | loss: 83.4861899CurrentTrain: epoch  2, batch    93 | loss: 88.8152086CurrentTrain: epoch  2, batch    94 | loss: 106.1926269CurrentTrain: epoch  2, batch    95 | loss: 72.7433320CurrentTrain: epoch  3, batch     0 | loss: 102.6253640CurrentTrain: epoch  3, batch     1 | loss: 82.2597486CurrentTrain: epoch  3, batch     2 | loss: 84.6264471CurrentTrain: epoch  3, batch     3 | loss: 73.4187987CurrentTrain: epoch  3, batch     4 | loss: 71.9952819CurrentTrain: epoch  3, batch     5 | loss: 82.9145813CurrentTrain: epoch  3, batch     6 | loss: 85.8155225CurrentTrain: epoch  3, batch     7 | loss: 126.8345275CurrentTrain: epoch  3, batch     8 | loss: 60.2307945CurrentTrain: epoch  3, batch     9 | loss: 106.8665077CurrentTrain: epoch  3, batch    10 | loss: 77.3179263CurrentTrain: epoch  3, batch    11 | loss: 69.4896501CurrentTrain: epoch  3, batch    12 | loss: 125.3245036CurrentTrain: epoch  3, batch    13 | loss: 72.4493757CurrentTrain: epoch  3, batch    14 | loss: 175.0989979CurrentTrain: epoch  3, batch    15 | loss: 132.0576425CurrentTrain: epoch  3, batch    16 | loss: 99.6292281CurrentTrain: epoch  3, batch    17 | loss: 85.4542081CurrentTrain: epoch  3, batch    18 | loss: 69.2901176CurrentTrain: epoch  3, batch    19 | loss: 71.5658854CurrentTrain: epoch  3, batch    20 | loss: 125.7857746CurrentTrain: epoch  3, batch    21 | loss: 69.6962735CurrentTrain: epoch  3, batch    22 | loss: 71.1848648CurrentTrain: epoch  3, batch    23 | loss: 73.3545083CurrentTrain: epoch  3, batch    24 | loss: 84.5385619CurrentTrain: epoch  3, batch    25 | loss: 88.8487394CurrentTrain: epoch  3, batch    26 | loss: 64.8067597CurrentTrain: epoch  3, batch    27 | loss: 66.0511528CurrentTrain: epoch  3, batch    28 | loss: 86.4468183CurrentTrain: epoch  3, batch    29 | loss: 68.4757139CurrentTrain: epoch  3, batch    30 | loss: 73.8498267CurrentTrain: epoch  3, batch    31 | loss: 84.1122870CurrentTrain: epoch  3, batch    32 | loss: 86.3647537CurrentTrain: epoch  3, batch    33 | loss: 81.2704593CurrentTrain: epoch  3, batch    34 | loss: 84.9707447CurrentTrain: epoch  3, batch    35 | loss: 82.3701053CurrentTrain: epoch  3, batch    36 | loss: 80.7763956CurrentTrain: epoch  3, batch    37 | loss: 100.9952087CurrentTrain: epoch  3, batch    38 | loss: 111.6132770CurrentTrain: epoch  3, batch    39 | loss: 86.6510790CurrentTrain: epoch  3, batch    40 | loss: 62.8417919CurrentTrain: epoch  3, batch    41 | loss: 103.0891222CurrentTrain: epoch  3, batch    42 | loss: 89.1776098CurrentTrain: epoch  3, batch    43 | loss: 72.3770779CurrentTrain: epoch  3, batch    44 | loss: 86.3032774CurrentTrain: epoch  3, batch    45 | loss: 85.6849779CurrentTrain: epoch  3, batch    46 | loss: 73.4134788CurrentTrain: epoch  3, batch    47 | loss: 80.9911195CurrentTrain: epoch  3, batch    48 | loss: 66.1778919CurrentTrain: epoch  3, batch    49 | loss: 75.2252458CurrentTrain: epoch  3, batch    50 | loss: 70.5582867CurrentTrain: epoch  3, batch    51 | loss: 80.5702713CurrentTrain: epoch  3, batch    52 | loss: 86.5658599CurrentTrain: epoch  3, batch    53 | loss: 83.7560909CurrentTrain: epoch  3, batch    54 | loss: 72.6810516CurrentTrain: epoch  3, batch    55 | loss: 135.4019351CurrentTrain: epoch  3, batch    56 | loss: 81.7478441CurrentTrain: epoch  3, batch    57 | loss: 98.5708972CurrentTrain: epoch  3, batch    58 | loss: 60.9679864CurrentTrain: epoch  3, batch    59 | loss: 101.8583033CurrentTrain: epoch  3, batch    60 | loss: 84.5915793CurrentTrain: epoch  3, batch    61 | loss: 84.9558070CurrentTrain: epoch  3, batch    62 | loss: 182.0354460CurrentTrain: epoch  3, batch    63 | loss: 85.5883908CurrentTrain: epoch  3, batch    64 | loss: 83.8965379CurrentTrain: epoch  3, batch    65 | loss: 106.3321670CurrentTrain: epoch  3, batch    66 | loss: 77.5045042CurrentTrain: epoch  3, batch    67 | loss: 67.9953623CurrentTrain: epoch  3, batch    68 | loss: 71.9996546CurrentTrain: epoch  3, batch    69 | loss: 71.7523816CurrentTrain: epoch  3, batch    70 | loss: 57.4069389CurrentTrain: epoch  3, batch    71 | loss: 79.3837117CurrentTrain: epoch  3, batch    72 | loss: 78.1703692CurrentTrain: epoch  3, batch    73 | loss: 86.2231347CurrentTrain: epoch  3, batch    74 | loss: 107.4084319CurrentTrain: epoch  3, batch    75 | loss: 84.7521286CurrentTrain: epoch  3, batch    76 | loss: 87.1781695CurrentTrain: epoch  3, batch    77 | loss: 87.3530922CurrentTrain: epoch  3, batch    78 | loss: 72.9026043CurrentTrain: epoch  3, batch    79 | loss: 103.5157867CurrentTrain: epoch  3, batch    80 | loss: 71.2369977CurrentTrain: epoch  3, batch    81 | loss: 99.8925538CurrentTrain: epoch  3, batch    82 | loss: 101.8937892CurrentTrain: epoch  3, batch    83 | loss: 64.4751918CurrentTrain: epoch  3, batch    84 | loss: 88.6071819CurrentTrain: epoch  3, batch    85 | loss: 127.8111656CurrentTrain: epoch  3, batch    86 | loss: 71.6133501CurrentTrain: epoch  3, batch    87 | loss: 101.9874236CurrentTrain: epoch  3, batch    88 | loss: 105.1783989CurrentTrain: epoch  3, batch    89 | loss: 80.0016203CurrentTrain: epoch  3, batch    90 | loss: 82.1870899CurrentTrain: epoch  3, batch    91 | loss: 85.2300428CurrentTrain: epoch  3, batch    92 | loss: 102.9878927CurrentTrain: epoch  3, batch    93 | loss: 74.6841806CurrentTrain: epoch  3, batch    94 | loss: 68.9888585CurrentTrain: epoch  3, batch    95 | loss: 76.5275009CurrentTrain: epoch  4, batch     0 | loss: 81.5471173CurrentTrain: epoch  4, batch     1 | loss: 61.3528192CurrentTrain: epoch  4, batch     2 | loss: 66.6225637CurrentTrain: epoch  4, batch     3 | loss: 169.4083756CurrentTrain: epoch  4, batch     4 | loss: 97.6072987CurrentTrain: epoch  4, batch     5 | loss: 76.4084200CurrentTrain: epoch  4, batch     6 | loss: 72.5155517CurrentTrain: epoch  4, batch     7 | loss: 80.6695905CurrentTrain: epoch  4, batch     8 | loss: 97.8517090CurrentTrain: epoch  4, batch     9 | loss: 70.8258432CurrentTrain: epoch  4, batch    10 | loss: 102.0667598CurrentTrain: epoch  4, batch    11 | loss: 69.9334598CurrentTrain: epoch  4, batch    12 | loss: 83.7713083CurrentTrain: epoch  4, batch    13 | loss: 69.4212330CurrentTrain: epoch  4, batch    14 | loss: 99.9149828CurrentTrain: epoch  4, batch    15 | loss: 105.5540553CurrentTrain: epoch  4, batch    16 | loss: 132.9580277CurrentTrain: epoch  4, batch    17 | loss: 124.8468955CurrentTrain: epoch  4, batch    18 | loss: 83.5943028CurrentTrain: epoch  4, batch    19 | loss: 69.5406737CurrentTrain: epoch  4, batch    20 | loss: 68.2847290CurrentTrain: epoch  4, batch    21 | loss: 128.2056670CurrentTrain: epoch  4, batch    22 | loss: 103.0087894CurrentTrain: epoch  4, batch    23 | loss: 81.0854429CurrentTrain: epoch  4, batch    24 | loss: 99.9735637CurrentTrain: epoch  4, batch    25 | loss: 66.5909658CurrentTrain: epoch  4, batch    26 | loss: 85.7831468CurrentTrain: epoch  4, batch    27 | loss: 100.6157564CurrentTrain: epoch  4, batch    28 | loss: 125.6542060CurrentTrain: epoch  4, batch    29 | loss: 78.9633232CurrentTrain: epoch  4, batch    30 | loss: 83.6915239CurrentTrain: epoch  4, batch    31 | loss: 67.8751483CurrentTrain: epoch  4, batch    32 | loss: 86.1555172CurrentTrain: epoch  4, batch    33 | loss: 61.6490964CurrentTrain: epoch  4, batch    34 | loss: 102.8518609CurrentTrain: epoch  4, batch    35 | loss: 85.6571210CurrentTrain: epoch  4, batch    36 | loss: 105.7780940CurrentTrain: epoch  4, batch    37 | loss: 74.9924344CurrentTrain: epoch  4, batch    38 | loss: 84.7820761CurrentTrain: epoch  4, batch    39 | loss: 65.7451974CurrentTrain: epoch  4, batch    40 | loss: 71.5947439CurrentTrain: epoch  4, batch    41 | loss: 82.4795941CurrentTrain: epoch  4, batch    42 | loss: 61.3138312CurrentTrain: epoch  4, batch    43 | loss: 103.3110908CurrentTrain: epoch  4, batch    44 | loss: 80.6674322CurrentTrain: epoch  4, batch    45 | loss: 98.1395027CurrentTrain: epoch  4, batch    46 | loss: 85.8191604CurrentTrain: epoch  4, batch    47 | loss: 126.3699548CurrentTrain: epoch  4, batch    48 | loss: 99.6806423CurrentTrain: epoch  4, batch    49 | loss: 67.8726882CurrentTrain: epoch  4, batch    50 | loss: 85.4487028CurrentTrain: epoch  4, batch    51 | loss: 128.9225562CurrentTrain: epoch  4, batch    52 | loss: 74.4350266CurrentTrain: epoch  4, batch    53 | loss: 83.8347181CurrentTrain: epoch  4, batch    54 | loss: 101.8326705CurrentTrain: epoch  4, batch    55 | loss: 98.3247990CurrentTrain: epoch  4, batch    56 | loss: 77.9739361CurrentTrain: epoch  4, batch    57 | loss: 86.9473150CurrentTrain: epoch  4, batch    58 | loss: 84.1206721CurrentTrain: epoch  4, batch    59 | loss: 70.9481005CurrentTrain: epoch  4, batch    60 | loss: 82.5168192CurrentTrain: epoch  4, batch    61 | loss: 62.7027028CurrentTrain: epoch  4, batch    62 | loss: 65.6329278CurrentTrain: epoch  4, batch    63 | loss: 85.1359207CurrentTrain: epoch  4, batch    64 | loss: 101.1307039CurrentTrain: epoch  4, batch    65 | loss: 67.4969859CurrentTrain: epoch  4, batch    66 | loss: 102.4151801CurrentTrain: epoch  4, batch    67 | loss: 68.6529027CurrentTrain: epoch  4, batch    68 | loss: 85.7264906CurrentTrain: epoch  4, batch    69 | loss: 77.2806167CurrentTrain: epoch  4, batch    70 | loss: 60.2064448CurrentTrain: epoch  4, batch    71 | loss: 103.5070205CurrentTrain: epoch  4, batch    72 | loss: 176.5686522CurrentTrain: epoch  4, batch    73 | loss: 68.5169506CurrentTrain: epoch  4, batch    74 | loss: 101.7279473CurrentTrain: epoch  4, batch    75 | loss: 74.7324791CurrentTrain: epoch  4, batch    76 | loss: 59.6569190CurrentTrain: epoch  4, batch    77 | loss: 83.7740263CurrentTrain: epoch  4, batch    78 | loss: 63.5197958CurrentTrain: epoch  4, batch    79 | loss: 83.0824628CurrentTrain: epoch  4, batch    80 | loss: 127.9503608CurrentTrain: epoch  4, batch    81 | loss: 82.3948966CurrentTrain: epoch  4, batch    82 | loss: 71.3995361CurrentTrain: epoch  4, batch    83 | loss: 129.1856954CurrentTrain: epoch  4, batch    84 | loss: 78.2593868CurrentTrain: epoch  4, batch    85 | loss: 103.8625279CurrentTrain: epoch  4, batch    86 | loss: 102.6497781CurrentTrain: epoch  4, batch    87 | loss: 83.2499828CurrentTrain: epoch  4, batch    88 | loss: 81.4378725CurrentTrain: epoch  4, batch    89 | loss: 71.1776287CurrentTrain: epoch  4, batch    90 | loss: 70.8547351CurrentTrain: epoch  4, batch    91 | loss: 135.5756530CurrentTrain: epoch  4, batch    92 | loss: 70.5988777CurrentTrain: epoch  4, batch    93 | loss: 69.7187353CurrentTrain: epoch  4, batch    94 | loss: 102.8700359CurrentTrain: epoch  4, batch    95 | loss: 46.4007420CurrentTrain: epoch  5, batch     0 | loss: 78.9147148CurrentTrain: epoch  5, batch     1 | loss: 62.5212156CurrentTrain: epoch  5, batch     2 | loss: 67.1195952CurrentTrain: epoch  5, batch     3 | loss: 124.9439596CurrentTrain: epoch  5, batch     4 | loss: 94.3642246CurrentTrain: epoch  5, batch     5 | loss: 93.4751041CurrentTrain: epoch  5, batch     6 | loss: 100.0079325CurrentTrain: epoch  5, batch     7 | loss: 78.0477909CurrentTrain: epoch  5, batch     8 | loss: 56.4850409CurrentTrain: epoch  5, batch     9 | loss: 103.5660725CurrentTrain: epoch  5, batch    10 | loss: 128.3312497CurrentTrain: epoch  5, batch    11 | loss: 79.0085982CurrentTrain: epoch  5, batch    12 | loss: 98.1666794CurrentTrain: epoch  5, batch    13 | loss: 71.6080131CurrentTrain: epoch  5, batch    14 | loss: 78.6636867CurrentTrain: epoch  5, batch    15 | loss: 81.2790602CurrentTrain: epoch  5, batch    16 | loss: 80.2517562CurrentTrain: epoch  5, batch    17 | loss: 81.1448281CurrentTrain: epoch  5, batch    18 | loss: 85.3621383CurrentTrain: epoch  5, batch    19 | loss: 124.1107319CurrentTrain: epoch  5, batch    20 | loss: 79.3448212CurrentTrain: epoch  5, batch    21 | loss: 100.2009559CurrentTrain: epoch  5, batch    22 | loss: 79.0660327CurrentTrain: epoch  5, batch    23 | loss: 91.8155377CurrentTrain: epoch  5, batch    24 | loss: 101.9383368CurrentTrain: epoch  5, batch    25 | loss: 81.6016014CurrentTrain: epoch  5, batch    26 | loss: 67.5716553CurrentTrain: epoch  5, batch    27 | loss: 95.5263989CurrentTrain: epoch  5, batch    28 | loss: 101.8031626CurrentTrain: epoch  5, batch    29 | loss: 69.8177021CurrentTrain: epoch  5, batch    30 | loss: 105.7176755CurrentTrain: epoch  5, batch    31 | loss: 81.6434008CurrentTrain: epoch  5, batch    32 | loss: 69.1757809CurrentTrain: epoch  5, batch    33 | loss: 85.5105034CurrentTrain: epoch  5, batch    34 | loss: 79.4307230CurrentTrain: epoch  5, batch    35 | loss: 80.1874799CurrentTrain: epoch  5, batch    36 | loss: 68.7630576CurrentTrain: epoch  5, batch    37 | loss: 70.4309997CurrentTrain: epoch  5, batch    38 | loss: 100.9913230CurrentTrain: epoch  5, batch    39 | loss: 57.4819235CurrentTrain: epoch  5, batch    40 | loss: 81.1701020CurrentTrain: epoch  5, batch    41 | loss: 57.6228763CurrentTrain: epoch  5, batch    42 | loss: 71.7535573CurrentTrain: epoch  5, batch    43 | loss: 55.8782739CurrentTrain: epoch  5, batch    44 | loss: 58.6735924CurrentTrain: epoch  5, batch    45 | loss: 84.4044433CurrentTrain: epoch  5, batch    46 | loss: 99.6261915CurrentTrain: epoch  5, batch    47 | loss: 101.8642324CurrentTrain: epoch  5, batch    48 | loss: 124.0713501CurrentTrain: epoch  5, batch    49 | loss: 98.2256109CurrentTrain: epoch  5, batch    50 | loss: 81.9315584CurrentTrain: epoch  5, batch    51 | loss: 82.5040650CurrentTrain: epoch  5, batch    52 | loss: 125.8973062CurrentTrain: epoch  5, batch    53 | loss: 87.2943785CurrentTrain: epoch  5, batch    54 | loss: 65.5888712CurrentTrain: epoch  5, batch    55 | loss: 102.1871382CurrentTrain: epoch  5, batch    56 | loss: 59.5492651CurrentTrain: epoch  5, batch    57 | loss: 96.9565754CurrentTrain: epoch  5, batch    58 | loss: 127.4150651CurrentTrain: epoch  5, batch    59 | loss: 94.8014505CurrentTrain: epoch  5, batch    60 | loss: 67.2940798CurrentTrain: epoch  5, batch    61 | loss: 71.1428090CurrentTrain: epoch  5, batch    62 | loss: 85.0995036CurrentTrain: epoch  5, batch    63 | loss: 64.8929345CurrentTrain: epoch  5, batch    64 | loss: 88.1037585CurrentTrain: epoch  5, batch    65 | loss: 77.6873867CurrentTrain: epoch  5, batch    66 | loss: 83.1482536CurrentTrain: epoch  5, batch    67 | loss: 85.2464596CurrentTrain: epoch  5, batch    68 | loss: 100.3089320CurrentTrain: epoch  5, batch    69 | loss: 65.2826969CurrentTrain: epoch  5, batch    70 | loss: 79.2207656CurrentTrain: epoch  5, batch    71 | loss: 126.2693049CurrentTrain: epoch  5, batch    72 | loss: 56.5944166CurrentTrain: epoch  5, batch    73 | loss: 58.1905794CurrentTrain: epoch  5, batch    74 | loss: 72.7243798CurrentTrain: epoch  5, batch    75 | loss: 65.1424034CurrentTrain: epoch  5, batch    76 | loss: 71.2084532CurrentTrain: epoch  5, batch    77 | loss: 72.2542461CurrentTrain: epoch  5, batch    78 | loss: 57.7922709CurrentTrain: epoch  5, batch    79 | loss: 68.1275770CurrentTrain: epoch  5, batch    80 | loss: 79.2825988CurrentTrain: epoch  5, batch    81 | loss: 99.4083427CurrentTrain: epoch  5, batch    82 | loss: 76.4827277CurrentTrain: epoch  5, batch    83 | loss: 123.8593552CurrentTrain: epoch  5, batch    84 | loss: 54.8960649CurrentTrain: epoch  5, batch    85 | loss: 98.8108274CurrentTrain: epoch  5, batch    86 | loss: 86.1058663CurrentTrain: epoch  5, batch    87 | loss: 128.7788527CurrentTrain: epoch  5, batch    88 | loss: 68.0809322CurrentTrain: epoch  5, batch    89 | loss: 101.1111267CurrentTrain: epoch  5, batch    90 | loss: 130.1832351CurrentTrain: epoch  5, batch    91 | loss: 99.3904763CurrentTrain: epoch  5, batch    92 | loss: 79.7957608CurrentTrain: epoch  5, batch    93 | loss: 72.3327969CurrentTrain: epoch  5, batch    94 | loss: 57.8265949CurrentTrain: epoch  5, batch    95 | loss: 81.1903188CurrentTrain: epoch  6, batch     0 | loss: 79.8160074CurrentTrain: epoch  6, batch     1 | loss: 82.3515450CurrentTrain: epoch  6, batch     2 | loss: 79.2160506CurrentTrain: epoch  6, batch     3 | loss: 78.7332903CurrentTrain: epoch  6, batch     4 | loss: 102.1111706CurrentTrain: epoch  6, batch     5 | loss: 79.2769870CurrentTrain: epoch  6, batch     6 | loss: 74.0200225CurrentTrain: epoch  6, batch     7 | loss: 82.7531427CurrentTrain: epoch  6, batch     8 | loss: 64.7594032CurrentTrain: epoch  6, batch     9 | loss: 96.5723648CurrentTrain: epoch  6, batch    10 | loss: 65.9188904CurrentTrain: epoch  6, batch    11 | loss: 66.4273743CurrentTrain: epoch  6, batch    12 | loss: 65.5079492CurrentTrain: epoch  6, batch    13 | loss: 100.1069251CurrentTrain: epoch  6, batch    14 | loss: 69.4764118CurrentTrain: epoch  6, batch    15 | loss: 68.7789492CurrentTrain: epoch  6, batch    16 | loss: 88.9242538CurrentTrain: epoch  6, batch    17 | loss: 98.1603534CurrentTrain: epoch  6, batch    18 | loss: 65.6623583CurrentTrain: epoch  6, batch    19 | loss: 126.1237483CurrentTrain: epoch  6, batch    20 | loss: 67.7783676CurrentTrain: epoch  6, batch    21 | loss: 54.5983678CurrentTrain: epoch  6, batch    22 | loss: 67.3047103CurrentTrain: epoch  6, batch    23 | loss: 68.8851517CurrentTrain: epoch  6, batch    24 | loss: 76.6635298CurrentTrain: epoch  6, batch    25 | loss: 97.5144292CurrentTrain: epoch  6, batch    26 | loss: 93.2558743CurrentTrain: epoch  6, batch    27 | loss: 77.5023560CurrentTrain: epoch  6, batch    28 | loss: 98.1991235CurrentTrain: epoch  6, batch    29 | loss: 79.9955192CurrentTrain: epoch  6, batch    30 | loss: 81.7558443CurrentTrain: epoch  6, batch    31 | loss: 100.7085975CurrentTrain: epoch  6, batch    32 | loss: 98.7691946CurrentTrain: epoch  6, batch    33 | loss: 81.3512427CurrentTrain: epoch  6, batch    34 | loss: 98.3516821CurrentTrain: epoch  6, batch    35 | loss: 84.3102668CurrentTrain: epoch  6, batch    36 | loss: 119.1839268CurrentTrain: epoch  6, batch    37 | loss: 100.8670564CurrentTrain: epoch  6, batch    38 | loss: 95.3053965CurrentTrain: epoch  6, batch    39 | loss: 58.4327596CurrentTrain: epoch  6, batch    40 | loss: 77.2785867CurrentTrain: epoch  6, batch    41 | loss: 79.7474406CurrentTrain: epoch  6, batch    42 | loss: 77.3082359CurrentTrain: epoch  6, batch    43 | loss: 121.4289347CurrentTrain: epoch  6, batch    44 | loss: 126.8366505CurrentTrain: epoch  6, batch    45 | loss: 97.9178983CurrentTrain: epoch  6, batch    46 | loss: 92.2898453CurrentTrain: epoch  6, batch    47 | loss: 65.2418391CurrentTrain: epoch  6, batch    48 | loss: 100.6369995CurrentTrain: epoch  6, batch    49 | loss: 97.6799514CurrentTrain: epoch  6, batch    50 | loss: 64.6479838CurrentTrain: epoch  6, batch    51 | loss: 83.7537392CurrentTrain: epoch  6, batch    52 | loss: 68.6117303CurrentTrain: epoch  6, batch    53 | loss: 84.9791365CurrentTrain: epoch  6, batch    54 | loss: 100.6596120CurrentTrain: epoch  6, batch    55 | loss: 82.0744685CurrentTrain: epoch  6, batch    56 | loss: 95.0438593CurrentTrain: epoch  6, batch    57 | loss: 96.8934598CurrentTrain: epoch  6, batch    58 | loss: 99.0089171CurrentTrain: epoch  6, batch    59 | loss: 64.7680753CurrentTrain: epoch  6, batch    60 | loss: 78.7693371CurrentTrain: epoch  6, batch    61 | loss: 126.5691187CurrentTrain: epoch  6, batch    62 | loss: 83.1616907CurrentTrain: epoch  6, batch    63 | loss: 66.5665477CurrentTrain: epoch  6, batch    64 | loss: 57.0014256CurrentTrain: epoch  6, batch    65 | loss: 68.2160557CurrentTrain: epoch  6, batch    66 | loss: 98.6333957CurrentTrain: epoch  6, batch    67 | loss: 81.8295662CurrentTrain: epoch  6, batch    68 | loss: 77.2368355CurrentTrain: epoch  6, batch    69 | loss: 60.8285302CurrentTrain: epoch  6, batch    70 | loss: 81.3195856CurrentTrain: epoch  6, batch    71 | loss: 97.9222841CurrentTrain: epoch  6, batch    72 | loss: 99.0758125CurrentTrain: epoch  6, batch    73 | loss: 101.0107908CurrentTrain: epoch  6, batch    74 | loss: 69.3368154CurrentTrain: epoch  6, batch    75 | loss: 71.5078956CurrentTrain: epoch  6, batch    76 | loss: 60.0365665CurrentTrain: epoch  6, batch    77 | loss: 99.1836080CurrentTrain: epoch  6, batch    78 | loss: 78.6396878CurrentTrain: epoch  6, batch    79 | loss: 58.5379594CurrentTrain: epoch  6, batch    80 | loss: 84.7664219CurrentTrain: epoch  6, batch    81 | loss: 100.7746664CurrentTrain: epoch  6, batch    82 | loss: 72.0356634CurrentTrain: epoch  6, batch    83 | loss: 97.4932786CurrentTrain: epoch  6, batch    84 | loss: 82.8857129CurrentTrain: epoch  6, batch    85 | loss: 63.2484785CurrentTrain: epoch  6, batch    86 | loss: 85.0099767CurrentTrain: epoch  6, batch    87 | loss: 94.9924936CurrentTrain: epoch  6, batch    88 | loss: 96.1499071CurrentTrain: epoch  6, batch    89 | loss: 103.7374921CurrentTrain: epoch  6, batch    90 | loss: 101.4495716CurrentTrain: epoch  6, batch    91 | loss: 101.9616660CurrentTrain: epoch  6, batch    92 | loss: 78.6882586CurrentTrain: epoch  6, batch    93 | loss: 79.1669753CurrentTrain: epoch  6, batch    94 | loss: 80.6407823CurrentTrain: epoch  6, batch    95 | loss: 69.3070462CurrentTrain: epoch  7, batch     0 | loss: 63.8996459CurrentTrain: epoch  7, batch     1 | loss: 122.2657243CurrentTrain: epoch  7, batch     2 | loss: 96.9456581CurrentTrain: epoch  7, batch     3 | loss: 68.0974155CurrentTrain: epoch  7, batch     4 | loss: 79.5064391CurrentTrain: epoch  7, batch     5 | loss: 101.5004439CurrentTrain: epoch  7, batch     6 | loss: 74.6887907CurrentTrain: epoch  7, batch     7 | loss: 54.1617968CurrentTrain: epoch  7, batch     8 | loss: 67.4149654CurrentTrain: epoch  7, batch     9 | loss: 67.9871297CurrentTrain: epoch  7, batch    10 | loss: 101.4377457CurrentTrain: epoch  7, batch    11 | loss: 78.7657011CurrentTrain: epoch  7, batch    12 | loss: 96.5611349CurrentTrain: epoch  7, batch    13 | loss: 76.6370137CurrentTrain: epoch  7, batch    14 | loss: 94.5838959CurrentTrain: epoch  7, batch    15 | loss: 69.0929774CurrentTrain: epoch  7, batch    16 | loss: 91.8990083CurrentTrain: epoch  7, batch    17 | loss: 94.4837059CurrentTrain: epoch  7, batch    18 | loss: 67.0374194CurrentTrain: epoch  7, batch    19 | loss: 66.6063691CurrentTrain: epoch  7, batch    20 | loss: 63.6362076CurrentTrain: epoch  7, batch    21 | loss: 123.2762363CurrentTrain: epoch  7, batch    22 | loss: 64.5692998CurrentTrain: epoch  7, batch    23 | loss: 69.1883518CurrentTrain: epoch  7, batch    24 | loss: 65.8908151CurrentTrain: epoch  7, batch    25 | loss: 69.6738758CurrentTrain: epoch  7, batch    26 | loss: 99.6542732CurrentTrain: epoch  7, batch    27 | loss: 96.1656885CurrentTrain: epoch  7, batch    28 | loss: 77.9700578CurrentTrain: epoch  7, batch    29 | loss: 99.0934565CurrentTrain: epoch  7, batch    30 | loss: 81.4235467CurrentTrain: epoch  7, batch    31 | loss: 67.2577224CurrentTrain: epoch  7, batch    32 | loss: 78.2582076CurrentTrain: epoch  7, batch    33 | loss: 97.3405507CurrentTrain: epoch  7, batch    34 | loss: 76.0928241CurrentTrain: epoch  7, batch    35 | loss: 80.6933364CurrentTrain: epoch  7, batch    36 | loss: 73.2592346CurrentTrain: epoch  7, batch    37 | loss: 122.4302662CurrentTrain: epoch  7, batch    38 | loss: 80.9047960CurrentTrain: epoch  7, batch    39 | loss: 65.1885456CurrentTrain: epoch  7, batch    40 | loss: 63.9785640CurrentTrain: epoch  7, batch    41 | loss: 82.9204469CurrentTrain: epoch  7, batch    42 | loss: 121.6842702CurrentTrain: epoch  7, batch    43 | loss: 76.7428580CurrentTrain: epoch  7, batch    44 | loss: 65.6671618CurrentTrain: epoch  7, batch    45 | loss: 99.1520339CurrentTrain: epoch  7, batch    46 | loss: 81.7100191CurrentTrain: epoch  7, batch    47 | loss: 64.9160526CurrentTrain: epoch  7, batch    48 | loss: 95.4778831CurrentTrain: epoch  7, batch    49 | loss: 100.0463144CurrentTrain: epoch  7, batch    50 | loss: 69.1386093CurrentTrain: epoch  7, batch    51 | loss: 94.8959298CurrentTrain: epoch  7, batch    52 | loss: 116.4111092CurrentTrain: epoch  7, batch    53 | loss: 64.7010504CurrentTrain: epoch  7, batch    54 | loss: 67.1753429CurrentTrain: epoch  7, batch    55 | loss: 66.5158992CurrentTrain: epoch  7, batch    56 | loss: 61.6957973CurrentTrain: epoch  7, batch    57 | loss: 125.7564058CurrentTrain: epoch  7, batch    58 | loss: 60.8085716CurrentTrain: epoch  7, batch    59 | loss: 65.0596949CurrentTrain: epoch  7, batch    60 | loss: 76.0629973CurrentTrain: epoch  7, batch    61 | loss: 98.9255910CurrentTrain: epoch  7, batch    62 | loss: 68.4518239CurrentTrain: epoch  7, batch    63 | loss: 128.7474876CurrentTrain: epoch  7, batch    64 | loss: 65.7350820CurrentTrain: epoch  7, batch    65 | loss: 84.1887122CurrentTrain: epoch  7, batch    66 | loss: 127.3581439CurrentTrain: epoch  7, batch    67 | loss: 81.1528374CurrentTrain: epoch  7, batch    68 | loss: 122.6329538CurrentTrain: epoch  7, batch    69 | loss: 102.1951136CurrentTrain: epoch  7, batch    70 | loss: 94.5244986CurrentTrain: epoch  7, batch    71 | loss: 82.3319453CurrentTrain: epoch  7, batch    72 | loss: 77.2660497CurrentTrain: epoch  7, batch    73 | loss: 69.5789139CurrentTrain: epoch  7, batch    74 | loss: 122.5142378CurrentTrain: epoch  7, batch    75 | loss: 97.7083600CurrentTrain: epoch  7, batch    76 | loss: 78.6377051CurrentTrain: epoch  7, batch    77 | loss: 54.7888797CurrentTrain: epoch  7, batch    78 | loss: 71.6633648CurrentTrain: epoch  7, batch    79 | loss: 80.4604132CurrentTrain: epoch  7, batch    80 | loss: 68.9627323CurrentTrain: epoch  7, batch    81 | loss: 100.7395563CurrentTrain: epoch  7, batch    82 | loss: 71.0834123CurrentTrain: epoch  7, batch    83 | loss: 95.3539233CurrentTrain: epoch  7, batch    84 | loss: 82.0617749CurrentTrain: epoch  7, batch    85 | loss: 122.6202594CurrentTrain: epoch  7, batch    86 | loss: 79.0583114CurrentTrain: epoch  7, batch    87 | loss: 58.3627425CurrentTrain: epoch  7, batch    88 | loss: 60.8875318CurrentTrain: epoch  7, batch    89 | loss: 69.6072326CurrentTrain: epoch  7, batch    90 | loss: 77.6505609CurrentTrain: epoch  7, batch    91 | loss: 98.9935453CurrentTrain: epoch  7, batch    92 | loss: 65.8990980CurrentTrain: epoch  7, batch    93 | loss: 119.1555994CurrentTrain: epoch  7, batch    94 | loss: 76.0041872CurrentTrain: epoch  7, batch    95 | loss: 78.4123976CurrentTrain: epoch  8, batch     0 | loss: 68.6691773CurrentTrain: epoch  8, batch     1 | loss: 125.2497298CurrentTrain: epoch  8, batch     2 | loss: 64.4984191CurrentTrain: epoch  8, batch     3 | loss: 54.6855624CurrentTrain: epoch  8, batch     4 | loss: 97.0711088CurrentTrain: epoch  8, batch     5 | loss: 96.2810217CurrentTrain: epoch  8, batch     6 | loss: 93.3012794CurrentTrain: epoch  8, batch     7 | loss: 66.0431287CurrentTrain: epoch  8, batch     8 | loss: 79.0002693CurrentTrain: epoch  8, batch     9 | loss: 55.7833755CurrentTrain: epoch  8, batch    10 | loss: 76.1786491CurrentTrain: epoch  8, batch    11 | loss: 78.4616858CurrentTrain: epoch  8, batch    12 | loss: 80.4705391CurrentTrain: epoch  8, batch    13 | loss: 53.8021807CurrentTrain: epoch  8, batch    14 | loss: 121.2805000CurrentTrain: epoch  8, batch    15 | loss: 66.7384833CurrentTrain: epoch  8, batch    16 | loss: 100.6821204CurrentTrain: epoch  8, batch    17 | loss: 91.7303737CurrentTrain: epoch  8, batch    18 | loss: 64.8971636CurrentTrain: epoch  8, batch    19 | loss: 95.1900064CurrentTrain: epoch  8, batch    20 | loss: 79.4701802CurrentTrain: epoch  8, batch    21 | loss: 97.7631507CurrentTrain: epoch  8, batch    22 | loss: 167.0622401CurrentTrain: epoch  8, batch    23 | loss: 78.3806508CurrentTrain: epoch  8, batch    24 | loss: 81.9979944CurrentTrain: epoch  8, batch    25 | loss: 118.6979840CurrentTrain: epoch  8, batch    26 | loss: 78.6874696CurrentTrain: epoch  8, batch    27 | loss: 82.3493389CurrentTrain: epoch  8, batch    28 | loss: 81.1369120CurrentTrain: epoch  8, batch    29 | loss: 66.4647201CurrentTrain: epoch  8, batch    30 | loss: 77.9500200CurrentTrain: epoch  8, batch    31 | loss: 121.9165082CurrentTrain: epoch  8, batch    32 | loss: 75.7067113CurrentTrain: epoch  8, batch    33 | loss: 74.3306232CurrentTrain: epoch  8, batch    34 | loss: 62.0345048CurrentTrain: epoch  8, batch    35 | loss: 76.5600055CurrentTrain: epoch  8, batch    36 | loss: 75.7456682CurrentTrain: epoch  8, batch    37 | loss: 124.0922542CurrentTrain: epoch  8, batch    38 | loss: 98.4447512CurrentTrain: epoch  8, batch    39 | loss: 122.9927461CurrentTrain: epoch  8, batch    40 | loss: 55.3523978CurrentTrain: epoch  8, batch    41 | loss: 91.6632230CurrentTrain: epoch  8, batch    42 | loss: 98.0654874CurrentTrain: epoch  8, batch    43 | loss: 73.3935856CurrentTrain: epoch  8, batch    44 | loss: 56.6498825CurrentTrain: epoch  8, batch    45 | loss: 55.9803964CurrentTrain: epoch  8, batch    46 | loss: 81.5081060CurrentTrain: epoch  8, batch    47 | loss: 74.9435440CurrentTrain: epoch  8, batch    48 | loss: 83.0272665CurrentTrain: epoch  8, batch    49 | loss: 77.1639588CurrentTrain: epoch  8, batch    50 | loss: 78.1182150CurrentTrain: epoch  8, batch    51 | loss: 78.4282833CurrentTrain: epoch  8, batch    52 | loss: 74.9821612CurrentTrain: epoch  8, batch    53 | loss: 74.5166343CurrentTrain: epoch  8, batch    54 | loss: 122.0060560CurrentTrain: epoch  8, batch    55 | loss: 100.4052762CurrentTrain: epoch  8, batch    56 | loss: 58.9811933CurrentTrain: epoch  8, batch    57 | loss: 97.4880499CurrentTrain: epoch  8, batch    58 | loss: 76.2259693CurrentTrain: epoch  8, batch    59 | loss: 122.5175332CurrentTrain: epoch  8, batch    60 | loss: 66.6104990CurrentTrain: epoch  8, batch    61 | loss: 74.4923587CurrentTrain: epoch  8, batch    62 | loss: 168.1450184CurrentTrain: epoch  8, batch    63 | loss: 65.4237905CurrentTrain: epoch  8, batch    64 | loss: 78.6153663CurrentTrain: epoch  8, batch    65 | loss: 68.6587875CurrentTrain: epoch  8, batch    66 | loss: 73.7986057CurrentTrain: epoch  8, batch    67 | loss: 95.3570735CurrentTrain: epoch  8, batch    68 | loss: 97.8794173CurrentTrain: epoch  8, batch    69 | loss: 64.7044828CurrentTrain: epoch  8, batch    70 | loss: 68.0561520CurrentTrain: epoch  8, batch    71 | loss: 77.1758311CurrentTrain: epoch  8, batch    72 | loss: 77.7082175CurrentTrain: epoch  8, batch    73 | loss: 121.4422109CurrentTrain: epoch  8, batch    74 | loss: 76.2612996CurrentTrain: epoch  8, batch    75 | loss: 64.7475194CurrentTrain: epoch  8, batch    76 | loss: 95.9372692CurrentTrain: epoch  8, batch    77 | loss: 64.1926630CurrentTrain: epoch  8, batch    78 | loss: 95.2332551CurrentTrain: epoch  8, batch    79 | loss: 60.4625127CurrentTrain: epoch  8, batch    80 | loss: 94.3238692CurrentTrain: epoch  8, batch    81 | loss: 80.0640298CurrentTrain: epoch  8, batch    82 | loss: 62.4806764CurrentTrain: epoch  8, batch    83 | loss: 68.2332606CurrentTrain: epoch  8, batch    84 | loss: 78.4367541CurrentTrain: epoch  8, batch    85 | loss: 80.1281416CurrentTrain: epoch  8, batch    86 | loss: 95.5915009CurrentTrain: epoch  8, batch    87 | loss: 56.2742912CurrentTrain: epoch  8, batch    88 | loss: 162.7763603CurrentTrain: epoch  8, batch    89 | loss: 62.6114351CurrentTrain: epoch  8, batch    90 | loss: 98.1095148CurrentTrain: epoch  8, batch    91 | loss: 64.1663434CurrentTrain: epoch  8, batch    92 | loss: 62.8749426CurrentTrain: epoch  8, batch    93 | loss: 68.7463021CurrentTrain: epoch  8, batch    94 | loss: 60.9238108CurrentTrain: epoch  8, batch    95 | loss: 82.2273304CurrentTrain: epoch  9, batch     0 | loss: 76.8350235CurrentTrain: epoch  9, batch     1 | loss: 63.1003057CurrentTrain: epoch  9, batch     2 | loss: 121.0802534CurrentTrain: epoch  9, batch     3 | loss: 78.8961629CurrentTrain: epoch  9, batch     4 | loss: 73.5251722CurrentTrain: epoch  9, batch     5 | loss: 81.5477953CurrentTrain: epoch  9, batch     6 | loss: 65.4081086CurrentTrain: epoch  9, batch     7 | loss: 66.5642395CurrentTrain: epoch  9, batch     8 | loss: 75.8638613CurrentTrain: epoch  9, batch     9 | loss: 78.5196507CurrentTrain: epoch  9, batch    10 | loss: 76.3082033CurrentTrain: epoch  9, batch    11 | loss: 76.8926819CurrentTrain: epoch  9, batch    12 | loss: 96.0951583CurrentTrain: epoch  9, batch    13 | loss: 76.9546284CurrentTrain: epoch  9, batch    14 | loss: 79.4452924CurrentTrain: epoch  9, batch    15 | loss: 63.3735926CurrentTrain: epoch  9, batch    16 | loss: 78.8805318CurrentTrain: epoch  9, batch    17 | loss: 76.4936429CurrentTrain: epoch  9, batch    18 | loss: 125.4879686CurrentTrain: epoch  9, batch    19 | loss: 61.2923457CurrentTrain: epoch  9, batch    20 | loss: 95.7943434CurrentTrain: epoch  9, batch    21 | loss: 117.3932170CurrentTrain: epoch  9, batch    22 | loss: 93.3331092CurrentTrain: epoch  9, batch    23 | loss: 77.4482595CurrentTrain: epoch  9, batch    24 | loss: 95.7915208CurrentTrain: epoch  9, batch    25 | loss: 61.2476974CurrentTrain: epoch  9, batch    26 | loss: 67.7402218CurrentTrain: epoch  9, batch    27 | loss: 76.1798504CurrentTrain: epoch  9, batch    28 | loss: 117.8265392CurrentTrain: epoch  9, batch    29 | loss: 54.3719253CurrentTrain: epoch  9, batch    30 | loss: 78.2077845CurrentTrain: epoch  9, batch    31 | loss: 95.7708915CurrentTrain: epoch  9, batch    32 | loss: 73.3714996CurrentTrain: epoch  9, batch    33 | loss: 77.1502826CurrentTrain: epoch  9, batch    34 | loss: 124.1276177CurrentTrain: epoch  9, batch    35 | loss: 67.8796598CurrentTrain: epoch  9, batch    36 | loss: 73.0414992CurrentTrain: epoch  9, batch    37 | loss: 98.2611149CurrentTrain: epoch  9, batch    38 | loss: 92.8333439CurrentTrain: epoch  9, batch    39 | loss: 79.8475192CurrentTrain: epoch  9, batch    40 | loss: 55.2174960CurrentTrain: epoch  9, batch    41 | loss: 94.7832274CurrentTrain: epoch  9, batch    42 | loss: 67.4175709CurrentTrain: epoch  9, batch    43 | loss: 74.2251883CurrentTrain: epoch  9, batch    44 | loss: 64.2721485CurrentTrain: epoch  9, batch    45 | loss: 94.0432234CurrentTrain: epoch  9, batch    46 | loss: 78.3665437CurrentTrain: epoch  9, batch    47 | loss: 96.7711158CurrentTrain: epoch  9, batch    48 | loss: 79.3914675CurrentTrain: epoch  9, batch    49 | loss: 78.6152700CurrentTrain: epoch  9, batch    50 | loss: 61.7421366CurrentTrain: epoch  9, batch    51 | loss: 68.2763441CurrentTrain: epoch  9, batch    52 | loss: 99.9949396CurrentTrain: epoch  9, batch    53 | loss: 77.6707551CurrentTrain: epoch  9, batch    54 | loss: 95.8791189CurrentTrain: epoch  9, batch    55 | loss: 75.4781405CurrentTrain: epoch  9, batch    56 | loss: 75.4808386CurrentTrain: epoch  9, batch    57 | loss: 58.0110035CurrentTrain: epoch  9, batch    58 | loss: 61.8380528CurrentTrain: epoch  9, batch    59 | loss: 124.7803366CurrentTrain: epoch  9, batch    60 | loss: 97.9392413CurrentTrain: epoch  9, batch    61 | loss: 80.1894568CurrentTrain: epoch  9, batch    62 | loss: 67.4358428CurrentTrain: epoch  9, batch    63 | loss: 119.9276719CurrentTrain: epoch  9, batch    64 | loss: 75.4066463CurrentTrain: epoch  9, batch    65 | loss: 80.2028186CurrentTrain: epoch  9, batch    66 | loss: 64.0247112CurrentTrain: epoch  9, batch    67 | loss: 92.8669338CurrentTrain: epoch  9, batch    68 | loss: 71.6176833CurrentTrain: epoch  9, batch    69 | loss: 65.9542804CurrentTrain: epoch  9, batch    70 | loss: 65.3488976CurrentTrain: epoch  9, batch    71 | loss: 68.3872355CurrentTrain: epoch  9, batch    72 | loss: 93.2614241CurrentTrain: epoch  9, batch    73 | loss: 74.2608096CurrentTrain: epoch  9, batch    74 | loss: 76.9311122CurrentTrain: epoch  9, batch    75 | loss: 66.0808933CurrentTrain: epoch  9, batch    76 | loss: 98.0661318CurrentTrain: epoch  9, batch    77 | loss: 78.8758316CurrentTrain: epoch  9, batch    78 | loss: 55.8309962CurrentTrain: epoch  9, batch    79 | loss: 124.9435371CurrentTrain: epoch  9, batch    80 | loss: 78.2804782CurrentTrain: epoch  9, batch    81 | loss: 75.9074718CurrentTrain: epoch  9, batch    82 | loss: 94.5095099CurrentTrain: epoch  9, batch    83 | loss: 64.0309604CurrentTrain: epoch  9, batch    84 | loss: 76.6909095CurrentTrain: epoch  9, batch    85 | loss: 58.1350768CurrentTrain: epoch  9, batch    86 | loss: 76.8483957CurrentTrain: epoch  9, batch    87 | loss: 95.3451102CurrentTrain: epoch  9, batch    88 | loss: 76.7586285CurrentTrain: epoch  9, batch    89 | loss: 74.0594617CurrentTrain: epoch  9, batch    90 | loss: 64.7847110CurrentTrain: epoch  9, batch    91 | loss: 92.8660363CurrentTrain: epoch  9, batch    92 | loss: 73.9977887CurrentTrain: epoch  9, batch    93 | loss: 67.7678574CurrentTrain: epoch  9, batch    94 | loss: 167.1830837CurrentTrain: epoch  9, batch    95 | loss: 67.9895800

F1 score per class: {32: np.float64(0.5280898876404494), 6: np.float64(0.8130841121495327), 19: np.float64(0.35294117647058826), 24: np.float64(0.7374301675977654), 26: np.float64(0.9222797927461139), 29: np.float64(0.8148148148148148)}
Micro-average F1 score: 0.7554240631163708
Weighted-average F1 score: 0.7622523817110116
F1 score per class: {32: np.float64(0.6666666666666666), 6: np.float64(0.8), 19: np.float64(0.21875), 24: np.float64(0.7282608695652174), 26: np.float64(0.9387755102040817), 29: np.float64(0.8207547169811321)}
Micro-average F1 score: 0.7544483985765125
Weighted-average F1 score: 0.7402916231984987
F1 score per class: {32: np.float64(0.6923076923076923), 6: np.float64(0.8018018018018018), 19: np.float64(0.2916666666666667), 24: np.float64(0.7292817679558011), 26: np.float64(0.9387755102040817), 29: np.float64(0.8169014084507042)}
Micro-average F1 score: 0.7714808043875686
Weighted-average F1 score: 0.7653527464027639

F1 score per class: {32: np.float64(0.5280898876404494), 6: np.float64(0.8130841121495327), 19: np.float64(0.35294117647058826), 24: np.float64(0.7374301675977654), 26: np.float64(0.9222797927461139), 29: np.float64(0.8148148148148148)}
Micro-average F1 score: 0.7554240631163708
Weighted-average F1 score: 0.7622523817110116
F1 score per class: {32: np.float64(0.6666666666666666), 6: np.float64(0.8), 19: np.float64(0.21875), 24: np.float64(0.7282608695652174), 26: np.float64(0.9387755102040817), 29: np.float64(0.8207547169811321)}
Micro-average F1 score: 0.7544483985765125
Weighted-average F1 score: 0.7402916231984987
F1 score per class: {32: np.float64(0.6923076923076923), 6: np.float64(0.8018018018018018), 19: np.float64(0.2916666666666667), 24: np.float64(0.7292817679558011), 26: np.float64(0.9387755102040817), 29: np.float64(0.8169014084507042)}
Micro-average F1 score: 0.7714808043875686
Weighted-average F1 score: 0.7653527464027639

F1 score per class: {32: np.float64(0.3884297520661157), 6: np.float64(0.759825327510917), 19: np.float64(0.22641509433962265), 24: np.float64(0.6875), 26: np.float64(0.8476190476190476), 29: np.float64(0.654275092936803)}
Micro-average F1 score: 0.6410041841004184
Weighted-average F1 score: 0.6324366414898056
F1 score per class: {32: np.float64(0.45892351274787535), 6: np.float64(0.7377049180327869), 19: np.float64(0.12612612612612611), 24: np.float64(0.6536585365853659), 26: np.float64(0.8518518518518519), 29: np.float64(0.6615969581749049)}
Micro-average F1 score: 0.6091954022988506
Weighted-average F1 score: 0.5827873592568092
F1 score per class: {32: np.float64(0.47368421052631576), 6: np.float64(0.7385892116182573), 19: np.float64(0.16470588235294117), 24: np.float64(0.66), 26: np.float64(0.8518518518518519), 29: np.float64(0.6566037735849056)}
Micro-average F1 score: 0.625648628613788
Weighted-average F1 score: 0.6052495660162623

F1 score per class: {32: np.float64(0.3884297520661157), 6: np.float64(0.759825327510917), 19: np.float64(0.22641509433962265), 24: np.float64(0.6875), 26: np.float64(0.8476190476190476), 29: np.float64(0.654275092936803)}
Micro-average F1 score: 0.6410041841004184
Weighted-average F1 score: 0.6324366414898056
F1 score per class: {32: np.float64(0.45892351274787535), 6: np.float64(0.7377049180327869), 19: np.float64(0.12612612612612611), 24: np.float64(0.6536585365853659), 26: np.float64(0.8518518518518519), 29: np.float64(0.6615969581749049)}
Micro-average F1 score: 0.6091954022988506
Weighted-average F1 score: 0.5827873592568092
F1 score per class: {32: np.float64(0.47368421052631576), 6: np.float64(0.7385892116182573), 19: np.float64(0.16470588235294117), 24: np.float64(0.66), 26: np.float64(0.8518518518518519), 29: np.float64(0.6566037735849056)}
Micro-average F1 score: 0.625648628613788
Weighted-average F1 score: 0.6052495660162623
cur_acc_wo_na:  ['0.7554']
his_acc_wo_na:  ['0.7554']
cur_acc des_wo_na:  ['0.7544']
his_acc des_wo_na:  ['0.7544']
cur_acc rrf_wo_na:  ['0.7715']
his_acc rrf_wo_na:  ['0.7715']
cur_acc_w_na:  ['0.6410']
his_acc_w_na:  ['0.6410']
cur_acc des_w_na:  ['0.6092']
his_acc des_w_na:  ['0.6092']
cur_acc rrf_w_na:  ['0.6256']
his_acc rrf_w_na:  ['0.6256']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 96.0512740CurrentTrain: epoch  0, batch     1 | loss: 91.0527342CurrentTrain: epoch  0, batch     2 | loss: 140.6983773CurrentTrain: epoch  0, batch     3 | loss: 54.4123220CurrentTrain: epoch  1, batch     0 | loss: 75.7923277CurrentTrain: epoch  1, batch     1 | loss: 88.9687685CurrentTrain: epoch  1, batch     2 | loss: 103.0133478CurrentTrain: epoch  1, batch     3 | loss: 72.5254344CurrentTrain: epoch  2, batch     0 | loss: 106.6636790CurrentTrain: epoch  2, batch     1 | loss: 83.0089577CurrentTrain: epoch  2, batch     2 | loss: 84.1117317CurrentTrain: epoch  2, batch     3 | loss: 86.9458627CurrentTrain: epoch  3, batch     0 | loss: 81.1235031CurrentTrain: epoch  3, batch     1 | loss: 71.7274846CurrentTrain: epoch  3, batch     2 | loss: 100.5460355CurrentTrain: epoch  3, batch     3 | loss: 85.8949649CurrentTrain: epoch  4, batch     0 | loss: 97.9309168CurrentTrain: epoch  4, batch     1 | loss: 68.8020117CurrentTrain: epoch  4, batch     2 | loss: 69.0079810CurrentTrain: epoch  4, batch     3 | loss: 57.1722849CurrentTrain: epoch  5, batch     0 | loss: 80.3991508CurrentTrain: epoch  5, batch     1 | loss: 71.2340737CurrentTrain: epoch  5, batch     2 | loss: 65.2309563CurrentTrain: epoch  5, batch     3 | loss: 53.4918073CurrentTrain: epoch  6, batch     0 | loss: 78.3491660CurrentTrain: epoch  6, batch     1 | loss: 75.5794674CurrentTrain: epoch  6, batch     2 | loss: 65.1972914CurrentTrain: epoch  6, batch     3 | loss: 85.8767651CurrentTrain: epoch  7, batch     0 | loss: 98.4170551CurrentTrain: epoch  7, batch     1 | loss: 64.5986156CurrentTrain: epoch  7, batch     2 | loss: 77.0679630CurrentTrain: epoch  7, batch     3 | loss: 81.7711287CurrentTrain: epoch  8, batch     0 | loss: 64.7034040CurrentTrain: epoch  8, batch     1 | loss: 77.7182381CurrentTrain: epoch  8, batch     2 | loss: 78.0865705CurrentTrain: epoch  8, batch     3 | loss: 63.3905515CurrentTrain: epoch  9, batch     0 | loss: 64.1572577CurrentTrain: epoch  9, batch     1 | loss: 76.3525807CurrentTrain: epoch  9, batch     2 | loss: 79.6001822CurrentTrain: epoch  9, batch     3 | loss: 42.9707548
MemoryTrain:  epoch  0, batch     0 | loss: 1.9873487MemoryTrain:  epoch  1, batch     0 | loss: 1.8132873MemoryTrain:  epoch  2, batch     0 | loss: 1.4671481MemoryTrain:  epoch  3, batch     0 | loss: 1.1334066MemoryTrain:  epoch  4, batch     0 | loss: 0.9486381MemoryTrain:  epoch  5, batch     0 | loss: 0.7505351MemoryTrain:  epoch  6, batch     0 | loss: 0.6682386MemoryTrain:  epoch  7, batch     0 | loss: 0.4903420MemoryTrain:  epoch  8, batch     0 | loss: 0.3905076MemoryTrain:  epoch  9, batch     0 | loss: 0.3506519

F1 score per class: {32: np.float64(0.0), 35: np.float64(0.8421052631578947), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.547945205479452), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.6428571428571429), 26: np.float64(0.5050505050505051), 29: np.float64(0.41025641025641024)}
Micro-average F1 score: 0.5116279069767442
Weighted-average F1 score: 0.45111799026269567
F1 score per class: {32: np.float64(0.0), 35: np.float64(0.7368421052631579), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.782608695652174), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.8113207547169812), 26: np.float64(0.5576923076923077), 29: np.float64(0.5797101449275363)}
Micro-average F1 score: 0.6221198156682027
Weighted-average F1 score: 0.5616529861089264
F1 score per class: {32: np.float64(0.0), 35: np.float64(0.7619047619047619), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.7586206896551724), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.8), 26: np.float64(0.5523809523809524), 29: np.float64(0.5555555555555556)}
Micro-average F1 score: 0.616504854368932
Weighted-average F1 score: 0.5565604920401456

F1 score per class: {32: np.float64(0.6346153846153846), 35: np.float64(0.7272727272727273), 37: np.float64(0.8113207547169812), 6: np.float64(0.1875), 38: np.float64(0.547945205479452), 15: np.float64(0.7368421052631579), 19: np.float64(0.8947368421052632), 24: np.float64(0.8038277511961722), 25: np.float64(0.5142857142857142), 26: np.float64(0.43478260869565216), 29: np.float64(0.41025641025641024)}
Micro-average F1 score: 0.690406976744186
Weighted-average F1 score: 0.6985116146349396
F1 score per class: {32: np.float64(0.6882591093117408), 35: np.float64(0.6086956521739131), 37: np.float64(0.7678571428571429), 6: np.float64(0.29508196721311475), 38: np.float64(0.782608695652174), 15: np.float64(0.708994708994709), 19: np.float64(0.9154228855721394), 24: np.float64(0.8137254901960784), 25: np.float64(0.5584415584415584), 26: np.float64(0.47540983606557374), 29: np.float64(0.46511627906976744)}
Micro-average F1 score: 0.6949469744229569
Weighted-average F1 score: 0.6815063537815874
F1 score per class: {32: np.float64(0.6612903225806451), 35: np.float64(0.64), 37: np.float64(0.7747747747747747), 6: np.float64(0.35555555555555557), 38: np.float64(0.7586206896551724), 15: np.float64(0.7333333333333333), 19: np.float64(0.9081632653061225), 24: np.float64(0.8173076923076923), 25: np.float64(0.5793103448275863), 26: np.float64(0.4603174603174603), 29: np.float64(0.4918032786885246)}
Micro-average F1 score: 0.7038237200259235
Weighted-average F1 score: 0.6957893425960449

F1 score per class: {32: np.float64(0.0), 35: np.float64(0.6666666666666666), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.5), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5684210526315789), 26: np.float64(0.49019607843137253), 29: np.float64(0.32653061224489793)}
Micro-average F1 score: 0.42718446601941745
Weighted-average F1 score: 0.35919070047575025
F1 score per class: {32: np.float64(0.0), 35: np.float64(0.56), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.6857142857142857), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.688), 26: np.float64(0.5132743362831859), 29: np.float64(0.4)}
Micro-average F1 score: 0.48300536672629696
Weighted-average F1 score: 0.4236268071672235
F1 score per class: {32: np.float64(0.0), 35: np.float64(0.5925925925925926), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.6804123711340206), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.6829268292682927), 26: np.float64(0.5087719298245614), 29: np.float64(0.375)}
Micro-average F1 score: 0.4847328244274809
Weighted-average F1 score: 0.423644107408509

F1 score per class: {32: np.float64(0.44594594594594594), 35: np.float64(0.5161290322580645), 37: np.float64(0.7478260869565218), 6: np.float64(0.12244897959183673), 38: np.float64(0.5), 15: np.float64(0.6631578947368421), 19: np.float64(0.7906976744186046), 24: np.float64(0.6486486486486487), 25: np.float64(0.391304347826087), 26: np.float64(0.3401360544217687), 29: np.float64(0.2807017543859649)}
Micro-average F1 score: 0.5614657210401891
Weighted-average F1 score: 0.5537334726072625
F1 score per class: {32: np.float64(0.4509283819628647), 35: np.float64(0.4666666666666667), 37: np.float64(0.6991869918699187), 6: np.float64(0.14634146341463414), 38: np.float64(0.6857142857142857), 15: np.float64(0.6261682242990654), 19: np.float64(0.7763713080168776), 24: np.float64(0.6561264822134387), 25: np.float64(0.3944954128440367), 26: np.float64(0.3625), 29: np.float64(0.25157232704402516)}
Micro-average F1 score: 0.5249764373232799
Weighted-average F1 score: 0.49982224810137704
F1 score per class: {32: np.float64(0.44324324324324327), 35: np.float64(0.4444444444444444), 37: np.float64(0.7049180327868853), 6: np.float64(0.21052631578947367), 38: np.float64(0.6804123711340206), 15: np.float64(0.6567164179104478), 19: np.float64(0.7876106194690266), 24: np.float64(0.6589147286821705), 25: np.float64(0.4263959390862944), 26: np.float64(0.3473053892215569), 29: np.float64(0.2631578947368421)}
Micro-average F1 score: 0.5468277945619335
Weighted-average F1 score: 0.5266704002082657
cur_acc_wo_na:  ['0.7554', '0.5116']
his_acc_wo_na:  ['0.7554', '0.6904']
cur_acc des_wo_na:  ['0.7544', '0.6221']
his_acc des_wo_na:  ['0.7544', '0.6949']
cur_acc rrf_wo_na:  ['0.7715', '0.6165']
his_acc rrf_wo_na:  ['0.7715', '0.7038']
cur_acc_w_na:  ['0.6410', '0.4272']
his_acc_w_na:  ['0.6410', '0.5615']
cur_acc des_w_na:  ['0.6092', '0.4830']
his_acc des_w_na:  ['0.6092', '0.5250']
cur_acc rrf_w_na:  ['0.6256', '0.4847']
his_acc rrf_w_na:  ['0.6256', '0.5468']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 123.1570135CurrentTrain: epoch  0, batch     1 | loss: 86.9988852CurrentTrain: epoch  0, batch     2 | loss: 81.9613111CurrentTrain: epoch  0, batch     3 | loss: 51.6702366CurrentTrain: epoch  1, batch     0 | loss: 81.6004245CurrentTrain: epoch  1, batch     1 | loss: 74.3871226CurrentTrain: epoch  1, batch     2 | loss: 86.4626990CurrentTrain: epoch  1, batch     3 | loss: 83.0004105CurrentTrain: epoch  2, batch     0 | loss: 81.8484700CurrentTrain: epoch  2, batch     1 | loss: 85.1981819CurrentTrain: epoch  2, batch     2 | loss: 86.4168236CurrentTrain: epoch  2, batch     3 | loss: 50.9308644CurrentTrain: epoch  3, batch     0 | loss: 103.1774370CurrentTrain: epoch  3, batch     1 | loss: 84.7133148CurrentTrain: epoch  3, batch     2 | loss: 80.0906092CurrentTrain: epoch  3, batch     3 | loss: 58.4041665CurrentTrain: epoch  4, batch     0 | loss: 81.2639690CurrentTrain: epoch  4, batch     1 | loss: 100.0907378CurrentTrain: epoch  4, batch     2 | loss: 81.1478361CurrentTrain: epoch  4, batch     3 | loss: 56.3256545CurrentTrain: epoch  5, batch     0 | loss: 64.8002545CurrentTrain: epoch  5, batch     1 | loss: 82.2277304CurrentTrain: epoch  5, batch     2 | loss: 77.3650892CurrentTrain: epoch  5, batch     3 | loss: 50.5918970CurrentTrain: epoch  6, batch     0 | loss: 78.1554152CurrentTrain: epoch  6, batch     1 | loss: 67.2108312CurrentTrain: epoch  6, batch     2 | loss: 78.8899337CurrentTrain: epoch  6, batch     3 | loss: 56.6702167CurrentTrain: epoch  7, batch     0 | loss: 80.6116394CurrentTrain: epoch  7, batch     1 | loss: 73.8706535CurrentTrain: epoch  7, batch     2 | loss: 65.4687372CurrentTrain: epoch  7, batch     3 | loss: 71.7621461CurrentTrain: epoch  8, batch     0 | loss: 93.1596886CurrentTrain: epoch  8, batch     1 | loss: 93.1445706CurrentTrain: epoch  8, batch     2 | loss: 74.4372814CurrentTrain: epoch  8, batch     3 | loss: 54.2354506CurrentTrain: epoch  9, batch     0 | loss: 77.0049390CurrentTrain: epoch  9, batch     1 | loss: 97.6715715CurrentTrain: epoch  9, batch     2 | loss: 60.6799447CurrentTrain: epoch  9, batch     3 | loss: 45.6902805
MemoryTrain:  epoch  0, batch     0 | loss: 0.9761374MemoryTrain:  epoch  1, batch     0 | loss: 0.8808764MemoryTrain:  epoch  2, batch     0 | loss: 0.7542334MemoryTrain:  epoch  3, batch     0 | loss: 0.5413850MemoryTrain:  epoch  4, batch     0 | loss: 0.4657898MemoryTrain:  epoch  5, batch     0 | loss: 0.3994331MemoryTrain:  epoch  6, batch     0 | loss: 0.3033611MemoryTrain:  epoch  7, batch     0 | loss: 0.2707064MemoryTrain:  epoch  8, batch     0 | loss: 0.2432338MemoryTrain:  epoch  9, batch     0 | loss: 0.2028696

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.36363636363636365), 35: np.float64(0.0), 36: np.float64(0.5641025641025641), 37: np.float64(0.0), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.9142857142857143), 15: np.float64(0.0), 20: np.float64(0.42857142857142855), 24: np.float64(0.0), 26: np.float64(0.574468085106383), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.46684350132625996
Weighted-average F1 score: 0.38413224781630495
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.5594405594405595), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.6352941176470588), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.8292682926829268), 20: np.float64(0.0), 24: np.float64(0.47058823529411764), 25: np.float64(0.0), 26: np.float64(0.7142857142857143), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.5495867768595041
Weighted-average F1 score: 0.4676047709102983
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.5774647887323944), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.6511627906976745), 6: np.float64(0.0), 8: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.85), 20: np.float64(0.0), 24: np.float64(0.5), 26: np.float64(0.0), 29: np.float64(0.6722689075630253), 30: np.float64(0.0)}
Micro-average F1 score: 0.5627705627705628
Weighted-average F1 score: 0.48503382474390466

F1 score per class: {32: np.float64(0.5818181818181818), 33: np.float64(0.3333333333333333), 35: np.float64(0.6666666666666666), 36: np.float64(0.8018867924528302), 37: np.float64(0.4731182795698925), 6: np.float64(0.22857142857142856), 38: np.float64(0.38235294117647056), 8: np.float64(0.7142857142857143), 15: np.float64(0.882051282051282), 19: np.float64(0.8), 20: np.float64(0.7962085308056872), 24: np.float64(0.35294117647058826), 25: np.float64(0.5192307692307693), 26: np.float64(0.5192307692307693), 29: np.float64(0.22535211267605634), 30: np.float64(0.12903225806451613)}
Micro-average F1 score: 0.6184971098265896
Weighted-average F1 score: 0.6566626596310015
F1 score per class: {32: np.float64(0.6382978723404256), 33: np.float64(0.449438202247191), 35: np.float64(0.5384615384615384), 36: np.float64(0.7478260869565218), 37: np.float64(0.4909090909090909), 6: np.float64(0.30303030303030304), 38: np.float64(0.5681818181818182), 8: np.float64(0.6633165829145728), 15: np.float64(0.9029126213592233), 19: np.float64(0.4533333333333333), 20: np.float64(0.8), 24: np.float64(0.32), 25: np.float64(0.6164383561643836), 26: np.float64(0.5389221556886228), 29: np.float64(0.35051546391752575), 30: np.float64(0.37209302325581395)}
Micro-average F1 score: 0.6182336182336182
Weighted-average F1 score: 0.6166750853873846
F1 score per class: {32: np.float64(0.6244725738396625), 33: np.float64(0.4823529411764706), 35: np.float64(0.5517241379310345), 36: np.float64(0.7510917030567685), 37: np.float64(0.49557522123893805), 6: np.float64(0.32653061224489793), 38: np.float64(0.4533333333333333), 8: np.float64(0.6875), 15: np.float64(0.9019607843137255), 19: np.float64(0.5573770491803278), 20: np.float64(0.7962962962962963), 24: np.float64(0.36363636363636365), 25: np.float64(0.6518518518518519), 26: np.float64(0.5298013245033113), 29: np.float64(0.3409090909090909), 30: np.float64(0.4)}
Micro-average F1 score: 0.6305320735952262
Weighted-average F1 score: 0.6377116372134509

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.3389830508474576), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.4835164835164835), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.8648648648648649), 20: np.float64(0.0), 24: np.float64(0.42857142857142855), 25: np.float64(0.0), 26: np.float64(0.5192307692307693), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.3752665245202559
Weighted-average F1 score: 0.2815820750231803
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.4519774011299435), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.5046728971962616), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.7555555555555555), 20: np.float64(0.0), 24: np.float64(0.47058823529411764), 25: np.float64(0.0), 26: np.float64(0.569620253164557), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.3958333333333333
Weighted-average F1 score: 0.3288220662295348
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.47953216374269003), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.5283018867924528), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.8095238095238095), 20: np.float64(0.0), 24: np.float64(0.5), 25: np.float64(0.0), 26: np.float64(0.5369127516778524), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.4133545310015898
Weighted-average F1 score: 0.34249346446823875

F1 score per class: {32: np.float64(0.3890577507598784), 33: np.float64(0.3076923076923077), 35: np.float64(0.46153846153846156), 36: np.float64(0.7296137339055794), 37: np.float64(0.31654676258992803), 6: np.float64(0.1702127659574468), 38: np.float64(0.35135135135135137), 8: np.float64(0.6310679611650486), 15: np.float64(0.7747747747747747), 19: np.float64(0.7111111111111111), 20: np.float64(0.6199261992619927), 24: np.float64(0.3), 25: np.float64(0.4251968503937008), 26: np.float64(0.45), 29: np.float64(0.2077922077922078), 30: np.float64(0.09090909090909091)}
Micro-average F1 score: 0.504003768252473
Weighted-average F1 score: 0.5152435922790058
F1 score per class: {32: np.float64(0.42134831460674155), 33: np.float64(0.31746031746031744), 35: np.float64(0.4), 36: np.float64(0.671875), 37: np.float64(0.3103448275862069), 6: np.float64(0.16129032258064516), 38: np.float64(0.5102040816326531), 8: np.float64(0.5689655172413793), 15: np.float64(0.7530364372469636), 19: np.float64(0.35051546391752575), 20: np.float64(0.6209386281588448), 24: np.float64(0.24242424242424243), 25: np.float64(0.4368932038834951), 26: np.float64(0.4147465437788018), 29: np.float64(0.2857142857142857), 30: np.float64(0.24242424242424243)}
Micro-average F1 score: 0.46683399067766224
Weighted-average F1 score: 0.4565333573246449
F1 score per class: {32: np.float64(0.4111111111111111), 33: np.float64(0.36123348017621143), 35: np.float64(0.38095238095238093), 36: np.float64(0.671875), 37: np.float64(0.3218390804597701), 6: np.float64(0.18604651162790697), 38: np.float64(0.40963855421686746), 8: np.float64(0.6), 15: np.float64(0.7634854771784232), 19: np.float64(0.44155844155844154), 20: np.float64(0.6187050359712231), 24: np.float64(0.2962962962962963), 25: np.float64(0.4782608695652174), 26: np.float64(0.40609137055837563), 29: np.float64(0.30303030303030304), 30: np.float64(0.25806451612903225)}
Micro-average F1 score: 0.4852659778032912
Weighted-average F1 score: 0.47993609164746887
cur_acc_wo_na:  ['0.7554', '0.5116', '0.4668']
his_acc_wo_na:  ['0.7554', '0.6904', '0.6185']
cur_acc des_wo_na:  ['0.7544', '0.6221', '0.5496']
his_acc des_wo_na:  ['0.7544', '0.6949', '0.6182']
cur_acc rrf_wo_na:  ['0.7715', '0.6165', '0.5628']
his_acc rrf_wo_na:  ['0.7715', '0.7038', '0.6305']
cur_acc_w_na:  ['0.6410', '0.4272', '0.3753']
his_acc_w_na:  ['0.6410', '0.5615', '0.5040']
cur_acc des_w_na:  ['0.6092', '0.4830', '0.3958']
his_acc des_w_na:  ['0.6092', '0.5250', '0.4668']
cur_acc rrf_w_na:  ['0.6256', '0.4847', '0.4134']
his_acc rrf_w_na:  ['0.6256', '0.5468', '0.4853']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 100.5889303CurrentTrain: epoch  0, batch     1 | loss: 141.1276517CurrentTrain: epoch  0, batch     2 | loss: 92.8702618CurrentTrain: epoch  0, batch     3 | loss: 83.9895879CurrentTrain: epoch  0, batch     4 | loss: 66.7141234CurrentTrain: epoch  1, batch     0 | loss: 75.0370090CurrentTrain: epoch  1, batch     1 | loss: 107.9630639CurrentTrain: epoch  1, batch     2 | loss: 90.7430831CurrentTrain: epoch  1, batch     3 | loss: 74.3077560CurrentTrain: epoch  1, batch     4 | loss: 110.5028984CurrentTrain: epoch  2, batch     0 | loss: 107.7003929CurrentTrain: epoch  2, batch     1 | loss: 75.8689948CurrentTrain: epoch  2, batch     2 | loss: 85.1465901CurrentTrain: epoch  2, batch     3 | loss: 86.5441662CurrentTrain: epoch  2, batch     4 | loss: 46.9713613CurrentTrain: epoch  3, batch     0 | loss: 130.8258244CurrentTrain: epoch  3, batch     1 | loss: 98.1564739CurrentTrain: epoch  3, batch     2 | loss: 81.9863081CurrentTrain: epoch  3, batch     3 | loss: 85.2362078CurrentTrain: epoch  3, batch     4 | loss: 57.0068000CurrentTrain: epoch  4, batch     0 | loss: 86.4080649CurrentTrain: epoch  4, batch     1 | loss: 83.5589808CurrentTrain: epoch  4, batch     2 | loss: 79.0805937CurrentTrain: epoch  4, batch     3 | loss: 98.7452662CurrentTrain: epoch  4, batch     4 | loss: 54.9208036CurrentTrain: epoch  5, batch     0 | loss: 67.2208857CurrentTrain: epoch  5, batch     1 | loss: 81.1849034CurrentTrain: epoch  5, batch     2 | loss: 123.5856852CurrentTrain: epoch  5, batch     3 | loss: 103.5781407CurrentTrain: epoch  5, batch     4 | loss: 68.7440507CurrentTrain: epoch  6, batch     0 | loss: 70.7950424CurrentTrain: epoch  6, batch     1 | loss: 80.9482696CurrentTrain: epoch  6, batch     2 | loss: 95.1460892CurrentTrain: epoch  6, batch     3 | loss: 79.4321489CurrentTrain: epoch  6, batch     4 | loss: 68.8100951CurrentTrain: epoch  7, batch     0 | loss: 78.0810586CurrentTrain: epoch  7, batch     1 | loss: 95.2784472CurrentTrain: epoch  7, batch     2 | loss: 80.8353811CurrentTrain: epoch  7, batch     3 | loss: 98.6508779CurrentTrain: epoch  7, batch     4 | loss: 36.6160358CurrentTrain: epoch  8, batch     0 | loss: 80.8559660CurrentTrain: epoch  8, batch     1 | loss: 65.6383854CurrentTrain: epoch  8, batch     2 | loss: 66.2839881CurrentTrain: epoch  8, batch     3 | loss: 96.1986703CurrentTrain: epoch  8, batch     4 | loss: 68.2702316CurrentTrain: epoch  9, batch     0 | loss: 123.3368938CurrentTrain: epoch  9, batch     1 | loss: 93.3179410CurrentTrain: epoch  9, batch     2 | loss: 96.2893132CurrentTrain: epoch  9, batch     3 | loss: 65.1645655CurrentTrain: epoch  9, batch     4 | loss: 51.6324265
MemoryTrain:  epoch  0, batch     0 | loss: 1.4938329MemoryTrain:  epoch  1, batch     0 | loss: 1.1408832MemoryTrain:  epoch  2, batch     0 | loss: 1.0259065MemoryTrain:  epoch  3, batch     0 | loss: 0.8849903MemoryTrain:  epoch  4, batch     0 | loss: 0.6423187MemoryTrain:  epoch  5, batch     0 | loss: 0.5317715MemoryTrain:  epoch  6, batch     0 | loss: 0.5429205MemoryTrain:  epoch  7, batch     0 | loss: 0.3815568MemoryTrain:  epoch  8, batch     0 | loss: 0.3427850MemoryTrain:  epoch  9, batch     0 | loss: 0.2802692

F1 score per class: {32: np.float64(0.21468926553672316), 1: np.float64(0.7225806451612903), 34: np.float64(0.0), 3: np.float64(0.0), 35: np.float64(0.09803921568627451), 37: np.float64(0.0), 33: np.float64(0.547085201793722), 6: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.6548672566371682), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.39599555061179087
Weighted-average F1 score: 0.3426212387521455
F1 score per class: {1: np.float64(0.2122905027932961), 3: np.float64(0.625), 6: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.05925925925925926), 19: np.float64(0.0), 22: np.float64(0.5585585585585585), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.688), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0)}
Micro-average F1 score: 0.34132310642377756
Weighted-average F1 score: 0.28291326849595005
F1 score per class: {32: np.float64(0.2122905027932961), 1: np.float64(0.7218934911242604), 34: np.float64(0.0), 3: np.float64(0.0), 35: np.float64(0.08955223880597014), 37: np.float64(0.0), 33: np.float64(0.5414847161572053), 6: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.688), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.3782178217821782
Weighted-average F1 score: 0.3237230002746851

F1 score per class: {1: np.float64(0.16666666666666666), 3: np.float64(0.5161290322580645), 6: np.float64(0.5806451612903226), 8: np.float64(0.34108527131782945), 14: np.float64(0.08196721311475409), 15: np.float64(0.6956521739130435), 19: np.float64(0.6788990825688074), 20: np.float64(0.39436619718309857), 22: np.float64(0.48412698412698413), 24: np.float64(0.08695652173913043), 25: np.float64(0.3880597014925373), 26: np.float64(0.7027027027027027), 29: np.float64(0.8669950738916257), 30: np.float64(0.8823529411764706), 32: np.float64(0.6058091286307054), 33: np.float64(0.2727272727272727), 34: np.float64(0.30962343096234307), 35: np.float64(0.0759493670886076), 36: np.float64(0.5473684210526316), 37: np.float64(0.15151515151515152), 38: np.float64(0.1935483870967742)}
Micro-average F1 score: 0.47356987690079655
Weighted-average F1 score: 0.47135179593512894
F1 score per class: {1: np.float64(0.17040358744394618), 3: np.float64(0.4444444444444444), 6: np.float64(0.5877551020408164), 8: np.float64(0.4540540540540541), 14: np.float64(0.045454545454545456), 15: np.float64(0.631578947368421), 19: np.float64(0.6335877862595419), 20: np.float64(0.5), 22: np.float64(0.4940239043824701), 24: np.float64(0.09523809523809523), 25: np.float64(0.5853658536585366), 26: np.float64(0.6666666666666666), 29: np.float64(0.8440366972477065), 30: np.float64(0.6538461538461539), 32: np.float64(0.5725806451612904), 33: np.float64(0.2727272727272727), 34: np.float64(0.3628691983122363), 35: np.float64(0.2709677419354839), 36: np.float64(0.5960264900662252), 37: np.float64(0.20952380952380953), 38: np.float64(0.34782608695652173)}
Micro-average F1 score: 0.4727608494921514
Weighted-average F1 score: 0.45822009853673673
F1 score per class: {1: np.float64(0.16666666666666666), 3: np.float64(0.5126050420168067), 6: np.float64(0.5761316872427984), 8: np.float64(0.4429530201342282), 14: np.float64(0.06741573033707865), 15: np.float64(0.631578947368421), 19: np.float64(0.6586345381526104), 20: np.float64(0.4742268041237113), 22: np.float64(0.47876447876447875), 24: np.float64(0.06896551724137931), 25: np.float64(0.5), 26: np.float64(0.6910994764397905), 29: np.float64(0.8653846153846154), 30: np.float64(0.8717948717948718), 32: np.float64(0.5772357723577236), 33: np.float64(0.3157894736842105), 34: np.float64(0.30714285714285716), 35: np.float64(0.2184873949579832), 36: np.float64(0.5964912280701754), 37: np.float64(0.14285714285714285), 38: np.float64(0.3076923076923077)}
Micro-average F1 score: 0.47096774193548385
Weighted-average F1 score: 0.4549279883612718

F1 score per class: {32: np.float64(0.11275964391691394), 1: np.float64(0.5925925925925926), 34: np.float64(0.0), 3: np.float64(0.0), 35: np.float64(0.08), 37: np.float64(0.0), 6: np.float64(0.0), 33: np.float64(0.45185185185185184), 8: np.float64(0.0), 14: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.5211267605633803), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.2800944138473643
Weighted-average F1 score: 0.24099011428759923
F1 score per class: {1: np.float64(0.1165644171779141), 3: np.float64(0.4807692307692308), 6: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.047619047619047616), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.4460431654676259), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.5088757396449705), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.23405654174884943
Weighted-average F1 score: 0.20025740708105086
F1 score per class: {1: np.float64(0.11515151515151516), 3: np.float64(0.5648148148148148), 6: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.07228915662650602), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.43356643356643354), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.5149700598802395), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.26164383561643834
Weighted-average F1 score: 0.22780357579016886

F1 score per class: {1: np.float64(0.08296943231441048), 3: np.float64(0.3771043771043771), 6: np.float64(0.375), 8: np.float64(0.3076923076923077), 14: np.float64(0.062111801242236024), 15: np.float64(0.5161290322580645), 19: np.float64(0.6115702479338843), 20: np.float64(0.27722772277227725), 22: np.float64(0.3708206686930091), 24: np.float64(0.08), 25: np.float64(0.37681159420289856), 26: np.float64(0.625), 29: np.float64(0.7302904564315352), 30: np.float64(0.8333333333333334), 32: np.float64(0.45482866043613707), 33: np.float64(0.24), 34: np.float64(0.22560975609756098), 35: np.float64(0.0594059405940594), 36: np.float64(0.4482758620689655), 37: np.float64(0.14492753623188406), 38: np.float64(0.12244897959183673)}
Micro-average F1 score: 0.35485621269669015
Weighted-average F1 score: 0.338952770776092
F1 score per class: {1: np.float64(0.0892018779342723), 3: np.float64(0.3048780487804878), 6: np.float64(0.37994722955145116), 8: np.float64(0.328125), 14: np.float64(0.03508771929824561), 15: np.float64(0.46153846153846156), 19: np.float64(0.5589225589225589), 20: np.float64(0.31137724550898205), 22: np.float64(0.36578171091445427), 24: np.float64(0.07407407407407407), 25: np.float64(0.5274725274725275), 26: np.float64(0.5775862068965517), 29: np.float64(0.6840148698884758), 30: np.float64(0.5666666666666667), 32: np.float64(0.42900302114803623), 33: np.float64(0.1875), 34: np.float64(0.24022346368715083), 35: np.float64(0.18340611353711792), 36: np.float64(0.4265402843601896), 37: np.float64(0.18487394957983194), 38: np.float64(0.21052631578947367)}
Micro-average F1 score: 0.34072759538598046
Weighted-average F1 score: 0.3259938823835001
F1 score per class: {1: np.float64(0.0867579908675799), 3: np.float64(0.3515850144092219), 6: np.float64(0.3713527851458886), 8: np.float64(0.3473684210526316), 14: np.float64(0.05172413793103448), 15: np.float64(0.46153846153846156), 19: np.float64(0.5815602836879432), 20: np.float64(0.3108108108108108), 22: np.float64(0.35327635327635326), 24: np.float64(0.06060606060606061), 25: np.float64(0.45569620253164556), 26: np.float64(0.6027397260273972), 29: np.float64(0.7086614173228346), 30: np.float64(0.8292682926829268), 32: np.float64(0.4303030303030303), 33: np.float64(0.23076923076923078), 34: np.float64(0.2113022113022113), 35: np.float64(0.15028901734104047), 36: np.float64(0.4563758389261745), 37: np.float64(0.1348314606741573), 38: np.float64(0.17142857142857143)}
Micro-average F1 score: 0.3426425721661582
Weighted-average F1 score: 0.32494665948456414
cur_acc_wo_na:  ['0.7554', '0.5116', '0.4668', '0.3960']
his_acc_wo_na:  ['0.7554', '0.6904', '0.6185', '0.4736']
cur_acc des_wo_na:  ['0.7544', '0.6221', '0.5496', '0.3413']
his_acc des_wo_na:  ['0.7544', '0.6949', '0.6182', '0.4728']
cur_acc rrf_wo_na:  ['0.7715', '0.6165', '0.5628', '0.3782']
his_acc rrf_wo_na:  ['0.7715', '0.7038', '0.6305', '0.4710']
cur_acc_w_na:  ['0.6410', '0.4272', '0.3753', '0.2801']
his_acc_w_na:  ['0.6410', '0.5615', '0.5040', '0.3549']
cur_acc des_w_na:  ['0.6092', '0.4830', '0.3958', '0.2341']
his_acc des_w_na:  ['0.6092', '0.5250', '0.4668', '0.3407']
cur_acc rrf_w_na:  ['0.6256', '0.4847', '0.4134', '0.2616']
his_acc rrf_w_na:  ['0.6256', '0.5468', '0.4853', '0.3426']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 148.9840420CurrentTrain: epoch  0, batch     1 | loss: 97.9805357CurrentTrain: epoch  0, batch     2 | loss: 88.1775470CurrentTrain: epoch  0, batch     3 | loss: 92.8078281CurrentTrain: epoch  0, batch     4 | loss: 122.2406611CurrentTrain: epoch  1, batch     0 | loss: 92.7651639CurrentTrain: epoch  1, batch     1 | loss: 107.8831326CurrentTrain: epoch  1, batch     2 | loss: 94.8577167CurrentTrain: epoch  1, batch     3 | loss: 101.6974227CurrentTrain: epoch  1, batch     4 | loss: 64.7807780CurrentTrain: epoch  2, batch     0 | loss: 90.1841979CurrentTrain: epoch  2, batch     1 | loss: 68.8479990CurrentTrain: epoch  2, batch     2 | loss: 105.9686768CurrentTrain: epoch  2, batch     3 | loss: 101.5699032CurrentTrain: epoch  2, batch     4 | loss: 116.4575550CurrentTrain: epoch  3, batch     0 | loss: 71.5350258CurrentTrain: epoch  3, batch     1 | loss: 97.5383374CurrentTrain: epoch  3, batch     2 | loss: 128.9963747CurrentTrain: epoch  3, batch     3 | loss: 87.4125126CurrentTrain: epoch  3, batch     4 | loss: 80.4717223CurrentTrain: epoch  4, batch     0 | loss: 82.3899771CurrentTrain: epoch  4, batch     1 | loss: 96.7056033CurrentTrain: epoch  4, batch     2 | loss: 123.7942920CurrentTrain: epoch  4, batch     3 | loss: 86.0984793CurrentTrain: epoch  4, batch     4 | loss: 51.9010466CurrentTrain: epoch  5, batch     0 | loss: 127.0689276CurrentTrain: epoch  5, batch     1 | loss: 84.0629273CurrentTrain: epoch  5, batch     2 | loss: 68.2178632CurrentTrain: epoch  5, batch     3 | loss: 99.2907161CurrentTrain: epoch  5, batch     4 | loss: 49.6842046CurrentTrain: epoch  6, batch     0 | loss: 83.8745357CurrentTrain: epoch  6, batch     1 | loss: 77.8499394CurrentTrain: epoch  6, batch     2 | loss: 83.4236608CurrentTrain: epoch  6, batch     3 | loss: 79.1399401CurrentTrain: epoch  6, batch     4 | loss: 64.1147141CurrentTrain: epoch  7, batch     0 | loss: 124.7307935CurrentTrain: epoch  7, batch     1 | loss: 98.4213992CurrentTrain: epoch  7, batch     2 | loss: 77.0834337CurrentTrain: epoch  7, batch     3 | loss: 79.5804664CurrentTrain: epoch  7, batch     4 | loss: 60.6489382CurrentTrain: epoch  8, batch     0 | loss: 96.1241410CurrentTrain: epoch  8, batch     1 | loss: 67.3605268CurrentTrain: epoch  8, batch     2 | loss: 124.0026601CurrentTrain: epoch  8, batch     3 | loss: 79.6678591CurrentTrain: epoch  8, batch     4 | loss: 40.2990504CurrentTrain: epoch  9, batch     0 | loss: 64.9241891CurrentTrain: epoch  9, batch     1 | loss: 95.4259729CurrentTrain: epoch  9, batch     2 | loss: 74.6177065CurrentTrain: epoch  9, batch     3 | loss: 95.8568820CurrentTrain: epoch  9, batch     4 | loss: 107.7084008
MemoryTrain:  epoch  0, batch     0 | loss: 0.9914543MemoryTrain:  epoch  1, batch     0 | loss: 0.8292895MemoryTrain:  epoch  2, batch     0 | loss: 0.5867403MemoryTrain:  epoch  3, batch     0 | loss: 0.5142934MemoryTrain:  epoch  4, batch     0 | loss: 0.4108769MemoryTrain:  epoch  5, batch     0 | loss: 0.3483618MemoryTrain:  epoch  6, batch     0 | loss: 0.3126926MemoryTrain:  epoch  7, batch     0 | loss: 0.2597432MemoryTrain:  epoch  8, batch     0 | loss: 0.2322750MemoryTrain:  epoch  9, batch     0 | loss: 0.2301651

F1 score per class: {32: np.float64(0.0), 34: np.float64(0.8846153846153846), 3: np.float64(0.0), 5: np.float64(0.0), 38: np.float64(0.5789473684210527), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.7246376811594203), 14: np.float64(0.2857142857142857), 15: np.float64(0.1348314606741573), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.49560117302052786
Weighted-average F1 score: 0.39986305823941204
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.7396226415094339), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.546583850931677), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.7246376811594203), 17: np.float64(0.0), 18: np.float64(0.1568627450980392), 19: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.4146919431279621
Weighted-average F1 score: 0.3412610893529557
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.8270042194092827), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.5644171779141104), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.7575757575757576), 17: np.float64(0.0), 18: np.float64(0.17475728155339806), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.4529262086513995
Weighted-average F1 score: 0.36796974141747496

F1 score per class: {1: np.float64(0.17857142857142858), 3: np.float64(0.4444444444444444), 5: np.float64(0.7244094488188977), 6: np.float64(0.507177033492823), 8: np.float64(0.19801980198019803), 10: np.float64(0.3651452282157676), 14: np.float64(0.056074766355140186), 15: np.float64(0.64), 16: np.float64(0.5494505494505495), 17: np.float64(0.1111111111111111), 18: np.float64(0.08888888888888889), 19: np.float64(0.6521739130434783), 20: np.float64(0.4358974358974359), 22: np.float64(0.5058365758754864), 24: np.float64(0.10526315789473684), 25: np.float64(0.36363636363636365), 26: np.float64(0.6804123711340206), 29: np.float64(0.8472906403940886), 30: np.float64(0.9142857142857143), 32: np.float64(0.5833333333333334), 33: np.float64(0.4), 34: np.float64(0.22826086956521738), 35: np.float64(0.08333333333333333), 36: np.float64(0.1917808219178082), 37: np.float64(0.15584415584415584), 38: np.float64(0.06666666666666667)}
Micro-average F1 score: 0.43519820073095306
Weighted-average F1 score: 0.4344260550652607
F1 score per class: {1: np.float64(0.18723404255319148), 3: np.float64(0.4253393665158371), 5: np.float64(0.5414364640883977), 6: np.float64(0.531986531986532), 8: np.float64(0.43209876543209874), 10: np.float64(0.36363636363636365), 14: np.float64(0.056818181818181816), 15: np.float64(0.5454545454545454), 16: np.float64(0.5376344086021505), 17: np.float64(0.0), 18: np.float64(0.10666666666666667), 19: np.float64(0.6064981949458483), 20: np.float64(0.45454545454545453), 22: np.float64(0.4844290657439446), 24: np.float64(0.05555555555555555), 25: np.float64(0.5), 26: np.float64(0.6194690265486725), 29: np.float64(0.8251121076233184), 30: np.float64(0.5151515151515151), 32: np.float64(0.5535055350553506), 33: np.float64(0.2727272727272727), 34: np.float64(0.23626373626373626), 35: np.float64(0.24161073825503357), 36: np.float64(0.5625), 37: np.float64(0.18461538461538463), 38: np.float64(0.35555555555555557)}
Micro-average F1 score: 0.4281484855386017
Weighted-average F1 score: 0.4154557435673955
F1 score per class: {1: np.float64(0.17886178861788618), 3: np.float64(0.49523809523809526), 5: np.float64(0.6343042071197411), 6: np.float64(0.5427509293680297), 8: np.float64(0.37593984962406013), 10: np.float64(0.34980988593155893), 14: np.float64(0.07453416149068323), 15: np.float64(0.5217391304347826), 16: np.float64(0.5319148936170213), 17: np.float64(0.0), 18: np.float64(0.11612903225806452), 19: np.float64(0.6217228464419475), 20: np.float64(0.5376344086021505), 22: np.float64(0.49645390070921985), 24: np.float64(0.06896551724137931), 25: np.float64(0.4657534246575342), 26: np.float64(0.6445497630331753), 29: np.float64(0.861244019138756), 30: np.float64(0.7555555555555555), 32: np.float64(0.5641025641025641), 33: np.float64(0.35294117647058826), 34: np.float64(0.22380952380952382), 35: np.float64(0.17543859649122806), 36: np.float64(0.45454545454545453), 37: np.float64(0.17777777777777778), 38: np.float64(0.17647058823529413)}
Micro-average F1 score: 0.4364252845725357
Weighted-average F1 score: 0.42261227673702956

F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.7330677290836654), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.4808743169398907), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.4424778761061947), 17: np.float64(0.23529411764705882), 18: np.float64(0.11320754716981132), 20: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.3434959349593496
Weighted-average F1 score: 0.2782840858903277
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.5632183908045977), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.4536082474226804), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.45045045045045046), 17: np.float64(0.0), 18: np.float64(0.128), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.2734375
Weighted-average F1 score: 0.22915121779258832
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.6261980830670927), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.45544554455445546), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.44642857142857145), 17: np.float64(0.0), 18: np.float64(0.14285714285714285), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.2999157540016849
Weighted-average F1 score: 0.25154452887955414

F1 score per class: {1: np.float64(0.09049773755656108), 3: np.float64(0.33497536945812806), 5: np.float64(0.5380116959064327), 6: np.float64(0.3063583815028902), 8: np.float64(0.1724137931034483), 10: np.float64(0.25287356321839083), 14: np.float64(0.047244094488188976), 15: np.float64(0.4444444444444444), 16: np.float64(0.2808988764044944), 17: np.float64(0.07272727272727272), 18: np.float64(0.06315789473684211), 19: np.float64(0.5555555555555556), 20: np.float64(0.2809917355371901), 22: np.float64(0.3951367781155015), 24: np.float64(0.1), 25: np.float64(0.34782608695652173), 26: np.float64(0.5866666666666667), 29: np.float64(0.6991869918699187), 30: np.float64(0.8648648648648649), 32: np.float64(0.4375), 33: np.float64(0.35294117647058826), 34: np.float64(0.13570274636510501), 35: np.float64(0.06666666666666667), 36: np.float64(0.17721518987341772), 37: np.float64(0.15), 38: np.float64(0.045454545454545456)}
Micro-average F1 score: 0.3107809676771733
Weighted-average F1 score: 0.2984923300420763
F1 score per class: {1: np.float64(0.0962800875273523), 3: np.float64(0.2946708463949843), 5: np.float64(0.3462897526501767), 6: np.float64(0.316), 8: np.float64(0.3125), 10: np.float64(0.24444444444444444), 14: np.float64(0.04310344827586207), 15: np.float64(0.34285714285714286), 16: np.float64(0.2994011976047904), 17: np.float64(0.0), 18: np.float64(0.0784313725490196), 19: np.float64(0.4772727272727273), 20: np.float64(0.26490066225165565), 22: np.float64(0.35989717223650386), 24: np.float64(0.04081632653061224), 25: np.float64(0.43564356435643564), 26: np.float64(0.5), 29: np.float64(0.6153846153846154), 30: np.float64(0.425), 32: np.float64(0.4076086956521739), 33: np.float64(0.17647058823529413), 34: np.float64(0.1407528641571195), 35: np.float64(0.16071428571428573), 36: np.float64(0.3870967741935484), 37: np.float64(0.1348314606741573), 38: np.float64(0.1951219512195122)}
Micro-average F1 score: 0.2883435582822086
Weighted-average F1 score: 0.2785023120821062
F1 score per class: {1: np.float64(0.09341825902335456), 3: np.float64(0.3525423728813559), 5: np.float64(0.3967611336032389), 6: np.float64(0.32516703786191536), 8: np.float64(0.29069767441860467), 10: np.float64(0.23057644110275688), 14: np.float64(0.05581395348837209), 15: np.float64(0.3157894736842105), 16: np.float64(0.27472527472527475), 17: np.float64(0.0), 18: np.float64(0.0821917808219178), 19: np.float64(0.503030303030303), 20: np.float64(0.32051282051282054), 22: np.float64(0.3713527851458886), 24: np.float64(0.058823529411764705), 25: np.float64(0.43037974683544306), 26: np.float64(0.5483870967741935), 29: np.float64(0.6716417910447762), 30: np.float64(0.6938775510204082), 32: np.float64(0.41621621621621624), 33: np.float64(0.23076923076923078), 34: np.float64(0.13505747126436782), 35: np.float64(0.125), 36: np.float64(0.3448275862068966), 37: np.float64(0.15384615384615385), 38: np.float64(0.10714285714285714)}
Micro-average F1 score: 0.2979004794180856
Weighted-average F1 score: 0.2848123141551817
cur_acc_wo_na:  ['0.7554', '0.5116', '0.4668', '0.3960', '0.4956']
his_acc_wo_na:  ['0.7554', '0.6904', '0.6185', '0.4736', '0.4352']
cur_acc des_wo_na:  ['0.7544', '0.6221', '0.5496', '0.3413', '0.4147']
his_acc des_wo_na:  ['0.7544', '0.6949', '0.6182', '0.4728', '0.4281']
cur_acc rrf_wo_na:  ['0.7715', '0.6165', '0.5628', '0.3782', '0.4529']
his_acc rrf_wo_na:  ['0.7715', '0.7038', '0.6305', '0.4710', '0.4364']
cur_acc_w_na:  ['0.6410', '0.4272', '0.3753', '0.2801', '0.3435']
his_acc_w_na:  ['0.6410', '0.5615', '0.5040', '0.3549', '0.3108']
cur_acc des_w_na:  ['0.6092', '0.4830', '0.3958', '0.2341', '0.2734']
his_acc des_w_na:  ['0.6092', '0.5250', '0.4668', '0.3407', '0.2883']
cur_acc rrf_w_na:  ['0.6256', '0.4847', '0.4134', '0.2616', '0.2999']
his_acc rrf_w_na:  ['0.6256', '0.5468', '0.4853', '0.3426', '0.2979']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 109.8031073CurrentTrain: epoch  0, batch     1 | loss: 144.3394034CurrentTrain: epoch  0, batch     2 | loss: 114.3830490CurrentTrain: epoch  0, batch     3 | loss: 97.6005396CurrentTrain: epoch  1, batch     0 | loss: 146.6103216CurrentTrain: epoch  1, batch     1 | loss: 79.7458165CurrentTrain: epoch  1, batch     2 | loss: 104.2813985CurrentTrain: epoch  1, batch     3 | loss: 73.8972272CurrentTrain: epoch  2, batch     0 | loss: 105.8433778CurrentTrain: epoch  2, batch     1 | loss: 76.4095796CurrentTrain: epoch  2, batch     2 | loss: 102.5313687CurrentTrain: epoch  2, batch     3 | loss: 60.0472870CurrentTrain: epoch  3, batch     0 | loss: 71.8956996CurrentTrain: epoch  3, batch     1 | loss: 87.4451960CurrentTrain: epoch  3, batch     2 | loss: 72.8585740CurrentTrain: epoch  3, batch     3 | loss: 70.6318871CurrentTrain: epoch  4, batch     0 | loss: 85.3700591CurrentTrain: epoch  4, batch     1 | loss: 85.6062479CurrentTrain: epoch  4, batch     2 | loss: 85.2445596CurrentTrain: epoch  4, batch     3 | loss: 61.7494326CurrentTrain: epoch  5, batch     0 | loss: 98.9655608CurrentTrain: epoch  5, batch     1 | loss: 86.2728873CurrentTrain: epoch  5, batch     2 | loss: 122.9478710CurrentTrain: epoch  5, batch     3 | loss: 61.4780994CurrentTrain: epoch  6, batch     0 | loss: 85.6869427CurrentTrain: epoch  6, batch     1 | loss: 99.1553799CurrentTrain: epoch  6, batch     2 | loss: 97.8481417CurrentTrain: epoch  6, batch     3 | loss: 51.0336235CurrentTrain: epoch  7, batch     0 | loss: 64.4873811CurrentTrain: epoch  7, batch     1 | loss: 94.6583585CurrentTrain: epoch  7, batch     2 | loss: 98.5307219CurrentTrain: epoch  7, batch     3 | loss: 83.5284348CurrentTrain: epoch  8, batch     0 | loss: 75.1714284CurrentTrain: epoch  8, batch     1 | loss: 77.6400228CurrentTrain: epoch  8, batch     2 | loss: 70.4801947CurrentTrain: epoch  8, batch     3 | loss: 99.0527748CurrentTrain: epoch  9, batch     0 | loss: 65.4321717CurrentTrain: epoch  9, batch     1 | loss: 66.7212163CurrentTrain: epoch  9, batch     2 | loss: 94.9717182CurrentTrain: epoch  9, batch     3 | loss: 78.2490103
MemoryTrain:  epoch  0, batch     0 | loss: 0.8654927MemoryTrain:  epoch  1, batch     0 | loss: 0.7322151MemoryTrain:  epoch  2, batch     0 | loss: 0.5881190MemoryTrain:  epoch  3, batch     0 | loss: 0.5022970MemoryTrain:  epoch  4, batch     0 | loss: 0.4234328MemoryTrain:  epoch  5, batch     0 | loss: 0.3825577MemoryTrain:  epoch  6, batch     0 | loss: 0.3081000MemoryTrain:  epoch  7, batch     0 | loss: 0.2519149MemoryTrain:  epoch  8, batch     0 | loss: 0.2384471MemoryTrain:  epoch  9, batch     0 | loss: 0.2155131

F1 score per class: {0: np.float64(0.8611111111111112), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.9417989417989417), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.26666666666666666), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.5806451612903226), 22: np.float64(0.0), 23: np.float64(0.7640449438202247), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0)}
Micro-average F1 score: 0.71900826446281
Weighted-average F1 score: 0.6314982917276925
F1 score per class: {0: np.float64(0.7578947368421053), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8877551020408163), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.4444444444444444), 14: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.625), 22: np.float64(0.0), 23: np.float64(0.6744186046511628), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.5704918032786885
Weighted-average F1 score: 0.45612176382547076
F1 score per class: {0: np.float64(0.813953488372093), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.93048128342246), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.2857142857142857), 14: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.5405405405405406), 22: np.float64(0.0), 23: np.float64(0.6823529411764706), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.6059544658493871
Weighted-average F1 score: 0.4916799890808099

F1 score per class: {0: np.float64(0.62), 1: np.float64(0.16), 3: np.float64(0.5714285714285714), 4: np.float64(0.9417989417989417), 5: np.float64(0.7322834645669292), 6: np.float64(0.5064377682403434), 8: np.float64(0.12903225806451613), 10: np.float64(0.32335329341317365), 13: np.float64(0.05128205128205128), 14: np.float64(0.02631578947368421), 15: np.float64(0.6666666666666666), 16: np.float64(0.647887323943662), 17: np.float64(0.08333333333333333), 18: np.float64(0.12903225806451613), 19: np.float64(0.704225352112676), 20: np.float64(0.4), 21: np.float64(0.2033898305084746), 22: np.float64(0.526829268292683), 23: np.float64(0.6415094339622641), 24: np.float64(0.0), 25: np.float64(0.36363636363636365), 26: np.float64(0.6702127659574468), 29: np.float64(0.7938144329896907), 30: np.float64(0.9444444444444444), 32: np.float64(0.5527272727272727), 33: np.float64(0.4), 34: np.float64(0.2554517133956386), 35: np.float64(0.1927710843373494), 36: np.float64(0.08695652173913043), 37: np.float64(0.15151515151515152), 38: np.float64(0.12903225806451613)}
Micro-average F1 score: 0.46964608628261434
Weighted-average F1 score: 0.47089041465301906
F1 score per class: {0: np.float64(0.3364485981308411), 1: np.float64(0.17475728155339806), 3: np.float64(0.4435146443514644), 4: np.float64(0.8877551020408163), 5: np.float64(0.5552407932011332), 6: np.float64(0.5347985347985348), 8: np.float64(0.42105263157894735), 10: np.float64(0.38613861386138615), 13: np.float64(0.06557377049180328), 14: np.float64(0.048484848484848485), 15: np.float64(0.631578947368421), 16: np.float64(0.5679012345679012), 17: np.float64(0.21428571428571427), 18: np.float64(0.12280701754385964), 19: np.float64(0.6484375), 20: np.float64(0.5416666666666666), 21: np.float64(0.17777777777777778), 22: np.float64(0.4032258064516129), 23: np.float64(0.5918367346938775), 24: np.float64(0.09090909090909091), 25: np.float64(0.5), 26: np.float64(0.6036036036036037), 29: np.float64(0.8090909090909091), 30: np.float64(0.68), 32: np.float64(0.5276872964169381), 33: np.float64(0.35294117647058826), 34: np.float64(0.2826086956521739), 35: np.float64(0.2727272727272727), 36: np.float64(0.5573770491803278), 37: np.float64(0.20408163265306123), 38: np.float64(0.38596491228070173)}
Micro-average F1 score: 0.446040213377103
Weighted-average F1 score: 0.42733357872106864
F1 score per class: {0: np.float64(0.4605263157894737), 1: np.float64(0.1722488038277512), 3: np.float64(0.4472573839662447), 4: np.float64(0.93048128342246), 5: np.float64(0.6254071661237784), 6: np.float64(0.5378787878787878), 8: np.float64(0.2542372881355932), 10: np.float64(0.3827751196172249), 13: np.float64(0.043478260869565216), 14: np.float64(0.055944055944055944), 15: np.float64(0.6666666666666666), 16: np.float64(0.5897435897435898), 17: np.float64(0.2222222222222222), 18: np.float64(0.13725490196078433), 19: np.float64(0.6507936507936508), 20: np.float64(0.6), 21: np.float64(0.1694915254237288), 22: np.float64(0.45454545454545453), 23: np.float64(0.5918367346938775), 24: np.float64(0.09523809523809523), 25: np.float64(0.45714285714285713), 26: np.float64(0.6220095693779905), 29: np.float64(0.8461538461538461), 30: np.float64(0.7727272727272727), 32: np.float64(0.5294117647058824), 33: np.float64(0.35294117647058826), 34: np.float64(0.2484472049689441), 35: np.float64(0.21739130434782608), 36: np.float64(0.3855421686746988), 37: np.float64(0.1388888888888889), 38: np.float64(0.3076923076923077)}
Micro-average F1 score: 0.44702276707530647
Weighted-average F1 score: 0.4283475197024495

F1 score per class: {0: np.float64(0.8493150684931506), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.9035532994923858), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.14814814814814814), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.4090909090909091), 22: np.float64(0.0), 23: np.float64(0.68), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.5480314960629922
Weighted-average F1 score: 0.43575290022639984
F1 score per class: {0: np.float64(0.6666666666666666), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8529411764705882), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.25), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.45977011494252873), 22: np.float64(0.0), 23: np.float64(0.5858585858585859), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.4223300970873786
Weighted-average F1 score: 0.32284931885381224
F1 score per class: {0: np.float64(0.7608695652173914), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8923076923076924), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.16666666666666666), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.4), 22: np.float64(0.0), 23: np.float64(0.5918367346938775), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.44993498049414826
Weighted-average F1 score: 0.3416528178365058

F1 score per class: {0: np.float64(0.4626865671641791), 1: np.float64(0.08376963350785341), 3: np.float64(0.42857142857142855), 4: np.float64(0.8855721393034826), 5: np.float64(0.5329512893982808), 6: np.float64(0.3089005235602094), 8: np.float64(0.1188118811881188), 10: np.float64(0.2488479262672811), 13: np.float64(0.02531645569620253), 14: np.float64(0.023529411764705882), 15: np.float64(0.46153846153846156), 16: np.float64(0.40350877192982454), 17: np.float64(0.03773584905660377), 18: np.float64(0.09090909090909091), 19: np.float64(0.6410256410256411), 20: np.float64(0.26548672566371684), 21: np.float64(0.12413793103448276), 22: np.float64(0.4778761061946903), 23: np.float64(0.5271317829457365), 24: np.float64(0.0), 25: np.float64(0.34782608695652173), 26: np.float64(0.5833333333333334), 29: np.float64(0.6814159292035398), 30: np.float64(0.8717948717948718), 32: np.float64(0.40105540897097625), 33: np.float64(0.4), 34: np.float64(0.15891472868217055), 35: np.float64(0.13559322033898305), 36: np.float64(0.0821917808219178), 37: np.float64(0.14084507042253522), 38: np.float64(0.0975609756097561)}
Micro-average F1 score: 0.34386230376394933
Weighted-average F1 score: 0.3259141011966104
F1 score per class: {0: np.float64(0.22018348623853212), 1: np.float64(0.09113924050632911), 3: np.float64(0.29526462395543174), 4: np.float64(0.8325358851674641), 5: np.float64(0.35766423357664234), 6: np.float64(0.31601731601731603), 8: np.float64(0.2891566265060241), 10: np.float64(0.2582781456953642), 13: np.float64(0.036036036036036036), 14: np.float64(0.03827751196172249), 15: np.float64(0.5), 16: np.float64(0.3458646616541353), 17: np.float64(0.0967741935483871), 18: np.float64(0.08860759493670886), 19: np.float64(0.5286624203821656), 20: np.float64(0.3170731707317073), 21: np.float64(0.11661807580174927), 22: np.float64(0.31347962382445144), 23: np.float64(0.4715447154471545), 24: np.float64(0.08), 25: np.float64(0.45652173913043476), 26: np.float64(0.5173745173745173), 29: np.float64(0.624561403508772), 30: np.float64(0.5483870967741935), 32: np.float64(0.3829787234042553), 33: np.float64(0.2608695652173913), 34: np.float64(0.16595744680851063), 35: np.float64(0.17872340425531916), 36: np.float64(0.4276729559748428), 37: np.float64(0.15748031496062992), 38: np.float64(0.22916666666666666)}
Micro-average F1 score: 0.30762699872647514
Weighted-average F1 score: 0.2908816747931116
F1 score per class: {0: np.float64(0.3153153153153153), 1: np.float64(0.08977556109725686), 3: np.float64(0.301994301994302), 4: np.float64(0.87), 5: np.float64(0.4067796610169492), 6: np.float64(0.32054176072234764), 8: np.float64(0.20134228187919462), 10: np.float64(0.2572347266881029), 13: np.float64(0.023952095808383235), 14: np.float64(0.044444444444444446), 15: np.float64(0.48), 16: np.float64(0.3484848484848485), 17: np.float64(0.1111111111111111), 18: np.float64(0.09523809523809523), 19: np.float64(0.5377049180327869), 20: np.float64(0.34394904458598724), 21: np.float64(0.11049723756906077), 22: np.float64(0.35714285714285715), 23: np.float64(0.46774193548387094), 24: np.float64(0.09523809523809523), 25: np.float64(0.43243243243243246), 26: np.float64(0.5371900826446281), 29: np.float64(0.6901960784313725), 30: np.float64(0.68), 32: np.float64(0.38571428571428573), 33: np.float64(0.3), 34: np.float64(0.149812734082397), 35: np.float64(0.14423076923076922), 36: np.float64(0.3047619047619048), 37: np.float64(0.12345679012345678), 38: np.float64(0.20689655172413793)}
Micro-average F1 score: 0.3117557251908397
Weighted-average F1 score: 0.2926051818695553
cur_acc_wo_na:  ['0.7554', '0.5116', '0.4668', '0.3960', '0.4956', '0.7190']
his_acc_wo_na:  ['0.7554', '0.6904', '0.6185', '0.4736', '0.4352', '0.4696']
cur_acc des_wo_na:  ['0.7544', '0.6221', '0.5496', '0.3413', '0.4147', '0.5705']
his_acc des_wo_na:  ['0.7544', '0.6949', '0.6182', '0.4728', '0.4281', '0.4460']
cur_acc rrf_wo_na:  ['0.7715', '0.6165', '0.5628', '0.3782', '0.4529', '0.6060']
his_acc rrf_wo_na:  ['0.7715', '0.7038', '0.6305', '0.4710', '0.4364', '0.4470']
cur_acc_w_na:  ['0.6410', '0.4272', '0.3753', '0.2801', '0.3435', '0.5480']
his_acc_w_na:  ['0.6410', '0.5615', '0.5040', '0.3549', '0.3108', '0.3439']
cur_acc des_w_na:  ['0.6092', '0.4830', '0.3958', '0.2341', '0.2734', '0.4223']
his_acc des_w_na:  ['0.6092', '0.5250', '0.4668', '0.3407', '0.2883', '0.3076']
cur_acc rrf_w_na:  ['0.6256', '0.4847', '0.4134', '0.2616', '0.2999', '0.4499']
his_acc rrf_w_na:  ['0.6256', '0.5468', '0.4853', '0.3426', '0.2979', '0.3118']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 89.0029389CurrentTrain: epoch  0, batch     1 | loss: 120.9920517CurrentTrain: epoch  0, batch     2 | loss: 111.1035128CurrentTrain: epoch  0, batch     3 | loss: 117.1597828CurrentTrain: epoch  0, batch     4 | loss: 29.1558126CurrentTrain: epoch  1, batch     0 | loss: 94.2598520CurrentTrain: epoch  1, batch     1 | loss: 132.5552976CurrentTrain: epoch  1, batch     2 | loss: 73.4076782CurrentTrain: epoch  1, batch     3 | loss: 181.4792867CurrentTrain: epoch  1, batch     4 | loss: 30.6714597CurrentTrain: epoch  2, batch     0 | loss: 108.4437309CurrentTrain: epoch  2, batch     1 | loss: 103.2508176CurrentTrain: epoch  2, batch     2 | loss: 98.5412382CurrentTrain: epoch  2, batch     3 | loss: 85.3389373CurrentTrain: epoch  2, batch     4 | loss: 15.5274940CurrentTrain: epoch  3, batch     0 | loss: 85.1144060CurrentTrain: epoch  3, batch     1 | loss: 85.0503422CurrentTrain: epoch  3, batch     2 | loss: 81.8204840CurrentTrain: epoch  3, batch     3 | loss: 81.0523187CurrentTrain: epoch  3, batch     4 | loss: 27.5516478CurrentTrain: epoch  4, batch     0 | loss: 68.5216786CurrentTrain: epoch  4, batch     1 | loss: 65.1085068CurrentTrain: epoch  4, batch     2 | loss: 85.7275737CurrentTrain: epoch  4, batch     3 | loss: 82.6567348CurrentTrain: epoch  4, batch     4 | loss: 44.9084688CurrentTrain: epoch  5, batch     0 | loss: 67.5343969CurrentTrain: epoch  5, batch     1 | loss: 124.0271977CurrentTrain: epoch  5, batch     2 | loss: 81.9926294CurrentTrain: epoch  5, batch     3 | loss: 78.8115800CurrentTrain: epoch  5, batch     4 | loss: 26.0871727CurrentTrain: epoch  6, batch     0 | loss: 79.4514055CurrentTrain: epoch  6, batch     1 | loss: 67.3341578CurrentTrain: epoch  6, batch     2 | loss: 76.0552796CurrentTrain: epoch  6, batch     3 | loss: 98.7504693CurrentTrain: epoch  6, batch     4 | loss: 41.1717798CurrentTrain: epoch  7, batch     0 | loss: 78.6648489CurrentTrain: epoch  7, batch     1 | loss: 68.0220264CurrentTrain: epoch  7, batch     2 | loss: 78.6062822CurrentTrain: epoch  7, batch     3 | loss: 77.8865148CurrentTrain: epoch  7, batch     4 | loss: 12.2126433CurrentTrain: epoch  8, batch     0 | loss: 65.3677814CurrentTrain: epoch  8, batch     1 | loss: 93.7761208CurrentTrain: epoch  8, batch     2 | loss: 80.6175972CurrentTrain: epoch  8, batch     3 | loss: 64.1338753CurrentTrain: epoch  8, batch     4 | loss: 25.1523319CurrentTrain: epoch  9, batch     0 | loss: 78.3950652CurrentTrain: epoch  9, batch     1 | loss: 91.7635955CurrentTrain: epoch  9, batch     2 | loss: 78.3890627CurrentTrain: epoch  9, batch     3 | loss: 75.2487785CurrentTrain: epoch  9, batch     4 | loss: 25.0347738
MemoryTrain:  epoch  0, batch     0 | loss: 0.8425751MemoryTrain:  epoch  1, batch     0 | loss: 0.7617063MemoryTrain:  epoch  2, batch     0 | loss: 0.6379548MemoryTrain:  epoch  3, batch     0 | loss: 0.5785247MemoryTrain:  epoch  4, batch     0 | loss: 0.4763880MemoryTrain:  epoch  5, batch     0 | loss: 0.4184390MemoryTrain:  epoch  6, batch     0 | loss: 0.3521894MemoryTrain:  epoch  7, batch     0 | loss: 0.3450702MemoryTrain:  epoch  8, batch     0 | loss: 0.2898895MemoryTrain:  epoch  9, batch     0 | loss: 0.2519722

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.5384615384615384), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.33043478260869563), 12: np.float64(0.6075949367088608), 13: np.float64(0.0), 14: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 28: np.float64(0.46153846153846156), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.1111111111111111)}
Micro-average F1 score: 0.38388625592417064
Weighted-average F1 score: 0.30575481953463846
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.45161290322580644), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.3969465648854962), 12: np.float64(0.6521739130434783), 13: np.float64(0.0), 14: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 28: np.float64(0.5), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.48)}
Micro-average F1 score: 0.3515358361774744
Weighted-average F1 score: 0.24813840560407696
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.56), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.4153846153846154), 12: np.float64(0.6555555555555556), 13: np.float64(0.0), 14: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 28: np.float64(0.34782608695652173), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.34782608695652173)}
Micro-average F1 score: 0.37969924812030076
Weighted-average F1 score: 0.27858921526375335

F1 score per class: {0: np.float64(0.6966292134831461), 1: np.float64(0.17297297297297298), 2: np.float64(0.28), 3: np.float64(0.4172661870503597), 4: np.float64(0.8888888888888888), 5: np.float64(0.782608695652174), 6: np.float64(0.5), 8: np.float64(0.13636363636363635), 10: np.float64(0.31901840490797545), 11: np.float64(0.14960629921259844), 12: np.float64(0.3392226148409894), 13: np.float64(0.0392156862745098), 14: np.float64(0.024691358024691357), 15: np.float64(0.6666666666666666), 16: np.float64(0.5151515151515151), 17: np.float64(0.0), 18: np.float64(0.04081632653061224), 19: np.float64(0.6929824561403509), 20: np.float64(0.29850746268656714), 21: np.float64(0.21487603305785125), 22: np.float64(0.5), 23: np.float64(0.6666666666666666), 24: np.float64(0.0), 25: np.float64(0.3880597014925373), 26: np.float64(0.6473988439306358), 28: np.float64(0.0975609756097561), 29: np.float64(0.7351351351351352), 30: np.float64(0.9444444444444444), 32: np.float64(0.5642857142857143), 33: np.float64(0.375), 34: np.float64(0.2537313432835821), 35: np.float64(0.20253164556962025), 36: np.float64(0.11428571428571428), 37: np.float64(0.15384615384615385), 38: np.float64(0.24), 39: np.float64(0.047619047619047616)}
Micro-average F1 score: 0.42700381679389315
Weighted-average F1 score: 0.42480186673581
F1 score per class: {0: np.float64(0.35294117647058826), 1: np.float64(0.19047619047619047), 2: np.float64(0.1686746987951807), 3: np.float64(0.4369747899159664), 4: np.float64(0.8717948717948718), 5: np.float64(0.6030769230769231), 6: np.float64(0.5078369905956113), 8: np.float64(0.42790697674418604), 10: np.float64(0.3380281690140845), 11: np.float64(0.1750841750841751), 12: np.float64(0.2850356294536817), 13: np.float64(0.03125), 14: np.float64(0.04285714285714286), 15: np.float64(0.631578947368421), 16: np.float64(0.5352112676056338), 17: np.float64(0.0), 18: np.float64(0.1), 19: np.float64(0.625), 20: np.float64(0.5168539325842697), 21: np.float64(0.16091954022988506), 22: np.float64(0.38461538461538464), 23: np.float64(0.6666666666666666), 24: np.float64(0.09090909090909091), 25: np.float64(0.5128205128205128), 26: np.float64(0.6432160804020101), 28: np.float64(0.1951219512195122), 29: np.float64(0.7783251231527094), 30: np.float64(0.5806451612903226), 32: np.float64(0.4885057471264368), 33: np.float64(0.2857142857142857), 34: np.float64(0.3108108108108108), 35: np.float64(0.26573426573426573), 36: np.float64(0.3695652173913043), 37: np.float64(0.21153846153846154), 38: np.float64(0.3492063492063492), 39: np.float64(0.15584415584415584)}
Micro-average F1 score: 0.40597227159616067
Weighted-average F1 score: 0.38854395011458653
F1 score per class: {0: np.float64(0.5245901639344263), 1: np.float64(0.19791666666666666), 2: np.float64(0.208955223880597), 3: np.float64(0.45045045045045046), 4: np.float64(0.8888888888888888), 5: np.float64(0.7028985507246377), 6: np.float64(0.5159010600706714), 8: np.float64(0.3076923076923077), 10: np.float64(0.3482587064676617), 11: np.float64(0.17880794701986755), 12: np.float64(0.30179028132992325), 13: np.float64(0.029850746268656716), 14: np.float64(0.045454545454545456), 15: np.float64(0.631578947368421), 16: np.float64(0.5352112676056338), 17: np.float64(0.0), 18: np.float64(0.08333333333333333), 19: np.float64(0.6363636363636364), 20: np.float64(0.4473684210526316), 21: np.float64(0.17777777777777778), 22: np.float64(0.39805825242718446), 23: np.float64(0.6666666666666666), 24: np.float64(0.09090909090909091), 25: np.float64(0.5066666666666667), 26: np.float64(0.6451612903225806), 28: np.float64(0.07766990291262135), 29: np.float64(0.7939698492462312), 30: np.float64(0.8181818181818182), 32: np.float64(0.5431309904153354), 33: np.float64(0.3333333333333333), 34: np.float64(0.28187919463087246), 35: np.float64(0.17543859649122806), 36: np.float64(0.23376623376623376), 37: np.float64(0.15), 38: np.float64(0.3492063492063492), 39: np.float64(0.11267605633802817)}
Micro-average F1 score: 0.4127601633923361
Weighted-average F1 score: 0.39562326375277596

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.3333333333333333), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.2714285714285714), 12: np.float64(0.5133689839572193), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.23076923076923078), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.08333333333333333)}
Micro-average F1 score: 0.2682119205298013
Weighted-average F1 score: 0.20977809559933322
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.27450980392156865), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.3170731707317073), 12: np.float64(0.5106382978723404), 13: np.float64(0.0), 14: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.21052631578947367), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.3333333333333333)}
Micro-average F1 score: 0.22366992399565688
Weighted-average F1 score: 0.16839354096880219
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.32558139534883723), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.33540372670807456), 12: np.float64(0.5130434782608696), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.14545454545454545), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.25)}
Micro-average F1 score: 0.24574209245742093
Weighted-average F1 score: 0.18836858259009384

F1 score per class: {0: np.float64(0.5344827586206896), 1: np.float64(0.08672086720867209), 2: np.float64(0.1590909090909091), 3: np.float64(0.3372093023255814), 4: np.float64(0.837696335078534), 5: np.float64(0.631578947368421), 6: np.float64(0.28717948717948716), 8: np.float64(0.12631578947368421), 10: np.float64(0.2561576354679803), 11: np.float64(0.09947643979057591), 12: np.float64(0.1348314606741573), 13: np.float64(0.02197802197802198), 14: np.float64(0.02197802197802198), 15: np.float64(0.6), 16: np.float64(0.3300970873786408), 17: np.float64(0.0), 18: np.float64(0.03125), 19: np.float64(0.6294820717131474), 20: np.float64(0.20408163265306123), 21: np.float64(0.1262135922330097), 22: np.float64(0.45595854922279794), 23: np.float64(0.5765765765765766), 24: np.float64(0.0), 25: np.float64(0.37142857142857144), 26: np.float64(0.5743589743589743), 28: np.float64(0.05454545454545454), 29: np.float64(0.6384976525821596), 30: np.float64(0.8717948717948718), 32: np.float64(0.41688654353562005), 33: np.float64(0.35294117647058826), 34: np.float64(0.18994413407821228), 35: np.float64(0.16), 36: np.float64(0.10526315789473684), 37: np.float64(0.14492753623188406), 38: np.float64(0.14814814814814814), 39: np.float64(0.03125)}
Micro-average F1 score: 0.2995314591700134
Weighted-average F1 score: 0.27532274388746264
F1 score per class: {0: np.float64(0.23684210526315788), 1: np.float64(0.09498680738786279), 2: np.float64(0.09032258064516129), 3: np.float64(0.30144927536231886), 4: np.float64(0.8095238095238095), 5: np.float64(0.4074844074844075), 6: np.float64(0.28125), 8: np.float64(0.2939297124600639), 10: np.float64(0.23684210526315788), 11: np.float64(0.11581291759465479), 12: np.float64(0.12320328542094455), 13: np.float64(0.016260162601626018), 14: np.float64(0.03488372093023256), 15: np.float64(0.5), 16: np.float64(0.3486238532110092), 17: np.float64(0.0), 18: np.float64(0.06779661016949153), 19: np.float64(0.5414012738853503), 20: np.float64(0.27218934911242604), 21: np.float64(0.10526315789473684), 22: np.float64(0.3137254901960784), 23: np.float64(0.5112781954887218), 24: np.float64(0.08333333333333333), 25: np.float64(0.4819277108433735), 26: np.float64(0.5517241379310345), 28: np.float64(0.0851063829787234), 29: np.float64(0.6448979591836734), 30: np.float64(0.48), 32: np.float64(0.35196687370600416), 33: np.float64(0.20689655172413793), 34: np.float64(0.1862348178137652), 35: np.float64(0.17757009345794392), 36: np.float64(0.2833333333333333), 37: np.float64(0.1864406779661017), 38: np.float64(0.22), 39: np.float64(0.08759124087591241)}
Micro-average F1 score: 0.26735338873931874
Weighted-average F1 score: 0.24910673290689916
F1 score per class: {0: np.float64(0.3516483516483517), 1: np.float64(0.1), 2: np.float64(0.11666666666666667), 3: np.float64(0.32894736842105265), 4: np.float64(0.8316831683168316), 5: np.float64(0.4801980198019802), 6: np.float64(0.2874015748031496), 8: np.float64(0.24539877300613497), 10: np.float64(0.24734982332155478), 11: np.float64(0.11868131868131868), 12: np.float64(0.12566560170394037), 13: np.float64(0.01639344262295082), 14: np.float64(0.03614457831325301), 15: np.float64(0.5), 16: np.float64(0.34234234234234234), 17: np.float64(0.0), 18: np.float64(0.05504587155963303), 19: np.float64(0.5637583892617449), 20: np.float64(0.25), 21: np.float64(0.11299435028248588), 22: np.float64(0.328), 23: np.float64(0.5151515151515151), 24: np.float64(0.08695652173913043), 25: np.float64(0.4810126582278481), 26: np.float64(0.5607476635514018), 28: np.float64(0.038834951456310676), 29: np.float64(0.6610878661087866), 30: np.float64(0.6792452830188679), 32: np.float64(0.3953488372093023), 33: np.float64(0.2727272727272727), 34: np.float64(0.18181818181818182), 35: np.float64(0.12987012987012986), 36: np.float64(0.1978021978021978), 37: np.float64(0.13636363636363635), 38: np.float64(0.205607476635514), 39: np.float64(0.07339449541284404)}
Micro-average F1 score: 0.2749773227938318
Weighted-average F1 score: 0.25395625211173506
cur_acc_wo_na:  ['0.7554', '0.5116', '0.4668', '0.3960', '0.4956', '0.7190', '0.3839']
his_acc_wo_na:  ['0.7554', '0.6904', '0.6185', '0.4736', '0.4352', '0.4696', '0.4270']
cur_acc des_wo_na:  ['0.7544', '0.6221', '0.5496', '0.3413', '0.4147', '0.5705', '0.3515']
his_acc des_wo_na:  ['0.7544', '0.6949', '0.6182', '0.4728', '0.4281', '0.4460', '0.4060']
cur_acc rrf_wo_na:  ['0.7715', '0.6165', '0.5628', '0.3782', '0.4529', '0.6060', '0.3797']
his_acc rrf_wo_na:  ['0.7715', '0.7038', '0.6305', '0.4710', '0.4364', '0.4470', '0.4128']
cur_acc_w_na:  ['0.6410', '0.4272', '0.3753', '0.2801', '0.3435', '0.5480', '0.2682']
his_acc_w_na:  ['0.6410', '0.5615', '0.5040', '0.3549', '0.3108', '0.3439', '0.2995']
cur_acc des_w_na:  ['0.6092', '0.4830', '0.3958', '0.2341', '0.2734', '0.4223', '0.2237']
his_acc des_w_na:  ['0.6092', '0.5250', '0.4668', '0.3407', '0.2883', '0.3076', '0.2674']
cur_acc rrf_w_na:  ['0.6256', '0.4847', '0.4134', '0.2616', '0.2999', '0.4499', '0.2457']
his_acc rrf_w_na:  ['0.6256', '0.5468', '0.4853', '0.3426', '0.2979', '0.3118', '0.2750']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 82.4900614CurrentTrain: epoch  0, batch     1 | loss: 99.3283472CurrentTrain: epoch  0, batch     2 | loss: 83.9429441CurrentTrain: epoch  0, batch     3 | loss: 26.2090433CurrentTrain: epoch  1, batch     0 | loss: 106.7290064CurrentTrain: epoch  1, batch     1 | loss: 74.5447121CurrentTrain: epoch  1, batch     2 | loss: 88.2573832CurrentTrain: epoch  1, batch     3 | loss: 14.1953079CurrentTrain: epoch  2, batch     0 | loss: 78.6410666CurrentTrain: epoch  2, batch     1 | loss: 70.1892293CurrentTrain: epoch  2, batch     2 | loss: 108.4438614CurrentTrain: epoch  2, batch     3 | loss: 6.1227924CurrentTrain: epoch  3, batch     0 | loss: 62.8199574CurrentTrain: epoch  3, batch     1 | loss: 96.6999696CurrentTrain: epoch  3, batch     2 | loss: 86.6342336CurrentTrain: epoch  3, batch     3 | loss: 18.1398577CurrentTrain: epoch  4, batch     0 | loss: 78.6866320CurrentTrain: epoch  4, batch     1 | loss: 68.9219109CurrentTrain: epoch  4, batch     2 | loss: 76.3599463CurrentTrain: epoch  4, batch     3 | loss: 16.7955860CurrentTrain: epoch  5, batch     0 | loss: 73.5147464CurrentTrain: epoch  5, batch     1 | loss: 80.3505921CurrentTrain: epoch  5, batch     2 | loss: 68.4075718CurrentTrain: epoch  5, batch     3 | loss: 7.5523765CurrentTrain: epoch  6, batch     0 | loss: 64.8159059CurrentTrain: epoch  6, batch     1 | loss: 78.8041915CurrentTrain: epoch  6, batch     2 | loss: 73.9094832CurrentTrain: epoch  6, batch     3 | loss: 12.0265209CurrentTrain: epoch  7, batch     0 | loss: 64.7743191CurrentTrain: epoch  7, batch     1 | loss: 61.9423003CurrentTrain: epoch  7, batch     2 | loss: 77.3795355CurrentTrain: epoch  7, batch     3 | loss: 9.2623488CurrentTrain: epoch  8, batch     0 | loss: 75.8180633CurrentTrain: epoch  8, batch     1 | loss: 63.3245048CurrentTrain: epoch  8, batch     2 | loss: 74.0178571CurrentTrain: epoch  8, batch     3 | loss: 4.0407024CurrentTrain: epoch  9, batch     0 | loss: 63.3264324CurrentTrain: epoch  9, batch     1 | loss: 72.9356499CurrentTrain: epoch  9, batch     2 | loss: 74.3209603CurrentTrain: epoch  9, batch     3 | loss: 9.3904360
MemoryTrain:  epoch  0, batch     0 | loss: 0.7957630MemoryTrain:  epoch  1, batch     0 | loss: 0.6951160MemoryTrain:  epoch  2, batch     0 | loss: 0.5045045MemoryTrain:  epoch  3, batch     0 | loss: 0.4170026MemoryTrain:  epoch  4, batch     0 | loss: 0.3574924MemoryTrain:  epoch  5, batch     0 | loss: 0.3045515MemoryTrain:  epoch  6, batch     0 | loss: 0.2972765MemoryTrain:  epoch  7, batch     0 | loss: 0.3000873MemoryTrain:  epoch  8, batch     0 | loss: 0.2285747MemoryTrain:  epoch  9, batch     0 | loss: 0.2371422

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 3: np.float64(0.0), 7: np.float64(0.6), 9: np.float64(0.819672131147541), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.24), 31: np.float64(0.2), 34: np.float64(0.0), 40: np.float64(0.3511450381679389)}
Micro-average F1 score: 0.3273809523809524
Weighted-average F1 score: 0.2625705495258743
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6), 9: np.float64(0.6578947368421053), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.38461538461538464), 30: np.float64(0.0), 31: np.float64(0.16666666666666666), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.49230769230769234)}
Micro-average F1 score: 0.35967302452316074
Weighted-average F1 score: 0.28887146415750536
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6), 9: np.float64(0.7692307692307693), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.38461538461538464), 30: np.float64(0.0), 31: np.float64(0.18181818181818182), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 40: np.float64(0.48120300751879697)}
Micro-average F1 score: 0.375
Weighted-average F1 score: 0.29796033245834214

F1 score per class: {0: np.float64(0.3364485981308411), 1: np.float64(0.15286624203821655), 2: np.float64(0.23333333333333334), 3: np.float64(0.4129032258064516), 4: np.float64(0.88268156424581), 5: np.float64(0.706766917293233), 6: np.float64(0.32679738562091504), 7: np.float64(0.037267080745341616), 8: np.float64(0.23157894736842105), 9: np.float64(0.78125), 10: np.float64(0.275), 11: np.float64(0.1519756838905775), 12: np.float64(0.34782608695652173), 13: np.float64(0.015503875968992248), 14: np.float64(0.03571428571428571), 15: np.float64(0.5714285714285714), 16: np.float64(0.53125), 17: np.float64(0.0), 18: np.float64(0.061855670103092786), 19: np.float64(0.549618320610687), 20: np.float64(0.5063291139240507), 21: np.float64(0.2037037037037037), 22: np.float64(0.5454545454545454), 23: np.float64(0.7115384615384616), 24: np.float64(0.0), 25: np.float64(0.4657534246575342), 26: np.float64(0.5605095541401274), 27: np.float64(0.09523809523809523), 28: np.float64(0.12631578947368421), 29: np.float64(0.7150837988826816), 30: np.float64(0.9142857142857143), 31: np.float64(0.08), 32: np.float64(0.6015625), 33: np.float64(0.375), 34: np.float64(0.23684210526315788), 35: np.float64(0.09090909090909091), 36: np.float64(0.058823529411764705), 37: np.float64(0.15151515151515152), 38: np.float64(0.2545454545454545), 39: np.float64(0.13636363636363635), 40: np.float64(0.12137203166226913)}
Micro-average F1 score: 0.3571830985915493
Weighted-average F1 score: 0.3289808268323068
F1 score per class: {0: np.float64(0.254416961130742), 1: np.float64(0.15853658536585366), 2: np.float64(0.17391304347826086), 3: np.float64(0.49193548387096775), 4: np.float64(0.8272251308900523), 5: np.float64(0.532608695652174), 6: np.float64(0.358695652173913), 7: np.float64(0.03314917127071823), 8: np.float64(0.38578680203045684), 9: np.float64(0.352112676056338), 10: np.float64(0.26136363636363635), 11: np.float64(0.1557377049180328), 12: np.float64(0.3018867924528302), 13: np.float64(0.019417475728155338), 14: np.float64(0.04878048780487805), 15: np.float64(0.6), 16: np.float64(0.5974025974025974), 17: np.float64(0.0), 18: np.float64(0.16091954022988506), 19: np.float64(0.5146579804560261), 20: np.float64(0.46296296296296297), 21: np.float64(0.18090452261306533), 22: np.float64(0.48484848484848486), 23: np.float64(0.6470588235294118), 24: np.float64(0.09523809523809523), 25: np.float64(0.6067415730337079), 26: np.float64(0.6243386243386243), 27: np.float64(0.13513513513513514), 28: np.float64(0.19230769230769232), 29: np.float64(0.7301587301587301), 30: np.float64(0.7555555555555555), 31: np.float64(0.044444444444444446), 32: np.float64(0.5144694533762058), 33: np.float64(0.3333333333333333), 34: np.float64(0.225), 35: np.float64(0.25688073394495414), 36: np.float64(0.3829787234042553), 37: np.float64(0.20408163265306123), 38: np.float64(0.3076923076923077), 39: np.float64(0.15384615384615385), 40: np.float64(0.22535211267605634)}
Micro-average F1 score: 0.3599806980858935
Weighted-average F1 score: 0.33519615315911094
F1 score per class: {0: np.float64(0.2571428571428571), 1: np.float64(0.1566265060240964), 2: np.float64(0.18666666666666668), 3: np.float64(0.5086206896551724), 4: np.float64(0.8743169398907104), 5: np.float64(0.6018808777429467), 6: np.float64(0.3699421965317919), 7: np.float64(0.03409090909090909), 8: np.float64(0.33093525179856115), 9: np.float64(0.6944444444444444), 10: np.float64(0.26285714285714284), 11: np.float64(0.15037593984962405), 12: np.float64(0.3076923076923077), 13: np.float64(0.018867924528301886), 14: np.float64(0.046153846153846156), 15: np.float64(0.6), 16: np.float64(0.6301369863013698), 17: np.float64(0.0), 18: np.float64(0.13924050632911392), 19: np.float64(0.5473684210526316), 20: np.float64(0.5111111111111111), 21: np.float64(0.18181818181818182), 22: np.float64(0.49746192893401014), 23: np.float64(0.6534653465346535), 24: np.float64(0.1), 25: np.float64(0.5783132530120482), 26: np.float64(0.6373626373626373), 27: np.float64(0.13157894736842105), 28: np.float64(0.13333333333333333), 29: np.float64(0.7351351351351352), 30: np.float64(0.8717948717948718), 31: np.float64(0.06060606060606061), 32: np.float64(0.5435540069686411), 33: np.float64(0.35294117647058826), 34: np.float64(0.2231404958677686), 35: np.float64(0.21978021978021978), 36: np.float64(0.24691358024691357), 37: np.float64(0.18181818181818182), 38: np.float64(0.24324324324324326), 39: np.float64(0.1111111111111111), 40: np.float64(0.20317460317460317)}
Micro-average F1 score: 0.3631730932563275
Weighted-average F1 score: 0.3339011494510132

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5), 9: np.float64(0.7575757575757576), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.21428571428571427), 31: np.float64(0.16666666666666666), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 40: np.float64(0.3108108108108108)}
Micro-average F1 score: 0.248868778280543
Weighted-average F1 score: 0.19374648642941325
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5), 9: np.float64(0.5434782608695652), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.35714285714285715), 28: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.125), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.42953020134228187)}
Micro-average F1 score: 0.2634730538922156
Weighted-average F1 score: 0.2099965229541576
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5), 9: np.float64(0.684931506849315), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.3448275862068966), 28: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.13333333333333333), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 40: np.float64(0.4155844155844156)}
Micro-average F1 score: 0.27789473684210525
Weighted-average F1 score: 0.21795738303274578

F1 score per class: {0: np.float64(0.22429906542056074), 1: np.float64(0.07692307692307693), 2: np.float64(0.12844036697247707), 3: np.float64(0.3121951219512195), 4: np.float64(0.8315789473684211), 5: np.float64(0.46078431372549017), 6: np.float64(0.20161290322580644), 7: np.float64(0.021660649819494584), 8: np.float64(0.205607476635514), 9: np.float64(0.6944444444444444), 10: np.float64(0.21153846153846154), 11: np.float64(0.099601593625498), 12: np.float64(0.14432989690721648), 13: np.float64(0.00851063829787234), 14: np.float64(0.031007751937984496), 15: np.float64(0.5), 16: np.float64(0.34), 17: np.float64(0.0), 18: np.float64(0.04225352112676056), 19: np.float64(0.51985559566787), 20: np.float64(0.28776978417266186), 21: np.float64(0.12021857923497267), 22: np.float64(0.46956521739130436), 23: np.float64(0.5606060606060606), 24: np.float64(0.0), 25: np.float64(0.4358974358974359), 26: np.float64(0.5), 27: np.float64(0.06896551724137931), 28: np.float64(0.06976744186046512), 29: np.float64(0.624390243902439), 30: np.float64(0.8421052631578947), 31: np.float64(0.0392156862745098), 32: np.float64(0.4502923976608187), 33: np.float64(0.3333333333333333), 34: np.float64(0.14634146341463414), 35: np.float64(0.07407407407407407), 36: np.float64(0.05714285714285714), 37: np.float64(0.14285714285714285), 38: np.float64(0.14736842105263157), 39: np.float64(0.08333333333333333), 40: np.float64(0.08502772643253234)}
Micro-average F1 score: 0.2428188433550364
Weighted-average F1 score: 0.21627185624790607
F1 score per class: {0: np.float64(0.16666666666666666), 1: np.float64(0.07951070336391437), 2: np.float64(0.09876543209876543), 3: np.float64(0.32707774798927614), 4: np.float64(0.7783251231527094), 5: np.float64(0.30963665086887837), 6: np.float64(0.23404255319148937), 7: np.float64(0.01675977653631285), 8: np.float64(0.2846441947565543), 9: np.float64(0.25252525252525254), 10: np.float64(0.19246861924686193), 11: np.float64(0.11550151975683891), 12: np.float64(0.13578500707213578), 13: np.float64(0.010362694300518135), 14: np.float64(0.04316546762589928), 15: np.float64(0.48), 16: np.float64(0.36507936507936506), 17: np.float64(0.0), 18: np.float64(0.09523809523809523), 19: np.float64(0.4553314121037464), 20: np.float64(0.24390243902439024), 21: np.float64(0.11842105263157894), 22: np.float64(0.3983402489626556), 23: np.float64(0.49624060150375937), 24: np.float64(0.08695652173913043), 25: np.float64(0.5294117647058824), 26: np.float64(0.5339366515837104), 27: np.float64(0.08695652173913043), 28: np.float64(0.078125), 29: np.float64(0.6160714285714286), 30: np.float64(0.6666666666666666), 31: np.float64(0.022222222222222223), 32: np.float64(0.3686635944700461), 33: np.float64(0.25), 34: np.float64(0.1409921671018277), 35: np.float64(0.18421052631578946), 36: np.float64(0.2926829268292683), 37: np.float64(0.17391304347826086), 38: np.float64(0.17518248175182483), 39: np.float64(0.08403361344537816), 40: np.float64(0.1588089330024814)}
Micro-average F1 score: 0.2378826530612245
Weighted-average F1 score: 0.21770977495791033
F1 score per class: {0: np.float64(0.1702127659574468), 1: np.float64(0.07761194029850746), 2: np.float64(0.10071942446043165), 3: np.float64(0.3575757575757576), 4: np.float64(0.8247422680412371), 5: np.float64(0.3615819209039548), 6: np.float64(0.24806201550387597), 7: np.float64(0.017241379310344827), 8: np.float64(0.2787878787878788), 9: np.float64(0.5952380952380952), 10: np.float64(0.1908713692946058), 11: np.float64(0.10101010101010101), 12: np.float64(0.13464235624123422), 13: np.float64(0.010101010101010102), 14: np.float64(0.039735099337748346), 15: np.float64(0.48), 16: np.float64(0.3770491803278688), 17: np.float64(0.0), 18: np.float64(0.0873015873015873), 19: np.float64(0.5016077170418006), 20: np.float64(0.27218934911242604), 21: np.float64(0.11764705882352941), 22: np.float64(0.4100418410041841), 23: np.float64(0.4888888888888889), 24: np.float64(0.09090909090909091), 25: np.float64(0.5274725274725275), 26: np.float64(0.5631067961165048), 27: np.float64(0.09174311926605505), 28: np.float64(0.06282722513089005), 29: np.float64(0.6210045662100456), 30: np.float64(0.7906976744186046), 31: np.float64(0.03125), 32: np.float64(0.3939393939393939), 33: np.float64(0.2608695652173913), 34: np.float64(0.13953488372093023), 35: np.float64(0.16393442622950818), 36: np.float64(0.20408163265306123), 37: np.float64(0.16666666666666666), 38: np.float64(0.140625), 39: np.float64(0.06521739130434782), 40: np.float64(0.14349775784753363)}
Micro-average F1 score: 0.24243111463884795
Weighted-average F1 score: 0.21801690639271254
cur_acc_wo_na:  ['0.7554', '0.5116', '0.4668', '0.3960', '0.4956', '0.7190', '0.3839', '0.3274']
his_acc_wo_na:  ['0.7554', '0.6904', '0.6185', '0.4736', '0.4352', '0.4696', '0.4270', '0.3572']
cur_acc des_wo_na:  ['0.7544', '0.6221', '0.5496', '0.3413', '0.4147', '0.5705', '0.3515', '0.3597']
his_acc des_wo_na:  ['0.7544', '0.6949', '0.6182', '0.4728', '0.4281', '0.4460', '0.4060', '0.3600']
cur_acc rrf_wo_na:  ['0.7715', '0.6165', '0.5628', '0.3782', '0.4529', '0.6060', '0.3797', '0.3750']
his_acc rrf_wo_na:  ['0.7715', '0.7038', '0.6305', '0.4710', '0.4364', '0.4470', '0.4128', '0.3632']
cur_acc_w_na:  ['0.6410', '0.4272', '0.3753', '0.2801', '0.3435', '0.5480', '0.2682', '0.2489']
his_acc_w_na:  ['0.6410', '0.5615', '0.5040', '0.3549', '0.3108', '0.3439', '0.2995', '0.2428']
cur_acc des_w_na:  ['0.6092', '0.4830', '0.3958', '0.2341', '0.2734', '0.4223', '0.2237', '0.2635']
his_acc des_w_na:  ['0.6092', '0.5250', '0.4668', '0.3407', '0.2883', '0.3076', '0.2674', '0.2379']
cur_acc rrf_w_na:  ['0.6256', '0.4847', '0.4134', '0.2616', '0.2999', '0.4499', '0.2457', '0.2779']
his_acc rrf_w_na:  ['0.6256', '0.5468', '0.4853', '0.3426', '0.2979', '0.3118', '0.2750', '0.2424']
--------Round  5
seed:  600
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 2 0 1 6 3 4 5]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 107.7399305CurrentTrain: epoch  0, batch     1 | loss: 80.3521851CurrentTrain: epoch  0, batch     2 | loss: 120.6657427CurrentTrain: epoch  0, batch     3 | loss: 87.8241885CurrentTrain: epoch  0, batch     4 | loss: 88.2358685CurrentTrain: epoch  0, batch     5 | loss: 119.4870369CurrentTrain: epoch  0, batch     6 | loss: 101.8900403CurrentTrain: epoch  0, batch     7 | loss: 100.0227523CurrentTrain: epoch  0, batch     8 | loss: 87.0959973CurrentTrain: epoch  0, batch     9 | loss: 100.0186048CurrentTrain: epoch  0, batch    10 | loss: 100.8094918CurrentTrain: epoch  0, batch    11 | loss: 118.6382577CurrentTrain: epoch  0, batch    12 | loss: 85.9250197CurrentTrain: epoch  0, batch    13 | loss: 85.8721943CurrentTrain: epoch  0, batch    14 | loss: 99.6701368CurrentTrain: epoch  0, batch    15 | loss: 86.5548363CurrentTrain: epoch  0, batch    16 | loss: 99.0838293CurrentTrain: epoch  0, batch    17 | loss: 100.1568036CurrentTrain: epoch  0, batch    18 | loss: 99.0885641CurrentTrain: epoch  0, batch    19 | loss: 86.5140872CurrentTrain: epoch  0, batch    20 | loss: 145.7076317CurrentTrain: epoch  0, batch    21 | loss: 118.2789423CurrentTrain: epoch  0, batch    22 | loss: 117.8829607CurrentTrain: epoch  0, batch    23 | loss: 117.7564403CurrentTrain: epoch  0, batch    24 | loss: 75.8552457CurrentTrain: epoch  0, batch    25 | loss: 99.2940818CurrentTrain: epoch  0, batch    26 | loss: 192.1647922CurrentTrain: epoch  0, batch    27 | loss: 98.5118017CurrentTrain: epoch  0, batch    28 | loss: 191.3899518CurrentTrain: epoch  0, batch    29 | loss: 146.0405277CurrentTrain: epoch  0, batch    30 | loss: 117.6497264CurrentTrain: epoch  0, batch    31 | loss: 84.5627753CurrentTrain: epoch  0, batch    32 | loss: 116.4176695CurrentTrain: epoch  0, batch    33 | loss: 117.5680892CurrentTrain: epoch  0, batch    34 | loss: 117.1437643CurrentTrain: epoch  0, batch    35 | loss: 145.9902626CurrentTrain: epoch  0, batch    36 | loss: 96.3530027CurrentTrain: epoch  0, batch    37 | loss: 96.7827315CurrentTrain: epoch  0, batch    38 | loss: 82.4411970CurrentTrain: epoch  0, batch    39 | loss: 98.5105697CurrentTrain: epoch  0, batch    40 | loss: 85.1999159CurrentTrain: epoch  0, batch    41 | loss: 84.6710375CurrentTrain: epoch  0, batch    42 | loss: 83.8284292CurrentTrain: epoch  0, batch    43 | loss: 115.4694087CurrentTrain: epoch  0, batch    44 | loss: 96.7710797CurrentTrain: epoch  0, batch    45 | loss: 96.4200165CurrentTrain: epoch  0, batch    46 | loss: 94.5189011CurrentTrain: epoch  0, batch    47 | loss: 93.6190574CurrentTrain: epoch  0, batch    48 | loss: 82.4217379CurrentTrain: epoch  0, batch    49 | loss: 117.4278264CurrentTrain: epoch  0, batch    50 | loss: 95.9953319CurrentTrain: epoch  0, batch    51 | loss: 83.3414474CurrentTrain: epoch  0, batch    52 | loss: 81.3582294CurrentTrain: epoch  0, batch    53 | loss: 97.3713800CurrentTrain: epoch  0, batch    54 | loss: 95.3674124CurrentTrain: epoch  0, batch    55 | loss: 80.7408844CurrentTrain: epoch  0, batch    56 | loss: 112.2505890CurrentTrain: epoch  0, batch    57 | loss: 140.8134050CurrentTrain: epoch  0, batch    58 | loss: 93.7424954CurrentTrain: epoch  0, batch    59 | loss: 95.5566191CurrentTrain: epoch  0, batch    60 | loss: 142.8132290CurrentTrain: epoch  0, batch    61 | loss: 93.9287278CurrentTrain: epoch  0, batch    62 | loss: 94.4328866CurrentTrain: epoch  0, batch    63 | loss: 94.5264143CurrentTrain: epoch  0, batch    64 | loss: 80.4066224CurrentTrain: epoch  0, batch    65 | loss: 81.2292151CurrentTrain: epoch  0, batch    66 | loss: 92.8414918CurrentTrain: epoch  0, batch    67 | loss: 79.3789326CurrentTrain: epoch  0, batch    68 | loss: 93.7796223CurrentTrain: epoch  0, batch    69 | loss: 77.0579135CurrentTrain: epoch  0, batch    70 | loss: 112.9060439CurrentTrain: epoch  0, batch    71 | loss: 81.1330879CurrentTrain: epoch  0, batch    72 | loss: 91.2970369CurrentTrain: epoch  0, batch    73 | loss: 92.4245242CurrentTrain: epoch  0, batch    74 | loss: 78.9623620CurrentTrain: epoch  0, batch    75 | loss: 77.3993016CurrentTrain: epoch  0, batch    76 | loss: 95.8485036CurrentTrain: epoch  0, batch    77 | loss: 91.9610585CurrentTrain: epoch  0, batch    78 | loss: 140.4747957CurrentTrain: epoch  0, batch    79 | loss: 77.5472433CurrentTrain: epoch  0, batch    80 | loss: 78.7798972CurrentTrain: epoch  0, batch    81 | loss: 112.3363999CurrentTrain: epoch  0, batch    82 | loss: 111.8831277CurrentTrain: epoch  0, batch    83 | loss: 107.2146111CurrentTrain: epoch  0, batch    84 | loss: 95.1205187CurrentTrain: epoch  0, batch    85 | loss: 128.5221174CurrentTrain: epoch  0, batch    86 | loss: 95.6911951CurrentTrain: epoch  0, batch    87 | loss: 92.7426194CurrentTrain: epoch  0, batch    88 | loss: 91.5714424CurrentTrain: epoch  0, batch    89 | loss: 111.9106833CurrentTrain: epoch  0, batch    90 | loss: 78.6799393CurrentTrain: epoch  0, batch    91 | loss: 109.6217122CurrentTrain: epoch  0, batch    92 | loss: 91.4363546CurrentTrain: epoch  0, batch    93 | loss: 91.5562197CurrentTrain: epoch  0, batch    94 | loss: 113.6627444CurrentTrain: epoch  0, batch    95 | loss: 87.9685941CurrentTrain: epoch  1, batch     0 | loss: 88.6119987CurrentTrain: epoch  1, batch     1 | loss: 92.2422160CurrentTrain: epoch  1, batch     2 | loss: 78.6126953CurrentTrain: epoch  1, batch     3 | loss: 110.1551907CurrentTrain: epoch  1, batch     4 | loss: 91.8703241CurrentTrain: epoch  1, batch     5 | loss: 111.1027079CurrentTrain: epoch  1, batch     6 | loss: 68.7262605CurrentTrain: epoch  1, batch     7 | loss: 88.2298779CurrentTrain: epoch  1, batch     8 | loss: 87.7168722CurrentTrain: epoch  1, batch     9 | loss: 92.3083880CurrentTrain: epoch  1, batch    10 | loss: 89.2949333CurrentTrain: epoch  1, batch    11 | loss: 91.2682563CurrentTrain: epoch  1, batch    12 | loss: 87.5008553CurrentTrain: epoch  1, batch    13 | loss: 90.8302427CurrentTrain: epoch  1, batch    14 | loss: 108.5526499CurrentTrain: epoch  1, batch    15 | loss: 77.1058028CurrentTrain: epoch  1, batch    16 | loss: 67.3735470CurrentTrain: epoch  1, batch    17 | loss: 67.9352669CurrentTrain: epoch  1, batch    18 | loss: 104.7390381CurrentTrain: epoch  1, batch    19 | loss: 89.1915733CurrentTrain: epoch  1, batch    20 | loss: 93.2581224CurrentTrain: epoch  1, batch    21 | loss: 78.7324449CurrentTrain: epoch  1, batch    22 | loss: 79.0328086CurrentTrain: epoch  1, batch    23 | loss: 87.6894862CurrentTrain: epoch  1, batch    24 | loss: 107.4245620CurrentTrain: epoch  1, batch    25 | loss: 89.4756629CurrentTrain: epoch  1, batch    26 | loss: 76.6576754CurrentTrain: epoch  1, batch    27 | loss: 90.8257330CurrentTrain: epoch  1, batch    28 | loss: 104.5459631CurrentTrain: epoch  1, batch    29 | loss: 111.2373999CurrentTrain: epoch  1, batch    30 | loss: 90.9480172CurrentTrain: epoch  1, batch    31 | loss: 75.1853895CurrentTrain: epoch  1, batch    32 | loss: 109.9228636CurrentTrain: epoch  1, batch    33 | loss: 137.3276059CurrentTrain: epoch  1, batch    34 | loss: 86.6663542CurrentTrain: epoch  1, batch    35 | loss: 88.4926089CurrentTrain: epoch  1, batch    36 | loss: 75.7619499CurrentTrain: epoch  1, batch    37 | loss: 63.4268021CurrentTrain: epoch  1, batch    38 | loss: 89.2537186CurrentTrain: epoch  1, batch    39 | loss: 104.4672631CurrentTrain: epoch  1, batch    40 | loss: 85.2625466CurrentTrain: epoch  1, batch    41 | loss: 72.7622715CurrentTrain: epoch  1, batch    42 | loss: 89.5505622CurrentTrain: epoch  1, batch    43 | loss: 73.4497475CurrentTrain: epoch  1, batch    44 | loss: 84.0849438CurrentTrain: epoch  1, batch    45 | loss: 88.2980239CurrentTrain: epoch  1, batch    46 | loss: 106.6245812CurrentTrain: epoch  1, batch    47 | loss: 134.4494927CurrentTrain: epoch  1, batch    48 | loss: 85.3972570CurrentTrain: epoch  1, batch    49 | loss: 140.8548246CurrentTrain: epoch  1, batch    50 | loss: 109.5266677CurrentTrain: epoch  1, batch    51 | loss: 72.9440344CurrentTrain: epoch  1, batch    52 | loss: 134.0987092CurrentTrain: epoch  1, batch    53 | loss: 64.9199697CurrentTrain: epoch  1, batch    54 | loss: 90.5870409CurrentTrain: epoch  1, batch    55 | loss: 89.2516197CurrentTrain: epoch  1, batch    56 | loss: 183.6867003CurrentTrain: epoch  1, batch    57 | loss: 62.8238606CurrentTrain: epoch  1, batch    58 | loss: 177.9456719CurrentTrain: epoch  1, batch    59 | loss: 109.9232387CurrentTrain: epoch  1, batch    60 | loss: 71.6604381CurrentTrain: epoch  1, batch    61 | loss: 89.9620104CurrentTrain: epoch  1, batch    62 | loss: 87.6297264CurrentTrain: epoch  1, batch    63 | loss: 75.0422544CurrentTrain: epoch  1, batch    64 | loss: 102.3336583CurrentTrain: epoch  1, batch    65 | loss: 87.9732871CurrentTrain: epoch  1, batch    66 | loss: 89.5789775CurrentTrain: epoch  1, batch    67 | loss: 89.5091818CurrentTrain: epoch  1, batch    68 | loss: 107.5698643CurrentTrain: epoch  1, batch    69 | loss: 90.0807227CurrentTrain: epoch  1, batch    70 | loss: 89.4967353CurrentTrain: epoch  1, batch    71 | loss: 73.2165428CurrentTrain: epoch  1, batch    72 | loss: 122.3229553CurrentTrain: epoch  1, batch    73 | loss: 60.3355769CurrentTrain: epoch  1, batch    74 | loss: 103.5177913CurrentTrain: epoch  1, batch    75 | loss: 76.9684243CurrentTrain: epoch  1, batch    76 | loss: 141.8368601CurrentTrain: epoch  1, batch    77 | loss: 88.0164643CurrentTrain: epoch  1, batch    78 | loss: 88.6902054CurrentTrain: epoch  1, batch    79 | loss: 91.4284647CurrentTrain: epoch  1, batch    80 | loss: 92.8524682CurrentTrain: epoch  1, batch    81 | loss: 92.8351182CurrentTrain: epoch  1, batch    82 | loss: 106.3382992CurrentTrain: epoch  1, batch    83 | loss: 94.3481427CurrentTrain: epoch  1, batch    84 | loss: 105.4383248CurrentTrain: epoch  1, batch    85 | loss: 107.6184879CurrentTrain: epoch  1, batch    86 | loss: 84.5816221CurrentTrain: epoch  1, batch    87 | loss: 83.5904313CurrentTrain: epoch  1, batch    88 | loss: 66.6310051CurrentTrain: epoch  1, batch    89 | loss: 109.3712546CurrentTrain: epoch  1, batch    90 | loss: 73.3811485CurrentTrain: epoch  1, batch    91 | loss: 134.1000380CurrentTrain: epoch  1, batch    92 | loss: 74.6707155CurrentTrain: epoch  1, batch    93 | loss: 107.4136671CurrentTrain: epoch  1, batch    94 | loss: 88.4708469CurrentTrain: epoch  1, batch    95 | loss: 150.5361668CurrentTrain: epoch  2, batch     0 | loss: 75.9562066CurrentTrain: epoch  2, batch     1 | loss: 85.6210973CurrentTrain: epoch  2, batch     2 | loss: 84.4113731CurrentTrain: epoch  2, batch     3 | loss: 104.8498609CurrentTrain: epoch  2, batch     4 | loss: 91.0022940CurrentTrain: epoch  2, batch     5 | loss: 66.6140342CurrentTrain: epoch  2, batch     6 | loss: 64.0537431CurrentTrain: epoch  2, batch     7 | loss: 73.3611940CurrentTrain: epoch  2, batch     8 | loss: 104.9755062CurrentTrain: epoch  2, batch     9 | loss: 136.3138863CurrentTrain: epoch  2, batch    10 | loss: 74.6422788CurrentTrain: epoch  2, batch    11 | loss: 181.5115847CurrentTrain: epoch  2, batch    12 | loss: 107.5380897CurrentTrain: epoch  2, batch    13 | loss: 66.8303565CurrentTrain: epoch  2, batch    14 | loss: 131.1410743CurrentTrain: epoch  2, batch    15 | loss: 83.5859240CurrentTrain: epoch  2, batch    16 | loss: 84.5734892CurrentTrain: epoch  2, batch    17 | loss: 82.2586858CurrentTrain: epoch  2, batch    18 | loss: 72.0376825CurrentTrain: epoch  2, batch    19 | loss: 101.1758818CurrentTrain: epoch  2, batch    20 | loss: 73.7868031CurrentTrain: epoch  2, batch    21 | loss: 107.0018681CurrentTrain: epoch  2, batch    22 | loss: 63.7298638CurrentTrain: epoch  2, batch    23 | loss: 73.8599383CurrentTrain: epoch  2, batch    24 | loss: 72.0213860CurrentTrain: epoch  2, batch    25 | loss: 130.5191572CurrentTrain: epoch  2, batch    26 | loss: 110.2728701CurrentTrain: epoch  2, batch    27 | loss: 133.9383031CurrentTrain: epoch  2, batch    28 | loss: 88.1414818CurrentTrain: epoch  2, batch    29 | loss: 106.3137231CurrentTrain: epoch  2, batch    30 | loss: 90.1290890CurrentTrain: epoch  2, batch    31 | loss: 103.5654991CurrentTrain: epoch  2, batch    32 | loss: 86.0274347CurrentTrain: epoch  2, batch    33 | loss: 70.5493143CurrentTrain: epoch  2, batch    34 | loss: 89.7477413CurrentTrain: epoch  2, batch    35 | loss: 88.3641983CurrentTrain: epoch  2, batch    36 | loss: 69.7442566CurrentTrain: epoch  2, batch    37 | loss: 102.7046579CurrentTrain: epoch  2, batch    38 | loss: 84.2365393CurrentTrain: epoch  2, batch    39 | loss: 75.4144311CurrentTrain: epoch  2, batch    40 | loss: 89.1967465CurrentTrain: epoch  2, batch    41 | loss: 75.1774140CurrentTrain: epoch  2, batch    42 | loss: 102.7186482CurrentTrain: epoch  2, batch    43 | loss: 129.1156000CurrentTrain: epoch  2, batch    44 | loss: 72.8869877CurrentTrain: epoch  2, batch    45 | loss: 83.8792043CurrentTrain: epoch  2, batch    46 | loss: 63.9436733CurrentTrain: epoch  2, batch    47 | loss: 100.9314243CurrentTrain: epoch  2, batch    48 | loss: 86.7955402CurrentTrain: epoch  2, batch    49 | loss: 87.4756155CurrentTrain: epoch  2, batch    50 | loss: 86.6338423CurrentTrain: epoch  2, batch    51 | loss: 106.8566890CurrentTrain: epoch  2, batch    52 | loss: 74.8131616CurrentTrain: epoch  2, batch    53 | loss: 129.5122720CurrentTrain: epoch  2, batch    54 | loss: 61.1409039CurrentTrain: epoch  2, batch    55 | loss: 70.6132125CurrentTrain: epoch  2, batch    56 | loss: 100.4563878CurrentTrain: epoch  2, batch    57 | loss: 86.3179693CurrentTrain: epoch  2, batch    58 | loss: 108.5831304CurrentTrain: epoch  2, batch    59 | loss: 75.1050363CurrentTrain: epoch  2, batch    60 | loss: 133.2760051CurrentTrain: epoch  2, batch    61 | loss: 82.7437264CurrentTrain: epoch  2, batch    62 | loss: 83.5785137CurrentTrain: epoch  2, batch    63 | loss: 71.8268071CurrentTrain: epoch  2, batch    64 | loss: 71.6438616CurrentTrain: epoch  2, batch    65 | loss: 83.7742664CurrentTrain: epoch  2, batch    66 | loss: 73.2888687CurrentTrain: epoch  2, batch    67 | loss: 81.9553287CurrentTrain: epoch  2, batch    68 | loss: 86.8056333CurrentTrain: epoch  2, batch    69 | loss: 103.7106992CurrentTrain: epoch  2, batch    70 | loss: 104.1153118CurrentTrain: epoch  2, batch    71 | loss: 65.6301081CurrentTrain: epoch  2, batch    72 | loss: 72.7440601CurrentTrain: epoch  2, batch    73 | loss: 82.7662471CurrentTrain: epoch  2, batch    74 | loss: 86.0856604CurrentTrain: epoch  2, batch    75 | loss: 74.5143726CurrentTrain: epoch  2, batch    76 | loss: 88.7894138CurrentTrain: epoch  2, batch    77 | loss: 127.7440456CurrentTrain: epoch  2, batch    78 | loss: 101.0477844CurrentTrain: epoch  2, batch    79 | loss: 103.5703698CurrentTrain: epoch  2, batch    80 | loss: 63.1249990CurrentTrain: epoch  2, batch    81 | loss: 88.4632145CurrentTrain: epoch  2, batch    82 | loss: 66.2926948CurrentTrain: epoch  2, batch    83 | loss: 83.3882556CurrentTrain: epoch  2, batch    84 | loss: 74.9567008CurrentTrain: epoch  2, batch    85 | loss: 95.2191025CurrentTrain: epoch  2, batch    86 | loss: 103.4199496CurrentTrain: epoch  2, batch    87 | loss: 102.0968346CurrentTrain: epoch  2, batch    88 | loss: 134.3483009CurrentTrain: epoch  2, batch    89 | loss: 73.6161790CurrentTrain: epoch  2, batch    90 | loss: 89.1737327CurrentTrain: epoch  2, batch    91 | loss: 83.7826483CurrentTrain: epoch  2, batch    92 | loss: 85.0972566CurrentTrain: epoch  2, batch    93 | loss: 87.3924426CurrentTrain: epoch  2, batch    94 | loss: 72.3740099CurrentTrain: epoch  2, batch    95 | loss: 86.5233530CurrentTrain: epoch  3, batch     0 | loss: 82.1930296CurrentTrain: epoch  3, batch     1 | loss: 85.1211439CurrentTrain: epoch  3, batch     2 | loss: 98.2511768CurrentTrain: epoch  3, batch     3 | loss: 87.1592574CurrentTrain: epoch  3, batch     4 | loss: 108.4615819CurrentTrain: epoch  3, batch     5 | loss: 61.1906724CurrentTrain: epoch  3, batch     6 | loss: 70.4355010CurrentTrain: epoch  3, batch     7 | loss: 71.5651634CurrentTrain: epoch  3, batch     8 | loss: 126.0873708CurrentTrain: epoch  3, batch     9 | loss: 101.4175669CurrentTrain: epoch  3, batch    10 | loss: 106.5402777CurrentTrain: epoch  3, batch    11 | loss: 103.9413850CurrentTrain: epoch  3, batch    12 | loss: 72.2010796CurrentTrain: epoch  3, batch    13 | loss: 101.7464319CurrentTrain: epoch  3, batch    14 | loss: 102.0236238CurrentTrain: epoch  3, batch    15 | loss: 68.2927541CurrentTrain: epoch  3, batch    16 | loss: 79.1131839CurrentTrain: epoch  3, batch    17 | loss: 81.8276827CurrentTrain: epoch  3, batch    18 | loss: 100.3119077CurrentTrain: epoch  3, batch    19 | loss: 103.3601285CurrentTrain: epoch  3, batch    20 | loss: 73.8788795CurrentTrain: epoch  3, batch    21 | loss: 65.2493896CurrentTrain: epoch  3, batch    22 | loss: 66.4260015CurrentTrain: epoch  3, batch    23 | loss: 124.8585301CurrentTrain: epoch  3, batch    24 | loss: 86.6479444CurrentTrain: epoch  3, batch    25 | loss: 74.0008666CurrentTrain: epoch  3, batch    26 | loss: 103.2122003CurrentTrain: epoch  3, batch    27 | loss: 103.8916517CurrentTrain: epoch  3, batch    28 | loss: 60.0141887CurrentTrain: epoch  3, batch    29 | loss: 69.0015917CurrentTrain: epoch  3, batch    30 | loss: 86.0797701CurrentTrain: epoch  3, batch    31 | loss: 98.3342042CurrentTrain: epoch  3, batch    32 | loss: 101.3529011CurrentTrain: epoch  3, batch    33 | loss: 69.3660540CurrentTrain: epoch  3, batch    34 | loss: 85.0878937CurrentTrain: epoch  3, batch    35 | loss: 56.7285456CurrentTrain: epoch  3, batch    36 | loss: 69.7745844CurrentTrain: epoch  3, batch    37 | loss: 136.3455143CurrentTrain: epoch  3, batch    38 | loss: 81.6804501CurrentTrain: epoch  3, batch    39 | loss: 74.4608064CurrentTrain: epoch  3, batch    40 | loss: 87.3214310CurrentTrain: epoch  3, batch    41 | loss: 86.2417137CurrentTrain: epoch  3, batch    42 | loss: 62.8551401CurrentTrain: epoch  3, batch    43 | loss: 87.9712562CurrentTrain: epoch  3, batch    44 | loss: 97.3297226CurrentTrain: epoch  3, batch    45 | loss: 103.2463767CurrentTrain: epoch  3, batch    46 | loss: 100.3684301CurrentTrain: epoch  3, batch    47 | loss: 61.0131991CurrentTrain: epoch  3, batch    48 | loss: 73.8468507CurrentTrain: epoch  3, batch    49 | loss: 73.2232358CurrentTrain: epoch  3, batch    50 | loss: 68.3585629CurrentTrain: epoch  3, batch    51 | loss: 98.7926603CurrentTrain: epoch  3, batch    52 | loss: 70.6155839CurrentTrain: epoch  3, batch    53 | loss: 86.2205124CurrentTrain: epoch  3, batch    54 | loss: 81.8443640CurrentTrain: epoch  3, batch    55 | loss: 102.4390850CurrentTrain: epoch  3, batch    56 | loss: 84.2727092CurrentTrain: epoch  3, batch    57 | loss: 132.8900419CurrentTrain: epoch  3, batch    58 | loss: 130.7593396CurrentTrain: epoch  3, batch    59 | loss: 129.0255597CurrentTrain: epoch  3, batch    60 | loss: 82.4419742CurrentTrain: epoch  3, batch    61 | loss: 81.1283899CurrentTrain: epoch  3, batch    62 | loss: 101.8260553CurrentTrain: epoch  3, batch    63 | loss: 133.1228499CurrentTrain: epoch  3, batch    64 | loss: 61.5749660CurrentTrain: epoch  3, batch    65 | loss: 73.3388482CurrentTrain: epoch  3, batch    66 | loss: 128.1170735CurrentTrain: epoch  3, batch    67 | loss: 87.2166508CurrentTrain: epoch  3, batch    68 | loss: 58.0017377CurrentTrain: epoch  3, batch    69 | loss: 103.5260688CurrentTrain: epoch  3, batch    70 | loss: 87.2580456CurrentTrain: epoch  3, batch    71 | loss: 69.5541089CurrentTrain: epoch  3, batch    72 | loss: 71.9350071CurrentTrain: epoch  3, batch    73 | loss: 83.8107451CurrentTrain: epoch  3, batch    74 | loss: 88.5634433CurrentTrain: epoch  3, batch    75 | loss: 71.5509789CurrentTrain: epoch  3, batch    76 | loss: 73.3955553CurrentTrain: epoch  3, batch    77 | loss: 71.7578811CurrentTrain: epoch  3, batch    78 | loss: 70.9072144CurrentTrain: epoch  3, batch    79 | loss: 109.3578890CurrentTrain: epoch  3, batch    80 | loss: 86.8892304CurrentTrain: epoch  3, batch    81 | loss: 79.5238061CurrentTrain: epoch  3, batch    82 | loss: 106.5757524CurrentTrain: epoch  3, batch    83 | loss: 102.3453089CurrentTrain: epoch  3, batch    84 | loss: 103.4912598CurrentTrain: epoch  3, batch    85 | loss: 104.7837689CurrentTrain: epoch  3, batch    86 | loss: 99.3521854CurrentTrain: epoch  3, batch    87 | loss: 104.7255758CurrentTrain: epoch  3, batch    88 | loss: 99.7102399CurrentTrain: epoch  3, batch    89 | loss: 60.1803908CurrentTrain: epoch  3, batch    90 | loss: 136.2979860CurrentTrain: epoch  3, batch    91 | loss: 102.6200241CurrentTrain: epoch  3, batch    92 | loss: 88.1535323CurrentTrain: epoch  3, batch    93 | loss: 83.8514395CurrentTrain: epoch  3, batch    94 | loss: 88.3978248CurrentTrain: epoch  3, batch    95 | loss: 70.4965478CurrentTrain: epoch  4, batch     0 | loss: 81.5972883CurrentTrain: epoch  4, batch     1 | loss: 70.3755689CurrentTrain: epoch  4, batch     2 | loss: 69.9727348CurrentTrain: epoch  4, batch     3 | loss: 128.5274451CurrentTrain: epoch  4, batch     4 | loss: 61.1821128CurrentTrain: epoch  4, batch     5 | loss: 73.6110376CurrentTrain: epoch  4, batch     6 | loss: 82.2957942CurrentTrain: epoch  4, batch     7 | loss: 83.9893698CurrentTrain: epoch  4, batch     8 | loss: 125.2496158CurrentTrain: epoch  4, batch     9 | loss: 69.8417021CurrentTrain: epoch  4, batch    10 | loss: 171.1941238CurrentTrain: epoch  4, batch    11 | loss: 127.9524766CurrentTrain: epoch  4, batch    12 | loss: 99.6229357CurrentTrain: epoch  4, batch    13 | loss: 103.1433200CurrentTrain: epoch  4, batch    14 | loss: 83.8623628CurrentTrain: epoch  4, batch    15 | loss: 65.4876147CurrentTrain: epoch  4, batch    16 | loss: 100.4653519CurrentTrain: epoch  4, batch    17 | loss: 70.2724064CurrentTrain: epoch  4, batch    18 | loss: 84.8056870CurrentTrain: epoch  4, batch    19 | loss: 67.3377488CurrentTrain: epoch  4, batch    20 | loss: 84.6009858CurrentTrain: epoch  4, batch    21 | loss: 80.8096223CurrentTrain: epoch  4, batch    22 | loss: 70.7950514CurrentTrain: epoch  4, batch    23 | loss: 100.6629688CurrentTrain: epoch  4, batch    24 | loss: 82.2333522CurrentTrain: epoch  4, batch    25 | loss: 99.3635908CurrentTrain: epoch  4, batch    26 | loss: 103.8308693CurrentTrain: epoch  4, batch    27 | loss: 67.8705600CurrentTrain: epoch  4, batch    28 | loss: 79.9861390CurrentTrain: epoch  4, batch    29 | loss: 100.2729792CurrentTrain: epoch  4, batch    30 | loss: 84.2919358CurrentTrain: epoch  4, batch    31 | loss: 81.1193550CurrentTrain: epoch  4, batch    32 | loss: 82.2897808CurrentTrain: epoch  4, batch    33 | loss: 99.1928580CurrentTrain: epoch  4, batch    34 | loss: 69.2664259CurrentTrain: epoch  4, batch    35 | loss: 132.1669251CurrentTrain: epoch  4, batch    36 | loss: 125.0176146CurrentTrain: epoch  4, batch    37 | loss: 106.0443382CurrentTrain: epoch  4, batch    38 | loss: 84.0872652CurrentTrain: epoch  4, batch    39 | loss: 103.5964613CurrentTrain: epoch  4, batch    40 | loss: 71.8668172CurrentTrain: epoch  4, batch    41 | loss: 69.7674263CurrentTrain: epoch  4, batch    42 | loss: 71.1688989CurrentTrain: epoch  4, batch    43 | loss: 84.6504955CurrentTrain: epoch  4, batch    44 | loss: 85.8086407CurrentTrain: epoch  4, batch    45 | loss: 58.4872683CurrentTrain: epoch  4, batch    46 | loss: 126.6549068CurrentTrain: epoch  4, batch    47 | loss: 81.7546965CurrentTrain: epoch  4, batch    48 | loss: 99.1308522CurrentTrain: epoch  4, batch    49 | loss: 81.7120546CurrentTrain: epoch  4, batch    50 | loss: 84.7521349CurrentTrain: epoch  4, batch    51 | loss: 101.7523225CurrentTrain: epoch  4, batch    52 | loss: 68.6767995CurrentTrain: epoch  4, batch    53 | loss: 84.9492760CurrentTrain: epoch  4, batch    54 | loss: 57.4630926CurrentTrain: epoch  4, batch    55 | loss: 63.8238872CurrentTrain: epoch  4, batch    56 | loss: 128.7486476CurrentTrain: epoch  4, batch    57 | loss: 95.6779711CurrentTrain: epoch  4, batch    58 | loss: 57.2483595CurrentTrain: epoch  4, batch    59 | loss: 73.8719299CurrentTrain: epoch  4, batch    60 | loss: 102.3507193CurrentTrain: epoch  4, batch    61 | loss: 70.0710776CurrentTrain: epoch  4, batch    62 | loss: 84.7379748CurrentTrain: epoch  4, batch    63 | loss: 98.7070845CurrentTrain: epoch  4, batch    64 | loss: 102.3043776CurrentTrain: epoch  4, batch    65 | loss: 97.6762286CurrentTrain: epoch  4, batch    66 | loss: 82.0373914CurrentTrain: epoch  4, batch    67 | loss: 80.5313933CurrentTrain: epoch  4, batch    68 | loss: 85.7269637CurrentTrain: epoch  4, batch    69 | loss: 88.1114498CurrentTrain: epoch  4, batch    70 | loss: 81.0495620CurrentTrain: epoch  4, batch    71 | loss: 70.3524220CurrentTrain: epoch  4, batch    72 | loss: 84.2601537CurrentTrain: epoch  4, batch    73 | loss: 70.0038577CurrentTrain: epoch  4, batch    74 | loss: 83.6751970CurrentTrain: epoch  4, batch    75 | loss: 61.3569551CurrentTrain: epoch  4, batch    76 | loss: 81.7921493CurrentTrain: epoch  4, batch    77 | loss: 103.5004138CurrentTrain: epoch  4, batch    78 | loss: 69.1612569CurrentTrain: epoch  4, batch    79 | loss: 99.4165159CurrentTrain: epoch  4, batch    80 | loss: 83.7908800CurrentTrain: epoch  4, batch    81 | loss: 88.0146839CurrentTrain: epoch  4, batch    82 | loss: 102.1147539CurrentTrain: epoch  4, batch    83 | loss: 81.0151662CurrentTrain: epoch  4, batch    84 | loss: 80.5779975CurrentTrain: epoch  4, batch    85 | loss: 70.5197613CurrentTrain: epoch  4, batch    86 | loss: 167.0648293CurrentTrain: epoch  4, batch    87 | loss: 73.3805034CurrentTrain: epoch  4, batch    88 | loss: 130.8063865CurrentTrain: epoch  4, batch    89 | loss: 71.3367432CurrentTrain: epoch  4, batch    90 | loss: 78.3672106CurrentTrain: epoch  4, batch    91 | loss: 70.2417214CurrentTrain: epoch  4, batch    92 | loss: 79.5930033CurrentTrain: epoch  4, batch    93 | loss: 135.1071589CurrentTrain: epoch  4, batch    94 | loss: 68.7073242CurrentTrain: epoch  4, batch    95 | loss: 69.6413913CurrentTrain: epoch  5, batch     0 | loss: 101.6329086CurrentTrain: epoch  5, batch     1 | loss: 60.6338391CurrentTrain: epoch  5, batch     2 | loss: 67.5811995CurrentTrain: epoch  5, batch     3 | loss: 83.1819067CurrentTrain: epoch  5, batch     4 | loss: 69.3732799CurrentTrain: epoch  5, batch     5 | loss: 103.2836448CurrentTrain: epoch  5, batch     6 | loss: 82.3264003CurrentTrain: epoch  5, batch     7 | loss: 79.1931591CurrentTrain: epoch  5, batch     8 | loss: 58.9870378CurrentTrain: epoch  5, batch     9 | loss: 96.7840075CurrentTrain: epoch  5, batch    10 | loss: 82.8476027CurrentTrain: epoch  5, batch    11 | loss: 101.9776519CurrentTrain: epoch  5, batch    12 | loss: 97.8901779CurrentTrain: epoch  5, batch    13 | loss: 83.2775693CurrentTrain: epoch  5, batch    14 | loss: 68.6057785CurrentTrain: epoch  5, batch    15 | loss: 104.2068602CurrentTrain: epoch  5, batch    16 | loss: 81.8513409CurrentTrain: epoch  5, batch    17 | loss: 80.1384274CurrentTrain: epoch  5, batch    18 | loss: 165.1439637CurrentTrain: epoch  5, batch    19 | loss: 79.4969336CurrentTrain: epoch  5, batch    20 | loss: 83.5891246CurrentTrain: epoch  5, batch    21 | loss: 97.3131448CurrentTrain: epoch  5, batch    22 | loss: 82.5240117CurrentTrain: epoch  5, batch    23 | loss: 78.1647372CurrentTrain: epoch  5, batch    24 | loss: 59.0244675CurrentTrain: epoch  5, batch    25 | loss: 100.2346926CurrentTrain: epoch  5, batch    26 | loss: 86.2619995CurrentTrain: epoch  5, batch    27 | loss: 60.3135494CurrentTrain: epoch  5, batch    28 | loss: 65.4026326CurrentTrain: epoch  5, batch    29 | loss: 99.6078587CurrentTrain: epoch  5, batch    30 | loss: 78.9862125CurrentTrain: epoch  5, batch    31 | loss: 66.4033976CurrentTrain: epoch  5, batch    32 | loss: 96.2068155CurrentTrain: epoch  5, batch    33 | loss: 85.0221192CurrentTrain: epoch  5, batch    34 | loss: 69.9590063CurrentTrain: epoch  5, batch    35 | loss: 63.2965841CurrentTrain: epoch  5, batch    36 | loss: 67.7562746CurrentTrain: epoch  5, batch    37 | loss: 83.5917104CurrentTrain: epoch  5, batch    38 | loss: 62.7664261CurrentTrain: epoch  5, batch    39 | loss: 67.0682362CurrentTrain: epoch  5, batch    40 | loss: 68.2399806CurrentTrain: epoch  5, batch    41 | loss: 80.4332403CurrentTrain: epoch  5, batch    42 | loss: 102.6893110CurrentTrain: epoch  5, batch    43 | loss: 102.7265398CurrentTrain: epoch  5, batch    44 | loss: 122.6481040CurrentTrain: epoch  5, batch    45 | loss: 71.2667560CurrentTrain: epoch  5, batch    46 | loss: 97.5652359CurrentTrain: epoch  5, batch    47 | loss: 59.4978070CurrentTrain: epoch  5, batch    48 | loss: 85.4023415CurrentTrain: epoch  5, batch    49 | loss: 100.8313698CurrentTrain: epoch  5, batch    50 | loss: 81.2772773CurrentTrain: epoch  5, batch    51 | loss: 68.7451367CurrentTrain: epoch  5, batch    52 | loss: 99.8333605CurrentTrain: epoch  5, batch    53 | loss: 63.8402848CurrentTrain: epoch  5, batch    54 | loss: 128.3295174CurrentTrain: epoch  5, batch    55 | loss: 97.5484260CurrentTrain: epoch  5, batch    56 | loss: 71.1402227CurrentTrain: epoch  5, batch    57 | loss: 84.2715827CurrentTrain: epoch  5, batch    58 | loss: 98.3518467CurrentTrain: epoch  5, batch    59 | loss: 71.6527031CurrentTrain: epoch  5, batch    60 | loss: 84.3373710CurrentTrain: epoch  5, batch    61 | loss: 80.4222370CurrentTrain: epoch  5, batch    62 | loss: 69.6491638CurrentTrain: epoch  5, batch    63 | loss: 98.6537768CurrentTrain: epoch  5, batch    64 | loss: 80.3946645CurrentTrain: epoch  5, batch    65 | loss: 82.0165779CurrentTrain: epoch  5, batch    66 | loss: 65.1223815CurrentTrain: epoch  5, batch    67 | loss: 93.9357277CurrentTrain: epoch  5, batch    68 | loss: 99.2727718CurrentTrain: epoch  5, batch    69 | loss: 62.2385643CurrentTrain: epoch  5, batch    70 | loss: 100.7164547CurrentTrain: epoch  5, batch    71 | loss: 58.4685985CurrentTrain: epoch  5, batch    72 | loss: 84.5934239CurrentTrain: epoch  5, batch    73 | loss: 56.1103576CurrentTrain: epoch  5, batch    74 | loss: 82.1003088CurrentTrain: epoch  5, batch    75 | loss: 65.1252710CurrentTrain: epoch  5, batch    76 | loss: 125.7188881CurrentTrain: epoch  5, batch    77 | loss: 82.4885651CurrentTrain: epoch  5, batch    78 | loss: 104.3076761CurrentTrain: epoch  5, batch    79 | loss: 81.5166495CurrentTrain: epoch  5, batch    80 | loss: 100.4651929CurrentTrain: epoch  5, batch    81 | loss: 100.9943863CurrentTrain: epoch  5, batch    82 | loss: 86.2837720CurrentTrain: epoch  5, batch    83 | loss: 171.7178762CurrentTrain: epoch  5, batch    84 | loss: 59.8774551CurrentTrain: epoch  5, batch    85 | loss: 66.4152989CurrentTrain: epoch  5, batch    86 | loss: 178.1640929CurrentTrain: epoch  5, batch    87 | loss: 86.0920875CurrentTrain: epoch  5, batch    88 | loss: 121.9369546CurrentTrain: epoch  5, batch    89 | loss: 66.5122587CurrentTrain: epoch  5, batch    90 | loss: 72.8127742CurrentTrain: epoch  5, batch    91 | loss: 128.5691896CurrentTrain: epoch  5, batch    92 | loss: 67.1455865CurrentTrain: epoch  5, batch    93 | loss: 100.7137744CurrentTrain: epoch  5, batch    94 | loss: 95.7724273CurrentTrain: epoch  5, batch    95 | loss: 109.9003736CurrentTrain: epoch  6, batch     0 | loss: 70.0546999CurrentTrain: epoch  6, batch     1 | loss: 99.2547270CurrentTrain: epoch  6, batch     2 | loss: 78.0020059CurrentTrain: epoch  6, batch     3 | loss: 69.8433715CurrentTrain: epoch  6, batch     4 | loss: 80.7000032CurrentTrain: epoch  6, batch     5 | loss: 96.2613535CurrentTrain: epoch  6, batch     6 | loss: 99.4706871CurrentTrain: epoch  6, batch     7 | loss: 122.6650381CurrentTrain: epoch  6, batch     8 | loss: 65.3685641CurrentTrain: epoch  6, batch     9 | loss: 53.0012957CurrentTrain: epoch  6, batch    10 | loss: 93.8298932CurrentTrain: epoch  6, batch    11 | loss: 80.3915076CurrentTrain: epoch  6, batch    12 | loss: 95.7530138CurrentTrain: epoch  6, batch    13 | loss: 96.3527155CurrentTrain: epoch  6, batch    14 | loss: 57.4955337CurrentTrain: epoch  6, batch    15 | loss: 80.2696258CurrentTrain: epoch  6, batch    16 | loss: 56.4715308CurrentTrain: epoch  6, batch    17 | loss: 68.5086039CurrentTrain: epoch  6, batch    18 | loss: 95.6746435CurrentTrain: epoch  6, batch    19 | loss: 78.4858143CurrentTrain: epoch  6, batch    20 | loss: 57.4245047CurrentTrain: epoch  6, batch    21 | loss: 75.4074280CurrentTrain: epoch  6, batch    22 | loss: 80.6288764CurrentTrain: epoch  6, batch    23 | loss: 98.1687785CurrentTrain: epoch  6, batch    24 | loss: 97.7383217CurrentTrain: epoch  6, batch    25 | loss: 95.6076416CurrentTrain: epoch  6, batch    26 | loss: 77.4463590CurrentTrain: epoch  6, batch    27 | loss: 95.7468787CurrentTrain: epoch  6, batch    28 | loss: 80.9171003CurrentTrain: epoch  6, batch    29 | loss: 68.4649783CurrentTrain: epoch  6, batch    30 | loss: 99.6150154CurrentTrain: epoch  6, batch    31 | loss: 71.2975601CurrentTrain: epoch  6, batch    32 | loss: 58.0803382CurrentTrain: epoch  6, batch    33 | loss: 63.9998126CurrentTrain: epoch  6, batch    34 | loss: 96.8583550CurrentTrain: epoch  6, batch    35 | loss: 65.4406342CurrentTrain: epoch  6, batch    36 | loss: 85.1685904CurrentTrain: epoch  6, batch    37 | loss: 59.5220678CurrentTrain: epoch  6, batch    38 | loss: 98.0023706CurrentTrain: epoch  6, batch    39 | loss: 81.8462655CurrentTrain: epoch  6, batch    40 | loss: 81.5276067CurrentTrain: epoch  6, batch    41 | loss: 130.7620894CurrentTrain: epoch  6, batch    42 | loss: 122.5849773CurrentTrain: epoch  6, batch    43 | loss: 61.2509734CurrentTrain: epoch  6, batch    44 | loss: 84.5966031CurrentTrain: epoch  6, batch    45 | loss: 98.6550744CurrentTrain: epoch  6, batch    46 | loss: 78.7299231CurrentTrain: epoch  6, batch    47 | loss: 100.8181141CurrentTrain: epoch  6, batch    48 | loss: 83.7350656CurrentTrain: epoch  6, batch    49 | loss: 95.7336970CurrentTrain: epoch  6, batch    50 | loss: 125.2159798CurrentTrain: epoch  6, batch    51 | loss: 78.7224423CurrentTrain: epoch  6, batch    52 | loss: 104.4766407CurrentTrain: epoch  6, batch    53 | loss: 97.9388619CurrentTrain: epoch  6, batch    54 | loss: 100.0105762CurrentTrain: epoch  6, batch    55 | loss: 97.6178714CurrentTrain: epoch  6, batch    56 | loss: 100.9475263CurrentTrain: epoch  6, batch    57 | loss: 166.8349485CurrentTrain: epoch  6, batch    58 | loss: 79.7305175CurrentTrain: epoch  6, batch    59 | loss: 71.7429880CurrentTrain: epoch  6, batch    60 | loss: 122.4743011CurrentTrain: epoch  6, batch    61 | loss: 80.0396952CurrentTrain: epoch  6, batch    62 | loss: 97.8948201CurrentTrain: epoch  6, batch    63 | loss: 69.0113139CurrentTrain: epoch  6, batch    64 | loss: 78.0625556CurrentTrain: epoch  6, batch    65 | loss: 70.1797527CurrentTrain: epoch  6, batch    66 | loss: 67.5411608CurrentTrain: epoch  6, batch    67 | loss: 69.8736545CurrentTrain: epoch  6, batch    68 | loss: 82.1528539CurrentTrain: epoch  6, batch    69 | loss: 76.3297734CurrentTrain: epoch  6, batch    70 | loss: 67.7639859CurrentTrain: epoch  6, batch    71 | loss: 63.1299329CurrentTrain: epoch  6, batch    72 | loss: 107.0808593CurrentTrain: epoch  6, batch    73 | loss: 101.3958595CurrentTrain: epoch  6, batch    74 | loss: 58.9111428CurrentTrain: epoch  6, batch    75 | loss: 96.7368157CurrentTrain: epoch  6, batch    76 | loss: 79.6409313CurrentTrain: epoch  6, batch    77 | loss: 76.3245543CurrentTrain: epoch  6, batch    78 | loss: 76.8859040CurrentTrain: epoch  6, batch    79 | loss: 69.9306235CurrentTrain: epoch  6, batch    80 | loss: 80.6656901CurrentTrain: epoch  6, batch    81 | loss: 98.0529450CurrentTrain: epoch  6, batch    82 | loss: 98.9276657CurrentTrain: epoch  6, batch    83 | loss: 54.3808998CurrentTrain: epoch  6, batch    84 | loss: 68.8107085CurrentTrain: epoch  6, batch    85 | loss: 96.7266293CurrentTrain: epoch  6, batch    86 | loss: 64.9286552CurrentTrain: epoch  6, batch    87 | loss: 66.8182702CurrentTrain: epoch  6, batch    88 | loss: 81.5326257CurrentTrain: epoch  6, batch    89 | loss: 77.9359943CurrentTrain: epoch  6, batch    90 | loss: 96.5211528CurrentTrain: epoch  6, batch    91 | loss: 80.2686883CurrentTrain: epoch  6, batch    92 | loss: 67.2071240CurrentTrain: epoch  6, batch    93 | loss: 100.0121056CurrentTrain: epoch  6, batch    94 | loss: 97.7221149CurrentTrain: epoch  6, batch    95 | loss: 81.7251323CurrentTrain: epoch  7, batch     0 | loss: 78.3834076CurrentTrain: epoch  7, batch     1 | loss: 67.0501180CurrentTrain: epoch  7, batch     2 | loss: 123.9657049CurrentTrain: epoch  7, batch     3 | loss: 82.0899322CurrentTrain: epoch  7, batch     4 | loss: 81.7035113CurrentTrain: epoch  7, batch     5 | loss: 76.3869215CurrentTrain: epoch  7, batch     6 | loss: 75.5822182CurrentTrain: epoch  7, batch     7 | loss: 65.6069437CurrentTrain: epoch  7, batch     8 | loss: 68.2822903CurrentTrain: epoch  7, batch     9 | loss: 77.8285258CurrentTrain: epoch  7, batch    10 | loss: 123.5728642CurrentTrain: epoch  7, batch    11 | loss: 83.3385624CurrentTrain: epoch  7, batch    12 | loss: 96.7750153CurrentTrain: epoch  7, batch    13 | loss: 96.9792792CurrentTrain: epoch  7, batch    14 | loss: 56.8173343CurrentTrain: epoch  7, batch    15 | loss: 68.3760999CurrentTrain: epoch  7, batch    16 | loss: 123.5942161CurrentTrain: epoch  7, batch    17 | loss: 82.2588043CurrentTrain: epoch  7, batch    18 | loss: 95.7771091CurrentTrain: epoch  7, batch    19 | loss: 76.1273967CurrentTrain: epoch  7, batch    20 | loss: 96.5059904CurrentTrain: epoch  7, batch    21 | loss: 75.8862515CurrentTrain: epoch  7, batch    22 | loss: 79.2506112CurrentTrain: epoch  7, batch    23 | loss: 80.9922589CurrentTrain: epoch  7, batch    24 | loss: 80.1274806CurrentTrain: epoch  7, batch    25 | loss: 65.3999664CurrentTrain: epoch  7, batch    26 | loss: 76.7587058CurrentTrain: epoch  7, batch    27 | loss: 79.6535033CurrentTrain: epoch  7, batch    28 | loss: 77.7438426CurrentTrain: epoch  7, batch    29 | loss: 58.4722160CurrentTrain: epoch  7, batch    30 | loss: 79.3952921CurrentTrain: epoch  7, batch    31 | loss: 123.9643538CurrentTrain: epoch  7, batch    32 | loss: 80.0177150CurrentTrain: epoch  7, batch    33 | loss: 101.4095833CurrentTrain: epoch  7, batch    34 | loss: 91.2466646CurrentTrain: epoch  7, batch    35 | loss: 95.7047856CurrentTrain: epoch  7, batch    36 | loss: 64.8963008CurrentTrain: epoch  7, batch    37 | loss: 78.8689367CurrentTrain: epoch  7, batch    38 | loss: 92.9639052CurrentTrain: epoch  7, batch    39 | loss: 81.5190616CurrentTrain: epoch  7, batch    40 | loss: 120.4657215CurrentTrain: epoch  7, batch    41 | loss: 100.5687704CurrentTrain: epoch  7, batch    42 | loss: 101.0625950CurrentTrain: epoch  7, batch    43 | loss: 81.4135160CurrentTrain: epoch  7, batch    44 | loss: 69.4898074CurrentTrain: epoch  7, batch    45 | loss: 75.3600997CurrentTrain: epoch  7, batch    46 | loss: 56.6727003CurrentTrain: epoch  7, batch    47 | loss: 69.8350898CurrentTrain: epoch  7, batch    48 | loss: 66.9449212CurrentTrain: epoch  7, batch    49 | loss: 68.0179842CurrentTrain: epoch  7, batch    50 | loss: 78.0159226CurrentTrain: epoch  7, batch    51 | loss: 96.5709971CurrentTrain: epoch  7, batch    52 | loss: 66.8543354CurrentTrain: epoch  7, batch    53 | loss: 76.1516214CurrentTrain: epoch  7, batch    54 | loss: 99.2583773CurrentTrain: epoch  7, batch    55 | loss: 66.0534715CurrentTrain: epoch  7, batch    56 | loss: 66.9810727CurrentTrain: epoch  7, batch    57 | loss: 64.6221966CurrentTrain: epoch  7, batch    58 | loss: 54.7834670CurrentTrain: epoch  7, batch    59 | loss: 127.5023085CurrentTrain: epoch  7, batch    60 | loss: 62.8948992CurrentTrain: epoch  7, batch    61 | loss: 69.0377950CurrentTrain: epoch  7, batch    62 | loss: 78.6426359CurrentTrain: epoch  7, batch    63 | loss: 120.6749883CurrentTrain: epoch  7, batch    64 | loss: 123.2861143CurrentTrain: epoch  7, batch    65 | loss: 100.0152780CurrentTrain: epoch  7, batch    66 | loss: 100.1720452CurrentTrain: epoch  7, batch    67 | loss: 64.5302858CurrentTrain: epoch  7, batch    68 | loss: 66.0808247CurrentTrain: epoch  7, batch    69 | loss: 97.3653628CurrentTrain: epoch  7, batch    70 | loss: 100.8448330CurrentTrain: epoch  7, batch    71 | loss: 78.8476116CurrentTrain: epoch  7, batch    72 | loss: 58.7306047CurrentTrain: epoch  7, batch    73 | loss: 79.6784350CurrentTrain: epoch  7, batch    74 | loss: 128.1644556CurrentTrain: epoch  7, batch    75 | loss: 94.6276754CurrentTrain: epoch  7, batch    76 | loss: 95.4759760CurrentTrain: epoch  7, batch    77 | loss: 128.9091228CurrentTrain: epoch  7, batch    78 | loss: 66.3673172CurrentTrain: epoch  7, batch    79 | loss: 123.4710478CurrentTrain: epoch  7, batch    80 | loss: 80.7311392CurrentTrain: epoch  7, batch    81 | loss: 66.0286123CurrentTrain: epoch  7, batch    82 | loss: 93.3996158CurrentTrain: epoch  7, batch    83 | loss: 67.4214104CurrentTrain: epoch  7, batch    84 | loss: 80.1203645CurrentTrain: epoch  7, batch    85 | loss: 67.7605528CurrentTrain: epoch  7, batch    86 | loss: 69.9254152CurrentTrain: epoch  7, batch    87 | loss: 99.9172174CurrentTrain: epoch  7, batch    88 | loss: 100.2689274CurrentTrain: epoch  7, batch    89 | loss: 75.5618670CurrentTrain: epoch  7, batch    90 | loss: 93.7980726CurrentTrain: epoch  7, batch    91 | loss: 75.6231780CurrentTrain: epoch  7, batch    92 | loss: 63.2276551CurrentTrain: epoch  7, batch    93 | loss: 127.9410794CurrentTrain: epoch  7, batch    94 | loss: 67.0215461CurrentTrain: epoch  7, batch    95 | loss: 79.6963526CurrentTrain: epoch  8, batch     0 | loss: 52.3220471CurrentTrain: epoch  8, batch     1 | loss: 125.8273053CurrentTrain: epoch  8, batch     2 | loss: 79.7895525CurrentTrain: epoch  8, batch     3 | loss: 91.3157950CurrentTrain: epoch  8, batch     4 | loss: 77.8052660CurrentTrain: epoch  8, batch     5 | loss: 65.2188847CurrentTrain: epoch  8, batch     6 | loss: 98.6962252CurrentTrain: epoch  8, batch     7 | loss: 78.2150659CurrentTrain: epoch  8, batch     8 | loss: 77.1258760CurrentTrain: epoch  8, batch     9 | loss: 118.7379061CurrentTrain: epoch  8, batch    10 | loss: 94.6033844CurrentTrain: epoch  8, batch    11 | loss: 97.1096236CurrentTrain: epoch  8, batch    12 | loss: 52.2164075CurrentTrain: epoch  8, batch    13 | loss: 57.1667050CurrentTrain: epoch  8, batch    14 | loss: 57.4860382CurrentTrain: epoch  8, batch    15 | loss: 79.2006156CurrentTrain: epoch  8, batch    16 | loss: 77.9347723CurrentTrain: epoch  8, batch    17 | loss: 61.9636268CurrentTrain: epoch  8, batch    18 | loss: 57.4902333CurrentTrain: epoch  8, batch    19 | loss: 67.9906479CurrentTrain: epoch  8, batch    20 | loss: 64.0187495CurrentTrain: epoch  8, batch    21 | loss: 79.8195583CurrentTrain: epoch  8, batch    22 | loss: 76.4822015CurrentTrain: epoch  8, batch    23 | loss: 55.3770135CurrentTrain: epoch  8, batch    24 | loss: 93.9888316CurrentTrain: epoch  8, batch    25 | loss: 100.6615361CurrentTrain: epoch  8, batch    26 | loss: 80.6536539CurrentTrain: epoch  8, batch    27 | loss: 92.4262096CurrentTrain: epoch  8, batch    28 | loss: 97.0875705CurrentTrain: epoch  8, batch    29 | loss: 94.9614158CurrentTrain: epoch  8, batch    30 | loss: 56.8050020CurrentTrain: epoch  8, batch    31 | loss: 68.0482619CurrentTrain: epoch  8, batch    32 | loss: 61.4173740CurrentTrain: epoch  8, batch    33 | loss: 67.8246550CurrentTrain: epoch  8, batch    34 | loss: 67.0669459CurrentTrain: epoch  8, batch    35 | loss: 68.3644504CurrentTrain: epoch  8, batch    36 | loss: 65.7300319CurrentTrain: epoch  8, batch    37 | loss: 56.9509229CurrentTrain: epoch  8, batch    38 | loss: 65.5571865CurrentTrain: epoch  8, batch    39 | loss: 94.6870051CurrentTrain: epoch  8, batch    40 | loss: 82.3463216CurrentTrain: epoch  8, batch    41 | loss: 79.1536909CurrentTrain: epoch  8, batch    42 | loss: 59.1323717CurrentTrain: epoch  8, batch    43 | loss: 67.7481358CurrentTrain: epoch  8, batch    44 | loss: 76.8615844CurrentTrain: epoch  8, batch    45 | loss: 68.1684939CurrentTrain: epoch  8, batch    46 | loss: 62.5168386CurrentTrain: epoch  8, batch    47 | loss: 90.6579474CurrentTrain: epoch  8, batch    48 | loss: 64.8083586CurrentTrain: epoch  8, batch    49 | loss: 96.3403004CurrentTrain: epoch  8, batch    50 | loss: 77.9239479CurrentTrain: epoch  8, batch    51 | loss: 68.5865305CurrentTrain: epoch  8, batch    52 | loss: 67.6041545CurrentTrain: epoch  8, batch    53 | loss: 72.6249120CurrentTrain: epoch  8, batch    54 | loss: 95.0140861CurrentTrain: epoch  8, batch    55 | loss: 78.6173147CurrentTrain: epoch  8, batch    56 | loss: 120.1722091CurrentTrain: epoch  8, batch    57 | loss: 126.1174264CurrentTrain: epoch  8, batch    58 | loss: 75.9043664CurrentTrain: epoch  8, batch    59 | loss: 65.0373407CurrentTrain: epoch  8, batch    60 | loss: 101.2960865CurrentTrain: epoch  8, batch    61 | loss: 98.9836204CurrentTrain: epoch  8, batch    62 | loss: 79.5893324CurrentTrain: epoch  8, batch    63 | loss: 95.1173078CurrentTrain: epoch  8, batch    64 | loss: 95.6137650CurrentTrain: epoch  8, batch    65 | loss: 75.8183185CurrentTrain: epoch  8, batch    66 | loss: 66.9952481CurrentTrain: epoch  8, batch    67 | loss: 79.8629077CurrentTrain: epoch  8, batch    68 | loss: 68.2122304CurrentTrain: epoch  8, batch    69 | loss: 78.2040061CurrentTrain: epoch  8, batch    70 | loss: 95.7244444CurrentTrain: epoch  8, batch    71 | loss: 68.9910172CurrentTrain: epoch  8, batch    72 | loss: 66.3710177CurrentTrain: epoch  8, batch    73 | loss: 126.4910421CurrentTrain: epoch  8, batch    74 | loss: 123.2665557CurrentTrain: epoch  8, batch    75 | loss: 95.5087692CurrentTrain: epoch  8, batch    76 | loss: 96.5266823CurrentTrain: epoch  8, batch    77 | loss: 119.8688830CurrentTrain: epoch  8, batch    78 | loss: 92.3525790CurrentTrain: epoch  8, batch    79 | loss: 72.1411297CurrentTrain: epoch  8, batch    80 | loss: 62.2383827CurrentTrain: epoch  8, batch    81 | loss: 99.3926435CurrentTrain: epoch  8, batch    82 | loss: 122.5679298CurrentTrain: epoch  8, batch    83 | loss: 95.5232987CurrentTrain: epoch  8, batch    84 | loss: 81.0320546CurrentTrain: epoch  8, batch    85 | loss: 125.4190517CurrentTrain: epoch  8, batch    86 | loss: 79.4385341CurrentTrain: epoch  8, batch    87 | loss: 66.3311869CurrentTrain: epoch  8, batch    88 | loss: 123.8368954CurrentTrain: epoch  8, batch    89 | loss: 69.6073516CurrentTrain: epoch  8, batch    90 | loss: 78.3741959CurrentTrain: epoch  8, batch    91 | loss: 65.9725155CurrentTrain: epoch  8, batch    92 | loss: 77.3255264CurrentTrain: epoch  8, batch    93 | loss: 63.3231808CurrentTrain: epoch  8, batch    94 | loss: 77.9486934CurrentTrain: epoch  8, batch    95 | loss: 81.9403332CurrentTrain: epoch  9, batch     0 | loss: 78.6694996CurrentTrain: epoch  9, batch     1 | loss: 67.8571670CurrentTrain: epoch  9, batch     2 | loss: 64.1253101CurrentTrain: epoch  9, batch     3 | loss: 80.7938892CurrentTrain: epoch  9, batch     4 | loss: 80.1986324CurrentTrain: epoch  9, batch     5 | loss: 94.3047890CurrentTrain: epoch  9, batch     6 | loss: 75.6004690CurrentTrain: epoch  9, batch     7 | loss: 55.4219052CurrentTrain: epoch  9, batch     8 | loss: 74.9041874CurrentTrain: epoch  9, batch     9 | loss: 96.6292400CurrentTrain: epoch  9, batch    10 | loss: 66.6717091CurrentTrain: epoch  9, batch    11 | loss: 54.7687418CurrentTrain: epoch  9, batch    12 | loss: 78.6898359CurrentTrain: epoch  9, batch    13 | loss: 92.3838253CurrentTrain: epoch  9, batch    14 | loss: 63.0898123CurrentTrain: epoch  9, batch    15 | loss: 93.3836581CurrentTrain: epoch  9, batch    16 | loss: 79.4105640CurrentTrain: epoch  9, batch    17 | loss: 73.6144849CurrentTrain: epoch  9, batch    18 | loss: 80.0198615CurrentTrain: epoch  9, batch    19 | loss: 76.5182827CurrentTrain: epoch  9, batch    20 | loss: 91.3319301CurrentTrain: epoch  9, batch    21 | loss: 65.3275376CurrentTrain: epoch  9, batch    22 | loss: 71.6563902CurrentTrain: epoch  9, batch    23 | loss: 79.8234836CurrentTrain: epoch  9, batch    24 | loss: 64.8020799CurrentTrain: epoch  9, batch    25 | loss: 99.3627555CurrentTrain: epoch  9, batch    26 | loss: 64.9218023CurrentTrain: epoch  9, batch    27 | loss: 75.9532558CurrentTrain: epoch  9, batch    28 | loss: 75.4489203CurrentTrain: epoch  9, batch    29 | loss: 73.4301487CurrentTrain: epoch  9, batch    30 | loss: 75.9255518CurrentTrain: epoch  9, batch    31 | loss: 72.0232630CurrentTrain: epoch  9, batch    32 | loss: 67.4916099CurrentTrain: epoch  9, batch    33 | loss: 76.7456914CurrentTrain: epoch  9, batch    34 | loss: 76.2338029CurrentTrain: epoch  9, batch    35 | loss: 77.4722703CurrentTrain: epoch  9, batch    36 | loss: 97.4306007CurrentTrain: epoch  9, batch    37 | loss: 170.5361761CurrentTrain: epoch  9, batch    38 | loss: 94.2623350CurrentTrain: epoch  9, batch    39 | loss: 78.3917579CurrentTrain: epoch  9, batch    40 | loss: 63.2774749CurrentTrain: epoch  9, batch    41 | loss: 79.8943939CurrentTrain: epoch  9, batch    42 | loss: 65.8112634CurrentTrain: epoch  9, batch    43 | loss: 78.9366314CurrentTrain: epoch  9, batch    44 | loss: 63.3393449CurrentTrain: epoch  9, batch    45 | loss: 94.6321178CurrentTrain: epoch  9, batch    46 | loss: 78.2677046CurrentTrain: epoch  9, batch    47 | loss: 64.0923528CurrentTrain: epoch  9, batch    48 | loss: 78.1595110CurrentTrain: epoch  9, batch    49 | loss: 69.1625866CurrentTrain: epoch  9, batch    50 | loss: 63.6319866CurrentTrain: epoch  9, batch    51 | loss: 77.7794268CurrentTrain: epoch  9, batch    52 | loss: 66.5320407CurrentTrain: epoch  9, batch    53 | loss: 126.3130280CurrentTrain: epoch  9, batch    54 | loss: 64.5007803CurrentTrain: epoch  9, batch    55 | loss: 121.1983174CurrentTrain: epoch  9, batch    56 | loss: 95.6858488CurrentTrain: epoch  9, batch    57 | loss: 77.3559131CurrentTrain: epoch  9, batch    58 | loss: 94.8798082CurrentTrain: epoch  9, batch    59 | loss: 91.0416593CurrentTrain: epoch  9, batch    60 | loss: 78.6778065CurrentTrain: epoch  9, batch    61 | loss: 84.6286389CurrentTrain: epoch  9, batch    62 | loss: 64.3866248CurrentTrain: epoch  9, batch    63 | loss: 75.0060084CurrentTrain: epoch  9, batch    64 | loss: 126.3258324CurrentTrain: epoch  9, batch    65 | loss: 95.1728495CurrentTrain: epoch  9, batch    66 | loss: 80.8380631CurrentTrain: epoch  9, batch    67 | loss: 93.6936469CurrentTrain: epoch  9, batch    68 | loss: 124.8739023CurrentTrain: epoch  9, batch    69 | loss: 95.1954766CurrentTrain: epoch  9, batch    70 | loss: 74.7695464CurrentTrain: epoch  9, batch    71 | loss: 69.3787286CurrentTrain: epoch  9, batch    72 | loss: 53.6362170CurrentTrain: epoch  9, batch    73 | loss: 66.6905233CurrentTrain: epoch  9, batch    74 | loss: 73.8957134CurrentTrain: epoch  9, batch    75 | loss: 80.9351601CurrentTrain: epoch  9, batch    76 | loss: 64.8490676CurrentTrain: epoch  9, batch    77 | loss: 121.4854345CurrentTrain: epoch  9, batch    78 | loss: 91.7108607CurrentTrain: epoch  9, batch    79 | loss: 53.0025923CurrentTrain: epoch  9, batch    80 | loss: 57.0420779CurrentTrain: epoch  9, batch    81 | loss: 58.3488266CurrentTrain: epoch  9, batch    82 | loss: 66.0562308CurrentTrain: epoch  9, batch    83 | loss: 64.4710226CurrentTrain: epoch  9, batch    84 | loss: 83.8284949CurrentTrain: epoch  9, batch    85 | loss: 70.3842039CurrentTrain: epoch  9, batch    86 | loss: 55.5185263CurrentTrain: epoch  9, batch    87 | loss: 76.8712629CurrentTrain: epoch  9, batch    88 | loss: 92.0967870CurrentTrain: epoch  9, batch    89 | loss: 65.2948443CurrentTrain: epoch  9, batch    90 | loss: 75.8474778CurrentTrain: epoch  9, batch    91 | loss: 66.8807110CurrentTrain: epoch  9, batch    92 | loss: 126.1238076CurrentTrain: epoch  9, batch    93 | loss: 78.6621348CurrentTrain: epoch  9, batch    94 | loss: 75.2204347CurrentTrain: epoch  9, batch    95 | loss: 102.1346575

F1 score per class: {32: np.float64(0.5951219512195122), 6: np.float64(0.797979797979798), 19: np.float64(0.35294117647058826), 24: np.float64(0.7570621468926554), 26: np.float64(0.9052631578947369), 29: np.float64(0.8656716417910447)}
Micro-average F1 score: 0.7681592039800995
Weighted-average F1 score: 0.7670168156997016
F1 score per class: {32: np.float64(0.64), 6: np.float64(0.7981220657276995), 19: np.float64(0.23529411764705882), 24: np.float64(0.7204301075268817), 26: np.float64(0.9238578680203046), 29: np.float64(0.8472906403940886)}
Micro-average F1 score: 0.7572093023255814
Weighted-average F1 score: 0.7482848073886095
F1 score per class: {32: np.float64(0.64), 6: np.float64(0.8097560975609757), 19: np.float64(0.2926829268292683), 24: np.float64(0.7282608695652174), 26: np.float64(0.9230769230769231), 29: np.float64(0.8472906403940886)}
Micro-average F1 score: 0.7673314339981007
Weighted-average F1 score: 0.7624172976772947

F1 score per class: {32: np.float64(0.5951219512195122), 6: np.float64(0.797979797979798), 19: np.float64(0.35294117647058826), 24: np.float64(0.7570621468926554), 26: np.float64(0.9052631578947369), 29: np.float64(0.8656716417910447)}
Micro-average F1 score: 0.7681592039800995
Weighted-average F1 score: 0.7670168156997016
F1 score per class: {32: np.float64(0.64), 6: np.float64(0.7981220657276995), 19: np.float64(0.23529411764705882), 24: np.float64(0.7204301075268817), 26: np.float64(0.9238578680203046), 29: np.float64(0.8472906403940886)}
Micro-average F1 score: 0.7572093023255814
Weighted-average F1 score: 0.7482848073886095
F1 score per class: {32: np.float64(0.64), 6: np.float64(0.8097560975609757), 19: np.float64(0.2926829268292683), 24: np.float64(0.7282608695652174), 26: np.float64(0.9230769230769231), 29: np.float64(0.8472906403940886)}
Micro-average F1 score: 0.7673314339981007
Weighted-average F1 score: 0.7624172976772947

F1 score per class: {32: np.float64(0.4295774647887324), 6: np.float64(0.7596153846153846), 19: np.float64(0.2222222222222222), 24: np.float64(0.708994708994709), 26: np.float64(0.8269230769230769), 29: np.float64(0.6987951807228916)}
Micro-average F1 score: 0.6476510067114094
Weighted-average F1 score: 0.6314679798153124
F1 score per class: {32: np.float64(0.4350453172205438), 6: np.float64(0.7522123893805309), 19: np.float64(0.14457831325301204), 24: np.float64(0.6568627450980392), 26: np.float64(0.8387096774193549), 29: np.float64(0.688)}
Micro-average F1 score: 0.6209000762776506
Weighted-average F1 score: 0.5981268315883971
F1 score per class: {32: np.float64(0.43636363636363634), 6: np.float64(0.7649769585253456), 19: np.float64(0.17391304347826086), 24: np.float64(0.67), 26: np.float64(0.8450704225352113), 29: np.float64(0.688)}
Micro-average F1 score: 0.6317435496481626
Weighted-average F1 score: 0.610287074211527

F1 score per class: {32: np.float64(0.4295774647887324), 6: np.float64(0.7596153846153846), 19: np.float64(0.2222222222222222), 24: np.float64(0.708994708994709), 26: np.float64(0.8269230769230769), 29: np.float64(0.6987951807228916)}
Micro-average F1 score: 0.6476510067114094
Weighted-average F1 score: 0.6314679798153124
F1 score per class: {32: np.float64(0.4350453172205438), 6: np.float64(0.7522123893805309), 19: np.float64(0.14457831325301204), 24: np.float64(0.6568627450980392), 26: np.float64(0.8387096774193549), 29: np.float64(0.688)}
Micro-average F1 score: 0.6209000762776506
Weighted-average F1 score: 0.5981268315883971
F1 score per class: {32: np.float64(0.43636363636363634), 6: np.float64(0.7649769585253456), 19: np.float64(0.17391304347826086), 24: np.float64(0.67), 26: np.float64(0.8450704225352113), 29: np.float64(0.688)}
Micro-average F1 score: 0.6317435496481626
Weighted-average F1 score: 0.610287074211527
cur_acc_wo_na:  ['0.7682']
his_acc_wo_na:  ['0.7682']
cur_acc des_wo_na:  ['0.7572']
his_acc des_wo_na:  ['0.7572']
cur_acc rrf_wo_na:  ['0.7673']
his_acc rrf_wo_na:  ['0.7673']
cur_acc_w_na:  ['0.6477']
his_acc_w_na:  ['0.6477']
cur_acc des_w_na:  ['0.6209']
his_acc des_w_na:  ['0.6209']
cur_acc rrf_w_na:  ['0.6317']
his_acc rrf_w_na:  ['0.6317']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 84.1510123CurrentTrain: epoch  0, batch     1 | loss: 155.2167140CurrentTrain: epoch  0, batch     2 | loss: 114.8795876CurrentTrain: epoch  0, batch     3 | loss: 90.2957644CurrentTrain: epoch  0, batch     4 | loss: 121.0017279CurrentTrain: epoch  1, batch     0 | loss: 90.5465890CurrentTrain: epoch  1, batch     1 | loss: 107.6468337CurrentTrain: epoch  1, batch     2 | loss: 77.8795841CurrentTrain: epoch  1, batch     3 | loss: 108.7700642CurrentTrain: epoch  1, batch     4 | loss: 60.4211868CurrentTrain: epoch  2, batch     0 | loss: 84.2943843CurrentTrain: epoch  2, batch     1 | loss: 128.4079541CurrentTrain: epoch  2, batch     2 | loss: 109.2502053CurrentTrain: epoch  2, batch     3 | loss: 90.1896115CurrentTrain: epoch  2, batch     4 | loss: 66.3446488CurrentTrain: epoch  3, batch     0 | loss: 105.1516941CurrentTrain: epoch  3, batch     1 | loss: 84.2160329CurrentTrain: epoch  3, batch     2 | loss: 103.8974198CurrentTrain: epoch  3, batch     3 | loss: 101.1661011CurrentTrain: epoch  3, batch     4 | loss: 82.3423825CurrentTrain: epoch  4, batch     0 | loss: 101.2640626CurrentTrain: epoch  4, batch     1 | loss: 70.1384557CurrentTrain: epoch  4, batch     2 | loss: 129.4026273CurrentTrain: epoch  4, batch     3 | loss: 68.7398697CurrentTrain: epoch  4, batch     4 | loss: 82.6947579CurrentTrain: epoch  5, batch     0 | loss: 68.6111224CurrentTrain: epoch  5, batch     1 | loss: 103.0479110CurrentTrain: epoch  5, batch     2 | loss: 101.2489330CurrentTrain: epoch  5, batch     3 | loss: 125.6695351CurrentTrain: epoch  5, batch     4 | loss: 59.2320828CurrentTrain: epoch  6, batch     0 | loss: 81.4307571CurrentTrain: epoch  6, batch     1 | loss: 68.9106222CurrentTrain: epoch  6, batch     2 | loss: 123.2270614CurrentTrain: epoch  6, batch     3 | loss: 80.6844819CurrentTrain: epoch  6, batch     4 | loss: 108.6843935CurrentTrain: epoch  7, batch     0 | loss: 99.1813827CurrentTrain: epoch  7, batch     1 | loss: 95.8938071CurrentTrain: epoch  7, batch     2 | loss: 125.8583118CurrentTrain: epoch  7, batch     3 | loss: 63.4544344CurrentTrain: epoch  7, batch     4 | loss: 74.3066531CurrentTrain: epoch  8, batch     0 | loss: 67.3871612CurrentTrain: epoch  8, batch     1 | loss: 96.7549743CurrentTrain: epoch  8, batch     2 | loss: 80.2027853CurrentTrain: epoch  8, batch     3 | loss: 81.0095844CurrentTrain: epoch  8, batch     4 | loss: 57.5097340CurrentTrain: epoch  9, batch     0 | loss: 80.3285123CurrentTrain: epoch  9, batch     1 | loss: 95.1982608CurrentTrain: epoch  9, batch     2 | loss: 75.2551651CurrentTrain: epoch  9, batch     3 | loss: 80.0422317CurrentTrain: epoch  9, batch     4 | loss: 58.7308658
MemoryTrain:  epoch  0, batch     0 | loss: 1.8099182MemoryTrain:  epoch  1, batch     0 | loss: 1.5683722MemoryTrain:  epoch  2, batch     0 | loss: 1.2672127MemoryTrain:  epoch  3, batch     0 | loss: 1.0316468MemoryTrain:  epoch  4, batch     0 | loss: 0.7854647MemoryTrain:  epoch  5, batch     0 | loss: 0.7386749MemoryTrain:  epoch  6, batch     0 | loss: 0.6136146MemoryTrain:  epoch  7, batch     0 | loss: 0.4362879MemoryTrain:  epoch  8, batch     0 | loss: 0.4524368MemoryTrain:  epoch  9, batch     0 | loss: 0.3191765

F1 score per class: {32: np.float64(0.8955223880597015), 5: np.float64(0.0), 6: np.float64(0.1651376146788991), 10: np.float64(0.6382978723404256), 16: np.float64(0.5), 17: np.float64(0.17391304347826086), 18: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5503355704697986
Weighted-average F1 score: 0.6423993037849797
F1 score per class: {32: np.float64(0.768595041322314), 5: np.float64(0.0), 6: np.float64(0.5285714285714286), 10: np.float64(0.6885245901639344), 16: np.float64(0.6363636363636364), 17: np.float64(0.5797101449275363), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.6278659611992945
Weighted-average F1 score: 0.613233907959162
F1 score per class: {32: np.float64(0.8122270742358079), 5: np.float64(0.0), 6: np.float64(0.5285714285714286), 10: np.float64(0.6885245901639344), 16: np.float64(0.5833333333333334), 17: np.float64(0.5483870967741935), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.6422018348623854
Weighted-average F1 score: 0.6309445703855509

F1 score per class: {32: np.float64(0.8955223880597015), 5: np.float64(0.6271186440677966), 6: np.float64(0.1651376146788991), 10: np.float64(0.625), 16: np.float64(0.2127659574468085), 17: np.float64(0.16666666666666666), 18: np.float64(0.8097560975609757), 19: np.float64(0.4117647058823529), 24: np.float64(0.7428571428571429), 26: np.float64(0.8979591836734694), 29: np.float64(0.8431372549019608)}
Micro-average F1 score: 0.6999334664005322
Weighted-average F1 score: 0.7328742488440552
F1 score per class: {32: np.float64(0.7294117647058823), 5: np.float64(0.5876777251184834), 6: np.float64(0.4900662251655629), 10: np.float64(0.5753424657534246), 16: np.float64(0.2413793103448276), 17: np.float64(0.49382716049382713), 18: np.float64(0.7705627705627706), 19: np.float64(0.3673469387755102), 24: np.float64(0.7252747252747253), 26: np.float64(0.9215686274509803), 29: np.float64(0.827906976744186)}
Micro-average F1 score: 0.6865497076023391
Weighted-average F1 score: 0.6816993241220567
F1 score per class: {32: np.float64(0.768595041322314), 5: np.float64(0.6046511627906976), 6: np.float64(0.4868421052631579), 10: np.float64(0.6176470588235294), 16: np.float64(0.24561403508771928), 17: np.float64(0.4857142857142857), 18: np.float64(0.7945205479452054), 19: np.float64(0.4186046511627907), 24: np.float64(0.7415730337078652), 26: np.float64(0.9207920792079208), 29: np.float64(0.8262910798122066)}
Micro-average F1 score: 0.702833031946956
Weighted-average F1 score: 0.6999158897366579

F1 score per class: {32: np.float64(0.7758620689655172), 5: np.float64(0.0), 6: np.float64(0.16216216216216217), 10: np.float64(0.46153846153846156), 16: np.float64(0.3333333333333333), 17: np.float64(0.13114754098360656), 18: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.42782608695652175
Weighted-average F1 score: 0.43645138469794237
F1 score per class: {32: np.float64(0.5849056603773585), 5: np.float64(0.0), 6: np.float64(0.4567901234567901), 10: np.float64(0.45161290322580644), 16: np.float64(0.3684210526315789), 17: np.float64(0.3389830508474576), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.4346764346764347
Weighted-average F1 score: 0.409620390727018
F1 score per class: {32: np.float64(0.6138613861386139), 5: np.float64(0.0), 6: np.float64(0.4625), 10: np.float64(0.45161290322580644), 16: np.float64(0.32558139534883723), 17: np.float64(0.35789473684210527), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.4533678756476684
Weighted-average F1 score: 0.42871600094368345

F1 score per class: {32: np.float64(0.7725321888412017), 5: np.float64(0.3967828418230563), 6: np.float64(0.1592920353982301), 10: np.float64(0.4411764705882353), 16: np.float64(0.12345679012345678), 17: np.float64(0.12307692307692308), 18: np.float64(0.7545454545454545), 19: np.float64(0.2692307692307692), 24: np.float64(0.6735751295336787), 26: np.float64(0.7892376681614349), 29: np.float64(0.6666666666666666)}
Micro-average F1 score: 0.5598722724853645
Weighted-average F1 score: 0.5594381532481747
F1 score per class: {32: np.float64(0.5224719101123596), 5: np.float64(0.3780487804878049), 6: np.float64(0.4), 10: np.float64(0.3559322033898305), 16: np.float64(0.1320754716981132), 17: np.float64(0.2857142857142857), 18: np.float64(0.6926070038910506), 19: np.float64(0.18), 24: np.float64(0.6285714285714286), 26: np.float64(0.7736625514403292), 29: np.float64(0.6544117647058824)}
Micro-average F1 score: 0.5071274298056155
Weighted-average F1 score: 0.4887209613153898
F1 score per class: {32: np.float64(0.5470588235294118), 5: np.float64(0.39274924471299094), 6: np.float64(0.40437158469945356), 10: np.float64(0.38181818181818183), 16: np.float64(0.12612612612612611), 17: np.float64(0.30357142857142855), 18: np.float64(0.7219917012448133), 19: np.float64(0.20689655172413793), 24: np.float64(0.66), 26: np.float64(0.7848101265822784), 29: np.float64(0.6567164179104478)}
Micro-average F1 score: 0.5252252252252252
Weighted-average F1 score: 0.5060899360127648
cur_acc_wo_na:  ['0.7682', '0.5503']
his_acc_wo_na:  ['0.7682', '0.6999']
cur_acc des_wo_na:  ['0.7572', '0.6279']
his_acc des_wo_na:  ['0.7572', '0.6865']
cur_acc rrf_wo_na:  ['0.7673', '0.6422']
his_acc rrf_wo_na:  ['0.7673', '0.7028']
cur_acc_w_na:  ['0.6477', '0.4278']
his_acc_w_na:  ['0.6477', '0.5599']
cur_acc des_w_na:  ['0.6209', '0.4347']
his_acc des_w_na:  ['0.6209', '0.5071']
cur_acc rrf_w_na:  ['0.6317', '0.4534']
his_acc rrf_w_na:  ['0.6317', '0.5252']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 98.7543347CurrentTrain: epoch  0, batch     1 | loss: 80.6146397CurrentTrain: epoch  0, batch     2 | loss: 80.5805438CurrentTrain: epoch  0, batch     3 | loss: 9.5009443CurrentTrain: epoch  1, batch     0 | loss: 77.7960129CurrentTrain: epoch  1, batch     1 | loss: 75.4550285CurrentTrain: epoch  1, batch     2 | loss: 73.1091607CurrentTrain: epoch  1, batch     3 | loss: 20.6500791CurrentTrain: epoch  2, batch     0 | loss: 65.6588283CurrentTrain: epoch  2, batch     1 | loss: 84.8612418CurrentTrain: epoch  2, batch     2 | loss: 99.1103744CurrentTrain: epoch  2, batch     3 | loss: 19.6484528CurrentTrain: epoch  3, batch     0 | loss: 67.2717043CurrentTrain: epoch  3, batch     1 | loss: 70.9285428CurrentTrain: epoch  3, batch     2 | loss: 79.7105296CurrentTrain: epoch  3, batch     3 | loss: 10.8384962CurrentTrain: epoch  4, batch     0 | loss: 65.7070642CurrentTrain: epoch  4, batch     1 | loss: 67.6224999CurrentTrain: epoch  4, batch     2 | loss: 68.3160108CurrentTrain: epoch  4, batch     3 | loss: 19.4549712CurrentTrain: epoch  5, batch     0 | loss: 64.2085986CurrentTrain: epoch  5, batch     1 | loss: 63.9637452CurrentTrain: epoch  5, batch     2 | loss: 67.9597289CurrentTrain: epoch  5, batch     3 | loss: 18.2389563CurrentTrain: epoch  6, batch     0 | loss: 65.6645929CurrentTrain: epoch  6, batch     1 | loss: 61.3048526CurrentTrain: epoch  6, batch     2 | loss: 66.1148694CurrentTrain: epoch  6, batch     3 | loss: 19.8085973CurrentTrain: epoch  7, batch     0 | loss: 59.8405840CurrentTrain: epoch  7, batch     1 | loss: 73.0249300CurrentTrain: epoch  7, batch     2 | loss: 95.6168660CurrentTrain: epoch  7, batch     3 | loss: 41.8922624CurrentTrain: epoch  8, batch     0 | loss: 62.9064694CurrentTrain: epoch  8, batch     1 | loss: 62.8432128CurrentTrain: epoch  8, batch     2 | loss: 62.4178291CurrentTrain: epoch  8, batch     3 | loss: 17.7601707CurrentTrain: epoch  9, batch     0 | loss: 75.6320099CurrentTrain: epoch  9, batch     1 | loss: 71.8267482CurrentTrain: epoch  9, batch     2 | loss: 72.4698781CurrentTrain: epoch  9, batch     3 | loss: 9.3230695
MemoryTrain:  epoch  0, batch     0 | loss: 1.0341245MemoryTrain:  epoch  1, batch     0 | loss: 0.7941697MemoryTrain:  epoch  2, batch     0 | loss: 0.6499993MemoryTrain:  epoch  3, batch     0 | loss: 0.5376600MemoryTrain:  epoch  4, batch     0 | loss: 0.3387539MemoryTrain:  epoch  5, batch     0 | loss: 0.3150793MemoryTrain:  epoch  6, batch     0 | loss: 0.2788917MemoryTrain:  epoch  7, batch     0 | loss: 0.2406782MemoryTrain:  epoch  8, batch     0 | loss: 0.2196546MemoryTrain:  epoch  9, batch     0 | loss: 0.1638502

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5714285714285714), 7: np.float64(0.8571428571428571), 40: np.float64(0.0), 9: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.23529411764705882), 26: np.float64(0.0), 27: np.float64(0.5), 29: np.float64(0.0), 31: np.float64(0.3007518796992481)}
Micro-average F1 score: 0.35379061371841153
Weighted-average F1 score: 0.2966085368600136
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5714285714285714), 7: np.float64(0.6756756756756757), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.3157894736842105), 26: np.float64(0.0), 27: np.float64(0.3333333333333333), 29: np.float64(0.0), 31: np.float64(0.390625)}
Micro-average F1 score: 0.3696369636963696
Weighted-average F1 score: 0.3187347076758104
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5714285714285714), 7: np.float64(0.78125), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.3157894736842105), 26: np.float64(0.0), 27: np.float64(0.4), 29: np.float64(0.0), 31: np.float64(0.38461538461538464)}
Micro-average F1 score: 0.3888888888888889
Weighted-average F1 score: 0.3320186656960704

F1 score per class: {32: np.float64(0.8450704225352113), 5: np.float64(0.40559440559440557), 6: np.float64(0.03669724770642202), 7: np.float64(0.8571428571428571), 40: np.float64(0.19642857142857142), 10: np.float64(0.5384615384615384), 9: np.float64(0.0), 16: np.float64(0.08888888888888889), 17: np.float64(0.6166666666666667), 18: np.float64(0.25), 19: np.float64(0.7209302325581395), 24: np.float64(0.16), 26: np.float64(0.8556149732620321), 27: np.float64(0.2857142857142857), 29: np.float64(0.8186528497409327), 31: np.float64(0.145985401459854)}
Micro-average F1 score: 0.5269909139497595
Weighted-average F1 score: 0.4995989785916137
F1 score per class: {32: np.float64(0.6619217081850534), 5: np.float64(0.45977011494252873), 6: np.float64(0.044444444444444446), 7: np.float64(0.6578947368421053), 40: np.float64(0.4625), 10: np.float64(0.5507246376811594), 9: np.float64(0.0), 16: np.float64(0.42105263157894735), 17: np.float64(0.6204081632653061), 18: np.float64(0.2702702702702703), 19: np.float64(0.7303370786516854), 24: np.float64(0.23076923076923078), 26: np.float64(0.8808290155440415), 27: np.float64(0.16666666666666666), 29: np.float64(0.821256038647343), 31: np.float64(0.2109704641350211)}
Micro-average F1 score: 0.5576642335766423
Weighted-average F1 score: 0.532105864374936
F1 score per class: {32: np.float64(0.7159533073929961), 5: np.float64(0.4624277456647399), 6: np.float64(0.04395604395604396), 7: np.float64(0.78125), 40: np.float64(0.44755244755244755), 10: np.float64(0.6129032258064516), 9: np.float64(0.0), 16: np.float64(0.2127659574468085), 17: np.float64(0.628099173553719), 18: np.float64(0.1935483870967742), 19: np.float64(0.7303370786516854), 24: np.float64(0.21428571428571427), 26: np.float64(0.875), 27: np.float64(0.2222222222222222), 29: np.float64(0.8333333333333334), 31: np.float64(0.20161290322580644)}
Micro-average F1 score: 0.561491935483871
Weighted-average F1 score: 0.5367232963274599

F1 score per class: {32: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.7868852459016393), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.2222222222222222), 26: np.float64(0.0), 27: np.float64(0.4), 29: np.float64(0.0), 31: np.float64(0.25157232704402516)}
Micro-average F1 score: 0.30246913580246915
Weighted-average F1 score: 0.2583103641841656
F1 score per class: {32: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.5952380952380952), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.2857142857142857), 26: np.float64(0.0), 27: np.float64(0.25), 29: np.float64(0.0), 31: np.float64(0.3184713375796178)}
Micro-average F1 score: 0.3027027027027027
Weighted-average F1 score: 0.26622450333636644
F1 score per class: {32: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.7246376811594203), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.2857142857142857), 26: np.float64(0.0), 27: np.float64(0.2857142857142857), 29: np.float64(0.0), 31: np.float64(0.3125)}
Micro-average F1 score: 0.3218390804597701
Weighted-average F1 score: 0.27830643591513154

F1 score per class: {32: np.float64(0.6382978723404256), 5: np.float64(0.31016042780748665), 6: np.float64(0.020100502512562814), 7: np.float64(0.7868852459016393), 40: np.float64(0.1864406779661017), 10: np.float64(0.35), 9: np.float64(0.0), 16: np.float64(0.0851063829787234), 17: np.float64(0.5849802371541502), 18: np.float64(0.20689655172413793), 19: np.float64(0.6631016042780749), 24: np.float64(0.13793103448275862), 26: np.float64(0.7619047619047619), 27: np.float64(0.2222222222222222), 29: np.float64(0.6723404255319149), 31: np.float64(0.11142061281337047)}
Micro-average F1 score: 0.42245072836332476
Weighted-average F1 score: 0.3902739528263859
F1 score per class: {32: np.float64(0.45036319612590797), 5: np.float64(0.32), 6: np.float64(0.024844720496894408), 7: np.float64(0.5434782608695652), 40: np.float64(0.37948717948717947), 10: np.float64(0.3247863247863248), 9: np.float64(0.0), 16: np.float64(0.3), 17: np.float64(0.5801526717557252), 18: np.float64(0.1724137931034483), 19: np.float64(0.6598984771573604), 24: np.float64(0.18181818181818182), 26: np.float64(0.776255707762557), 27: np.float64(0.125), 29: np.float64(0.6692913385826772), 31: np.float64(0.15772870662460567)}
Micro-average F1 score: 0.42491657397107896
Weighted-average F1 score: 0.3973808038536639
F1 score per class: {32: np.float64(0.4986449864498645), 5: np.float64(0.32388663967611336), 6: np.float64(0.024691358024691357), 7: np.float64(0.7142857142857143), 40: np.float64(0.3878787878787879), 10: np.float64(0.35514018691588783), 9: np.float64(0.0), 16: np.float64(0.1724137931034483), 17: np.float64(0.5914396887159533), 18: np.float64(0.15), 19: np.float64(0.6666666666666666), 24: np.float64(0.16666666666666666), 26: np.float64(0.7671232876712328), 27: np.float64(0.16666666666666666), 29: np.float64(0.6692913385826772), 31: np.float64(0.1510574018126888)}
Micro-average F1 score: 0.4356667970277669
Weighted-average F1 score: 0.4077056129768049
cur_acc_wo_na:  ['0.7682', '0.5503', '0.3538']
his_acc_wo_na:  ['0.7682', '0.6999', '0.5270']
cur_acc des_wo_na:  ['0.7572', '0.6279', '0.3696']
his_acc des_wo_na:  ['0.7572', '0.6865', '0.5577']
cur_acc rrf_wo_na:  ['0.7673', '0.6422', '0.3889']
his_acc rrf_wo_na:  ['0.7673', '0.7028', '0.5615']
cur_acc_w_na:  ['0.6477', '0.4278', '0.3025']
his_acc_w_na:  ['0.6477', '0.5599', '0.4225']
cur_acc des_w_na:  ['0.6209', '0.4347', '0.3027']
his_acc des_w_na:  ['0.6209', '0.5071', '0.4249']
cur_acc rrf_w_na:  ['0.6317', '0.4534', '0.3218']
his_acc rrf_w_na:  ['0.6317', '0.5252', '0.4357']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 102.5519960CurrentTrain: epoch  0, batch     1 | loss: 97.3189249CurrentTrain: epoch  0, batch     2 | loss: 118.7798548CurrentTrain: epoch  0, batch     3 | loss: 95.2969191CurrentTrain: epoch  1, batch     0 | loss: 78.6017734CurrentTrain: epoch  1, batch     1 | loss: 73.5582752CurrentTrain: epoch  1, batch     2 | loss: 97.9207014CurrentTrain: epoch  1, batch     3 | loss: 91.8208183CurrentTrain: epoch  2, batch     0 | loss: 86.6731139CurrentTrain: epoch  2, batch     1 | loss: 71.7267648CurrentTrain: epoch  2, batch     2 | loss: 109.3994616CurrentTrain: epoch  2, batch     3 | loss: 72.3848829CurrentTrain: epoch  3, batch     0 | loss: 101.5682541CurrentTrain: epoch  3, batch     1 | loss: 86.6979260CurrentTrain: epoch  3, batch     2 | loss: 85.8975031CurrentTrain: epoch  3, batch     3 | loss: 81.6427976CurrentTrain: epoch  4, batch     0 | loss: 99.0273661CurrentTrain: epoch  4, batch     1 | loss: 101.8001665CurrentTrain: epoch  4, batch     2 | loss: 88.3636517CurrentTrain: epoch  4, batch     3 | loss: 54.3709781CurrentTrain: epoch  5, batch     0 | loss: 99.2370548CurrentTrain: epoch  5, batch     1 | loss: 78.2815306CurrentTrain: epoch  5, batch     2 | loss: 102.9868828CurrentTrain: epoch  5, batch     3 | loss: 64.6027737CurrentTrain: epoch  6, batch     0 | loss: 81.4697954CurrentTrain: epoch  6, batch     1 | loss: 77.8852590CurrentTrain: epoch  6, batch     2 | loss: 82.4055163CurrentTrain: epoch  6, batch     3 | loss: 78.2422328CurrentTrain: epoch  7, batch     0 | loss: 76.9996147CurrentTrain: epoch  7, batch     1 | loss: 97.2360309CurrentTrain: epoch  7, batch     2 | loss: 80.4977820CurrentTrain: epoch  7, batch     3 | loss: 65.5183696CurrentTrain: epoch  8, batch     0 | loss: 82.3746696CurrentTrain: epoch  8, batch     1 | loss: 77.1631212CurrentTrain: epoch  8, batch     2 | loss: 76.9492967CurrentTrain: epoch  8, batch     3 | loss: 54.9876983CurrentTrain: epoch  9, batch     0 | loss: 74.6827352CurrentTrain: epoch  9, batch     1 | loss: 64.9569153CurrentTrain: epoch  9, batch     2 | loss: 97.7527614CurrentTrain: epoch  9, batch     3 | loss: 79.1841951
MemoryTrain:  epoch  0, batch     0 | loss: 0.9713932MemoryTrain:  epoch  1, batch     0 | loss: 0.8238806MemoryTrain:  epoch  2, batch     0 | loss: 0.7078323MemoryTrain:  epoch  3, batch     0 | loss: 0.5497055MemoryTrain:  epoch  4, batch     0 | loss: 0.4535937MemoryTrain:  epoch  5, batch     0 | loss: 0.4001509MemoryTrain:  epoch  6, batch     0 | loss: 0.3397779MemoryTrain:  epoch  7, batch     0 | loss: 0.2948114MemoryTrain:  epoch  8, batch     0 | loss: 0.2719785MemoryTrain:  epoch  9, batch     0 | loss: 0.2390813

F1 score per class: {0: np.float64(0.9014084507042254), 4: np.float64(0.9690721649484536), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.21052631578947367), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3548387096774194), 23: np.float64(0.7619047619047619), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.7080745341614907
Weighted-average F1 score: 0.6231122260099891
F1 score per class: {0: np.float64(0.7954545454545454), 4: np.float64(0.9411764705882353), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.18181818181818182), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.4383561643835616), 23: np.float64(0.6904761904761905), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.6180555555555556
Weighted-average F1 score: 0.5210674769718989
F1 score per class: {0: np.float64(0.8533333333333334), 4: np.float64(0.964824120603015), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.16666666666666666), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.410958904109589), 23: np.float64(0.6987951807228916), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.651685393258427
Weighted-average F1 score: 0.5526363750052823

F1 score per class: {0: np.float64(0.7619047619047619), 4: np.float64(0.9690721649484536), 5: np.float64(0.7894736842105263), 6: np.float64(0.33587786259541985), 7: np.float64(0.0425531914893617), 9: np.float64(0.8333333333333334), 10: np.float64(0.0), 13: np.float64(0.03125), 16: np.float64(0.5833333333333334), 17: np.float64(0.0), 18: np.float64(0.13043478260869565), 19: np.float64(0.6511627906976745), 21: np.float64(0.24719101123595505), 23: np.float64(0.6736842105263158), 24: np.float64(0.09523809523809523), 26: np.float64(0.6994535519125683), 27: np.float64(0.34285714285714286), 29: np.float64(0.8350515463917526), 31: np.float64(0.25), 32: np.float64(0.7920792079207921), 40: np.float64(0.25210084033613445)}
Micro-average F1 score: 0.5486284289276808
Weighted-average F1 score: 0.5298046231641884
F1 score per class: {0: np.float64(0.5882352941176471), 4: np.float64(0.9142857142857143), 5: np.float64(0.5413105413105413), 6: np.float64(0.37333333333333335), 7: np.float64(0.029411764705882353), 9: np.float64(0.6172839506172839), 10: np.float64(0.19834710743801653), 13: np.float64(0.029850746268656716), 16: np.float64(0.4883720930232558), 17: np.float64(0.0), 18: np.float64(0.42105263157894735), 19: np.float64(0.6086956521739131), 21: np.float64(0.2601626016260163), 23: np.float64(0.6236559139784946), 24: np.float64(0.24), 26: np.float64(0.6701030927835051), 27: np.float64(0.27586206896551724), 29: np.float64(0.8341708542713567), 31: np.float64(0.09090909090909091), 32: np.float64(0.7523809523809524), 40: np.float64(0.24413145539906103)}
Micro-average F1 score: 0.5044091710758377
Weighted-average F1 score: 0.4747105631148045
F1 score per class: {0: np.float64(0.6530612244897959), 4: np.float64(0.9458128078817734), 5: np.float64(0.6391752577319587), 6: np.float64(0.3698630136986301), 7: np.float64(0.034782608695652174), 9: np.float64(0.746268656716418), 10: np.float64(0.10810810810810811), 13: np.float64(0.027972027972027972), 16: np.float64(0.6557377049180327), 17: np.float64(0.0), 18: np.float64(0.3333333333333333), 19: np.float64(0.6218487394957983), 21: np.float64(0.24793388429752067), 23: np.float64(0.6041666666666666), 24: np.float64(0.24), 26: np.float64(0.6772486772486772), 27: np.float64(0.27586206896551724), 29: np.float64(0.8557213930348259), 31: np.float64(0.1111111111111111), 32: np.float64(0.7596153846153846), 40: np.float64(0.22707423580786026)}
Micro-average F1 score: 0.5218045112781955
Weighted-average F1 score: 0.4926396298128312

F1 score per class: {0: np.float64(0.8648648648648649), 4: np.float64(0.9261083743842364), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.08163265306122448), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.2894736842105263), 23: np.float64(0.6956521739130435), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5560975609756098
Weighted-average F1 score: 0.44382699471349596
F1 score per class: {0: np.float64(0.7526881720430108), 4: np.float64(0.8767123287671232), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0784313725490196), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3137254901960784), 23: np.float64(0.5918367346938775), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4587628865979381
Weighted-average F1 score: 0.36429016397169156
F1 score per class: {0: np.float64(0.8311688311688312), 4: np.float64(0.9056603773584906), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.07407407407407407), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.297029702970297), 23: np.float64(0.5979381443298969), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.49361702127659574
Weighted-average F1 score: 0.3896893434328856

F1 score per class: {0: np.float64(0.6037735849056604), 4: np.float64(0.912621359223301), 5: np.float64(0.5732484076433121), 6: np.float64(0.2732919254658385), 7: np.float64(0.023255813953488372), 9: np.float64(0.7575757575757576), 10: np.float64(0.0), 13: np.float64(0.01556420233463035), 16: np.float64(0.3888888888888889), 17: np.float64(0.0), 18: np.float64(0.09836065573770492), 19: np.float64(0.6167400881057269), 21: np.float64(0.15492957746478872), 23: np.float64(0.5818181818181818), 24: np.float64(0.08), 26: np.float64(0.6432160804020101), 27: np.float64(0.22641509433962265), 29: np.float64(0.7136563876651982), 31: np.float64(0.18181818181818182), 32: np.float64(0.6153846153846154), 40: np.float64(0.20689655172413793)}
Micro-average F1 score: 0.4253947792458911
Weighted-average F1 score: 0.3932572864344114
F1 score per class: {0: np.float64(0.46357615894039733), 4: np.float64(0.8311688311688312), 5: np.float64(0.336283185840708), 6: np.float64(0.2731707317073171), 7: np.float64(0.01568627450980392), 9: np.float64(0.5154639175257731), 10: np.float64(0.183206106870229), 13: np.float64(0.01509433962264151), 16: np.float64(0.28378378378378377), 17: np.float64(0.0), 18: np.float64(0.24806201550387597), 19: np.float64(0.56), 21: np.float64(0.15023474178403756), 23: np.float64(0.5087719298245614), 24: np.float64(0.2), 26: np.float64(0.6046511627906976), 27: np.float64(0.18604651162790697), 29: np.float64(0.6775510204081633), 31: np.float64(0.04878048780487805), 32: np.float64(0.5917602996254682), 40: np.float64(0.18840579710144928)}
Micro-average F1 score: 0.36322072644145287
Weighted-average F1 score: 0.33048182902735634
F1 score per class: {0: np.float64(0.512), 4: np.float64(0.8767123287671232), 5: np.float64(0.40789473684210525), 6: np.float64(0.27411167512690354), 7: np.float64(0.018518518518518517), 9: np.float64(0.684931506849315), 10: np.float64(0.10344827586206896), 13: np.float64(0.014234875444839857), 16: np.float64(0.35714285714285715), 17: np.float64(0.0), 18: np.float64(0.2222222222222222), 19: np.float64(0.5873015873015873), 21: np.float64(0.14705882352941177), 23: np.float64(0.49572649572649574), 24: np.float64(0.2), 26: np.float64(0.6124401913875598), 27: np.float64(0.17391304347826086), 29: np.float64(0.6907630522088354), 31: np.float64(0.07142857142857142), 32: np.float64(0.5984848484848485), 40: np.float64(0.17687074829931973)}
Micro-average F1 score: 0.3834254143646409
Weighted-average F1 score: 0.3495758145652105
cur_acc_wo_na:  ['0.7682', '0.5503', '0.3538', '0.7081']
his_acc_wo_na:  ['0.7682', '0.6999', '0.5270', '0.5486']
cur_acc des_wo_na:  ['0.7572', '0.6279', '0.3696', '0.6181']
his_acc des_wo_na:  ['0.7572', '0.6865', '0.5577', '0.5044']
cur_acc rrf_wo_na:  ['0.7673', '0.6422', '0.3889', '0.6517']
his_acc rrf_wo_na:  ['0.7673', '0.7028', '0.5615', '0.5218']
cur_acc_w_na:  ['0.6477', '0.4278', '0.3025', '0.5561']
his_acc_w_na:  ['0.6477', '0.5599', '0.4225', '0.4254']
cur_acc des_w_na:  ['0.6209', '0.4347', '0.3027', '0.4588']
his_acc des_w_na:  ['0.6209', '0.5071', '0.4249', '0.3632']
cur_acc rrf_w_na:  ['0.6317', '0.4534', '0.3218', '0.4936']
his_acc rrf_w_na:  ['0.6317', '0.5252', '0.4357', '0.3834']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 97.1312316CurrentTrain: epoch  0, batch     1 | loss: 86.2988584CurrentTrain: epoch  0, batch     2 | loss: 94.9168665CurrentTrain: epoch  0, batch     3 | loss: 54.3786095CurrentTrain: epoch  1, batch     0 | loss: 76.5371559CurrentTrain: epoch  1, batch     1 | loss: 132.7597648CurrentTrain: epoch  1, batch     2 | loss: 72.2164762CurrentTrain: epoch  1, batch     3 | loss: 55.1063290CurrentTrain: epoch  2, batch     0 | loss: 127.3324002CurrentTrain: epoch  2, batch     1 | loss: 104.6219202CurrentTrain: epoch  2, batch     2 | loss: 70.6240441CurrentTrain: epoch  2, batch     3 | loss: 47.9873229CurrentTrain: epoch  3, batch     0 | loss: 78.6094019CurrentTrain: epoch  3, batch     1 | loss: 71.9852929CurrentTrain: epoch  3, batch     2 | loss: 82.2743336CurrentTrain: epoch  3, batch     3 | loss: 105.6975848CurrentTrain: epoch  4, batch     0 | loss: 78.8585042CurrentTrain: epoch  4, batch     1 | loss: 80.6340970CurrentTrain: epoch  4, batch     2 | loss: 78.4050602CurrentTrain: epoch  4, batch     3 | loss: 104.2323326CurrentTrain: epoch  5, batch     0 | loss: 81.5506490CurrentTrain: epoch  5, batch     1 | loss: 81.6886243CurrentTrain: epoch  5, batch     2 | loss: 77.2951377CurrentTrain: epoch  5, batch     3 | loss: 38.0969451CurrentTrain: epoch  6, batch     0 | loss: 80.0359093CurrentTrain: epoch  6, batch     1 | loss: 72.6361599CurrentTrain: epoch  6, batch     2 | loss: 81.9698778CurrentTrain: epoch  6, batch     3 | loss: 46.6426008CurrentTrain: epoch  7, batch     0 | loss: 95.9276519CurrentTrain: epoch  7, batch     1 | loss: 66.0125840CurrentTrain: epoch  7, batch     2 | loss: 62.5402391CurrentTrain: epoch  7, batch     3 | loss: 48.1833058CurrentTrain: epoch  8, batch     0 | loss: 119.9622226CurrentTrain: epoch  8, batch     1 | loss: 62.5532572CurrentTrain: epoch  8, batch     2 | loss: 93.1334337CurrentTrain: epoch  8, batch     3 | loss: 45.0104678CurrentTrain: epoch  9, batch     0 | loss: 95.7475933CurrentTrain: epoch  9, batch     1 | loss: 76.4523918CurrentTrain: epoch  9, batch     2 | loss: 62.0184433CurrentTrain: epoch  9, batch     3 | loss: 36.9114375
MemoryTrain:  epoch  0, batch     0 | loss: 0.8183161MemoryTrain:  epoch  1, batch     0 | loss: 0.7053096MemoryTrain:  epoch  2, batch     0 | loss: 0.6155126MemoryTrain:  epoch  3, batch     0 | loss: 0.5162563MemoryTrain:  epoch  4, batch     0 | loss: 0.4141860MemoryTrain:  epoch  5, batch     0 | loss: 0.3706228MemoryTrain:  epoch  6, batch     0 | loss: 0.3046199MemoryTrain:  epoch  7, batch     0 | loss: 0.2581337MemoryTrain:  epoch  8, batch     0 | loss: 0.2316379MemoryTrain:  epoch  9, batch     0 | loss: 0.2234121

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.0), 0: np.float64(0.0), 36: np.float64(0.6829268292682927), 5: np.float64(0.0), 7: np.float64(0.8521739130434782), 8: np.float64(0.0), 40: np.float64(0.0), 13: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.8571428571428571), 26: np.float64(0.0), 27: np.float64(0.375), 29: np.float64(0.5319148936170213), 30: np.float64(0.0)}
Micro-average F1 score: 0.6179540709812108
Weighted-average F1 score: 0.5610824123406564
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.611764705882353), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.7722772277227723), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7317073170731707), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.5), 36: np.float64(0.7591240875912408), 40: np.float64(0.0)}
Micro-average F1 score: 0.5559322033898305
Weighted-average F1 score: 0.46584807721751414
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.6235294117647059), 10: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.7850467289719626), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8108108108108109), 32: np.float64(0.0), 33: np.float64(0.5), 36: np.float64(0.7), 40: np.float64(0.0)}
Micro-average F1 score: 0.5830258302583026
Weighted-average F1 score: 0.5015954626275481

F1 score per class: {0: np.float64(0.7415730337078652), 4: np.float64(0.9247311827956989), 5: np.float64(0.8177777777777778), 6: np.float64(0.2923076923076923), 7: np.float64(0.03508771929824561), 8: np.float64(0.3373493975903614), 9: np.float64(0.8727272727272727), 10: np.float64(0.019801980198019802), 13: np.float64(0.08163265306122448), 16: np.float64(0.6086956521739131), 17: np.float64(0.0), 18: np.float64(0.0975609756097561), 19: np.float64(0.6491228070175439), 20: np.float64(0.5355191256830601), 21: np.float64(0.1891891891891892), 23: np.float64(0.5783132530120482), 24: np.float64(0.09090909090909091), 26: np.float64(0.6632653061224489), 27: np.float64(0.32432432432432434), 29: np.float64(0.8367346938775511), 30: np.float64(0.8571428571428571), 31: np.float64(0.2), 32: np.float64(0.7431192660550459), 33: np.float64(0.18181818181818182), 36: np.float64(0.49019607843137253), 40: np.float64(0.2374429223744292)}
Micro-average F1 score: 0.5243942914039164
Weighted-average F1 score: 0.514150129829374
F1 score per class: {0: np.float64(0.5303030303030303), 4: np.float64(0.9333333333333333), 5: np.float64(0.49238578680203043), 6: np.float64(0.4772727272727273), 7: np.float64(0.031746031746031744), 8: np.float64(0.27296587926509186), 9: np.float64(0.5747126436781609), 10: np.float64(0.10909090909090909), 13: np.float64(0.08333333333333333), 16: np.float64(0.43010752688172044), 17: np.float64(0.0), 18: np.float64(0.41975308641975306), 19: np.float64(0.5899280575539568), 20: np.float64(0.6446280991735537), 21: np.float64(0.22485207100591717), 23: np.float64(0.6222222222222222), 24: np.float64(0.21428571428571427), 26: np.float64(0.6534653465346535), 27: np.float64(0.2564102564102564), 29: np.float64(0.8275862068965517), 30: np.float64(0.5769230769230769), 31: np.float64(0.08333333333333333), 32: np.float64(0.7330316742081447), 33: np.float64(0.1875), 36: np.float64(0.538860103626943), 40: np.float64(0.19095477386934673)}
Micro-average F1 score: 0.48017148981779206
Weighted-average F1 score: 0.4571224117749255
F1 score per class: {0: np.float64(0.6126126126126126), 4: np.float64(0.98), 5: np.float64(0.6807017543859649), 6: np.float64(0.4375), 7: np.float64(0.03361344537815126), 8: np.float64(0.2717948717948718), 9: np.float64(0.746268656716418), 10: np.float64(0.057692307692307696), 13: np.float64(0.08695652173913043), 16: np.float64(0.6551724137931034), 17: np.float64(0.0), 18: np.float64(0.417910447761194), 19: np.float64(0.6303501945525292), 20: np.float64(0.6176470588235294), 21: np.float64(0.25757575757575757), 23: np.float64(0.6021505376344086), 24: np.float64(0.16), 26: np.float64(0.6633165829145728), 27: np.float64(0.3333333333333333), 29: np.float64(0.8275862068965517), 30: np.float64(0.7142857142857143), 31: np.float64(0.13333333333333333), 32: np.float64(0.7272727272727273), 33: np.float64(0.18181818181818182), 36: np.float64(0.525), 40: np.float64(0.17699115044247787)}
Micro-average F1 score: 0.5084449621432732
Weighted-average F1 score: 0.48500076420417315

F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.48695652173913045), 13: np.float64(0.0), 20: np.float64(0.5130890052356021), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8108108108108109), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.375), 36: np.float64(0.4424778761061947), 40: np.float64(0.0)}
Micro-average F1 score: 0.41514726507713884
Weighted-average F1 score: 0.37368417059749726
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.4425531914893617), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.609375), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.6818181818181818), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.3333333333333333), 36: np.float64(0.5810055865921788), 40: np.float64(0.0)}
Micro-average F1 score: 0.37744533947065595
Weighted-average F1 score: 0.3201870856631125
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.44537815126050423), 10: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.6086956521739131), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7692307692307693), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.3157894736842105), 36: np.float64(0.5384615384615384), 40: np.float64(0.0)}
Micro-average F1 score: 0.3979848866498741
Weighted-average F1 score: 0.3435653182346987

F1 score per class: {0: np.float64(0.5689655172413793), 4: np.float64(0.8686868686868687), 5: np.float64(0.673992673992674), 6: np.float64(0.24358974358974358), 7: np.float64(0.018433179723502304), 8: np.float64(0.18887015177065766), 9: np.float64(0.8), 10: np.float64(0.0196078431372549), 13: np.float64(0.044444444444444446), 16: np.float64(0.45901639344262296), 17: np.float64(0.0), 18: np.float64(0.0975609756097561), 19: np.float64(0.6192468619246861), 20: np.float64(0.2396088019559902), 21: np.float64(0.13861386138613863), 23: np.float64(0.4752475247524752), 24: np.float64(0.08), 26: np.float64(0.5963302752293578), 27: np.float64(0.2033898305084746), 29: np.float64(0.6978723404255319), 30: np.float64(0.8108108108108109), 31: np.float64(0.125), 32: np.float64(0.5605536332179931), 33: np.float64(0.12244897959183673), 36: np.float64(0.36496350364963503), 40: np.float64(0.19402985074626866)}
Micro-average F1 score: 0.38545986826055134
Weighted-average F1 score: 0.35738195685600266
F1 score per class: {0: np.float64(0.4093567251461988), 4: np.float64(0.8711111111111111), 5: np.float64(0.313915857605178), 6: np.float64(0.336), 7: np.float64(0.017167381974248927), 8: np.float64(0.15522388059701492), 9: np.float64(0.45871559633027525), 10: np.float64(0.10526315789473684), 13: np.float64(0.046511627906976744), 16: np.float64(0.24539877300613497), 17: np.float64(0.0), 18: np.float64(0.24817518248175183), 19: np.float64(0.5484949832775919), 20: np.float64(0.40414507772020725), 21: np.float64(0.14671814671814673), 23: np.float64(0.4628099173553719), 24: np.float64(0.17142857142857143), 26: np.float64(0.5714285714285714), 27: np.float64(0.16393442622950818), 29: np.float64(0.6746987951807228), 30: np.float64(0.46875), 31: np.float64(0.041666666666666664), 32: np.float64(0.5684210526315789), 33: np.float64(0.11214953271028037), 36: np.float64(0.348993288590604), 40: np.float64(0.15261044176706828)}
Micro-average F1 score: 0.3386883386883387
Weighted-average F1 score: 0.3152549716338861
F1 score per class: {0: np.float64(0.4755244755244755), 4: np.float64(0.9158878504672897), 5: np.float64(0.46973365617433416), 6: np.float64(0.3333333333333333), 7: np.float64(0.017167381974248927), 8: np.float64(0.15273775216138327), 9: np.float64(0.6756756756756757), 10: np.float64(0.05660377358490566), 13: np.float64(0.046511627906976744), 16: np.float64(0.3877551020408163), 17: np.float64(0.0), 18: np.float64(0.2857142857142857), 19: np.float64(0.5912408759124088), 20: np.float64(0.37168141592920356), 21: np.float64(0.16346153846153846), 23: np.float64(0.45528455284552843), 24: np.float64(0.13333333333333333), 26: np.float64(0.5945945945945946), 27: np.float64(0.21212121212121213), 29: np.float64(0.6829268292682927), 30: np.float64(0.625), 31: np.float64(0.06451612903225806), 32: np.float64(0.5498281786941581), 33: np.float64(0.09917355371900827), 36: np.float64(0.32684824902723736), 40: np.float64(0.14084507042253522)}
Micro-average F1 score: 0.362993762993763
Weighted-average F1 score: 0.3363055458014083
cur_acc_wo_na:  ['0.7682', '0.5503', '0.3538', '0.7081', '0.6180']
his_acc_wo_na:  ['0.7682', '0.6999', '0.5270', '0.5486', '0.5244']
cur_acc des_wo_na:  ['0.7572', '0.6279', '0.3696', '0.6181', '0.5559']
his_acc des_wo_na:  ['0.7572', '0.6865', '0.5577', '0.5044', '0.4802']
cur_acc rrf_wo_na:  ['0.7673', '0.6422', '0.3889', '0.6517', '0.5830']
his_acc rrf_wo_na:  ['0.7673', '0.7028', '0.5615', '0.5218', '0.5084']
cur_acc_w_na:  ['0.6477', '0.4278', '0.3025', '0.5561', '0.4151']
his_acc_w_na:  ['0.6477', '0.5599', '0.4225', '0.4254', '0.3855']
cur_acc des_w_na:  ['0.6209', '0.4347', '0.3027', '0.4588', '0.3774']
his_acc des_w_na:  ['0.6209', '0.5071', '0.4249', '0.3632', '0.3387']
cur_acc rrf_w_na:  ['0.6317', '0.4534', '0.3218', '0.4936', '0.3980']
his_acc rrf_w_na:  ['0.6317', '0.5252', '0.4357', '0.3834', '0.3630']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 114.7007968CurrentTrain: epoch  0, batch     1 | loss: 100.9225141CurrentTrain: epoch  0, batch     2 | loss: 112.9377830CurrentTrain: epoch  0, batch     3 | loss: 88.0469370CurrentTrain: epoch  0, batch     4 | loss: 33.4930175CurrentTrain: epoch  1, batch     0 | loss: 93.8787066CurrentTrain: epoch  1, batch     1 | loss: 132.9366184CurrentTrain: epoch  1, batch     2 | loss: 88.2597478CurrentTrain: epoch  1, batch     3 | loss: 104.3552671CurrentTrain: epoch  1, batch     4 | loss: 21.0141860CurrentTrain: epoch  2, batch     0 | loss: 71.3835776CurrentTrain: epoch  2, batch     1 | loss: 86.0618396CurrentTrain: epoch  2, batch     2 | loss: 81.1816049CurrentTrain: epoch  2, batch     3 | loss: 174.0711450CurrentTrain: epoch  2, batch     4 | loss: 23.4335387CurrentTrain: epoch  3, batch     0 | loss: 97.7105603CurrentTrain: epoch  3, batch     1 | loss: 69.5139524CurrentTrain: epoch  3, batch     2 | loss: 83.3833988CurrentTrain: epoch  3, batch     3 | loss: 102.2690782CurrentTrain: epoch  3, batch     4 | loss: 23.4552150CurrentTrain: epoch  4, batch     0 | loss: 78.3632969CurrentTrain: epoch  4, batch     1 | loss: 98.6700742CurrentTrain: epoch  4, batch     2 | loss: 78.0635055CurrentTrain: epoch  4, batch     3 | loss: 80.8135515CurrentTrain: epoch  4, batch     4 | loss: 40.0351701CurrentTrain: epoch  5, batch     0 | loss: 98.4273661CurrentTrain: epoch  5, batch     1 | loss: 65.6726571CurrentTrain: epoch  5, batch     2 | loss: 94.9787996CurrentTrain: epoch  5, batch     3 | loss: 80.5550717CurrentTrain: epoch  5, batch     4 | loss: 26.6726869CurrentTrain: epoch  6, batch     0 | loss: 78.6522922CurrentTrain: epoch  6, batch     1 | loss: 65.2260452CurrentTrain: epoch  6, batch     2 | loss: 80.6865867CurrentTrain: epoch  6, batch     3 | loss: 69.0405259CurrentTrain: epoch  6, batch     4 | loss: 40.4713232CurrentTrain: epoch  7, batch     0 | loss: 91.5105073CurrentTrain: epoch  7, batch     1 | loss: 75.1858701CurrentTrain: epoch  7, batch     2 | loss: 124.6949839CurrentTrain: epoch  7, batch     3 | loss: 78.2971074CurrentTrain: epoch  7, batch     4 | loss: 15.7047984CurrentTrain: epoch  8, batch     0 | loss: 92.7117124CurrentTrain: epoch  8, batch     1 | loss: 75.9311326CurrentTrain: epoch  8, batch     2 | loss: 78.8787237CurrentTrain: epoch  8, batch     3 | loss: 93.8680923CurrentTrain: epoch  8, batch     4 | loss: 9.0156946CurrentTrain: epoch  9, batch     0 | loss: 94.3462085CurrentTrain: epoch  9, batch     1 | loss: 60.7069780CurrentTrain: epoch  9, batch     2 | loss: 119.2020433CurrentTrain: epoch  9, batch     3 | loss: 74.6409917CurrentTrain: epoch  9, batch     4 | loss: 23.6177321
MemoryTrain:  epoch  0, batch     0 | loss: 0.9162866MemoryTrain:  epoch  1, batch     0 | loss: 0.7637773MemoryTrain:  epoch  2, batch     0 | loss: 0.6774355MemoryTrain:  epoch  3, batch     0 | loss: 0.5320499MemoryTrain:  epoch  4, batch     0 | loss: 0.5002242MemoryTrain:  epoch  5, batch     0 | loss: 0.3912027MemoryTrain:  epoch  6, batch     0 | loss: 0.4000348MemoryTrain:  epoch  7, batch     0 | loss: 0.3240588MemoryTrain:  epoch  8, batch     0 | loss: 0.2843292MemoryTrain:  epoch  9, batch     0 | loss: 0.2428673

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.7777777777777778), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.5384615384615384), 12: np.float64(0.43795620437956206), 13: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 28: np.float64(0.3225806451612903), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 39: np.float64(0.10526315789473684), 40: np.float64(0.0)}
Micro-average F1 score: 0.40865384615384615
Weighted-average F1 score: 0.3439869787086892
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.6363636363636364), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.4857142857142857), 12: np.float64(0.5777777777777777), 13: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.29411764705882354), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.5217391304347826), 40: np.float64(0.0)}
Micro-average F1 score: 0.3895131086142322
Weighted-average F1 score: 0.2923644550778883
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.6363636363636364), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.4931506849315068), 12: np.float64(0.6022727272727273), 13: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.2777777777777778), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.43478260869565216), 40: np.float64(0.0)}
Micro-average F1 score: 0.42655935613682094
Weighted-average F1 score: 0.3393489767177

F1 score per class: {0: np.float64(0.775), 2: np.float64(0.5185185185185185), 4: np.float64(0.7976190476190477), 5: np.float64(0.8341232227488151), 6: np.float64(0.18333333333333332), 7: np.float64(0.019801980198019802), 8: np.float64(0.28451882845188287), 9: np.float64(0.819672131147541), 10: np.float64(0.0392156862745098), 11: np.float64(0.2507462686567164), 12: np.float64(0.30612244897959184), 13: np.float64(0.1), 16: np.float64(0.5833333333333334), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.6574074074074074), 20: np.float64(0.6178861788617886), 21: np.float64(0.21052631578947367), 23: np.float64(0.5789473684210527), 24: np.float64(0.09090909090909091), 26: np.float64(0.6120218579234973), 27: np.float64(0.3), 28: np.float64(0.10752688172043011), 29: np.float64(0.8), 30: np.float64(0.8571428571428571), 31: np.float64(0.18181818181818182), 32: np.float64(0.7707317073170732), 33: np.float64(0.23076923076923078), 36: np.float64(0.34146341463414637), 39: np.float64(0.06896551724137931), 40: np.float64(0.2761904761904762)}
Micro-average F1 score: 0.46181172291296624
Weighted-average F1 score: 0.4483936324921453
F1 score per class: {0: np.float64(0.5354330708661418), 2: np.float64(0.2545454545454545), 4: np.float64(0.850828729281768), 5: np.float64(0.5783132530120482), 6: np.float64(0.39805825242718446), 7: np.float64(0.03669724770642202), 8: np.float64(0.2883435582822086), 9: np.float64(0.5882352941176471), 10: np.float64(0.17699115044247787), 11: np.float64(0.2786885245901639), 12: np.float64(0.28184281842818426), 13: np.float64(0.0), 16: np.float64(0.5945945945945946), 17: np.float64(0.0), 18: np.float64(0.29508196721311475), 19: np.float64(0.6), 20: np.float64(0.5765765765765766), 21: np.float64(0.22857142857142856), 23: np.float64(0.6153846153846154), 24: np.float64(0.21428571428571427), 26: np.float64(0.6530612244897959), 27: np.float64(0.2857142857142857), 28: np.float64(0.12658227848101267), 29: np.float64(0.7979274611398963), 30: np.float64(0.6382978723404256), 31: np.float64(0.08333333333333333), 32: np.float64(0.7280701754385965), 33: np.float64(0.15384615384615385), 36: np.float64(0.5045045045045045), 39: np.float64(0.25), 40: np.float64(0.23232323232323232)}
Micro-average F1 score: 0.4446043165467626
Weighted-average F1 score: 0.42089696904090224
F1 score per class: {0: np.float64(0.6407766990291263), 2: np.float64(0.3111111111111111), 4: np.float64(0.8636363636363636), 5: np.float64(0.7540983606557377), 6: np.float64(0.35374149659863946), 7: np.float64(0.018018018018018018), 8: np.float64(0.2865853658536585), 9: np.float64(0.7352941176470589), 10: np.float64(0.11214953271028037), 11: np.float64(0.2482758620689655), 12: np.float64(0.31085043988269795), 13: np.float64(0.0), 16: np.float64(0.5714285714285714), 17: np.float64(0.0), 18: np.float64(0.09302325581395349), 19: np.float64(0.6363636363636364), 20: np.float64(0.591304347826087), 21: np.float64(0.27692307692307694), 23: np.float64(0.6588235294117647), 24: np.float64(0.23076923076923078), 26: np.float64(0.6458333333333334), 27: np.float64(0.2631578947368421), 28: np.float64(0.11363636363636363), 29: np.float64(0.7938144329896907), 30: np.float64(0.7142857142857143), 31: np.float64(0.125), 32: np.float64(0.7345132743362832), 33: np.float64(0.16666666666666666), 36: np.float64(0.4489795918367347), 39: np.float64(0.19230769230769232), 40: np.float64(0.23809523809523808)}
Micro-average F1 score: 0.45550683518184165
Weighted-average F1 score: 0.4306233515612398

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.4827586206896552), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.417910447761194), 12: np.float64(0.39215686274509803), 13: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.14925373134328357), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.08), 40: np.float64(0.0)}
Micro-average F1 score: 0.275974025974026
Weighted-average F1 score: 0.2200235186034054
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.4117647058823529), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.3953488372093023), 12: np.float64(0.4642857142857143), 13: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.1388888888888889), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.4444444444444444), 40: np.float64(0.0)}
Micro-average F1 score: 0.25710754017305315
Weighted-average F1 score: 0.19617205967921264
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.4117647058823529), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.3829787234042553), 12: np.float64(0.4796380090497738), 13: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.13333333333333333), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.3448275862068966), 40: np.float64(0.0)}
Micro-average F1 score: 0.2800528401585205
Weighted-average F1 score: 0.22441252083446797

F1 score per class: {0: np.float64(0.6138613861386139), 2: np.float64(0.2857142857142857), 4: np.float64(0.7444444444444445), 5: np.float64(0.7154471544715447), 6: np.float64(0.15492957746478872), 7: np.float64(0.010309278350515464), 8: np.float64(0.17215189873417722), 9: np.float64(0.7575757575757576), 10: np.float64(0.038461538461538464), 11: np.float64(0.16901408450704225), 12: np.float64(0.18072289156626506), 13: np.float64(0.06451612903225806), 16: np.float64(0.4745762711864407), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.6255506607929515), 20: np.float64(0.3377777777777778), 21: np.float64(0.14285714285714285), 23: np.float64(0.5176470588235295), 24: np.float64(0.08695652173913043), 26: np.float64(0.5517241379310345), 27: np.float64(0.18461538461538463), 28: np.float64(0.05813953488372093), 29: np.float64(0.6782608695652174), 30: np.float64(0.7894736842105263), 31: np.float64(0.11764705882352941), 32: np.float64(0.5830258302583026), 33: np.float64(0.17142857142857143), 36: np.float64(0.2692307692307692), 39: np.float64(0.03571428571428571), 40: np.float64(0.22745098039215686)}
Micro-average F1 score: 0.3418054338299737
Weighted-average F1 score: 0.3154882246615402
F1 score per class: {0: np.float64(0.40963855421686746), 2: np.float64(0.1728395061728395), 4: np.float64(0.806282722513089), 5: np.float64(0.3958762886597938), 6: np.float64(0.25949367088607594), 7: np.float64(0.018867924528301886), 8: np.float64(0.16845878136200718), 9: np.float64(0.4716981132075472), 10: np.float64(0.16260162601626016), 11: np.float64(0.19540229885057472), 12: np.float64(0.1566265060240964), 13: np.float64(0.0), 16: np.float64(0.3333333333333333), 17: np.float64(0.0), 18: np.float64(0.1836734693877551), 19: np.float64(0.5631768953068592), 20: np.float64(0.367816091954023), 21: np.float64(0.14760147601476015), 23: np.float64(0.5137614678899083), 24: np.float64(0.17647058823529413), 26: np.float64(0.5844748858447488), 27: np.float64(0.18181818181818182), 28: np.float64(0.06756756756756757), 29: np.float64(0.6724890829694323), 30: np.float64(0.5263157894736842), 31: np.float64(0.047619047619047616), 32: np.float64(0.5608108108108109), 33: np.float64(0.11320754716981132), 36: np.float64(0.35443037974683544), 39: np.float64(0.13953488372093023), 40: np.float64(0.17898832684824903)}
Micro-average F1 score: 0.30982620320855614
Weighted-average F1 score: 0.28542597016168003
F1 score per class: {0: np.float64(0.5038167938931297), 2: np.float64(0.18181818181818182), 4: np.float64(0.8172043010752689), 5: np.float64(0.5395894428152492), 6: np.float64(0.2694300518134715), 7: np.float64(0.009259259259259259), 8: np.float64(0.16234887737478412), 9: np.float64(0.6756756756756757), 10: np.float64(0.10810810810810811), 11: np.float64(0.16822429906542055), 12: np.float64(0.16536661466458658), 13: np.float64(0.0), 16: np.float64(0.4266666666666667), 17: np.float64(0.0), 18: np.float64(0.06779661016949153), 19: np.float64(0.6015625), 20: np.float64(0.36363636363636365), 21: np.float64(0.17142857142857143), 23: np.float64(0.5544554455445545), 24: np.float64(0.1935483870967742), 26: np.float64(0.5821596244131455), 27: np.float64(0.15384615384615385), 28: np.float64(0.06172839506172839), 29: np.float64(0.6695652173913044), 30: np.float64(0.625), 31: np.float64(0.08), 32: np.float64(0.5570469798657718), 33: np.float64(0.125), 36: np.float64(0.3235294117647059), 39: np.float64(0.1111111111111111), 40: np.float64(0.1865671641791045)}
Micro-average F1 score: 0.31969587255611875
Weighted-average F1 score: 0.2908895027455566
cur_acc_wo_na:  ['0.7682', '0.5503', '0.3538', '0.7081', '0.6180', '0.4087']
his_acc_wo_na:  ['0.7682', '0.6999', '0.5270', '0.5486', '0.5244', '0.4618']
cur_acc des_wo_na:  ['0.7572', '0.6279', '0.3696', '0.6181', '0.5559', '0.3895']
his_acc des_wo_na:  ['0.7572', '0.6865', '0.5577', '0.5044', '0.4802', '0.4446']
cur_acc rrf_wo_na:  ['0.7673', '0.6422', '0.3889', '0.6517', '0.5830', '0.4266']
his_acc rrf_wo_na:  ['0.7673', '0.7028', '0.5615', '0.5218', '0.5084', '0.4555']
cur_acc_w_na:  ['0.6477', '0.4278', '0.3025', '0.5561', '0.4151', '0.2760']
his_acc_w_na:  ['0.6477', '0.5599', '0.4225', '0.4254', '0.3855', '0.3418']
cur_acc des_w_na:  ['0.6209', '0.4347', '0.3027', '0.4588', '0.3774', '0.2571']
his_acc des_w_na:  ['0.6209', '0.5071', '0.4249', '0.3632', '0.3387', '0.3098']
cur_acc rrf_w_na:  ['0.6317', '0.4534', '0.3218', '0.4936', '0.3980', '0.2801']
his_acc rrf_w_na:  ['0.6317', '0.5252', '0.4357', '0.3834', '0.3630', '0.3197']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 119.2869695CurrentTrain: epoch  0, batch     1 | loss: 102.3375672CurrentTrain: epoch  0, batch     2 | loss: 103.2128803CurrentTrain: epoch  0, batch     3 | loss: 91.2322081CurrentTrain: epoch  0, batch     4 | loss: 77.9515747CurrentTrain: epoch  1, batch     0 | loss: 75.4701308CurrentTrain: epoch  1, batch     1 | loss: 89.5779140CurrentTrain: epoch  1, batch     2 | loss: 90.8434238CurrentTrain: epoch  1, batch     3 | loss: 136.7142323CurrentTrain: epoch  1, batch     4 | loss: 48.7983511CurrentTrain: epoch  2, batch     0 | loss: 106.4940529CurrentTrain: epoch  2, batch     1 | loss: 104.3455284CurrentTrain: epoch  2, batch     2 | loss: 86.6860554CurrentTrain: epoch  2, batch     3 | loss: 70.9819919CurrentTrain: epoch  2, batch     4 | loss: 100.3848580CurrentTrain: epoch  3, batch     0 | loss: 101.2457247CurrentTrain: epoch  3, batch     1 | loss: 104.3246115CurrentTrain: epoch  3, batch     2 | loss: 83.6682193CurrentTrain: epoch  3, batch     3 | loss: 70.7611268CurrentTrain: epoch  3, batch     4 | loss: 56.1620579CurrentTrain: epoch  4, batch     0 | loss: 82.5230055CurrentTrain: epoch  4, batch     1 | loss: 79.4013535CurrentTrain: epoch  4, batch     2 | loss: 127.6261840CurrentTrain: epoch  4, batch     3 | loss: 83.8318267CurrentTrain: epoch  4, batch     4 | loss: 69.4748017CurrentTrain: epoch  5, batch     0 | loss: 100.0251678CurrentTrain: epoch  5, batch     1 | loss: 78.8851585CurrentTrain: epoch  5, batch     2 | loss: 101.9535409CurrentTrain: epoch  5, batch     3 | loss: 67.9006511CurrentTrain: epoch  5, batch     4 | loss: 55.5928905CurrentTrain: epoch  6, batch     0 | loss: 165.8260325CurrentTrain: epoch  6, batch     1 | loss: 68.6844741CurrentTrain: epoch  6, batch     2 | loss: 121.4458817CurrentTrain: epoch  6, batch     3 | loss: 66.0169803CurrentTrain: epoch  6, batch     4 | loss: 70.8028726CurrentTrain: epoch  7, batch     0 | loss: 97.6988075CurrentTrain: epoch  7, batch     1 | loss: 64.3874016CurrentTrain: epoch  7, batch     2 | loss: 96.0536583CurrentTrain: epoch  7, batch     3 | loss: 81.0943313CurrentTrain: epoch  7, batch     4 | loss: 71.0054720CurrentTrain: epoch  8, batch     0 | loss: 66.6660261CurrentTrain: epoch  8, batch     1 | loss: 76.1581030CurrentTrain: epoch  8, batch     2 | loss: 66.2222359CurrentTrain: epoch  8, batch     3 | loss: 164.5346318CurrentTrain: epoch  8, batch     4 | loss: 69.0831734CurrentTrain: epoch  9, batch     0 | loss: 75.6616032CurrentTrain: epoch  9, batch     1 | loss: 76.7252150CurrentTrain: epoch  9, batch     2 | loss: 121.5755668CurrentTrain: epoch  9, batch     3 | loss: 77.7010349CurrentTrain: epoch  9, batch     4 | loss: 66.8786479
MemoryTrain:  epoch  0, batch     0 | loss: 0.9933351MemoryTrain:  epoch  1, batch     0 | loss: 0.8819301MemoryTrain:  epoch  2, batch     0 | loss: 0.7453284MemoryTrain:  epoch  3, batch     0 | loss: 0.5798996MemoryTrain:  epoch  4, batch     0 | loss: 0.4411399MemoryTrain:  epoch  5, batch     0 | loss: 0.4173199MemoryTrain:  epoch  6, batch     0 | loss: 0.3582293MemoryTrain:  epoch  7, batch     0 | loss: 0.3047195MemoryTrain:  epoch  8, batch     0 | loss: 0.2724001MemoryTrain:  epoch  9, batch     0 | loss: 0.2466832

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.21951219512195122), 3: np.float64(0.686046511627907), 7: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.12345679012345678), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.544), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.7286821705426356), 40: np.float64(0.0)}
Micro-average F1 score: 0.41693121693121693
Weighted-average F1 score: 0.3753385533117051
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.21978021978021978), 3: np.float64(0.5882352941176471), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.12371134020618557), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.4740740740740741), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.7205882352941176), 36: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3502145922746781
Weighted-average F1 score: 0.3106867551954451
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.22950819672131148), 3: np.float64(0.6213592233009708), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.125), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.4701492537313433), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.7205882352941176), 40: np.float64(0.0)}
Micro-average F1 score: 0.36576576576576575
Weighted-average F1 score: 0.3266661078478121

F1 score per class: {0: np.float64(0.7941176470588235), 1: np.float64(0.16589861751152074), 2: np.float64(0.36363636363636365), 3: np.float64(0.4738955823293173), 4: np.float64(0.7530864197530864), 5: np.float64(0.8599033816425121), 6: np.float64(0.18487394957983194), 7: np.float64(0.018691588785046728), 8: np.float64(0.30357142857142855), 9: np.float64(0.7619047619047619), 10: np.float64(0.0392156862745098), 11: np.float64(0.0641025641025641), 12: np.float64(0.24719101123595505), 13: np.float64(0.07692307692307693), 14: np.float64(0.09900990099009901), 16: np.float64(0.2777777777777778), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5611510791366906), 20: np.float64(0.5873015873015873), 21: np.float64(0.06896551724137931), 22: np.float64(0.4594594594594595), 23: np.float64(0.5641025641025641), 24: np.float64(0.0), 26: np.float64(0.6492146596858639), 27: np.float64(0.0), 28: np.float64(0.07042253521126761), 29: np.float64(0.7860696517412935), 30: np.float64(0.8571428571428571), 31: np.float64(0.0), 32: np.float64(0.6666666666666666), 33: np.float64(0.3157894736842105), 34: np.float64(0.1902834008097166), 36: np.float64(0.41379310344827586), 39: np.float64(0.06451612903225806), 40: np.float64(0.1722488038277512)}
Micro-average F1 score: 0.3904990193942035
Weighted-average F1 score: 0.37347563653692806
F1 score per class: {0: np.float64(0.5818181818181818), 1: np.float64(0.1606425702811245), 2: np.float64(0.25925925925925924), 3: np.float64(0.38011695906432746), 4: np.float64(0.7544910179640718), 5: np.float64(0.6012658227848101), 6: np.float64(0.3804878048780488), 7: np.float64(0.02040816326530612), 8: np.float64(0.313588850174216), 9: np.float64(0.49504950495049505), 10: np.float64(0.12389380530973451), 11: np.float64(0.039735099337748346), 12: np.float64(0.28289473684210525), 13: np.float64(0.10526315789473684), 14: np.float64(0.09448818897637795), 16: np.float64(0.5970149253731343), 17: np.float64(0.0), 18: np.float64(0.043478260869565216), 19: np.float64(0.5249169435215947), 20: np.float64(0.6105263157894737), 21: np.float64(0.17142857142857143), 22: np.float64(0.37317784256559766), 23: np.float64(0.5806451612903226), 24: np.float64(0.05), 26: np.float64(0.6633165829145728), 27: np.float64(0.0), 28: np.float64(0.10869565217391304), 29: np.float64(0.7403314917127072), 30: np.float64(0.6363636363636364), 31: np.float64(0.07142857142857142), 32: np.float64(0.625), 33: np.float64(0.16216216216216217), 34: np.float64(0.2076271186440678), 36: np.float64(0.5234899328859061), 39: np.float64(0.21052631578947367), 40: np.float64(0.25862068965517243)}
Micro-average F1 score: 0.3797238372093023
Weighted-average F1 score: 0.3642997314786977
F1 score per class: {0: np.float64(0.6739130434782609), 1: np.float64(0.1686746987951807), 2: np.float64(0.3684210526315789), 3: np.float64(0.40894568690095845), 4: np.float64(0.7951807228915663), 5: np.float64(0.7322834645669292), 6: np.float64(0.3221476510067114), 7: np.float64(0.017857142857142856), 8: np.float64(0.30201342281879195), 9: np.float64(0.7246376811594203), 10: np.float64(0.057692307692307696), 11: np.float64(0.03614457831325301), 12: np.float64(0.3129251700680272), 13: np.float64(0.09090909090909091), 14: np.float64(0.09230769230769231), 16: np.float64(0.5), 17: np.float64(0.0), 18: np.float64(0.047619047619047616), 19: np.float64(0.5473684210526316), 20: np.float64(0.6138613861386139), 21: np.float64(0.06896551724137931), 22: np.float64(0.3673469387755102), 23: np.float64(0.6136363636363636), 24: np.float64(0.0), 26: np.float64(0.6666666666666666), 27: np.float64(0.0), 28: np.float64(0.10204081632653061), 29: np.float64(0.7431693989071039), 30: np.float64(0.7368421052631579), 31: np.float64(0.08695652173913043), 32: np.float64(0.6561264822134387), 33: np.float64(0.1935483870967742), 34: np.float64(0.19678714859437751), 36: np.float64(0.5), 39: np.float64(0.1111111111111111), 40: np.float64(0.24096385542168675)}
Micro-average F1 score: 0.3828889315173604
Weighted-average F1 score: 0.3627518991649043

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.11960132890365449), 2: np.float64(0.0), 3: np.float64(0.5315315315315315), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.1111111111111111), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.43729903536977494), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.5766871165644172), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2863372093023256
Weighted-average F1 score: 0.25441952769191123
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.12158054711246201), 2: np.float64(0.0), 3: np.float64(0.39634146341463417), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.11009174311926606), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.3710144927536232), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.5833333333333334), 36: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.22934232715008432
Weighted-average F1 score: 0.2048328588056835
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.1253731343283582), 2: np.float64(0.0), 3: np.float64(0.43243243243243246), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.1111111111111111), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.3631123919308357), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.5833333333333334), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2420989862850328
Weighted-average F1 score: 0.21719689746235907

F1 score per class: {0: np.float64(0.6206896551724138), 1: np.float64(0.08845208845208845), 2: np.float64(0.2), 3: np.float64(0.29873417721518986), 4: np.float64(0.7052023121387283), 5: np.float64(0.7325102880658436), 6: np.float64(0.1506849315068493), 7: np.float64(0.009259259259259259), 8: np.float64(0.19883040935672514), 9: np.float64(0.6857142857142857), 10: np.float64(0.038834951456310676), 11: np.float64(0.05952380952380952), 12: np.float64(0.16058394160583941), 13: np.float64(0.03389830508474576), 14: np.float64(0.08849557522123894), 16: np.float64(0.23255813953488372), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5288135593220339), 20: np.float64(0.30327868852459017), 21: np.float64(0.057971014492753624), 22: np.float64(0.3333333333333333), 23: np.float64(0.5057471264367817), 24: np.float64(0.0), 26: np.float64(0.5821596244131455), 27: np.float64(0.0), 28: np.float64(0.03571428571428571), 29: np.float64(0.6422764227642277), 30: np.float64(0.8108108108108109), 31: np.float64(0.0), 32: np.float64(0.49491525423728816), 33: np.float64(0.25), 34: np.float64(0.11338962605548854), 36: np.float64(0.32142857142857145), 39: np.float64(0.03389830508474576), 40: np.float64(0.13688212927756654)}
Micro-average F1 score: 0.2783040844851685
Weighted-average F1 score: 0.25507859174015673
F1 score per class: {0: np.float64(0.4413793103448276), 1: np.float64(0.08908685968819599), 2: np.float64(0.1728395061728395), 3: np.float64(0.22491349480968859), 4: np.float64(0.7159090909090909), 5: np.float64(0.4051172707889126), 6: np.float64(0.254071661237785), 7: np.float64(0.0106951871657754), 8: np.float64(0.18072289156626506), 9: np.float64(0.37593984962406013), 10: np.float64(0.11475409836065574), 11: np.float64(0.03680981595092025), 12: np.float64(0.1482758620689655), 13: np.float64(0.045454545454545456), 14: np.float64(0.08108108108108109), 16: np.float64(0.37383177570093457), 17: np.float64(0.0), 18: np.float64(0.03571428571428571), 19: np.float64(0.4831804281345566), 20: np.float64(0.3945578231292517), 21: np.float64(0.11612903225806452), 22: np.float64(0.2723404255319149), 23: np.float64(0.4462809917355372), 24: np.float64(0.0425531914893617), 26: np.float64(0.584070796460177), 27: np.float64(0.0), 28: np.float64(0.05555555555555555), 29: np.float64(0.6568627450980392), 30: np.float64(0.4666666666666667), 31: np.float64(0.04), 32: np.float64(0.4582210242587601), 33: np.float64(0.10526315789473684), 34: np.float64(0.12710765239948119), 36: np.float64(0.3333333333333333), 39: np.float64(0.10126582278481013), 40: np.float64(0.19480519480519481)}
Micro-average F1 score: 0.2584714321048726
Weighted-average F1 score: 0.2423555947493499
F1 score per class: {0: np.float64(0.5210084033613446), 1: np.float64(0.09071274298056156), 2: np.float64(0.2153846153846154), 3: np.float64(0.24150943396226415), 4: np.float64(0.7542857142857143), 5: np.float64(0.523943661971831), 6: np.float64(0.24615384615384617), 7: np.float64(0.008771929824561403), 8: np.float64(0.1782178217821782), 9: np.float64(0.6410256410256411), 10: np.float64(0.05504587155963303), 11: np.float64(0.032432432432432434), 12: np.float64(0.16112084063047286), 13: np.float64(0.041666666666666664), 14: np.float64(0.07894736842105263), 16: np.float64(0.4), 17: np.float64(0.0), 18: np.float64(0.04081632653061224), 19: np.float64(0.5114754098360655), 20: np.float64(0.38271604938271603), 21: np.float64(0.056074766355140186), 22: np.float64(0.2587268993839836), 23: np.float64(0.5142857142857142), 24: np.float64(0.0), 26: np.float64(0.5945945945945946), 27: np.float64(0.0), 28: np.float64(0.05128205128205128), 29: np.float64(0.6570048309178744), 30: np.float64(0.6363636363636364), 31: np.float64(0.05405405405405406), 32: np.float64(0.47564469914040114), 33: np.float64(0.13333333333333333), 34: np.float64(0.11965811965811966), 36: np.float64(0.34838709677419355), 39: np.float64(0.05555555555555555), 40: np.float64(0.18292682926829268)}
Micro-average F1 score: 0.2633245382585752
Weighted-average F1 score: 0.24229228800407238
cur_acc_wo_na:  ['0.7682', '0.5503', '0.3538', '0.7081', '0.6180', '0.4087', '0.4169']
his_acc_wo_na:  ['0.7682', '0.6999', '0.5270', '0.5486', '0.5244', '0.4618', '0.3905']
cur_acc des_wo_na:  ['0.7572', '0.6279', '0.3696', '0.6181', '0.5559', '0.3895', '0.3502']
his_acc des_wo_na:  ['0.7572', '0.6865', '0.5577', '0.5044', '0.4802', '0.4446', '0.3797']
cur_acc rrf_wo_na:  ['0.7673', '0.6422', '0.3889', '0.6517', '0.5830', '0.4266', '0.3658']
his_acc rrf_wo_na:  ['0.7673', '0.7028', '0.5615', '0.5218', '0.5084', '0.4555', '0.3829']
cur_acc_w_na:  ['0.6477', '0.4278', '0.3025', '0.5561', '0.4151', '0.2760', '0.2863']
his_acc_w_na:  ['0.6477', '0.5599', '0.4225', '0.4254', '0.3855', '0.3418', '0.2783']
cur_acc des_w_na:  ['0.6209', '0.4347', '0.3027', '0.4588', '0.3774', '0.2571', '0.2293']
his_acc des_w_na:  ['0.6209', '0.5071', '0.4249', '0.3632', '0.3387', '0.3098', '0.2585']
cur_acc rrf_w_na:  ['0.6317', '0.4534', '0.3218', '0.4936', '0.3980', '0.2801', '0.2421']
his_acc rrf_w_na:  ['0.6317', '0.5252', '0.4357', '0.3834', '0.3630', '0.3197', '0.2633']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 102.3897623CurrentTrain: epoch  0, batch     1 | loss: 120.7641618CurrentTrain: epoch  0, batch     2 | loss: 116.3973718CurrentTrain: epoch  0, batch     3 | loss: 54.7322214CurrentTrain: epoch  1, batch     0 | loss: 84.5238083CurrentTrain: epoch  1, batch     1 | loss: 108.8875752CurrentTrain: epoch  1, batch     2 | loss: 82.2499264CurrentTrain: epoch  1, batch     3 | loss: 75.0900802CurrentTrain: epoch  2, batch     0 | loss: 73.5365738CurrentTrain: epoch  2, batch     1 | loss: 85.9172824CurrentTrain: epoch  2, batch     2 | loss: 104.9271354CurrentTrain: epoch  2, batch     3 | loss: 54.9307527CurrentTrain: epoch  3, batch     0 | loss: 131.5353504CurrentTrain: epoch  3, batch     1 | loss: 65.8908963CurrentTrain: epoch  3, batch     2 | loss: 81.6359636CurrentTrain: epoch  3, batch     3 | loss: 67.5829375CurrentTrain: epoch  4, batch     0 | loss: 103.2771839CurrentTrain: epoch  4, batch     1 | loss: 123.9013661CurrentTrain: epoch  4, batch     2 | loss: 64.1902443CurrentTrain: epoch  4, batch     3 | loss: 46.4768007CurrentTrain: epoch  5, batch     0 | loss: 82.8077625CurrentTrain: epoch  5, batch     1 | loss: 73.5002474CurrentTrain: epoch  5, batch     2 | loss: 97.9977713CurrentTrain: epoch  5, batch     3 | loss: 65.8066663CurrentTrain: epoch  6, batch     0 | loss: 65.7173800CurrentTrain: epoch  6, batch     1 | loss: 68.5403360CurrentTrain: epoch  6, batch     2 | loss: 75.7217611CurrentTrain: epoch  6, batch     3 | loss: 68.4417665CurrentTrain: epoch  7, batch     0 | loss: 78.3841552CurrentTrain: epoch  7, batch     1 | loss: 97.5905526CurrentTrain: epoch  7, batch     2 | loss: 76.0942440CurrentTrain: epoch  7, batch     3 | loss: 43.5947866CurrentTrain: epoch  8, batch     0 | loss: 74.5784704CurrentTrain: epoch  8, batch     1 | loss: 76.6558684CurrentTrain: epoch  8, batch     2 | loss: 91.2210568CurrentTrain: epoch  8, batch     3 | loss: 82.8258194CurrentTrain: epoch  9, batch     0 | loss: 76.2539176CurrentTrain: epoch  9, batch     1 | loss: 74.5861284CurrentTrain: epoch  9, batch     2 | loss: 95.7242550CurrentTrain: epoch  9, batch     3 | loss: 49.3577514
MemoryTrain:  epoch  0, batch     0 | loss: 0.8108441MemoryTrain:  epoch  1, batch     0 | loss: 0.7614453MemoryTrain:  epoch  2, batch     0 | loss: 0.6206326MemoryTrain:  epoch  3, batch     0 | loss: 0.5010206MemoryTrain:  epoch  4, batch     0 | loss: 0.4701545MemoryTrain:  epoch  5, batch     0 | loss: 0.4055623MemoryTrain:  epoch  6, batch     0 | loss: 0.2818559MemoryTrain:  epoch  7, batch     0 | loss: 0.2782015MemoryTrain:  epoch  8, batch     0 | loss: 0.2440478MemoryTrain:  epoch  9, batch     0 | loss: 0.2359064

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.6666666666666666), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.3225806451612903), 28: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.8932038834951457), 37: np.float64(0.5714285714285714), 38: np.float64(0.6086956521739131), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.463519313304721
Weighted-average F1 score: 0.3610435818117357
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.631578947368421), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.5194805194805194), 26: np.float64(0.0), 28: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.8571428571428571), 36: np.float64(0.0), 37: np.float64(0.5), 38: np.float64(0.5769230769230769), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.40069686411149824
Weighted-average F1 score: 0.2863353663410105
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.6), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.5), 28: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.8490566037735849), 36: np.float64(0.0), 37: np.float64(0.5210084033613446), 38: np.float64(0.5769230769230769), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4352720450281426
Weighted-average F1 score: 0.3291679603976516

F1 score per class: {0: np.float64(0.7407407407407407), 1: np.float64(0.1685823754789272), 2: np.float64(0.21052631578947367), 3: np.float64(0.1897810218978102), 4: np.float64(0.7607361963190185), 5: np.float64(0.7931034482758621), 6: np.float64(0.15517241379310345), 7: np.float64(0.046511627906976744), 8: np.float64(0.3981042654028436), 9: np.float64(0.7164179104477612), 10: np.float64(0.019801980198019802), 11: np.float64(0.08196721311475409), 12: np.float64(0.08759124087591241), 13: np.float64(0.045454545454545456), 14: np.float64(0.09876543209876543), 15: np.float64(0.1518987341772152), 16: np.float64(0.5116279069767442), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5285714285714286), 20: np.float64(0.49230769230769234), 21: np.float64(0.07407407407407407), 22: np.float64(0.4394904458598726), 23: np.float64(0.4864864864864865), 24: np.float64(0.0), 25: np.float64(0.3225806451612903), 26: np.float64(0.6428571428571429), 27: np.float64(0.0), 28: np.float64(0.08421052631578947), 29: np.float64(0.77), 30: np.float64(0.8571428571428571), 31: np.float64(0.15384615384615385), 32: np.float64(0.6333333333333333), 33: np.float64(0.35294117647058826), 34: np.float64(0.2271062271062271), 35: np.float64(0.3205574912891986), 36: np.float64(0.136986301369863), 37: np.float64(0.15311004784688995), 38: np.float64(0.28), 39: np.float64(0.10810810810810811), 40: np.float64(0.20725388601036268)}
Micro-average F1 score: 0.35626441199077635
Weighted-average F1 score: 0.3494262561274308
F1 score per class: {0: np.float64(0.5230769230769231), 1: np.float64(0.1646090534979424), 2: np.float64(0.21212121212121213), 3: np.float64(0.34782608695652173), 4: np.float64(0.7790697674418605), 5: np.float64(0.536723163841808), 6: np.float64(0.3372093023255814), 7: np.float64(0.04054054054054054), 8: np.float64(0.3154121863799283), 9: np.float64(0.4132231404958678), 10: np.float64(0.10714285714285714), 11: np.float64(0.11842105263157894), 12: np.float64(0.23134328358208955), 13: np.float64(0.05714285714285714), 14: np.float64(0.10144927536231885), 15: np.float64(0.3), 16: np.float64(0.5945945945945946), 17: np.float64(0.0), 18: np.float64(0.10526315789473684), 19: np.float64(0.48615384615384616), 20: np.float64(0.4), 21: np.float64(0.15841584158415842), 22: np.float64(0.35492957746478876), 23: np.float64(0.6122448979591837), 24: np.float64(0.046511627906976744), 25: np.float64(0.49382716049382713), 26: np.float64(0.6376811594202898), 27: np.float64(0.0), 28: np.float64(0.08), 29: np.float64(0.7659574468085106), 30: np.float64(0.6153846153846154), 31: np.float64(0.07142857142857142), 32: np.float64(0.6199261992619927), 33: np.float64(0.14634146341463414), 34: np.float64(0.22018348623853212), 35: np.float64(0.33210332103321033), 36: np.float64(0.484375), 37: np.float64(0.12446351931330472), 38: np.float64(0.1986754966887417), 39: np.float64(0.14634146341463414), 40: np.float64(0.2575107296137339)}
Micro-average F1 score: 0.3427338572969641
Weighted-average F1 score: 0.32370984356055205
F1 score per class: {0: np.float64(0.6336633663366337), 1: np.float64(0.1732283464566929), 2: np.float64(0.36363636363636365), 3: np.float64(0.4074074074074074), 4: np.float64(0.8235294117647058), 5: np.float64(0.6863468634686347), 6: np.float64(0.3108108108108108), 7: np.float64(0.041379310344827586), 8: np.float64(0.31386861313868614), 9: np.float64(0.7142857142857143), 10: np.float64(0.057692307692307696), 11: np.float64(0.11920529801324503), 12: np.float64(0.2558139534883721), 13: np.float64(0.05), 14: np.float64(0.10606060606060606), 15: np.float64(0.21428571428571427), 16: np.float64(0.6), 17: np.float64(0.0), 18: np.float64(0.07407407407407407), 19: np.float64(0.512987012987013), 20: np.float64(0.4230769230769231), 21: np.float64(0.10989010989010989), 22: np.float64(0.34408602150537637), 23: np.float64(0.6136363636363636), 24: np.float64(0.0), 25: np.float64(0.48717948717948717), 26: np.float64(0.6666666666666666), 27: np.float64(0.0), 28: np.float64(0.08130081300813008), 29: np.float64(0.7539267015706806), 30: np.float64(0.75), 31: np.float64(0.09090909090909091), 32: np.float64(0.6287878787878788), 33: np.float64(0.1875), 34: np.float64(0.2188449848024316), 35: np.float64(0.3202846975088968), 36: np.float64(0.34951456310679613), 37: np.float64(0.13025210084033614), 38: np.float64(0.20689655172413793), 39: np.float64(0.08888888888888889), 40: np.float64(0.24793388429752067)}
Micro-average F1 score: 0.35130718954248363
Weighted-average F1 score: 0.3284301047610762

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.4), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.29850746268656714), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.736), 36: np.float64(0.0), 37: np.float64(0.5), 38: np.float64(0.56), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3302752293577982
Weighted-average F1 score: 0.2500256334222925
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.46153846153846156), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.4819277108433735), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.7692307692307693), 36: np.float64(0.0), 37: np.float64(0.4233576642335766), 38: np.float64(0.46875), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.279126213592233
Weighted-average F1 score: 0.1967369909084689
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.41379310344827586), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.4634146341463415), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.743801652892562), 36: np.float64(0.0), 37: np.float64(0.43661971830985913), 38: np.float64(0.47619047619047616), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.30486202365308807
Weighted-average F1 score: 0.22553590582225347

F1 score per class: {0: np.float64(0.5405405405405406), 1: np.float64(0.08943089430894309), 2: np.float64(0.13333333333333333), 3: np.float64(0.1368421052631579), 4: np.float64(0.7126436781609196), 5: np.float64(0.6501766784452296), 6: np.float64(0.1267605633802817), 7: np.float64(0.022813688212927757), 8: np.float64(0.2507462686567164), 9: np.float64(0.6575342465753424), 10: np.float64(0.019230769230769232), 11: np.float64(0.08), 12: np.float64(0.07058823529411765), 13: np.float64(0.024691358024691357), 14: np.float64(0.08602150537634409), 15: np.float64(0.07317073170731707), 16: np.float64(0.41509433962264153), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.49498327759197325), 20: np.float64(0.27586206896551724), 21: np.float64(0.06153846153846154), 22: np.float64(0.32935560859188545), 23: np.float64(0.4235294117647059), 24: np.float64(0.0), 25: np.float64(0.29411764705882354), 26: np.float64(0.5650224215246636), 27: np.float64(0.0), 28: np.float64(0.04371584699453552), 29: np.float64(0.6135458167330677), 30: np.float64(0.8108108108108109), 31: np.float64(0.09090909090909091), 32: np.float64(0.48717948717948717), 33: np.float64(0.2727272727272727), 34: np.float64(0.13247863247863248), 35: np.float64(0.1862348178137652), 36: np.float64(0.11764705882352941), 37: np.float64(0.10223642172523961), 38: np.float64(0.1686746987951807), 39: np.float64(0.06779661016949153), 40: np.float64(0.16806722689075632)}
Micro-average F1 score: 0.252795200436324
Weighted-average F1 score: 0.23575759757295622
F1 score per class: {0: np.float64(0.384180790960452), 1: np.float64(0.08771929824561403), 2: np.float64(0.13592233009708737), 3: np.float64(0.21052631578947367), 4: np.float64(0.7403314917127072), 5: np.float64(0.36259541984732824), 6: np.float64(0.23293172690763053), 7: np.float64(0.020761245674740483), 8: np.float64(0.17706237424547283), 9: np.float64(0.3048780487804878), 10: np.float64(0.09836065573770492), 11: np.float64(0.09782608695652174), 12: np.float64(0.12133072407045009), 13: np.float64(0.02631578947368421), 14: np.float64(0.07954545454545454), 15: np.float64(0.22641509433962265), 16: np.float64(0.36065573770491804), 17: np.float64(0.0), 18: np.float64(0.075), 19: np.float64(0.4328767123287671), 20: np.float64(0.26666666666666666), 21: np.float64(0.1038961038961039), 22: np.float64(0.26195426195426197), 23: np.float64(0.4316546762589928), 24: np.float64(0.037037037037037035), 25: np.float64(0.43010752688172044), 26: np.float64(0.5477178423236515), 27: np.float64(0.0), 28: np.float64(0.04405286343612335), 29: np.float64(0.6515837104072398), 30: np.float64(0.4050632911392405), 31: np.float64(0.03389830508474576), 32: np.float64(0.45652173913043476), 33: np.float64(0.08450704225352113), 34: np.float64(0.1306715063520871), 35: np.float64(0.21844660194174756), 36: np.float64(0.32460732984293195), 37: np.float64(0.07967032967032966), 38: np.float64(0.1276595744680851), 39: np.float64(0.0821917808219178), 40: np.float64(0.1875)}
Micro-average F1 score: 0.23051409618573798
Weighted-average F1 score: 0.21431320727333947
F1 score per class: {0: np.float64(0.46715328467153283), 1: np.float64(0.09243697478991597), 2: np.float64(0.19672131147540983), 3: np.float64(0.26112759643916916), 4: np.float64(0.7821229050279329), 5: np.float64(0.512396694214876), 6: np.float64(0.2358974358974359), 7: np.float64(0.02), 8: np.float64(0.1829787234042553), 9: np.float64(0.625), 10: np.float64(0.05504587155963303), 11: np.float64(0.09836065573770492), 12: np.float64(0.1306930693069307), 13: np.float64(0.024390243902439025), 14: np.float64(0.08139534883720931), 15: np.float64(0.13333333333333333), 16: np.float64(0.46153846153846156), 17: np.float64(0.0), 18: np.float64(0.05970149253731343), 19: np.float64(0.47023809523809523), 20: np.float64(0.2838709677419355), 21: np.float64(0.07751937984496124), 22: np.float64(0.2490272373540856), 23: np.float64(0.4864864864864865), 24: np.float64(0.0), 25: np.float64(0.4222222222222222), 26: np.float64(0.5764192139737991), 27: np.float64(0.0), 28: np.float64(0.04524886877828054), 29: np.float64(0.6371681415929203), 30: np.float64(0.5769230769230769), 31: np.float64(0.046511627906976744), 32: np.float64(0.47701149425287354), 33: np.float64(0.12244897959183673), 34: np.float64(0.13114754098360656), 35: np.float64(0.1939655172413793), 36: np.float64(0.2535211267605634), 37: np.float64(0.08244680851063829), 38: np.float64(0.1271186440677966), 39: np.float64(0.05333333333333334), 40: np.float64(0.18518518518518517)}
Micro-average F1 score: 0.23936762413716323
Weighted-average F1 score: 0.2185830942086923
cur_acc_wo_na:  ['0.7682', '0.5503', '0.3538', '0.7081', '0.6180', '0.4087', '0.4169', '0.4635']
his_acc_wo_na:  ['0.7682', '0.6999', '0.5270', '0.5486', '0.5244', '0.4618', '0.3905', '0.3563']
cur_acc des_wo_na:  ['0.7572', '0.6279', '0.3696', '0.6181', '0.5559', '0.3895', '0.3502', '0.4007']
his_acc des_wo_na:  ['0.7572', '0.6865', '0.5577', '0.5044', '0.4802', '0.4446', '0.3797', '0.3427']
cur_acc rrf_wo_na:  ['0.7673', '0.6422', '0.3889', '0.6517', '0.5830', '0.4266', '0.3658', '0.4353']
his_acc rrf_wo_na:  ['0.7673', '0.7028', '0.5615', '0.5218', '0.5084', '0.4555', '0.3829', '0.3513']
cur_acc_w_na:  ['0.6477', '0.4278', '0.3025', '0.5561', '0.4151', '0.2760', '0.2863', '0.3303']
his_acc_w_na:  ['0.6477', '0.5599', '0.4225', '0.4254', '0.3855', '0.3418', '0.2783', '0.2528']
cur_acc des_w_na:  ['0.6209', '0.4347', '0.3027', '0.4588', '0.3774', '0.2571', '0.2293', '0.2791']
his_acc des_w_na:  ['0.6209', '0.5071', '0.4249', '0.3632', '0.3387', '0.3098', '0.2585', '0.2305']
cur_acc rrf_w_na:  ['0.6317', '0.4534', '0.3218', '0.4936', '0.3980', '0.2801', '0.2421', '0.3049']
his_acc rrf_w_na:  ['0.6317', '0.5252', '0.4357', '0.3834', '0.3630', '0.3197', '0.2633', '0.2394']
----------END
his_acc mean_wo_na:  [0.7618 0.6542 0.5555 0.5228 0.4589 0.4309 0.3932 0.3735]
his_acc des mean_wo_na:  [0.7506 0.6468 0.5532 0.5015 0.44   0.4156 0.3817 0.3542]
his_acc rrf mean_wo_na:  [0.7643 0.6595 0.5615 0.5064 0.4495 0.423  0.3876 0.362 ]
his_acc mean_w_na:  [0.6425 0.5218 0.43   0.3892 0.3304 0.3116 0.2789 0.2654]
his_acc des mean_w_na:  [0.6089 0.4904 0.4106 0.3557 0.3009 0.2842 0.2591 0.2374]
his_acc rrf mean_w_na:  [0.6242 0.5051 0.4222 0.3634 0.3112 0.2927 0.2658 0.2453]
