#############params############
cuda
Task=Tacred, 5-shot
Encoding model: bert
pattern=hybridprompt
mem=1, margin=0.3, gen=0, gen_num=2
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'NA or unknown'])
CurrentTrain: epoch  0, batch     0 | loss: 260.6909352CurrentTrain: epoch  0, batch     1 | loss: 196.6768015CurrentTrain: epoch  0, batch     2 | loss: 187.2307392CurrentTrain: epoch  0, batch     3 | loss: 194.4124209CurrentTrain: epoch  0, batch     4 | loss: 200.5584525CurrentTrain: epoch  0, batch     5 | loss: 187.4505819CurrentTrain: epoch  0, batch     6 | loss: 227.8345084CurrentTrain: epoch  0, batch     7 | loss: 226.5831597CurrentTrain: epoch  0, batch     8 | loss: 187.0117034CurrentTrain: epoch  0, batch     9 | loss: 187.8540207CurrentTrain: epoch  0, batch    10 | loss: 145.6959548CurrentTrain: epoch  0, batch    11 | loss: 225.8835254CurrentTrain: epoch  0, batch    12 | loss: 206.3044904CurrentTrain: epoch  0, batch    13 | loss: 360.1189282CurrentTrain: epoch  0, batch    14 | loss: 217.5818261CurrentTrain: epoch  0, batch    15 | loss: 211.6422684CurrentTrain: epoch  0, batch    16 | loss: 191.8524395CurrentTrain: epoch  0, batch    17 | loss: 256.5509305CurrentTrain: epoch  0, batch    18 | loss: 210.6085312CurrentTrain: epoch  0, batch    19 | loss: 197.5107602CurrentTrain: epoch  0, batch    20 | loss: 296.9052790CurrentTrain: epoch  0, batch    21 | loss: 288.6609915CurrentTrain: epoch  0, batch    22 | loss: 365.2424527CurrentTrain: epoch  0, batch    23 | loss: 280.7785497CurrentTrain: epoch  0, batch    24 | loss: 210.4111986CurrentTrain: epoch  0, batch    25 | loss: 358.5172762CurrentTrain: epoch  0, batch    26 | loss: 191.6368258CurrentTrain: epoch  0, batch    27 | loss: 251.1078989CurrentTrain: epoch  0, batch    28 | loss: 281.1798731CurrentTrain: epoch  0, batch    29 | loss: 193.4756981CurrentTrain: epoch  0, batch    30 | loss: 294.7795018CurrentTrain: epoch  0, batch    31 | loss: 280.9148761CurrentTrain: epoch  0, batch    32 | loss: 248.5855752CurrentTrain: epoch  0, batch    33 | loss: 190.6512258CurrentTrain: epoch  0, batch    34 | loss: 287.8101888CurrentTrain: epoch  0, batch    35 | loss: 211.2344294CurrentTrain: epoch  0, batch    36 | loss: 204.4723047CurrentTrain: epoch  0, batch    37 | loss: 216.6064448CurrentTrain: epoch  0, batch    38 | loss: 209.1264841CurrentTrain: epoch  0, batch    39 | loss: 196.5306107CurrentTrain: epoch  0, batch    40 | loss: 256.1530427CurrentTrain: epoch  0, batch    41 | loss: 203.3515855CurrentTrain: epoch  0, batch    42 | loss: 196.6046614CurrentTrain: epoch  0, batch    43 | loss: 158.0465422CurrentTrain: epoch  0, batch    44 | loss: 216.2680118CurrentTrain: epoch  0, batch    45 | loss: 172.0531608CurrentTrain: epoch  0, batch    46 | loss: 240.8073205CurrentTrain: epoch  0, batch    47 | loss: 190.6856152CurrentTrain: epoch  0, batch    48 | loss: 230.3075874CurrentTrain: epoch  0, batch    49 | loss: 209.3171023CurrentTrain: epoch  0, batch    50 | loss: 229.0733010CurrentTrain: epoch  0, batch    51 | loss: 209.5807682CurrentTrain: epoch  0, batch    52 | loss: 229.7694887CurrentTrain: epoch  0, batch    53 | loss: 288.2295085CurrentTrain: epoch  0, batch    54 | loss: 256.3405033CurrentTrain: epoch  0, batch    55 | loss: 172.7572998CurrentTrain: epoch  0, batch    56 | loss: 196.4747599CurrentTrain: epoch  0, batch    57 | loss: 191.0408747CurrentTrain: epoch  0, batch    58 | loss: 189.5472120CurrentTrain: epoch  0, batch    59 | loss: 214.3753451CurrentTrain: epoch  0, batch    60 | loss: 190.5651553CurrentTrain: epoch  0, batch    61 | loss: 214.9467202CurrentTrain: epoch  0, batch    62 | loss: 195.2061788CurrentTrain: epoch  0, batch    63 | loss: 228.8943904CurrentTrain: epoch  0, batch    64 | loss: 209.4420192CurrentTrain: epoch  0, batch    65 | loss: 167.5474329CurrentTrain: epoch  0, batch    66 | loss: 200.8637224CurrentTrain: epoch  0, batch    67 | loss: 215.2063968CurrentTrain: epoch  0, batch    68 | loss: 196.1107562CurrentTrain: epoch  0, batch    69 | loss: 294.5017722CurrentTrain: epoch  0, batch    70 | loss: 256.6530342CurrentTrain: epoch  0, batch    71 | loss: 189.3183238CurrentTrain: epoch  0, batch    72 | loss: 222.3762804CurrentTrain: epoch  0, batch    73 | loss: 247.4620981CurrentTrain: epoch  0, batch    74 | loss: 280.2837111CurrentTrain: epoch  0, batch    75 | loss: 230.0807969CurrentTrain: epoch  0, batch    76 | loss: 237.7161109CurrentTrain: epoch  0, batch    77 | loss: 212.8644637CurrentTrain: epoch  0, batch    78 | loss: 245.8796184CurrentTrain: epoch  0, batch    79 | loss: 239.3837448CurrentTrain: epoch  0, batch    80 | loss: 193.2118111CurrentTrain: epoch  0, batch    81 | loss: 221.5629015CurrentTrain: epoch  0, batch    82 | loss: 246.6793842CurrentTrain: epoch  0, batch    83 | loss: 200.8134809CurrentTrain: epoch  0, batch    84 | loss: 229.8058558CurrentTrain: epoch  0, batch    85 | loss: 170.8798130CurrentTrain: epoch  0, batch    86 | loss: 261.9666988CurrentTrain: epoch  0, batch    87 | loss: 199.8832431CurrentTrain: epoch  0, batch    88 | loss: 202.3636313CurrentTrain: epoch  0, batch    89 | loss: 160.1023579CurrentTrain: epoch  0, batch    90 | loss: 220.7077668CurrentTrain: epoch  0, batch    91 | loss: 175.0148328CurrentTrain: epoch  0, batch    92 | loss: 193.3904822CurrentTrain: epoch  0, batch    93 | loss: 260.8207921CurrentTrain: epoch  0, batch    94 | loss: 193.6739982CurrentTrain: epoch  0, batch    95 | loss: 205.4110987CurrentTrain: epoch  1, batch     0 | loss: 193.1381499CurrentTrain: epoch  1, batch     1 | loss: 220.7646926CurrentTrain: epoch  1, batch     2 | loss: 200.3505665CurrentTrain: epoch  1, batch     3 | loss: 192.7205134CurrentTrain: epoch  1, batch     4 | loss: 196.3188698CurrentTrain: epoch  1, batch     5 | loss: 170.1138244CurrentTrain: epoch  1, batch     6 | loss: 220.6963319CurrentTrain: epoch  1, batch     7 | loss: 275.1127286CurrentTrain: epoch  1, batch     8 | loss: 189.5884089CurrentTrain: epoch  1, batch     9 | loss: 252.2689425CurrentTrain: epoch  1, batch    10 | loss: 196.2558757CurrentTrain: epoch  1, batch    11 | loss: 183.8615283CurrentTrain: epoch  1, batch    12 | loss: 169.5683294CurrentTrain: epoch  1, batch    13 | loss: 238.4962474CurrentTrain: epoch  1, batch    14 | loss: 213.5737922CurrentTrain: epoch  1, batch    15 | loss: 218.5402072CurrentTrain: epoch  1, batch    16 | loss: 281.6558268CurrentTrain: epoch  1, batch    17 | loss: 170.5862963CurrentTrain: epoch  1, batch    18 | loss: 185.9235262CurrentTrain: epoch  1, batch    19 | loss: 246.0211593CurrentTrain: epoch  1, batch    20 | loss: 291.8720923CurrentTrain: epoch  1, batch    21 | loss: 189.9781185CurrentTrain: epoch  1, batch    22 | loss: 189.1951806CurrentTrain: epoch  1, batch    23 | loss: 210.0813916CurrentTrain: epoch  1, batch    24 | loss: 276.4574377CurrentTrain: epoch  1, batch    25 | loss: 211.4946863CurrentTrain: epoch  1, batch    26 | loss: 168.0406425CurrentTrain: epoch  1, batch    27 | loss: 189.8126018CurrentTrain: epoch  1, batch    28 | loss: 162.5438307CurrentTrain: epoch  1, batch    29 | loss: 190.7717043CurrentTrain: epoch  1, batch    30 | loss: 223.2498333CurrentTrain: epoch  1, batch    31 | loss: 197.2695820CurrentTrain: epoch  1, batch    32 | loss: 251.3839308CurrentTrain: epoch  1, batch    33 | loss: 217.5013324CurrentTrain: epoch  1, batch    34 | loss: 200.8674215CurrentTrain: epoch  1, batch    35 | loss: 291.6160876CurrentTrain: epoch  1, batch    36 | loss: 204.9990886CurrentTrain: epoch  1, batch    37 | loss: 208.8339037CurrentTrain: epoch  1, batch    38 | loss: 201.8809473CurrentTrain: epoch  1, batch    39 | loss: 175.3504177CurrentTrain: epoch  1, batch    40 | loss: 157.3641400CurrentTrain: epoch  1, batch    41 | loss: 176.2615786CurrentTrain: epoch  1, batch    42 | loss: 204.1387049CurrentTrain: epoch  1, batch    43 | loss: 216.3386700CurrentTrain: epoch  1, batch    44 | loss: 279.3055383CurrentTrain: epoch  1, batch    45 | loss: 210.2635412CurrentTrain: epoch  1, batch    46 | loss: 251.4288556CurrentTrain: epoch  1, batch    47 | loss: 174.5731379CurrentTrain: epoch  1, batch    48 | loss: 215.6321524CurrentTrain: epoch  1, batch    49 | loss: 207.6471343CurrentTrain: epoch  1, batch    50 | loss: 202.8185026CurrentTrain: epoch  1, batch    51 | loss: 253.5390221CurrentTrain: epoch  1, batch    52 | loss: 246.4381456CurrentTrain: epoch  1, batch    53 | loss: 274.4353127CurrentTrain: epoch  1, batch    54 | loss: 198.2863226CurrentTrain: epoch  1, batch    55 | loss: 215.9399627CurrentTrain: epoch  1, batch    56 | loss: 200.2397604CurrentTrain: epoch  1, batch    57 | loss: 240.7462243CurrentTrain: epoch  1, batch    58 | loss: 210.2723851CurrentTrain: epoch  1, batch    59 | loss: 169.1151386CurrentTrain: epoch  1, batch    60 | loss: 195.4920529CurrentTrain: epoch  1, batch    61 | loss: 287.9226709CurrentTrain: epoch  1, batch    62 | loss: 290.8036159CurrentTrain: epoch  1, batch    63 | loss: 184.2303811CurrentTrain: epoch  1, batch    64 | loss: 194.2370807CurrentTrain: epoch  1, batch    65 | loss: 240.5713792CurrentTrain: epoch  1, batch    66 | loss: 173.6963936CurrentTrain: epoch  1, batch    67 | loss: 280.6841975CurrentTrain: epoch  1, batch    68 | loss: 167.1742268CurrentTrain: epoch  1, batch    69 | loss: 200.5519523CurrentTrain: epoch  1, batch    70 | loss: 167.5999944CurrentTrain: epoch  1, batch    71 | loss: 208.3295666CurrentTrain: epoch  1, batch    72 | loss: 241.8051830CurrentTrain: epoch  1, batch    73 | loss: 211.0169687CurrentTrain: epoch  1, batch    74 | loss: 226.3012322CurrentTrain: epoch  1, batch    75 | loss: 199.6194321CurrentTrain: epoch  1, batch    76 | loss: 223.5507810CurrentTrain: epoch  1, batch    77 | loss: 220.9563173CurrentTrain: epoch  1, batch    78 | loss: 195.9208661CurrentTrain: epoch  1, batch    79 | loss: 192.8483040CurrentTrain: epoch  1, batch    80 | loss: 159.4558601CurrentTrain: epoch  1, batch    81 | loss: 219.6975071CurrentTrain: epoch  1, batch    82 | loss: 161.5892713CurrentTrain: epoch  1, batch    83 | loss: 364.2720629CurrentTrain: epoch  1, batch    84 | loss: 227.9099700CurrentTrain: epoch  1, batch    85 | loss: 187.5449248CurrentTrain: epoch  1, batch    86 | loss: 164.6188949CurrentTrain: epoch  1, batch    87 | loss: 194.6698151CurrentTrain: epoch  1, batch    88 | loss: 242.9836537CurrentTrain: epoch  1, batch    89 | loss: 226.4629141CurrentTrain: epoch  1, batch    90 | loss: 168.4852295CurrentTrain: epoch  1, batch    91 | loss: 222.8507562CurrentTrain: epoch  1, batch    92 | loss: 200.9423296CurrentTrain: epoch  1, batch    93 | loss: 290.7502323CurrentTrain: epoch  1, batch    94 | loss: 202.5884630CurrentTrain: epoch  1, batch    95 | loss: 154.0301525CurrentTrain: epoch  2, batch     0 | loss: 171.4826982CurrentTrain: epoch  2, batch     1 | loss: 244.3617221CurrentTrain: epoch  2, batch     2 | loss: 206.9295275CurrentTrain: epoch  2, batch     3 | loss: 215.1824071CurrentTrain: epoch  2, batch     4 | loss: 270.8347263CurrentTrain: epoch  2, batch     5 | loss: 172.5475652CurrentTrain: epoch  2, batch     6 | loss: 274.8212443CurrentTrain: epoch  2, batch     7 | loss: 185.3541615CurrentTrain: epoch  2, batch     8 | loss: 225.0770746CurrentTrain: epoch  2, batch     9 | loss: 158.3359746CurrentTrain: epoch  2, batch    10 | loss: 224.2990215CurrentTrain: epoch  2, batch    11 | loss: 151.4744783CurrentTrain: epoch  2, batch    12 | loss: 158.2445941CurrentTrain: epoch  2, batch    13 | loss: 241.9694403CurrentTrain: epoch  2, batch    14 | loss: 240.4500039CurrentTrain: epoch  2, batch    15 | loss: 242.5750973CurrentTrain: epoch  2, batch    16 | loss: 205.0284410CurrentTrain: epoch  2, batch    17 | loss: 212.3111916CurrentTrain: epoch  2, batch    18 | loss: 191.9709279CurrentTrain: epoch  2, batch    19 | loss: 226.1063810CurrentTrain: epoch  2, batch    20 | loss: 173.9094498CurrentTrain: epoch  2, batch    21 | loss: 223.0774270CurrentTrain: epoch  2, batch    22 | loss: 186.5142747CurrentTrain: epoch  2, batch    23 | loss: 205.7441264CurrentTrain: epoch  2, batch    24 | loss: 194.7662440CurrentTrain: epoch  2, batch    25 | loss: 182.2934515CurrentTrain: epoch  2, batch    26 | loss: 208.1513715CurrentTrain: epoch  2, batch    27 | loss: 185.0716095CurrentTrain: epoch  2, batch    28 | loss: 240.1972378CurrentTrain: epoch  2, batch    29 | loss: 234.4477802CurrentTrain: epoch  2, batch    30 | loss: 215.4805583CurrentTrain: epoch  2, batch    31 | loss: 196.1792183CurrentTrain: epoch  2, batch    32 | loss: 202.5818697CurrentTrain: epoch  2, batch    33 | loss: 257.7287130CurrentTrain: epoch  2, batch    34 | loss: 247.8715591CurrentTrain: epoch  2, batch    35 | loss: 226.7487914CurrentTrain: epoch  2, batch    36 | loss: 207.5614091CurrentTrain: epoch  2, batch    37 | loss: 221.3168468CurrentTrain: epoch  2, batch    38 | loss: 187.4958698CurrentTrain: epoch  2, batch    39 | loss: 240.1067485CurrentTrain: epoch  2, batch    40 | loss: 156.4988394CurrentTrain: epoch  2, batch    41 | loss: 248.2980020CurrentTrain: epoch  2, batch    42 | loss: 224.9438714CurrentTrain: epoch  2, batch    43 | loss: 181.5195671CurrentTrain: epoch  2, batch    44 | loss: 198.8128139CurrentTrain: epoch  2, batch    45 | loss: 189.2447782CurrentTrain: epoch  2, batch    46 | loss: 222.8487347CurrentTrain: epoch  2, batch    47 | loss: 181.9181779CurrentTrain: epoch  2, batch    48 | loss: 287.3352716CurrentTrain: epoch  2, batch    49 | loss: 282.2274207CurrentTrain: epoch  2, batch    50 | loss: 166.6564807CurrentTrain: epoch  2, batch    51 | loss: 291.3566348CurrentTrain: epoch  2, batch    52 | loss: 194.5175640CurrentTrain: epoch  2, batch    53 | loss: 215.0669768CurrentTrain: epoch  2, batch    54 | loss: 239.2360912CurrentTrain: epoch  2, batch    55 | loss: 213.2815390CurrentTrain: epoch  2, batch    56 | loss: 189.2300759CurrentTrain: epoch  2, batch    57 | loss: 166.0508189CurrentTrain: epoch  2, batch    58 | loss: 195.2211451CurrentTrain: epoch  2, batch    59 | loss: 182.8241967CurrentTrain: epoch  2, batch    60 | loss: 192.9753098CurrentTrain: epoch  2, batch    61 | loss: 169.4000941CurrentTrain: epoch  2, batch    62 | loss: 212.5417250CurrentTrain: epoch  2, batch    63 | loss: 172.7028083CurrentTrain: epoch  2, batch    64 | loss: 186.0914508CurrentTrain: epoch  2, batch    65 | loss: 197.7514986CurrentTrain: epoch  2, batch    66 | loss: 288.3364373CurrentTrain: epoch  2, batch    67 | loss: 236.2587812CurrentTrain: epoch  2, batch    68 | loss: 187.3092694CurrentTrain: epoch  2, batch    69 | loss: 169.6831218CurrentTrain: epoch  2, batch    70 | loss: 213.8262261CurrentTrain: epoch  2, batch    71 | loss: 184.9042684CurrentTrain: epoch  2, batch    72 | loss: 359.7266771CurrentTrain: epoch  2, batch    73 | loss: 209.1741613CurrentTrain: epoch  2, batch    74 | loss: 204.3906605CurrentTrain: epoch  2, batch    75 | loss: 191.5910738CurrentTrain: epoch  2, batch    76 | loss: 230.4981339CurrentTrain: epoch  2, batch    77 | loss: 163.3276674CurrentTrain: epoch  2, batch    78 | loss: 205.5248377CurrentTrain: epoch  2, batch    79 | loss: 205.8400007CurrentTrain: epoch  2, batch    80 | loss: 177.3303720CurrentTrain: epoch  2, batch    81 | loss: 212.2759239CurrentTrain: epoch  2, batch    82 | loss: 233.8445670CurrentTrain: epoch  2, batch    83 | loss: 250.3990699CurrentTrain: epoch  2, batch    84 | loss: 172.7117727CurrentTrain: epoch  2, batch    85 | loss: 262.4965587CurrentTrain: epoch  2, batch    86 | loss: 164.1182569CurrentTrain: epoch  2, batch    87 | loss: 170.4715044CurrentTrain: epoch  2, batch    88 | loss: 186.6205488CurrentTrain: epoch  2, batch    89 | loss: 200.9171708CurrentTrain: epoch  2, batch    90 | loss: 221.0429229CurrentTrain: epoch  2, batch    91 | loss: 204.7871404CurrentTrain: epoch  2, batch    92 | loss: 197.9602406CurrentTrain: epoch  2, batch    93 | loss: 207.6289627CurrentTrain: epoch  2, batch    94 | loss: 205.9805575CurrentTrain: epoch  2, batch    95 | loss: 154.8379015CurrentTrain: epoch  3, batch     0 | loss: 212.8515862CurrentTrain: epoch  3, batch     1 | loss: 223.7109454CurrentTrain: epoch  3, batch     2 | loss: 215.2763341CurrentTrain: epoch  3, batch     3 | loss: 213.9035738CurrentTrain: epoch  3, batch     4 | loss: 204.7923021CurrentTrain: epoch  3, batch     5 | loss: 230.8587398CurrentTrain: epoch  3, batch     6 | loss: 187.9991058CurrentTrain: epoch  3, batch     7 | loss: 172.3757309CurrentTrain: epoch  3, batch     8 | loss: 186.8309305CurrentTrain: epoch  3, batch     9 | loss: 259.7534472CurrentTrain: epoch  3, batch    10 | loss: 201.1975693CurrentTrain: epoch  3, batch    11 | loss: 195.8496347CurrentTrain: epoch  3, batch    12 | loss: 230.2808048CurrentTrain: epoch  3, batch    13 | loss: 230.0373314CurrentTrain: epoch  3, batch    14 | loss: 214.0560069CurrentTrain: epoch  3, batch    15 | loss: 231.0426046CurrentTrain: epoch  3, batch    16 | loss: 224.4197459CurrentTrain: epoch  3, batch    17 | loss: 169.8732420CurrentTrain: epoch  3, batch    18 | loss: 178.6444683CurrentTrain: epoch  3, batch    19 | loss: 200.1826046CurrentTrain: epoch  3, batch    20 | loss: 232.8668973CurrentTrain: epoch  3, batch    21 | loss: 189.1629907CurrentTrain: epoch  3, batch    22 | loss: 229.1169803CurrentTrain: epoch  3, batch    23 | loss: 196.9882775CurrentTrain: epoch  3, batch    24 | loss: 185.2345086CurrentTrain: epoch  3, batch    25 | loss: 206.8184455CurrentTrain: epoch  3, batch    26 | loss: 238.7767752CurrentTrain: epoch  3, batch    27 | loss: 251.0892434CurrentTrain: epoch  3, batch    28 | loss: 229.5923369CurrentTrain: epoch  3, batch    29 | loss: 193.1267231CurrentTrain: epoch  3, batch    30 | loss: 222.9834731CurrentTrain: epoch  3, batch    31 | loss: 194.2409489CurrentTrain: epoch  3, batch    32 | loss: 197.8441987CurrentTrain: epoch  3, batch    33 | loss: 276.7412210CurrentTrain: epoch  3, batch    34 | loss: 214.7858690CurrentTrain: epoch  3, batch    35 | loss: 268.0239212CurrentTrain: epoch  3, batch    36 | loss: 154.6053332CurrentTrain: epoch  3, batch    37 | loss: 269.8091373CurrentTrain: epoch  3, batch    38 | loss: 148.4709798CurrentTrain: epoch  3, batch    39 | loss: 205.1660124CurrentTrain: epoch  3, batch    40 | loss: 197.1115184CurrentTrain: epoch  3, batch    41 | loss: 182.3699475CurrentTrain: epoch  3, batch    42 | loss: 196.9564937CurrentTrain: epoch  3, batch    43 | loss: 169.0528116CurrentTrain: epoch  3, batch    44 | loss: 179.2004631CurrentTrain: epoch  3, batch    45 | loss: 194.0479779CurrentTrain: epoch  3, batch    46 | loss: 238.4793572CurrentTrain: epoch  3, batch    47 | loss: 213.3224518CurrentTrain: epoch  3, batch    48 | loss: 279.4190502CurrentTrain: epoch  3, batch    49 | loss: 178.1405257CurrentTrain: epoch  3, batch    50 | loss: 201.5593406CurrentTrain: epoch  3, batch    51 | loss: 192.6394272CurrentTrain: epoch  3, batch    52 | loss: 277.0812915CurrentTrain: epoch  3, batch    53 | loss: 186.6710846CurrentTrain: epoch  3, batch    54 | loss: 237.1747347CurrentTrain: epoch  3, batch    55 | loss: 189.3956146CurrentTrain: epoch  3, batch    56 | loss: 200.8930440CurrentTrain: epoch  3, batch    57 | loss: 194.9352447CurrentTrain: epoch  3, batch    58 | loss: 207.5865355CurrentTrain: epoch  3, batch    59 | loss: 266.6684414CurrentTrain: epoch  3, batch    60 | loss: 212.5308443CurrentTrain: epoch  3, batch    61 | loss: 179.4318671CurrentTrain: epoch  3, batch    62 | loss: 181.2528739CurrentTrain: epoch  3, batch    63 | loss: 214.6199501CurrentTrain: epoch  3, batch    64 | loss: 182.5300942CurrentTrain: epoch  3, batch    65 | loss: 233.0897501CurrentTrain: epoch  3, batch    66 | loss: 239.5910925CurrentTrain: epoch  3, batch    67 | loss: 199.5705351CurrentTrain: epoch  3, batch    68 | loss: 204.1648856CurrentTrain: epoch  3, batch    69 | loss: 184.8834512CurrentTrain: epoch  3, batch    70 | loss: 206.8459257CurrentTrain: epoch  3, batch    71 | loss: 143.9949781CurrentTrain: epoch  3, batch    72 | loss: 200.0471493CurrentTrain: epoch  3, batch    73 | loss: 141.9640317CurrentTrain: epoch  3, batch    74 | loss: 214.0697145CurrentTrain: epoch  3, batch    75 | loss: 238.8578414CurrentTrain: epoch  3, batch    76 | loss: 212.4896922CurrentTrain: epoch  3, batch    77 | loss: 214.9164490CurrentTrain: epoch  3, batch    78 | loss: 258.6853486CurrentTrain: epoch  3, batch    79 | loss: 181.6179827CurrentTrain: epoch  3, batch    80 | loss: 225.5650801CurrentTrain: epoch  3, batch    81 | loss: 143.6927601CurrentTrain: epoch  3, batch    82 | loss: 251.4732122CurrentTrain: epoch  3, batch    83 | loss: 191.5349027CurrentTrain: epoch  3, batch    84 | loss: 184.5754081CurrentTrain: epoch  3, batch    85 | loss: 233.1500039CurrentTrain: epoch  3, batch    86 | loss: 193.6791730CurrentTrain: epoch  3, batch    87 | loss: 222.0015375