#############params############
cuda
Task=Tacred, 5-shot
Encoding model: bert
pattern=hybridprompt
mem=1, margin=0.3, gen=0, gen_num=2
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 166.1926046CurrentTrain: epoch  0, batch     1 | loss: 126.6288487CurrentTrain: epoch  0, batch     2 | loss: 121.2833035CurrentTrain: epoch  0, batch     3 | loss: 127.6462198CurrentTrain: epoch  0, batch     4 | loss: 132.6859901CurrentTrain: epoch  0, batch     5 | loss: 121.7484435CurrentTrain: epoch  0, batch     6 | loss: 150.1367786CurrentTrain: epoch  0, batch     7 | loss: 145.7149288CurrentTrain: epoch  0, batch     8 | loss: 121.1363263CurrentTrain: epoch  0, batch     9 | loss: 121.6378960CurrentTrain: epoch  0, batch    10 | loss: 99.6249638CurrentTrain: epoch  0, batch    11 | loss: 144.3220179CurrentTrain: epoch  0, batch    12 | loss: 135.4945306CurrentTrain: epoch  0, batch    13 | loss: 217.3208324CurrentTrain: epoch  0, batch    14 | loss: 144.4384229CurrentTrain: epoch  0, batch    15 | loss: 134.8655788CurrentTrain: epoch  0, batch    16 | loss: 124.2897042CurrentTrain: epoch  0, batch    17 | loss: 162.4823018CurrentTrain: epoch  0, batch    18 | loss: 136.8866413CurrentTrain: epoch  0, batch    19 | loss: 130.2032495CurrentTrain: epoch  0, batch    20 | loss: 185.7754603CurrentTrain: epoch  0, batch    21 | loss: 185.7549813CurrentTrain: epoch  0, batch    22 | loss: 225.4886611CurrentTrain: epoch  0, batch    23 | loss: 187.3837319CurrentTrain: epoch  0, batch    24 | loss: 140.9244578CurrentTrain: epoch  0, batch    25 | loss: 220.1969497CurrentTrain: epoch  0, batch    26 | loss: 125.7038609CurrentTrain: epoch  0, batch    27 | loss: 158.6138748CurrentTrain: epoch  0, batch    28 | loss: 179.1520649CurrentTrain: epoch  0, batch    29 | loss: 127.0712324CurrentTrain: epoch  0, batch    30 | loss: 185.4118351CurrentTrain: epoch  0, batch    31 | loss: 177.3598944CurrentTrain: epoch  0, batch    32 | loss: 160.3456647CurrentTrain: epoch  0, batch    33 | loss: 123.1797019CurrentTrain: epoch  0, batch    34 | loss: 183.2685403CurrentTrain: epoch  0, batch    35 | loss: 135.2765733CurrentTrain: epoch  0, batch    36 | loss: 133.0426029CurrentTrain: epoch  0, batch    37 | loss: 139.8589075CurrentTrain: epoch  0, batch    38 | loss: 135.2928746CurrentTrain: epoch  0, batch    39 | loss: 126.5759927CurrentTrain: epoch  0, batch    40 | loss: 162.3230031CurrentTrain: epoch  0, batch    41 | loss: 130.9630237CurrentTrain: epoch  0, batch    42 | loss: 125.8061928CurrentTrain: epoch  0, batch    43 | loss: 111.2817354CurrentTrain: epoch  0, batch    44 | loss: 140.4004940CurrentTrain: epoch  0, batch    45 | loss: 113.7324126CurrentTrain: epoch  0, batch    46 | loss: 154.5406324CurrentTrain: epoch  0, batch    47 | loss: 125.7676108CurrentTrain: epoch  0, batch    48 | loss: 144.7855339CurrentTrain: epoch  0, batch    49 | loss: 135.6705763CurrentTrain: epoch  0, batch    50 | loss: 145.6030169CurrentTrain: epoch  0, batch    51 | loss: 138.7468571CurrentTrain: epoch  0, batch    52 | loss: 144.3024415CurrentTrain: epoch  0, batch    53 | loss: 181.0310185CurrentTrain: epoch  0, batch    54 | loss: 161.8764062CurrentTrain: epoch  0, batch    55 | loss: 114.6020396CurrentTrain: epoch  0, batch    56 | loss: 128.3947852CurrentTrain: epoch  0, batch    57 | loss: 127.0170145CurrentTrain: epoch  0, batch    58 | loss: 124.7681210CurrentTrain: epoch  0, batch    59 | loss: 137.3233710CurrentTrain: epoch  0, batch    60 | loss: 125.6515613CurrentTrain: epoch  0, batch    61 | loss: 137.2772209CurrentTrain: epoch  0, batch    62 | loss: 125.1932714CurrentTrain: epoch  0, batch    63 | loss: 146.8421232CurrentTrain: epoch  0, batch    64 | loss: 138.6054049CurrentTrain: epoch  0, batch    65 | loss: 113.1202266CurrentTrain: epoch  0, batch    66 | loss: 128.4531882CurrentTrain: epoch  0, batch    67 | loss: 138.1716922CurrentTrain: epoch  0, batch    68 | loss: 126.8528936CurrentTrain: epoch  0, batch    69 | loss: 182.2059091CurrentTrain: epoch  0, batch    70 | loss: 167.1453795CurrentTrain: epoch  0, batch    71 | loss: 124.1510079CurrentTrain: epoch  0, batch    72 | loss: 149.4787308CurrentTrain: epoch  0, batch    73 | loss: 159.2569376CurrentTrain: epoch  0, batch    74 | loss: 176.5891069CurrentTrain: epoch  0, batch    75 | loss: 144.1695211CurrentTrain: epoch  0, batch    76 | loss: 150.2961069CurrentTrain: epoch  0, batch    77 | loss: 135.1321947CurrentTrain: epoch  0, batch    78 | loss: 157.8330040CurrentTrain: epoch  0, batch    79 | loss: 151.8053374CurrentTrain: epoch  0, batch    80 | loss: 131.4448386CurrentTrain: epoch  0, batch    81 | loss: 138.7798325CurrentTrain: epoch  0, batch    82 | loss: 158.9694782CurrentTrain: epoch  0, batch    83 | loss: 130.3231048CurrentTrain: epoch  0, batch    84 | loss: 147.8623719CurrentTrain: epoch  0, batch    85 | loss: 112.5382377CurrentTrain: epoch  0, batch    86 | loss: 165.5836138CurrentTrain: epoch  0, batch    87 | loss: 127.5437262CurrentTrain: epoch  0, batch    88 | loss: 128.9042641CurrentTrain: epoch  0, batch    89 | loss: 102.1984046CurrentTrain: epoch  0, batch    90 | loss: 142.7714461CurrentTrain: epoch  0, batch    91 | loss: 115.5709073CurrentTrain: epoch  0, batch    92 | loss: 125.4953187CurrentTrain: epoch  0, batch    93 | loss: 170.1497165CurrentTrain: epoch  0, batch    94 | loss: 123.7772663CurrentTrain: epoch  0, batch    95 | loss: 129.7377687CurrentTrain: epoch  1, batch     0 | loss: 127.6735602CurrentTrain: epoch  1, batch     1 | loss: 139.7516951CurrentTrain: epoch  1, batch     2 | loss: 132.6547549CurrentTrain: epoch  1, batch     3 | loss: 121.9683632CurrentTrain: epoch  1, batch     4 | loss: 124.9192445CurrentTrain: epoch  1, batch     5 | loss: 110.8469746CurrentTrain: epoch  1, batch     6 | loss: 140.7415781CurrentTrain: epoch  1, batch     7 | loss: 171.5443421CurrentTrain: epoch  1, batch     8 | loss: 124.0090461CurrentTrain: epoch  1, batch     9 | loss: 154.1708546CurrentTrain: epoch  1, batch    10 | loss: 134.0607255CurrentTrain: epoch  1, batch    11 | loss: 121.0191135CurrentTrain: epoch  1, batch    12 | loss: 110.8083585CurrentTrain: epoch  1, batch    13 | loss: 152.9466537CurrentTrain: epoch  1, batch    14 | loss: 140.4246777CurrentTrain: epoch  1, batch    15 | loss: 138.5639296CurrentTrain: epoch  1, batch    16 | loss: 173.8549782CurrentTrain: epoch  1, batch    17 | loss: 114.2634900CurrentTrain: epoch  1, batch    18 | loss: 120.9102446CurrentTrain: epoch  1, batch    19 | loss: 156.4666717CurrentTrain: epoch  1, batch    20 | loss: 185.7260737CurrentTrain: epoch  1, batch    21 | loss: 121.6377726CurrentTrain: epoch  1, batch    22 | loss: 118.8424872CurrentTrain: epoch  1, batch    23 | loss: 135.9831924CurrentTrain: epoch  1, batch    24 | loss: 170.2900849CurrentTrain: epoch  1, batch    25 | loss: 135.0541701CurrentTrain: epoch  1, batch    26 | loss: 107.1018454CurrentTrain: epoch  1, batch    27 | loss: 121.1047547CurrentTrain: epoch  1, batch    28 | loss: 106.1014412CurrentTrain: epoch  1, batch    29 | loss: 115.7784863CurrentTrain: epoch  1, batch    30 | loss: 140.1802318CurrentTrain: epoch  1, batch    31 | loss: 125.9318163CurrentTrain: epoch  1, batch    32 | loss: 157.2861210CurrentTrain: epoch  1, batch    33 | loss: 147.5629993CurrentTrain: epoch  1, batch    34 | loss: 132.2859833CurrentTrain: epoch  1, batch    35 | loss: 179.6685218CurrentTrain: epoch  1, batch    36 | loss: 130.0560558CurrentTrain: epoch  1, batch    37 | loss: 131.5831736CurrentTrain: epoch  1, batch    38 | loss: 129.8665425CurrentTrain: epoch  1, batch    39 | loss: 109.0652036CurrentTrain: epoch  1, batch    40 | loss: 104.0191697CurrentTrain: epoch  1, batch    41 | loss: 111.9240980CurrentTrain: epoch  1, batch    42 | loss: 130.3408935CurrentTrain: epoch  1, batch    43 | loss: 133.9997490CurrentTrain: epoch  1, batch    44 | loss: 171.8720966CurrentTrain: epoch  1, batch    45 | loss: 131.9334663CurrentTrain: epoch  1, batch    46 | loss: 156.1294781CurrentTrain: epoch  1, batch    47 | loss: 110.1714881CurrentTrain: epoch  1, batch    48 | loss: 141.1438871CurrentTrain: epoch  1, batch    49 | loss: 132.3130015CurrentTrain: epoch  1, batch    50 | loss: 127.4962516CurrentTrain: epoch  1, batch    51 | loss: 161.1417531CurrentTrain: epoch  1, batch    52 | loss: 156.8048443CurrentTrain: epoch  1, batch    53 | loss: 173.9984047CurrentTrain: epoch  1, batch    54 | loss: 125.0111132CurrentTrain: epoch  1, batch    55 | loss: 135.9272540CurrentTrain: epoch  1, batch    56 | loss: 130.7573602CurrentTrain: epoch  1, batch    57 | loss: 158.2851670CurrentTrain: epoch  1, batch    58 | loss: 132.6462137CurrentTrain: epoch  1, batch    59 | loss: 108.5219541CurrentTrain: epoch  1, batch    60 | loss: 123.3767789CurrentTrain: epoch  1, batch    61 | loss: 175.6929541CurrentTrain: epoch  1, batch    62 | loss: 179.8730479CurrentTrain: epoch  1, batch    63 | loss: 114.2765272CurrentTrain: epoch  1, batch    64 | loss: 124.5855504CurrentTrain: epoch  1, batch    65 | loss: 151.0564969CurrentTrain: epoch  1, batch    66 | loss: 113.4168112CurrentTrain: epoch  1, batch    67 | loss: 180.9067917CurrentTrain: epoch  1, batch    68 | loss: 107.0314339CurrentTrain: epoch  1, batch    69 | loss: 126.6813601CurrentTrain: epoch  1, batch    70 | loss: 106.9719753CurrentTrain: epoch  1, batch    71 | loss: 128.7296275CurrentTrain: epoch  1, batch    72 | loss: 151.3694035CurrentTrain: epoch  1, batch    73 | loss: 133.7940473CurrentTrain: epoch  1, batch    74 | loss: 146.3065779CurrentTrain: epoch  1, batch    75 | loss: 125.1281988CurrentTrain: epoch  1, batch    76 | loss: 144.2996119CurrentTrain: epoch  1, batch    77 | loss: 142.3712957CurrentTrain: epoch  1, batch    78 | loss: 121.6817873CurrentTrain: epoch  1, batch    79 | loss: 127.4408036CurrentTrain: epoch  1, batch    80 | loss: 108.8034615CurrentTrain: epoch  1, batch    81 | loss: 140.3460918CurrentTrain: epoch  1, batch    82 | loss: 107.5160244CurrentTrain: epoch  1, batch    83 | loss: 215.4508126CurrentTrain: epoch  1, batch    84 | loss: 145.6381485CurrentTrain: epoch  1, batch    85 | loss: 115.2125819CurrentTrain: epoch  1, batch    86 | loss: 105.9560476CurrentTrain: epoch  1, batch    87 | loss: 123.9911113CurrentTrain: epoch  1, batch    88 | loss: 152.1951201CurrentTrain: epoch  1, batch    89 | loss: 139.8320105CurrentTrain: epoch  1, batch    90 | loss: 109.6261561CurrentTrain: epoch  1, batch    91 | loss: 141.1614958CurrentTrain: epoch  1, batch    92 | loss: 128.4701996CurrentTrain: epoch  1, batch    93 | loss: 178.0465424CurrentTrain: epoch  1, batch    94 | loss: 130.9771928CurrentTrain: epoch  1, batch    95 | loss: 99.3533202CurrentTrain: epoch  2, batch     0 | loss: 113.6547848CurrentTrain: epoch  2, batch     1 | loss: 149.6022886CurrentTrain: epoch  2, batch     2 | loss: 129.8471911CurrentTrain: epoch  2, batch     3 | loss: 135.3124473CurrentTrain: epoch  2, batch     4 | loss: 172.4150569CurrentTrain: epoch  2, batch     5 | loss: 111.7477176CurrentTrain: epoch  2, batch     6 | loss: 165.3148137CurrentTrain: epoch  2, batch     7 | loss: 117.7092428CurrentTrain: epoch  2, batch     8 | loss: 152.5131355CurrentTrain: epoch  2, batch     9 | loss: 99.2205937CurrentTrain: epoch  2, batch    10 | loss: 139.9388977CurrentTrain: epoch  2, batch    11 | loss: 97.7157246CurrentTrain: epoch  2, batch    12 | loss: 103.9897784CurrentTrain: epoch  2, batch    13 | loss: 149.1968159CurrentTrain: epoch  2, batch    14 | loss: 154.1198743CurrentTrain: epoch  2, batch    15 | loss: 152.1588202CurrentTrain: epoch  2, batch    16 | loss: 125.3108064CurrentTrain: epoch  2, batch    17 | loss: 135.3318005CurrentTrain: epoch  2, batch    18 | loss: 123.0530131CurrentTrain: epoch  2, batch    19 | loss: 140.0172406CurrentTrain: epoch  2, batch    20 | loss: 112.5844394CurrentTrain: epoch  2, batch    21 | loss: 140.5755542CurrentTrain: epoch  2, batch    22 | loss: 118.3428724CurrentTrain: epoch  2, batch    23 | loss: 129.8749870CurrentTrain: epoch  2, batch    24 | loss: 123.0672491CurrentTrain: epoch  2, batch    25 | loss: 118.9200520CurrentTrain: epoch  2, batch    26 | loss: 131.8750435CurrentTrain: epoch  2, batch    27 | loss: 114.8544634CurrentTrain: epoch  2, batch    28 | loss: 148.4157393CurrentTrain: epoch  2, batch    29 | loss: 144.6674614CurrentTrain: epoch  2, batch    30 | loss: 135.7420126CurrentTrain: epoch  2, batch    31 | loss: 128.7834704CurrentTrain: epoch  2, batch    32 | loss: 128.2532338CurrentTrain: epoch  2, batch    33 | loss: 155.5910224CurrentTrain: epoch  2, batch    34 | loss: 157.7795242CurrentTrain: epoch  2, batch    35 | loss: 140.0669417CurrentTrain: epoch  2, batch    36 | loss: 130.3395157CurrentTrain: epoch  2, batch    37 | loss: 138.3410540CurrentTrain: epoch  2, batch    38 | loss: 115.4818037CurrentTrain: epoch  2, batch    39 | loss: 148.8022020CurrentTrain: epoch  2, batch    40 | loss: 99.6884907CurrentTrain: epoch  2, batch    41 | loss: 156.5873499CurrentTrain: epoch  2, batch    42 | loss: 140.5316334CurrentTrain: epoch  2, batch    43 | loss: 114.5364396CurrentTrain: epoch  2, batch    44 | loss: 132.1542125CurrentTrain: epoch  2, batch    45 | loss: 116.1632240CurrentTrain: epoch  2, batch    46 | loss: 146.5045400CurrentTrain: epoch  2, batch    47 | loss: 117.4589725CurrentTrain: epoch  2, batch    48 | loss: 173.9297965CurrentTrain: epoch  2, batch    49 | loss: 172.2950536CurrentTrain: epoch  2, batch    50 | loss: 105.7328407CurrentTrain: epoch  2, batch    51 | loss: 178.5070553CurrentTrain: epoch  2, batch    52 | loss: 120.0619251CurrentTrain: epoch  2, batch    53 | loss: 133.9094012CurrentTrain: epoch  2, batch    54 | loss: 150.4795003CurrentTrain: epoch  2, batch    55 | loss: 132.2383989CurrentTrain: epoch  2, batch    56 | loss: 121.7389185CurrentTrain: epoch  2, batch    57 | loss: 104.4746534CurrentTrain: epoch  2, batch    58 | loss: 121.6101956CurrentTrain: epoch  2, batch    59 | loss: 112.8780080CurrentTrain: epoch  2, batch    60 | loss: 123.3448302CurrentTrain: epoch  2, batch    61 | loss: 107.0252730CurrentTrain: epoch  2, batch    62 | loss: 130.0035162CurrentTrain: epoch  2, batch    63 | loss: 108.5654122CurrentTrain: epoch  2, batch    64 | loss: 113.6427067CurrentTrain: epoch  2, batch    65 | loss: 123.2245709CurrentTrain: epoch  2, batch    66 | loss: 177.3939932CurrentTrain: epoch  2, batch    67 | loss: 144.9786701CurrentTrain: epoch  2, batch    68 | loss: 114.6974317CurrentTrain: epoch  2, batch    69 | loss: 110.3781813CurrentTrain: epoch  2, batch    70 | loss: 138.1272133CurrentTrain: epoch  2, batch    71 | loss: 115.5167636CurrentTrain: epoch  2, batch    72 | loss: 215.7836328CurrentTrain: epoch  2, batch    73 | loss: 130.3452483CurrentTrain: epoch  2, batch    74 | loss: 126.7465170CurrentTrain: epoch  2, batch    75 | loss: 120.1313495CurrentTrain: epoch  2, batch    76 | loss: 143.8614418CurrentTrain: epoch  2, batch    77 | loss: 105.1571752CurrentTrain: epoch  2, batch    78 | loss: 135.9085393CurrentTrain: epoch  2, batch    79 | loss: 129.6616600CurrentTrain: epoch  2, batch    80 | loss: 110.6482421CurrentTrain: epoch  2, batch    81 | loss: 133.1468948CurrentTrain: epoch  2, batch    82 | loss: 149.3774832CurrentTrain: epoch  2, batch    83 | loss: 157.1414394CurrentTrain: epoch  2, batch    84 | loss: 112.0340836CurrentTrain: epoch  2, batch    85 | loss: 165.3720105CurrentTrain: epoch  2, batch    86 | loss: 102.0868504CurrentTrain: epoch  2, batch    87 | loss: 105.7588122CurrentTrain: epoch  2, batch    88 | loss: 117.0636978CurrentTrain: epoch  2, batch    89 | loss: 129.8486266CurrentTrain: epoch  2, batch    90 | loss: 135.2992277CurrentTrain: epoch  2, batch    91 | loss: 125.7407493CurrentTrain: epoch  2, batch    92 | loss: 120.8929368CurrentTrain: epoch  2, batch    93 | loss: 130.3494173CurrentTrain: epoch  2, batch    94 | loss: 128.3211811CurrentTrain: epoch  2, batch    95 | loss: 99.7253830CurrentTrain: epoch  3, batch     0 | loss: 131.9588115CurrentTrain: epoch  3, batch     1 | loss: 138.4865381CurrentTrain: epoch  3, batch     2 | loss: 131.5219282CurrentTrain: epoch  3, batch     3 | loss: 134.3168683CurrentTrain: epoch  3, batch     4 | loss: 127.4693066CurrentTrain: epoch  3, batch     5 | loss: 139.8754839CurrentTrain: epoch  3, batch     6 | loss: 119.1455818CurrentTrain: epoch  3, batch     7 | loss: 105.0483614CurrentTrain: epoch  3, batch     8 | loss: 119.2717848CurrentTrain: epoch  3, batch     9 | loss: 159.3695873CurrentTrain: epoch  3, batch    10 | loss: 123.8362878CurrentTrain: epoch  3, batch    11 | loss: 120.8816449CurrentTrain: epoch  3, batch    12 | loss: 145.8971108CurrentTrain: epoch  3, batch    13 | loss: 142.5305718CurrentTrain: epoch  3, batch    14 | loss: 130.2309180CurrentTrain: epoch  3, batch    15 | loss: 143.7453120CurrentTrain: epoch  3, batch    16 | loss: 136.6874252CurrentTrain: epoch  3, batch    17 | loss: 110.0795911CurrentTrain: epoch  3, batch    18 | loss: 111.2495547CurrentTrain: epoch  3, batch    19 | loss: 122.9531389CurrentTrain: epoch  3, batch    20 | loss: 144.9404701CurrentTrain: epoch  3, batch    21 | loss: 118.7323250CurrentTrain: epoch  3, batch    22 | loss: 145.2287248CurrentTrain: epoch  3, batch    23 | loss: 126.4473597CurrentTrain: epoch  3, batch    24 | loss: 117.4971155CurrentTrain: epoch  3, batch    25 | loss: 130.4322928CurrentTrain: epoch  3, batch    26 | loss: 146.3153369CurrentTrain: epoch  3, batch    27 | loss: 153.4460497CurrentTrain: epoch  3, batch    28 | loss: 149.3793048CurrentTrain: epoch  3, batch    29 | loss: 119.1512417CurrentTrain: epoch  3, batch    30 | loss: 137.8970633CurrentTrain: epoch  3, batch    31 | loss: 121.6648603CurrentTrain: epoch  3, batch    32 | loss: 122.5560101CurrentTrain: epoch  3, batch    33 | loss: 171.0668437CurrentTrain: epoch  3, batch    34 | loss: 131.6354292CurrentTrain: epoch  3, batch    35 | loss: 171.4327725CurrentTrain: epoch  3, batch    36 | loss: 99.5577567CurrentTrain: epoch  3, batch    37 | loss: 166.9314375CurrentTrain: epoch  3, batch    38 | loss: 96.0756750CurrentTrain: epoch  3, batch    39 | loss: 130.6927438CurrentTrain: epoch  3, batch    40 | loss: 122.7385807CurrentTrain: epoch  3, batch    41 | loss: 116.1902271CurrentTrain: epoch  3, batch    42 | loss: 128.9464273CurrentTrain: epoch  3, batch    43 | loss: 109.1880599CurrentTrain: epoch  3, batch    44 | loss: 111.0808565CurrentTrain: epoch  3, batch    45 | loss: 119.1832331CurrentTrain: epoch  3, batch    46 | loss: 147.4296419CurrentTrain: epoch  3, batch    47 | loss: 133.1578001CurrentTrain: epoch  3, batch    48 | loss: 168.5204203CurrentTrain: epoch  3, batch    49 | loss: 108.6064649CurrentTrain: epoch  3, batch    50 | loss: 125.8722726CurrentTrain: epoch  3, batch    51 | loss: 122.1731410CurrentTrain: epoch  3, batch    52 | loss: 172.1476285CurrentTrain: epoch  3, batch    53 | loss: 117.0923985CurrentTrain: epoch  3, batch    54 | loss: 147.1675117CurrentTrain: epoch  3, batch    55 | loss: 118.0448741CurrentTrain: epoch  3, batch    56 | loss: 122.0905811CurrentTrain: epoch  3, batch    57 | loss: 121.2306529CurrentTrain: epoch  3, batch    58 | loss: 130.8609999CurrentTrain: epoch  3, batch    59 | loss: 162.4582330CurrentTrain: epoch  3, batch    60 | loss: 132.1946251CurrentTrain: epoch  3, batch    61 | loss: 114.5062909CurrentTrain: epoch  3, batch    62 | loss: 113.0922597CurrentTrain: epoch  3, batch    63 | loss: 138.0409379CurrentTrain: epoch  3, batch    64 | loss: 114.9498206CurrentTrain: epoch  3, batch    65 | loss: 145.5332841CurrentTrain: epoch  3, batch    66 | loss: 154.4997002CurrentTrain: epoch  3, batch    67 | loss: 121.2470076CurrentTrain: epoch  3, batch    68 | loss: 127.7049802CurrentTrain: epoch  3, batch    69 | loss: 112.5483402CurrentTrain: epoch  3, batch    70 | loss: 126.0662351CurrentTrain: epoch  3, batch    71 | loss: 90.7250160CurrentTrain: epoch  3, batch    72 | loss: 133.9128719CurrentTrain: epoch  3, batch    73 | loss: 89.7892413CurrentTrain: epoch  3, batch    74 | loss: 133.2944523CurrentTrain: epoch  3, batch    75 | loss: 148.9017067CurrentTrain: epoch  3, batch    76 | loss: 130.5217575CurrentTrain: epoch  3, batch    77 | loss: 133.8985671CurrentTrain: epoch  3, batch    78 | loss: 161.6348478CurrentTrain: epoch  3, batch    79 | loss: 114.8580865CurrentTrain: epoch  3, batch    80 | loss: 139.0626812CurrentTrain: epoch  3, batch    81 | loss: 93.8761465CurrentTrain: epoch  3, batch    82 | loss: 155.4337150CurrentTrain: epoch  3, batch    83 | loss: 122.3531597CurrentTrain: epoch  3, batch    84 | loss: 114.4264878CurrentTrain: epoch  3, batch    85 | loss: 147.3152810CurrentTrain: epoch  3, batch    86 | loss: 118.4675639CurrentTrain: epoch  3, batch    87 | loss: 133.8244309CurrentTrain: epoch  3, batch    88 | loss: 107.1237959CurrentTrain: epoch  3, batch    89 | loss: 103.3002608CurrentTrain: epoch  3, batch    90 | loss: 130.3559290CurrentTrain: epoch  3, batch    91 | loss: 137.2256282CurrentTrain: epoch  3, batch    92 | loss: 117.1227768CurrentTrain: epoch  3, batch    93 | loss: 126.5104116CurrentTrain: epoch  3, batch    94 | loss: 153.0519694CurrentTrain: epoch  3, batch    95 | loss: 85.9713696CurrentTrain: epoch  4, batch     0 | loss: 120.4297775CurrentTrain: epoch  4, batch     1 | loss: 150.1402097CurrentTrain: epoch  4, batch     2 | loss: 135.3904104CurrentTrain: epoch  4, batch     3 | loss: 109.1855981CurrentTrain: epoch  4, batch     4 | loss: 172.9621594CurrentTrain: epoch  4, batch     5 | loss: 135.2807412CurrentTrain: epoch  4, batch     6 | loss: 117.9120507CurrentTrain: epoch  4, batch     7 | loss: 107.6860142CurrentTrain: epoch  4, batch     8 | loss: 150.1790277CurrentTrain: epoch  4, batch     9 | loss: 168.0212891CurrentTrain: epoch  4, batch    10 | loss: 149.3286962CurrentTrain: epoch  4, batch    11 | loss: 116.9795487CurrentTrain: epoch  4, batch    12 | loss: 122.9166745CurrentTrain: epoch  4, batch    13 | loss: 112.1972832CurrentTrain: epoch  4, batch    14 | loss: 121.6493942CurrentTrain: epoch  4, batch    15 | loss: 145.4909867CurrentTrain: epoch  4, batch    16 | loss: 136.5656900CurrentTrain: epoch  4, batch    17 | loss: 168.8628089CurrentTrain: epoch  4, batch    18 | loss: 119.5662569CurrentTrain: epoch  4, batch    19 | loss: 122.2190427CurrentTrain: epoch  4, batch    20 | loss: 116.7315321CurrentTrain: epoch  4, batch    21 | loss: 120.7568661CurrentTrain: epoch  4, batch    22 | loss: 148.4022406CurrentTrain: epoch  4, batch    23 | loss: 108.1961074CurrentTrain: epoch  4, batch    24 | loss: 127.6941363CurrentTrain: epoch  4, batch    25 | loss: 140.9806379CurrentTrain: epoch  4, batch    26 | loss: 131.1101519CurrentTrain: epoch  4, batch    27 | loss: 118.4445071CurrentTrain: epoch  4, batch    28 | loss: 143.4566029CurrentTrain: epoch  4, batch    29 | loss: 124.1421791CurrentTrain: epoch  4, batch    30 | loss: 123.6858913CurrentTrain: epoch  4, batch    31 | loss: 115.0624597CurrentTrain: epoch  4, batch    32 | loss: 123.0839297CurrentTrain: epoch  4, batch    33 | loss: 95.4493462CurrentTrain: epoch  4, batch    34 | loss: 140.5198293CurrentTrain: epoch  4, batch    35 | loss: 132.6465723CurrentTrain: epoch  4, batch    36 | loss: 121.6779472CurrentTrain: epoch  4, batch    37 | loss: 109.6698847CurrentTrain: epoch  4, batch    38 | loss: 123.6861745CurrentTrain: epoch  4, batch    39 | loss: 120.2697576CurrentTrain: epoch  4, batch    40 | loss: 131.4097499CurrentTrain: epoch  4, batch    41 | loss: 114.6590668CurrentTrain: epoch  4, batch    42 | loss: 132.3570773CurrentTrain: epoch  4, batch    43 | loss: 99.8596310CurrentTrain: epoch  4, batch    44 | loss: 108.2883803CurrentTrain: epoch  4, batch    45 | loss: 129.8064566CurrentTrain: epoch  4, batch    46 | loss: 118.2007592CurrentTrain: epoch  4, batch    47 | loss: 134.4188046CurrentTrain: epoch  4, batch    48 | loss: 125.4050316CurrentTrain: epoch  4, batch    49 | loss: 127.1254967CurrentTrain: epoch  4, batch    50 | loss: 131.2633849CurrentTrain: epoch  4, batch    51 | loss: 117.2382992CurrentTrain: epoch  4, batch    52 | loss: 132.3263153CurrentTrain: epoch  4, batch    53 | loss: 161.3651966CurrentTrain: epoch  4, batch    54 | loss: 124.9031765CurrentTrain: epoch  4, batch    55 | loss: 146.5901592CurrentTrain: epoch  4, batch    56 | loss: 174.4432855CurrentTrain: epoch  4, batch    57 | loss: 112.7280349CurrentTrain: epoch  4, batch    58 | loss: 162.5325710CurrentTrain: epoch  4, batch    59 | loss: 141.4969865CurrentTrain: epoch  4, batch    60 | loss: 134.4056135CurrentTrain: epoch  4, batch    61 | loss: 107.7231959CurrentTrain: epoch  4, batch    62 | loss: 92.3725628CurrentTrain: epoch  4, batch    63 | loss: 112.6974765CurrentTrain: epoch  4, batch    64 | loss: 130.8534591CurrentTrain: epoch  4, batch    65 | loss: 165.4582937CurrentTrain: epoch  4, batch    66 | loss: 116.2119711CurrentTrain: epoch  4, batch    67 | loss: 113.6636096CurrentTrain: epoch  4, batch    68 | loss: 145.4262274CurrentTrain: epoch  4, batch    69 | loss: 109.7784403CurrentTrain: epoch  4, batch    70 | loss: 125.1068223CurrentTrain: epoch  4, batch    71 | loss: 139.4661221CurrentTrain: epoch  4, batch    72 | loss: 98.3679361CurrentTrain: epoch  4, batch    73 | loss: 119.1559933CurrentTrain: epoch  4, batch    74 | loss: 173.4476983CurrentTrain: epoch  4, batch    75 | loss: 126.0868529CurrentTrain: epoch  4, batch    76 | loss: 175.3837097CurrentTrain: epoch  4, batch    77 | loss: 138.9817473CurrentTrain: epoch  4, batch    78 | loss: 107.3993736CurrentTrain: epoch  4, batch    79 | loss: 145.2893120CurrentTrain: epoch  4, batch    80 | loss: 108.6666894CurrentTrain: epoch  4, batch    81 | loss: 168.7049318CurrentTrain: epoch  4, batch    82 | loss: 113.6424804CurrentTrain: epoch  4, batch    83 | loss: 111.7040811CurrentTrain: epoch  4, batch    84 | loss: 98.3551396CurrentTrain: epoch  4, batch    85 | loss: 128.7947410CurrentTrain: epoch  4, batch    86 | loss: 156.9219759CurrentTrain: epoch  4, batch    87 | loss: 159.9176412CurrentTrain: epoch  4, batch    88 | loss: 145.6629487CurrentTrain: epoch  4, batch    89 | loss: 111.4973325CurrentTrain: epoch  4, batch    90 | loss: 149.7104774CurrentTrain: epoch  4, batch    91 | loss: 129.8978185CurrentTrain: epoch  4, batch    92 | loss: 131.6057507CurrentTrain: epoch  4, batch    93 | loss: 115.9208059CurrentTrain: epoch  4, batch    94 | loss: 138.3732603CurrentTrain: epoch  4, batch    95 | loss: 99.8581166CurrentTrain: epoch  5, batch     0 | loss: 120.5041893CurrentTrain: epoch  5, batch     1 | loss: 118.2931360CurrentTrain: epoch  5, batch     2 | loss: 141.0834934CurrentTrain: epoch  5, batch     3 | loss: 127.0342741CurrentTrain: epoch  5, batch     4 | loss: 120.3346287CurrentTrain: epoch  5, batch     5 | loss: 108.0198298CurrentTrain: epoch  5, batch     6 | loss: 170.0987011CurrentTrain: epoch  5, batch     7 | loss: 112.6226160CurrentTrain: epoch  5, batch     8 | loss: 120.8624538CurrentTrain: epoch  5, batch     9 | loss: 114.0644647CurrentTrain: epoch  5, batch    10 | loss: 117.3031388CurrentTrain: epoch  5, batch    11 | loss: 147.6855304CurrentTrain: epoch  5, batch    12 | loss: 172.0574016CurrentTrain: epoch  5, batch    13 | loss: 110.2113604CurrentTrain: epoch  5, batch    14 | loss: 137.2041334CurrentTrain: epoch  5, batch    15 | loss: 102.9188645CurrentTrain: epoch  5, batch    16 | loss: 130.2661655CurrentTrain: epoch  5, batch    17 | loss: 101.1295853CurrentTrain: epoch  5, batch    18 | loss: 118.5465013CurrentTrain: epoch  5, batch    19 | loss: 150.7595182CurrentTrain: epoch  5, batch    20 | loss: 125.2791385CurrentTrain: epoch  5, batch    21 | loss: 102.9323908CurrentTrain: epoch  5, batch    22 | loss: 132.6480900CurrentTrain: epoch  5, batch    23 | loss: 132.2715263CurrentTrain: epoch  5, batch    24 | loss: 106.0719701CurrentTrain: epoch  5, batch    25 | loss: 125.1435186CurrentTrain: epoch  5, batch    26 | loss: 149.3888551CurrentTrain: epoch  5, batch    27 | loss: 132.0372823CurrentTrain: epoch  5, batch    28 | loss: 171.7292956CurrentTrain: epoch  5, batch    29 | loss: 272.2564450CurrentTrain: epoch  5, batch    30 | loss: 113.9391982CurrentTrain: epoch  5, batch    31 | loss: 193.7991113CurrentTrain: epoch  5, batch    32 | loss: 99.8697796CurrentTrain: epoch  5, batch    33 | loss: 104.3464609CurrentTrain: epoch  5, batch    34 | loss: 120.9801846CurrentTrain: epoch  5, batch    35 | loss: 92.4938544CurrentTrain: epoch  5, batch    36 | loss: 165.0018332CurrentTrain: epoch  5, batch    37 | loss: 120.8374226CurrentTrain: epoch  5, batch    38 | loss: 126.1358932CurrentTrain: epoch  5, batch    39 | loss: 148.6679030CurrentTrain: epoch  5, batch    40 | loss: 119.0787261CurrentTrain: epoch  5, batch    41 | loss: 148.3266094CurrentTrain: epoch  5, batch    42 | loss: 172.0407071CurrentTrain: epoch  5, batch    43 | loss: 116.9986011CurrentTrain: epoch  5, batch    44 | loss: 112.0520124CurrentTrain: epoch  5, batch    45 | loss: 129.3093625CurrentTrain: epoch  5, batch    46 | loss: 134.3412592CurrentTrain: epoch  5, batch    47 | loss: 105.3467516CurrentTrain: epoch  5, batch    48 | loss: 102.1513704CurrentTrain: epoch  5, batch    49 | loss: 117.7607092CurrentTrain: epoch  5, batch    50 | loss: 103.6531312CurrentTrain: epoch  5, batch    51 | loss: 117.1081667CurrentTrain: epoch  5, batch    52 | loss: 132.8086997CurrentTrain: epoch  5, batch    53 | loss: 108.8234646CurrentTrain: epoch  5, batch    54 | loss: 125.7152967CurrentTrain: epoch  5, batch    55 | loss: 150.4595370CurrentTrain: epoch  5, batch    56 | loss: 173.6351062CurrentTrain: epoch  5, batch    57 | loss: 137.8786140CurrentTrain: epoch  5, batch    58 | loss: 130.1298204CurrentTrain: epoch  5, batch    59 | loss: 164.5640189CurrentTrain: epoch  5, batch    60 | loss: 147.0027576CurrentTrain: epoch  5, batch    61 | loss: 121.8571417CurrentTrain: epoch  5, batch    62 | loss: 148.4136330CurrentTrain: epoch  5, batch    63 | loss: 123.4542295CurrentTrain: epoch  5, batch    64 | loss: 97.0132136CurrentTrain: epoch  5, batch    65 | loss: 108.1200628CurrentTrain: epoch  5, batch    66 | loss: 120.9912692CurrentTrain: epoch  5, batch    67 | loss: 116.4220293CurrentTrain: epoch  5, batch    68 | loss: 99.6510218CurrentTrain: epoch  5, batch    69 | loss: 122.3416831CurrentTrain: epoch  5, batch    70 | loss: 144.8956567CurrentTrain: epoch  5, batch    71 | loss: 150.4267467CurrentTrain: epoch  5, batch    72 | loss: 139.2182521CurrentTrain: epoch  5, batch    73 | loss: 105.6769973CurrentTrain: epoch  5, batch    74 | loss: 101.7300038CurrentTrain: epoch  5, batch    75 | loss: 111.8116143CurrentTrain: epoch  5, batch    76 | loss: 163.8387817CurrentTrain: epoch  5, batch    77 | loss: 130.0990059CurrentTrain: epoch  5, batch    78 | loss: 116.5485229CurrentTrain: epoch  5, batch    79 | loss: 122.2448941CurrentTrain: epoch  5, batch    80 | loss: 132.4968839CurrentTrain: epoch  5, batch    81 | loss: 142.3379888CurrentTrain: epoch  5, batch    82 | loss: 131.8555078CurrentTrain: epoch  5, batch    83 | loss: 147.2369455CurrentTrain: epoch  5, batch    84 | loss: 138.2647671CurrentTrain: epoch  5, batch    85 | loss: 132.6220791CurrentTrain: epoch  5, batch    86 | loss: 145.5206214CurrentTrain: epoch  5, batch    87 | loss: 103.6330459CurrentTrain: epoch  5, batch    88 | loss: 146.5842164CurrentTrain: epoch  5, batch    89 | loss: 119.0938384CurrentTrain: epoch  5, batch    90 | loss: 127.0720320CurrentTrain: epoch  5, batch    91 | loss: 135.3142665CurrentTrain: epoch  5, batch    92 | loss: 120.3325823CurrentTrain: epoch  5, batch    93 | loss: 107.1309845CurrentTrain: epoch  5, batch    94 | loss: 166.3768889CurrentTrain: epoch  5, batch    95 | loss: 105.4135016CurrentTrain: epoch  6, batch     0 | loss: 95.5249147CurrentTrain: epoch  6, batch     1 | loss: 122.9166103CurrentTrain: epoch  6, batch     2 | loss: 118.8981892CurrentTrain: epoch  6, batch     3 | loss: 148.4799352CurrentTrain: epoch  6, batch     4 | loss: 170.0703799CurrentTrain: epoch  6, batch     5 | loss: 202.5954291CurrentTrain: epoch  6, batch     6 | loss: 128.5799946CurrentTrain: epoch  6, batch     7 | loss: 131.1155434CurrentTrain: epoch  6, batch     8 | loss: 143.3348125CurrentTrain: epoch  6, batch     9 | loss: 133.6172200CurrentTrain: epoch  6, batch    10 | loss: 160.9092093CurrentTrain: epoch  6, batch    11 | loss: 128.8510575CurrentTrain: epoch  6, batch    12 | loss: 148.2043480CurrentTrain: epoch  6, batch    13 | loss: 139.0026528CurrentTrain: epoch  6, batch    14 | loss: 101.9069945CurrentTrain: epoch  6, batch    15 | loss: 108.2001203CurrentTrain: epoch  6, batch    16 | loss: 106.4719538CurrentTrain: epoch  6, batch    17 | loss: 133.4725789CurrentTrain: epoch  6, batch    18 | loss: 106.7504287CurrentTrain: epoch  6, batch    19 | loss: 114.5216833CurrentTrain: epoch  6, batch    20 | loss: 107.5634398CurrentTrain: epoch  6, batch    21 | loss: 127.4711901CurrentTrain: epoch  6, batch    22 | loss: 134.2752480CurrentTrain: epoch  6, batch    23 | loss: 132.3203753CurrentTrain: epoch  6, batch    24 | loss: 142.6363734CurrentTrain: epoch  6, batch    25 | loss: 103.9307783CurrentTrain: epoch  6, batch    26 | loss: 117.3345972CurrentTrain: epoch  6, batch    27 | loss: 111.3065726CurrentTrain: epoch  6, batch    28 | loss: 120.8542590CurrentTrain: epoch  6, batch    29 | loss: 130.1120111CurrentTrain: epoch  6, batch    30 | loss: 142.2748872CurrentTrain: epoch  6, batch    31 | loss: 96.2930017CurrentTrain: epoch  6, batch    32 | loss: 136.1745491CurrentTrain: epoch  6, batch    33 | loss: 139.8487150CurrentTrain: epoch  6, batch    34 | loss: 134.4342809CurrentTrain: epoch  6, batch    35 | loss: 106.5987841CurrentTrain: epoch  6, batch    36 | loss: 109.8614583CurrentTrain: epoch  6, batch    37 | loss: 124.0833391CurrentTrain: epoch  6, batch    38 | loss: 143.2517028CurrentTrain: epoch  6, batch    39 | loss: 116.7463272CurrentTrain: epoch  6, batch    40 | loss: 113.3110101CurrentTrain: epoch  6, batch    41 | loss: 130.2350227CurrentTrain: epoch  6, batch    42 | loss: 114.5944827CurrentTrain: epoch  6, batch    43 | loss: 106.6490352CurrentTrain: epoch  6, batch    44 | loss: 90.4803975CurrentTrain: epoch  6, batch    45 | loss: 128.9665101CurrentTrain: epoch  6, batch    46 | loss: 120.1777154CurrentTrain: epoch  6, batch    47 | loss: 171.1544014CurrentTrain: epoch  6, batch    48 | loss: 118.1184125CurrentTrain: epoch  6, batch    49 | loss: 107.8335838CurrentTrain: epoch  6, batch    50 | loss: 146.4176768CurrentTrain: epoch  6, batch    51 | loss: 139.6570714CurrentTrain: epoch  6, batch    52 | loss: 166.0273158CurrentTrain: epoch  6, batch    53 | loss: 148.0617858CurrentTrain: epoch  6, batch    54 | loss: 127.9894453CurrentTrain: epoch  6, batch    55 | loss: 128.2558636CurrentTrain: epoch  6, batch    56 | loss: 143.5755767CurrentTrain: epoch  6, batch    57 | loss: 92.5034237CurrentTrain: epoch  6, batch    58 | loss: 143.7673151CurrentTrain: epoch  6, batch    59 | loss: 104.0846360CurrentTrain: epoch  6, batch    60 | loss: 119.2229936CurrentTrain: epoch  6, batch    61 | loss: 134.1971845CurrentTrain: epoch  6, batch    62 | loss: 139.1298617CurrentTrain: epoch  6, batch    63 | loss: 115.0564430CurrentTrain: epoch  6, batch    64 | loss: 120.4451322CurrentTrain: epoch  6, batch    65 | loss: 145.8267104CurrentTrain: epoch  6, batch    66 | loss: 126.7170028CurrentTrain: epoch  6, batch    67 | loss: 126.2815606CurrentTrain: epoch  6, batch    68 | loss: 141.0513556CurrentTrain: epoch  6, batch    69 | loss: 119.8100059CurrentTrain: epoch  6, batch    70 | loss: 145.8441774CurrentTrain: epoch  6, batch    71 | loss: 101.8965367CurrentTrain: epoch  6, batch    72 | loss: 106.6898089CurrentTrain: epoch  6, batch    73 | loss: 96.9626916CurrentTrain: epoch  6, batch    74 | loss: 152.2018006CurrentTrain: epoch  6, batch    75 | loss: 141.8956363CurrentTrain: epoch  6, batch    76 | loss: 90.5398680CurrentTrain: epoch  6, batch    77 | loss: 102.0375022CurrentTrain: epoch  6, batch    78 | loss: 142.2007084CurrentTrain: epoch  6, batch    79 | loss: 137.0610476CurrentTrain: epoch  6, batch    80 | loss: 119.4025725CurrentTrain: epoch  6, batch    81 | loss: 99.5899997CurrentTrain: epoch  6, batch    82 | loss: 115.5068358CurrentTrain: epoch  6, batch    83 | loss: 129.4377129CurrentTrain: epoch  6, batch    84 | loss: 123.0372544CurrentTrain: epoch  6, batch    85 | loss: 99.4976463CurrentTrain: epoch  6, batch    86 | loss: 117.0996139CurrentTrain: epoch  6, batch    87 | loss: 137.2115331CurrentTrain: epoch  6, batch    88 | loss: 137.6675249CurrentTrain: epoch  6, batch    89 | loss: 150.1342416CurrentTrain: epoch  6, batch    90 | loss: 138.3134561CurrentTrain: epoch  6, batch    91 | loss: 100.5228334CurrentTrain: epoch  6, batch    92 | loss: 127.4073482CurrentTrain: epoch  6, batch    93 | loss: 117.9181922CurrentTrain: epoch  6, batch    94 | loss: 117.6380283CurrentTrain: epoch  6, batch    95 | loss: 127.0273853CurrentTrain: epoch  7, batch     0 | loss: 125.1834253CurrentTrain: epoch  7, batch     1 | loss: 136.9129854CurrentTrain: epoch  7, batch     2 | loss: 129.7923276CurrentTrain: epoch  7, batch     3 | loss: 124.3226157CurrentTrain: epoch  7, batch     4 | loss: 119.7845527CurrentTrain: epoch  7, batch     5 | loss: 142.6441466CurrentTrain: epoch  7, batch     6 | loss: 128.4102103CurrentTrain: epoch  7, batch     7 | loss: 120.7396224CurrentTrain: epoch  7, batch     8 | loss: 107.6575585CurrentTrain: epoch  7, batch     9 | loss: 102.8061228CurrentTrain: epoch  7, batch    10 | loss: 108.2793761CurrentTrain: epoch  7, batch    11 | loss: 111.4467128CurrentTrain: epoch  7, batch    12 | loss: 142.0475807CurrentTrain: epoch  7, batch    13 | loss: 128.6122759CurrentTrain: epoch  7, batch    14 | loss: 126.7178771CurrentTrain: epoch  7, batch    15 | loss: 121.1726250CurrentTrain: epoch  7, batch    16 | loss: 149.9205688CurrentTrain: epoch  7, batch    17 | loss: 101.0271603CurrentTrain: epoch  7, batch    18 | loss: 112.0963524CurrentTrain: epoch  7, batch    19 | loss: 101.8058465CurrentTrain: epoch  7, batch    20 | loss: 108.1419073CurrentTrain: epoch  7, batch    21 | loss: 112.9814714CurrentTrain: epoch  7, batch    22 | loss: 143.9020168CurrentTrain: epoch  7, batch    23 | loss: 135.7711757CurrentTrain: epoch  7, batch    24 | loss: 110.8290856CurrentTrain: epoch  7, batch    25 | loss: 96.5517393CurrentTrain: epoch  7, batch    26 | loss: 124.3184119CurrentTrain: epoch  7, batch    27 | loss: 146.2858482CurrentTrain: epoch  7, batch    28 | loss: 111.0031239CurrentTrain: epoch  7, batch    29 | loss: 147.8825174CurrentTrain: epoch  7, batch    30 | loss: 120.7959465CurrentTrain: epoch  7, batch    31 | loss: 131.9866674CurrentTrain: epoch  7, batch    32 | loss: 152.4950531CurrentTrain: epoch  7, batch    33 | loss: 127.5799693CurrentTrain: epoch  7, batch    34 | loss: 132.7317712CurrentTrain: epoch  7, batch    35 | loss: 142.7201691CurrentTrain: epoch  7, batch    36 | loss: 127.2428909CurrentTrain: epoch  7, batch    37 | loss: 138.3980824CurrentTrain: epoch  7, batch    38 | loss: 125.9119914CurrentTrain: epoch  7, batch    39 | loss: 154.6261821CurrentTrain: epoch  7, batch    40 | loss: 123.7632903CurrentTrain: epoch  7, batch    41 | loss: 100.9267158CurrentTrain: epoch  7, batch    42 | loss: 131.2486690CurrentTrain: epoch  7, batch    43 | loss: 108.7261728CurrentTrain: epoch  7, batch    44 | loss: 114.9771685CurrentTrain: epoch  7, batch    45 | loss: 141.0917933CurrentTrain: epoch  7, batch    46 | loss: 117.2420310CurrentTrain: epoch  7, batch    47 | loss: 110.9316847CurrentTrain: epoch  7, batch    48 | loss: 165.5112687CurrentTrain: epoch  7, batch    49 | loss: 103.9517340CurrentTrain: epoch  7, batch    50 | loss: 130.4868576CurrentTrain: epoch  7, batch    51 | loss: 110.2856298CurrentTrain: epoch  7, batch    52 | loss: 112.0754522CurrentTrain: epoch  7, batch    53 | loss: 138.2530728CurrentTrain: epoch  7, batch    54 | loss: 105.5403405CurrentTrain: epoch  7, batch    55 | loss: 145.7368031CurrentTrain: epoch  7, batch    56 | loss: 136.1832664CurrentTrain: epoch  7, batch    57 | loss: 131.0017862CurrentTrain: epoch  7, batch    58 | loss: 132.3146358CurrentTrain: epoch  7, batch    59 | loss: 166.7543438CurrentTrain: epoch  7, batch    60 | loss: 101.6324719CurrentTrain: epoch  7, batch    61 | loss: 116.0720789CurrentTrain: epoch  7, batch    62 | loss: 155.7976292CurrentTrain: epoch  7, batch    63 | loss: 119.5488084CurrentTrain: epoch  7, batch    64 | loss: 96.2946131CurrentTrain: epoch  7, batch    65 | loss: 109.7777266CurrentTrain: epoch  7, batch    66 | loss: 122.4333541CurrentTrain: epoch  7, batch    67 | loss: 131.7062837CurrentTrain: epoch  7, batch    68 | loss: 100.0130868CurrentTrain: epoch  7, batch    69 | loss: 122.1551481CurrentTrain: epoch  7, batch    70 | loss: 118.1496315CurrentTrain: epoch  7, batch    71 | loss: 144.1909569CurrentTrain: epoch  7, batch    72 | loss: 108.9451276CurrentTrain: epoch  7, batch    73 | loss: 121.6256699CurrentTrain: epoch  7, batch    74 | loss: 90.5892917CurrentTrain: epoch  7, batch    75 | loss: 103.4437673CurrentTrain: epoch  7, batch    76 | loss: 111.0606798CurrentTrain: epoch  7, batch    77 | loss: 143.2179071CurrentTrain: epoch  7, batch    78 | loss: 129.9271310CurrentTrain: epoch  7, batch    79 | loss: 167.6223112CurrentTrain: epoch  7, batch    80 | loss: 118.1247597CurrentTrain: epoch  7, batch    81 | loss: 105.7254501CurrentTrain: epoch  7, batch    82 | loss: 121.7989152CurrentTrain: epoch  7, batch    83 | loss: 98.7488110CurrentTrain: epoch  7, batch    84 | loss: 121.2272715CurrentTrain: epoch  7, batch    85 | loss: 139.0448264CurrentTrain: epoch  7, batch    86 | loss: 104.9820494CurrentTrain: epoch  7, batch    87 | loss: 141.8345926CurrentTrain: epoch  7, batch    88 | loss: 129.2725229CurrentTrain: epoch  7, batch    89 | loss: 158.6507063CurrentTrain: epoch  7, batch    90 | loss: 126.4349809CurrentTrain: epoch  7, batch    91 | loss: 120.9243254CurrentTrain: epoch  7, batch    92 | loss: 139.1680609CurrentTrain: epoch  7, batch    93 | loss: 104.5621932CurrentTrain: epoch  7, batch    94 | loss: 109.6267430CurrentTrain: epoch  7, batch    95 | loss: 122.9276897CurrentTrain: epoch  8, batch     0 | loss: 108.8338767CurrentTrain: epoch  8, batch     1 | loss: 104.4930087CurrentTrain: epoch  8, batch     2 | loss: 139.3262095CurrentTrain: epoch  8, batch     3 | loss: 175.7829134CurrentTrain: epoch  8, batch     4 | loss: 122.4649831CurrentTrain: epoch  8, batch     5 | loss: 119.9482994CurrentTrain: epoch  8, batch     6 | loss: 130.1896650CurrentTrain: epoch  8, batch     7 | loss: 115.6742778CurrentTrain: epoch  8, batch     8 | loss: 112.7255826CurrentTrain: epoch  8, batch     9 | loss: 142.0003475CurrentTrain: epoch  8, batch    10 | loss: 103.2247191CurrentTrain: epoch  8, batch    11 | loss: 113.7627013CurrentTrain: epoch  8, batch    12 | loss: 119.0961310CurrentTrain: epoch  8, batch    13 | loss: 127.0558554CurrentTrain: epoch  8, batch    14 | loss: 125.5927223CurrentTrain: epoch  8, batch    15 | loss: 123.4239819CurrentTrain: epoch  8, batch    16 | loss: 134.0787694CurrentTrain: epoch  8, batch    17 | loss: 131.1229640CurrentTrain: epoch  8, batch    18 | loss: 140.5758044CurrentTrain: epoch  8, batch    19 | loss: 110.5366130CurrentTrain: epoch  8, batch    20 | loss: 110.1119704CurrentTrain: epoch  8, batch    21 | loss: 111.8362327CurrentTrain: epoch  8, batch    22 | loss: 126.4005218CurrentTrain: epoch  8, batch    23 | loss: 112.9884741CurrentTrain: epoch  8, batch    24 | loss: 100.8882618CurrentTrain: epoch  8, batch    25 | loss: 134.6031954CurrentTrain: epoch  8, batch    26 | loss: 103.0969784CurrentTrain: epoch  8, batch    27 | loss: 118.0818683CurrentTrain: epoch  8, batch    28 | loss: 106.6135307CurrentTrain: epoch  8, batch    29 | loss: 112.9606740CurrentTrain: epoch  8, batch    30 | loss: 151.9336978CurrentTrain: epoch  8, batch    31 | loss: 92.1486931CurrentTrain: epoch  8, batch    32 | loss: 192.9313692CurrentTrain: epoch  8, batch    33 | loss: 151.5214424CurrentTrain: epoch  8, batch    34 | loss: 137.8225450CurrentTrain: epoch  8, batch    35 | loss: 100.7174679CurrentTrain: epoch  8, batch    36 | loss: 132.0712290CurrentTrain: epoch  8, batch    37 | loss: 114.7876406CurrentTrain: epoch  8, batch    38 | loss: 120.6765092CurrentTrain: epoch  8, batch    39 | loss: 129.1065830CurrentTrain: epoch  8, batch    40 | loss: 126.2560640CurrentTrain: epoch  8, batch    41 | loss: 144.7033598CurrentTrain: epoch  8, batch    42 | loss: 132.0550497CurrentTrain: epoch  8, batch    43 | loss: 150.7403640CurrentTrain: epoch  8, batch    44 | loss: 160.4513237CurrentTrain: epoch  8, batch    45 | loss: 128.5972569CurrentTrain: epoch  8, batch    46 | loss: 107.5640616CurrentTrain: epoch  8, batch    47 | loss: 127.5308075CurrentTrain: epoch  8, batch    48 | loss: 105.7200915CurrentTrain: epoch  8, batch    49 | loss: 115.5123616CurrentTrain: epoch  8, batch    50 | loss: 134.7503864CurrentTrain: epoch  8, batch    51 | loss: 102.4110842CurrentTrain: epoch  8, batch    52 | loss: 125.7143014CurrentTrain: epoch  8, batch    53 | loss: 149.6401086CurrentTrain: epoch  8, batch    54 | loss: 137.9108710CurrentTrain: epoch  8, batch    55 | loss: 135.3408806CurrentTrain: epoch  8, batch    56 | loss: 112.6791918CurrentTrain: epoch  8, batch    57 | loss: 110.6963467CurrentTrain: epoch  8, batch    58 | loss: 121.1967276CurrentTrain: epoch  8, batch    59 | loss: 86.7047812CurrentTrain: epoch  8, batch    60 | loss: 160.4889400CurrentTrain: epoch  8, batch    61 | loss: 139.2925954CurrentTrain: epoch  8, batch    62 | loss: 95.5144945CurrentTrain: epoch  8, batch    63 | loss: 124.9962270CurrentTrain: epoch  8, batch    64 | loss: 122.8178371CurrentTrain: epoch  8, batch    65 | loss: 118.7846730CurrentTrain: epoch  8, batch    66 | loss: 102.8019109CurrentTrain: epoch  8, batch    67 | loss: 127.6235232CurrentTrain: epoch  8, batch    68 | loss: 128.8756197CurrentTrain: epoch  8, batch    69 | loss: 128.4387672CurrentTrain: epoch  8, batch    70 | loss: 134.6757420CurrentTrain: epoch  8, batch    71 | loss: 152.8055830CurrentTrain: epoch  8, batch    72 | loss: 115.3345611CurrentTrain: epoch  8, batch    73 | loss: 127.5590625CurrentTrain: epoch  8, batch    74 | loss: 140.3376744CurrentTrain: epoch  8, batch    75 | loss: 120.3230557CurrentTrain: epoch  8, batch    76 | loss: 97.6334283CurrentTrain: epoch  8, batch    77 | loss: 157.8072565CurrentTrain: epoch  8, batch    78 | loss: 92.7641850CurrentTrain: epoch  8, batch    79 | loss: 119.1721674CurrentTrain: epoch  8, batch    80 | loss: 129.7098581CurrentTrain: epoch  8, batch    81 | loss: 128.1870214CurrentTrain: epoch  8, batch    82 | loss: 119.3454445CurrentTrain: epoch  8, batch    83 | loss: 105.3399391CurrentTrain: epoch  8, batch    84 | loss: 168.8201740CurrentTrain: epoch  8, batch    85 | loss: 151.3160688CurrentTrain: epoch  8, batch    86 | loss: 141.8393459CurrentTrain: epoch  8, batch    87 | loss: 121.1348819CurrentTrain: epoch  8, batch    88 | loss: 81.3494566CurrentTrain: epoch  8, batch    89 | loss: 117.7609763CurrentTrain: epoch  8, batch    90 | loss: 115.1436089CurrentTrain: epoch  8, batch    91 | loss: 132.5170883CurrentTrain: epoch  8, batch    92 | loss: 125.9354346CurrentTrain: epoch  8, batch    93 | loss: 124.6395040CurrentTrain: epoch  8, batch    94 | loss: 136.1396911CurrentTrain: epoch  8, batch    95 | loss: 132.7429584CurrentTrain: epoch  9, batch     0 | loss: 112.4786061CurrentTrain: epoch  9, batch     1 | loss: 151.9278594CurrentTrain: epoch  9, batch     2 | loss: 113.2108776CurrentTrain: epoch  9, batch     3 | loss: 108.6990223CurrentTrain: epoch  9, batch     4 | loss: 129.7097416CurrentTrain: epoch  9, batch     5 | loss: 87.7184968CurrentTrain: epoch  9, batch     6 | loss: 139.3659327CurrentTrain: epoch  9, batch     7 | loss: 116.3142314CurrentTrain: epoch  9, batch     8 | loss: 137.1864805CurrentTrain: epoch  9, batch     9 | loss: 104.3920764CurrentTrain: epoch  9, batch    10 | loss: 146.7537031CurrentTrain: epoch  9, batch    11 | loss: 114.3636312CurrentTrain: epoch  9, batch    12 | loss: 134.4105345CurrentTrain: epoch  9, batch    13 | loss: 146.6667436CurrentTrain: epoch  9, batch    14 | loss: 137.3989898CurrentTrain: epoch  9, batch    15 | loss: 111.0237980CurrentTrain: epoch  9, batch    16 | loss: 169.3616709CurrentTrain: epoch  9, batch    17 | loss: 124.5612934CurrentTrain: epoch  9, batch    18 | loss: 117.6894380CurrentTrain: epoch  9, batch    19 | loss: 129.0877431CurrentTrain: epoch  9, batch    20 | loss: 99.4430921CurrentTrain: epoch  9, batch    21 | loss: 137.4853189CurrentTrain: epoch  9, batch    22 | loss: 113.3657884CurrentTrain: epoch  9, batch    23 | loss: 112.0521346CurrentTrain: epoch  9, batch    24 | loss: 165.0585005CurrentTrain: epoch  9, batch    25 | loss: 133.3379138CurrentTrain: epoch  9, batch    26 | loss: 91.7161808CurrentTrain: epoch  9, batch    27 | loss: 151.1699543CurrentTrain: epoch  9, batch    28 | loss: 108.3640983CurrentTrain: epoch  9, batch    29 | loss: 110.4657554CurrentTrain: epoch  9, batch    30 | loss: 103.8392303CurrentTrain: epoch  9, batch    31 | loss: 119.5241634CurrentTrain: epoch  9, batch    32 | loss: 138.5621081CurrentTrain: epoch  9, batch    33 | loss: 115.4646369CurrentTrain: epoch  9, batch    34 | loss: 110.6993420CurrentTrain: epoch  9, batch    35 | loss: 156.0072688CurrentTrain: epoch  9, batch    36 | loss: 120.7470142CurrentTrain: epoch  9, batch    37 | loss: 125.0631488CurrentTrain: epoch  9, batch    38 | loss: 129.4827169CurrentTrain: epoch  9, batch    39 | loss: 114.7334045CurrentTrain: epoch  9, batch    40 | loss: 97.1930038CurrentTrain: epoch  9, batch    41 | loss: 128.5315484CurrentTrain: epoch  9, batch    42 | loss: 99.8955470CurrentTrain: epoch  9, batch    43 | loss: 98.7428749CurrentTrain: epoch  9, batch    44 | loss: 157.9249548CurrentTrain: epoch  9, batch    45 | loss: 116.3391032CurrentTrain: epoch  9, batch    46 | loss: 126.5695189CurrentTrain: epoch  9, batch    47 | loss: 144.7511781CurrentTrain: epoch  9, batch    48 | loss: 118.4118660CurrentTrain: epoch  9, batch    49 | loss: 111.5638981CurrentTrain: epoch  9, batch    50 | loss: 109.8182163CurrentTrain: epoch  9, batch    51 | loss: 123.0545128CurrentTrain: epoch  9, batch    52 | loss: 127.8249353CurrentTrain: epoch  9, batch    53 | loss: 126.2635532CurrentTrain: epoch  9, batch    54 | loss: 109.7955172CurrentTrain: epoch  9, batch    55 | loss: 105.1516467CurrentTrain: epoch  9, batch    56 | loss: 127.0082743CurrentTrain: epoch  9, batch    57 | loss: 89.6789114CurrentTrain: epoch  9, batch    58 | loss: 129.1323500CurrentTrain: epoch  9, batch    59 | loss: 140.9268820CurrentTrain: epoch  9, batch    60 | loss: 106.5554480CurrentTrain: epoch  9, batch    61 | loss: 95.0480067CurrentTrain: epoch  9, batch    62 | loss: 136.5131189CurrentTrain: epoch  9, batch    63 | loss: 95.1592620CurrentTrain: epoch  9, batch    64 | loss: 95.2068092CurrentTrain: epoch  9, batch    65 | loss: 136.6441783CurrentTrain: epoch  9, batch    66 | loss: 134.6517268CurrentTrain: epoch  9, batch    67 | loss: 117.2148052CurrentTrain: epoch  9, batch    68 | loss: 165.0434343CurrentTrain: epoch  9, batch    69 | loss: 143.2342859CurrentTrain: epoch  9, batch    70 | loss: 118.5261011CurrentTrain: epoch  9, batch    71 | loss: 141.2943652CurrentTrain: epoch  9, batch    72 | loss: 103.4374731CurrentTrain: epoch  9, batch    73 | loss: 141.6759086CurrentTrain: epoch  9, batch    74 | loss: 171.0009398CurrentTrain: epoch  9, batch    75 | loss: 142.2751340CurrentTrain: epoch  9, batch    76 | loss: 134.4955398CurrentTrain: epoch  9, batch    77 | loss: 107.0519865CurrentTrain: epoch  9, batch    78 | loss: 153.6183727CurrentTrain: epoch  9, batch    79 | loss: 118.4468360CurrentTrain: epoch  9, batch    80 | loss: 100.1968082CurrentTrain: epoch  9, batch    81 | loss: 91.4359023CurrentTrain: epoch  9, batch    82 | loss: 146.2955325CurrentTrain: epoch  9, batch    83 | loss: 164.7521154CurrentTrain: epoch  9, batch    84 | loss: 165.3694168CurrentTrain: epoch  9, batch    85 | loss: 111.0004195CurrentTrain: epoch  9, batch    86 | loss: 112.2890188CurrentTrain: epoch  9, batch    87 | loss: 107.6574816CurrentTrain: epoch  9, batch    88 | loss: 169.8790011CurrentTrain: epoch  9, batch    89 | loss: 101.1464457CurrentTrain: epoch  9, batch    90 | loss: 132.0305616CurrentTrain: epoch  9, batch    91 | loss: 117.7977871CurrentTrain: epoch  9, batch    92 | loss: 89.2654030CurrentTrain: epoch  9, batch    93 | loss: 107.0591970CurrentTrain: epoch  9, batch    94 | loss: 125.6828593CurrentTrain: epoch  9, batch    95 | loss: 95.6732504

F1 score per class: {32: np.float64(0.547486033519553), 6: np.float64(0.8516746411483254), 19: np.float64(0.42424242424242425), 24: np.float64(0.7301587301587301), 26: np.float64(0.9175257731958762), 29: np.float64(0.7947598253275109)}
Micro-average F1 score: 0.7628267182962246
Weighted-average F1 score: 0.7693264777255083
F1 score per class: {32: np.float64(0.6226415094339622), 6: np.float64(0.821917808219178), 19: np.float64(0.2318840579710145), 24: np.float64(0.6934673366834171), 26: np.float64(0.9253731343283582), 29: np.float64(0.8076923076923077)}
Micro-average F1 score: 0.740072202166065
Weighted-average F1 score: 0.7266387751199991
F1 score per class: {32: np.float64(0.6368159203980099), 6: np.float64(0.8256880733944955), 19: np.float64(0.32), 24: np.float64(0.6934673366834171), 26: np.float64(0.9292929292929293), 29: np.float64(0.8095238095238095)}
Micro-average F1 score: 0.758364312267658
Weighted-average F1 score: 0.7540523173310643

F1 score per class: {32: np.float64(0.547486033519553), 6: np.float64(0.8516746411483254), 19: np.float64(0.42424242424242425), 24: np.float64(0.7301587301587301), 26: np.float64(0.9175257731958762), 29: np.float64(0.7947598253275109)}
Micro-average F1 score: 0.7628267182962246
Weighted-average F1 score: 0.7693264777255083
F1 score per class: {32: np.float64(0.6226415094339622), 6: np.float64(0.821917808219178), 19: np.float64(0.2318840579710145), 24: np.float64(0.6934673366834171), 26: np.float64(0.9253731343283582), 29: np.float64(0.8076923076923077)}
Micro-average F1 score: 0.740072202166065
Weighted-average F1 score: 0.7266387751199991
F1 score per class: {32: np.float64(0.6368159203980099), 6: np.float64(0.8256880733944955), 19: np.float64(0.32), 24: np.float64(0.6934673366834171), 26: np.float64(0.9292929292929293), 29: np.float64(0.8095238095238095)}
Micro-average F1 score: 0.758364312267658
Weighted-average F1 score: 0.7540523173310643

F1 score per class: {32: np.float64(0.4224137931034483), 6: np.float64(0.8018018018018018), 19: np.float64(0.25), 24: np.float64(0.6602870813397129), 26: np.float64(0.8356807511737089), 29: np.float64(0.5852090032154341)}
Micro-average F1 score: 0.6339501206757844
Weighted-average F1 score: 0.6247734578435716
F1 score per class: {32: np.float64(0.42857142857142855), 6: np.float64(0.759493670886076), 19: np.float64(0.13675213675213677), 24: np.float64(0.6188340807174888), 26: np.float64(0.8340807174887892), 29: np.float64(0.6511627906976745)}
Micro-average F1 score: 0.6002928257686676
Weighted-average F1 score: 0.5758540008282027
F1 score per class: {32: np.float64(0.44912280701754387), 6: np.float64(0.7627118644067796), 19: np.float64(0.1927710843373494), 24: np.float64(0.6188340807174888), 26: np.float64(0.8363636363636363), 29: np.float64(0.6390977443609023)}
Micro-average F1 score: 0.6214775323686215
Weighted-average F1 score: 0.6061850404972234

F1 score per class: {32: np.float64(0.4224137931034483), 6: np.float64(0.8018018018018018), 19: np.float64(0.25), 24: np.float64(0.6602870813397129), 26: np.float64(0.8356807511737089), 29: np.float64(0.5852090032154341)}
Micro-average F1 score: 0.6339501206757844
Weighted-average F1 score: 0.6247734578435716
F1 score per class: {32: np.float64(0.42857142857142855), 6: np.float64(0.759493670886076), 19: np.float64(0.13675213675213677), 24: np.float64(0.6188340807174888), 26: np.float64(0.8340807174887892), 29: np.float64(0.6511627906976745)}
Micro-average F1 score: 0.6002928257686676
Weighted-average F1 score: 0.5758540008282027
F1 score per class: {32: np.float64(0.44912280701754387), 6: np.float64(0.7627118644067796), 19: np.float64(0.1927710843373494), 24: np.float64(0.6188340807174888), 26: np.float64(0.8363636363636363), 29: np.float64(0.6390977443609023)}
Micro-average F1 score: 0.6214775323686215
Weighted-average F1 score: 0.6061850404972234
cur_acc_wo_na:  ['0.7628']
his_acc_wo_na:  ['0.7628']
cur_acc des_wo_na:  ['0.7401']
his_acc des_wo_na:  ['0.7401']
cur_acc rrf_wo_na:  ['0.7584']
his_acc rrf_wo_na:  ['0.7584']
cur_acc_w_na:  ['0.6340']
his_acc_w_na:  ['0.6340']
cur_acc des_w_na:  ['0.6003']
his_acc des_w_na:  ['0.6003']
cur_acc rrf_w_na:  ['0.6215']
his_acc rrf_w_na:  ['0.6215']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 124.8016466CurrentTrain: epoch  0, batch     1 | loss: 183.3569236CurrentTrain: epoch  0, batch     2 | loss: 151.4691476CurrentTrain: epoch  0, batch     3 | loss: 150.8116555CurrentTrain: epoch  0, batch     4 | loss: 24.2088324CurrentTrain: epoch  1, batch     0 | loss: 154.5137093CurrentTrain: epoch  1, batch     1 | loss: 122.7328738CurrentTrain: epoch  1, batch     2 | loss: 158.1873889CurrentTrain: epoch  1, batch     3 | loss: 115.1912271CurrentTrain: epoch  1, batch     4 | loss: 32.0554771CurrentTrain: epoch  2, batch     0 | loss: 162.1818666CurrentTrain: epoch  2, batch     1 | loss: 126.5948756CurrentTrain: epoch  2, batch     2 | loss: 128.9842624CurrentTrain: epoch  2, batch     3 | loss: 126.5256539CurrentTrain: epoch  2, batch     4 | loss: 22.8364466CurrentTrain: epoch  3, batch     0 | loss: 121.0682258CurrentTrain: epoch  3, batch     1 | loss: 122.2244837CurrentTrain: epoch  3, batch     2 | loss: 135.7954439CurrentTrain: epoch  3, batch     3 | loss: 148.8809607CurrentTrain: epoch  3, batch     4 | loss: 31.9803967CurrentTrain: epoch  4, batch     0 | loss: 136.7657848CurrentTrain: epoch  4, batch     1 | loss: 149.6619427CurrentTrain: epoch  4, batch     2 | loss: 117.4158520CurrentTrain: epoch  4, batch     3 | loss: 139.4504278CurrentTrain: epoch  4, batch     4 | loss: 16.5556567CurrentTrain: epoch  5, batch     0 | loss: 122.2684809CurrentTrain: epoch  5, batch     1 | loss: 119.3163429CurrentTrain: epoch  5, batch     2 | loss: 117.5166113CurrentTrain: epoch  5, batch     3 | loss: 172.5440652CurrentTrain: epoch  5, batch     4 | loss: 19.9520868CurrentTrain: epoch  6, batch     0 | loss: 120.4425326CurrentTrain: epoch  6, batch     1 | loss: 142.7495787CurrentTrain: epoch  6, batch     2 | loss: 122.0302155CurrentTrain: epoch  6, batch     3 | loss: 133.1554986CurrentTrain: epoch  6, batch     4 | loss: 29.7514065CurrentTrain: epoch  7, batch     0 | loss: 159.0669251CurrentTrain: epoch  7, batch     1 | loss: 117.9836727CurrentTrain: epoch  7, batch     2 | loss: 141.3430287CurrentTrain: epoch  7, batch     3 | loss: 124.0869917CurrentTrain: epoch  7, batch     4 | loss: 18.2298245CurrentTrain: epoch  8, batch     0 | loss: 131.0097310CurrentTrain: epoch  8, batch     1 | loss: 109.1528153CurrentTrain: epoch  8, batch     2 | loss: 131.7220662CurrentTrain: epoch  8, batch     3 | loss: 158.1594106CurrentTrain: epoch  8, batch     4 | loss: 15.5268839CurrentTrain: epoch  9, batch     0 | loss: 126.4785956CurrentTrain: epoch  9, batch     1 | loss: 115.3902981CurrentTrain: epoch  9, batch     2 | loss: 115.4407546CurrentTrain: epoch  9, batch     3 | loss: 111.5777624CurrentTrain: epoch  9, batch     4 | loss: 46.8296246
MemoryTrain:  epoch  0, batch     0 | loss: 2.1734946MemoryTrain:  epoch  1, batch     0 | loss: 1.9692976MemoryTrain:  epoch  2, batch     0 | loss: 1.5832856MemoryTrain:  epoch  3, batch     0 | loss: 1.2735318MemoryTrain:  epoch  4, batch     0 | loss: 1.0625681MemoryTrain:  epoch  5, batch     0 | loss: 0.9178621MemoryTrain:  epoch  6, batch     0 | loss: 0.8101365MemoryTrain:  epoch  7, batch     0 | loss: 0.5778090MemoryTrain:  epoch  8, batch     0 | loss: 0.5463615MemoryTrain:  epoch  9, batch     0 | loss: 0.4401005

F1 score per class: {32: np.float64(0.631578947368421), 2: np.float64(0.0), 6: np.float64(0.582089552238806), 39: np.float64(0.5641025641025641), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.3448275862068966), 24: np.float64(0.0), 28: np.float64(0.3125)}
Micro-average F1 score: 0.4888888888888889
Weighted-average F1 score: 0.416924902025579
F1 score per class: {32: np.float64(0.64), 2: np.float64(0.0), 6: np.float64(0.6277372262773723), 39: np.float64(0.5232558139534884), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.35714285714285715), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.28)}
Micro-average F1 score: 0.4585987261146497
Weighted-average F1 score: 0.38054126918690295
F1 score per class: {32: np.float64(0.6666666666666666), 2: np.float64(0.0), 6: np.float64(0.5736434108527132), 39: np.float64(0.5061728395061729), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.29411764705882354), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.2857142857142857)}
Micro-average F1 score: 0.4383561643835616
Weighted-average F1 score: 0.35867193935101993

F1 score per class: {32: np.float64(0.5714285714285714), 2: np.float64(0.61), 6: np.float64(0.5416666666666666), 39: np.float64(0.44221105527638194), 11: np.float64(0.7659574468085106), 12: np.float64(0.3333333333333333), 19: np.float64(0.7344632768361582), 24: np.float64(0.1724137931034483), 26: np.float64(0.8539325842696629), 28: np.float64(0.7863247863247863), 29: np.float64(0.2564102564102564)}
Micro-average F1 score: 0.641781270464964
Weighted-average F1 score: 0.6290284902586772
F1 score per class: {32: np.float64(0.5517241379310345), 2: np.float64(0.6190476190476191), 6: np.float64(0.5733333333333334), 39: np.float64(0.3629032258064516), 11: np.float64(0.7338709677419355), 12: np.float64(0.20930232558139536), 19: np.float64(0.73224043715847), 24: np.float64(0.2), 26: np.float64(0.8842105263157894), 28: np.float64(0.7209302325581395), 29: np.float64(0.175)}
Micro-average F1 score: 0.5969976905311778
Weighted-average F1 score: 0.568284830856263
F1 score per class: {32: np.float64(0.6086956521739131), 2: np.float64(0.6019417475728155), 6: np.float64(0.524822695035461), 39: np.float64(0.36936936936936937), 11: np.float64(0.7368421052631579), 12: np.float64(0.2807017543859649), 19: np.float64(0.7292817679558011), 24: np.float64(0.16393442622950818), 26: np.float64(0.8888888888888888), 28: np.float64(0.7209302325581395), 29: np.float64(0.1791044776119403)}
Micro-average F1 score: 0.6053268765133172
Weighted-average F1 score: 0.5844156952252967

F1 score per class: {32: np.float64(0.41379310344827586), 2: np.float64(0.0), 6: np.float64(0.5064935064935064), 39: np.float64(0.4583333333333333), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.14705882352941177), 26: np.float64(0.0), 28: np.float64(0.18867924528301888)}
Micro-average F1 score: 0.35106382978723405
Weighted-average F1 score: 0.2900090438898726
F1 score per class: {32: np.float64(0.3902439024390244), 2: np.float64(0.0), 6: np.float64(0.5149700598802395), 39: np.float64(0.430622009569378), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.15384615384615385), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.16666666666666666)}
Micro-average F1 score: 0.32190760059612517
Weighted-average F1 score: 0.2666905665653702
F1 score per class: {32: np.float64(0.42424242424242425), 2: np.float64(0.0), 6: np.float64(0.46540880503144655), 39: np.float64(0.4079601990049751), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.136986301369863), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.16666666666666666)}
Micro-average F1 score: 0.3033175355450237
Weighted-average F1 score: 0.24879371906826359

F1 score per class: {32: np.float64(0.375), 2: np.float64(0.3973941368078176), 6: np.float64(0.4508670520231214), 39: np.float64(0.27586206896551724), 11: np.float64(0.703125), 12: np.float64(0.208955223880597), 19: np.float64(0.6770833333333334), 24: np.float64(0.08547008547008547), 26: np.float64(0.8), 28: np.float64(0.5679012345679012), 29: np.float64(0.15151515151515152)}
Micro-average F1 score: 0.47968673519334315
Weighted-average F1 score: 0.45041803615596077
F1 score per class: {32: np.float64(0.2962962962962963), 2: np.float64(0.3857566765578635), 6: np.float64(0.45989304812834225), 39: np.float64(0.23809523809523808), 11: np.float64(0.6642335766423357), 12: np.float64(0.11764705882352941), 19: np.float64(0.6568627450980392), 24: np.float64(0.1), 26: np.float64(0.8115942028985508), 28: np.float64(0.5360230547550432), 29: np.float64(0.09859154929577464)}
Micro-average F1 score: 0.43390684011749897
Weighted-average F1 score: 0.3993367356891664
F1 score per class: {32: np.float64(0.3783783783783784), 2: np.float64(0.37920489296636084), 6: np.float64(0.4157303370786517), 39: np.float64(0.23631123919308358), 11: np.float64(0.6642335766423357), 12: np.float64(0.17204301075268819), 19: np.float64(0.6567164179104478), 24: np.float64(0.08196721311475409), 26: np.float64(0.8155339805825242), 28: np.float64(0.5329512893982808), 29: np.float64(0.1)}
Micro-average F1 score: 0.44365572315882873
Weighted-average F1 score: 0.41289563174944205
cur_acc_wo_na:  ['0.7628', '0.4889']
his_acc_wo_na:  ['0.7628', '0.6418']
cur_acc des_wo_na:  ['0.7401', '0.4586']
his_acc des_wo_na:  ['0.7401', '0.5970']
cur_acc rrf_wo_na:  ['0.7584', '0.4384']
his_acc rrf_wo_na:  ['0.7584', '0.6053']
cur_acc_w_na:  ['0.6340', '0.3511']
his_acc_w_na:  ['0.6340', '0.4797']
cur_acc des_w_na:  ['0.6003', '0.3219']
his_acc des_w_na:  ['0.6003', '0.4339']
cur_acc rrf_w_na:  ['0.6215', '0.3033']
his_acc rrf_w_na:  ['0.6215', '0.4437']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 165.7194401CurrentTrain: epoch  0, batch     1 | loss: 109.9222867CurrentTrain: epoch  0, batch     2 | loss: 150.2504255CurrentTrain: epoch  0, batch     3 | loss: 11.1163277CurrentTrain: epoch  1, batch     0 | loss: 123.7618314CurrentTrain: epoch  1, batch     1 | loss: 109.6369792CurrentTrain: epoch  1, batch     2 | loss: 123.3875437CurrentTrain: epoch  1, batch     3 | loss: 14.8020048CurrentTrain: epoch  2, batch     0 | loss: 103.4971332CurrentTrain: epoch  2, batch     1 | loss: 130.0280466CurrentTrain: epoch  2, batch     2 | loss: 116.6429849CurrentTrain: epoch  2, batch     3 | loss: 15.8253899CurrentTrain: epoch  3, batch     0 | loss: 161.2232748CurrentTrain: epoch  3, batch     1 | loss: 123.3313386CurrentTrain: epoch  3, batch     2 | loss: 90.4893044CurrentTrain: epoch  3, batch     3 | loss: 18.6692047CurrentTrain: epoch  4, batch     0 | loss: 160.3970894CurrentTrain: epoch  4, batch     1 | loss: 98.6261739CurrentTrain: epoch  4, batch     2 | loss: 106.4836400CurrentTrain: epoch  4, batch     3 | loss: 7.2315775CurrentTrain: epoch  5, batch     0 | loss: 99.4619250CurrentTrain: epoch  5, batch     1 | loss: 127.1770535CurrentTrain: epoch  5, batch     2 | loss: 126.3639263CurrentTrain: epoch  5, batch     3 | loss: 11.1965136CurrentTrain: epoch  6, batch     0 | loss: 104.5493636CurrentTrain: epoch  6, batch     1 | loss: 121.6318770CurrentTrain: epoch  6, batch     2 | loss: 110.3632791CurrentTrain: epoch  6, batch     3 | loss: 20.4099685CurrentTrain: epoch  7, batch     0 | loss: 109.1824989CurrentTrain: epoch  7, batch     1 | loss: 126.1836562CurrentTrain: epoch  7, batch     2 | loss: 110.7605003CurrentTrain: epoch  7, batch     3 | loss: 13.0132571CurrentTrain: epoch  8, batch     0 | loss: 143.3493033CurrentTrain: epoch  8, batch     1 | loss: 115.5543297CurrentTrain: epoch  8, batch     2 | loss: 81.0853409CurrentTrain: epoch  8, batch     3 | loss: 9.6421012CurrentTrain: epoch  9, batch     0 | loss: 107.7457432CurrentTrain: epoch  9, batch     1 | loss: 129.9611720CurrentTrain: epoch  9, batch     2 | loss: 92.5014471CurrentTrain: epoch  9, batch     3 | loss: 12.5729224
MemoryTrain:  epoch  0, batch     0 | loss: 1.3097682MemoryTrain:  epoch  1, batch     0 | loss: 1.1410992MemoryTrain:  epoch  2, batch     0 | loss: 0.9543823MemoryTrain:  epoch  3, batch     0 | loss: 0.7822065MemoryTrain:  epoch  4, batch     0 | loss: 0.6465142MemoryTrain:  epoch  5, batch     0 | loss: 0.5627857MemoryTrain:  epoch  6, batch     0 | loss: 0.5141594MemoryTrain:  epoch  7, batch     0 | loss: 0.4403146MemoryTrain:  epoch  8, batch     0 | loss: 0.3563789MemoryTrain:  epoch  9, batch     0 | loss: 0.3312909

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5714285714285714), 7: np.float64(0.8888888888888888), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.38095238095238093), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.2857142857142857)}
Micro-average F1 score: 0.35335689045936397
Weighted-average F1 score: 0.293791678407063
F1 score per class: {32: np.float64(0.0), 2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7352941176470589), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.5217391304347826), 26: np.float64(0.0), 27: np.float64(0.3333333333333333), 28: np.float64(0.0), 31: np.float64(0.2753623188405797)}
Micro-average F1 score: 0.3161094224924012
Weighted-average F1 score: 0.2730625111520847
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7936507936507936), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.47619047619047616), 26: np.float64(0.0), 27: np.float64(0.3333333333333333), 28: np.float64(0.0), 31: np.float64(0.2695035460992908)}
Micro-average F1 score: 0.31746031746031744
Weighted-average F1 score: 0.26956067349843155

F1 score per class: {32: np.float64(0.4444444444444444), 2: np.float64(0.46987951807228917), 6: np.float64(0.05263157894736842), 7: np.float64(0.8888888888888888), 40: np.float64(0.49206349206349204), 11: np.float64(0.3026315789473684), 12: np.float64(0.636734693877551), 39: np.float64(0.16666666666666666), 9: np.float64(0.6946107784431138), 19: np.float64(0.25806451612903225), 24: np.float64(0.2631578947368421), 26: np.float64(0.8457142857142858), 27: np.float64(0.0), 28: np.float64(0.8), 29: np.float64(0.18181818181818182), 31: np.float64(0.15037593984962405)}
Micro-average F1 score: 0.5069328896283971
Weighted-average F1 score: 0.4696806070003181
F1 score per class: {32: np.float64(0.5517241379310345), 2: np.float64(0.47513812154696133), 6: np.float64(0.0), 7: np.float64(0.6944444444444444), 39: np.float64(0.6133333333333333), 40: np.float64(0.3438914027149321), 12: np.float64(0.610909090909091), 9: np.float64(0.20408163265306123), 11: np.float64(0.7344632768361582), 19: np.float64(0.3), 24: np.float64(0.1282051282051282), 26: np.float64(0.7831325301204819), 27: np.float64(0.12121212121212122), 28: np.float64(0.7634854771784232), 29: np.float64(0.2222222222222222), 31: np.float64(0.13380281690140844)}
Micro-average F1 score: 0.48773448773448774
Weighted-average F1 score: 0.44369085229877836
F1 score per class: {32: np.float64(0.5454545454545454), 2: np.float64(0.4725274725274725), 6: np.float64(0.0), 7: np.float64(0.78125), 39: np.float64(0.5652173913043478), 40: np.float64(0.34375), 12: np.float64(0.6153846153846154), 11: np.float64(0.18181818181818182), 9: np.float64(0.7314285714285714), 19: np.float64(0.23809523809523808), 24: np.float64(0.14925373134328357), 26: np.float64(0.7831325301204819), 27: np.float64(0.125), 28: np.float64(0.7711864406779662), 29: np.float64(0.2222222222222222), 31: np.float64(0.13058419243986255)}
Micro-average F1 score: 0.4909274193548387
Weighted-average F1 score: 0.44792187486891644

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.4444444444444444), 7: np.float64(0.8275862068965517), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 11: np.float64(0.0), 19: np.float64(0.38095238095238093), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.23391812865497075)}
Micro-average F1 score: 0.29673590504451036
Weighted-average F1 score: 0.2484382183746568
F1 score per class: {32: np.float64(0.0), 2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6578947368421053), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 11: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.4444444444444444), 26: np.float64(0.0), 27: np.float64(0.23529411764705882), 28: np.float64(0.0), 31: np.float64(0.21839080459770116)}
Micro-average F1 score: 0.2524271844660194
Weighted-average F1 score: 0.2207912621355359
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7352941176470589), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 11: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.4), 26: np.float64(0.0), 27: np.float64(0.2857142857142857), 28: np.float64(0.0), 31: np.float64(0.21468926553672316)}
Micro-average F1 score: 0.2604166666666667
Weighted-average F1 score: 0.22411871967870642

F1 score per class: {32: np.float64(0.3076923076923077), 2: np.float64(0.312), 6: np.float64(0.02877697841726619), 7: np.float64(0.8275862068965517), 40: np.float64(0.4305555555555556), 11: np.float64(0.21904761904761905), 12: np.float64(0.6), 39: np.float64(0.12903225806451613), 9: np.float64(0.6480446927374302), 19: np.float64(0.21052631578947367), 24: np.float64(0.125), 26: np.float64(0.7956989247311828), 27: np.float64(0.0), 28: np.float64(0.6360424028268551), 29: np.float64(0.11764705882352941), 31: np.float64(0.11204481792717087)}
Micro-average F1 score: 0.3970460469157255
Weighted-average F1 score: 0.35511499720411677
F1 score per class: {32: np.float64(0.32653061224489793), 2: np.float64(0.3161764705882353), 6: np.float64(0.0), 7: np.float64(0.6024096385542169), 39: np.float64(0.47668393782383417), 40: np.float64(0.22686567164179106), 12: np.float64(0.5656565656565656), 11: np.float64(0.13333333333333333), 9: np.float64(0.6701030927835051), 19: np.float64(0.19672131147540983), 24: np.float64(0.06060606060606061), 26: np.float64(0.7471264367816092), 27: np.float64(0.07142857142857142), 28: np.float64(0.5993485342019544), 29: np.float64(0.11267605633802817), 31: np.float64(0.09669211195928754)}
Micro-average F1 score: 0.36123975774848593
Weighted-average F1 score: 0.3206467786884831
F1 score per class: {32: np.float64(0.3333333333333333), 2: np.float64(0.3104693140794224), 6: np.float64(0.0), 7: np.float64(0.7142857142857143), 39: np.float64(0.4642857142857143), 40: np.float64(0.23487544483985764), 12: np.float64(0.5714285714285714), 11: np.float64(0.1276595744680851), 9: np.float64(0.6772486772486772), 19: np.float64(0.14925373134328357), 24: np.float64(0.07194244604316546), 26: np.float64(0.7471264367816092), 27: np.float64(0.08695652173913043), 28: np.float64(0.6026490066225165), 29: np.float64(0.12121212121212122), 31: np.float64(0.09429280397022333)}
Micro-average F1 score: 0.37076513132851163
Weighted-average F1 score: 0.32888242097111847
cur_acc_wo_na:  ['0.7628', '0.4889', '0.3534']
his_acc_wo_na:  ['0.7628', '0.6418', '0.5069']
cur_acc des_wo_na:  ['0.7401', '0.4586', '0.3161']
his_acc des_wo_na:  ['0.7401', '0.5970', '0.4877']
cur_acc rrf_wo_na:  ['0.7584', '0.4384', '0.3175']
his_acc rrf_wo_na:  ['0.7584', '0.6053', '0.4909']
cur_acc_w_na:  ['0.6340', '0.3511', '0.2967']
his_acc_w_na:  ['0.6340', '0.4797', '0.3970']
cur_acc des_w_na:  ['0.6003', '0.3219', '0.2524']
his_acc des_w_na:  ['0.6003', '0.4339', '0.3612']
cur_acc rrf_w_na:  ['0.6215', '0.3033', '0.2604']
his_acc rrf_w_na:  ['0.6215', '0.4437', '0.3708']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 121.3200994CurrentTrain: epoch  0, batch     1 | loss: 125.9550959CurrentTrain: epoch  0, batch     2 | loss: 154.7573892CurrentTrain: epoch  0, batch     3 | loss: 148.0828119CurrentTrain: epoch  1, batch     0 | loss: 115.6908009CurrentTrain: epoch  1, batch     1 | loss: 142.7890674CurrentTrain: epoch  1, batch     2 | loss: 122.9372506CurrentTrain: epoch  1, batch     3 | loss: 101.1863213CurrentTrain: epoch  2, batch     0 | loss: 124.9400197CurrentTrain: epoch  2, batch     1 | loss: 114.9579328CurrentTrain: epoch  2, batch     2 | loss: 112.6554091CurrentTrain: epoch  2, batch     3 | loss: 109.8886230CurrentTrain: epoch  3, batch     0 | loss: 138.0214052CurrentTrain: epoch  3, batch     1 | loss: 123.9281923CurrentTrain: epoch  3, batch     2 | loss: 124.9628398CurrentTrain: epoch  3, batch     3 | loss: 91.1922680CurrentTrain: epoch  4, batch     0 | loss: 120.6847527CurrentTrain: epoch  4, batch     1 | loss: 135.3695892CurrentTrain: epoch  4, batch     2 | loss: 159.8399414CurrentTrain: epoch  4, batch     3 | loss: 71.2409421CurrentTrain: epoch  5, batch     0 | loss: 141.7665619CurrentTrain: epoch  5, batch     1 | loss: 116.6260340CurrentTrain: epoch  5, batch     2 | loss: 135.3757663CurrentTrain: epoch  5, batch     3 | loss: 73.3751920CurrentTrain: epoch  6, batch     0 | loss: 162.0805000CurrentTrain: epoch  6, batch     1 | loss: 115.4759530CurrentTrain: epoch  6, batch     2 | loss: 126.3080507CurrentTrain: epoch  6, batch     3 | loss: 88.0282955CurrentTrain: epoch  7, batch     0 | loss: 122.7868676CurrentTrain: epoch  7, batch     1 | loss: 100.2459898CurrentTrain: epoch  7, batch     2 | loss: 124.1561329CurrentTrain: epoch  7, batch     3 | loss: 88.1422150CurrentTrain: epoch  8, batch     0 | loss: 135.4796753CurrentTrain: epoch  8, batch     1 | loss: 110.7201762CurrentTrain: epoch  8, batch     2 | loss: 114.6313976CurrentTrain: epoch  8, batch     3 | loss: 94.3604472CurrentTrain: epoch  9, batch     0 | loss: 116.7496994CurrentTrain: epoch  9, batch     1 | loss: 129.5083081CurrentTrain: epoch  9, batch     2 | loss: 107.5877933CurrentTrain: epoch  9, batch     3 | loss: 102.0205976
MemoryTrain:  epoch  0, batch     0 | loss: 1.0489628MemoryTrain:  epoch  1, batch     0 | loss: 0.9142647MemoryTrain:  epoch  2, batch     0 | loss: 0.7497075MemoryTrain:  epoch  3, batch     0 | loss: 0.6392146MemoryTrain:  epoch  4, batch     0 | loss: 0.5334227MemoryTrain:  epoch  5, batch     0 | loss: 0.4205004MemoryTrain:  epoch  6, batch     0 | loss: 0.3679773MemoryTrain:  epoch  7, batch     0 | loss: 0.3044465MemoryTrain:  epoch  8, batch     0 | loss: 0.2670714MemoryTrain:  epoch  9, batch     0 | loss: 0.2493620

F1 score per class: {32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.8695652173913043), 6: np.float64(0.0), 11: np.float64(0.4411764705882353), 12: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.7391304347826086), 15: np.float64(0.5620915032679739), 19: np.float64(0.5128205128205128), 25: np.float64(0.0), 28: np.float64(0.0)}
Micro-average F1 score: 0.5295508274231678
Weighted-average F1 score: 0.48010384966906705
F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.6153846153846154), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.8125), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.7678571428571429), 37: np.float64(0.535031847133758), 38: np.float64(0.6296296296296297), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5447897623400365
Weighted-average F1 score: 0.46446213613521525
F1 score per class: {6: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.6666666666666666), 19: np.float64(0.0), 25: np.float64(0.7228915662650602), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.75), 37: np.float64(0.5212121212121212), 38: np.float64(0.6153846153846154), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5405405405405406
Weighted-average F1 score: 0.46999834506010635

F1 score per class: {2: np.float64(0.5454545454545454), 6: np.float64(0.4574468085106383), 7: np.float64(0.06349206349206349), 9: np.float64(0.8888888888888888), 11: np.float64(0.25), 12: np.float64(0.15483870967741936), 15: np.float64(0.47619047619047616), 19: np.float64(0.6141732283464567), 24: np.float64(0.1), 25: np.float64(0.4411764705882353), 26: np.float64(0.7398843930635838), 27: np.float64(0.3018867924528302), 28: np.float64(0.2), 29: np.float64(0.8457142857142858), 31: np.float64(0.0), 32: np.float64(0.7467811158798283), 35: np.float64(0.5354330708661418), 37: np.float64(0.22872340425531915), 38: np.float64(0.3508771929824561), 39: np.float64(0.09090909090909091), 40: np.float64(0.18018018018018017)}
Micro-average F1 score: 0.44507269789983844
Weighted-average F1 score: 0.41879974874350845
F1 score per class: {2: np.float64(0.48484848484848486), 6: np.float64(0.4594594594594595), 7: np.float64(0.05333333333333334), 9: np.float64(0.6172839506172839), 11: np.float64(0.4563758389261745), 12: np.float64(0.27586206896551724), 15: np.float64(0.2857142857142857), 19: np.float64(0.6037735849056604), 24: np.float64(0.1724137931034483), 25: np.float64(0.8125), 26: np.float64(0.717391304347826), 27: np.float64(0.34615384615384615), 28: np.float64(0.1111111111111111), 29: np.float64(0.8804347826086957), 31: np.float64(0.09090909090909091), 32: np.float64(0.7419354838709677), 35: np.float64(0.4574468085106383), 37: np.float64(0.22105263157894736), 38: np.float64(0.44155844155844154), 39: np.float64(0.12244897959183673), 40: np.float64(0.176)}
Micro-average F1 score: 0.4442953020134228
Weighted-average F1 score: 0.40396960923336
F1 score per class: {2: np.float64(0.6153846153846154), 6: np.float64(0.46445497630331756), 7: np.float64(0.0547945205479452), 9: np.float64(0.7936507936507936), 11: np.float64(0.4393939393939394), 12: np.float64(0.287292817679558), 15: np.float64(0.2727272727272727), 19: np.float64(0.6153846153846154), 24: np.float64(0.23076923076923078), 25: np.float64(0.7228915662650602), 26: np.float64(0.7262569832402235), 27: np.float64(0.3157894736842105), 28: np.float64(0.12121212121212122), 29: np.float64(0.8666666666666667), 31: np.float64(0.125), 32: np.float64(0.7419354838709677), 35: np.float64(0.45901639344262296), 37: np.float64(0.21662468513853905), 38: np.float64(0.4383561643835616), 39: np.float64(0.15789473684210525), 40: np.float64(0.16923076923076924)}
Micro-average F1 score: 0.44756225885654155
Weighted-average F1 score: 0.40494212083828524

F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.6896551724137931), 19: np.float64(0.0), 25: np.float64(0.4166666666666667), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6181818181818182), 37: np.float64(0.43), 38: np.float64(0.43478260869565216), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3916083916083916
Weighted-average F1 score: 0.3394490453866426
F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.4), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.6902654867256637), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6142857142857143), 37: np.float64(0.417910447761194), 38: np.float64(0.4857142857142857), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.37626262626262624
Weighted-average F1 score: 0.31827918171915803
F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.47368421052631576), 19: np.float64(0.0), 25: np.float64(0.6521739130434783), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6131386861313869), 37: np.float64(0.4075829383886256), 38: np.float64(0.463768115942029), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3883495145631068
Weighted-average F1 score: 0.3319991497578479

F1 score per class: {2: np.float64(0.36363636363636365), 6: np.float64(0.3017543859649123), 7: np.float64(0.037037037037037035), 9: np.float64(0.8135593220338984), 11: np.float64(0.24299065420560748), 12: np.float64(0.10909090909090909), 15: np.float64(0.25316455696202533), 19: np.float64(0.5652173913043478), 24: np.float64(0.1), 25: np.float64(0.4166666666666667), 26: np.float64(0.6701570680628273), 27: np.float64(0.1797752808988764), 28: np.float64(0.11009174311926606), 29: np.float64(0.783068783068783), 31: np.float64(0.0), 32: np.float64(0.5878378378378378), 35: np.float64(0.35051546391752575), 37: np.float64(0.12855007473841554), 38: np.float64(0.2631578947368421), 39: np.float64(0.058823529411764705), 40: np.float64(0.13937282229965156)}
Micro-average F1 score: 0.3237367802585194
Weighted-average F1 score: 0.2898890347399461
F1 score per class: {2: np.float64(0.2711864406779661), 6: np.float64(0.2786885245901639), 7: np.float64(0.030303030303030304), 9: np.float64(0.5319148936170213), 11: np.float64(0.3930635838150289), 12: np.float64(0.16326530612244897), 15: np.float64(0.15384615384615385), 19: np.float64(0.5614035087719298), 24: np.float64(0.10309278350515463), 25: np.float64(0.6782608695652174), 26: np.float64(0.6407766990291263), 27: np.float64(0.1935483870967742), 28: np.float64(0.0594059405940594), 29: np.float64(0.782608695652174), 31: np.float64(0.05714285714285714), 32: np.float64(0.5661538461538461), 35: np.float64(0.2975778546712803), 37: np.float64(0.12982998454404945), 38: np.float64(0.288135593220339), 39: np.float64(0.05454545454545454), 40: np.float64(0.1282798833819242)}
Micro-average F1 score: 0.3048583928160258
Weighted-average F1 score: 0.27086255618527877
F1 score per class: {2: np.float64(0.38095238095238093), 6: np.float64(0.2890855457227139), 7: np.float64(0.030534351145038167), 9: np.float64(0.7246376811594203), 11: np.float64(0.3918918918918919), 12: np.float64(0.18571428571428572), 15: np.float64(0.144), 19: np.float64(0.5734767025089605), 24: np.float64(0.20689655172413793), 25: np.float64(0.6451612903225806), 26: np.float64(0.65), 27: np.float64(0.17307692307692307), 28: np.float64(0.06382978723404255), 29: np.float64(0.7684729064039408), 31: np.float64(0.09090909090909091), 32: np.float64(0.5714285714285714), 35: np.float64(0.2968197879858657), 37: np.float64(0.12721893491124261), 38: np.float64(0.27586206896551724), 39: np.float64(0.08695652173913043), 40: np.float64(0.12429378531073447)}
Micro-average F1 score: 0.31335952848722987
Weighted-average F1 score: 0.27597829669379453
cur_acc_wo_na:  ['0.7628', '0.4889', '0.3534', '0.5296']
his_acc_wo_na:  ['0.7628', '0.6418', '0.5069', '0.4451']
cur_acc des_wo_na:  ['0.7401', '0.4586', '0.3161', '0.5448']
his_acc des_wo_na:  ['0.7401', '0.5970', '0.4877', '0.4443']
cur_acc rrf_wo_na:  ['0.7584', '0.4384', '0.3175', '0.5405']
his_acc rrf_wo_na:  ['0.7584', '0.6053', '0.4909', '0.4476']
cur_acc_w_na:  ['0.6340', '0.3511', '0.2967', '0.3916']
his_acc_w_na:  ['0.6340', '0.4797', '0.3970', '0.3237']
cur_acc des_w_na:  ['0.6003', '0.3219', '0.2524', '0.3763']
his_acc des_w_na:  ['0.6003', '0.4339', '0.3612', '0.3049']
cur_acc rrf_w_na:  ['0.6215', '0.3033', '0.2604', '0.3883']
his_acc rrf_w_na:  ['0.6215', '0.4437', '0.3708', '0.3134']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 181.5440396CurrentTrain: epoch  0, batch     1 | loss: 143.0387415CurrentTrain: epoch  0, batch     2 | loss: 144.8097974CurrentTrain: epoch  0, batch     3 | loss: 151.9872169CurrentTrain: epoch  0, batch     4 | loss: 99.3663875CurrentTrain: epoch  1, batch     0 | loss: 130.8094725CurrentTrain: epoch  1, batch     1 | loss: 160.4103717CurrentTrain: epoch  1, batch     2 | loss: 114.8486300CurrentTrain: epoch  1, batch     3 | loss: 154.8781356CurrentTrain: epoch  1, batch     4 | loss: 122.1759047CurrentTrain: epoch  2, batch     0 | loss: 134.0563066CurrentTrain: epoch  2, batch     1 | loss: 133.3407917CurrentTrain: epoch  2, batch     2 | loss: 122.4597953CurrentTrain: epoch  2, batch     3 | loss: 136.8099090CurrentTrain: epoch  2, batch     4 | loss: 120.2528723CurrentTrain: epoch  3, batch     0 | loss: 100.5873911CurrentTrain: epoch  3, batch     1 | loss: 147.2171705CurrentTrain: epoch  3, batch     2 | loss: 125.8510698CurrentTrain: epoch  3, batch     3 | loss: 164.8768539CurrentTrain: epoch  3, batch     4 | loss: 149.7184277CurrentTrain: epoch  4, batch     0 | loss: 117.2676962CurrentTrain: epoch  4, batch     1 | loss: 150.6475557CurrentTrain: epoch  4, batch     2 | loss: 128.8222642CurrentTrain: epoch  4, batch     3 | loss: 133.2890389CurrentTrain: epoch  4, batch     4 | loss: 94.8964300CurrentTrain: epoch  5, batch     0 | loss: 168.9497013CurrentTrain: epoch  5, batch     1 | loss: 107.7380588CurrentTrain: epoch  5, batch     2 | loss: 135.4476369CurrentTrain: epoch  5, batch     3 | loss: 135.4138252CurrentTrain: epoch  5, batch     4 | loss: 92.1817066CurrentTrain: epoch  6, batch     0 | loss: 139.7261048CurrentTrain: epoch  6, batch     1 | loss: 120.2958325CurrentTrain: epoch  6, batch     2 | loss: 146.0521719CurrentTrain: epoch  6, batch     3 | loss: 146.0281455CurrentTrain: epoch  6, batch     4 | loss: 52.9663622CurrentTrain: epoch  7, batch     0 | loss: 131.9457648CurrentTrain: epoch  7, batch     1 | loss: 129.4132509CurrentTrain: epoch  7, batch     2 | loss: 123.1355194CurrentTrain: epoch  7, batch     3 | loss: 139.2867407CurrentTrain: epoch  7, batch     4 | loss: 77.6241367CurrentTrain: epoch  8, batch     0 | loss: 138.9866166CurrentTrain: epoch  8, batch     1 | loss: 112.1578107CurrentTrain: epoch  8, batch     2 | loss: 141.5269285CurrentTrain: epoch  8, batch     3 | loss: 118.8326250CurrentTrain: epoch  8, batch     4 | loss: 75.8584670CurrentTrain: epoch  9, batch     0 | loss: 120.2401179CurrentTrain: epoch  9, batch     1 | loss: 101.7498740CurrentTrain: epoch  9, batch     2 | loss: 126.2388011CurrentTrain: epoch  9, batch     3 | loss: 159.0078062CurrentTrain: epoch  9, batch     4 | loss: 92.1526807
MemoryTrain:  epoch  0, batch     0 | loss: 1.2506073MemoryTrain:  epoch  1, batch     0 | loss: 1.1155782MemoryTrain:  epoch  2, batch     0 | loss: 0.9690651MemoryTrain:  epoch  3, batch     0 | loss: 0.8005414MemoryTrain:  epoch  4, batch     0 | loss: 0.6924764MemoryTrain:  epoch  5, batch     0 | loss: 0.6452321MemoryTrain:  epoch  6, batch     0 | loss: 0.5287065MemoryTrain:  epoch  7, batch     0 | loss: 0.4457258MemoryTrain:  epoch  8, batch     0 | loss: 0.3394224MemoryTrain:  epoch  9, batch     0 | loss: 0.3570730

F1 score per class: {1: np.float64(0.2033898305084746), 3: np.float64(0.6106870229007634), 6: np.float64(0.0), 7: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.12658227848101267), 19: np.float64(0.0), 22: np.float64(0.5317460317460317), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6875), 35: np.float64(0.0), 37: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.35080645161290325
Weighted-average F1 score: 0.29297273827324893
F1 score per class: {1: np.float64(0.24), 2: np.float64(0.0), 3: np.float64(0.6428571428571429), 6: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.057971014492753624), 19: np.float64(0.0), 22: np.float64(0.5158730158730159), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6538461538461539), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3202511773940345
Weighted-average F1 score: 0.27237666094341945
F1 score per class: {1: np.float64(0.2598870056497175), 3: np.float64(0.6483516483516484), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.06666666666666667), 19: np.float64(0.0), 22: np.float64(0.5247148288973384), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6666666666666666), 35: np.float64(0.0), 37: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3352506162695152
Weighted-average F1 score: 0.2861883909574867

F1 score per class: {1: np.float64(0.1643835616438356), 2: np.float64(0.5555555555555556), 3: np.float64(0.47904191616766467), 6: np.float64(0.4530386740331492), 7: np.float64(0.057971014492753624), 9: np.float64(0.8275862068965517), 11: np.float64(0.02247191011235955), 12: np.float64(0.15483870967741936), 14: np.float64(0.10204081632653061), 15: np.float64(0.7272727272727273), 19: np.float64(0.5669291338582677), 22: np.float64(0.44816053511705684), 24: np.float64(0.0), 25: np.float64(0.3939393939393939), 26: np.float64(0.7314285714285714), 27: np.float64(0.0), 28: np.float64(0.17142857142857143), 29: np.float64(0.7909604519774012), 31: np.float64(0.0), 32: np.float64(0.6115702479338843), 34: np.float64(0.27586206896551724), 35: np.float64(0.19834710743801653), 37: np.float64(0.2076923076923077), 38: np.float64(0.391304347826087), 39: np.float64(0.058823529411764705), 40: np.float64(0.16589861751152074)}
Micro-average F1 score: 0.37071742313323575
Weighted-average F1 score: 0.3558129120795928
F1 score per class: {1: np.float64(0.17355371900826447), 2: np.float64(0.5185185185185185), 3: np.float64(0.4), 6: np.float64(0.4419475655430712), 7: np.float64(0.038461538461538464), 9: np.float64(0.5882352941176471), 11: np.float64(0.02247191011235955), 12: np.float64(0.2764976958525346), 14: np.float64(0.038834951456310676), 15: np.float64(0.5454545454545454), 19: np.float64(0.5492957746478874), 22: np.float64(0.4513888888888889), 24: np.float64(0.09523809523809523), 25: np.float64(0.8), 26: np.float64(0.708994708994709), 27: np.float64(0.0), 28: np.float64(0.09523809523809523), 29: np.float64(0.8089887640449438), 31: np.float64(0.04878048780487805), 32: np.float64(0.5934065934065934), 34: np.float64(0.21841541755888652), 35: np.float64(0.2236842105263158), 37: np.float64(0.13008130081300814), 38: np.float64(0.46511627906976744), 39: np.float64(0.10526315789473684), 40: np.float64(0.17543859649122806)}
Micro-average F1 score: 0.3493892601982024
Weighted-average F1 score: 0.32632220376901194
F1 score per class: {1: np.float64(0.19166666666666668), 2: np.float64(0.6), 3: np.float64(0.41843971631205673), 6: np.float64(0.45267489711934156), 7: np.float64(0.034482758620689655), 9: np.float64(0.746268656716418), 11: np.float64(0.02247191011235955), 12: np.float64(0.2631578947368421), 14: np.float64(0.0449438202247191), 15: np.float64(0.6), 19: np.float64(0.5519713261648745), 22: np.float64(0.4524590163934426), 24: np.float64(0.0), 25: np.float64(0.7228915662650602), 26: np.float64(0.7252747252747253), 27: np.float64(0.0), 28: np.float64(0.1111111111111111), 29: np.float64(0.8022598870056498), 31: np.float64(0.0), 32: np.float64(0.6051660516605166), 34: np.float64(0.22632794457274827), 35: np.float64(0.20359281437125748), 37: np.float64(0.11808118081180811), 38: np.float64(0.36923076923076925), 39: np.float64(0.1), 40: np.float64(0.16666666666666666)}
Micro-average F1 score: 0.3512925827494564
Weighted-average F1 score: 0.32753338183031255

F1 score per class: {1: np.float64(0.11612903225806452), 2: np.float64(0.0), 3: np.float64(0.547945205479452), 6: np.float64(0.0), 7: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.11904761904761904), 19: np.float64(0.0), 22: np.float64(0.40853658536585363), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.4971751412429379), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.24183460736622656
Weighted-average F1 score: 0.20290106938451713
F1 score per class: {1: np.float64(0.134185303514377), 2: np.float64(0.0), 3: np.float64(0.4548736462093863), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.046511627906976744), 15: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.39634146341463417), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.4533333333333333), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.20816326530612245
Weighted-average F1 score: 0.18388683181890444
F1 score per class: {1: np.float64(0.14511041009463724), 2: np.float64(0.0), 3: np.float64(0.4816326530612245), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.05555555555555555), 15: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.39655172413793105), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.460093896713615), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.22042139384116693
Weighted-average F1 score: 0.19477220373165063

F1 score per class: {1: np.float64(0.08977556109725686), 2: np.float64(0.3333333333333333), 3: np.float64(0.3686635944700461), 6: np.float64(0.30036630036630035), 7: np.float64(0.031496062992125984), 9: np.float64(0.7741935483870968), 11: np.float64(0.02247191011235955), 12: np.float64(0.10344827586206896), 14: np.float64(0.08771929824561403), 15: np.float64(0.5161290322580645), 19: np.float64(0.51985559566787), 22: np.float64(0.32682926829268294), 24: np.float64(0.0), 25: np.float64(0.38235294117647056), 26: np.float64(0.6597938144329897), 27: np.float64(0.0), 28: np.float64(0.09302325581395349), 29: np.float64(0.7216494845360825), 31: np.float64(0.0), 32: np.float64(0.44984802431610943), 34: np.float64(0.16236162361623616), 35: np.float64(0.1348314606741573), 37: np.float64(0.1424802110817942), 38: np.float64(0.29508196721311475), 39: np.float64(0.03773584905660377), 40: np.float64(0.14007782101167315)}
Micro-average F1 score: 0.2682771773680865
Weighted-average F1 score: 0.24803818366354413
F1 score per class: {1: np.float64(0.0945945945945946), 2: np.float64(0.2916666666666667), 3: np.float64(0.2587268993839836), 6: np.float64(0.26222222222222225), 7: np.float64(0.02127659574468085), 9: np.float64(0.4672897196261682), 11: np.float64(0.02197802197802198), 12: np.float64(0.1652892561983471), 14: np.float64(0.028985507246376812), 15: np.float64(0.3076923076923077), 19: np.float64(0.5), 22: np.float64(0.32098765432098764), 24: np.float64(0.09523809523809523), 25: np.float64(0.6785714285714286), 26: np.float64(0.6203703703703703), 27: np.float64(0.0), 28: np.float64(0.05223880597014925), 29: np.float64(0.7346938775510204), 31: np.float64(0.025974025974025976), 32: np.float64(0.44021739130434784), 34: np.float64(0.13333333333333333), 35: np.float64(0.15384615384615385), 37: np.float64(0.08695652173913043), 38: np.float64(0.2702702702702703), 39: np.float64(0.057971014492753624), 40: np.float64(0.13054830287206268)}
Micro-average F1 score: 0.23828984596038982
Weighted-average F1 score: 0.21933399746185683
F1 score per class: {1: np.float64(0.10337078651685393), 2: np.float64(0.3333333333333333), 3: np.float64(0.2822966507177033), 6: np.float64(0.275), 7: np.float64(0.018018018018018018), 9: np.float64(0.6756756756756757), 11: np.float64(0.02197802197802198), 12: np.float64(0.15822784810126583), 14: np.float64(0.03404255319148936), 15: np.float64(0.3333333333333333), 19: np.float64(0.5032679738562091), 22: np.float64(0.3194444444444444), 24: np.float64(0.0), 25: np.float64(0.6451612903225806), 26: np.float64(0.6470588235294118), 27: np.float64(0.0), 28: np.float64(0.061946902654867256), 29: np.float64(0.7282051282051282), 31: np.float64(0.0), 32: np.float64(0.4444444444444444), 34: np.float64(0.13517241379310344), 35: np.float64(0.13654618473895583), 37: np.float64(0.08184143222506395), 38: np.float64(0.2553191489361702), 39: np.float64(0.05128205128205128), 40: np.float64(0.12339331619537275)}
Micro-average F1 score: 0.24249499666444296
Weighted-average F1 score: 0.22192835942884498
cur_acc_wo_na:  ['0.7628', '0.4889', '0.3534', '0.5296', '0.3508']
his_acc_wo_na:  ['0.7628', '0.6418', '0.5069', '0.4451', '0.3707']
cur_acc des_wo_na:  ['0.7401', '0.4586', '0.3161', '0.5448', '0.3203']
his_acc des_wo_na:  ['0.7401', '0.5970', '0.4877', '0.4443', '0.3494']
cur_acc rrf_wo_na:  ['0.7584', '0.4384', '0.3175', '0.5405', '0.3353']
his_acc rrf_wo_na:  ['0.7584', '0.6053', '0.4909', '0.4476', '0.3513']
cur_acc_w_na:  ['0.6340', '0.3511', '0.2967', '0.3916', '0.2418']
his_acc_w_na:  ['0.6340', '0.4797', '0.3970', '0.3237', '0.2683']
cur_acc des_w_na:  ['0.6003', '0.3219', '0.2524', '0.3763', '0.2082']
his_acc des_w_na:  ['0.6003', '0.4339', '0.3612', '0.3049', '0.2383']
cur_acc rrf_w_na:  ['0.6215', '0.3033', '0.2604', '0.3883', '0.2204']
his_acc rrf_w_na:  ['0.6215', '0.4437', '0.3708', '0.3134', '0.2425']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 126.2769769CurrentTrain: epoch  0, batch     1 | loss: 132.4988716CurrentTrain: epoch  0, batch     2 | loss: 191.5321847CurrentTrain: epoch  0, batch     3 | loss: 129.6361397CurrentTrain: epoch  1, batch     0 | loss: 167.6950272CurrentTrain: epoch  1, batch     1 | loss: 118.9726147CurrentTrain: epoch  1, batch     2 | loss: 124.1195544CurrentTrain: epoch  1, batch     3 | loss: 141.9161911CurrentTrain: epoch  2, batch     0 | loss: 147.6366435CurrentTrain: epoch  2, batch     1 | loss: 141.5854503CurrentTrain: epoch  2, batch     2 | loss: 119.4123935CurrentTrain: epoch  2, batch     3 | loss: 109.0168913CurrentTrain: epoch  3, batch     0 | loss: 121.7933936CurrentTrain: epoch  3, batch     1 | loss: 206.9864877CurrentTrain: epoch  3, batch     2 | loss: 106.6368926CurrentTrain: epoch  3, batch     3 | loss: 97.2617568CurrentTrain: epoch  4, batch     0 | loss: 140.7286232CurrentTrain: epoch  4, batch     1 | loss: 122.9519970CurrentTrain: epoch  4, batch     2 | loss: 128.8980240CurrentTrain: epoch  4, batch     3 | loss: 103.7601706CurrentTrain: epoch  5, batch     0 | loss: 122.3840404CurrentTrain: epoch  5, batch     1 | loss: 143.3274103CurrentTrain: epoch  5, batch     2 | loss: 126.9478252CurrentTrain: epoch  5, batch     3 | loss: 90.8062023CurrentTrain: epoch  6, batch     0 | loss: 163.2856228CurrentTrain: epoch  6, batch     1 | loss: 109.4713598CurrentTrain: epoch  6, batch     2 | loss: 122.5532733CurrentTrain: epoch  6, batch     3 | loss: 100.5871417CurrentTrain: epoch  7, batch     0 | loss: 110.0920292CurrentTrain: epoch  7, batch     1 | loss: 124.0217448CurrentTrain: epoch  7, batch     2 | loss: 125.9847302CurrentTrain: epoch  7, batch     3 | loss: 96.9338298CurrentTrain: epoch  8, batch     0 | loss: 107.0836003CurrentTrain: epoch  8, batch     1 | loss: 109.1115672CurrentTrain: epoch  8, batch     2 | loss: 123.8299212CurrentTrain: epoch  8, batch     3 | loss: 160.4867525CurrentTrain: epoch  9, batch     0 | loss: 105.9230367CurrentTrain: epoch  9, batch     1 | loss: 107.8868294CurrentTrain: epoch  9, batch     2 | loss: 124.7159266CurrentTrain: epoch  9, batch     3 | loss: 104.8335657
MemoryTrain:  epoch  0, batch     0 | loss: 1.1619491MemoryTrain:  epoch  1, batch     0 | loss: 0.9974592MemoryTrain:  epoch  2, batch     0 | loss: 0.8288113MemoryTrain:  epoch  3, batch     0 | loss: 0.6745106MemoryTrain:  epoch  4, batch     0 | loss: 0.5851309MemoryTrain:  epoch  5, batch     0 | loss: 0.4729953MemoryTrain:  epoch  6, batch     0 | loss: 0.4167749MemoryTrain:  epoch  7, batch     0 | loss: 0.3561346MemoryTrain:  epoch  8, batch     0 | loss: 0.3332958MemoryTrain:  epoch  9, batch     0 | loss: 0.3464168

F1 score per class: {0: np.float64(0.7526881720430108), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.6883116883116883), 6: np.float64(0.0), 7: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.18181818181818182), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3333333333333333), 22: np.float64(0.0), 23: np.float64(0.8181818181818182), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4925373134328358
Weighted-average F1 score: 0.37222278198186737
F1 score per class: {0: np.float64(0.7), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7932960893854749), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.15384615384615385), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.4375), 22: np.float64(0.0), 23: np.float64(0.782608695652174), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4570596797671033
Weighted-average F1 score: 0.33759325823676567
F1 score per class: {0: np.float64(0.7142857142857143), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8047337278106509), 6: np.float64(0.0), 7: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.16666666666666666), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3728813559322034), 22: np.float64(0.0), 23: np.float64(0.7912087912087912), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4617737003058104
Weighted-average F1 score: 0.33529628395465133

F1 score per class: {0: np.float64(0.32710280373831774), 1: np.float64(0.16666666666666666), 2: np.float64(0.43478260869565216), 3: np.float64(0.45454545454545453), 4: np.float64(0.6883116883116883), 6: np.float64(0.45), 7: np.float64(0.0), 9: np.float64(0.7575757575757576), 11: np.float64(0.0), 12: np.float64(0.13414634146341464), 13: np.float64(0.03571428571428571), 14: np.float64(0.0594059405940594), 15: np.float64(0.5217391304347826), 19: np.float64(0.5342960288808665), 21: np.float64(0.0958904109589041), 22: np.float64(0.417910447761194), 23: np.float64(0.7422680412371134), 24: np.float64(0.0), 25: np.float64(0.4411764705882353), 26: np.float64(0.6900584795321637), 27: np.float64(0.0), 28: np.float64(0.18867924528301888), 29: np.float64(0.7613636363636364), 31: np.float64(0.14285714285714285), 32: np.float64(0.587360594795539), 34: np.float64(0.23232323232323232), 35: np.float64(0.17647058823529413), 37: np.float64(0.2653061224489796), 38: np.float64(0.3111111111111111), 39: np.float64(0.08333333333333333), 40: np.float64(0.13178294573643412)}
Micro-average F1 score: 0.35591162903617385
Weighted-average F1 score: 0.331919561146478
F1 score per class: {0: np.float64(0.2755905511811024), 1: np.float64(0.1684981684981685), 2: np.float64(0.3157894736842105), 3: np.float64(0.3623693379790941), 4: np.float64(0.7513227513227513), 6: np.float64(0.4444444444444444), 7: np.float64(0.0851063829787234), 9: np.float64(0.5263157894736842), 11: np.float64(0.0), 12: np.float64(0.2145922746781116), 13: np.float64(0.031746031746031744), 14: np.float64(0.0449438202247191), 15: np.float64(0.6), 19: np.float64(0.4966887417218543), 21: np.float64(0.14814814814814814), 22: np.float64(0.43478260869565216), 23: np.float64(0.7128712871287128), 24: np.float64(0.0), 25: np.float64(0.7777777777777778), 26: np.float64(0.7103825136612022), 27: np.float64(0.0), 28: np.float64(0.12195121951219512), 29: np.float64(0.7570621468926554), 31: np.float64(0.044444444444444446), 32: np.float64(0.5795053003533569), 34: np.float64(0.22018348623853212), 35: np.float64(0.24271844660194175), 37: np.float64(0.14912280701754385), 38: np.float64(0.47058823529411764), 39: np.float64(0.125), 40: np.float64(0.1761006289308176)}
Micro-average F1 score: 0.3467297084318361
Weighted-average F1 score: 0.3201259379111778
F1 score per class: {0: np.float64(0.2734375), 1: np.float64(0.17293233082706766), 2: np.float64(0.35294117647058826), 3: np.float64(0.39357429718875503), 4: np.float64(0.8047337278106509), 6: np.float64(0.46774193548387094), 7: np.float64(0.0851063829787234), 9: np.float64(0.7142857142857143), 11: np.float64(0.0), 12: np.float64(0.23809523809523808), 13: np.float64(0.03225806451612903), 14: np.float64(0.046511627906976744), 15: np.float64(0.6), 19: np.float64(0.5226480836236934), 21: np.float64(0.11398963730569948), 22: np.float64(0.4383561643835616), 23: np.float64(0.72), 24: np.float64(0.0), 25: np.float64(0.6153846153846154), 26: np.float64(0.7111111111111111), 27: np.float64(0.0), 28: np.float64(0.1111111111111111), 29: np.float64(0.768361581920904), 31: np.float64(0.07142857142857142), 32: np.float64(0.570446735395189), 34: np.float64(0.21428571428571427), 35: np.float64(0.22105263157894736), 37: np.float64(0.1504424778761062), 38: np.float64(0.4057971014492754), 39: np.float64(0.07142857142857142), 40: np.float64(0.16981132075471697)}
Micro-average F1 score: 0.3468089472604145
Weighted-average F1 score: 0.3162160641054046

F1 score per class: {0: np.float64(0.6481481481481481), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.6583850931677019), 6: np.float64(0.0), 7: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.09090909090909091), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.28), 22: np.float64(0.0), 23: np.float64(0.6990291262135923), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3702664796633941
Weighted-average F1 score: 0.26813609495976476
F1 score per class: {0: np.float64(0.6194690265486725), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7357512953367875), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.07692307692307693), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3076923076923077), 22: np.float64(0.0), 23: np.float64(0.6486486486486487), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3237113402061856
Weighted-average F1 score: 0.23612660409927594
F1 score per class: {0: np.float64(0.6140350877192983), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7640449438202247), 6: np.float64(0.0), 7: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.07692307692307693), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.2558139534883721), 22: np.float64(0.0), 23: np.float64(0.6666666666666666), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3282608695652174
Weighted-average F1 score: 0.23318289442325035

F1 score per class: {0: np.float64(0.219435736677116), 1: np.float64(0.08928571428571429), 2: np.float64(0.2564102564102564), 3: np.float64(0.33816425120772947), 4: np.float64(0.6424242424242425), 6: np.float64(0.2830188679245283), 7: np.float64(0.0), 9: np.float64(0.6944444444444444), 11: np.float64(0.0), 12: np.float64(0.09016393442622951), 13: np.float64(0.01639344262295082), 14: np.float64(0.047244094488188976), 15: np.float64(0.36363636363636365), 19: np.float64(0.48366013071895425), 21: np.float64(0.0660377358490566), 22: np.float64(0.3169811320754717), 23: np.float64(0.6050420168067226), 24: np.float64(0.0), 25: np.float64(0.4225352112676056), 26: np.float64(0.6243386243386243), 27: np.float64(0.0), 28: np.float64(0.12658227848101267), 29: np.float64(0.6733668341708543), 31: np.float64(0.06896551724137931), 32: np.float64(0.42245989304812837), 34: np.float64(0.1435257410296412), 35: np.float64(0.125), 37: np.float64(0.16993464052287582), 38: np.float64(0.25), 39: np.float64(0.058823529411764705), 40: np.float64(0.1033434650455927)}
Micro-average F1 score: 0.25553425135088026
Weighted-average F1 score: 0.23111312837440398
F1 score per class: {0: np.float64(0.18867924528301888), 1: np.float64(0.09218436873747494), 2: np.float64(0.2), 3: np.float64(0.22807017543859648), 4: np.float64(0.6255506607929515), 6: np.float64(0.25263157894736843), 7: np.float64(0.05063291139240506), 9: np.float64(0.42735042735042733), 11: np.float64(0.0), 12: np.float64(0.12953367875647667), 13: np.float64(0.01282051282051282), 14: np.float64(0.03619909502262444), 15: np.float64(0.48), 19: np.float64(0.42735042735042733), 21: np.float64(0.09271523178807947), 22: np.float64(0.3246753246753247), 23: np.float64(0.5413533834586466), 24: np.float64(0.0), 25: np.float64(0.6730769230769231), 26: np.float64(0.6403940886699507), 27: np.float64(0.0), 28: np.float64(0.08849557522123894), 29: np.float64(0.6633663366336634), 31: np.float64(0.021052631578947368), 32: np.float64(0.4120603015075377), 34: np.float64(0.13314840499306518), 35: np.float64(0.16447368421052633), 37: np.float64(0.09714285714285714), 38: np.float64(0.2962962962962963), 39: np.float64(0.06557377049180328), 40: np.float64(0.12669683257918551)}
Micro-average F1 score: 0.23624161073825503
Weighted-average F1 score: 0.21576599538779062
F1 score per class: {0: np.float64(0.18181818181818182), 1: np.float64(0.09504132231404959), 2: np.float64(0.21428571428571427), 3: np.float64(0.25925925925925924), 4: np.float64(0.7046632124352331), 6: np.float64(0.2703962703962704), 7: np.float64(0.05405405405405406), 9: np.float64(0.6493506493506493), 11: np.float64(0.0), 12: np.float64(0.1404494382022472), 13: np.float64(0.012345679012345678), 14: np.float64(0.03619909502262444), 15: np.float64(0.42857142857142855), 19: np.float64(0.46439628482972134), 21: np.float64(0.0718954248366013), 22: np.float64(0.33217993079584773), 23: np.float64(0.5669291338582677), 24: np.float64(0.0), 25: np.float64(0.5517241379310345), 26: np.float64(0.6464646464646465), 27: np.float64(0.0), 28: np.float64(0.08), 29: np.float64(0.6699507389162561), 31: np.float64(0.03636363636363636), 32: np.float64(0.40987654320987654), 34: np.float64(0.12990527740189445), 35: np.float64(0.14634146341463414), 37: np.float64(0.09742120343839542), 38: np.float64(0.27184466019417475), 39: np.float64(0.037037037037037035), 40: np.float64(0.12217194570135746)}
Micro-average F1 score: 0.23789414414414414
Weighted-average F1 score: 0.21372782835432436
cur_acc_wo_na:  ['0.7628', '0.4889', '0.3534', '0.5296', '0.3508', '0.4925']
his_acc_wo_na:  ['0.7628', '0.6418', '0.5069', '0.4451', '0.3707', '0.3559']
cur_acc des_wo_na:  ['0.7401', '0.4586', '0.3161', '0.5448', '0.3203', '0.4571']
his_acc des_wo_na:  ['0.7401', '0.5970', '0.4877', '0.4443', '0.3494', '0.3467']
cur_acc rrf_wo_na:  ['0.7584', '0.4384', '0.3175', '0.5405', '0.3353', '0.4618']
his_acc rrf_wo_na:  ['0.7584', '0.6053', '0.4909', '0.4476', '0.3513', '0.3468']
cur_acc_w_na:  ['0.6340', '0.3511', '0.2967', '0.3916', '0.2418', '0.3703']
his_acc_w_na:  ['0.6340', '0.4797', '0.3970', '0.3237', '0.2683', '0.2555']
cur_acc des_w_na:  ['0.6003', '0.3219', '0.2524', '0.3763', '0.2082', '0.3237']
his_acc des_w_na:  ['0.6003', '0.4339', '0.3612', '0.3049', '0.2383', '0.2362']
cur_acc rrf_w_na:  ['0.6215', '0.3033', '0.2604', '0.3883', '0.2204', '0.3283']
his_acc rrf_w_na:  ['0.6215', '0.4437', '0.3708', '0.3134', '0.2425', '0.2379']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 140.1467490CurrentTrain: epoch  0, batch     1 | loss: 125.6707490CurrentTrain: epoch  0, batch     2 | loss: 129.8467291CurrentTrain: epoch  0, batch     3 | loss: 106.6940607CurrentTrain: epoch  1, batch     0 | loss: 145.3401173CurrentTrain: epoch  1, batch     1 | loss: 131.0115345CurrentTrain: epoch  1, batch     2 | loss: 122.0095378CurrentTrain: epoch  1, batch     3 | loss: 66.8254014CurrentTrain: epoch  2, batch     0 | loss: 115.3019652CurrentTrain: epoch  2, batch     1 | loss: 117.6330730CurrentTrain: epoch  2, batch     2 | loss: 132.9028636CurrentTrain: epoch  2, batch     3 | loss: 80.1750407CurrentTrain: epoch  3, batch     0 | loss: 108.2554752CurrentTrain: epoch  3, batch     1 | loss: 128.6382874CurrentTrain: epoch  3, batch     2 | loss: 111.0894505CurrentTrain: epoch  3, batch     3 | loss: 77.8176927CurrentTrain: epoch  4, batch     0 | loss: 159.1097709CurrentTrain: epoch  4, batch     1 | loss: 123.6134026CurrentTrain: epoch  4, batch     2 | loss: 104.7252925CurrentTrain: epoch  4, batch     3 | loss: 68.1831528CurrentTrain: epoch  5, batch     0 | loss: 140.5565954CurrentTrain: epoch  5, batch     1 | loss: 118.8352482CurrentTrain: epoch  5, batch     2 | loss: 123.3869748CurrentTrain: epoch  5, batch     3 | loss: 66.7617961CurrentTrain: epoch  6, batch     0 | loss: 104.1277128CurrentTrain: epoch  6, batch     1 | loss: 146.7479017CurrentTrain: epoch  6, batch     2 | loss: 128.9001361CurrentTrain: epoch  6, batch     3 | loss: 76.7088549CurrentTrain: epoch  7, batch     0 | loss: 98.7477297CurrentTrain: epoch  7, batch     1 | loss: 114.7801387CurrentTrain: epoch  7, batch     2 | loss: 128.9557835CurrentTrain: epoch  7, batch     3 | loss: 74.2293587CurrentTrain: epoch  8, batch     0 | loss: 114.7940218CurrentTrain: epoch  8, batch     1 | loss: 112.5567462CurrentTrain: epoch  8, batch     2 | loss: 119.5616656CurrentTrain: epoch  8, batch     3 | loss: 79.2006568CurrentTrain: epoch  9, batch     0 | loss: 113.9479068CurrentTrain: epoch  9, batch     1 | loss: 110.6007912CurrentTrain: epoch  9, batch     2 | loss: 105.2546842CurrentTrain: epoch  9, batch     3 | loss: 95.4127308
MemoryTrain:  epoch  0, batch     0 | loss: 0.7137986MemoryTrain:  epoch  1, batch     0 | loss: 0.6061382MemoryTrain:  epoch  2, batch     0 | loss: 0.5305250MemoryTrain:  epoch  3, batch     0 | loss: 0.4506764MemoryTrain:  epoch  4, batch     0 | loss: 0.3911383MemoryTrain:  epoch  5, batch     0 | loss: 0.3485655MemoryTrain:  epoch  6, batch     0 | loss: 0.3167123MemoryTrain:  epoch  7, batch     0 | loss: 0.2520346MemoryTrain:  epoch  8, batch     0 | loss: 0.2446511MemoryTrain:  epoch  9, batch     0 | loss: 0.2342518

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.5945945945945946), 12: np.float64(0.0), 13: np.float64(0.0), 20: np.float64(0.7311827956989247), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8648648648648649), 32: np.float64(0.0), 33: np.float64(0.5333333333333333), 34: np.float64(0.0), 36: np.float64(0.5773195876288659), 37: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5153374233128835
Weighted-average F1 score: 0.40291385654066525
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.6071428571428571), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 20: np.float64(0.7289719626168224), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7727272727272727), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.47619047619047616), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.7445255474452555), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5054263565891473
Weighted-average F1 score: 0.4067592827024634
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.6265060240963856), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 20: np.float64(0.7524752475247525), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8292682926829268), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.4), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.7008547008547008), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5049833887043189
Weighted-average F1 score: 0.3940885198503242

F1 score per class: {0: np.float64(0.47761194029850745), 1: np.float64(0.15966386554621848), 2: np.float64(0.5), 3: np.float64(0.36363636363636365), 4: np.float64(0.7904191616766467), 6: np.float64(0.4519230769230769), 7: np.float64(0.0), 8: np.float64(0.2724458204334365), 9: np.float64(0.746268656716418), 11: np.float64(0.02247191011235955), 12: np.float64(0.14084507042253522), 13: np.float64(0.08333333333333333), 14: np.float64(0.06593406593406594), 15: np.float64(0.7058823529411765), 19: np.float64(0.5278810408921933), 20: np.float64(0.6181818181818182), 21: np.float64(0.09876543209876543), 22: np.float64(0.47058823529411764), 23: np.float64(0.6744186046511628), 24: np.float64(0.0), 25: np.float64(0.34375), 26: np.float64(0.6705202312138728), 27: np.float64(0.0), 28: np.float64(0.47619047619047616), 29: np.float64(0.7734806629834254), 30: np.float64(0.7272727272727273), 31: np.float64(0.10526315789473684), 32: np.float64(0.5860805860805861), 33: np.float64(0.20512820512820512), 34: np.float64(0.24489795918367346), 35: np.float64(0.16793893129770993), 36: np.float64(0.47863247863247865), 37: np.float64(0.3007518796992481), 38: np.float64(0.30303030303030304), 39: np.float64(0.0), 40: np.float64(0.19130434782608696)}
Micro-average F1 score: 0.3927818139207874
Weighted-average F1 score: 0.38063841218466954
F1 score per class: {0: np.float64(0.2545454545454545), 1: np.float64(0.1791044776119403), 2: np.float64(0.27906976744186046), 3: np.float64(0.4084507042253521), 4: np.float64(0.8617021276595744), 6: np.float64(0.5221238938053098), 7: np.float64(0.0), 8: np.float64(0.2372093023255814), 9: np.float64(0.4854368932038835), 11: np.float64(0.10752688172043011), 12: np.float64(0.21782178217821782), 13: np.float64(0.1), 14: np.float64(0.05), 15: np.float64(0.5454545454545454), 19: np.float64(0.5), 20: np.float64(0.45348837209302323), 21: np.float64(0.11180124223602485), 22: np.float64(0.4132841328413284), 23: np.float64(0.6923076923076923), 24: np.float64(0.0), 25: np.float64(0.5783132530120482), 26: np.float64(0.6918918918918919), 27: np.float64(0.0), 28: np.float64(0.19607843137254902), 29: np.float64(0.8223350253807107), 30: np.float64(0.2905982905982906), 31: np.float64(0.028985507246376812), 32: np.float64(0.5407166123778502), 33: np.float64(0.136986301369863), 34: np.float64(0.2795031055900621), 35: np.float64(0.2604166666666667), 36: np.float64(0.4788732394366197), 37: np.float64(0.2077922077922078), 38: np.float64(0.5106382978723404), 39: np.float64(0.19047619047619047), 40: np.float64(0.17843866171003717)}
Micro-average F1 score: 0.3694849709966602
Weighted-average F1 score: 0.3487670136512666
F1 score per class: {0: np.float64(0.2982456140350877), 1: np.float64(0.1776061776061776), 2: np.float64(0.34285714285714286), 3: np.float64(0.4411764705882353), 4: np.float64(0.8729281767955801), 6: np.float64(0.5089285714285714), 7: np.float64(0.0), 8: np.float64(0.2549019607843137), 9: np.float64(0.6944444444444444), 11: np.float64(0.08695652173913043), 12: np.float64(0.21978021978021978), 13: np.float64(0.13333333333333333), 14: np.float64(0.043478260869565216), 15: np.float64(0.631578947368421), 19: np.float64(0.517799352750809), 20: np.float64(0.4935064935064935), 21: np.float64(0.11464968152866242), 22: np.float64(0.43089430894308944), 23: np.float64(0.6868686868686869), 24: np.float64(0.0), 25: np.float64(0.48), 26: np.float64(0.6923076923076923), 27: np.float64(0.0), 28: np.float64(0.19230769230769232), 29: np.float64(0.806282722513089), 30: np.float64(0.40963855421686746), 31: np.float64(0.05128205128205128), 32: np.float64(0.5448717948717948), 33: np.float64(0.12307692307692308), 34: np.float64(0.25936599423631124), 35: np.float64(0.21875), 36: np.float64(0.5256410256410257), 37: np.float64(0.2138364779874214), 38: np.float64(0.45454545454545453), 39: np.float64(0.11764705882352941), 40: np.float64(0.16546762589928057)}
Micro-average F1 score: 0.37615544236936427
Weighted-average F1 score: 0.3541770030377829

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.43564356435643564), 12: np.float64(0.0), 13: np.float64(0.0), 20: np.float64(0.5862068965517241), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8205128205128205), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.47058823529411764), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.448), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3615494978479197
Weighted-average F1 score: 0.28910619033338353
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.4473684210526316), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5531914893617021), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.723404255319149), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.3333333333333333), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.5396825396825397), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.33504624871531347
Weighted-average F1 score: 0.2787876311757774
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.44635193133047213), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 20: np.float64(0.5671641791044776), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7555555555555555), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.26666666666666666), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.4939759036144578), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.33443344334433445
Weighted-average F1 score: 0.2762939961108361

F1 score per class: {0: np.float64(0.34594594594594597), 1: np.float64(0.08636363636363636), 2: np.float64(0.2777777777777778), 3: np.float64(0.2716049382716049), 4: np.float64(0.7542857142857143), 6: np.float64(0.27246376811594203), 7: np.float64(0.0), 8: np.float64(0.1527777777777778), 9: np.float64(0.6756756756756757), 11: np.float64(0.02247191011235955), 12: np.float64(0.09852216748768473), 13: np.float64(0.037037037037037035), 14: np.float64(0.0594059405940594), 15: np.float64(0.6), 19: np.float64(0.48135593220338985), 20: np.float64(0.3417085427135678), 21: np.float64(0.08), 22: np.float64(0.35494880546075086), 23: np.float64(0.6041666666666666), 24: np.float64(0.0), 25: np.float64(0.3384615384615385), 26: np.float64(0.6073298429319371), 27: np.float64(0.0), 28: np.float64(0.2857142857142857), 29: np.float64(0.6730769230769231), 30: np.float64(0.5925925925925926), 31: np.float64(0.05128205128205128), 32: np.float64(0.4155844155844156), 33: np.float64(0.14545454545454545), 34: np.float64(0.171021377672209), 35: np.float64(0.11956521739130435), 36: np.float64(0.3236994219653179), 37: np.float64(0.23255813953488372), 38: np.float64(0.21739130434782608), 39: np.float64(0.0), 40: np.float64(0.15120274914089346)}
Micro-average F1 score: 0.28445349626612354
Weighted-average F1 score: 0.2663660803648356
F1 score per class: {0: np.float64(0.1715686274509804), 1: np.float64(0.09937888198757763), 2: np.float64(0.16901408450704225), 3: np.float64(0.26303854875283444), 4: np.float64(0.782608695652174), 6: np.float64(0.31466666666666665), 7: np.float64(0.0), 8: np.float64(0.13076923076923078), 9: np.float64(0.3875968992248062), 11: np.float64(0.10416666666666667), 12: np.float64(0.12753623188405797), 13: np.float64(0.05128205128205128), 14: np.float64(0.044444444444444446), 15: np.float64(0.4444444444444444), 19: np.float64(0.4359673024523161), 20: np.float64(0.24761904761904763), 21: np.float64(0.0782608695652174), 22: np.float64(0.28940568475452194), 23: np.float64(0.5217391304347826), 24: np.float64(0.0), 25: np.float64(0.5333333333333333), 26: np.float64(0.6153846153846154), 27: np.float64(0.0), 28: np.float64(0.11235955056179775), 29: np.float64(0.7074235807860262), 30: np.float64(0.21656050955414013), 31: np.float64(0.015748031496062992), 32: np.float64(0.3851508120649652), 33: np.float64(0.08849557522123894), 34: np.float64(0.17110266159695817), 35: np.float64(0.16666666666666666), 36: np.float64(0.30177514792899407), 37: np.float64(0.16161616161616163), 38: np.float64(0.2857142857142857), 39: np.float64(0.17391304347826086), 40: np.float64(0.1329639889196676)}
Micro-average F1 score: 0.25140533429015666
Weighted-average F1 score: 0.23392318773404208
F1 score per class: {0: np.float64(0.20359281437125748), 1: np.float64(0.09623430962343096), 2: np.float64(0.20689655172413793), 3: np.float64(0.30612244897959184), 4: np.float64(0.8404255319148937), 6: np.float64(0.3048128342245989), 7: np.float64(0.0), 8: np.float64(0.1363040629095675), 9: np.float64(0.6097560975609756), 11: np.float64(0.0851063829787234), 12: np.float64(0.12539184952978055), 13: np.float64(0.058823529411764705), 14: np.float64(0.03821656050955414), 15: np.float64(0.42857142857142855), 19: np.float64(0.4584527220630373), 20: np.float64(0.2620689655172414), 21: np.float64(0.08490566037735849), 22: np.float64(0.301994301994302), 23: np.float64(0.5483870967741935), 24: np.float64(0.0), 25: np.float64(0.45569620253164556), 26: np.float64(0.6237623762376238), 27: np.float64(0.0), 28: np.float64(0.10989010989010989), 29: np.float64(0.6905829596412556), 30: np.float64(0.3090909090909091), 31: np.float64(0.028985507246376812), 32: np.float64(0.3854875283446712), 33: np.float64(0.07920792079207921), 34: np.float64(0.16216216216216217), 35: np.float64(0.14482758620689656), 36: np.float64(0.3166023166023166), 37: np.float64(0.16037735849056603), 38: np.float64(0.3225806451612903), 39: np.float64(0.11764705882352941), 40: np.float64(0.125)}
Micro-average F1 score: 0.258390566282234
Weighted-average F1 score: 0.23861464639001875
cur_acc_wo_na:  ['0.7628', '0.4889', '0.3534', '0.5296', '0.3508', '0.4925', '0.5153']
his_acc_wo_na:  ['0.7628', '0.6418', '0.5069', '0.4451', '0.3707', '0.3559', '0.3928']
cur_acc des_wo_na:  ['0.7401', '0.4586', '0.3161', '0.5448', '0.3203', '0.4571', '0.5054']
his_acc des_wo_na:  ['0.7401', '0.5970', '0.4877', '0.4443', '0.3494', '0.3467', '0.3695']
cur_acc rrf_wo_na:  ['0.7584', '0.4384', '0.3175', '0.5405', '0.3353', '0.4618', '0.5050']
his_acc rrf_wo_na:  ['0.7584', '0.6053', '0.4909', '0.4476', '0.3513', '0.3468', '0.3762']
cur_acc_w_na:  ['0.6340', '0.3511', '0.2967', '0.3916', '0.2418', '0.3703', '0.3615']
his_acc_w_na:  ['0.6340', '0.4797', '0.3970', '0.3237', '0.2683', '0.2555', '0.2845']
cur_acc des_w_na:  ['0.6003', '0.3219', '0.2524', '0.3763', '0.2082', '0.3237', '0.3350']
his_acc des_w_na:  ['0.6003', '0.4339', '0.3612', '0.3049', '0.2383', '0.2362', '0.2514']
cur_acc rrf_w_na:  ['0.6215', '0.3033', '0.2604', '0.3883', '0.2204', '0.3283', '0.3344']
his_acc rrf_w_na:  ['0.6215', '0.4437', '0.3708', '0.3134', '0.2425', '0.2379', '0.2584']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 168.8367593CurrentTrain: epoch  0, batch     1 | loss: 180.5621758CurrentTrain: epoch  0, batch     2 | loss: 152.7856613CurrentTrain: epoch  0, batch     3 | loss: 119.1265882CurrentTrain: epoch  0, batch     4 | loss: 90.9369971CurrentTrain: epoch  1, batch     0 | loss: 130.8181395CurrentTrain: epoch  1, batch     1 | loss: 129.7849164CurrentTrain: epoch  1, batch     2 | loss: 159.6987546CurrentTrain: epoch  1, batch     3 | loss: 164.0489726CurrentTrain: epoch  1, batch     4 | loss: 126.4878848CurrentTrain: epoch  2, batch     0 | loss: 151.8925960CurrentTrain: epoch  2, batch     1 | loss: 165.6658018CurrentTrain: epoch  2, batch     2 | loss: 147.4956295CurrentTrain: epoch  2, batch     3 | loss: 139.8942662CurrentTrain: epoch  2, batch     4 | loss: 79.8072885CurrentTrain: epoch  3, batch     0 | loss: 119.9537604CurrentTrain: epoch  3, batch     1 | loss: 142.1136947CurrentTrain: epoch  3, batch     2 | loss: 126.8979932CurrentTrain: epoch  3, batch     3 | loss: 143.9634201CurrentTrain: epoch  3, batch     4 | loss: 110.8227589CurrentTrain: epoch  4, batch     0 | loss: 131.6849636CurrentTrain: epoch  4, batch     1 | loss: 111.2160770CurrentTrain: epoch  4, batch     2 | loss: 146.6728199CurrentTrain: epoch  4, batch     3 | loss: 123.0241660CurrentTrain: epoch  4, batch     4 | loss: 171.3383471CurrentTrain: epoch  5, batch     0 | loss: 126.8741335CurrentTrain: epoch  5, batch     1 | loss: 124.1459194CurrentTrain: epoch  5, batch     2 | loss: 124.3405487CurrentTrain: epoch  5, batch     3 | loss: 146.6590028CurrentTrain: epoch  5, batch     4 | loss: 78.9131217CurrentTrain: epoch  6, batch     0 | loss: 124.2890514CurrentTrain: epoch  6, batch     1 | loss: 134.1517658CurrentTrain: epoch  6, batch     2 | loss: 112.4976005CurrentTrain: epoch  6, batch     3 | loss: 133.1173099CurrentTrain: epoch  6, batch     4 | loss: 105.5247414CurrentTrain: epoch  7, batch     0 | loss: 133.8279125CurrentTrain: epoch  7, batch     1 | loss: 125.4721758CurrentTrain: epoch  7, batch     2 | loss: 172.8565415CurrentTrain: epoch  7, batch     3 | loss: 105.5398361CurrentTrain: epoch  7, batch     4 | loss: 89.8695991CurrentTrain: epoch  8, batch     0 | loss: 137.6093442CurrentTrain: epoch  8, batch     1 | loss: 126.7409687CurrentTrain: epoch  8, batch     2 | loss: 141.3508488CurrentTrain: epoch  8, batch     3 | loss: 117.7156209CurrentTrain: epoch  8, batch     4 | loss: 77.6961953CurrentTrain: epoch  9, batch     0 | loss: 140.8817174CurrentTrain: epoch  9, batch     1 | loss: 125.9309686CurrentTrain: epoch  9, batch     2 | loss: 111.0392013CurrentTrain: epoch  9, batch     3 | loss: 144.6556106CurrentTrain: epoch  9, batch     4 | loss: 90.1283613
MemoryTrain:  epoch  0, batch     0 | loss: 1.0446779MemoryTrain:  epoch  1, batch     0 | loss: 0.8552563MemoryTrain:  epoch  2, batch     0 | loss: 0.6949296MemoryTrain:  epoch  3, batch     0 | loss: 0.5743984MemoryTrain:  epoch  4, batch     0 | loss: 0.4570363MemoryTrain:  epoch  5, batch     0 | loss: 0.3636256MemoryTrain:  epoch  6, batch     0 | loss: 0.4153879MemoryTrain:  epoch  7, batch     0 | loss: 0.2623864MemoryTrain:  epoch  8, batch     0 | loss: 0.2494571MemoryTrain:  epoch  9, batch     0 | loss: 0.2397130

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.8532110091743119), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.3140495867768595), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.6274509803921569), 17: np.float64(0.8), 18: np.float64(0.24096385542168675), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.48896434634974534
Weighted-average F1 score: 0.4355742758546829
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.5773809523809523), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.49295774647887325), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.576271186440678), 17: np.float64(0.7777777777777778), 18: np.float64(0.18326693227091634), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.358
Weighted-average F1 score: 0.3037253011419519
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.7320754716981132), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.5205479452054794), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.576271186440678), 17: np.float64(0.75), 18: np.float64(0.24358974358974358), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4179456906729634
Weighted-average F1 score: 0.3427087604266197

F1 score per class: {0: np.float64(0.6060606060606061), 1: np.float64(0.15966386554621848), 2: np.float64(0.5263157894736842), 3: np.float64(0.26666666666666666), 4: np.float64(0.7831325301204819), 5: np.float64(0.7237354085603113), 6: np.float64(0.26582278481012656), 7: np.float64(0.0), 8: np.float64(0.26277372262773724), 9: np.float64(0.7384615384615385), 10: np.float64(0.21965317919075145), 11: np.float64(0.02247191011235955), 12: np.float64(0.136986301369863), 13: np.float64(0.07142857142857142), 14: np.float64(0.07228915662650602), 15: np.float64(0.5263157894736842), 16: np.float64(0.5161290322580645), 17: np.float64(0.42857142857142855), 18: np.float64(0.17857142857142858), 19: np.float64(0.5107913669064749), 20: np.float64(0.5517241379310345), 21: np.float64(0.1038961038961039), 22: np.float64(0.43243243243243246), 23: np.float64(0.6666666666666666), 24: np.float64(0.0), 25: np.float64(0.3125), 26: np.float64(0.627906976744186), 27: np.float64(0.0), 28: np.float64(0.38461538461538464), 29: np.float64(0.7403314917127072), 30: np.float64(0.7567567567567568), 31: np.float64(0.125), 32: np.float64(0.6090909090909091), 33: np.float64(0.2222222222222222), 34: np.float64(0.23417721518987342), 35: np.float64(0.19801980198019803), 36: np.float64(0.4), 37: np.float64(0.3418803418803419), 38: np.float64(0.24242424242424243), 39: np.float64(0.0), 40: np.float64(0.19900497512437812)}
Micro-average F1 score: 0.38914832110295755
Weighted-average F1 score: 0.3871525724676885
F1 score per class: {0: np.float64(0.3119266055045872), 1: np.float64(0.16666666666666666), 2: np.float64(0.35294117647058826), 3: np.float64(0.34782608695652173), 4: np.float64(0.8341232227488151), 5: np.float64(0.40501043841336115), 6: np.float64(0.4485981308411215), 7: np.float64(0.0392156862745098), 8: np.float64(0.28378378378378377), 9: np.float64(0.45045045045045046), 10: np.float64(0.3465346534653465), 11: np.float64(0.16494845360824742), 12: np.float64(0.27419354838709675), 13: np.float64(0.14285714285714285), 14: np.float64(0.05405405405405406), 15: np.float64(0.5), 16: np.float64(0.40963855421686746), 17: np.float64(0.16279069767441862), 18: np.float64(0.09850107066381156), 19: np.float64(0.4716417910447761), 20: np.float64(0.3142857142857143), 21: np.float64(0.13071895424836602), 22: np.float64(0.391304347826087), 23: np.float64(0.625), 24: np.float64(0.0), 25: np.float64(0.4878048780487805), 26: np.float64(0.6951871657754011), 27: np.float64(0.0), 28: np.float64(0.17857142857142858), 29: np.float64(0.8163265306122449), 30: np.float64(0.2698412698412698), 31: np.float64(0.03333333333333333), 32: np.float64(0.5605536332179931), 33: np.float64(0.11235955056179775), 34: np.float64(0.2901960784313726), 35: np.float64(0.2962962962962963), 36: np.float64(0.4720496894409938), 37: np.float64(0.14893617021276595), 38: np.float64(0.48), 39: np.float64(0.11764705882352941), 40: np.float64(0.1299638989169675)}
Micro-average F1 score: 0.3430625449317038
Weighted-average F1 score: 0.3220556465958151
F1 score per class: {0: np.float64(0.34972677595628415), 1: np.float64(0.17490494296577946), 2: np.float64(0.42857142857142855), 3: np.float64(0.3617021276595745), 4: np.float64(0.8804347826086957), 5: np.float64(0.5257452574525745), 6: np.float64(0.42786069651741293), 7: np.float64(0.0), 8: np.float64(0.3023255813953488), 9: np.float64(0.6756756756756757), 10: np.float64(0.3377777777777778), 11: np.float64(0.08602150537634409), 12: np.float64(0.23684210526315788), 13: np.float64(0.14285714285714285), 14: np.float64(0.06153846153846154), 15: np.float64(0.46153846153846156), 16: np.float64(0.40476190476190477), 17: np.float64(0.19672131147540983), 18: np.float64(0.14728682170542637), 19: np.float64(0.4876543209876543), 20: np.float64(0.4444444444444444), 21: np.float64(0.12578616352201258), 22: np.float64(0.41295546558704455), 23: np.float64(0.6285714285714286), 24: np.float64(0.0), 25: np.float64(0.43243243243243246), 26: np.float64(0.6703296703296703), 27: np.float64(0.0), 28: np.float64(0.1694915254237288), 29: np.float64(0.8125), 30: np.float64(0.4146341463414634), 31: np.float64(0.05405405405405406), 32: np.float64(0.5724907063197026), 33: np.float64(0.0898876404494382), 34: np.float64(0.21717171717171718), 35: np.float64(0.2185792349726776), 36: np.float64(0.5481481481481482), 37: np.float64(0.17073170731707318), 38: np.float64(0.35294117647058826), 39: np.float64(0.21052631578947367), 40: np.float64(0.12318840579710146)}
Micro-average F1 score: 0.3600644122383253
Weighted-average F1 score: 0.3391083369189786

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.6739130434782609), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.29457364341085274), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.463768115942029), 17: np.float64(0.6), 18: np.float64(0.19801980198019803), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.33962264150943394
Weighted-average F1 score: 0.2876076139153154
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.4349775784753363), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.45161290322580644), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.40476190476190477), 17: np.float64(0.5), 18: np.float64(0.14241486068111456), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.23661599471249173
Weighted-average F1 score: 0.20002323754391862
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.532967032967033), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.4691358024691358), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.40476190476190477), 17: np.float64(0.5), 18: np.float64(0.18357487922705315), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2698170731707317
Weighted-average F1 score: 0.22234998917193532

F1 score per class: {0: np.float64(0.43478260869565216), 1: np.float64(0.08775981524249422), 2: np.float64(0.2857142857142857), 3: np.float64(0.21374045801526717), 4: np.float64(0.7386363636363636), 5: np.float64(0.5166666666666667), 6: np.float64(0.17796610169491525), 7: np.float64(0.0), 8: np.float64(0.20930232558139536), 9: np.float64(0.676056338028169), 10: np.float64(0.1792452830188679), 11: np.float64(0.02247191011235955), 12: np.float64(0.08733624454148471), 13: np.float64(0.0392156862745098), 14: np.float64(0.06451612903225806), 15: np.float64(0.45454545454545453), 16: np.float64(0.3516483516483517), 17: np.float64(0.27906976744186046), 18: np.float64(0.12578616352201258), 19: np.float64(0.46864686468646866), 20: np.float64(0.2909090909090909), 21: np.float64(0.0784313725490196), 22: np.float64(0.3287671232876712), 23: np.float64(0.5918367346938775), 24: np.float64(0.0), 25: np.float64(0.30303030303030304), 26: np.float64(0.5654450261780105), 27: np.float64(0.0), 28: np.float64(0.2564102564102564), 29: np.float64(0.6568627450980392), 30: np.float64(0.6222222222222222), 31: np.float64(0.07407407407407407), 32: np.float64(0.46048109965635736), 33: np.float64(0.13559322033898305), 34: np.float64(0.14566929133858267), 35: np.float64(0.15267175572519084), 36: np.float64(0.3025210084033613), 37: np.float64(0.25477707006369427), 38: np.float64(0.18604651162790697), 39: np.float64(0.0), 40: np.float64(0.1652892561983471)}
Micro-average F1 score: 0.28911283660994547
Weighted-average F1 score: 0.27582175940863524
F1 score per class: {0: np.float64(0.2125), 1: np.float64(0.09145129224652088), 2: np.float64(0.21052631578947367), 3: np.float64(0.22346368715083798), 4: np.float64(0.7242798353909465), 5: np.float64(0.25064599483204136), 6: np.float64(0.2601626016260163), 7: np.float64(0.02247191011235955), 8: np.float64(0.1791044776119403), 9: np.float64(0.3472222222222222), 10: np.float64(0.24390243902439024), 11: np.float64(0.1568627450980392), 12: np.float64(0.13821138211382114), 13: np.float64(0.06451612903225806), 14: np.float64(0.046511627906976744), 15: np.float64(0.42857142857142855), 16: np.float64(0.2677165354330709), 17: np.float64(0.09210526315789473), 18: np.float64(0.07198748043818466), 19: np.float64(0.4082687338501292), 20: np.float64(0.1752988047808765), 21: np.float64(0.091324200913242), 22: np.float64(0.2727272727272727), 23: np.float64(0.44871794871794873), 24: np.float64(0.0), 25: np.float64(0.45454545454545453), 26: np.float64(0.6103286384976526), 27: np.float64(0.0), 28: np.float64(0.10526315789473684), 29: np.float64(0.6926406926406926), 30: np.float64(0.2125), 31: np.float64(0.01904761904761905), 32: np.float64(0.39705882352941174), 33: np.float64(0.062111801242236024), 34: np.float64(0.16666666666666666), 35: np.float64(0.20711974110032363), 36: np.float64(0.26666666666666666), 37: np.float64(0.11290322580645161), 38: np.float64(0.2608695652173913), 39: np.float64(0.07142857142857142), 40: np.float64(0.0906801007556675)}
Micro-average F1 score: 0.22977657935285054
Weighted-average F1 score: 0.21500919147434375
F1 score per class: {0: np.float64(0.23443223443223443), 1: np.float64(0.09484536082474226), 2: np.float64(0.24489795918367346), 3: np.float64(0.2556390977443609), 4: np.float64(0.8223350253807107), 5: np.float64(0.31239935587761675), 6: np.float64(0.24362606232294617), 7: np.float64(0.0), 8: np.float64(0.1822429906542056), 9: np.float64(0.5882352941176471), 10: np.float64(0.23529411764705882), 11: np.float64(0.08333333333333333), 12: np.float64(0.11920529801324503), 13: np.float64(0.06060606060606061), 14: np.float64(0.05263157894736842), 15: np.float64(0.3870967741935484), 16: np.float64(0.26356589147286824), 17: np.float64(0.11764705882352941), 18: np.float64(0.10215053763440861), 19: np.float64(0.43169398907103823), 20: np.float64(0.21649484536082475), 21: np.float64(0.08771929824561403), 22: np.float64(0.2947976878612717), 23: np.float64(0.4489795918367347), 24: np.float64(0.0), 25: np.float64(0.4050632911392405), 26: np.float64(0.5951219512195122), 27: np.float64(0.0), 28: np.float64(0.10416666666666667), 29: np.float64(0.6902654867256637), 30: np.float64(0.3238095238095238), 31: np.float64(0.031746031746031744), 32: np.float64(0.3979328165374677), 33: np.float64(0.05), 34: np.float64(0.1371610845295056), 35: np.float64(0.15384615384615385), 36: np.float64(0.3162393162393162), 37: np.float64(0.12727272727272726), 38: np.float64(0.20689655172413793), 39: np.float64(0.15384615384615385), 40: np.float64(0.08607594936708861)}
Micro-average F1 score: 0.24149476185333188
Weighted-average F1 score: 0.22506300140742996
cur_acc_wo_na:  ['0.7628', '0.4889', '0.3534', '0.5296', '0.3508', '0.4925', '0.5153', '0.4890']
his_acc_wo_na:  ['0.7628', '0.6418', '0.5069', '0.4451', '0.3707', '0.3559', '0.3928', '0.3891']
cur_acc des_wo_na:  ['0.7401', '0.4586', '0.3161', '0.5448', '0.3203', '0.4571', '0.5054', '0.3580']
his_acc des_wo_na:  ['0.7401', '0.5970', '0.4877', '0.4443', '0.3494', '0.3467', '0.3695', '0.3431']
cur_acc rrf_wo_na:  ['0.7584', '0.4384', '0.3175', '0.5405', '0.3353', '0.4618', '0.5050', '0.4179']
his_acc rrf_wo_na:  ['0.7584', '0.6053', '0.4909', '0.4476', '0.3513', '0.3468', '0.3762', '0.3601']
cur_acc_w_na:  ['0.6340', '0.3511', '0.2967', '0.3916', '0.2418', '0.3703', '0.3615', '0.3396']
his_acc_w_na:  ['0.6340', '0.4797', '0.3970', '0.3237', '0.2683', '0.2555', '0.2845', '0.2891']
cur_acc des_w_na:  ['0.6003', '0.3219', '0.2524', '0.3763', '0.2082', '0.3237', '0.3350', '0.2366']
his_acc des_w_na:  ['0.6003', '0.4339', '0.3612', '0.3049', '0.2383', '0.2362', '0.2514', '0.2298']
cur_acc rrf_w_na:  ['0.6215', '0.3033', '0.2604', '0.3883', '0.2204', '0.3283', '0.3344', '0.2698']
his_acc rrf_w_na:  ['0.6215', '0.4437', '0.3708', '0.3134', '0.2425', '0.2379', '0.2584', '0.2415']
--------Round  1
seed:  200
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 6 3 2 4 0 5 1]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 167.1377503CurrentTrain: epoch  0, batch     1 | loss: 118.7062732CurrentTrain: epoch  0, batch     2 | loss: 122.9029455CurrentTrain: epoch  0, batch     3 | loss: 146.0144915CurrentTrain: epoch  0, batch     4 | loss: 121.4279256CurrentTrain: epoch  0, batch     5 | loss: 187.6274140CurrentTrain: epoch  0, batch     6 | loss: 126.0170294CurrentTrain: epoch  0, batch     7 | loss: 146.6327578CurrentTrain: epoch  0, batch     8 | loss: 124.3537538CurrentTrain: epoch  0, batch     9 | loss: 152.9712616CurrentTrain: epoch  0, batch    10 | loss: 126.7412187CurrentTrain: epoch  0, batch    11 | loss: 145.7677265CurrentTrain: epoch  0, batch    12 | loss: 121.3907596CurrentTrain: epoch  0, batch    13 | loss: 174.6809045CurrentTrain: epoch  0, batch    14 | loss: 139.7278672CurrentTrain: epoch  0, batch    15 | loss: 148.1580680CurrentTrain: epoch  0, batch    16 | loss: 140.5593224CurrentTrain: epoch  0, batch    17 | loss: 102.6624532CurrentTrain: epoch  0, batch    18 | loss: 134.1845480CurrentTrain: epoch  0, batch    19 | loss: 139.3001281CurrentTrain: epoch  0, batch    20 | loss: 159.1082912CurrentTrain: epoch  0, batch    21 | loss: 160.4776736CurrentTrain: epoch  0, batch    22 | loss: 135.6672580CurrentTrain: epoch  0, batch    23 | loss: 143.6671609CurrentTrain: epoch  0, batch    24 | loss: 121.8228895CurrentTrain: epoch  0, batch    25 | loss: 168.0741217CurrentTrain: epoch  0, batch    26 | loss: 144.6064805CurrentTrain: epoch  0, batch    27 | loss: 135.3620863CurrentTrain: epoch  0, batch    28 | loss: 130.9162224CurrentTrain: epoch  0, batch    29 | loss: 138.8180761CurrentTrain: epoch  0, batch    30 | loss: 133.4101154CurrentTrain: epoch  0, batch    31 | loss: 161.6352638CurrentTrain: epoch  0, batch    32 | loss: 109.0166890CurrentTrain: epoch  0, batch    33 | loss: 129.3508443CurrentTrain: epoch  0, batch    34 | loss: 167.9758166CurrentTrain: epoch  0, batch    35 | loss: 147.3105128CurrentTrain: epoch  0, batch    36 | loss: 133.8583693CurrentTrain: epoch  0, batch    37 | loss: 138.3579300CurrentTrain: epoch  0, batch    38 | loss: 141.0513681CurrentTrain: epoch  0, batch    39 | loss: 138.6360070CurrentTrain: epoch  0, batch    40 | loss: 180.7004683CurrentTrain: epoch  0, batch    41 | loss: 151.7055272CurrentTrain: epoch  0, batch    42 | loss: 137.6977222CurrentTrain: epoch  0, batch    43 | loss: 138.4024093CurrentTrain: epoch  0, batch    44 | loss: 151.9354185CurrentTrain: epoch  0, batch    45 | loss: 153.3999381CurrentTrain: epoch  0, batch    46 | loss: 175.4420601CurrentTrain: epoch  0, batch    47 | loss: 126.9368666CurrentTrain: epoch  0, batch    48 | loss: 132.6117333CurrentTrain: epoch  0, batch    49 | loss: 144.7045084CurrentTrain: epoch  0, batch    50 | loss: 104.8375971CurrentTrain: epoch  0, batch    51 | loss: 159.1042551CurrentTrain: epoch  0, batch    52 | loss: 123.0020751CurrentTrain: epoch  0, batch    53 | loss: 121.6460639CurrentTrain: epoch  0, batch    54 | loss: 107.8594555CurrentTrain: epoch  0, batch    55 | loss: 225.8621466CurrentTrain: epoch  0, batch    56 | loss: 185.4490710CurrentTrain: epoch  0, batch    57 | loss: 219.3867922CurrentTrain: epoch  0, batch    58 | loss: 155.6653935CurrentTrain: epoch  0, batch    59 | loss: 152.0344035CurrentTrain: epoch  0, batch    60 | loss: 171.0796487CurrentTrain: epoch  0, batch    61 | loss: 105.1209659CurrentTrain: epoch  0, batch    62 | loss: 219.4757640CurrentTrain: epoch  0, batch    63 | loss: 143.2219450CurrentTrain: epoch  0, batch    64 | loss: 128.8078993CurrentTrain: epoch  0, batch    65 | loss: 140.6884084CurrentTrain: epoch  0, batch    66 | loss: 168.4455712CurrentTrain: epoch  0, batch    67 | loss: 137.4989362CurrentTrain: epoch  0, batch    68 | loss: 121.4330984CurrentTrain: epoch  0, batch    69 | loss: 181.8728214CurrentTrain: epoch  0, batch    70 | loss: 136.2274276CurrentTrain: epoch  0, batch    71 | loss: 116.2586045CurrentTrain: epoch  0, batch    72 | loss: 140.5042176CurrentTrain: epoch  0, batch    73 | loss: 133.5038769CurrentTrain: epoch  0, batch    74 | loss: 157.6840166CurrentTrain: epoch  0, batch    75 | loss: 152.3737733CurrentTrain: epoch  0, batch    76 | loss: 174.1172483CurrentTrain: epoch  0, batch    77 | loss: 147.6690307CurrentTrain: epoch  0, batch    78 | loss: 143.6389573CurrentTrain: epoch  0, batch    79 | loss: 133.0375599CurrentTrain: epoch  0, batch    80 | loss: 123.8947525CurrentTrain: epoch  0, batch    81 | loss: 116.2297778CurrentTrain: epoch  0, batch    82 | loss: 134.5011825CurrentTrain: epoch  0, batch    83 | loss: 129.0954863CurrentTrain: epoch  0, batch    84 | loss: 122.6747673CurrentTrain: epoch  0, batch    85 | loss: 147.5529481CurrentTrain: epoch  0, batch    86 | loss: 137.7966708CurrentTrain: epoch  0, batch    87 | loss: 153.5039374CurrentTrain: epoch  0, batch    88 | loss: 114.1670803CurrentTrain: epoch  0, batch    89 | loss: 151.3615361CurrentTrain: epoch  0, batch    90 | loss: 138.3407452CurrentTrain: epoch  0, batch    91 | loss: 133.9418705CurrentTrain: epoch  0, batch    92 | loss: 131.6832317CurrentTrain: epoch  0, batch    93 | loss: 137.3146898CurrentTrain: epoch  0, batch    94 | loss: 181.6057730CurrentTrain: epoch  0, batch    95 | loss: 146.6497953CurrentTrain: epoch  1, batch     0 | loss: 134.5063499CurrentTrain: epoch  1, batch     1 | loss: 113.5329076CurrentTrain: epoch  1, batch     2 | loss: 159.4960298CurrentTrain: epoch  1, batch     3 | loss: 111.9506628CurrentTrain: epoch  1, batch     4 | loss: 148.5555535CurrentTrain: epoch  1, batch     5 | loss: 150.8889414CurrentTrain: epoch  1, batch     6 | loss: 171.0307285CurrentTrain: epoch  1, batch     7 | loss: 177.9674023CurrentTrain: epoch  1, batch     8 | loss: 192.1899903CurrentTrain: epoch  1, batch     9 | loss: 151.5209202CurrentTrain: epoch  1, batch    10 | loss: 145.9198945CurrentTrain: epoch  1, batch    11 | loss: 108.6943197CurrentTrain: epoch  1, batch    12 | loss: 156.2869596CurrentTrain: epoch  1, batch    13 | loss: 131.1120519CurrentTrain: epoch  1, batch    14 | loss: 139.4010266CurrentTrain: epoch  1, batch    15 | loss: 133.4941913CurrentTrain: epoch  1, batch    16 | loss: 146.1869757CurrentTrain: epoch  1, batch    17 | loss: 130.1321705CurrentTrain: epoch  1, batch    18 | loss: 125.8105154CurrentTrain: epoch  1, batch    19 | loss: 117.2551542CurrentTrain: epoch  1, batch    20 | loss: 117.8672006CurrentTrain: epoch  1, batch    21 | loss: 173.9352867CurrentTrain: epoch  1, batch    22 | loss: 107.3375072CurrentTrain: epoch  1, batch    23 | loss: 124.5197944CurrentTrain: epoch  1, batch    24 | loss: 105.8673997CurrentTrain: epoch  1, batch    25 | loss: 125.9025453CurrentTrain: epoch  1, batch    26 | loss: 124.6038398CurrentTrain: epoch  1, batch    27 | loss: 147.2233314CurrentTrain: epoch  1, batch    28 | loss: 175.4617157CurrentTrain: epoch  1, batch    29 | loss: 130.3963339CurrentTrain: epoch  1, batch    30 | loss: 130.5361374CurrentTrain: epoch  1, batch    31 | loss: 129.0234667CurrentTrain: epoch  1, batch    32 | loss: 118.7250266CurrentTrain: epoch  1, batch    33 | loss: 106.7868645CurrentTrain: epoch  1, batch    34 | loss: 175.1089140CurrentTrain: epoch  1, batch    35 | loss: 153.0079235CurrentTrain: epoch  1, batch    36 | loss: 113.9008114CurrentTrain: epoch  1, batch    37 | loss: 150.0346152CurrentTrain: epoch  1, batch    38 | loss: 179.6188950CurrentTrain: epoch  1, batch    39 | loss: 137.7124781CurrentTrain: epoch  1, batch    40 | loss: 116.8466598CurrentTrain: epoch  1, batch    41 | loss: 136.2374527CurrentTrain: epoch  1, batch    42 | loss: 150.3179928CurrentTrain: epoch  1, batch    43 | loss: 124.4807472CurrentTrain: epoch  1, batch    44 | loss: 145.4239264CurrentTrain: epoch  1, batch    45 | loss: 150.5959912CurrentTrain: epoch  1, batch    46 | loss: 210.1495181CurrentTrain: epoch  1, batch    47 | loss: 128.5709517CurrentTrain: epoch  1, batch    48 | loss: 142.3895183CurrentTrain: epoch  1, batch    49 | loss: 128.1258704CurrentTrain: epoch  1, batch    50 | loss: 148.8449974CurrentTrain: epoch  1, batch    51 | loss: 138.4070062CurrentTrain: epoch  1, batch    52 | loss: 179.1985258CurrentTrain: epoch  1, batch    53 | loss: 125.3319178CurrentTrain: epoch  1, batch    54 | loss: 122.7363728CurrentTrain: epoch  1, batch    55 | loss: 135.2838938CurrentTrain: epoch  1, batch    56 | loss: 124.7600316CurrentTrain: epoch  1, batch    57 | loss: 113.1218570CurrentTrain: epoch  1, batch    58 | loss: 155.0248250CurrentTrain: epoch  1, batch    59 | loss: 145.5786364CurrentTrain: epoch  1, batch    60 | loss: 109.4620712CurrentTrain: epoch  1, batch    61 | loss: 103.5994907CurrentTrain: epoch  1, batch    62 | loss: 155.1702718CurrentTrain: epoch  1, batch    63 | loss: 161.6337323CurrentTrain: epoch  1, batch    64 | loss: 115.5515807CurrentTrain: epoch  1, batch    65 | loss: 126.3163655CurrentTrain: epoch  1, batch    66 | loss: 141.5159888CurrentTrain: epoch  1, batch    67 | loss: 102.6231063CurrentTrain: epoch  1, batch    68 | loss: 139.2600419CurrentTrain: epoch  1, batch    69 | loss: 119.4610579CurrentTrain: epoch  1, batch    70 | loss: 161.9076898CurrentTrain: epoch  1, batch    71 | loss: 111.3436288CurrentTrain: epoch  1, batch    72 | loss: 145.4533721CurrentTrain: epoch  1, batch    73 | loss: 116.4228591CurrentTrain: epoch  1, batch    74 | loss: 127.9628718CurrentTrain: epoch  1, batch    75 | loss: 118.2422776CurrentTrain: epoch  1, batch    76 | loss: 131.1569916CurrentTrain: epoch  1, batch    77 | loss: 104.3604917CurrentTrain: epoch  1, batch    78 | loss: 128.7643546CurrentTrain: epoch  1, batch    79 | loss: 146.3742537CurrentTrain: epoch  1, batch    80 | loss: 124.5734068CurrentTrain: epoch  1, batch    81 | loss: 145.3848810CurrentTrain: epoch  1, batch    82 | loss: 124.0639526CurrentTrain: epoch  1, batch    83 | loss: 133.9671925CurrentTrain: epoch  1, batch    84 | loss: 121.2650809CurrentTrain: epoch  1, batch    85 | loss: 114.2570158CurrentTrain: epoch  1, batch    86 | loss: 130.8864822CurrentTrain: epoch  1, batch    87 | loss: 119.3484153CurrentTrain: epoch  1, batch    88 | loss: 139.1663576CurrentTrain: epoch  1, batch    89 | loss: 126.6262967CurrentTrain: epoch  1, batch    90 | loss: 121.8477713CurrentTrain: epoch  1, batch    91 | loss: 128.0698845CurrentTrain: epoch  1, batch    92 | loss: 130.7602809CurrentTrain: epoch  1, batch    93 | loss: 127.0093939CurrentTrain: epoch  1, batch    94 | loss: 127.6505546CurrentTrain: epoch  1, batch    95 | loss: 106.3237113CurrentTrain: epoch  2, batch     0 | loss: 104.8414622CurrentTrain: epoch  2, batch     1 | loss: 104.9205859CurrentTrain: epoch  2, batch     2 | loss: 125.0413587CurrentTrain: epoch  2, batch     3 | loss: 123.1030785CurrentTrain: epoch  2, batch     4 | loss: 101.6569082CurrentTrain: epoch  2, batch     5 | loss: 152.6012325CurrentTrain: epoch  2, batch     6 | loss: 122.5071254CurrentTrain: epoch  2, batch     7 | loss: 129.6272451CurrentTrain: epoch  2, batch     8 | loss: 176.2216263CurrentTrain: epoch  2, batch     9 | loss: 128.9834110CurrentTrain: epoch  2, batch    10 | loss: 123.1462020CurrentTrain: epoch  2, batch    11 | loss: 123.7626911CurrentTrain: epoch  2, batch    12 | loss: 95.0402651CurrentTrain: epoch  2, batch    13 | loss: 144.8668088CurrentTrain: epoch  2, batch    14 | loss: 123.5833557CurrentTrain: epoch  2, batch    15 | loss: 142.5852662CurrentTrain: epoch  2, batch    16 | loss: 99.3753954CurrentTrain: epoch  2, batch    17 | loss: 143.6541580CurrentTrain: epoch  2, batch    18 | loss: 171.8214825CurrentTrain: epoch  2, batch    19 | loss: 125.2980897CurrentTrain: epoch  2, batch    20 | loss: 136.9966092CurrentTrain: epoch  2, batch    21 | loss: 144.8392627CurrentTrain: epoch  2, batch    22 | loss: 144.2878666CurrentTrain: epoch  2, batch    23 | loss: 103.0707484CurrentTrain: epoch  2, batch    24 | loss: 99.5381626CurrentTrain: epoch  2, batch    25 | loss: 131.8488442CurrentTrain: epoch  2, batch    26 | loss: 98.0854215CurrentTrain: epoch  2, batch    27 | loss: 129.2005237CurrentTrain: epoch  2, batch    28 | loss: 123.2866046CurrentTrain: epoch  2, batch    29 | loss: 132.1996955CurrentTrain: epoch  2, batch    30 | loss: 129.7263306CurrentTrain: epoch  2, batch    31 | loss: 125.5854432CurrentTrain: epoch  2, batch    32 | loss: 146.3523401CurrentTrain: epoch  2, batch    33 | loss: 175.5849189CurrentTrain: epoch  2, batch    34 | loss: 128.5767021CurrentTrain: epoch  2, batch    35 | loss: 139.0246168CurrentTrain: epoch  2, batch    36 | loss: 165.9483263CurrentTrain: epoch  2, batch    37 | loss: 136.3796651CurrentTrain: epoch  2, batch    38 | loss: 131.1520261CurrentTrain: epoch  2, batch    39 | loss: 150.4460398CurrentTrain: epoch  2, batch    40 | loss: 128.2838274CurrentTrain: epoch  2, batch    41 | loss: 108.9532098CurrentTrain: epoch  2, batch    42 | loss: 107.3157954CurrentTrain: epoch  2, batch    43 | loss: 106.1858889CurrentTrain: epoch  2, batch    44 | loss: 170.0017661CurrentTrain: epoch  2, batch    45 | loss: 133.7149083CurrentTrain: epoch  2, batch    46 | loss: 129.5041555CurrentTrain: epoch  2, batch    47 | loss: 123.8511546CurrentTrain: epoch  2, batch    48 | loss: 165.5460116CurrentTrain: epoch  2, batch    49 | loss: 101.5580569CurrentTrain: epoch  2, batch    50 | loss: 159.3277385CurrentTrain: epoch  2, batch    51 | loss: 127.7141080CurrentTrain: epoch  2, batch    52 | loss: 144.4323813CurrentTrain: epoch  2, batch    53 | loss: 106.2400047CurrentTrain: epoch  2, batch    54 | loss: 147.7258978CurrentTrain: epoch  2, batch    55 | loss: 130.7199570CurrentTrain: epoch  2, batch    56 | loss: 141.3092315CurrentTrain: epoch  2, batch    57 | loss: 123.7502136CurrentTrain: epoch  2, batch    58 | loss: 127.7389920CurrentTrain: epoch  2, batch    59 | loss: 150.6905619CurrentTrain: epoch  2, batch    60 | loss: 140.4368313CurrentTrain: epoch  2, batch    61 | loss: 147.0553084CurrentTrain: epoch  2, batch    62 | loss: 113.3606489CurrentTrain: epoch  2, batch    63 | loss: 130.1437647CurrentTrain: epoch  2, batch    64 | loss: 97.6017974CurrentTrain: epoch  2, batch    65 | loss: 146.0590314CurrentTrain: epoch  2, batch    66 | loss: 108.9302308CurrentTrain: epoch  2, batch    67 | loss: 132.2347873CurrentTrain: epoch  2, batch    68 | loss: 115.7070109CurrentTrain: epoch  2, batch    69 | loss: 125.4763014CurrentTrain: epoch  2, batch    70 | loss: 174.4745667CurrentTrain: epoch  2, batch    71 | loss: 106.4581903CurrentTrain: epoch  2, batch    72 | loss: 119.0985892CurrentTrain: epoch  2, batch    73 | loss: 170.5718603CurrentTrain: epoch  2, batch    74 | loss: 128.5971088CurrentTrain: epoch  2, batch    75 | loss: 114.5826280CurrentTrain: epoch  2, batch    76 | loss: 152.0959411CurrentTrain: epoch  2, batch    77 | loss: 139.2187812CurrentTrain: epoch  2, batch    78 | loss: 148.4020775CurrentTrain: epoch  2, batch    79 | loss: 118.3024658CurrentTrain: epoch  2, batch    80 | loss: 174.1309805CurrentTrain: epoch  2, batch    81 | loss: 109.7581849CurrentTrain: epoch  2, batch    82 | loss: 140.6758375CurrentTrain: epoch  2, batch    83 | loss: 112.3447324CurrentTrain: epoch  2, batch    84 | loss: 103.8280414CurrentTrain: epoch  2, batch    85 | loss: 135.3459886CurrentTrain: epoch  2, batch    86 | loss: 177.9683538CurrentTrain: epoch  2, batch    87 | loss: 154.2969743CurrentTrain: epoch  2, batch    88 | loss: 126.0721061CurrentTrain: epoch  2, batch    89 | loss: 123.0052736CurrentTrain: epoch  2, batch    90 | loss: 121.6121307CurrentTrain: epoch  2, batch    91 | loss: 130.2850109CurrentTrain: epoch  2, batch    92 | loss: 157.8747276CurrentTrain: epoch  2, batch    93 | loss: 176.3353201CurrentTrain: epoch  2, batch    94 | loss: 112.2018567CurrentTrain: epoch  2, batch    95 | loss: 136.8083342CurrentTrain: epoch  3, batch     0 | loss: 173.8803938CurrentTrain: epoch  3, batch     1 | loss: 107.5000826CurrentTrain: epoch  3, batch     2 | loss: 102.4463608CurrentTrain: epoch  3, batch     3 | loss: 114.3152486CurrentTrain: epoch  3, batch     4 | loss: 154.8064839CurrentTrain: epoch  3, batch     5 | loss: 113.1183680CurrentTrain: epoch  3, batch     6 | loss: 107.5405055CurrentTrain: epoch  3, batch     7 | loss: 166.0724106CurrentTrain: epoch  3, batch     8 | loss: 123.7017979CurrentTrain: epoch  3, batch     9 | loss: 100.9309432CurrentTrain: epoch  3, batch    10 | loss: 146.7896089CurrentTrain: epoch  3, batch    11 | loss: 138.9173284CurrentTrain: epoch  3, batch    12 | loss: 114.4386440CurrentTrain: epoch  3, batch    13 | loss: 152.3702191CurrentTrain: epoch  3, batch    14 | loss: 122.1266655CurrentTrain: epoch  3, batch    15 | loss: 115.0916033CurrentTrain: epoch  3, batch    16 | loss: 129.8980814CurrentTrain: epoch  3, batch    17 | loss: 115.7970473CurrentTrain: epoch  3, batch    18 | loss: 130.5039715CurrentTrain: epoch  3, batch    19 | loss: 161.0725993CurrentTrain: epoch  3, batch    20 | loss: 130.5501755CurrentTrain: epoch  3, batch    21 | loss: 132.4833134CurrentTrain: epoch  3, batch    22 | loss: 112.6655848CurrentTrain: epoch  3, batch    23 | loss: 174.6845788CurrentTrain: epoch  3, batch    24 | loss: 109.8982830CurrentTrain: epoch  3, batch    25 | loss: 142.9287740CurrentTrain: epoch  3, batch    26 | loss: 143.5322449CurrentTrain: epoch  3, batch    27 | loss: 97.3470210CurrentTrain: epoch  3, batch    28 | loss: 119.1582200CurrentTrain: epoch  3, batch    29 | loss: 117.9421423CurrentTrain: epoch  3, batch    30 | loss: 168.8704579CurrentTrain: epoch  3, batch    31 | loss: 146.4092867CurrentTrain: epoch  3, batch    32 | loss: 176.6315852CurrentTrain: epoch  3, batch    33 | loss: 139.8748612CurrentTrain: epoch  3, batch    34 | loss: 143.7343560CurrentTrain: epoch  3, batch    35 | loss: 125.4546092CurrentTrain: epoch  3, batch    36 | loss: 136.8837542CurrentTrain: epoch  3, batch    37 | loss: 108.8739483CurrentTrain: epoch  3, batch    38 | loss: 117.4424051CurrentTrain: epoch  3, batch    39 | loss: 134.9537889CurrentTrain: epoch  3, batch    40 | loss: 87.1589338CurrentTrain: epoch  3, batch    41 | loss: 107.2265094CurrentTrain: epoch  3, batch    42 | loss: 172.1649761CurrentTrain: epoch  3, batch    43 | loss: 139.6284012CurrentTrain: epoch  3, batch    44 | loss: 140.1584695CurrentTrain: epoch  3, batch    45 | loss: 92.9122779CurrentTrain: epoch  3, batch    46 | loss: 165.9138690CurrentTrain: epoch  3, batch    47 | loss: 138.0282128CurrentTrain: epoch  3, batch    48 | loss: 118.0095505CurrentTrain: epoch  3, batch    49 | loss: 124.1450664CurrentTrain: epoch  3, batch    50 | loss: 143.8088764CurrentTrain: epoch  3, batch    51 | loss: 97.8879320CurrentTrain: epoch  3, batch    52 | loss: 145.1051546CurrentTrain: epoch  3, batch    53 | loss: 114.1410001CurrentTrain: epoch  3, batch    54 | loss: 120.6815417CurrentTrain: epoch  3, batch    55 | loss: 142.4288390CurrentTrain: epoch  3, batch    56 | loss: 141.3270026CurrentTrain: epoch  3, batch    57 | loss: 126.8596147CurrentTrain: epoch  3, batch    58 | loss: 114.3208004CurrentTrain: epoch  3, batch    59 | loss: 142.6264430CurrentTrain: epoch  3, batch    60 | loss: 131.6920979CurrentTrain: epoch  3, batch    61 | loss: 130.2966794CurrentTrain: epoch  3, batch    62 | loss: 120.5007770CurrentTrain: epoch  3, batch    63 | loss: 130.3796830CurrentTrain: epoch  3, batch    64 | loss: 111.3255414CurrentTrain: epoch  3, batch    65 | loss: 104.5987367CurrentTrain: epoch  3, batch    66 | loss: 125.4860509CurrentTrain: epoch  3, batch    67 | loss: 110.1313141CurrentTrain: epoch  3, batch    68 | loss: 143.5851336CurrentTrain: epoch  3, batch    69 | loss: 98.2453808CurrentTrain: epoch  3, batch    70 | loss: 128.8166200CurrentTrain: epoch  3, batch    71 | loss: 125.9791433CurrentTrain: epoch  3, batch    72 | loss: 115.3942291CurrentTrain: epoch  3, batch    73 | loss: 135.9328196CurrentTrain: epoch  3, batch    74 | loss: 113.9590275CurrentTrain: epoch  3, batch    75 | loss: 116.7725644CurrentTrain: epoch  3, batch    76 | loss: 128.9133657CurrentTrain: epoch  3, batch    77 | loss: 140.6090217CurrentTrain: epoch  3, batch    78 | loss: 157.7854600CurrentTrain: epoch  3, batch    79 | loss: 136.8970183CurrentTrain: epoch  3, batch    80 | loss: 123.1625819CurrentTrain: epoch  3, batch    81 | loss: 134.0612201CurrentTrain: epoch  3, batch    82 | loss: 123.9853367CurrentTrain: epoch  3, batch    83 | loss: 170.3303815CurrentTrain: epoch  3, batch    84 | loss: 120.1850027CurrentTrain: epoch  3, batch    85 | loss: 131.2039882CurrentTrain: epoch  3, batch    86 | loss: 119.2121351CurrentTrain: epoch  3, batch    87 | loss: 149.7592081CurrentTrain: epoch  3, batch    88 | loss: 195.6012894CurrentTrain: epoch  3, batch    89 | loss: 134.4703699CurrentTrain: epoch  3, batch    90 | loss: 133.2967851CurrentTrain: epoch  3, batch    91 | loss: 145.3619120CurrentTrain: epoch  3, batch    92 | loss: 147.8129679CurrentTrain: epoch  3, batch    93 | loss: 131.6842249CurrentTrain: epoch  3, batch    94 | loss: 117.0576487CurrentTrain: epoch  3, batch    95 | loss: 109.9455279CurrentTrain: epoch  4, batch     0 | loss: 120.2085814CurrentTrain: epoch  4, batch     1 | loss: 135.8683964CurrentTrain: epoch  4, batch     2 | loss: 117.9806359CurrentTrain: epoch  4, batch     3 | loss: 109.4707811CurrentTrain: epoch  4, batch     4 | loss: 175.1267346CurrentTrain: epoch  4, batch     5 | loss: 168.4439152CurrentTrain: epoch  4, batch     6 | loss: 120.8566743CurrentTrain: epoch  4, batch     7 | loss: 124.5022281CurrentTrain: epoch  4, batch     8 | loss: 101.9629914CurrentTrain: epoch  4, batch     9 | loss: 149.3782507CurrentTrain: epoch  4, batch    10 | loss: 135.5206465CurrentTrain: epoch  4, batch    11 | loss: 150.5427975CurrentTrain: epoch  4, batch    12 | loss: 106.9785679CurrentTrain: epoch  4, batch    13 | loss: 111.0677422CurrentTrain: epoch  4, batch    14 | loss: 126.6531067CurrentTrain: epoch  4, batch    15 | loss: 89.5827315CurrentTrain: epoch  4, batch    16 | loss: 171.1978916CurrentTrain: epoch  4, batch    17 | loss: 124.8736176CurrentTrain: epoch  4, batch    18 | loss: 161.2364612CurrentTrain: epoch  4, batch    19 | loss: 136.2904063CurrentTrain: epoch  4, batch    20 | loss: 130.2773829CurrentTrain: epoch  4, batch    21 | loss: 121.5401532CurrentTrain: epoch  4, batch    22 | loss: 128.7447886CurrentTrain: epoch  4, batch    23 | loss: 117.2712704CurrentTrain: epoch  4, batch    24 | loss: 126.1550844CurrentTrain: epoch  4, batch    25 | loss: 126.9120886CurrentTrain: epoch  4, batch    26 | loss: 109.4788791CurrentTrain: epoch  4, batch    27 | loss: 120.1511962CurrentTrain: epoch  4, batch    28 | loss: 120.8071918CurrentTrain: epoch  4, batch    29 | loss: 131.2682678CurrentTrain: epoch  4, batch    30 | loss: 146.6402910CurrentTrain: epoch  4, batch    31 | loss: 103.7803770CurrentTrain: epoch  4, batch    32 | loss: 128.1065850CurrentTrain: epoch  4, batch    33 | loss: 127.5831424CurrentTrain: epoch  4, batch    34 | loss: 143.8007534CurrentTrain: epoch  4, batch    35 | loss: 102.8298443CurrentTrain: epoch  4, batch    36 | loss: 124.8520999CurrentTrain: epoch  4, batch    37 | loss: 130.5770203CurrentTrain: epoch  4, batch    38 | loss: 98.0974658CurrentTrain: epoch  4, batch    39 | loss: 114.2355520CurrentTrain: epoch  4, batch    40 | loss: 139.7809680CurrentTrain: epoch  4, batch    41 | loss: 122.8151699CurrentTrain: epoch  4, batch    42 | loss: 121.7750862CurrentTrain: epoch  4, batch    43 | loss: 127.7460116CurrentTrain: epoch  4, batch    44 | loss: 143.6679924CurrentTrain: epoch  4, batch    45 | loss: 115.7065310CurrentTrain: epoch  4, batch    46 | loss: 113.8186243CurrentTrain: epoch  4, batch    47 | loss: 115.5616856CurrentTrain: epoch  4, batch    48 | loss: 97.5750785CurrentTrain: epoch  4, batch    49 | loss: 122.9515719CurrentTrain: epoch  4, batch    50 | loss: 119.6462321CurrentTrain: epoch  4, batch    51 | loss: 137.1358557CurrentTrain: epoch  4, batch    52 | loss: 127.0405202CurrentTrain: epoch  4, batch    53 | loss: 131.1205002CurrentTrain: epoch  4, batch    54 | loss: 144.7642348CurrentTrain: epoch  4, batch    55 | loss: 135.1194413CurrentTrain: epoch  4, batch    56 | loss: 158.7482980CurrentTrain: epoch  4, batch    57 | loss: 112.0106327CurrentTrain: epoch  4, batch    58 | loss: 118.9995023CurrentTrain: epoch  4, batch    59 | loss: 119.0606040CurrentTrain: epoch  4, batch    60 | loss: 100.7619308CurrentTrain: epoch  4, batch    61 | loss: 135.6998412CurrentTrain: epoch  4, batch    62 | loss: 122.3360246CurrentTrain: epoch  4, batch    63 | loss: 104.4027813CurrentTrain: epoch  4, batch    64 | loss: 132.6461515CurrentTrain: epoch  4, batch    65 | loss: 118.4952834CurrentTrain: epoch  4, batch    66 | loss: 143.6057944CurrentTrain: epoch  4, batch    67 | loss: 113.7968197CurrentTrain: epoch  4, batch    68 | loss: 127.5779759CurrentTrain: epoch  4, batch    69 | loss: 154.2652303CurrentTrain: epoch  4, batch    70 | loss: 120.1682441CurrentTrain: epoch  4, batch    71 | loss: 180.6698364CurrentTrain: epoch  4, batch    72 | loss: 171.3963425CurrentTrain: epoch  4, batch    73 | loss: 143.5980625CurrentTrain: epoch  4, batch    74 | loss: 129.7203076CurrentTrain: epoch  4, batch    75 | loss: 125.9391533CurrentTrain: epoch  4, batch    76 | loss: 130.2840990CurrentTrain: epoch  4, batch    77 | loss: 140.0911445CurrentTrain: epoch  4, batch    78 | loss: 172.8251196CurrentTrain: epoch  4, batch    79 | loss: 161.0663280CurrentTrain: epoch  4, batch    80 | loss: 127.5739253CurrentTrain: epoch  4, batch    81 | loss: 118.7043409CurrentTrain: epoch  4, batch    82 | loss: 100.9870415CurrentTrain: epoch  4, batch    83 | loss: 142.6722028CurrentTrain: epoch  4, batch    84 | loss: 139.8367022CurrentTrain: epoch  4, batch    85 | loss: 148.8805535CurrentTrain: epoch  4, batch    86 | loss: 146.7889465CurrentTrain: epoch  4, batch    87 | loss: 112.8080737CurrentTrain: epoch  4, batch    88 | loss: 130.6819181CurrentTrain: epoch  4, batch    89 | loss: 146.2590597CurrentTrain: epoch  4, batch    90 | loss: 161.3717701CurrentTrain: epoch  4, batch    91 | loss: 124.9048425CurrentTrain: epoch  4, batch    92 | loss: 153.6529796CurrentTrain: epoch  4, batch    93 | loss: 147.2041900CurrentTrain: epoch  4, batch    94 | loss: 87.7156404CurrentTrain: epoch  4, batch    95 | loss: 101.3877413CurrentTrain: epoch  5, batch     0 | loss: 102.9914754CurrentTrain: epoch  5, batch     1 | loss: 141.8330989CurrentTrain: epoch  5, batch     2 | loss: 126.1805449CurrentTrain: epoch  5, batch     3 | loss: 132.3738196CurrentTrain: epoch  5, batch     4 | loss: 153.5235125CurrentTrain: epoch  5, batch     5 | loss: 123.6068213CurrentTrain: epoch  5, batch     6 | loss: 158.3955622CurrentTrain: epoch  5, batch     7 | loss: 123.7213530CurrentTrain: epoch  5, batch     8 | loss: 110.8580371CurrentTrain: epoch  5, batch     9 | loss: 94.7334491CurrentTrain: epoch  5, batch    10 | loss: 127.9624505CurrentTrain: epoch  5, batch    11 | loss: 162.6299192CurrentTrain: epoch  5, batch    12 | loss: 115.2108959CurrentTrain: epoch  5, batch    13 | loss: 149.6849703CurrentTrain: epoch  5, batch    14 | loss: 121.8853006CurrentTrain: epoch  5, batch    15 | loss: 136.9542220CurrentTrain: epoch  5, batch    16 | loss: 128.2759206CurrentTrain: epoch  5, batch    17 | loss: 118.0679361CurrentTrain: epoch  5, batch    18 | loss: 128.5183384CurrentTrain: epoch  5, batch    19 | loss: 137.0240664CurrentTrain: epoch  5, batch    20 | loss: 135.5843226CurrentTrain: epoch  5, batch    21 | loss: 110.1557979CurrentTrain: epoch  5, batch    22 | loss: 134.1283621CurrentTrain: epoch  5, batch    23 | loss: 146.5499797CurrentTrain: epoch  5, batch    24 | loss: 117.0120979CurrentTrain: epoch  5, batch    25 | loss: 91.1796097CurrentTrain: epoch  5, batch    26 | loss: 121.5116172CurrentTrain: epoch  5, batch    27 | loss: 143.1246061CurrentTrain: epoch  5, batch    28 | loss: 157.1967483CurrentTrain: epoch  5, batch    29 | loss: 121.0575590CurrentTrain: epoch  5, batch    30 | loss: 155.6898321CurrentTrain: epoch  5, batch    31 | loss: 109.5984170CurrentTrain: epoch  5, batch    32 | loss: 130.9459640CurrentTrain: epoch  5, batch    33 | loss: 109.4417051CurrentTrain: epoch  5, batch    34 | loss: 132.8274016CurrentTrain: epoch  5, batch    35 | loss: 116.6630943CurrentTrain: epoch  5, batch    36 | loss: 103.8924094CurrentTrain: epoch  5, batch    37 | loss: 146.8578891CurrentTrain: epoch  5, batch    38 | loss: 133.7125712CurrentTrain: epoch  5, batch    39 | loss: 129.3552921CurrentTrain: epoch  5, batch    40 | loss: 111.7919373CurrentTrain: epoch  5, batch    41 | loss: 143.4468015CurrentTrain: epoch  5, batch    42 | loss: 124.8578448CurrentTrain: epoch  5, batch    43 | loss: 107.6857495CurrentTrain: epoch  5, batch    44 | loss: 99.5736713CurrentTrain: epoch  5, batch    45 | loss: 98.6544048CurrentTrain: epoch  5, batch    46 | loss: 146.8014954CurrentTrain: epoch  5, batch    47 | loss: 160.7645500CurrentTrain: epoch  5, batch    48 | loss: 96.9461020CurrentTrain: epoch  5, batch    49 | loss: 110.0097041CurrentTrain: epoch  5, batch    50 | loss: 105.6297872CurrentTrain: epoch  5, batch    51 | loss: 158.1674823CurrentTrain: epoch  5, batch    52 | loss: 163.0553298CurrentTrain: epoch  5, batch    53 | loss: 109.0520198CurrentTrain: epoch  5, batch    54 | loss: 148.2500892CurrentTrain: epoch  5, batch    55 | loss: 137.2361162CurrentTrain: epoch  5, batch    56 | loss: 107.6118368CurrentTrain: epoch  5, batch    57 | loss: 142.9269131CurrentTrain: epoch  5, batch    58 | loss: 106.4536339CurrentTrain: epoch  5, batch    59 | loss: 121.4194699CurrentTrain: epoch  5, batch    60 | loss: 128.1987290CurrentTrain: epoch  5, batch    61 | loss: 108.7358460CurrentTrain: epoch  5, batch    62 | loss: 116.8922351CurrentTrain: epoch  5, batch    63 | loss: 132.7865123CurrentTrain: epoch  5, batch    64 | loss: 171.9379399CurrentTrain: epoch  5, batch    65 | loss: 106.4263633CurrentTrain: epoch  5, batch    66 | loss: 168.1012179CurrentTrain: epoch  5, batch    67 | loss: 112.7714500CurrentTrain: epoch  5, batch    68 | loss: 130.6807562CurrentTrain: epoch  5, batch    69 | loss: 118.7170751CurrentTrain: epoch  5, batch    70 | loss: 162.1859506CurrentTrain: epoch  5, batch    71 | loss: 123.6092671CurrentTrain: epoch  5, batch    72 | loss: 156.0495720CurrentTrain: epoch  5, batch    73 | loss: 118.4867561CurrentTrain: epoch  5, batch    74 | loss: 123.5416047CurrentTrain: epoch  5, batch    75 | loss: 113.5743797CurrentTrain: epoch  5, batch    76 | loss: 115.8588854CurrentTrain: epoch  5, batch    77 | loss: 108.6961199CurrentTrain: epoch  5, batch    78 | loss: 117.3392302CurrentTrain: epoch  5, batch    79 | loss: 110.2976369CurrentTrain: epoch  5, batch    80 | loss: 140.2488855CurrentTrain: epoch  5, batch    81 | loss: 126.3987097CurrentTrain: epoch  5, batch    82 | loss: 138.6668310CurrentTrain: epoch  5, batch    83 | loss: 130.7953257CurrentTrain: epoch  5, batch    84 | loss: 138.8963358CurrentTrain: epoch  5, batch    85 | loss: 157.8970453CurrentTrain: epoch  5, batch    86 | loss: 125.7665269CurrentTrain: epoch  5, batch    87 | loss: 129.2410442CurrentTrain: epoch  5, batch    88 | loss: 122.9128796CurrentTrain: epoch  5, batch    89 | loss: 124.1596394CurrentTrain: epoch  5, batch    90 | loss: 168.8000423CurrentTrain: epoch  5, batch    91 | loss: 131.4221652CurrentTrain: epoch  5, batch    92 | loss: 130.0271315CurrentTrain: epoch  5, batch    93 | loss: 140.9107243CurrentTrain: epoch  5, batch    94 | loss: 121.0382380CurrentTrain: epoch  5, batch    95 | loss: 115.9744824CurrentTrain: epoch  6, batch     0 | loss: 108.1701829CurrentTrain: epoch  6, batch     1 | loss: 117.5046050CurrentTrain: epoch  6, batch     2 | loss: 119.5274459CurrentTrain: epoch  6, batch     3 | loss: 115.7751993CurrentTrain: epoch  6, batch     4 | loss: 120.7688117CurrentTrain: epoch  6, batch     5 | loss: 102.0434407CurrentTrain: epoch  6, batch     6 | loss: 128.9791406CurrentTrain: epoch  6, batch     7 | loss: 115.9204955CurrentTrain: epoch  6, batch     8 | loss: 115.0110178CurrentTrain: epoch  6, batch     9 | loss: 139.0961599CurrentTrain: epoch  6, batch    10 | loss: 89.3239403CurrentTrain: epoch  6, batch    11 | loss: 168.7104588CurrentTrain: epoch  6, batch    12 | loss: 144.8755119CurrentTrain: epoch  6, batch    13 | loss: 103.0304069CurrentTrain: epoch  6, batch    14 | loss: 130.9032414CurrentTrain: epoch  6, batch    15 | loss: 101.6515609CurrentTrain: epoch  6, batch    16 | loss: 130.1034520CurrentTrain: epoch  6, batch    17 | loss: 150.9632380CurrentTrain: epoch  6, batch    18 | loss: 127.8362690CurrentTrain: epoch  6, batch    19 | loss: 119.5956093CurrentTrain: epoch  6, batch    20 | loss: 115.6063523CurrentTrain: epoch  6, batch    21 | loss: 124.3309871CurrentTrain: epoch  6, batch    22 | loss: 112.9359374CurrentTrain: epoch  6, batch    23 | loss: 112.7660163CurrentTrain: epoch  6, batch    24 | loss: 143.4376461CurrentTrain: epoch  6, batch    25 | loss: 128.8547946CurrentTrain: epoch  6, batch    26 | loss: 128.8792365CurrentTrain: epoch  6, batch    27 | loss: 174.9316267CurrentTrain: epoch  6, batch    28 | loss: 98.5194711CurrentTrain: epoch  6, batch    29 | loss: 132.6838267CurrentTrain: epoch  6, batch    30 | loss: 108.8820511CurrentTrain: epoch  6, batch    31 | loss: 104.8099683CurrentTrain: epoch  6, batch    32 | loss: 168.3163695CurrentTrain: epoch  6, batch    33 | loss: 123.4224362CurrentTrain: epoch  6, batch    34 | loss: 133.3364635CurrentTrain: epoch  6, batch    35 | loss: 137.7628430CurrentTrain: epoch  6, batch    36 | loss: 113.3047996CurrentTrain: epoch  6, batch    37 | loss: 123.5834011CurrentTrain: epoch  6, batch    38 | loss: 92.4892247CurrentTrain: epoch  6, batch    39 | loss: 149.9296396CurrentTrain: epoch  6, batch    40 | loss: 113.7214889CurrentTrain: epoch  6, batch    41 | loss: 105.3909813CurrentTrain: epoch  6, batch    42 | loss: 117.3892187CurrentTrain: epoch  6, batch    43 | loss: 98.7364316CurrentTrain: epoch  6, batch    44 | loss: 110.0844585CurrentTrain: epoch  6, batch    45 | loss: 144.7006382CurrentTrain: epoch  6, batch    46 | loss: 114.3198809CurrentTrain: epoch  6, batch    47 | loss: 146.9036816CurrentTrain: epoch  6, batch    48 | loss: 143.8835922CurrentTrain: epoch  6, batch    49 | loss: 137.1338992CurrentTrain: epoch  6, batch    50 | loss: 116.1989407CurrentTrain: epoch  6, batch    51 | loss: 114.1482596CurrentTrain: epoch  6, batch    52 | loss: 107.2185191CurrentTrain: epoch  6, batch    53 | loss: 171.4812659CurrentTrain: epoch  6, batch    54 | loss: 111.4064826CurrentTrain: epoch  6, batch    55 | loss: 127.9492325CurrentTrain: epoch  6, batch    56 | loss: 127.6216583CurrentTrain: epoch  6, batch    57 | loss: 132.8101781CurrentTrain: epoch  6, batch    58 | loss: 139.7643877CurrentTrain: epoch  6, batch    59 | loss: 127.0456766CurrentTrain: epoch  6, batch    60 | loss: 128.6408789CurrentTrain: epoch  6, batch    61 | loss: 112.9317387CurrentTrain: epoch  6, batch    62 | loss: 122.2081155CurrentTrain: epoch  6, batch    63 | loss: 132.3535658CurrentTrain: epoch  6, batch    64 | loss: 136.6969125CurrentTrain: epoch  6, batch    65 | loss: 98.4773125CurrentTrain: epoch  6, batch    66 | loss: 145.0324832CurrentTrain: epoch  6, batch    67 | loss: 140.6672887CurrentTrain: epoch  6, batch    68 | loss: 124.5613358CurrentTrain: epoch  6, batch    69 | loss: 133.5349099CurrentTrain: epoch  6, batch    70 | loss: 107.0386492CurrentTrain: epoch  6, batch    71 | loss: 109.8151112CurrentTrain: epoch  6, batch    72 | loss: 159.9179412CurrentTrain: epoch  6, batch    73 | loss: 144.4831994CurrentTrain: epoch  6, batch    74 | loss: 125.1987656CurrentTrain: epoch  6, batch    75 | loss: 146.3754666CurrentTrain: epoch  6, batch    76 | loss: 156.3260026CurrentTrain: epoch  6, batch    77 | loss: 128.3323589CurrentTrain: epoch  6, batch    78 | loss: 121.6504501CurrentTrain: epoch  6, batch    79 | loss: 123.9547024CurrentTrain: epoch  6, batch    80 | loss: 107.9447975CurrentTrain: epoch  6, batch    81 | loss: 146.9285756CurrentTrain: epoch  6, batch    82 | loss: 108.6445233CurrentTrain: epoch  6, batch    83 | loss: 142.4333083CurrentTrain: epoch  6, batch    84 | loss: 133.1189546CurrentTrain: epoch  6, batch    85 | loss: 120.2541172CurrentTrain: epoch  6, batch    86 | loss: 111.7997729CurrentTrain: epoch  6, batch    87 | loss: 151.0456937CurrentTrain: epoch  6, batch    88 | loss: 118.6752810CurrentTrain: epoch  6, batch    89 | loss: 107.4782512CurrentTrain: epoch  6, batch    90 | loss: 164.0012239CurrentTrain: epoch  6, batch    91 | loss: 144.5933489CurrentTrain: epoch  6, batch    92 | loss: 126.4883527CurrentTrain: epoch  6, batch    93 | loss: 109.4989231CurrentTrain: epoch  6, batch    94 | loss: 126.1385267CurrentTrain: epoch  6, batch    95 | loss: 95.0773230CurrentTrain: epoch  7, batch     0 | loss: 108.6800341CurrentTrain: epoch  7, batch     1 | loss: 114.9950498CurrentTrain: epoch  7, batch     2 | loss: 110.6617565CurrentTrain: epoch  7, batch     3 | loss: 122.3449299CurrentTrain: epoch  7, batch     4 | loss: 118.5723264CurrentTrain: epoch  7, batch     5 | loss: 144.3164143CurrentTrain: epoch  7, batch     6 | loss: 159.2472624CurrentTrain: epoch  7, batch     7 | loss: 101.4091862CurrentTrain: epoch  7, batch     8 | loss: 100.6050937CurrentTrain: epoch  7, batch     9 | loss: 103.4860529CurrentTrain: epoch  7, batch    10 | loss: 106.8434650CurrentTrain: epoch  7, batch    11 | loss: 123.5660306CurrentTrain: epoch  7, batch    12 | loss: 141.2268033CurrentTrain: epoch  7, batch    13 | loss: 100.1652040CurrentTrain: epoch  7, batch    14 | loss: 113.2163054CurrentTrain: epoch  7, batch    15 | loss: 113.6570192CurrentTrain: epoch  7, batch    16 | loss: 118.0085000CurrentTrain: epoch  7, batch    17 | loss: 114.8438037CurrentTrain: epoch  7, batch    18 | loss: 166.9775406CurrentTrain: epoch  7, batch    19 | loss: 130.3874937CurrentTrain: epoch  7, batch    20 | loss: 113.4176102CurrentTrain: epoch  7, batch    21 | loss: 116.6099355CurrentTrain: epoch  7, batch    22 | loss: 111.2201667CurrentTrain: epoch  7, batch    23 | loss: 145.5071913CurrentTrain: epoch  7, batch    24 | loss: 122.3161473CurrentTrain: epoch  7, batch    25 | loss: 128.3085951CurrentTrain: epoch  7, batch    26 | loss: 142.5567401CurrentTrain: epoch  7, batch    27 | loss: 155.3933514CurrentTrain: epoch  7, batch    28 | loss: 125.9260825CurrentTrain: epoch  7, batch    29 | loss: 131.7213659CurrentTrain: epoch  7, batch    30 | loss: 95.2415904CurrentTrain: epoch  7, batch    31 | loss: 136.7376748CurrentTrain: epoch  7, batch    32 | loss: 149.9344026CurrentTrain: epoch  7, batch    33 | loss: 120.6846380CurrentTrain: epoch  7, batch    34 | loss: 116.1083358CurrentTrain: epoch  7, batch    35 | loss: 156.6402683CurrentTrain: epoch  7, batch    36 | loss: 126.9694152CurrentTrain: epoch  7, batch    37 | loss: 115.6740325CurrentTrain: epoch  7, batch    38 | loss: 130.2887885CurrentTrain: epoch  7, batch    39 | loss: 112.2371412CurrentTrain: epoch  7, batch    40 | loss: 129.9733812CurrentTrain: epoch  7, batch    41 | loss: 145.5553600CurrentTrain: epoch  7, batch    42 | loss: 117.3116858CurrentTrain: epoch  7, batch    43 | loss: 140.0269493CurrentTrain: epoch  7, batch    44 | loss: 135.6840712CurrentTrain: epoch  7, batch    45 | loss: 120.1213546CurrentTrain: epoch  7, batch    46 | loss: 156.5379528CurrentTrain: epoch  7, batch    47 | loss: 146.6827426CurrentTrain: epoch  7, batch    48 | loss: 134.0278118CurrentTrain: epoch  7, batch    49 | loss: 118.5172114CurrentTrain: epoch  7, batch    50 | loss: 99.7285307CurrentTrain: epoch  7, batch    51 | loss: 136.2218961CurrentTrain: epoch  7, batch    52 | loss: 109.2037027CurrentTrain: epoch  7, batch    53 | loss: 132.3949514CurrentTrain: epoch  7, batch    54 | loss: 105.6720788CurrentTrain: epoch  7, batch    55 | loss: 115.6962173CurrentTrain: epoch  7, batch    56 | loss: 113.8710863CurrentTrain: epoch  7, batch    57 | loss: 135.7214556CurrentTrain: epoch  7, batch    58 | loss: 139.4585963CurrentTrain: epoch  7, batch    59 | loss: 112.7845489CurrentTrain: epoch  7, batch    60 | loss: 106.4717171CurrentTrain: epoch  7, batch    61 | loss: 121.8677650CurrentTrain: epoch  7, batch    62 | loss: 115.8085513CurrentTrain: epoch  7, batch    63 | loss: 144.0114190CurrentTrain: epoch  7, batch    64 | loss: 103.3613585CurrentTrain: epoch  7, batch    65 | loss: 119.1799472CurrentTrain: epoch  7, batch    66 | loss: 140.9286209CurrentTrain: epoch  7, batch    67 | loss: 141.3011976CurrentTrain: epoch  7, batch    68 | loss: 120.7257366CurrentTrain: epoch  7, batch    69 | loss: 100.0210457CurrentTrain: epoch  7, batch    70 | loss: 108.4222003CurrentTrain: epoch  7, batch    71 | loss: 107.9471399CurrentTrain: epoch  7, batch    72 | loss: 146.4438368CurrentTrain: epoch  7, batch    73 | loss: 123.1215704CurrentTrain: epoch  7, batch    74 | loss: 129.0932391CurrentTrain: epoch  7, batch    75 | loss: 115.3041722CurrentTrain: epoch  7, batch    76 | loss: 173.1673955CurrentTrain: epoch  7, batch    77 | loss: 103.4145935CurrentTrain: epoch  7, batch    78 | loss: 157.1218809CurrentTrain: epoch  7, batch    79 | loss: 129.6375103CurrentTrain: epoch  7, batch    80 | loss: 166.1553138CurrentTrain: epoch  7, batch    81 | loss: 98.1477009CurrentTrain: epoch  7, batch    82 | loss: 117.2729813CurrentTrain: epoch  7, batch    83 | loss: 86.9907865CurrentTrain: epoch  7, batch    84 | loss: 112.8698551CurrentTrain: epoch  7, batch    85 | loss: 168.5998328CurrentTrain: epoch  7, batch    86 | loss: 98.8055567CurrentTrain: epoch  7, batch    87 | loss: 166.8772372CurrentTrain: epoch  7, batch    88 | loss: 125.7903002CurrentTrain: epoch  7, batch    89 | loss: 123.9372254CurrentTrain: epoch  7, batch    90 | loss: 170.0606719CurrentTrain: epoch  7, batch    91 | loss: 124.4872382CurrentTrain: epoch  7, batch    92 | loss: 87.4554490CurrentTrain: epoch  7, batch    93 | loss: 125.5349628CurrentTrain: epoch  7, batch    94 | loss: 118.1355082CurrentTrain: epoch  7, batch    95 | loss: 168.5142180CurrentTrain: epoch  8, batch     0 | loss: 115.5921280CurrentTrain: epoch  8, batch     1 | loss: 109.2591626CurrentTrain: epoch  8, batch     2 | loss: 108.8677987CurrentTrain: epoch  8, batch     3 | loss: 124.0679741CurrentTrain: epoch  8, batch     4 | loss: 106.4300996CurrentTrain: epoch  8, batch     5 | loss: 123.0889515CurrentTrain: epoch  8, batch     6 | loss: 94.8030552CurrentTrain: epoch  8, batch     7 | loss: 130.3317806CurrentTrain: epoch  8, batch     8 | loss: 117.9213052CurrentTrain: epoch  8, batch     9 | loss: 97.2327497CurrentTrain: epoch  8, batch    10 | loss: 123.8386092CurrentTrain: epoch  8, batch    11 | loss: 99.4489587CurrentTrain: epoch  8, batch    12 | loss: 125.9340076CurrentTrain: epoch  8, batch    13 | loss: 135.0048151CurrentTrain: epoch  8, batch    14 | loss: 141.1661973CurrentTrain: epoch  8, batch    15 | loss: 103.9722251CurrentTrain: epoch  8, batch    16 | loss: 156.9849060CurrentTrain: epoch  8, batch    17 | loss: 128.2966421CurrentTrain: epoch  8, batch    18 | loss: 137.5890938CurrentTrain: epoch  8, batch    19 | loss: 146.6925295CurrentTrain: epoch  8, batch    20 | loss: 115.2011938CurrentTrain: epoch  8, batch    21 | loss: 131.1491602CurrentTrain: epoch  8, batch    22 | loss: 118.6921454CurrentTrain: epoch  8, batch    23 | loss: 135.5290332CurrentTrain: epoch  8, batch    24 | loss: 121.4729424CurrentTrain: epoch  8, batch    25 | loss: 122.1648471CurrentTrain: epoch  8, batch    26 | loss: 137.4536727CurrentTrain: epoch  8, batch    27 | loss: 119.7163678CurrentTrain: epoch  8, batch    28 | loss: 138.7364417CurrentTrain: epoch  8, batch    29 | loss: 120.6903791CurrentTrain: epoch  8, batch    30 | loss: 121.3454900CurrentTrain: epoch  8, batch    31 | loss: 101.5735425CurrentTrain: epoch  8, batch    32 | loss: 95.5674284CurrentTrain: epoch  8, batch    33 | loss: 150.3381686CurrentTrain: epoch  8, batch    34 | loss: 163.3606009CurrentTrain: epoch  8, batch    35 | loss: 130.2077601CurrentTrain: epoch  8, batch    36 | loss: 123.4473390CurrentTrain: epoch  8, batch    37 | loss: 122.1016918CurrentTrain: epoch  8, batch    38 | loss: 119.2562511CurrentTrain: epoch  8, batch    39 | loss: 128.4095390CurrentTrain: epoch  8, batch    40 | loss: 119.5092654CurrentTrain: epoch  8, batch    41 | loss: 117.3417590CurrentTrain: epoch  8, batch    42 | loss: 109.0592648CurrentTrain: epoch  8, batch    43 | loss: 167.6861770CurrentTrain: epoch  8, batch    44 | loss: 166.8994901CurrentTrain: epoch  8, batch    45 | loss: 98.0656265CurrentTrain: epoch  8, batch    46 | loss: 104.3601607CurrentTrain: epoch  8, batch    47 | loss: 125.2574562CurrentTrain: epoch  8, batch    48 | loss: 138.4679388CurrentTrain: epoch  8, batch    49 | loss: 118.5342727CurrentTrain: epoch  8, batch    50 | loss: 86.4721201CurrentTrain: epoch  8, batch    51 | loss: 132.6940488CurrentTrain: epoch  8, batch    52 | loss: 158.9066395CurrentTrain: epoch  8, batch    53 | loss: 116.9821026CurrentTrain: epoch  8, batch    54 | loss: 119.5564951CurrentTrain: epoch  8, batch    55 | loss: 103.5580177CurrentTrain: epoch  8, batch    56 | loss: 100.7865805CurrentTrain: epoch  8, batch    57 | loss: 124.2365513CurrentTrain: epoch  8, batch    58 | loss: 91.1629117CurrentTrain: epoch  8, batch    59 | loss: 137.4828148CurrentTrain: epoch  8, batch    60 | loss: 144.0473050CurrentTrain: epoch  8, batch    61 | loss: 116.1485008CurrentTrain: epoch  8, batch    62 | loss: 160.9689583CurrentTrain: epoch  8, batch    63 | loss: 114.8900204CurrentTrain: epoch  8, batch    64 | loss: 141.9760054CurrentTrain: epoch  8, batch    65 | loss: 101.4470182CurrentTrain: epoch  8, batch    66 | loss: 134.0430904CurrentTrain: epoch  8, batch    67 | loss: 144.2389112CurrentTrain: epoch  8, batch    68 | loss: 139.7427042CurrentTrain: epoch  8, batch    69 | loss: 135.2759103CurrentTrain: epoch  8, batch    70 | loss: 91.2581390CurrentTrain: epoch  8, batch    71 | loss: 82.9853157CurrentTrain: epoch  8, batch    72 | loss: 125.5560412CurrentTrain: epoch  8, batch    73 | loss: 120.6402190CurrentTrain: epoch  8, batch    74 | loss: 135.1037710CurrentTrain: epoch  8, batch    75 | loss: 137.5013239CurrentTrain: epoch  8, batch    76 | loss: 112.8489682CurrentTrain: epoch  8, batch    77 | loss: 141.4486180CurrentTrain: epoch  8, batch    78 | loss: 116.4132396CurrentTrain: epoch  8, batch    79 | loss: 115.1731041CurrentTrain: epoch  8, batch    80 | loss: 108.6927583CurrentTrain: epoch  8, batch    81 | loss: 131.7457731CurrentTrain: epoch  8, batch    82 | loss: 115.6933854CurrentTrain: epoch  8, batch    83 | loss: 197.9140031CurrentTrain: epoch  8, batch    84 | loss: 111.7490856CurrentTrain: epoch  8, batch    85 | loss: 124.8718194CurrentTrain: epoch  8, batch    86 | loss: 112.4021471CurrentTrain: epoch  8, batch    87 | loss: 110.1192263CurrentTrain: epoch  8, batch    88 | loss: 129.3475269CurrentTrain: epoch  8, batch    89 | loss: 130.4883533CurrentTrain: epoch  8, batch    90 | loss: 96.4949336CurrentTrain: epoch  8, batch    91 | loss: 135.4053668CurrentTrain: epoch  8, batch    92 | loss: 112.8991134CurrentTrain: epoch  8, batch    93 | loss: 146.9684120CurrentTrain: epoch  8, batch    94 | loss: 103.7531436CurrentTrain: epoch  8, batch    95 | loss: 111.8910542CurrentTrain: epoch  9, batch     0 | loss: 131.5275283CurrentTrain: epoch  9, batch     1 | loss: 109.4499029CurrentTrain: epoch  9, batch     2 | loss: 137.8125535CurrentTrain: epoch  9, batch     3 | loss: 102.8768627CurrentTrain: epoch  9, batch     4 | loss: 137.6593119CurrentTrain: epoch  9, batch     5 | loss: 104.5823199CurrentTrain: epoch  9, batch     6 | loss: 92.9989398CurrentTrain: epoch  9, batch     7 | loss: 143.3293378CurrentTrain: epoch  9, batch     8 | loss: 126.9651150CurrentTrain: epoch  9, batch     9 | loss: 127.9756779CurrentTrain: epoch  9, batch    10 | loss: 139.6141507CurrentTrain: epoch  9, batch    11 | loss: 159.7602380CurrentTrain: epoch  9, batch    12 | loss: 138.2923394CurrentTrain: epoch  9, batch    13 | loss: 135.6399553CurrentTrain: epoch  9, batch    14 | loss: 131.6817628CurrentTrain: epoch  9, batch    15 | loss: 109.2740343CurrentTrain: epoch  9, batch    16 | loss: 112.1625409CurrentTrain: epoch  9, batch    17 | loss: 168.0878839CurrentTrain: epoch  9, batch    18 | loss: 133.5992694CurrentTrain: epoch  9, batch    19 | loss: 135.5153218CurrentTrain: epoch  9, batch    20 | loss: 120.1699131CurrentTrain: epoch  9, batch    21 | loss: 112.0553789CurrentTrain: epoch  9, batch    22 | loss: 118.3965953CurrentTrain: epoch  9, batch    23 | loss: 147.9177552CurrentTrain: epoch  9, batch    24 | loss: 142.0469917CurrentTrain: epoch  9, batch    25 | loss: 146.1668423CurrentTrain: epoch  9, batch    26 | loss: 123.5712044CurrentTrain: epoch  9, batch    27 | loss: 106.6695661CurrentTrain: epoch  9, batch    28 | loss: 107.9310880CurrentTrain: epoch  9, batch    29 | loss: 129.0825289CurrentTrain: epoch  9, batch    30 | loss: 105.0205306CurrentTrain: epoch  9, batch    31 | loss: 137.9979071CurrentTrain: epoch  9, batch    32 | loss: 117.9972836CurrentTrain: epoch  9, batch    33 | loss: 118.1094036CurrentTrain: epoch  9, batch    34 | loss: 150.6660376CurrentTrain: epoch  9, batch    35 | loss: 122.2330256CurrentTrain: epoch  9, batch    36 | loss: 100.2005294CurrentTrain: epoch  9, batch    37 | loss: 200.3640411CurrentTrain: epoch  9, batch    38 | loss: 121.0981640CurrentTrain: epoch  9, batch    39 | loss: 113.7776301CurrentTrain: epoch  9, batch    40 | loss: 149.5831422CurrentTrain: epoch  9, batch    41 | loss: 112.9197409CurrentTrain: epoch  9, batch    42 | loss: 99.4789282CurrentTrain: epoch  9, batch    43 | loss: 105.5845433CurrentTrain: epoch  9, batch    44 | loss: 115.8861512CurrentTrain: epoch  9, batch    45 | loss: 111.5910120CurrentTrain: epoch  9, batch    46 | loss: 156.9113276CurrentTrain: epoch  9, batch    47 | loss: 166.8444652CurrentTrain: epoch  9, batch    48 | loss: 125.3936724CurrentTrain: epoch  9, batch    49 | loss: 109.7633253CurrentTrain: epoch  9, batch    50 | loss: 121.6862966CurrentTrain: epoch  9, batch    51 | loss: 117.8771334CurrentTrain: epoch  9, batch    52 | loss: 99.3794129CurrentTrain: epoch  9, batch    53 | loss: 128.7133925CurrentTrain: epoch  9, batch    54 | loss: 106.0713129CurrentTrain: epoch  9, batch    55 | loss: 120.9795172CurrentTrain: epoch  9, batch    56 | loss: 106.4743465CurrentTrain: epoch  9, batch    57 | loss: 113.2688961CurrentTrain: epoch  9, batch    58 | loss: 109.2778319CurrentTrain: epoch  9, batch    59 | loss: 110.1657261CurrentTrain: epoch  9, batch    60 | loss: 137.3394631CurrentTrain: epoch  9, batch    61 | loss: 143.8829476CurrentTrain: epoch  9, batch    62 | loss: 112.2249718CurrentTrain: epoch  9, batch    63 | loss: 133.9908320CurrentTrain: epoch  9, batch    64 | loss: 189.5384259CurrentTrain: epoch  9, batch    65 | loss: 115.8047568CurrentTrain: epoch  9, batch    66 | loss: 141.8704015CurrentTrain: epoch  9, batch    67 | loss: 119.1561497CurrentTrain: epoch  9, batch    68 | loss: 119.2421068CurrentTrain: epoch  9, batch    69 | loss: 110.5931638CurrentTrain: epoch  9, batch    70 | loss: 114.0748194CurrentTrain: epoch  9, batch    71 | loss: 109.9729378CurrentTrain: epoch  9, batch    72 | loss: 107.5335994CurrentTrain: epoch  9, batch    73 | loss: 99.9666921CurrentTrain: epoch  9, batch    74 | loss: 119.2454103CurrentTrain: epoch  9, batch    75 | loss: 100.5549859CurrentTrain: epoch  9, batch    76 | loss: 108.6225255CurrentTrain: epoch  9, batch    77 | loss: 105.6463458CurrentTrain: epoch  9, batch    78 | loss: 140.2721693CurrentTrain: epoch  9, batch    79 | loss: 108.4789890CurrentTrain: epoch  9, batch    80 | loss: 164.1788659CurrentTrain: epoch  9, batch    81 | loss: 111.9730366CurrentTrain: epoch  9, batch    82 | loss: 137.4891389CurrentTrain: epoch  9, batch    83 | loss: 102.4924822CurrentTrain: epoch  9, batch    84 | loss: 146.8684421CurrentTrain: epoch  9, batch    85 | loss: 115.8233264CurrentTrain: epoch  9, batch    86 | loss: 106.6204306CurrentTrain: epoch  9, batch    87 | loss: 125.4446830CurrentTrain: epoch  9, batch    88 | loss: 106.1393380CurrentTrain: epoch  9, batch    89 | loss: 200.3688514CurrentTrain: epoch  9, batch    90 | loss: 103.5930132CurrentTrain: epoch  9, batch    91 | loss: 112.2483989CurrentTrain: epoch  9, batch    92 | loss: 104.4387543CurrentTrain: epoch  9, batch    93 | loss: 123.7877079CurrentTrain: epoch  9, batch    94 | loss: 102.8449263CurrentTrain: epoch  9, batch    95 | loss: 120.1380617

F1 score per class: {32: np.float64(0.59375), 6: np.float64(0.8110599078341014), 19: np.float64(0.2777777777777778), 24: np.float64(0.7514450867052023), 26: np.float64(0.945273631840796), 29: np.float64(0.8051948051948052)}
Micro-average F1 score: 0.7676190476190476
Weighted-average F1 score: 0.7712925880498299
F1 score per class: {32: np.float64(0.6543778801843319), 6: np.float64(0.8141592920353983), 19: np.float64(0.27848101265822783), 24: np.float64(0.7486033519553073), 26: np.float64(0.945273631840796), 29: np.float64(0.8018018018018018)}
Micro-average F1 score: 0.7562277580071174
Weighted-average F1 score: 0.7402075016343043
F1 score per class: {32: np.float64(0.6666666666666666), 6: np.float64(0.8088888888888889), 19: np.float64(0.3508771929824561), 24: np.float64(0.7570621468926554), 26: np.float64(0.945273631840796), 29: np.float64(0.7946428571428571)}
Micro-average F1 score: 0.7711941659070192
Weighted-average F1 score: 0.7641291733732803

F1 score per class: {32: np.float64(0.59375), 6: np.float64(0.8110599078341014), 19: np.float64(0.2777777777777778), 24: np.float64(0.7514450867052023), 26: np.float64(0.945273631840796), 29: np.float64(0.8051948051948052)}
Micro-average F1 score: 0.7676190476190476
Weighted-average F1 score: 0.7712925880498299
F1 score per class: {32: np.float64(0.6543778801843319), 6: np.float64(0.8141592920353983), 19: np.float64(0.27848101265822783), 24: np.float64(0.7486033519553073), 26: np.float64(0.945273631840796), 29: np.float64(0.8018018018018018)}
Micro-average F1 score: 0.7562277580071174
Weighted-average F1 score: 0.7402075016343043
F1 score per class: {32: np.float64(0.6666666666666666), 6: np.float64(0.8088888888888889), 19: np.float64(0.3508771929824561), 24: np.float64(0.7570621468926554), 26: np.float64(0.945273631840796), 29: np.float64(0.7946428571428571)}
Micro-average F1 score: 0.7711941659070192
Weighted-average F1 score: 0.7641291733732803

F1 score per class: {32: np.float64(0.4505928853754941), 6: np.float64(0.7619047619047619), 19: np.float64(0.19607843137254902), 24: np.float64(0.7065217391304348), 26: np.float64(0.8755760368663594), 29: np.float64(0.62)}
Micro-average F1 score: 0.6521035598705501
Weighted-average F1 score: 0.6420766656094555
F1 score per class: {32: np.float64(0.46557377049180326), 6: np.float64(0.7419354838709677), 19: np.float64(0.15172413793103448), 24: np.float64(0.6871794871794872), 26: np.float64(0.8715596330275229), 29: np.float64(0.6425992779783394)}
Micro-average F1 score: 0.6123919308357348
Weighted-average F1 score: 0.582050804899344
F1 score per class: {32: np.float64(0.4717607973421927), 6: np.float64(0.7489711934156379), 19: np.float64(0.18867924528301888), 24: np.float64(0.6979166666666666), 26: np.float64(0.8715596330275229), 29: np.float64(0.6289752650176679)}
Micro-average F1 score: 0.6299329858525688
Weighted-average F1 score: 0.6068914158035598

F1 score per class: {32: np.float64(0.4505928853754941), 6: np.float64(0.7619047619047619), 19: np.float64(0.19607843137254902), 24: np.float64(0.7065217391304348), 26: np.float64(0.8755760368663594), 29: np.float64(0.62)}
Micro-average F1 score: 0.6521035598705501
Weighted-average F1 score: 0.6420766656094555
F1 score per class: {32: np.float64(0.46557377049180326), 6: np.float64(0.7419354838709677), 19: np.float64(0.15172413793103448), 24: np.float64(0.6871794871794872), 26: np.float64(0.8715596330275229), 29: np.float64(0.6425992779783394)}
Micro-average F1 score: 0.6123919308357348
Weighted-average F1 score: 0.582050804899344
F1 score per class: {32: np.float64(0.4717607973421927), 6: np.float64(0.7489711934156379), 19: np.float64(0.18867924528301888), 24: np.float64(0.6979166666666666), 26: np.float64(0.8715596330275229), 29: np.float64(0.6289752650176679)}
Micro-average F1 score: 0.6299329858525688
Weighted-average F1 score: 0.6068914158035598
cur_acc_wo_na:  ['0.7676']
his_acc_wo_na:  ['0.7676']
cur_acc des_wo_na:  ['0.7562']
his_acc des_wo_na:  ['0.7562']
cur_acc rrf_wo_na:  ['0.7712']
his_acc rrf_wo_na:  ['0.7712']
cur_acc_w_na:  ['0.6521']
his_acc_w_na:  ['0.6521']
cur_acc des_w_na:  ['0.6124']
his_acc des_w_na:  ['0.6124']
cur_acc rrf_w_na:  ['0.6299']
his_acc rrf_w_na:  ['0.6299']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 116.7376630CurrentTrain: epoch  0, batch     1 | loss: 139.8941377CurrentTrain: epoch  0, batch     2 | loss: 135.3291128CurrentTrain: epoch  0, batch     3 | loss: 88.8979617CurrentTrain: epoch  1, batch     0 | loss: 169.4979817CurrentTrain: epoch  1, batch     1 | loss: 104.8153696CurrentTrain: epoch  1, batch     2 | loss: 151.3764406CurrentTrain: epoch  1, batch     3 | loss: 79.8981038CurrentTrain: epoch  2, batch     0 | loss: 134.8413616CurrentTrain: epoch  2, batch     1 | loss: 125.1481437CurrentTrain: epoch  2, batch     2 | loss: 126.9626441CurrentTrain: epoch  2, batch     3 | loss: 83.1891763CurrentTrain: epoch  3, batch     0 | loss: 137.7294912CurrentTrain: epoch  3, batch     1 | loss: 104.4953811CurrentTrain: epoch  3, batch     2 | loss: 146.7072174CurrentTrain: epoch  3, batch     3 | loss: 77.9456849CurrentTrain: epoch  4, batch     0 | loss: 129.9889717CurrentTrain: epoch  4, batch     1 | loss: 130.9175664CurrentTrain: epoch  4, batch     2 | loss: 107.1654348CurrentTrain: epoch  4, batch     3 | loss: 101.8019873CurrentTrain: epoch  5, batch     0 | loss: 157.6916928CurrentTrain: epoch  5, batch     1 | loss: 121.1386569CurrentTrain: epoch  5, batch     2 | loss: 113.6740331CurrentTrain: epoch  5, batch     3 | loss: 60.3134008CurrentTrain: epoch  6, batch     0 | loss: 111.1179437CurrentTrain: epoch  6, batch     1 | loss: 110.8533100CurrentTrain: epoch  6, batch     2 | loss: 103.5780342CurrentTrain: epoch  6, batch     3 | loss: 118.8107417CurrentTrain: epoch  7, batch     0 | loss: 149.6662830CurrentTrain: epoch  7, batch     1 | loss: 120.9060287CurrentTrain: epoch  7, batch     2 | loss: 116.1353374CurrentTrain: epoch  7, batch     3 | loss: 67.6204649CurrentTrain: epoch  8, batch     0 | loss: 129.2906097CurrentTrain: epoch  8, batch     1 | loss: 140.4519848CurrentTrain: epoch  8, batch     2 | loss: 135.8854955CurrentTrain: epoch  8, batch     3 | loss: 58.3388417CurrentTrain: epoch  9, batch     0 | loss: 106.8242967CurrentTrain: epoch  9, batch     1 | loss: 102.5403589CurrentTrain: epoch  9, batch     2 | loss: 143.7454799CurrentTrain: epoch  9, batch     3 | loss: 72.8508758
MemoryTrain:  epoch  0, batch     0 | loss: 1.4826678MemoryTrain:  epoch  1, batch     0 | loss: 1.2287779MemoryTrain:  epoch  2, batch     0 | loss: 1.0261884MemoryTrain:  epoch  3, batch     0 | loss: 0.8210777MemoryTrain:  epoch  4, batch     0 | loss: 0.6220843MemoryTrain:  epoch  5, batch     0 | loss: 0.5279763MemoryTrain:  epoch  6, batch     0 | loss: 0.5307353MemoryTrain:  epoch  7, batch     0 | loss: 0.4401418MemoryTrain:  epoch  8, batch     0 | loss: 0.3757355MemoryTrain:  epoch  9, batch     0 | loss: 0.3086036

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.416), 36: np.float64(0.0), 6: np.float64(0.5066666666666667), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.8888888888888888), 26: np.float64(0.0), 29: np.float64(0.42857142857142855), 30: np.float64(0.7317073170731707)}
Micro-average F1 score: 0.5278450363196125
Weighted-average F1 score: 0.4782864970878908
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.6739130434782609), 36: np.float64(0.0), 6: np.float64(0.68), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.6181818181818182), 26: np.float64(0.0), 29: np.float64(0.5333333333333333), 30: np.float64(0.6888888888888889)}
Micro-average F1 score: 0.5986622073578596
Weighted-average F1 score: 0.5548072359658665
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.6892655367231638), 36: np.float64(0.0), 6: np.float64(0.6666666666666666), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.7555555555555555), 26: np.float64(0.0), 29: np.float64(0.5), 30: np.float64(0.6941176470588235)}
Micro-average F1 score: 0.6137184115523465
Weighted-average F1 score: 0.5650222020556837

F1 score per class: {32: np.float64(0.5416666666666666), 33: np.float64(0.33548387096774196), 36: np.float64(0.8105726872246696), 6: np.float64(0.48717948717948717), 8: np.float64(0.3181818181818182), 19: np.float64(0.7252747252747253), 20: np.float64(0.9082125603864735), 24: np.float64(0.8421052631578947), 26: np.float64(0.7763713080168776), 29: np.float64(0.2857142857142857), 30: np.float64(0.6870229007633588)}
Micro-average F1 score: 0.6772486772486772
Weighted-average F1 score: 0.6868868650936669
F1 score per class: {32: np.float64(0.6133333333333333), 33: np.float64(0.47692307692307695), 36: np.float64(0.7430830039525692), 6: np.float64(0.6415094339622641), 8: np.float64(0.25), 19: np.float64(0.708994708994709), 20: np.float64(0.892018779342723), 24: np.float64(0.38636363636363635), 26: np.float64(0.7560975609756098), 29: np.float64(0.38095238095238093), 30: np.float64(0.5210084033613446)}
Micro-average F1 score: 0.6326211568525274
Weighted-average F1 score: 0.6144931989505471
F1 score per class: {32: np.float64(0.6090909090909091), 33: np.float64(0.4959349593495935), 36: np.float64(0.7704918032786885), 6: np.float64(0.6304347826086957), 8: np.float64(0.3125), 19: np.float64(0.7135135135135136), 20: np.float64(0.9004739336492891), 24: np.float64(0.5862068965517241), 26: np.float64(0.75), 29: np.float64(0.32), 30: np.float64(0.5756097560975609)}
Micro-average F1 score: 0.6618464961067854
Weighted-average F1 score: 0.6512446130997632

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.33986928104575165), 36: np.float64(0.0), 6: np.float64(0.42696629213483145), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.8205128205128205), 26: np.float64(0.0), 29: np.float64(0.375), 30: np.float64(0.5625)}
Micro-average F1 score: 0.4029574861367837
Weighted-average F1 score: 0.3566924673234504
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.48627450980392156), 36: np.float64(0.0), 6: np.float64(0.5151515151515151), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.5230769230769231), 26: np.float64(0.0), 29: np.float64(0.36363636363636365), 30: np.float64(0.4509090909090909)}
Micro-average F1 score: 0.40589569160997735
Weighted-average F1 score: 0.37956239838592776
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.4959349593495935), 36: np.float64(0.0), 6: np.float64(0.5321100917431193), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.6938775510204082), 26: np.float64(0.0), 29: np.float64(0.3333333333333333), 30: np.float64(0.4591439688715953)}
Micro-average F1 score: 0.42131350681536556
Weighted-average F1 score: 0.38878729384891453

F1 score per class: {32: np.float64(0.4046692607003891), 33: np.float64(0.24644549763033174), 36: np.float64(0.7419354838709677), 6: np.float64(0.3838383838383838), 8: np.float64(0.1917808219178082), 19: np.float64(0.6534653465346535), 20: np.float64(0.8034188034188035), 24: np.float64(0.7804878048780488), 26: np.float64(0.5878594249201278), 29: np.float64(0.21428571428571427), 30: np.float64(0.5)}
Micro-average F1 score: 0.542948038176034
Weighted-average F1 score: 0.5369721583780386
F1 score per class: {32: np.float64(0.4169184290030212), 33: np.float64(0.2938388625592417), 36: np.float64(0.6438356164383562), 6: np.float64(0.41975308641975306), 8: np.float64(0.136986301369863), 19: np.float64(0.6203703703703703), 20: np.float64(0.76), 24: np.float64(0.2857142857142857), 26: np.float64(0.5502958579881657), 29: np.float64(0.24242424242424243), 30: np.float64(0.3333333333333333)}
Micro-average F1 score: 0.4528161133905259
Weighted-average F1 score: 0.4326238957381717
F1 score per class: {32: np.float64(0.4336569579288026), 33: np.float64(0.3065326633165829), 36: np.float64(0.6738351254480287), 6: np.float64(0.4461538461538462), 8: np.float64(0.16), 19: np.float64(0.6346153846153846), 20: np.float64(0.7692307692307693), 24: np.float64(0.5), 26: np.float64(0.5454545454545454), 29: np.float64(0.2), 30: np.float64(0.36085626911314983)}
Micro-average F1 score: 0.4813915857605178
Weighted-average F1 score: 0.46256689178748006
cur_acc_wo_na:  ['0.7676', '0.5278']
his_acc_wo_na:  ['0.7676', '0.6772']
cur_acc des_wo_na:  ['0.7562', '0.5987']
his_acc des_wo_na:  ['0.7562', '0.6326']
cur_acc rrf_wo_na:  ['0.7712', '0.6137']
his_acc rrf_wo_na:  ['0.7712', '0.6618']
cur_acc_w_na:  ['0.6521', '0.4030']
his_acc_w_na:  ['0.6521', '0.5429']
cur_acc des_w_na:  ['0.6124', '0.4059']
his_acc des_w_na:  ['0.6124', '0.4528']
cur_acc rrf_w_na:  ['0.6299', '0.4213']
his_acc rrf_w_na:  ['0.6299', '0.4814']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 150.3934291CurrentTrain: epoch  0, batch     1 | loss: 136.3434421CurrentTrain: epoch  0, batch     2 | loss: 126.0348761CurrentTrain: epoch  0, batch     3 | loss: 155.0369756CurrentTrain: epoch  0, batch     4 | loss: 27.5397216CurrentTrain: epoch  1, batch     0 | loss: 153.2456563CurrentTrain: epoch  1, batch     1 | loss: 112.5565950CurrentTrain: epoch  1, batch     2 | loss: 146.6477094CurrentTrain: epoch  1, batch     3 | loss: 127.3388717CurrentTrain: epoch  1, batch     4 | loss: 25.3283814CurrentTrain: epoch  2, batch     0 | loss: 121.2184664CurrentTrain: epoch  2, batch     1 | loss: 128.5761034CurrentTrain: epoch  2, batch     2 | loss: 119.1115309CurrentTrain: epoch  2, batch     3 | loss: 176.5019087CurrentTrain: epoch  2, batch     4 | loss: 44.7720282CurrentTrain: epoch  3, batch     0 | loss: 111.5164194CurrentTrain: epoch  3, batch     1 | loss: 114.7699359CurrentTrain: epoch  3, batch     2 | loss: 146.0160826CurrentTrain: epoch  3, batch     3 | loss: 144.4889945CurrentTrain: epoch  3, batch     4 | loss: 23.7195110CurrentTrain: epoch  4, batch     0 | loss: 136.1779599CurrentTrain: epoch  4, batch     1 | loss: 142.8479916CurrentTrain: epoch  4, batch     2 | loss: 119.3378377CurrentTrain: epoch  4, batch     3 | loss: 112.0840505CurrentTrain: epoch  4, batch     4 | loss: 28.5323583CurrentTrain: epoch  5, batch     0 | loss: 108.1925108CurrentTrain: epoch  5, batch     1 | loss: 142.1066557CurrentTrain: epoch  5, batch     2 | loss: 132.7047040CurrentTrain: epoch  5, batch     3 | loss: 119.3468672CurrentTrain: epoch  5, batch     4 | loss: 16.6772417CurrentTrain: epoch  6, batch     0 | loss: 135.0394313CurrentTrain: epoch  6, batch     1 | loss: 92.1331944CurrentTrain: epoch  6, batch     2 | loss: 128.5781277CurrentTrain: epoch  6, batch     3 | loss: 166.0254927CurrentTrain: epoch  6, batch     4 | loss: 28.4561472CurrentTrain: epoch  7, batch     0 | loss: 155.6288919CurrentTrain: epoch  7, batch     1 | loss: 159.8258809CurrentTrain: epoch  7, batch     2 | loss: 103.6485164CurrentTrain: epoch  7, batch     3 | loss: 111.6772592CurrentTrain: epoch  7, batch     4 | loss: 22.4358566CurrentTrain: epoch  8, batch     0 | loss: 114.9125534CurrentTrain: epoch  8, batch     1 | loss: 164.1755094CurrentTrain: epoch  8, batch     2 | loss: 99.5551538CurrentTrain: epoch  8, batch     3 | loss: 139.6623641CurrentTrain: epoch  8, batch     4 | loss: 28.8795617CurrentTrain: epoch  9, batch     0 | loss: 109.8384605CurrentTrain: epoch  9, batch     1 | loss: 160.1581654CurrentTrain: epoch  9, batch     2 | loss: 139.2142758CurrentTrain: epoch  9, batch     3 | loss: 118.9951466CurrentTrain: epoch  9, batch     4 | loss: 12.1869725
MemoryTrain:  epoch  0, batch     0 | loss: 1.4062310MemoryTrain:  epoch  1, batch     0 | loss: 1.1672756MemoryTrain:  epoch  2, batch     0 | loss: 1.0128512MemoryTrain:  epoch  3, batch     0 | loss: 0.7574479MemoryTrain:  epoch  4, batch     0 | loss: 0.6175161MemoryTrain:  epoch  5, batch     0 | loss: 0.6365550MemoryTrain:  epoch  6, batch     0 | loss: 0.5084098MemoryTrain:  epoch  7, batch     0 | loss: 0.5190815MemoryTrain:  epoch  8, batch     0 | loss: 0.4762211MemoryTrain:  epoch  9, batch     0 | loss: 0.3939922

F1 score per class: {32: np.float64(0.6363636363636364), 33: np.float64(0.0), 2: np.float64(0.0), 6: np.float64(0.64), 39: np.float64(0.5153374233128835), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.5555555555555556), 20: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.2857142857142857)}
Micro-average F1 score: 0.49411764705882355
Weighted-average F1 score: 0.4270608761990024
F1 score per class: {32: np.float64(0.4117647058823529), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.5986394557823129), 6: np.float64(0.6829268292682927), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.3333333333333333), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.4)}
Micro-average F1 score: 0.45017182130584193
Weighted-average F1 score: 0.3555220273959211
F1 score per class: {32: np.float64(0.56), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.5960264900662252), 6: np.float64(0.6865671641791045), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.3225806451612903), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.4)}
Micro-average F1 score: 0.48608534322820035
Weighted-average F1 score: 0.39897596029678567

F1 score per class: {32: np.float64(0.5384615384615384), 33: np.float64(0.5742574257425742), 2: np.float64(0.2916666666666667), 36: np.float64(0.4343891402714932), 6: np.float64(0.34854771784232363), 39: np.float64(0.7782805429864253), 8: np.float64(0.5060240963855421), 11: np.float64(0.3076923076923077), 12: np.float64(0.7374301675977654), 19: np.float64(0.16393442622950818), 20: np.float64(0.8465608465608465), 24: np.float64(0.8421052631578947), 26: np.float64(0.7215686274509804), 28: np.float64(0.35294117647058826), 29: np.float64(0.3333333333333333), 30: np.float64(0.21428571428571427)}
Micro-average F1 score: 0.5585497305242528
Weighted-average F1 score: 0.5531970903052841
F1 score per class: {32: np.float64(0.2641509433962264), 33: np.float64(0.5916666666666667), 2: np.float64(0.3132530120481928), 36: np.float64(0.4607329842931937), 6: np.float64(0.4046242774566474), 39: np.float64(0.743801652892562), 8: np.float64(0.5660377358490566), 11: np.float64(0.23376623376623376), 12: np.float64(0.7282608695652174), 19: np.float64(0.1694915254237288), 20: np.float64(0.837696335078534), 24: np.float64(0.5), 26: np.float64(0.6917293233082706), 28: np.float64(0.2857142857142857), 29: np.float64(0.6301369863013698), 30: np.float64(0.2702702702702703)}
Micro-average F1 score: 0.5377100429855413
Weighted-average F1 score: 0.5114904388745299
F1 score per class: {32: np.float64(0.4117647058823529), 33: np.float64(0.5638766519823789), 2: np.float64(0.3089430894308943), 36: np.float64(0.42857142857142855), 6: np.float64(0.41194029850746267), 39: np.float64(0.7478991596638656), 8: np.float64(0.6041666666666666), 11: np.float64(0.2647058823529412), 12: np.float64(0.7292817679558011), 19: np.float64(0.15384615384615385), 20: np.float64(0.8421052631578947), 24: np.float64(0.7391304347826086), 26: np.float64(0.673992673992674), 28: np.float64(0.3), 29: np.float64(0.5882352941176471), 30: np.float64(0.2631578947368421)}
Micro-average F1 score: 0.5473595976529757
Weighted-average F1 score: 0.524805477327779

F1 score per class: {32: np.float64(0.4117647058823529), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.5133689839572193), 6: np.float64(0.42424242424242425), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.2127659574468085), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.21428571428571427)}
Micro-average F1 score: 0.3559322033898305
Weighted-average F1 score: 0.3072541158355974
F1 score per class: {32: np.float64(0.2545454545454545), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.4888888888888889), 6: np.float64(0.532319391634981), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.17857142857142858), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.3448275862068966)}
Micro-average F1 score: 0.2990867579908676
Weighted-average F1 score: 0.2392675371200953
F1 score per class: {32: np.float64(0.34146341463414637), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.4712041884816754), 6: np.float64(0.5411764705882353), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.15873015873015872), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.30303030303030304)}
Micro-average F1 score: 0.3350383631713555
Weighted-average F1 score: 0.2803391618309346

F1 score per class: {32: np.float64(0.3181818181818182), 33: np.float64(0.38666666666666666), 2: np.float64(0.2198952879581152), 36: np.float64(0.3333333333333333), 6: np.float64(0.208955223880597), 39: np.float64(0.7078189300411523), 8: np.float64(0.3783783783783784), 11: np.float64(0.1927710843373494), 12: np.float64(0.673469387755102), 19: np.float64(0.07936507936507936), 20: np.float64(0.7547169811320755), 24: np.float64(0.7804878048780488), 26: np.float64(0.5227272727272727), 28: np.float64(0.2857142857142857), 29: np.float64(0.26666666666666666), 30: np.float64(0.11538461538461539)}
Micro-average F1 score: 0.4119985543910372
Weighted-average F1 score: 0.39067889000655154
F1 score per class: {32: np.float64(0.14583333333333334), 33: np.float64(0.376657824933687), 2: np.float64(0.18024263431542462), 36: np.float64(0.352), 6: np.float64(0.23217247097844113), 39: np.float64(0.6545454545454545), 8: np.float64(0.3821656050955414), 11: np.float64(0.13043478260869565), 12: np.float64(0.6350710900473934), 19: np.float64(0.09090909090909091), 20: np.float64(0.7476635514018691), 24: np.float64(0.38636363636363635), 26: np.float64(0.5041095890410959), 28: np.float64(0.2222222222222222), 29: np.float64(0.44878048780487806), 30: np.float64(0.14285714285714285)}
Micro-average F1 score: 0.3656656922668084
Weighted-average F1 score: 0.33952520261387925
F1 score per class: {32: np.float64(0.21212121212121213), 33: np.float64(0.37209302325581395), 2: np.float64(0.2), 36: np.float64(0.31802120141342755), 6: np.float64(0.23752151462994836), 39: np.float64(0.6617100371747212), 8: np.float64(0.4084507042253521), 11: np.float64(0.15254237288135594), 12: np.float64(0.6439024390243903), 19: np.float64(0.07874015748031496), 20: np.float64(0.7511737089201878), 24: np.float64(0.68), 26: np.float64(0.4946236559139785), 28: np.float64(0.23076923076923078), 29: np.float64(0.445859872611465), 30: np.float64(0.12987012987012986)}
Micro-average F1 score: 0.38299120234604106
Weighted-average F1 score: 0.35694807064936424
cur_acc_wo_na:  ['0.7676', '0.5278', '0.4941']
his_acc_wo_na:  ['0.7676', '0.6772', '0.5585']
cur_acc des_wo_na:  ['0.7562', '0.5987', '0.4502']
his_acc des_wo_na:  ['0.7562', '0.6326', '0.5377']
cur_acc rrf_wo_na:  ['0.7712', '0.6137', '0.4861']
his_acc rrf_wo_na:  ['0.7712', '0.6618', '0.5474']
cur_acc_w_na:  ['0.6521', '0.4030', '0.3559']
his_acc_w_na:  ['0.6521', '0.5429', '0.4120']
cur_acc des_w_na:  ['0.6124', '0.4059', '0.2991']
his_acc des_w_na:  ['0.6124', '0.4528', '0.3657']
cur_acc rrf_w_na:  ['0.6299', '0.4213', '0.3350']
his_acc rrf_w_na:  ['0.6299', '0.4814', '0.3830']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 134.3402641CurrentTrain: epoch  0, batch     1 | loss: 159.2079380CurrentTrain: epoch  0, batch     2 | loss: 148.5592387CurrentTrain: epoch  0, batch     3 | loss: 181.2139495CurrentTrain: epoch  0, batch     4 | loss: 109.5742922CurrentTrain: epoch  1, batch     0 | loss: 119.0856778CurrentTrain: epoch  1, batch     1 | loss: 146.1870125CurrentTrain: epoch  1, batch     2 | loss: 151.9092263CurrentTrain: epoch  1, batch     3 | loss: 167.4175412CurrentTrain: epoch  1, batch     4 | loss: 91.7089405CurrentTrain: epoch  2, batch     0 | loss: 128.2942071CurrentTrain: epoch  2, batch     1 | loss: 150.0153803CurrentTrain: epoch  2, batch     2 | loss: 122.7223619CurrentTrain: epoch  2, batch     3 | loss: 150.4135400CurrentTrain: epoch  2, batch     4 | loss: 105.5415270CurrentTrain: epoch  3, batch     0 | loss: 122.9685436CurrentTrain: epoch  3, batch     1 | loss: 126.7581085CurrentTrain: epoch  3, batch     2 | loss: 143.4472193CurrentTrain: epoch  3, batch     3 | loss: 129.6807702CurrentTrain: epoch  3, batch     4 | loss: 84.3591554CurrentTrain: epoch  4, batch     0 | loss: 144.0494076CurrentTrain: epoch  4, batch     1 | loss: 136.3756077CurrentTrain: epoch  4, batch     2 | loss: 116.8882715CurrentTrain: epoch  4, batch     3 | loss: 126.5874425CurrentTrain: epoch  4, batch     4 | loss: 91.4675171CurrentTrain: epoch  5, batch     0 | loss: 171.3258842CurrentTrain: epoch  5, batch     1 | loss: 123.9531090CurrentTrain: epoch  5, batch     2 | loss: 126.5097106CurrentTrain: epoch  5, batch     3 | loss: 143.3603784CurrentTrain: epoch  5, batch     4 | loss: 74.5847352CurrentTrain: epoch  6, batch     0 | loss: 116.6804923CurrentTrain: epoch  6, batch     1 | loss: 145.9361565CurrentTrain: epoch  6, batch     2 | loss: 132.9977215CurrentTrain: epoch  6, batch     3 | loss: 124.2102249CurrentTrain: epoch  6, batch     4 | loss: 119.8800683CurrentTrain: epoch  7, batch     0 | loss: 94.6352825CurrentTrain: epoch  7, batch     1 | loss: 147.9181510CurrentTrain: epoch  7, batch     2 | loss: 131.1145356CurrentTrain: epoch  7, batch     3 | loss: 140.0314709CurrentTrain: epoch  7, batch     4 | loss: 126.1437160CurrentTrain: epoch  8, batch     0 | loss: 98.3980603CurrentTrain: epoch  8, batch     1 | loss: 146.0957271CurrentTrain: epoch  8, batch     2 | loss: 110.2016686CurrentTrain: epoch  8, batch     3 | loss: 166.3824817CurrentTrain: epoch  8, batch     4 | loss: 98.0494941CurrentTrain: epoch  9, batch     0 | loss: 124.9637433CurrentTrain: epoch  9, batch     1 | loss: 119.8363369CurrentTrain: epoch  9, batch     2 | loss: 128.9145287CurrentTrain: epoch  9, batch     3 | loss: 155.9139963CurrentTrain: epoch  9, batch     4 | loss: 73.2001414
MemoryTrain:  epoch  0, batch     0 | loss: 1.3358178MemoryTrain:  epoch  1, batch     0 | loss: 1.3603223MemoryTrain:  epoch  2, batch     0 | loss: 1.0007092MemoryTrain:  epoch  3, batch     0 | loss: 0.7761336MemoryTrain:  epoch  4, batch     0 | loss: 0.7079705MemoryTrain:  epoch  5, batch     0 | loss: 0.5761839MemoryTrain:  epoch  6, batch     0 | loss: 0.4892520MemoryTrain:  epoch  7, batch     0 | loss: 0.4420775MemoryTrain:  epoch  8, batch     0 | loss: 0.3799975MemoryTrain:  epoch  9, batch     0 | loss: 0.2803714

F1 score per class: {2: np.float64(0.0), 5: np.float64(0.9215686274509803), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.23931623931623933), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.6885245901639344), 17: np.float64(0.0), 18: np.float64(0.05), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5158730158730159
Weighted-average F1 score: 0.5324814720103509
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.7153284671532847), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.48226950354609927), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.7246376811594203), 17: np.float64(0.7058823529411765), 18: np.float64(0.4090909090909091), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5
Weighted-average F1 score: 0.44422269571974277
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.7804878048780488), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.4788732394366197), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.7058823529411765), 17: np.float64(0.7142857142857143), 18: np.float64(0.2702702702702703), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5082706766917293
Weighted-average F1 score: 0.4484803433206335

F1 score per class: {2: np.float64(0.42105263157894735), 5: np.float64(0.8995215311004785), 6: np.float64(0.5076142131979695), 8: np.float64(0.19607843137254902), 10: np.float64(0.1761006289308176), 11: np.float64(0.174496644295302), 12: np.float64(0.329004329004329), 16: np.float64(0.5753424657534246), 17: np.float64(0.0), 18: np.float64(0.047619047619047616), 19: np.float64(0.7706422018348624), 20: np.float64(0.475), 24: np.float64(0.2222222222222222), 26: np.float64(0.7231638418079096), 28: np.float64(0.2564102564102564), 29: np.float64(0.837696335078534), 30: np.float64(0.8421052631578947), 32: np.float64(0.7380952380952381), 33: np.float64(0.375), 36: np.float64(0.11428571428571428), 39: np.float64(0.17647058823529413)}
Micro-average F1 score: 0.5269410267288926
Weighted-average F1 score: 0.5641749601147097
F1 score per class: {2: np.float64(0.4666666666666667), 5: np.float64(0.6302250803858521), 6: np.float64(0.5809128630705395), 8: np.float64(0.3076923076923077), 10: np.float64(0.3541666666666667), 11: np.float64(0.24), 12: np.float64(0.35795454545454547), 16: np.float64(0.6024096385542169), 17: np.float64(0.35294117647058826), 18: np.float64(0.21818181818181817), 19: np.float64(0.7301587301587301), 20: np.float64(0.4897959183673469), 24: np.float64(0.2222222222222222), 26: np.float64(0.6903553299492385), 28: np.float64(0.1509433962264151), 29: np.float64(0.819672131147541), 30: np.float64(0.5074626865671642), 32: np.float64(0.6690391459074733), 33: np.float64(0.2727272727272727), 36: np.float64(0.5815602836879432), 39: np.float64(0.1951219512195122)}
Micro-average F1 score: 0.5032905045440301
Weighted-average F1 score: 0.4919229496345011
F1 score per class: {2: np.float64(0.43478260869565216), 5: np.float64(0.7032967032967034), 6: np.float64(0.5688888888888889), 8: np.float64(0.31137724550898205), 10: np.float64(0.34), 11: np.float64(0.273224043715847), 12: np.float64(0.367816091954023), 16: np.float64(0.5853658536585366), 17: np.float64(0.37037037037037035), 18: np.float64(0.16260162601626016), 19: np.float64(0.7449392712550608), 20: np.float64(0.5434782608695652), 24: np.float64(0.25806451612903225), 26: np.float64(0.7195767195767195), 28: np.float64(0.11764705882352941), 29: np.float64(0.819672131147541), 30: np.float64(0.7083333333333334), 32: np.float64(0.6836363636363636), 33: np.float64(0.2608695652173913), 36: np.float64(0.3917525773195876), 39: np.float64(0.2702702702702703)}
Micro-average F1 score: 0.5134589502018843
Weighted-average F1 score: 0.5036035772117058

F1 score per class: {2: np.float64(0.0), 5: np.float64(0.7932489451476793), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.224), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.46153846153846156), 17: np.float64(0.0), 18: np.float64(0.05), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.37249283667621774
Weighted-average F1 score: 0.33786481431061194
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.532608695652174), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.40476190476190477), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.45045045045045046), 17: np.float64(0.6), 18: np.float64(0.2553191489361702), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.3197879858657244
Weighted-average F1 score: 0.28026006768042094
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.6), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.3953488372093023), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.44036697247706424), 17: np.float64(0.625), 18: np.float64(0.20833333333333334), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.32847424684159376
Weighted-average F1 score: 0.28143529053310024

F1 score per class: {2: np.float64(0.25), 5: np.float64(0.7611336032388664), 6: np.float64(0.32894736842105265), 8: np.float64(0.18018018018018017), 10: np.float64(0.15819209039548024), 11: np.float64(0.14942528735632185), 12: np.float64(0.18181818181818182), 16: np.float64(0.358974358974359), 17: np.float64(0.0), 18: np.float64(0.04), 19: np.float64(0.7), 20: np.float64(0.34545454545454546), 24: np.float64(0.14925373134328357), 26: np.float64(0.6432160804020101), 28: np.float64(0.13157894736842105), 29: np.float64(0.7373271889400922), 30: np.float64(0.8), 32: np.float64(0.5705521472392638), 33: np.float64(0.3), 36: np.float64(0.10526315789473684), 39: np.float64(0.09523809523809523)}
Micro-average F1 score: 0.4022020725388601
Weighted-average F1 score: 0.40263754737053453
F1 score per class: {2: np.float64(0.25925925925925924), 5: np.float64(0.40329218106995884), 6: np.float64(0.33816425120772947), 8: np.float64(0.21694915254237288), 10: np.float64(0.2518518518518518), 11: np.float64(0.21686746987951808), 12: np.float64(0.1941448382126348), 16: np.float64(0.3424657534246575), 17: np.float64(0.2222222222222222), 18: np.float64(0.1157556270096463), 19: np.float64(0.6388888888888888), 20: np.float64(0.3221476510067114), 24: np.float64(0.12738853503184713), 26: np.float64(0.5862068965517241), 28: np.float64(0.07766990291262135), 29: np.float64(0.746268656716418), 30: np.float64(0.37777777777777777), 32: np.float64(0.5222222222222223), 33: np.float64(0.23076923076923078), 36: np.float64(0.4270833333333333), 39: np.float64(0.0963855421686747)}
Micro-average F1 score: 0.33982225983918746
Weighted-average F1 score: 0.32245407110059165
F1 score per class: {2: np.float64(0.25), 5: np.float64(0.4648910411622276), 6: np.float64(0.3450134770889488), 8: np.float64(0.2184873949579832), 10: np.float64(0.23859649122807017), 11: np.float64(0.21367521367521367), 12: np.float64(0.19722650231124808), 16: np.float64(0.3356643356643357), 17: np.float64(0.2222222222222222), 18: np.float64(0.09852216748768473), 19: np.float64(0.6715328467153284), 20: np.float64(0.35714285714285715), 24: np.float64(0.1553398058252427), 26: np.float64(0.6296296296296297), 28: np.float64(0.064), 29: np.float64(0.75), 30: np.float64(0.6071428571428571), 32: np.float64(0.5207756232686981), 33: np.float64(0.2), 36: np.float64(0.3064516129032258), 39: np.float64(0.12658227848101267)}
Micro-average F1 score: 0.3525063525063525
Weighted-average F1 score: 0.33434028764050727
cur_acc_wo_na:  ['0.7676', '0.5278', '0.4941', '0.5159']
his_acc_wo_na:  ['0.7676', '0.6772', '0.5585', '0.5269']
cur_acc des_wo_na:  ['0.7562', '0.5987', '0.4502', '0.5000']
his_acc des_wo_na:  ['0.7562', '0.6326', '0.5377', '0.5033']
cur_acc rrf_wo_na:  ['0.7712', '0.6137', '0.4861', '0.5083']
his_acc rrf_wo_na:  ['0.7712', '0.6618', '0.5474', '0.5135']
cur_acc_w_na:  ['0.6521', '0.4030', '0.3559', '0.3725']
his_acc_w_na:  ['0.6521', '0.5429', '0.4120', '0.4022']
cur_acc des_w_na:  ['0.6124', '0.4059', '0.2991', '0.3198']
his_acc des_w_na:  ['0.6124', '0.4528', '0.3657', '0.3398']
cur_acc rrf_w_na:  ['0.6299', '0.4213', '0.3350', '0.3285']
his_acc rrf_w_na:  ['0.6299', '0.4814', '0.3830', '0.3525']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 137.2635822CurrentTrain: epoch  0, batch     1 | loss: 141.3860300CurrentTrain: epoch  0, batch     2 | loss: 139.3040159CurrentTrain: epoch  0, batch     3 | loss: 188.8699660CurrentTrain: epoch  0, batch     4 | loss: 85.7032019CurrentTrain: epoch  1, batch     0 | loss: 116.3485790CurrentTrain: epoch  1, batch     1 | loss: 145.6153690CurrentTrain: epoch  1, batch     2 | loss: 215.7753788CurrentTrain: epoch  1, batch     3 | loss: 135.0180750CurrentTrain: epoch  1, batch     4 | loss: 83.6753277CurrentTrain: epoch  2, batch     0 | loss: 129.3724025CurrentTrain: epoch  2, batch     1 | loss: 129.3337613CurrentTrain: epoch  2, batch     2 | loss: 130.8363342CurrentTrain: epoch  2, batch     3 | loss: 146.8151542CurrentTrain: epoch  2, batch     4 | loss: 98.9494506CurrentTrain: epoch  3, batch     0 | loss: 108.9887020CurrentTrain: epoch  3, batch     1 | loss: 113.6442376CurrentTrain: epoch  3, batch     2 | loss: 133.8580485CurrentTrain: epoch  3, batch     3 | loss: 146.6370224CurrentTrain: epoch  3, batch     4 | loss: 147.2656436CurrentTrain: epoch  4, batch     0 | loss: 127.1784315CurrentTrain: epoch  4, batch     1 | loss: 136.8508774CurrentTrain: epoch  4, batch     2 | loss: 132.3221245CurrentTrain: epoch  4, batch     3 | loss: 119.4406491CurrentTrain: epoch  4, batch     4 | loss: 93.8949451CurrentTrain: epoch  5, batch     0 | loss: 138.4933275CurrentTrain: epoch  5, batch     1 | loss: 169.3054464CurrentTrain: epoch  5, batch     2 | loss: 138.9230192CurrentTrain: epoch  5, batch     3 | loss: 104.3207581CurrentTrain: epoch  5, batch     4 | loss: 78.8913662CurrentTrain: epoch  6, batch     0 | loss: 123.1297841CurrentTrain: epoch  6, batch     1 | loss: 142.5215307CurrentTrain: epoch  6, batch     2 | loss: 114.0862632CurrentTrain: epoch  6, batch     3 | loss: 126.6637742CurrentTrain: epoch  6, batch     4 | loss: 78.4517406CurrentTrain: epoch  7, batch     0 | loss: 117.2376935CurrentTrain: epoch  7, batch     1 | loss: 126.6628947CurrentTrain: epoch  7, batch     2 | loss: 131.9346450CurrentTrain: epoch  7, batch     3 | loss: 111.0784759CurrentTrain: epoch  7, batch     4 | loss: 95.8601319CurrentTrain: epoch  8, batch     0 | loss: 133.9149354CurrentTrain: epoch  8, batch     1 | loss: 165.3640336CurrentTrain: epoch  8, batch     2 | loss: 154.5682037CurrentTrain: epoch  8, batch     3 | loss: 109.7159757CurrentTrain: epoch  8, batch     4 | loss: 67.5950098CurrentTrain: epoch  9, batch     0 | loss: 110.3424520CurrentTrain: epoch  9, batch     1 | loss: 133.6610005CurrentTrain: epoch  9, batch     2 | loss: 118.5342742CurrentTrain: epoch  9, batch     3 | loss: 134.2026536CurrentTrain: epoch  9, batch     4 | loss: 89.3602955
MemoryTrain:  epoch  0, batch     0 | loss: 1.1606343MemoryTrain:  epoch  1, batch     0 | loss: 0.9673456MemoryTrain:  epoch  2, batch     0 | loss: 0.8055365MemoryTrain:  epoch  3, batch     0 | loss: 0.6865725MemoryTrain:  epoch  4, batch     0 | loss: 0.5409316MemoryTrain:  epoch  5, batch     0 | loss: 0.4880226MemoryTrain:  epoch  6, batch     0 | loss: 0.3959386MemoryTrain:  epoch  7, batch     0 | loss: 0.3586466MemoryTrain:  epoch  8, batch     0 | loss: 0.2977312MemoryTrain:  epoch  9, batch     0 | loss: 0.2420724

F1 score per class: {1: np.float64(0.21301775147928995), 3: np.float64(0.6871165644171779), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.13008130081300814), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.45081967213114754), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6461538461538462)}
Micro-average F1 score: 0.36088709677419356
Weighted-average F1 score: 0.313710618259969
F1 score per class: {1: np.float64(0.26229508196721313), 3: np.float64(0.6033057851239669), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0784313725490196), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.4722222222222222), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6363636363636364), 36: np.float64(0.0)}
Micro-average F1 score: 0.3306188925081433
Weighted-average F1 score: 0.29141579061357725
F1 score per class: {1: np.float64(0.25555555555555554), 3: np.float64(0.6575342465753424), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.08823529411764706), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.4915254237288136), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6666666666666666)}
Micro-average F1 score: 0.3587982832618026
Weighted-average F1 score: 0.31818485408945907

F1 score per class: {1: np.float64(0.18), 2: np.float64(0.4), 3: np.float64(0.5544554455445545), 5: np.float64(0.8952380952380953), 6: np.float64(0.5022421524663677), 8: np.float64(0.35294117647058826), 10: np.float64(0.3739130434782609), 11: np.float64(0.12422360248447205), 12: np.float64(0.2796610169491525), 14: np.float64(0.10062893081761007), 16: np.float64(0.5853658536585366), 17: np.float64(0.0), 18: np.float64(0.0392156862745098), 19: np.float64(0.6363636363636364), 20: np.float64(0.44155844155844154), 22: np.float64(0.3741496598639456), 24: np.float64(0.0), 26: np.float64(0.7142857142857143), 28: np.float64(0.136986301369863), 29: np.float64(0.8061224489795918), 30: np.float64(0.918918918918919), 32: np.float64(0.6277372262773723), 33: np.float64(0.3333333333333333), 34: np.float64(0.27009646302250806), 36: np.float64(0.13513513513513514), 39: np.float64(0.25)}
Micro-average F1 score: 0.4409199048374306
Weighted-average F1 score: 0.43348456069370633
F1 score per class: {1: np.float64(0.21238938053097345), 2: np.float64(0.4666666666666667), 3: np.float64(0.40668523676880225), 5: np.float64(0.6689419795221843), 6: np.float64(0.5220588235294118), 8: np.float64(0.3643410852713178), 10: np.float64(0.4186046511627907), 11: np.float64(0.1476510067114094), 12: np.float64(0.32972972972972975), 14: np.float64(0.04938271604938271), 16: np.float64(0.6341463414634146), 17: np.float64(0.24), 18: np.float64(0.15873015873015872), 19: np.float64(0.5870967741935483), 20: np.float64(0.4731182795698925), 22: np.float64(0.3953488372093023), 24: np.float64(0.1111111111111111), 26: np.float64(0.6868686868686869), 28: np.float64(0.14285714285714285), 29: np.float64(0.7916666666666666), 30: np.float64(0.6428571428571429), 32: np.float64(0.5341246290801187), 33: np.float64(0.375), 34: np.float64(0.1686746987951807), 36: np.float64(0.5815602836879432), 39: np.float64(0.16666666666666666)}
Micro-average F1 score: 0.4051087607264019
Weighted-average F1 score: 0.38610239444842326
F1 score per class: {1: np.float64(0.21100917431192662), 2: np.float64(0.4166666666666667), 3: np.float64(0.46006389776357826), 5: np.float64(0.7413127413127413), 6: np.float64(0.5378151260504201), 8: np.float64(0.3978494623655914), 10: np.float64(0.4025974025974026), 11: np.float64(0.1509433962264151), 12: np.float64(0.3389830508474576), 14: np.float64(0.05853658536585366), 16: np.float64(0.6190476190476191), 17: np.float64(0.23529411764705882), 18: np.float64(0.03389830508474576), 19: np.float64(0.6033898305084746), 20: np.float64(0.4772727272727273), 22: np.float64(0.39862542955326463), 24: np.float64(0.05128205128205128), 26: np.float64(0.7046632124352331), 28: np.float64(0.11594202898550725), 29: np.float64(0.7916666666666666), 30: np.float64(0.85), 32: np.float64(0.5415384615384615), 33: np.float64(0.35294117647058826), 34: np.float64(0.17513134851138354), 36: np.float64(0.2619047619047619), 39: np.float64(0.23076923076923078)}
Micro-average F1 score: 0.4094017094017094
Weighted-average F1 score: 0.39130144098886743

F1 score per class: {1: np.float64(0.1188118811881188), 2: np.float64(0.0), 3: np.float64(0.5544554455445545), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.11267605633802817), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.3448275862068966), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.5185185185185185)}
Micro-average F1 score: 0.2465564738292011
Weighted-average F1 score: 0.21399435352651341
F1 score per class: {1: np.float64(0.14285714285714285), 2: np.float64(0.0), 3: np.float64(0.4), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.06629834254143646), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.3655913978494624), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.44954128440366975), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.21156852527358
Weighted-average F1 score: 0.19131971957459934
F1 score per class: {1: np.float64(0.14067278287461774), 2: np.float64(0.0), 3: np.float64(0.4630225080385852), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.07643312101910828), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.36942675159235666), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.4807692307692308), 39: np.float64(0.0)}
Micro-average F1 score: 0.23209328151027206
Weighted-average F1 score: 0.20968361833993465

F1 score per class: {1: np.float64(0.0962566844919786), 2: np.float64(0.21621621621621623), 3: np.float64(0.3708609271523179), 5: np.float64(0.7230769230769231), 6: np.float64(0.30684931506849317), 8: np.float64(0.294478527607362), 10: np.float64(0.2606060606060606), 11: np.float64(0.1), 12: np.float64(0.14634146341463414), 14: np.float64(0.07920792079207921), 16: np.float64(0.35555555555555557), 17: np.float64(0.0), 18: np.float64(0.029411764705882353), 19: np.float64(0.5581395348837209), 20: np.float64(0.33663366336633666), 22: np.float64(0.2756892230576441), 24: np.float64(0.0), 26: np.float64(0.6341463414634146), 28: np.float64(0.07092198581560284), 29: np.float64(0.6869565217391305), 30: np.float64(0.8717948717948718), 32: np.float64(0.48314606741573035), 33: np.float64(0.2727272727272727), 34: np.float64(0.15217391304347827), 36: np.float64(0.125), 39: np.float64(0.12345679012345678)}
Micro-average F1 score: 0.30689972401103954
Weighted-average F1 score: 0.29052411863298416
F1 score per class: {1: np.float64(0.11085450346420324), 2: np.float64(0.2545454545454545), 3: np.float64(0.23548387096774193), 5: np.float64(0.43171806167400884), 6: np.float64(0.2903885480572597), 8: np.float64(0.23737373737373738), 10: np.float64(0.2669491525423729), 11: np.float64(0.1286549707602339), 12: np.float64(0.1628838451268358), 14: np.float64(0.04), 16: np.float64(0.36879432624113473), 17: np.float64(0.15), 18: np.float64(0.1), 19: np.float64(0.5013774104683195), 20: np.float64(0.29931972789115646), 22: np.float64(0.2833333333333333), 24: np.float64(0.08695652173913043), 26: np.float64(0.5787234042553191), 28: np.float64(0.06722689075630252), 29: np.float64(0.6940639269406392), 30: np.float64(0.5625), 32: np.float64(0.3991130820399113), 33: np.float64(0.2857142857142857), 34: np.float64(0.0980980980980981), 36: np.float64(0.4019607843137255), 39: np.float64(0.09090909090909091)}
Micro-average F1 score: 0.2616316535636036
Weighted-average F1 score: 0.24760690368647778
F1 score per class: {1: np.float64(0.11031175059952038), 2: np.float64(0.23809523809523808), 3: np.float64(0.277992277992278), 5: np.float64(0.518918918918919), 6: np.float64(0.30917874396135264), 8: np.float64(0.29959514170040485), 10: np.float64(0.2577962577962578), 11: np.float64(0.1218274111675127), 12: np.float64(0.16666666666666666), 14: np.float64(0.048), 16: np.float64(0.36363636363636365), 17: np.float64(0.125), 18: np.float64(0.025), 19: np.float64(0.52046783625731), 20: np.float64(0.29577464788732394), 22: np.float64(0.27488151658767773), 24: np.float64(0.045454545454545456), 26: np.float64(0.5991189427312775), 28: np.float64(0.05442176870748299), 29: np.float64(0.6972477064220184), 30: np.float64(0.8095238095238095), 32: np.float64(0.4045977011494253), 33: np.float64(0.2727272727272727), 34: np.float64(0.10070493454179255), 36: np.float64(0.21153846153846154), 39: np.float64(0.12371134020618557)}
Micro-average F1 score: 0.2681220263084243
Weighted-average F1 score: 0.2524840641226495
cur_acc_wo_na:  ['0.7676', '0.5278', '0.4941', '0.5159', '0.3609']
his_acc_wo_na:  ['0.7676', '0.6772', '0.5585', '0.5269', '0.4409']
cur_acc des_wo_na:  ['0.7562', '0.5987', '0.4502', '0.5000', '0.3306']
his_acc des_wo_na:  ['0.7562', '0.6326', '0.5377', '0.5033', '0.4051']
cur_acc rrf_wo_na:  ['0.7712', '0.6137', '0.4861', '0.5083', '0.3588']
his_acc rrf_wo_na:  ['0.7712', '0.6618', '0.5474', '0.5135', '0.4094']
cur_acc_w_na:  ['0.6521', '0.4030', '0.3559', '0.3725', '0.2466']
his_acc_w_na:  ['0.6521', '0.5429', '0.4120', '0.4022', '0.3069']
cur_acc des_w_na:  ['0.6124', '0.4059', '0.2991', '0.3198', '0.2116']
his_acc des_w_na:  ['0.6124', '0.4528', '0.3657', '0.3398', '0.2616']
cur_acc rrf_w_na:  ['0.6299', '0.4213', '0.3350', '0.3285', '0.2321']
his_acc rrf_w_na:  ['0.6299', '0.4814', '0.3830', '0.3525', '0.2681']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 129.3546471CurrentTrain: epoch  0, batch     1 | loss: 148.9400640CurrentTrain: epoch  0, batch     2 | loss: 105.2323965CurrentTrain: epoch  0, batch     3 | loss: 19.5603860CurrentTrain: epoch  1, batch     0 | loss: 111.9771030CurrentTrain: epoch  1, batch     1 | loss: 109.3194443CurrentTrain: epoch  1, batch     2 | loss: 143.2601613CurrentTrain: epoch  1, batch     3 | loss: 15.4754586CurrentTrain: epoch  2, batch     0 | loss: 122.6812007CurrentTrain: epoch  2, batch     1 | loss: 98.5016580CurrentTrain: epoch  2, batch     2 | loss: 132.5416049CurrentTrain: epoch  2, batch     3 | loss: 12.8047430CurrentTrain: epoch  3, batch     0 | loss: 118.0593607CurrentTrain: epoch  3, batch     1 | loss: 103.2035987CurrentTrain: epoch  3, batch     2 | loss: 130.7512182CurrentTrain: epoch  3, batch     3 | loss: 23.9713801CurrentTrain: epoch  4, batch     0 | loss: 132.1869310CurrentTrain: epoch  4, batch     1 | loss: 102.3619157CurrentTrain: epoch  4, batch     2 | loss: 96.3307383CurrentTrain: epoch  4, batch     3 | loss: 8.3261108CurrentTrain: epoch  5, batch     0 | loss: 89.4088407CurrentTrain: epoch  5, batch     1 | loss: 123.4521249CurrentTrain: epoch  5, batch     2 | loss: 116.9259033CurrentTrain: epoch  5, batch     3 | loss: 22.2539123CurrentTrain: epoch  6, batch     0 | loss: 107.3474729CurrentTrain: epoch  6, batch     1 | loss: 106.7291216CurrentTrain: epoch  6, batch     2 | loss: 108.0962780CurrentTrain: epoch  6, batch     3 | loss: 5.4138617CurrentTrain: epoch  7, batch     0 | loss: 101.1061445CurrentTrain: epoch  7, batch     1 | loss: 101.7829487CurrentTrain: epoch  7, batch     2 | loss: 109.7262614CurrentTrain: epoch  7, batch     3 | loss: 19.8698744CurrentTrain: epoch  8, batch     0 | loss: 103.0854361CurrentTrain: epoch  8, batch     1 | loss: 95.6055670CurrentTrain: epoch  8, batch     2 | loss: 114.7174736CurrentTrain: epoch  8, batch     3 | loss: 24.8561530CurrentTrain: epoch  9, batch     0 | loss: 102.0782006CurrentTrain: epoch  9, batch     1 | loss: 100.9904261CurrentTrain: epoch  9, batch     2 | loss: 99.5900007CurrentTrain: epoch  9, batch     3 | loss: 15.8475813
MemoryTrain:  epoch  0, batch     0 | loss: 0.8991889MemoryTrain:  epoch  1, batch     0 | loss: 0.6929180MemoryTrain:  epoch  2, batch     0 | loss: 0.5606440MemoryTrain:  epoch  3, batch     0 | loss: 0.4236138MemoryTrain:  epoch  4, batch     0 | loss: 0.3706689MemoryTrain:  epoch  5, batch     0 | loss: 0.2954473MemoryTrain:  epoch  6, batch     0 | loss: 0.2386274MemoryTrain:  epoch  7, batch     0 | loss: 0.2064462MemoryTrain:  epoch  8, batch     0 | loss: 0.1911055MemoryTrain:  epoch  9, batch     0 | loss: 0.1806573

F1 score per class: {32: np.float64(0.0), 1: np.float64(0.0), 34: np.float64(0.8), 3: np.float64(0.8679245283018868), 7: np.float64(0.0), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.3225806451612903)}
Micro-average F1 score: 0.3219178082191781
Weighted-average F1 score: 0.25560942917518653
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7272727272727273), 8: np.float64(0.0), 9: np.float64(0.6666666666666666), 10: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.16666666666666666), 32: np.float64(0.0), 34: np.float64(0.0), 40: np.float64(0.6580645161290323)}
Micro-average F1 score: 0.4764705882352941
Weighted-average F1 score: 0.4245512504433429
F1 score per class: {32: np.float64(0.0), 1: np.float64(0.0), 34: np.float64(0.0), 3: np.float64(0.6666666666666666), 6: np.float64(0.7666666666666667), 7: np.float64(0.0), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.2857142857142857), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.6296296296296297)}
Micro-average F1 score: 0.49221183800623053
Weighted-average F1 score: 0.44129028959946837

F1 score per class: {1: np.float64(0.1511111111111111), 2: np.float64(0.4), 3: np.float64(0.48484848484848486), 5: np.float64(0.8952380952380953), 6: np.float64(0.05555555555555555), 7: np.float64(0.04678362573099415), 8: np.float64(0.17647058823529413), 9: np.float64(0.8518518518518519), 10: np.float64(0.19736842105263158), 11: np.float64(0.1686746987951807), 12: np.float64(0.03896103896103896), 14: np.float64(0.045714285714285714), 16: np.float64(0.5625), 17: np.float64(0.0), 18: np.float64(0.03508771929824561), 19: np.float64(0.532319391634981), 20: np.float64(0.5454545454545454), 22: np.float64(0.29069767441860467), 24: np.float64(0.0), 26: np.float64(0.6823529411764706), 27: np.float64(0.0), 28: np.float64(0.17543859649122806), 29: np.float64(0.6900584795321637), 30: np.float64(0.8108108108108109), 31: np.float64(0.0), 32: np.float64(0.6504065040650406), 33: np.float64(0.375), 34: np.float64(0.35454545454545455), 36: np.float64(0.14084507042253522), 39: np.float64(0.08695652173913043), 40: np.float64(0.10443864229765012)}
Micro-average F1 score: 0.34233289646133686
Weighted-average F1 score: 0.32765713490234744
F1 score per class: {1: np.float64(0.18181818181818182), 2: np.float64(0.35294117647058826), 3: np.float64(0.5130111524163569), 5: np.float64(0.6468646864686468), 6: np.float64(0.2184873949579832), 7: np.float64(0.046511627906976744), 8: np.float64(0.36477987421383645), 9: np.float64(0.5319148936170213), 10: np.float64(0.2929936305732484), 11: np.float64(0.128), 12: np.float64(0.19626168224299065), 14: np.float64(0.06030150753768844), 16: np.float64(0.5633802816901409), 17: np.float64(0.26666666666666666), 18: np.float64(0.13333333333333333), 19: np.float64(0.5668016194331984), 20: np.float64(0.5154639175257731), 22: np.float64(0.42016806722689076), 24: np.float64(0.11428571428571428), 26: np.float64(0.6907216494845361), 27: np.float64(0.0), 28: np.float64(0.11904761904761904), 29: np.float64(0.7209302325581395), 30: np.float64(0.7555555555555555), 31: np.float64(0.025), 32: np.float64(0.5874125874125874), 33: np.float64(0.375), 34: np.float64(0.18455743879472694), 36: np.float64(0.6060606060606061), 39: np.float64(0.15384615384615385), 40: np.float64(0.2956521739130435)}
Micro-average F1 score: 0.3649937785151389
Weighted-average F1 score: 0.3422177268235868
F1 score per class: {1: np.float64(0.1700404858299595), 2: np.float64(0.46153846153846156), 3: np.float64(0.5714285714285714), 5: np.float64(0.7132352941176471), 6: np.float64(0.18803418803418803), 7: np.float64(0.044444444444444446), 8: np.float64(0.3404255319148936), 9: np.float64(0.7419354838709677), 10: np.float64(0.2929936305732484), 11: np.float64(0.1267605633802817), 12: np.float64(0.15151515151515152), 14: np.float64(0.08247422680412371), 16: np.float64(0.5405405405405406), 17: np.float64(0.15384615384615385), 18: np.float64(0.11428571428571428), 19: np.float64(0.5957446808510638), 20: np.float64(0.5263157894736842), 22: np.float64(0.4265402843601896), 24: np.float64(0.06896551724137931), 26: np.float64(0.7142857142857143), 27: np.float64(0.0), 28: np.float64(0.12987012987012986), 29: np.float64(0.7251461988304093), 30: np.float64(0.8648648648648649), 31: np.float64(0.06060606060606061), 32: np.float64(0.5899280575539568), 33: np.float64(0.3333333333333333), 34: np.float64(0.20568927789934355), 36: np.float64(0.3058823529411765), 39: np.float64(0.1111111111111111), 40: np.float64(0.26356589147286824)}
Micro-average F1 score: 0.3656633221850613
Weighted-average F1 score: 0.34291640664085865

F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.8), 9: np.float64(0.8363636363636363), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 40: np.float64(0.2962962962962963)}
Micro-average F1 score: 0.27325581395348836
Weighted-average F1 score: 0.20915824915824915
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7272727272727273), 8: np.float64(0.0), 9: np.float64(0.5813953488372093), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.1111111111111111), 32: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 40: np.float64(0.6071428571428571)}
Micro-average F1 score: 0.38028169014084506
Weighted-average F1 score: 0.3260878871343988
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6666666666666666), 9: np.float64(0.7301587301587301), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.18181818181818182), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 40: np.float64(0.5730337078651685)}
Micro-average F1 score: 0.4
Weighted-average F1 score: 0.3428918547475867

F1 score per class: {1: np.float64(0.08564231738035265), 2: np.float64(0.22857142857142856), 3: np.float64(0.34782608695652173), 5: np.float64(0.7401574803149606), 6: np.float64(0.046511627906976744), 7: np.float64(0.02416918429003021), 8: np.float64(0.16071428571428573), 9: np.float64(0.8070175438596491), 10: np.float64(0.17341040462427745), 11: np.float64(0.13270142180094788), 12: np.float64(0.030456852791878174), 14: np.float64(0.03571428571428571), 16: np.float64(0.36), 17: np.float64(0.0), 18: np.float64(0.023255813953488372), 19: np.float64(0.5017921146953405), 20: np.float64(0.3609022556390977), 22: np.float64(0.2242152466367713), 24: np.float64(0.0), 26: np.float64(0.6170212765957447), 27: np.float64(0.0), 28: np.float64(0.09433962264150944), 29: np.float64(0.6276595744680851), 30: np.float64(0.7692307692307693), 31: np.float64(0.0), 32: np.float64(0.517799352750809), 33: np.float64(0.3), 34: np.float64(0.2215909090909091), 36: np.float64(0.13513513513513514), 39: np.float64(0.05), 40: np.float64(0.08316008316008316)}
Micro-average F1 score: 0.258102766798419
Weighted-average F1 score: 0.23770666860394865
F1 score per class: {1: np.float64(0.10185185185185185), 2: np.float64(0.2), 3: np.float64(0.32935560859188545), 5: np.float64(0.42516268980477223), 6: np.float64(0.18439716312056736), 7: np.float64(0.0226628895184136), 8: np.float64(0.27358490566037735), 9: np.float64(0.43103448275862066), 10: np.float64(0.23115577889447236), 11: np.float64(0.11510791366906475), 12: np.float64(0.12138728323699421), 14: np.float64(0.04918032786885246), 16: np.float64(0.35714285714285715), 17: np.float64(0.16), 18: np.float64(0.07518796992481203), 19: np.float64(0.5185185185185185), 20: np.float64(0.3067484662576687), 22: np.float64(0.3105590062111801), 24: np.float64(0.09523809523809523), 26: np.float64(0.5877192982456141), 27: np.float64(0.0), 28: np.float64(0.056818181818181816), 29: np.float64(0.656084656084656), 30: np.float64(0.7083333333333334), 31: np.float64(0.013333333333333334), 32: np.float64(0.450402144772118), 33: np.float64(0.2857142857142857), 34: np.float64(0.1112372304199773), 36: np.float64(0.4419889502762431), 39: np.float64(0.08450704225352113), 40: np.float64(0.24)}
Micro-average F1 score: 0.2525832376578645
Weighted-average F1 score: 0.2332302404713414
F1 score per class: {1: np.float64(0.09655172413793103), 2: np.float64(0.2727272727272727), 3: np.float64(0.3728813559322034), 5: np.float64(0.49489795918367346), 6: np.float64(0.15942028985507245), 7: np.float64(0.02127659574468085), 8: np.float64(0.2696629213483146), 9: np.float64(0.6764705882352942), 10: np.float64(0.23), 11: np.float64(0.11320754716981132), 12: np.float64(0.09554140127388536), 14: np.float64(0.06557377049180328), 16: np.float64(0.3418803418803419), 17: np.float64(0.09090909090909091), 18: np.float64(0.06504065040650407), 19: np.float64(0.5511811023622047), 20: np.float64(0.31446540880503143), 22: np.float64(0.313588850174216), 24: np.float64(0.06060606060606061), 26: np.float64(0.6341463414634146), 27: np.float64(0.0), 28: np.float64(0.0641025641025641), 29: np.float64(0.6595744680851063), 30: np.float64(0.8205128205128205), 31: np.float64(0.029411764705882353), 32: np.float64(0.45054945054945056), 33: np.float64(0.25), 34: np.float64(0.12384716732542819), 36: np.float64(0.2524271844660194), 39: np.float64(0.06153846153846154), 40: np.float64(0.20816326530612245)}
Micro-average F1 score: 0.2565707133917397
Weighted-average F1 score: 0.23477143776609527
cur_acc_wo_na:  ['0.7676', '0.5278', '0.4941', '0.5159', '0.3609', '0.3219']
his_acc_wo_na:  ['0.7676', '0.6772', '0.5585', '0.5269', '0.4409', '0.3423']
cur_acc des_wo_na:  ['0.7562', '0.5987', '0.4502', '0.5000', '0.3306', '0.4765']
his_acc des_wo_na:  ['0.7562', '0.6326', '0.5377', '0.5033', '0.4051', '0.3650']
cur_acc rrf_wo_na:  ['0.7712', '0.6137', '0.4861', '0.5083', '0.3588', '0.4922']
his_acc rrf_wo_na:  ['0.7712', '0.6618', '0.5474', '0.5135', '0.4094', '0.3657']
cur_acc_w_na:  ['0.6521', '0.4030', '0.3559', '0.3725', '0.2466', '0.2733']
his_acc_w_na:  ['0.6521', '0.5429', '0.4120', '0.4022', '0.3069', '0.2581']
cur_acc des_w_na:  ['0.6124', '0.4059', '0.2991', '0.3198', '0.2116', '0.3803']
his_acc des_w_na:  ['0.6124', '0.4528', '0.3657', '0.3398', '0.2616', '0.2526']
cur_acc rrf_w_na:  ['0.6299', '0.4213', '0.3350', '0.3285', '0.2321', '0.4000']
his_acc rrf_w_na:  ['0.6299', '0.4814', '0.3830', '0.3525', '0.2681', '0.2566']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 132.7681364CurrentTrain: epoch  0, batch     1 | loss: 134.4361578CurrentTrain: epoch  0, batch     2 | loss: 129.6932673CurrentTrain: epoch  0, batch     3 | loss: 106.4683214CurrentTrain: epoch  1, batch     0 | loss: 131.0723488CurrentTrain: epoch  1, batch     1 | loss: 138.1487110CurrentTrain: epoch  1, batch     2 | loss: 117.0195886CurrentTrain: epoch  1, batch     3 | loss: 92.9635617CurrentTrain: epoch  2, batch     0 | loss: 113.5094575CurrentTrain: epoch  2, batch     1 | loss: 117.5141463CurrentTrain: epoch  2, batch     2 | loss: 122.1995190CurrentTrain: epoch  2, batch     3 | loss: 113.1807845CurrentTrain: epoch  3, batch     0 | loss: 122.1167623CurrentTrain: epoch  3, batch     1 | loss: 102.2309793CurrentTrain: epoch  3, batch     2 | loss: 148.1178719CurrentTrain: epoch  3, batch     3 | loss: 77.4907932CurrentTrain: epoch  4, batch     0 | loss: 112.1593977CurrentTrain: epoch  4, batch     1 | loss: 117.1626420CurrentTrain: epoch  4, batch     2 | loss: 137.0066715CurrentTrain: epoch  4, batch     3 | loss: 90.0417533CurrentTrain: epoch  5, batch     0 | loss: 100.1869276CurrentTrain: epoch  5, batch     1 | loss: 135.2954522CurrentTrain: epoch  5, batch     2 | loss: 124.7499290CurrentTrain: epoch  5, batch     3 | loss: 109.3663362CurrentTrain: epoch  6, batch     0 | loss: 98.9935663CurrentTrain: epoch  6, batch     1 | loss: 142.4866380CurrentTrain: epoch  6, batch     2 | loss: 128.1755776CurrentTrain: epoch  6, batch     3 | loss: 72.6156369CurrentTrain: epoch  7, batch     0 | loss: 124.5517491CurrentTrain: epoch  7, batch     1 | loss: 115.7652882CurrentTrain: epoch  7, batch     2 | loss: 106.4843919CurrentTrain: epoch  7, batch     3 | loss: 96.6404238CurrentTrain: epoch  8, batch     0 | loss: 153.5375615CurrentTrain: epoch  8, batch     1 | loss: 123.9830461CurrentTrain: epoch  8, batch     2 | loss: 91.2699542CurrentTrain: epoch  8, batch     3 | loss: 97.9361605CurrentTrain: epoch  9, batch     0 | loss: 100.3574397CurrentTrain: epoch  9, batch     1 | loss: 115.6278735CurrentTrain: epoch  9, batch     2 | loss: 126.1162112CurrentTrain: epoch  9, batch     3 | loss: 85.4619369
MemoryTrain:  epoch  0, batch     0 | loss: 0.9037094MemoryTrain:  epoch  1, batch     0 | loss: 0.8364091MemoryTrain:  epoch  2, batch     0 | loss: 0.6716533MemoryTrain:  epoch  3, batch     0 | loss: 0.6026261MemoryTrain:  epoch  4, batch     0 | loss: 0.5001402MemoryTrain:  epoch  5, batch     0 | loss: 0.4665195MemoryTrain:  epoch  6, batch     0 | loss: 0.3928756MemoryTrain:  epoch  7, batch     0 | loss: 0.3710447MemoryTrain:  epoch  8, batch     0 | loss: 0.3126624MemoryTrain:  epoch  9, batch     0 | loss: 0.2685490

F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.8571428571428571), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 25: np.float64(0.375), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.7835051546391752), 37: np.float64(0.33766233766233766), 38: np.float64(0.5641025641025641), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.39243498817966904
Weighted-average F1 score: 0.2788972814746011
F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.6956521739130435), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5569620253164557), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.74), 36: np.float64(0.0), 37: np.float64(0.4793388429752066), 38: np.float64(0.6521739130434783), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.35406698564593303
Weighted-average F1 score: 0.23784096901569032
F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.6956521739130435), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 25: np.float64(0.5714285714285714), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.7474747474747475), 37: np.float64(0.5), 38: np.float64(0.6222222222222222), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3850267379679144
Weighted-average F1 score: 0.26051599500874867

F1 score per class: {1: np.float64(0.16), 2: np.float64(0.4), 3: np.float64(0.30344827586206896), 5: np.float64(0.8401826484018264), 6: np.float64(0.15126050420168066), 7: np.float64(0.04519774011299435), 8: np.float64(0.22807017543859648), 9: np.float64(0.8135593220338984), 10: np.float64(0.23076923076923078), 11: np.float64(0.1564245810055866), 12: np.float64(0.08917197452229299), 14: np.float64(0.05194805194805195), 15: np.float64(0.32727272727272727), 16: np.float64(0.5866666666666667), 17: np.float64(0.0), 18: np.float64(0.07407407407407407), 19: np.float64(0.5121951219512195), 20: np.float64(0.4810126582278481), 22: np.float64(0.3105590062111801), 24: np.float64(0.0), 25: np.float64(0.375), 26: np.float64(0.6931818181818182), 27: np.float64(0.0), 28: np.float64(0.13513513513513514), 29: np.float64(0.7872340425531915), 30: np.float64(0.8947368421052632), 31: np.float64(0.11764705882352941), 32: np.float64(0.5365853658536586), 33: np.float64(0.4), 34: np.float64(0.354978354978355), 35: np.float64(0.3114754098360656), 36: np.float64(0.029850746268656716), 37: np.float64(0.16883116883116883), 38: np.float64(0.3013698630136986), 39: np.float64(0.1568627450980392), 40: np.float64(0.18867924528301888)}
Micro-average F1 score: 0.3375248180013236
Weighted-average F1 score: 0.32677563194257137
F1 score per class: {1: np.float64(0.16733067729083664), 2: np.float64(0.30434782608695654), 3: np.float64(0.40939597315436244), 5: np.float64(0.5648414985590778), 6: np.float64(0.3741935483870968), 7: np.float64(0.03940886699507389), 8: np.float64(0.38144329896907214), 9: np.float64(0.4854368932038835), 10: np.float64(0.3241106719367589), 11: np.float64(0.14184397163120568), 12: np.float64(0.2247191011235955), 14: np.float64(0.064), 15: np.float64(0.26666666666666666), 16: np.float64(0.5252525252525253), 17: np.float64(0.0), 18: np.float64(0.15873015873015872), 19: np.float64(0.48344370860927155), 20: np.float64(0.5252525252525253), 22: np.float64(0.39), 24: np.float64(0.10256410256410256), 25: np.float64(0.5432098765432098), 26: np.float64(0.6701030927835051), 27: np.float64(0.0), 28: np.float64(0.08196721311475409), 29: np.float64(0.7513812154696132), 30: np.float64(0.6296296296296297), 31: np.float64(0.02702702702702703), 32: np.float64(0.6064981949458483), 33: np.float64(0.375), 34: np.float64(0.19704433497536947), 35: np.float64(0.2781954887218045), 36: np.float64(0.48214285714285715), 37: np.float64(0.14463840399002495), 38: np.float64(0.26785714285714285), 39: np.float64(0.13333333333333333), 40: np.float64(0.22994652406417113)}
Micro-average F1 score: 0.32772565512779034
Weighted-average F1 score: 0.30213861640991135
F1 score per class: {1: np.float64(0.168), 2: np.float64(0.3783783783783784), 3: np.float64(0.44534412955465585), 5: np.float64(0.6736842105263158), 6: np.float64(0.36), 7: np.float64(0.04060913705583756), 8: np.float64(0.3576158940397351), 9: np.float64(0.7246376811594203), 10: np.float64(0.2966101694915254), 11: np.float64(0.15894039735099338), 12: np.float64(0.2230769230769231), 14: np.float64(0.043859649122807015), 15: np.float64(0.2191780821917808), 16: np.float64(0.5376344086021505), 17: np.float64(0.0), 18: np.float64(0.10810810810810811), 19: np.float64(0.512280701754386), 20: np.float64(0.4943820224719101), 22: np.float64(0.37373737373737376), 24: np.float64(0.0), 25: np.float64(0.5714285714285714), 26: np.float64(0.6808510638297872), 27: np.float64(0.0), 28: np.float64(0.09174311926605505), 29: np.float64(0.7513812154696132), 30: np.float64(0.7906976744186046), 31: np.float64(0.05128205128205128), 32: np.float64(0.5862068965517241), 33: np.float64(0.375), 34: np.float64(0.1926605504587156), 35: np.float64(0.275092936802974), 36: np.float64(0.11267605633802817), 37: np.float64(0.1592920353982301), 38: np.float64(0.26666666666666666), 39: np.float64(0.10810810810810811), 40: np.float64(0.2097560975609756)}
Micro-average F1 score: 0.328415205693456
Weighted-average F1 score: 0.30334404118038233

F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.6), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 25: np.float64(0.36923076923076925), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.6785714285714286), 37: np.float64(0.3170731707317073), 38: np.float64(0.4489795918367347), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2876949740034662
Weighted-average F1 score: 0.19839637853065462
F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.47058823529411764), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5238095238095238), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.6548672566371682), 36: np.float64(0.0), 37: np.float64(0.42028985507246375), 38: np.float64(0.4918032786885246), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.24315443592552027
Weighted-average F1 score: 0.1652667264225302
F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.47058823529411764), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 25: np.float64(0.5432098765432098), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.6379310344827587), 37: np.float64(0.42857142857142855), 38: np.float64(0.4666666666666667), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.26277372262773724
Weighted-average F1 score: 0.1799223332161656

F1 score per class: {1: np.float64(0.08845208845208845), 2: np.float64(0.20512820512820512), 3: np.float64(0.22448979591836735), 5: np.float64(0.6996197718631179), 6: np.float64(0.12), 7: np.float64(0.022988505747126436), 8: np.float64(0.19402985074626866), 9: np.float64(0.7619047619047619), 10: np.float64(0.1935483870967742), 11: np.float64(0.10687022900763359), 12: np.float64(0.058333333333333334), 14: np.float64(0.04040404040404041), 15: np.float64(0.225), 16: np.float64(0.36065573770491804), 17: np.float64(0.0), 18: np.float64(0.056338028169014086), 19: np.float64(0.4684014869888476), 20: np.float64(0.3140495867768595), 22: np.float64(0.25125628140703515), 24: np.float64(0.0), 25: np.float64(0.36923076923076925), 26: np.float64(0.6069651741293532), 27: np.float64(0.0), 28: np.float64(0.07092198581560284), 29: np.float64(0.6820276497695853), 30: np.float64(0.85), 31: np.float64(0.07407407407407407), 32: np.float64(0.41847826086956524), 33: np.float64(0.3333333333333333), 34: np.float64(0.21409921671018275), 35: np.float64(0.19689119170984457), 36: np.float64(0.028985507246376812), 37: np.float64(0.12206572769953052), 38: np.float64(0.15942028985507245), 39: np.float64(0.08333333333333333), 40: np.float64(0.14492753623188406)}
Micro-average F1 score: 0.2431659249841068
Weighted-average F1 score: 0.22552523733505572
F1 score per class: {1: np.float64(0.08955223880597014), 2: np.float64(0.1794871794871795), 3: np.float64(0.2675438596491228), 5: np.float64(0.3904382470119522), 6: np.float64(0.2648401826484018), 7: np.float64(0.020512820512820513), 8: np.float64(0.25874125874125875), 9: np.float64(0.373134328358209), 10: np.float64(0.21188630490956073), 11: np.float64(0.11904761904761904), 12: np.float64(0.12096774193548387), 14: np.float64(0.05211726384364821), 15: np.float64(0.1568627450980392), 16: np.float64(0.2988505747126437), 17: np.float64(0.0), 18: np.float64(0.09569377990430622), 19: np.float64(0.4319526627218935), 20: np.float64(0.28888888888888886), 22: np.float64(0.2932330827067669), 24: np.float64(0.08333333333333333), 25: np.float64(0.4835164835164835), 26: np.float64(0.5627705627705628), 27: np.float64(0.0), 28: np.float64(0.0411522633744856), 29: np.float64(0.6355140186915887), 30: np.float64(0.576271186440678), 31: np.float64(0.012578616352201259), 32: np.float64(0.4666666666666667), 33: np.float64(0.2857142857142857), 34: np.float64(0.12307692307692308), 35: np.float64(0.18316831683168316), 36: np.float64(0.33540372670807456), 37: np.float64(0.09602649006622517), 38: np.float64(0.15384615384615385), 39: np.float64(0.07142857142857142), 40: np.float64(0.15439856373429084)}
Micro-average F1 score: 0.21846021134354107
Weighted-average F1 score: 0.20152323823855633
F1 score per class: {1: np.float64(0.09071274298056156), 2: np.float64(0.2413793103448276), 3: np.float64(0.30985915492957744), 5: np.float64(0.47880299251870323), 6: np.float64(0.2583732057416268), 7: np.float64(0.02072538860103627), 8: np.float64(0.27979274611398963), 9: np.float64(0.6410256410256411), 10: np.float64(0.21021021021021022), 11: np.float64(0.12307692307692308), 12: np.float64(0.12184873949579832), 14: np.float64(0.03460207612456748), 15: np.float64(0.13559322033898305), 16: np.float64(0.30303030303030304), 17: np.float64(0.0), 18: np.float64(0.06299212598425197), 19: np.float64(0.45625), 20: np.float64(0.2732919254658385), 22: np.float64(0.2857142857142857), 24: np.float64(0.0), 25: np.float64(0.5116279069767442), 26: np.float64(0.5818181818181818), 27: np.float64(0.0), 28: np.float64(0.043668122270742356), 29: np.float64(0.6384976525821596), 30: np.float64(0.7555555555555555), 31: np.float64(0.02247191011235955), 32: np.float64(0.4509283819628647), 33: np.float64(0.2857142857142857), 34: np.float64(0.12138728323699421), 35: np.float64(0.1712962962962963), 36: np.float64(0.1038961038961039), 37: np.float64(0.10131332082551595), 38: np.float64(0.14814814814814814), 39: np.float64(0.0547945205479452), 40: np.float64(0.14333333333333334)}
Micro-average F1 score: 0.22120893253829066
Weighted-average F1 score: 0.20218476128747181
cur_acc_wo_na:  ['0.7676', '0.5278', '0.4941', '0.5159', '0.3609', '0.3219', '0.3924']
his_acc_wo_na:  ['0.7676', '0.6772', '0.5585', '0.5269', '0.4409', '0.3423', '0.3375']
cur_acc des_wo_na:  ['0.7562', '0.5987', '0.4502', '0.5000', '0.3306', '0.4765', '0.3541']
his_acc des_wo_na:  ['0.7562', '0.6326', '0.5377', '0.5033', '0.4051', '0.3650', '0.3277']
cur_acc rrf_wo_na:  ['0.7712', '0.6137', '0.4861', '0.5083', '0.3588', '0.4922', '0.3850']
his_acc rrf_wo_na:  ['0.7712', '0.6618', '0.5474', '0.5135', '0.4094', '0.3657', '0.3284']
cur_acc_w_na:  ['0.6521', '0.4030', '0.3559', '0.3725', '0.2466', '0.2733', '0.2877']
his_acc_w_na:  ['0.6521', '0.5429', '0.4120', '0.4022', '0.3069', '0.2581', '0.2432']
cur_acc des_w_na:  ['0.6124', '0.4059', '0.2991', '0.3198', '0.2116', '0.3803', '0.2432']
his_acc des_w_na:  ['0.6124', '0.4528', '0.3657', '0.3398', '0.2616', '0.2526', '0.2185']
cur_acc rrf_w_na:  ['0.6299', '0.4213', '0.3350', '0.3285', '0.2321', '0.4000', '0.2628']
his_acc rrf_w_na:  ['0.6299', '0.4814', '0.3830', '0.3525', '0.2681', '0.2566', '0.2212']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 138.9906325CurrentTrain: epoch  0, batch     1 | loss: 188.4488041CurrentTrain: epoch  0, batch     2 | loss: 120.7771499CurrentTrain: epoch  0, batch     3 | loss: 107.2978554CurrentTrain: epoch  1, batch     0 | loss: 134.7144139CurrentTrain: epoch  1, batch     1 | loss: 126.2487310CurrentTrain: epoch  1, batch     2 | loss: 121.2804403CurrentTrain: epoch  1, batch     3 | loss: 103.2329612CurrentTrain: epoch  2, batch     0 | loss: 147.3427291CurrentTrain: epoch  2, batch     1 | loss: 118.6980608CurrentTrain: epoch  2, batch     2 | loss: 122.9570437CurrentTrain: epoch  2, batch     3 | loss: 114.5834115CurrentTrain: epoch  3, batch     0 | loss: 149.7501120CurrentTrain: epoch  3, batch     1 | loss: 130.7004656CurrentTrain: epoch  3, batch     2 | loss: 112.5424955CurrentTrain: epoch  3, batch     3 | loss: 108.0741742CurrentTrain: epoch  4, batch     0 | loss: 126.3420355CurrentTrain: epoch  4, batch     1 | loss: 129.2771504CurrentTrain: epoch  4, batch     2 | loss: 163.2696116CurrentTrain: epoch  4, batch     3 | loss: 97.1140449CurrentTrain: epoch  5, batch     0 | loss: 115.5515250CurrentTrain: epoch  5, batch     1 | loss: 122.3834224CurrentTrain: epoch  5, batch     2 | loss: 131.7281051CurrentTrain: epoch  5, batch     3 | loss: 103.3371741CurrentTrain: epoch  6, batch     0 | loss: 149.3012503CurrentTrain: epoch  6, batch     1 | loss: 112.5180260CurrentTrain: epoch  6, batch     2 | loss: 111.0544082CurrentTrain: epoch  6, batch     3 | loss: 102.9522752CurrentTrain: epoch  7, batch     0 | loss: 126.9385197CurrentTrain: epoch  7, batch     1 | loss: 110.3066540CurrentTrain: epoch  7, batch     2 | loss: 106.9079292CurrentTrain: epoch  7, batch     3 | loss: 116.7172022CurrentTrain: epoch  8, batch     0 | loss: 144.5515221CurrentTrain: epoch  8, batch     1 | loss: 119.4514193CurrentTrain: epoch  8, batch     2 | loss: 118.2208312CurrentTrain: epoch  8, batch     3 | loss: 87.1273494CurrentTrain: epoch  9, batch     0 | loss: 108.3855862CurrentTrain: epoch  9, batch     1 | loss: 111.4572635CurrentTrain: epoch  9, batch     2 | loss: 141.3573899CurrentTrain: epoch  9, batch     3 | loss: 106.3986025
MemoryTrain:  epoch  0, batch     0 | loss: 0.9402023MemoryTrain:  epoch  1, batch     0 | loss: 0.8507741MemoryTrain:  epoch  2, batch     0 | loss: 0.6542253MemoryTrain:  epoch  3, batch     0 | loss: 0.4903228MemoryTrain:  epoch  4, batch     0 | loss: 0.4570689MemoryTrain:  epoch  5, batch     0 | loss: 0.3892360MemoryTrain:  epoch  6, batch     0 | loss: 0.3654893MemoryTrain:  epoch  7, batch     0 | loss: 0.3830176MemoryTrain:  epoch  8, batch     0 | loss: 0.2840240MemoryTrain:  epoch  9, batch     0 | loss: 0.2589195

F1 score per class: {0: np.float64(0.9066666666666666), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8950276243093923), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.21052631578947367), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.35), 23: np.float64(0.8222222222222222), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.6598360655737705
Weighted-average F1 score: 0.5537443838768742
F1 score per class: {0: np.float64(0.7578947368421053), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7853403141361257), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.14285714285714285), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.42105263157894735), 22: np.float64(0.0), 23: np.float64(0.691358024691358), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.45973645680819913
Weighted-average F1 score: 0.3480844899989258
F1 score per class: {0: np.float64(0.8235294117647058), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8602150537634409), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.14814814814814814), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.36363636363636365), 23: np.float64(0.6746987951807228), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5097402597402597
Weighted-average F1 score: 0.3883424116196965

F1 score per class: {0: np.float64(0.4563758389261745), 1: np.float64(0.14583333333333334), 2: np.float64(0.35714285714285715), 3: np.float64(0.37142857142857144), 4: np.float64(0.8901098901098901), 5: np.float64(0.8251121076233184), 6: np.float64(0.176), 7: np.float64(0.047337278106508875), 8: np.float64(0.2222222222222222), 9: np.float64(0.8679245283018868), 10: np.float64(0.18181818181818182), 11: np.float64(0.14193548387096774), 12: np.float64(0.0), 13: np.float64(0.026490066225165563), 14: np.float64(0.028985507246376812), 15: np.float64(0.3783783783783784), 16: np.float64(0.5846153846153846), 17: np.float64(0.0), 18: np.float64(0.07407407407407407), 19: np.float64(0.5023696682464455), 20: np.float64(0.5060240963855421), 21: np.float64(0.09395973154362416), 22: np.float64(0.01834862385321101), 23: np.float64(0.7184466019417476), 24: np.float64(0.0), 25: np.float64(0.4), 26: np.float64(0.6931818181818182), 27: np.float64(0.0), 28: np.float64(0.125), 29: np.float64(0.7593582887700535), 30: np.float64(0.918918918918919), 31: np.float64(0.0), 32: np.float64(0.5723684210526315), 33: np.float64(0.35294117647058826), 34: np.float64(0.48951048951048953), 35: np.float64(0.27672955974842767), 36: np.float64(0.029850746268656716), 37: np.float64(0.3308270676691729), 38: np.float64(0.3548387096774194), 39: np.float64(0.11764705882352941), 40: np.float64(0.25680933852140075)}
Micro-average F1 score: 0.3731765730459395
Weighted-average F1 score: 0.3710340846349724
F1 score per class: {0: np.float64(0.23841059602649006), 1: np.float64(0.18181818181818182), 2: np.float64(0.1891891891891892), 3: np.float64(0.39762611275964393), 4: np.float64(0.7653061224489796), 5: np.float64(0.6182965299684543), 6: np.float64(0.32098765432098764), 7: np.float64(0.038834951456310676), 8: np.float64(0.37362637362637363), 9: np.float64(0.5681818181818182), 10: np.float64(0.24644549763033174), 11: np.float64(0.14492753623188406), 12: np.float64(0.13333333333333333), 13: np.float64(0.018867924528301886), 14: np.float64(0.045454545454545456), 15: np.float64(0.4666666666666667), 16: np.float64(0.5783132530120482), 17: np.float64(0.0), 18: np.float64(0.1527777777777778), 19: np.float64(0.5161290322580645), 20: np.float64(0.5154639175257731), 21: np.float64(0.11469534050179211), 22: np.float64(0.16666666666666666), 23: np.float64(0.5894736842105263), 24: np.float64(0.0), 25: np.float64(0.575), 26: np.float64(0.6310679611650486), 27: np.float64(0.0), 28: np.float64(0.17391304347826086), 29: np.float64(0.7513227513227513), 30: np.float64(0.7083333333333334), 31: np.float64(0.08333333333333333), 32: np.float64(0.5902777777777778), 33: np.float64(0.3), 34: np.float64(0.25076452599388377), 35: np.float64(0.2867647058823529), 36: np.float64(0.40816326530612246), 37: np.float64(0.16901408450704225), 38: np.float64(0.2608695652173913), 39: np.float64(0.10526315789473684), 40: np.float64(0.31545741324921134)}
Micro-average F1 score: 0.334860983806905
Weighted-average F1 score: 0.31086885761652094
F1 score per class: {0: np.float64(0.3017241379310345), 1: np.float64(0.1794871794871795), 2: np.float64(0.2916666666666667), 3: np.float64(0.44881889763779526), 4: np.float64(0.8556149732620321), 5: np.float64(0.7401574803149606), 6: np.float64(0.3333333333333333), 7: np.float64(0.043243243243243246), 8: np.float64(0.34177215189873417), 9: np.float64(0.78125), 10: np.float64(0.25365853658536586), 11: np.float64(0.15286624203821655), 12: np.float64(0.11483253588516747), 13: np.float64(0.017467248908296942), 14: np.float64(0.032), 15: np.float64(0.3888888888888889), 16: np.float64(0.5853658536585366), 17: np.float64(0.0), 18: np.float64(0.06896551724137931), 19: np.float64(0.5541125541125541), 20: np.float64(0.4888888888888889), 21: np.float64(0.08955223880597014), 22: np.float64(0.1111111111111111), 23: np.float64(0.5714285714285714), 24: np.float64(0.0), 25: np.float64(0.5333333333333333), 26: np.float64(0.63), 27: np.float64(0.0), 28: np.float64(0.17391304347826086), 29: np.float64(0.745945945945946), 30: np.float64(0.85), 31: np.float64(0.1111111111111111), 32: np.float64(0.5403726708074534), 33: np.float64(0.3), 34: np.float64(0.26058631921824105), 35: np.float64(0.308411214953271), 36: np.float64(0.1111111111111111), 37: np.float64(0.1991701244813278), 38: np.float64(0.3191489361702128), 39: np.float64(0.13636363636363635), 40: np.float64(0.32051282051282054)}
Micro-average F1 score: 0.34488531726100785
Weighted-average F1 score: 0.3217461119590908

F1 score per class: {0: np.float64(0.8395061728395061), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8571428571428571), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.11764705882352941), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.3111111111111111), 23: np.float64(0.7326732673267327), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5119236883942766
Weighted-average F1 score: 0.39255663224384846
F1 score per class: {0: np.float64(0.6666666666666666), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7425742574257426), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.07692307692307693), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.3137254901960784), 22: np.float64(0.0), 23: np.float64(0.5773195876288659), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3267429760665973
Weighted-average F1 score: 0.23998890876047035
F1 score per class: {0: np.float64(0.7368421052631579), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8163265306122449), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.07547169811320754), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.2608695652173913), 22: np.float64(0.0), 23: np.float64(0.56), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3617511520737327
Weighted-average F1 score: 0.2628393117773665

F1 score per class: {0: np.float64(0.3022222222222222), 1: np.float64(0.07954545454545454), 2: np.float64(0.19607843137254902), 3: np.float64(0.2639593908629442), 4: np.float64(0.8307692307692308), 5: np.float64(0.696969696969697), 6: np.float64(0.1375), 7: np.float64(0.024615384615384615), 8: np.float64(0.2), 9: np.float64(0.8214285714285714), 10: np.float64(0.15384615384615385), 11: np.float64(0.10328638497652583), 12: np.float64(0.0), 13: np.float64(0.012861736334405145), 14: np.float64(0.02531645569620253), 15: np.float64(0.2692307692307692), 16: np.float64(0.3917525773195876), 17: np.float64(0.0), 18: np.float64(0.04819277108433735), 19: np.float64(0.4690265486725664), 20: np.float64(0.34146341463414637), 21: np.float64(0.06796116504854369), 22: np.float64(0.01694915254237288), 23: np.float64(0.5873015873015873), 24: np.float64(0.0), 25: np.float64(0.3939393939393939), 26: np.float64(0.61), 27: np.float64(0.0), 28: np.float64(0.06451612903225806), 29: np.float64(0.6543778801843319), 30: np.float64(0.85), 31: np.float64(0.0), 32: np.float64(0.4223300970873786), 33: np.float64(0.3), 34: np.float64(0.3181818181818182), 35: np.float64(0.1864406779661017), 36: np.float64(0.028985507246376812), 37: np.float64(0.2603550295857988), 38: np.float64(0.2222222222222222), 39: np.float64(0.06451612903225806), 40: np.float64(0.21782178217821782)}
Micro-average F1 score: 0.2753856041131105
Weighted-average F1 score: 0.2576840653410486
F1 score per class: {0: np.float64(0.15126050420168066), 1: np.float64(0.09713024282560706), 2: np.float64(0.12612612612612611), 3: np.float64(0.25523809523809526), 4: np.float64(0.6410256410256411), 5: np.float64(0.4444444444444444), 6: np.float64(0.23853211009174313), 7: np.float64(0.019559902200488997), 8: np.float64(0.2585551330798479), 9: np.float64(0.46296296296296297), 10: np.float64(0.1625), 11: np.float64(0.1282051282051282), 12: np.float64(0.08069164265129683), 13: np.float64(0.009111617312072893), 14: np.float64(0.038461538461538464), 15: np.float64(0.3111111111111111), 16: np.float64(0.34532374100719426), 17: np.float64(0.0), 18: np.float64(0.09482758620689655), 19: np.float64(0.4555160142348754), 20: np.float64(0.2824858757062147), 21: np.float64(0.07960199004975124), 22: np.float64(0.13714285714285715), 23: np.float64(0.45528455284552843), 24: np.float64(0.0), 25: np.float64(0.5476190476190477), 26: np.float64(0.5327868852459017), 27: np.float64(0.0), 28: np.float64(0.08791208791208792), 29: np.float64(0.6367713004484304), 30: np.float64(0.6415094339622641), 31: np.float64(0.0392156862745098), 32: np.float64(0.4381443298969072), 33: np.float64(0.24), 34: np.float64(0.14882032667876588), 35: np.float64(0.18932038834951456), 36: np.float64(0.2962962962962963), 37: np.float64(0.10810810810810811), 38: np.float64(0.15384615384615385), 39: np.float64(0.057971014492753624), 40: np.float64(0.24813895781637718)}
Micro-average F1 score: 0.22661015196939935
Weighted-average F1 score: 0.20798011811251294
F1 score per class: {0: np.float64(0.19021739130434784), 1: np.float64(0.0958904109589041), 2: np.float64(0.18181818181818182), 3: np.float64(0.3114754098360656), 4: np.float64(0.7729468599033816), 5: np.float64(0.5356125356125356), 6: np.float64(0.24644549763033174), 7: np.float64(0.02099737532808399), 8: np.float64(0.2727272727272727), 9: np.float64(0.7246376811594203), 10: np.float64(0.17687074829931973), 11: np.float64(0.1188118811881188), 12: np.float64(0.07058823529411765), 13: np.float64(0.008528784648187633), 14: np.float64(0.02702702702702703), 15: np.float64(0.2692307692307692), 16: np.float64(0.3404255319148936), 17: np.float64(0.0), 18: np.float64(0.041666666666666664), 19: np.float64(0.4980544747081712), 20: np.float64(0.26506024096385544), 21: np.float64(0.061696658097686374), 22: np.float64(0.09395973154362416), 23: np.float64(0.4375), 24: np.float64(0.0), 25: np.float64(0.4819277108433735), 26: np.float64(0.5502183406113537), 27: np.float64(0.0), 28: np.float64(0.08247422680412371), 29: np.float64(0.6388888888888888), 30: np.float64(0.7727272727272727), 31: np.float64(0.0625), 32: np.float64(0.4046511627906977), 33: np.float64(0.21428571428571427), 34: np.float64(0.15444015444015444), 35: np.float64(0.18333333333333332), 36: np.float64(0.10126582278481013), 37: np.float64(0.12151898734177215), 38: np.float64(0.18072289156626506), 39: np.float64(0.075), 40: np.float64(0.24752475247524752)}
Micro-average F1 score: 0.23449060899260102
Weighted-average F1 score: 0.2132150144274031
cur_acc_wo_na:  ['0.7676', '0.5278', '0.4941', '0.5159', '0.3609', '0.3219', '0.3924', '0.6598']
his_acc_wo_na:  ['0.7676', '0.6772', '0.5585', '0.5269', '0.4409', '0.3423', '0.3375', '0.3732']
cur_acc des_wo_na:  ['0.7562', '0.5987', '0.4502', '0.5000', '0.3306', '0.4765', '0.3541', '0.4597']
his_acc des_wo_na:  ['0.7562', '0.6326', '0.5377', '0.5033', '0.4051', '0.3650', '0.3277', '0.3349']
cur_acc rrf_wo_na:  ['0.7712', '0.6137', '0.4861', '0.5083', '0.3588', '0.4922', '0.3850', '0.5097']
his_acc rrf_wo_na:  ['0.7712', '0.6618', '0.5474', '0.5135', '0.4094', '0.3657', '0.3284', '0.3449']
cur_acc_w_na:  ['0.6521', '0.4030', '0.3559', '0.3725', '0.2466', '0.2733', '0.2877', '0.5119']
his_acc_w_na:  ['0.6521', '0.5429', '0.4120', '0.4022', '0.3069', '0.2581', '0.2432', '0.2754']
cur_acc des_w_na:  ['0.6124', '0.4059', '0.2991', '0.3198', '0.2116', '0.3803', '0.2432', '0.3267']
his_acc des_w_na:  ['0.6124', '0.4528', '0.3657', '0.3398', '0.2616', '0.2526', '0.2185', '0.2266']
cur_acc rrf_w_na:  ['0.6299', '0.4213', '0.3350', '0.3285', '0.2321', '0.4000', '0.2628', '0.3618']
his_acc rrf_w_na:  ['0.6299', '0.4814', '0.3830', '0.3525', '0.2681', '0.2566', '0.2212', '0.2345']
--------Round  2
seed:  300
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 2 3 1 5 6 0 4]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 117.8666584CurrentTrain: epoch  0, batch     1 | loss: 118.1099189CurrentTrain: epoch  0, batch     2 | loss: 145.7774088CurrentTrain: epoch  0, batch     3 | loss: 145.1485899CurrentTrain: epoch  0, batch     4 | loss: 134.8628652CurrentTrain: epoch  0, batch     5 | loss: 163.5084118CurrentTrain: epoch  0, batch     6 | loss: 140.1180829CurrentTrain: epoch  0, batch     7 | loss: 153.8522194CurrentTrain: epoch  0, batch     8 | loss: 126.3944638CurrentTrain: epoch  0, batch     9 | loss: 156.9858382CurrentTrain: epoch  0, batch    10 | loss: 111.5161389CurrentTrain: epoch  0, batch    11 | loss: 123.7409322CurrentTrain: epoch  0, batch    12 | loss: 128.8893007CurrentTrain: epoch  0, batch    13 | loss: 153.3746808CurrentTrain: epoch  0, batch    14 | loss: 182.0240025CurrentTrain: epoch  0, batch    15 | loss: 164.0872412CurrentTrain: epoch  0, batch    16 | loss: 162.5246196CurrentTrain: epoch  0, batch    17 | loss: 139.1872246CurrentTrain: epoch  0, batch    18 | loss: 187.2566664CurrentTrain: epoch  0, batch    19 | loss: 146.3490989CurrentTrain: epoch  0, batch    20 | loss: 108.8212678CurrentTrain: epoch  0, batch    21 | loss: 131.6952546CurrentTrain: epoch  0, batch    22 | loss: 135.9142442CurrentTrain: epoch  0, batch    23 | loss: 158.4495213CurrentTrain: epoch  0, batch    24 | loss: 159.7123479CurrentTrain: epoch  0, batch    25 | loss: 151.4187436CurrentTrain: epoch  0, batch    26 | loss: 120.2236846CurrentTrain: epoch  0, batch    27 | loss: 225.0048492CurrentTrain: epoch  0, batch    28 | loss: 143.0123371CurrentTrain: epoch  0, batch    29 | loss: 142.5302243CurrentTrain: epoch  0, batch    30 | loss: 136.9136737CurrentTrain: epoch  0, batch    31 | loss: 139.0020527CurrentTrain: epoch  0, batch    32 | loss: 162.3698698CurrentTrain: epoch  0, batch    33 | loss: 122.3075146CurrentTrain: epoch  0, batch    34 | loss: 145.2153390CurrentTrain: epoch  0, batch    35 | loss: 137.9433911CurrentTrain: epoch  0, batch    36 | loss: 159.7567259CurrentTrain: epoch  0, batch    37 | loss: 138.5661570CurrentTrain: epoch  0, batch    38 | loss: 138.1886261CurrentTrain: epoch  0, batch    39 | loss: 159.7854904CurrentTrain: epoch  0, batch    40 | loss: 123.0007191CurrentTrain: epoch  0, batch    41 | loss: 146.5139031CurrentTrain: epoch  0, batch    42 | loss: 186.7512253CurrentTrain: epoch  0, batch    43 | loss: 154.8573178CurrentTrain: epoch  0, batch    44 | loss: 138.9283334CurrentTrain: epoch  0, batch    45 | loss: 133.1269819CurrentTrain: epoch  0, batch    46 | loss: 134.3476685CurrentTrain: epoch  0, batch    47 | loss: 139.9431396CurrentTrain: epoch  0, batch    48 | loss: 137.7802391CurrentTrain: epoch  0, batch    49 | loss: 139.3316200CurrentTrain: epoch  0, batch    50 | loss: 132.5333446CurrentTrain: epoch  0, batch    51 | loss: 157.8745008CurrentTrain: epoch  0, batch    52 | loss: 114.2738690CurrentTrain: epoch  0, batch    53 | loss: 151.4241916CurrentTrain: epoch  0, batch    54 | loss: 130.7857835CurrentTrain: epoch  0, batch    55 | loss: 169.2784285CurrentTrain: epoch  0, batch    56 | loss: 180.2347273CurrentTrain: epoch  0, batch    57 | loss: 110.0550950CurrentTrain: epoch  0, batch    58 | loss: 156.3055991CurrentTrain: epoch  0, batch    59 | loss: 110.0932654CurrentTrain: epoch  0, batch    60 | loss: 155.9392047CurrentTrain: epoch  0, batch    61 | loss: 140.4477213CurrentTrain: epoch  0, batch    62 | loss: 148.7150291CurrentTrain: epoch  0, batch    63 | loss: 102.0634652CurrentTrain: epoch  0, batch    64 | loss: 157.6674327CurrentTrain: epoch  0, batch    65 | loss: 130.0432959CurrentTrain: epoch  0, batch    66 | loss: 140.2256429CurrentTrain: epoch  0, batch    67 | loss: 178.5279222CurrentTrain: epoch  0, batch    68 | loss: 143.5706696CurrentTrain: epoch  0, batch    69 | loss: 127.6428366CurrentTrain: epoch  0, batch    70 | loss: 111.0485682CurrentTrain: epoch  0, batch    71 | loss: 120.5633539CurrentTrain: epoch  0, batch    72 | loss: 159.9432239CurrentTrain: epoch  0, batch    73 | loss: 139.6783698CurrentTrain: epoch  0, batch    74 | loss: 106.5545446CurrentTrain: epoch  0, batch    75 | loss: 135.0807258CurrentTrain: epoch  0, batch    76 | loss: 111.7341109CurrentTrain: epoch  0, batch    77 | loss: 145.8443099CurrentTrain: epoch  0, batch    78 | loss: 118.8656658CurrentTrain: epoch  0, batch    79 | loss: 157.2205558CurrentTrain: epoch  0, batch    80 | loss: 132.4509611CurrentTrain: epoch  0, batch    81 | loss: 134.7776737CurrentTrain: epoch  0, batch    82 | loss: 121.4242683CurrentTrain: epoch  0, batch    83 | loss: 125.7798243CurrentTrain: epoch  0, batch    84 | loss: 158.0491041CurrentTrain: epoch  0, batch    85 | loss: 137.3923722CurrentTrain: epoch  0, batch    86 | loss: 129.2598801CurrentTrain: epoch  0, batch    87 | loss: 147.3250072CurrentTrain: epoch  0, batch    88 | loss: 132.2824449CurrentTrain: epoch  0, batch    89 | loss: 150.1653345CurrentTrain: epoch  0, batch    90 | loss: 129.7622193CurrentTrain: epoch  0, batch    91 | loss: 115.9786137CurrentTrain: epoch  0, batch    92 | loss: 113.5987981CurrentTrain: epoch  0, batch    93 | loss: 140.8835146CurrentTrain: epoch  0, batch    94 | loss: 131.2652159CurrentTrain: epoch  0, batch    95 | loss: 150.8523756CurrentTrain: epoch  1, batch     0 | loss: 125.7654513CurrentTrain: epoch  1, batch     1 | loss: 120.7581198CurrentTrain: epoch  1, batch     2 | loss: 153.7982968CurrentTrain: epoch  1, batch     3 | loss: 125.0277520CurrentTrain: epoch  1, batch     4 | loss: 122.7434012CurrentTrain: epoch  1, batch     5 | loss: 143.4636635CurrentTrain: epoch  1, batch     6 | loss: 140.9297441CurrentTrain: epoch  1, batch     7 | loss: 119.3007358CurrentTrain: epoch  1, batch     8 | loss: 122.9222723CurrentTrain: epoch  1, batch     9 | loss: 143.8569211CurrentTrain: epoch  1, batch    10 | loss: 137.1192623CurrentTrain: epoch  1, batch    11 | loss: 156.1043375CurrentTrain: epoch  1, batch    12 | loss: 153.8766986CurrentTrain: epoch  1, batch    13 | loss: 149.2689825CurrentTrain: epoch  1, batch    14 | loss: 132.6081426CurrentTrain: epoch  1, batch    15 | loss: 183.7754854CurrentTrain: epoch  1, batch    16 | loss: 132.6171562CurrentTrain: epoch  1, batch    17 | loss: 141.6022680CurrentTrain: epoch  1, batch    18 | loss: 151.8714460CurrentTrain: epoch  1, batch    19 | loss: 129.9376566CurrentTrain: epoch  1, batch    20 | loss: 224.8365861CurrentTrain: epoch  1, batch    21 | loss: 155.8600401CurrentTrain: epoch  1, batch    22 | loss: 139.1774063CurrentTrain: epoch  1, batch    23 | loss: 143.6715227CurrentTrain: epoch  1, batch    24 | loss: 147.8333855CurrentTrain: epoch  1, batch    25 | loss: 134.4843968CurrentTrain: epoch  1, batch    26 | loss: 127.9650869CurrentTrain: epoch  1, batch    27 | loss: 118.3428963CurrentTrain: epoch  1, batch    28 | loss: 145.1369831CurrentTrain: epoch  1, batch    29 | loss: 118.5364277CurrentTrain: epoch  1, batch    30 | loss: 125.2421056CurrentTrain: epoch  1, batch    31 | loss: 135.7463939CurrentTrain: epoch  1, batch    32 | loss: 104.3739662CurrentTrain: epoch  1, batch    33 | loss: 125.4221328CurrentTrain: epoch  1, batch    34 | loss: 127.7214413CurrentTrain: epoch  1, batch    35 | loss: 142.9451830CurrentTrain: epoch  1, batch    36 | loss: 124.9891100CurrentTrain: epoch  1, batch    37 | loss: 129.1874661CurrentTrain: epoch  1, batch    38 | loss: 106.9085387CurrentTrain: epoch  1, batch    39 | loss: 111.5008173CurrentTrain: epoch  1, batch    40 | loss: 114.9870339CurrentTrain: epoch  1, batch    41 | loss: 147.0162404CurrentTrain: epoch  1, batch    42 | loss: 114.1485418CurrentTrain: epoch  1, batch    43 | loss: 155.9510558CurrentTrain: epoch  1, batch    44 | loss: 115.9149805CurrentTrain: epoch  1, batch    45 | loss: 147.8806906CurrentTrain: epoch  1, batch    46 | loss: 110.0743005CurrentTrain: epoch  1, batch    47 | loss: 113.1376453CurrentTrain: epoch  1, batch    48 | loss: 139.9169484CurrentTrain: epoch  1, batch    49 | loss: 138.9333595CurrentTrain: epoch  1, batch    50 | loss: 103.9526473CurrentTrain: epoch  1, batch    51 | loss: 117.4188052CurrentTrain: epoch  1, batch    52 | loss: 149.8484664CurrentTrain: epoch  1, batch    53 | loss: 149.7110683CurrentTrain: epoch  1, batch    54 | loss: 129.4328507CurrentTrain: epoch  1, batch    55 | loss: 174.5731771CurrentTrain: epoch  1, batch    56 | loss: 138.9679095CurrentTrain: epoch  1, batch    57 | loss: 159.1617860CurrentTrain: epoch  1, batch    58 | loss: 209.5487234CurrentTrain: epoch  1, batch    59 | loss: 129.0911557CurrentTrain: epoch  1, batch    60 | loss: 151.0203915CurrentTrain: epoch  1, batch    61 | loss: 110.7319383CurrentTrain: epoch  1, batch    62 | loss: 123.2685591CurrentTrain: epoch  1, batch    63 | loss: 156.5041856CurrentTrain: epoch  1, batch    64 | loss: 140.1340676CurrentTrain: epoch  1, batch    65 | loss: 140.2084875CurrentTrain: epoch  1, batch    66 | loss: 109.5870091CurrentTrain: epoch  1, batch    67 | loss: 116.8512897CurrentTrain: epoch  1, batch    68 | loss: 169.4410089CurrentTrain: epoch  1, batch    69 | loss: 139.0837225CurrentTrain: epoch  1, batch    70 | loss: 135.1382750CurrentTrain: epoch  1, batch    71 | loss: 132.3472576CurrentTrain: epoch  1, batch    72 | loss: 128.3719899CurrentTrain: epoch  1, batch    73 | loss: 121.5066321CurrentTrain: epoch  1, batch    74 | loss: 147.5606712CurrentTrain: epoch  1, batch    75 | loss: 127.0271294CurrentTrain: epoch  1, batch    76 | loss: 154.7900733CurrentTrain: epoch  1, batch    77 | loss: 134.9844222CurrentTrain: epoch  1, batch    78 | loss: 118.8237599CurrentTrain: epoch  1, batch    79 | loss: 132.3780533CurrentTrain: epoch  1, batch    80 | loss: 110.1574269CurrentTrain: epoch  1, batch    81 | loss: 151.6227106CurrentTrain: epoch  1, batch    82 | loss: 101.1839233CurrentTrain: epoch  1, batch    83 | loss: 143.2543350CurrentTrain: epoch  1, batch    84 | loss: 137.2818694CurrentTrain: epoch  1, batch    85 | loss: 177.3428177CurrentTrain: epoch  1, batch    86 | loss: 108.5838772CurrentTrain: epoch  1, batch    87 | loss: 93.3586742CurrentTrain: epoch  1, batch    88 | loss: 155.0941449CurrentTrain: epoch  1, batch    89 | loss: 180.0099247CurrentTrain: epoch  1, batch    90 | loss: 128.1759111CurrentTrain: epoch  1, batch    91 | loss: 133.0367804CurrentTrain: epoch  1, batch    92 | loss: 122.8277468CurrentTrain: epoch  1, batch    93 | loss: 117.3639929CurrentTrain: epoch  1, batch    94 | loss: 107.1990807CurrentTrain: epoch  1, batch    95 | loss: 108.2756250CurrentTrain: epoch  2, batch     0 | loss: 125.1212742CurrentTrain: epoch  2, batch     1 | loss: 134.0576715CurrentTrain: epoch  2, batch     2 | loss: 106.6252007CurrentTrain: epoch  2, batch     3 | loss: 103.2843055CurrentTrain: epoch  2, batch     4 | loss: 167.7278860CurrentTrain: epoch  2, batch     5 | loss: 109.0826977CurrentTrain: epoch  2, batch     6 | loss: 96.8258351CurrentTrain: epoch  2, batch     7 | loss: 141.0064853CurrentTrain: epoch  2, batch     8 | loss: 131.1401516CurrentTrain: epoch  2, batch     9 | loss: 152.6012738CurrentTrain: epoch  2, batch    10 | loss: 121.0993296CurrentTrain: epoch  2, batch    11 | loss: 151.9800577CurrentTrain: epoch  2, batch    12 | loss: 176.8514607CurrentTrain: epoch  2, batch    13 | loss: 173.8287554CurrentTrain: epoch  2, batch    14 | loss: 126.1569860CurrentTrain: epoch  2, batch    15 | loss: 139.2492303CurrentTrain: epoch  2, batch    16 | loss: 143.7825604CurrentTrain: epoch  2, batch    17 | loss: 116.1549381CurrentTrain: epoch  2, batch    18 | loss: 125.1895930CurrentTrain: epoch  2, batch    19 | loss: 148.8865212CurrentTrain: epoch  2, batch    20 | loss: 202.5136655CurrentTrain: epoch  2, batch    21 | loss: 133.5205803CurrentTrain: epoch  2, batch    22 | loss: 149.3741254CurrentTrain: epoch  2, batch    23 | loss: 177.7422168CurrentTrain: epoch  2, batch    24 | loss: 142.3950522CurrentTrain: epoch  2, batch    25 | loss: 130.2770296CurrentTrain: epoch  2, batch    26 | loss: 136.6614311CurrentTrain: epoch  2, batch    27 | loss: 115.6393791CurrentTrain: epoch  2, batch    28 | loss: 136.9370962CurrentTrain: epoch  2, batch    29 | loss: 119.9892257CurrentTrain: epoch  2, batch    30 | loss: 167.0322190CurrentTrain: epoch  2, batch    31 | loss: 116.0369205CurrentTrain: epoch  2, batch    32 | loss: 132.9385419CurrentTrain: epoch  2, batch    33 | loss: 116.5588638CurrentTrain: epoch  2, batch    34 | loss: 139.0187006CurrentTrain: epoch  2, batch    35 | loss: 111.4067794CurrentTrain: epoch  2, batch    36 | loss: 110.7530402CurrentTrain: epoch  2, batch    37 | loss: 130.1100352CurrentTrain: epoch  2, batch    38 | loss: 126.0958246CurrentTrain: epoch  2, batch    39 | loss: 185.2693246CurrentTrain: epoch  2, batch    40 | loss: 156.9124467CurrentTrain: epoch  2, batch    41 | loss: 150.4109002CurrentTrain: epoch  2, batch    42 | loss: 136.8207833CurrentTrain: epoch  2, batch    43 | loss: 111.8181140CurrentTrain: epoch  2, batch    44 | loss: 148.8415555CurrentTrain: epoch  2, batch    45 | loss: 164.6757286CurrentTrain: epoch  2, batch    46 | loss: 139.4078257CurrentTrain: epoch  2, batch    47 | loss: 115.4637076CurrentTrain: epoch  2, batch    48 | loss: 127.8053540CurrentTrain: epoch  2, batch    49 | loss: 208.9945622CurrentTrain: epoch  2, batch    50 | loss: 141.3047648CurrentTrain: epoch  2, batch    51 | loss: 148.2396274CurrentTrain: epoch  2, batch    52 | loss: 137.9619072CurrentTrain: epoch  2, batch    53 | loss: 137.8964148CurrentTrain: epoch  2, batch    54 | loss: 116.9930633CurrentTrain: epoch  2, batch    55 | loss: 121.5350368CurrentTrain: epoch  2, batch    56 | loss: 94.0268339CurrentTrain: epoch  2, batch    57 | loss: 166.9794702CurrentTrain: epoch  2, batch    58 | loss: 133.4502186CurrentTrain: epoch  2, batch    59 | loss: 123.7495339CurrentTrain: epoch  2, batch    60 | loss: 135.5252801CurrentTrain: epoch  2, batch    61 | loss: 127.5086891CurrentTrain: epoch  2, batch    62 | loss: 113.9849544CurrentTrain: epoch  2, batch    63 | loss: 123.9246639CurrentTrain: epoch  2, batch    64 | loss: 138.7745307CurrentTrain: epoch  2, batch    65 | loss: 130.6819722CurrentTrain: epoch  2, batch    66 | loss: 104.8385725CurrentTrain: epoch  2, batch    67 | loss: 125.9201640CurrentTrain: epoch  2, batch    68 | loss: 141.3606968CurrentTrain: epoch  2, batch    69 | loss: 152.7445670CurrentTrain: epoch  2, batch    70 | loss: 127.7047461CurrentTrain: epoch  2, batch    71 | loss: 172.7848453CurrentTrain: epoch  2, batch    72 | loss: 169.7290135CurrentTrain: epoch  2, batch    73 | loss: 117.3824911CurrentTrain: epoch  2, batch    74 | loss: 132.9946777CurrentTrain: epoch  2, batch    75 | loss: 137.8049621CurrentTrain: epoch  2, batch    76 | loss: 120.8406829CurrentTrain: epoch  2, batch    77 | loss: 128.2347186CurrentTrain: epoch  2, batch    78 | loss: 122.4343899CurrentTrain: epoch  2, batch    79 | loss: 137.8513644CurrentTrain: epoch  2, batch    80 | loss: 117.6248292CurrentTrain: epoch  2, batch    81 | loss: 111.1868154CurrentTrain: epoch  2, batch    82 | loss: 147.7161258CurrentTrain: epoch  2, batch    83 | loss: 115.2928709CurrentTrain: epoch  2, batch    84 | loss: 126.4118335CurrentTrain: epoch  2, batch    85 | loss: 108.2362685CurrentTrain: epoch  2, batch    86 | loss: 123.1851919CurrentTrain: epoch  2, batch    87 | loss: 125.8435324CurrentTrain: epoch  2, batch    88 | loss: 131.7587742CurrentTrain: epoch  2, batch    89 | loss: 89.5266777CurrentTrain: epoch  2, batch    90 | loss: 135.8262513CurrentTrain: epoch  2, batch    91 | loss: 111.8310127CurrentTrain: epoch  2, batch    92 | loss: 125.0799547CurrentTrain: epoch  2, batch    93 | loss: 115.4027690CurrentTrain: epoch  2, batch    94 | loss: 205.3155518CurrentTrain: epoch  2, batch    95 | loss: 94.1787981CurrentTrain: epoch  3, batch     0 | loss: 125.6750309CurrentTrain: epoch  3, batch     1 | loss: 118.9129215CurrentTrain: epoch  3, batch     2 | loss: 177.6763182CurrentTrain: epoch  3, batch     3 | loss: 95.5751388CurrentTrain: epoch  3, batch     4 | loss: 112.4815585CurrentTrain: epoch  3, batch     5 | loss: 149.2250723CurrentTrain: epoch  3, batch     6 | loss: 113.3571471CurrentTrain: epoch  3, batch     7 | loss: 145.4091601CurrentTrain: epoch  3, batch     8 | loss: 156.5984764CurrentTrain: epoch  3, batch     9 | loss: 146.6098943CurrentTrain: epoch  3, batch    10 | loss: 127.4911130CurrentTrain: epoch  3, batch    11 | loss: 135.3418240CurrentTrain: epoch  3, batch    12 | loss: 103.5726087CurrentTrain: epoch  3, batch    13 | loss: 177.7796023CurrentTrain: epoch  3, batch    14 | loss: 187.1102657CurrentTrain: epoch  3, batch    15 | loss: 123.2292944CurrentTrain: epoch  3, batch    16 | loss: 138.1569827CurrentTrain: epoch  3, batch    17 | loss: 149.3634797CurrentTrain: epoch  3, batch    18 | loss: 137.5608230CurrentTrain: epoch  3, batch    19 | loss: 140.7888085CurrentTrain: epoch  3, batch    20 | loss: 114.4192397CurrentTrain: epoch  3, batch    21 | loss: 139.2704505CurrentTrain: epoch  3, batch    22 | loss: 149.4498838CurrentTrain: epoch  3, batch    23 | loss: 146.6310155CurrentTrain: epoch  3, batch    24 | loss: 139.6709914CurrentTrain: epoch  3, batch    25 | loss: 138.2778719CurrentTrain: epoch  3, batch    26 | loss: 125.4819897CurrentTrain: epoch  3, batch    27 | loss: 137.2840066CurrentTrain: epoch  3, batch    28 | loss: 101.5707744CurrentTrain: epoch  3, batch    29 | loss: 142.7151542CurrentTrain: epoch  3, batch    30 | loss: 166.7948915CurrentTrain: epoch  3, batch    31 | loss: 105.6279884CurrentTrain: epoch  3, batch    32 | loss: 156.3706043CurrentTrain: epoch  3, batch    33 | loss: 123.4060229CurrentTrain: epoch  3, batch    34 | loss: 137.6255036CurrentTrain: epoch  3, batch    35 | loss: 125.3402459CurrentTrain: epoch  3, batch    36 | loss: 112.2530009CurrentTrain: epoch  3, batch    37 | loss: 115.7195880CurrentTrain: epoch  3, batch    38 | loss: 153.8859131CurrentTrain: epoch  3, batch    39 | loss: 98.5798891CurrentTrain: epoch  3, batch    40 | loss: 107.1392321CurrentTrain: epoch  3, batch    41 | loss: 120.7959856CurrentTrain: epoch  3, batch    42 | loss: 120.8599885CurrentTrain: epoch  3, batch    43 | loss: 152.9983805CurrentTrain: epoch  3, batch    44 | loss: 142.4444798CurrentTrain: epoch  3, batch    45 | loss: 148.9811367CurrentTrain: epoch  3, batch    46 | loss: 92.0445269CurrentTrain: epoch  3, batch    47 | loss: 113.6338145CurrentTrain: epoch  3, batch    48 | loss: 119.2228276CurrentTrain: epoch  3, batch    49 | loss: 100.7883301CurrentTrain: epoch  3, batch    50 | loss: 102.2897125CurrentTrain: epoch  3, batch    51 | loss: 119.1182697CurrentTrain: epoch  3, batch    52 | loss: 100.6698395CurrentTrain: epoch  3, batch    53 | loss: 122.1152026CurrentTrain: epoch  3, batch    54 | loss: 131.7129448CurrentTrain: epoch  3, batch    55 | loss: 106.5783953CurrentTrain: epoch  3, batch    56 | loss: 121.6552793CurrentTrain: epoch  3, batch    57 | loss: 128.6063949CurrentTrain: epoch  3, batch    58 | loss: 150.5409376CurrentTrain: epoch  3, batch    59 | loss: 139.9782296CurrentTrain: epoch  3, batch    60 | loss: 116.8009454CurrentTrain: epoch  3, batch    61 | loss: 113.2575156CurrentTrain: epoch  3, batch    62 | loss: 124.5236436CurrentTrain: epoch  3, batch    63 | loss: 182.2412912CurrentTrain: epoch  3, batch    64 | loss: 107.1486264CurrentTrain: epoch  3, batch    65 | loss: 160.0541680CurrentTrain: epoch  3, batch    66 | loss: 165.6335259CurrentTrain: epoch  3, batch    67 | loss: 124.6111331CurrentTrain: epoch  3, batch    68 | loss: 118.0551198CurrentTrain: epoch  3, batch    69 | loss: 131.7291995CurrentTrain: epoch  3, batch    70 | loss: 139.3604552CurrentTrain: epoch  3, batch    71 | loss: 143.6930646CurrentTrain: epoch  3, batch    72 | loss: 116.3427158CurrentTrain: epoch  3, batch    73 | loss: 114.3943788CurrentTrain: epoch  3, batch    74 | loss: 129.3653431CurrentTrain: epoch  3, batch    75 | loss: 144.5918866CurrentTrain: epoch  3, batch    76 | loss: 112.9619235CurrentTrain: epoch  3, batch    77 | loss: 100.0378322CurrentTrain: epoch  3, batch    78 | loss: 148.0478455CurrentTrain: epoch  3, batch    79 | loss: 134.6820928CurrentTrain: epoch  3, batch    80 | loss: 143.1422624CurrentTrain: epoch  3, batch    81 | loss: 112.1325430CurrentTrain: epoch  3, batch    82 | loss: 118.9000509CurrentTrain: epoch  3, batch    83 | loss: 114.3189277CurrentTrain: epoch  3, batch    84 | loss: 113.4354367CurrentTrain: epoch  3, batch    85 | loss: 148.0838021CurrentTrain: epoch  3, batch    86 | loss: 108.9324246CurrentTrain: epoch  3, batch    87 | loss: 134.5640274CurrentTrain: epoch  3, batch    88 | loss: 160.7851020CurrentTrain: epoch  3, batch    89 | loss: 135.1314789CurrentTrain: epoch  3, batch    90 | loss: 110.9619944CurrentTrain: epoch  3, batch    91 | loss: 112.8638944CurrentTrain: epoch  3, batch    92 | loss: 120.9326327CurrentTrain: epoch  3, batch    93 | loss: 118.9443233CurrentTrain: epoch  3, batch    94 | loss: 152.5703973CurrentTrain: epoch  3, batch    95 | loss: 104.4250520CurrentTrain: epoch  4, batch     0 | loss: 109.3192481CurrentTrain: epoch  4, batch     1 | loss: 161.9557249CurrentTrain: epoch  4, batch     2 | loss: 105.9950187CurrentTrain: epoch  4, batch     3 | loss: 141.9426724CurrentTrain: epoch  4, batch     4 | loss: 105.3845166CurrentTrain: epoch  4, batch     5 | loss: 117.7463016CurrentTrain: epoch  4, batch     6 | loss: 131.6047720CurrentTrain: epoch  4, batch     7 | loss: 116.6146273CurrentTrain: epoch  4, batch     8 | loss: 115.1600263CurrentTrain: epoch  4, batch     9 | loss: 101.5998529CurrentTrain: epoch  4, batch    10 | loss: 123.3722560CurrentTrain: epoch  4, batch    11 | loss: 112.4950601CurrentTrain: epoch  4, batch    12 | loss: 117.4006400CurrentTrain: epoch  4, batch    13 | loss: 167.1692831CurrentTrain: epoch  4, batch    14 | loss: 149.4953184CurrentTrain: epoch  4, batch    15 | loss: 133.9429150CurrentTrain: epoch  4, batch    16 | loss: 120.3976201CurrentTrain: epoch  4, batch    17 | loss: 133.4788357CurrentTrain: epoch  4, batch    18 | loss: 147.8785805CurrentTrain: epoch  4, batch    19 | loss: 168.3648751CurrentTrain: epoch  4, batch    20 | loss: 119.4979539CurrentTrain: epoch  4, batch    21 | loss: 163.7428271CurrentTrain: epoch  4, batch    22 | loss: 107.4298906CurrentTrain: epoch  4, batch    23 | loss: 134.3939325CurrentTrain: epoch  4, batch    24 | loss: 124.3652350CurrentTrain: epoch  4, batch    25 | loss: 106.7815427CurrentTrain: epoch  4, batch    26 | loss: 107.3116646CurrentTrain: epoch  4, batch    27 | loss: 127.6224509CurrentTrain: epoch  4, batch    28 | loss: 145.6199556CurrentTrain: epoch  4, batch    29 | loss: 110.6967932CurrentTrain: epoch  4, batch    30 | loss: 127.2053104CurrentTrain: epoch  4, batch    31 | loss: 119.5626236CurrentTrain: epoch  4, batch    32 | loss: 146.7945636CurrentTrain: epoch  4, batch    33 | loss: 107.5892846CurrentTrain: epoch  4, batch    34 | loss: 126.4110208CurrentTrain: epoch  4, batch    35 | loss: 132.9527609CurrentTrain: epoch  4, batch    36 | loss: 166.8505355CurrentTrain: epoch  4, batch    37 | loss: 146.7482555CurrentTrain: epoch  4, batch    38 | loss: 153.5519123CurrentTrain: epoch  4, batch    39 | loss: 142.9760334CurrentTrain: epoch  4, batch    40 | loss: 127.8585860CurrentTrain: epoch  4, batch    41 | loss: 122.8583269CurrentTrain: epoch  4, batch    42 | loss: 132.5591169CurrentTrain: epoch  4, batch    43 | loss: 145.7242438CurrentTrain: epoch  4, batch    44 | loss: 176.2077676CurrentTrain: epoch  4, batch    45 | loss: 122.0552869CurrentTrain: epoch  4, batch    46 | loss: 124.9766187CurrentTrain: epoch  4, batch    47 | loss: 150.7576441CurrentTrain: epoch  4, batch    48 | loss: 174.0004169CurrentTrain: epoch  4, batch    49 | loss: 117.6817022CurrentTrain: epoch  4, batch    50 | loss: 118.1185549CurrentTrain: epoch  4, batch    51 | loss: 163.6634519CurrentTrain: epoch  4, batch    52 | loss: 128.4340791CurrentTrain: epoch  4, batch    53 | loss: 103.5520099CurrentTrain: epoch  4, batch    54 | loss: 106.0716050CurrentTrain: epoch  4, batch    55 | loss: 148.6045563CurrentTrain: epoch  4, batch    56 | loss: 122.5863326CurrentTrain: epoch  4, batch    57 | loss: 107.2309435CurrentTrain: epoch  4, batch    58 | loss: 107.3277372CurrentTrain: epoch  4, batch    59 | loss: 145.4055207CurrentTrain: epoch  4, batch    60 | loss: 115.1326939CurrentTrain: epoch  4, batch    61 | loss: 126.3347371CurrentTrain: epoch  4, batch    62 | loss: 121.1471053CurrentTrain: epoch  4, batch    63 | loss: 120.8893421CurrentTrain: epoch  4, batch    64 | loss: 116.1230308CurrentTrain: epoch  4, batch    65 | loss: 117.9361818CurrentTrain: epoch  4, batch    66 | loss: 140.8750061CurrentTrain: epoch  4, batch    67 | loss: 109.4010425CurrentTrain: epoch  4, batch    68 | loss: 103.8051759CurrentTrain: epoch  4, batch    69 | loss: 165.8053859CurrentTrain: epoch  4, batch    70 | loss: 125.0576692CurrentTrain: epoch  4, batch    71 | loss: 165.2801199CurrentTrain: epoch  4, batch    72 | loss: 91.5386750CurrentTrain: epoch  4, batch    73 | loss: 156.4514970CurrentTrain: epoch  4, batch    74 | loss: 105.0938014CurrentTrain: epoch  4, batch    75 | loss: 120.2066973CurrentTrain: epoch  4, batch    76 | loss: 108.8060080CurrentTrain: epoch  4, batch    77 | loss: 152.0722344CurrentTrain: epoch  4, batch    78 | loss: 149.7383389CurrentTrain: epoch  4, batch    79 | loss: 128.3793462CurrentTrain: epoch  4, batch    80 | loss: 121.7221995CurrentTrain: epoch  4, batch    81 | loss: 146.6139207CurrentTrain: epoch  4, batch    82 | loss: 114.5618715CurrentTrain: epoch  4, batch    83 | loss: 148.4430329CurrentTrain: epoch  4, batch    84 | loss: 113.7856266CurrentTrain: epoch  4, batch    85 | loss: 140.0651505CurrentTrain: epoch  4, batch    86 | loss: 147.2923498CurrentTrain: epoch  4, batch    87 | loss: 140.8274551CurrentTrain: epoch  4, batch    88 | loss: 140.2561064CurrentTrain: epoch  4, batch    89 | loss: 138.9158322CurrentTrain: epoch  4, batch    90 | loss: 137.0813535CurrentTrain: epoch  4, batch    91 | loss: 135.4847537CurrentTrain: epoch  4, batch    92 | loss: 142.3051354CurrentTrain: epoch  4, batch    93 | loss: 101.0992329CurrentTrain: epoch  4, batch    94 | loss: 118.5045465CurrentTrain: epoch  4, batch    95 | loss: 95.3936414CurrentTrain: epoch  5, batch     0 | loss: 146.6413064CurrentTrain: epoch  5, batch     1 | loss: 115.4596524CurrentTrain: epoch  5, batch     2 | loss: 139.9246063CurrentTrain: epoch  5, batch     3 | loss: 148.0978522CurrentTrain: epoch  5, batch     4 | loss: 112.9026174CurrentTrain: epoch  5, batch     5 | loss: 127.6959585CurrentTrain: epoch  5, batch     6 | loss: 144.2556548CurrentTrain: epoch  5, batch     7 | loss: 131.6521654CurrentTrain: epoch  5, batch     8 | loss: 108.0094234CurrentTrain: epoch  5, batch     9 | loss: 101.4428672CurrentTrain: epoch  5, batch    10 | loss: 147.2763774CurrentTrain: epoch  5, batch    11 | loss: 144.2978356CurrentTrain: epoch  5, batch    12 | loss: 101.0014090CurrentTrain: epoch  5, batch    13 | loss: 129.4901646CurrentTrain: epoch  5, batch    14 | loss: 161.0680172CurrentTrain: epoch  5, batch    15 | loss: 110.2374970CurrentTrain: epoch  5, batch    16 | loss: 164.0199986CurrentTrain: epoch  5, batch    17 | loss: 118.4023211CurrentTrain: epoch  5, batch    18 | loss: 136.3774512CurrentTrain: epoch  5, batch    19 | loss: 151.6570627CurrentTrain: epoch  5, batch    20 | loss: 130.8296984CurrentTrain: epoch  5, batch    21 | loss: 115.4454705CurrentTrain: epoch  5, batch    22 | loss: 128.4487590CurrentTrain: epoch  5, batch    23 | loss: 122.0067486CurrentTrain: epoch  5, batch    24 | loss: 110.4883384CurrentTrain: epoch  5, batch    25 | loss: 146.3335793CurrentTrain: epoch  5, batch    26 | loss: 121.1781054CurrentTrain: epoch  5, batch    27 | loss: 108.7504592CurrentTrain: epoch  5, batch    28 | loss: 169.2777798CurrentTrain: epoch  5, batch    29 | loss: 118.8334396CurrentTrain: epoch  5, batch    30 | loss: 126.2563980CurrentTrain: epoch  5, batch    31 | loss: 119.4686526CurrentTrain: epoch  5, batch    32 | loss: 114.9988158CurrentTrain: epoch  5, batch    33 | loss: 123.9159164CurrentTrain: epoch  5, batch    34 | loss: 142.8353691CurrentTrain: epoch  5, batch    35 | loss: 90.7177104CurrentTrain: epoch  5, batch    36 | loss: 118.4033502CurrentTrain: epoch  5, batch    37 | loss: 164.7032805CurrentTrain: epoch  5, batch    38 | loss: 117.1145754CurrentTrain: epoch  5, batch    39 | loss: 100.6527166CurrentTrain: epoch  5, batch    40 | loss: 170.6532198CurrentTrain: epoch  5, batch    41 | loss: 125.8462954CurrentTrain: epoch  5, batch    42 | loss: 121.0741016CurrentTrain: epoch  5, batch    43 | loss: 103.8282888CurrentTrain: epoch  5, batch    44 | loss: 144.6728727CurrentTrain: epoch  5, batch    45 | loss: 115.1093811CurrentTrain: epoch  5, batch    46 | loss: 108.2199850CurrentTrain: epoch  5, batch    47 | loss: 115.9921743CurrentTrain: epoch  5, batch    48 | loss: 150.9786282CurrentTrain: epoch  5, batch    49 | loss: 89.9596966CurrentTrain: epoch  5, batch    50 | loss: 130.3160921CurrentTrain: epoch  5, batch    51 | loss: 118.4803817CurrentTrain: epoch  5, batch    52 | loss: 126.1130671CurrentTrain: epoch  5, batch    53 | loss: 129.7139722CurrentTrain: epoch  5, batch    54 | loss: 125.1254258CurrentTrain: epoch  5, batch    55 | loss: 160.1842998CurrentTrain: epoch  5, batch    56 | loss: 206.1345323CurrentTrain: epoch  5, batch    57 | loss: 108.0246688CurrentTrain: epoch  5, batch    58 | loss: 131.7490332CurrentTrain: epoch  5, batch    59 | loss: 131.5972172CurrentTrain: epoch  5, batch    60 | loss: 99.5267672CurrentTrain: epoch  5, batch    61 | loss: 141.8883995CurrentTrain: epoch  5, batch    62 | loss: 138.0354135CurrentTrain: epoch  5, batch    63 | loss: 106.1888928CurrentTrain: epoch  5, batch    64 | loss: 113.9317327CurrentTrain: epoch  5, batch    65 | loss: 192.6845435CurrentTrain: epoch  5, batch    66 | loss: 123.4930425CurrentTrain: epoch  5, batch    67 | loss: 140.8875150CurrentTrain: epoch  5, batch    68 | loss: 116.5050760CurrentTrain: epoch  5, batch    69 | loss: 121.3328813CurrentTrain: epoch  5, batch    70 | loss: 120.6174618CurrentTrain: epoch  5, batch    71 | loss: 198.1989078CurrentTrain: epoch  5, batch    72 | loss: 93.8961342CurrentTrain: epoch  5, batch    73 | loss: 141.7864272CurrentTrain: epoch  5, batch    74 | loss: 107.0133044CurrentTrain: epoch  5, batch    75 | loss: 118.7901055CurrentTrain: epoch  5, batch    76 | loss: 115.5499872CurrentTrain: epoch  5, batch    77 | loss: 114.3974011CurrentTrain: epoch  5, batch    78 | loss: 116.8050986CurrentTrain: epoch  5, batch    79 | loss: 105.7133528CurrentTrain: epoch  5, batch    80 | loss: 125.2178660CurrentTrain: epoch  5, batch    81 | loss: 118.0395717CurrentTrain: epoch  5, batch    82 | loss: 110.6305802CurrentTrain: epoch  5, batch    83 | loss: 119.6778520CurrentTrain: epoch  5, batch    84 | loss: 138.8146081CurrentTrain: epoch  5, batch    85 | loss: 148.8886434CurrentTrain: epoch  5, batch    86 | loss: 129.3325120CurrentTrain: epoch  5, batch    87 | loss: 138.5762057CurrentTrain: epoch  5, batch    88 | loss: 136.4040929CurrentTrain: epoch  5, batch    89 | loss: 114.2803455CurrentTrain: epoch  5, batch    90 | loss: 130.1279682CurrentTrain: epoch  5, batch    91 | loss: 141.8712782CurrentTrain: epoch  5, batch    92 | loss: 132.2713376CurrentTrain: epoch  5, batch    93 | loss: 118.3798273CurrentTrain: epoch  5, batch    94 | loss: 146.3329721CurrentTrain: epoch  5, batch    95 | loss: 105.4851855CurrentTrain: epoch  6, batch     0 | loss: 152.6510042CurrentTrain: epoch  6, batch     1 | loss: 106.3269677CurrentTrain: epoch  6, batch     2 | loss: 130.3352381CurrentTrain: epoch  6, batch     3 | loss: 120.2643841CurrentTrain: epoch  6, batch     4 | loss: 121.3555843CurrentTrain: epoch  6, batch     5 | loss: 144.0210949CurrentTrain: epoch  6, batch     6 | loss: 134.4153757CurrentTrain: epoch  6, batch     7 | loss: 126.2827355CurrentTrain: epoch  6, batch     8 | loss: 142.9417013CurrentTrain: epoch  6, batch     9 | loss: 152.5982507CurrentTrain: epoch  6, batch    10 | loss: 124.8470090CurrentTrain: epoch  6, batch    11 | loss: 146.1320087CurrentTrain: epoch  6, batch    12 | loss: 130.1965368CurrentTrain: epoch  6, batch    13 | loss: 125.9816314CurrentTrain: epoch  6, batch    14 | loss: 101.3032470CurrentTrain: epoch  6, batch    15 | loss: 154.8945510CurrentTrain: epoch  6, batch    16 | loss: 135.6417961CurrentTrain: epoch  6, batch    17 | loss: 148.0260174CurrentTrain: epoch  6, batch    18 | loss: 172.4698840CurrentTrain: epoch  6, batch    19 | loss: 113.3312432CurrentTrain: epoch  6, batch    20 | loss: 201.6302602CurrentTrain: epoch  6, batch    21 | loss: 131.2515417CurrentTrain: epoch  6, batch    22 | loss: 115.2975504CurrentTrain: epoch  6, batch    23 | loss: 147.3852714CurrentTrain: epoch  6, batch    24 | loss: 103.7811177CurrentTrain: epoch  6, batch    25 | loss: 147.2345735CurrentTrain: epoch  6, batch    26 | loss: 107.6393238CurrentTrain: epoch  6, batch    27 | loss: 98.8920551CurrentTrain: epoch  6, batch    28 | loss: 121.6748090CurrentTrain: epoch  6, batch    29 | loss: 166.6983608CurrentTrain: epoch  6, batch    30 | loss: 121.8447638CurrentTrain: epoch  6, batch    31 | loss: 111.6221889CurrentTrain: epoch  6, batch    32 | loss: 113.8808724CurrentTrain: epoch  6, batch    33 | loss: 168.5090840CurrentTrain: epoch  6, batch    34 | loss: 121.7494086CurrentTrain: epoch  6, batch    35 | loss: 102.3881865CurrentTrain: epoch  6, batch    36 | loss: 147.7712757CurrentTrain: epoch  6, batch    37 | loss: 157.3539025CurrentTrain: epoch  6, batch    38 | loss: 142.3678944CurrentTrain: epoch  6, batch    39 | loss: 107.6305126CurrentTrain: epoch  6, batch    40 | loss: 147.8510835CurrentTrain: epoch  6, batch    41 | loss: 145.7945502CurrentTrain: epoch  6, batch    42 | loss: 96.1747260CurrentTrain: epoch  6, batch    43 | loss: 117.2698457CurrentTrain: epoch  6, batch    44 | loss: 117.4907436CurrentTrain: epoch  6, batch    45 | loss: 96.8282979CurrentTrain: epoch  6, batch    46 | loss: 111.8977877CurrentTrain: epoch  6, batch    47 | loss: 112.1809652CurrentTrain: epoch  6, batch    48 | loss: 110.7840988CurrentTrain: epoch  6, batch    49 | loss: 156.3840840CurrentTrain: epoch  6, batch    50 | loss: 160.0846640CurrentTrain: epoch  6, batch    51 | loss: 100.4172306CurrentTrain: epoch  6, batch    52 | loss: 108.7623389CurrentTrain: epoch  6, batch    53 | loss: 106.0889084CurrentTrain: epoch  6, batch    54 | loss: 128.3298020CurrentTrain: epoch  6, batch    55 | loss: 161.3069941CurrentTrain: epoch  6, batch    56 | loss: 161.5152388CurrentTrain: epoch  6, batch    57 | loss: 131.3785583CurrentTrain: epoch  6, batch    58 | loss: 146.9960920CurrentTrain: epoch  6, batch    59 | loss: 147.6939252CurrentTrain: epoch  6, batch    60 | loss: 154.9024597CurrentTrain: epoch  6, batch    61 | loss: 107.7264077CurrentTrain: epoch  6, batch    62 | loss: 112.1844843CurrentTrain: epoch  6, batch    63 | loss: 127.6494008CurrentTrain: epoch  6, batch    64 | loss: 123.3319890CurrentTrain: epoch  6, batch    65 | loss: 150.7355250CurrentTrain: epoch  6, batch    66 | loss: 122.0456662CurrentTrain: epoch  6, batch    67 | loss: 123.6761021CurrentTrain: epoch  6, batch    68 | loss: 124.6678834CurrentTrain: epoch  6, batch    69 | loss: 126.2799990CurrentTrain: epoch  6, batch    70 | loss: 142.4894933CurrentTrain: epoch  6, batch    71 | loss: 124.9341540CurrentTrain: epoch  6, batch    72 | loss: 93.0476271CurrentTrain: epoch  6, batch    73 | loss: 126.1834965CurrentTrain: epoch  6, batch    74 | loss: 135.8870483CurrentTrain: epoch  6, batch    75 | loss: 111.2026215CurrentTrain: epoch  6, batch    76 | loss: 124.3273479CurrentTrain: epoch  6, batch    77 | loss: 147.1035636CurrentTrain: epoch  6, batch    78 | loss: 142.4342774CurrentTrain: epoch  6, batch    79 | loss: 136.2667188CurrentTrain: epoch  6, batch    80 | loss: 137.5223657CurrentTrain: epoch  6, batch    81 | loss: 114.6744175CurrentTrain: epoch  6, batch    82 | loss: 118.6922404CurrentTrain: epoch  6, batch    83 | loss: 112.3782853CurrentTrain: epoch  6, batch    84 | loss: 140.8065053CurrentTrain: epoch  6, batch    85 | loss: 104.7783524CurrentTrain: epoch  6, batch    86 | loss: 134.9339773CurrentTrain: epoch  6, batch    87 | loss: 141.9206228CurrentTrain: epoch  6, batch    88 | loss: 157.9319809CurrentTrain: epoch  6, batch    89 | loss: 122.4155360CurrentTrain: epoch  6, batch    90 | loss: 92.4013185CurrentTrain: epoch  6, batch    91 | loss: 155.8139606CurrentTrain: epoch  6, batch    92 | loss: 103.7659674CurrentTrain: epoch  6, batch    93 | loss: 96.4104448CurrentTrain: epoch  6, batch    94 | loss: 95.7523862CurrentTrain: epoch  6, batch    95 | loss: 146.8100631CurrentTrain: epoch  7, batch     0 | loss: 93.8675600CurrentTrain: epoch  7, batch     1 | loss: 108.1368654CurrentTrain: epoch  7, batch     2 | loss: 157.8658480CurrentTrain: epoch  7, batch     3 | loss: 143.5536782CurrentTrain: epoch  7, batch     4 | loss: 155.9391384CurrentTrain: epoch  7, batch     5 | loss: 128.2733114CurrentTrain: epoch  7, batch     6 | loss: 115.1224429CurrentTrain: epoch  7, batch     7 | loss: 132.6855476CurrentTrain: epoch  7, batch     8 | loss: 90.4267133CurrentTrain: epoch  7, batch     9 | loss: 106.9599557CurrentTrain: epoch  7, batch    10 | loss: 154.2137673CurrentTrain: epoch  7, batch    11 | loss: 165.8747336CurrentTrain: epoch  7, batch    12 | loss: 122.8569193CurrentTrain: epoch  7, batch    13 | loss: 122.9328525CurrentTrain: epoch  7, batch    14 | loss: 87.6428767CurrentTrain: epoch  7, batch    15 | loss: 138.2171308CurrentTrain: epoch  7, batch    16 | loss: 103.6822820CurrentTrain: epoch  7, batch    17 | loss: 149.8085303CurrentTrain: epoch  7, batch    18 | loss: 109.2298060CurrentTrain: epoch  7, batch    19 | loss: 128.7135754CurrentTrain: epoch  7, batch    20 | loss: 135.2153980CurrentTrain: epoch  7, batch    21 | loss: 127.9464211CurrentTrain: epoch  7, batch    22 | loss: 141.7851020CurrentTrain: epoch  7, batch    23 | loss: 125.1873705CurrentTrain: epoch  7, batch    24 | loss: 160.3472987CurrentTrain: epoch  7, batch    25 | loss: 111.6983462CurrentTrain: epoch  7, batch    26 | loss: 134.7771712CurrentTrain: epoch  7, batch    27 | loss: 90.5108134CurrentTrain: epoch  7, batch    28 | loss: 98.2232577CurrentTrain: epoch  7, batch    29 | loss: 103.3804673CurrentTrain: epoch  7, batch    30 | loss: 140.2586326CurrentTrain: epoch  7, batch    31 | loss: 122.7407470CurrentTrain: epoch  7, batch    32 | loss: 133.8966117CurrentTrain: epoch  7, batch    33 | loss: 133.4425185CurrentTrain: epoch  7, batch    34 | loss: 140.3720131CurrentTrain: epoch  7, batch    35 | loss: 128.9603708CurrentTrain: epoch  7, batch    36 | loss: 118.6733969CurrentTrain: epoch  7, batch    37 | loss: 100.9637873CurrentTrain: epoch  7, batch    38 | loss: 115.1219300CurrentTrain: epoch  7, batch    39 | loss: 117.3124009CurrentTrain: epoch  7, batch    40 | loss: 173.5161734CurrentTrain: epoch  7, batch    41 | loss: 119.0691846CurrentTrain: epoch  7, batch    42 | loss: 135.8912866CurrentTrain: epoch  7, batch    43 | loss: 163.8878849CurrentTrain: epoch  7, batch    44 | loss: 91.4974465CurrentTrain: epoch  7, batch    45 | loss: 149.6780322CurrentTrain: epoch  7, batch    46 | loss: 105.2369855CurrentTrain: epoch  7, batch    47 | loss: 126.0229102CurrentTrain: epoch  7, batch    48 | loss: 123.1562532CurrentTrain: epoch  7, batch    49 | loss: 167.2628527CurrentTrain: epoch  7, batch    50 | loss: 149.6494016CurrentTrain: epoch  7, batch    51 | loss: 146.2757619CurrentTrain: epoch  7, batch    52 | loss: 112.1955731CurrentTrain: epoch  7, batch    53 | loss: 162.0022632CurrentTrain: epoch  7, batch    54 | loss: 123.0947020CurrentTrain: epoch  7, batch    55 | loss: 127.9384109CurrentTrain: epoch  7, batch    56 | loss: 107.8165483CurrentTrain: epoch  7, batch    57 | loss: 168.9189501CurrentTrain: epoch  7, batch    58 | loss: 115.5962163CurrentTrain: epoch  7, batch    59 | loss: 126.2848229CurrentTrain: epoch  7, batch    60 | loss: 130.1359543CurrentTrain: epoch  7, batch    61 | loss: 121.0593902CurrentTrain: epoch  7, batch    62 | loss: 139.7678870CurrentTrain: epoch  7, batch    63 | loss: 119.0650070CurrentTrain: epoch  7, batch    64 | loss: 86.9448699CurrentTrain: epoch  7, batch    65 | loss: 113.7062993CurrentTrain: epoch  7, batch    66 | loss: 122.1038951CurrentTrain: epoch  7, batch    67 | loss: 128.6159876CurrentTrain: epoch  7, batch    68 | loss: 126.1998612CurrentTrain: epoch  7, batch    69 | loss: 146.9100293CurrentTrain: epoch  7, batch    70 | loss: 122.1427657CurrentTrain: epoch  7, batch    71 | loss: 91.7627277CurrentTrain: epoch  7, batch    72 | loss: 120.0631782CurrentTrain: epoch  7, batch    73 | loss: 121.0991343CurrentTrain: epoch  7, batch    74 | loss: 157.4754906CurrentTrain: epoch  7, batch    75 | loss: 128.9208074CurrentTrain: epoch  7, batch    76 | loss: 113.1624678CurrentTrain: epoch  7, batch    77 | loss: 101.2588188CurrentTrain: epoch  7, batch    78 | loss: 265.8805075CurrentTrain: epoch  7, batch    79 | loss: 118.9710182CurrentTrain: epoch  7, batch    80 | loss: 123.0457998CurrentTrain: epoch  7, batch    81 | loss: 97.1396967CurrentTrain: epoch  7, batch    82 | loss: 148.6902639CurrentTrain: epoch  7, batch    83 | loss: 102.0055150CurrentTrain: epoch  7, batch    84 | loss: 125.6495086CurrentTrain: epoch  7, batch    85 | loss: 117.2932533CurrentTrain: epoch  7, batch    86 | loss: 169.8516938CurrentTrain: epoch  7, batch    87 | loss: 140.3131861CurrentTrain: epoch  7, batch    88 | loss: 157.9667753CurrentTrain: epoch  7, batch    89 | loss: 117.0825364CurrentTrain: epoch  7, batch    90 | loss: 121.8527280CurrentTrain: epoch  7, batch    91 | loss: 167.2728907CurrentTrain: epoch  7, batch    92 | loss: 159.3166257CurrentTrain: epoch  7, batch    93 | loss: 102.1242091CurrentTrain: epoch  7, batch    94 | loss: 84.1106585CurrentTrain: epoch  7, batch    95 | loss: 128.2708636CurrentTrain: epoch  8, batch     0 | loss: 146.5864823CurrentTrain: epoch  8, batch     1 | loss: 141.2088866CurrentTrain: epoch  8, batch     2 | loss: 127.3803622CurrentTrain: epoch  8, batch     3 | loss: 103.7291744CurrentTrain: epoch  8, batch     4 | loss: 111.1275205CurrentTrain: epoch  8, batch     5 | loss: 125.4835784CurrentTrain: epoch  8, batch     6 | loss: 113.4177061CurrentTrain: epoch  8, batch     7 | loss: 166.5223903CurrentTrain: epoch  8, batch     8 | loss: 108.4167510CurrentTrain: epoch  8, batch     9 | loss: 98.8385107CurrentTrain: epoch  8, batch    10 | loss: 90.1210759CurrentTrain: epoch  8, batch    11 | loss: 101.4754614CurrentTrain: epoch  8, batch    12 | loss: 103.6127556CurrentTrain: epoch  8, batch    13 | loss: 201.1319030CurrentTrain: epoch  8, batch    14 | loss: 129.2663257CurrentTrain: epoch  8, batch    15 | loss: 124.7406711CurrentTrain: epoch  8, batch    16 | loss: 166.4920401CurrentTrain: epoch  8, batch    17 | loss: 137.0341431CurrentTrain: epoch  8, batch    18 | loss: 137.5782779CurrentTrain: epoch  8, batch    19 | loss: 106.3925226CurrentTrain: epoch  8, batch    20 | loss: 95.2859840CurrentTrain: epoch  8, batch    21 | loss: 98.1844150CurrentTrain: epoch  8, batch    22 | loss: 167.4535506CurrentTrain: epoch  8, batch    23 | loss: 115.4233673CurrentTrain: epoch  8, batch    24 | loss: 143.1362689CurrentTrain: epoch  8, batch    25 | loss: 105.8203335CurrentTrain: epoch  8, batch    26 | loss: 135.0019236CurrentTrain: epoch  8, batch    27 | loss: 155.9992997CurrentTrain: epoch  8, batch    28 | loss: 127.5370023CurrentTrain: epoch  8, batch    29 | loss: 129.5150321CurrentTrain: epoch  8, batch    30 | loss: 118.0351226CurrentTrain: epoch  8, batch    31 | loss: 168.4917400CurrentTrain: epoch  8, batch    32 | loss: 155.5260262CurrentTrain: epoch  8, batch    33 | loss: 137.3178971CurrentTrain: epoch  8, batch    34 | loss: 169.6083175CurrentTrain: epoch  8, batch    35 | loss: 160.6447438CurrentTrain: epoch  8, batch    36 | loss: 118.6148533CurrentTrain: epoch  8, batch    37 | loss: 142.4089274CurrentTrain: epoch  8, batch    38 | loss: 161.4699825CurrentTrain: epoch  8, batch    39 | loss: 125.0082423CurrentTrain: epoch  8, batch    40 | loss: 114.4163936CurrentTrain: epoch  8, batch    41 | loss: 90.2860373CurrentTrain: epoch  8, batch    42 | loss: 198.9720692CurrentTrain: epoch  8, batch    43 | loss: 133.0504751CurrentTrain: epoch  8, batch    44 | loss: 135.0846680CurrentTrain: epoch  8, batch    45 | loss: 119.9971614CurrentTrain: epoch  8, batch    46 | loss: 129.4484684CurrentTrain: epoch  8, batch    47 | loss: 162.8640095CurrentTrain: epoch  8, batch    48 | loss: 117.7658793CurrentTrain: epoch  8, batch    49 | loss: 111.2257103CurrentTrain: epoch  8, batch    50 | loss: 117.9329025CurrentTrain: epoch  8, batch    51 | loss: 116.2805531CurrentTrain: epoch  8, batch    52 | loss: 97.5024119CurrentTrain: epoch  8, batch    53 | loss: 148.9633262CurrentTrain: epoch  8, batch    54 | loss: 136.2560487CurrentTrain: epoch  8, batch    55 | loss: 122.1668621CurrentTrain: epoch  8, batch    56 | loss: 123.4810777CurrentTrain: epoch  8, batch    57 | loss: 122.8892445CurrentTrain: epoch  8, batch    58 | loss: 133.4185213CurrentTrain: epoch  8, batch    59 | loss: 153.2173617CurrentTrain: epoch  8, batch    60 | loss: 109.8485016CurrentTrain: epoch  8, batch    61 | loss: 139.0881801CurrentTrain: epoch  8, batch    62 | loss: 104.7123140CurrentTrain: epoch  8, batch    63 | loss: 112.4753437CurrentTrain: epoch  8, batch    64 | loss: 118.1391418CurrentTrain: epoch  8, batch    65 | loss: 146.8426795CurrentTrain: epoch  8, batch    66 | loss: 106.9601867CurrentTrain: epoch  8, batch    67 | loss: 116.5876986CurrentTrain: epoch  8, batch    68 | loss: 123.8407496CurrentTrain: epoch  8, batch    69 | loss: 108.4237296CurrentTrain: epoch  8, batch    70 | loss: 119.3659002CurrentTrain: epoch  8, batch    71 | loss: 112.8214860CurrentTrain: epoch  8, batch    72 | loss: 169.2794749CurrentTrain: epoch  8, batch    73 | loss: 105.4953069CurrentTrain: epoch  8, batch    74 | loss: 111.7303905CurrentTrain: epoch  8, batch    75 | loss: 147.7488378CurrentTrain: epoch  8, batch    76 | loss: 122.0267746CurrentTrain: epoch  8, batch    77 | loss: 109.0941641CurrentTrain: epoch  8, batch    78 | loss: 101.1426022CurrentTrain: epoch  8, batch    79 | loss: 93.1435481CurrentTrain: epoch  8, batch    80 | loss: 116.5214926CurrentTrain: epoch  8, batch    81 | loss: 105.4327911CurrentTrain: epoch  8, batch    82 | loss: 99.8109769CurrentTrain: epoch  8, batch    83 | loss: 94.7026869CurrentTrain: epoch  8, batch    84 | loss: 133.5152939CurrentTrain: epoch  8, batch    85 | loss: 117.7586955CurrentTrain: epoch  8, batch    86 | loss: 100.0374771CurrentTrain: epoch  8, batch    87 | loss: 117.6975508CurrentTrain: epoch  8, batch    88 | loss: 129.3270659CurrentTrain: epoch  8, batch    89 | loss: 110.9762902CurrentTrain: epoch  8, batch    90 | loss: 161.0561878CurrentTrain: epoch  8, batch    91 | loss: 103.7584508CurrentTrain: epoch  8, batch    92 | loss: 111.0526136CurrentTrain: epoch  8, batch    93 | loss: 141.2849057CurrentTrain: epoch  8, batch    94 | loss: 141.4368176CurrentTrain: epoch  8, batch    95 | loss: 116.6632093CurrentTrain: epoch  9, batch     0 | loss: 149.9089301CurrentTrain: epoch  9, batch     1 | loss: 113.6186485CurrentTrain: epoch  9, batch     2 | loss: 110.5485932CurrentTrain: epoch  9, batch     3 | loss: 155.9972227CurrentTrain: epoch  9, batch     4 | loss: 190.2599633CurrentTrain: epoch  9, batch     5 | loss: 140.4418990CurrentTrain: epoch  9, batch     6 | loss: 151.7635649CurrentTrain: epoch  9, batch     7 | loss: 105.0265489CurrentTrain: epoch  9, batch     8 | loss: 130.7903111CurrentTrain: epoch  9, batch     9 | loss: 128.4600326CurrentTrain: epoch  9, batch    10 | loss: 111.6283689CurrentTrain: epoch  9, batch    11 | loss: 120.5196121CurrentTrain: epoch  9, batch    12 | loss: 110.8882715CurrentTrain: epoch  9, batch    13 | loss: 119.4852368CurrentTrain: epoch  9, batch    14 | loss: 127.2762891CurrentTrain: epoch  9, batch    15 | loss: 105.8655221CurrentTrain: epoch  9, batch    16 | loss: 162.0436333CurrentTrain: epoch  9, batch    17 | loss: 158.9720415CurrentTrain: epoch  9, batch    18 | loss: 111.1795834CurrentTrain: epoch  9, batch    19 | loss: 139.5275358CurrentTrain: epoch  9, batch    20 | loss: 118.5736633CurrentTrain: epoch  9, batch    21 | loss: 142.2582852CurrentTrain: epoch  9, batch    22 | loss: 112.5869931CurrentTrain: epoch  9, batch    23 | loss: 128.6947777CurrentTrain: epoch  9, batch    24 | loss: 133.5482244CurrentTrain: epoch  9, batch    25 | loss: 140.3199193CurrentTrain: epoch  9, batch    26 | loss: 126.0769783CurrentTrain: epoch  9, batch    27 | loss: 203.1271244CurrentTrain: epoch  9, batch    28 | loss: 117.3350781CurrentTrain: epoch  9, batch    29 | loss: 135.0587321CurrentTrain: epoch  9, batch    30 | loss: 116.3018714CurrentTrain: epoch  9, batch    31 | loss: 106.1309062CurrentTrain: epoch  9, batch    32 | loss: 111.0067212CurrentTrain: epoch  9, batch    33 | loss: 115.5169343CurrentTrain: epoch  9, batch    34 | loss: 108.9602586CurrentTrain: epoch  9, batch    35 | loss: 109.7953948CurrentTrain: epoch  9, batch    36 | loss: 122.0740945CurrentTrain: epoch  9, batch    37 | loss: 108.6731085CurrentTrain: epoch  9, batch    38 | loss: 113.0185397CurrentTrain: epoch  9, batch    39 | loss: 151.0532345CurrentTrain: epoch  9, batch    40 | loss: 121.6621971CurrentTrain: epoch  9, batch    41 | loss: 115.0859431CurrentTrain: epoch  9, batch    42 | loss: 114.4867012CurrentTrain: epoch  9, batch    43 | loss: 112.7748451CurrentTrain: epoch  9, batch    44 | loss: 90.1054364CurrentTrain: epoch  9, batch    45 | loss: 109.2723305CurrentTrain: epoch  9, batch    46 | loss: 127.3932585CurrentTrain: epoch  9, batch    47 | loss: 100.4820038CurrentTrain: epoch  9, batch    48 | loss: 112.1837026CurrentTrain: epoch  9, batch    49 | loss: 105.4640311CurrentTrain: epoch  9, batch    50 | loss: 117.8223571CurrentTrain: epoch  9, batch    51 | loss: 114.3124648CurrentTrain: epoch  9, batch    52 | loss: 136.1372506CurrentTrain: epoch  9, batch    53 | loss: 149.9352598CurrentTrain: epoch  9, batch    54 | loss: 107.3751937CurrentTrain: epoch  9, batch    55 | loss: 125.1439619CurrentTrain: epoch  9, batch    56 | loss: 172.0784091CurrentTrain: epoch  9, batch    57 | loss: 115.6097166CurrentTrain: epoch  9, batch    58 | loss: 143.2376945CurrentTrain: epoch  9, batch    59 | loss: 112.4663584CurrentTrain: epoch  9, batch    60 | loss: 87.8030611CurrentTrain: epoch  9, batch    61 | loss: 119.0821603CurrentTrain: epoch  9, batch    62 | loss: 118.8093631CurrentTrain: epoch  9, batch    63 | loss: 145.3038193CurrentTrain: epoch  9, batch    64 | loss: 155.9469368CurrentTrain: epoch  9, batch    65 | loss: 160.9874568CurrentTrain: epoch  9, batch    66 | loss: 160.8503374CurrentTrain: epoch  9, batch    67 | loss: 136.7323734CurrentTrain: epoch  9, batch    68 | loss: 113.5459325CurrentTrain: epoch  9, batch    69 | loss: 100.9049060CurrentTrain: epoch  9, batch    70 | loss: 110.4180915CurrentTrain: epoch  9, batch    71 | loss: 108.0140746CurrentTrain: epoch  9, batch    72 | loss: 131.5956256CurrentTrain: epoch  9, batch    73 | loss: 147.1469535CurrentTrain: epoch  9, batch    74 | loss: 96.9950735CurrentTrain: epoch  9, batch    75 | loss: 93.8484365CurrentTrain: epoch  9, batch    76 | loss: 116.5938945CurrentTrain: epoch  9, batch    77 | loss: 106.6083190CurrentTrain: epoch  9, batch    78 | loss: 120.0012437CurrentTrain: epoch  9, batch    79 | loss: 107.1310873CurrentTrain: epoch  9, batch    80 | loss: 129.1064616CurrentTrain: epoch  9, batch    81 | loss: 145.3126898CurrentTrain: epoch  9, batch    82 | loss: 119.0682028CurrentTrain: epoch  9, batch    83 | loss: 111.1584262CurrentTrain: epoch  9, batch    84 | loss: 111.3247533CurrentTrain: epoch  9, batch    85 | loss: 133.1641324CurrentTrain: epoch  9, batch    86 | loss: 97.9052355CurrentTrain: epoch  9, batch    87 | loss: 165.7107442CurrentTrain: epoch  9, batch    88 | loss: 82.0956382CurrentTrain: epoch  9, batch    89 | loss: 94.7441227CurrentTrain: epoch  9, batch    90 | loss: 112.2898228CurrentTrain: epoch  9, batch    91 | loss: 152.6511456CurrentTrain: epoch  9, batch    92 | loss: 160.7316637CurrentTrain: epoch  9, batch    93 | loss: 92.3780715CurrentTrain: epoch  9, batch    94 | loss: 129.7526583CurrentTrain: epoch  9, batch    95 | loss: 141.7288100

F1 score per class: {32: np.float64(0.5513513513513514), 6: np.float64(0.8155339805825242), 19: np.float64(0.3333333333333333), 24: np.float64(0.7486033519553073), 26: np.float64(0.9230769230769231), 29: np.float64(0.8301886792452831)}
Micro-average F1 score: 0.7620927936821322
Weighted-average F1 score: 0.7659082250078002
F1 score per class: {32: np.float64(0.6138613861386139), 6: np.float64(0.8053097345132744), 19: np.float64(0.22857142857142856), 24: np.float64(0.7386363636363636), 26: np.float64(0.9285714285714286), 29: np.float64(0.8071748878923767)}
Micro-average F1 score: 0.7447392497712717
Weighted-average F1 score: 0.7313571029747976
F1 score per class: {32: np.float64(0.6138613861386139), 6: np.float64(0.8108108108108109), 19: np.float64(0.2909090909090909), 24: np.float64(0.7386363636363636), 26: np.float64(0.9230769230769231), 29: np.float64(0.8090909090909091)}
Micro-average F1 score: 0.7551401869158878
Weighted-average F1 score: 0.7485797048700621

F1 score per class: {32: np.float64(0.5513513513513514), 6: np.float64(0.8155339805825242), 19: np.float64(0.3333333333333333), 24: np.float64(0.7486033519553073), 26: np.float64(0.9230769230769231), 29: np.float64(0.8301886792452831)}
Micro-average F1 score: 0.7620927936821322
Weighted-average F1 score: 0.7659082250078002
F1 score per class: {32: np.float64(0.6138613861386139), 6: np.float64(0.8053097345132744), 19: np.float64(0.22857142857142856), 24: np.float64(0.7386363636363636), 26: np.float64(0.9285714285714286), 29: np.float64(0.8071748878923767)}
Micro-average F1 score: 0.7447392497712717
Weighted-average F1 score: 0.7313571029747976
F1 score per class: {32: np.float64(0.6138613861386139), 6: np.float64(0.8108108108108109), 19: np.float64(0.2909090909090909), 24: np.float64(0.7386363636363636), 26: np.float64(0.9230769230769231), 29: np.float64(0.8090909090909091)}
Micro-average F1 score: 0.7551401869158878
Weighted-average F1 score: 0.7485797048700621

F1 score per class: {32: np.float64(0.40963855421686746), 6: np.float64(0.7671232876712328), 19: np.float64(0.19672131147540983), 24: np.float64(0.6871794871794872), 26: np.float64(0.8571428571428571), 29: np.float64(0.64)}
Micro-average F1 score: 0.6385442514474773
Weighted-average F1 score: 0.6256882746344401
F1 score per class: {32: np.float64(0.45255474452554745), 6: np.float64(0.7398373983739838), 19: np.float64(0.13445378151260504), 24: np.float64(0.6701030927835051), 26: np.float64(0.8544600938967136), 29: np.float64(0.6101694915254238)}
Micro-average F1 score: 0.6070096942580164
Weighted-average F1 score: 0.5818558321048065
F1 score per class: {32: np.float64(0.45255474452554745), 6: np.float64(0.7531380753138075), 19: np.float64(0.16), 24: np.float64(0.6701030927835051), 26: np.float64(0.8490566037735849), 29: np.float64(0.615916955017301)}
Micro-average F1 score: 0.617737003058104
Weighted-average F1 score: 0.5962570289349689

F1 score per class: {32: np.float64(0.40963855421686746), 6: np.float64(0.7671232876712328), 19: np.float64(0.19672131147540983), 24: np.float64(0.6871794871794872), 26: np.float64(0.8571428571428571), 29: np.float64(0.64)}
Micro-average F1 score: 0.6385442514474773
Weighted-average F1 score: 0.6256882746344401
F1 score per class: {32: np.float64(0.45255474452554745), 6: np.float64(0.7398373983739838), 19: np.float64(0.13445378151260504), 24: np.float64(0.6701030927835051), 26: np.float64(0.8544600938967136), 29: np.float64(0.6101694915254238)}
Micro-average F1 score: 0.6070096942580164
Weighted-average F1 score: 0.5818558321048065
F1 score per class: {32: np.float64(0.45255474452554745), 6: np.float64(0.7531380753138075), 19: np.float64(0.16), 24: np.float64(0.6701030927835051), 26: np.float64(0.8490566037735849), 29: np.float64(0.615916955017301)}
Micro-average F1 score: 0.617737003058104
Weighted-average F1 score: 0.5962570289349689
cur_acc_wo_na:  ['0.7621']
his_acc_wo_na:  ['0.7621']
cur_acc des_wo_na:  ['0.7447']
his_acc des_wo_na:  ['0.7447']
cur_acc rrf_wo_na:  ['0.7551']
his_acc rrf_wo_na:  ['0.7551']
cur_acc_w_na:  ['0.6385']
his_acc_w_na:  ['0.6385']
cur_acc des_w_na:  ['0.6070']
his_acc des_w_na:  ['0.6070']
cur_acc rrf_w_na:  ['0.6177']
his_acc rrf_w_na:  ['0.6177']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 135.8980269CurrentTrain: epoch  0, batch     1 | loss: 159.7412531CurrentTrain: epoch  0, batch     2 | loss: 155.3836879CurrentTrain: epoch  0, batch     3 | loss: 160.4374653CurrentTrain: epoch  0, batch     4 | loss: 80.5408834CurrentTrain: epoch  1, batch     0 | loss: 131.7532526CurrentTrain: epoch  1, batch     1 | loss: 144.8360210CurrentTrain: epoch  1, batch     2 | loss: 153.8752771CurrentTrain: epoch  1, batch     3 | loss: 124.2376214CurrentTrain: epoch  1, batch     4 | loss: 111.6175201CurrentTrain: epoch  2, batch     0 | loss: 128.0558010CurrentTrain: epoch  2, batch     1 | loss: 143.3749348CurrentTrain: epoch  2, batch     2 | loss: 145.7675986CurrentTrain: epoch  2, batch     3 | loss: 127.0925856CurrentTrain: epoch  2, batch     4 | loss: 110.8034752CurrentTrain: epoch  3, batch     0 | loss: 272.2886756CurrentTrain: epoch  3, batch     1 | loss: 120.3496152CurrentTrain: epoch  3, batch     2 | loss: 116.3298338CurrentTrain: epoch  3, batch     3 | loss: 147.6528751CurrentTrain: epoch  3, batch     4 | loss: 81.8740425CurrentTrain: epoch  4, batch     0 | loss: 115.9910157CurrentTrain: epoch  4, batch     1 | loss: 132.8086243CurrentTrain: epoch  4, batch     2 | loss: 171.4716571CurrentTrain: epoch  4, batch     3 | loss: 123.6299204CurrentTrain: epoch  4, batch     4 | loss: 103.9001968CurrentTrain: epoch  5, batch     0 | loss: 149.0119075CurrentTrain: epoch  5, batch     1 | loss: 124.7619436CurrentTrain: epoch  5, batch     2 | loss: 157.7588273CurrentTrain: epoch  5, batch     3 | loss: 118.9220483CurrentTrain: epoch  5, batch     4 | loss: 96.0910594CurrentTrain: epoch  6, batch     0 | loss: 125.7836619CurrentTrain: epoch  6, batch     1 | loss: 158.6368353CurrentTrain: epoch  6, batch     2 | loss: 115.0735739CurrentTrain: epoch  6, batch     3 | loss: 160.3632999CurrentTrain: epoch  6, batch     4 | loss: 88.2486543CurrentTrain: epoch  7, batch     0 | loss: 114.2947701CurrentTrain: epoch  7, batch     1 | loss: 142.1474158CurrentTrain: epoch  7, batch     2 | loss: 104.9235102CurrentTrain: epoch  7, batch     3 | loss: 127.0105929CurrentTrain: epoch  7, batch     4 | loss: 162.6559993CurrentTrain: epoch  8, batch     0 | loss: 109.2583796CurrentTrain: epoch  8, batch     1 | loss: 165.6626905CurrentTrain: epoch  8, batch     2 | loss: 115.1658234CurrentTrain: epoch  8, batch     3 | loss: 121.2229542CurrentTrain: epoch  8, batch     4 | loss: 94.1346550CurrentTrain: epoch  9, batch     0 | loss: 102.0960267CurrentTrain: epoch  9, batch     1 | loss: 129.9417951CurrentTrain: epoch  9, batch     2 | loss: 120.1832917CurrentTrain: epoch  9, batch     3 | loss: 146.3878391CurrentTrain: epoch  9, batch     4 | loss: 102.5746269
MemoryTrain:  epoch  0, batch     0 | loss: 1.8132291MemoryTrain:  epoch  1, batch     0 | loss: 1.5563073MemoryTrain:  epoch  2, batch     0 | loss: 1.4279197MemoryTrain:  epoch  3, batch     0 | loss: 1.0965688MemoryTrain:  epoch  4, batch     0 | loss: 0.9097867MemoryTrain:  epoch  5, batch     0 | loss: 0.7847627MemoryTrain:  epoch  6, batch     0 | loss: 0.6536301MemoryTrain:  epoch  7, batch     0 | loss: 0.4823102MemoryTrain:  epoch  8, batch     0 | loss: 0.3791146MemoryTrain:  epoch  9, batch     0 | loss: 0.3315262

F1 score per class: {32: np.float64(0.8737864077669902), 5: np.float64(0.0), 6: np.float64(0.09174311926605505), 10: np.float64(0.6274509803921569), 16: np.float64(0.18181818181818182), 17: np.float64(0.2727272727272727), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5209713024282561
Weighted-average F1 score: 0.6152330234895934
F1 score per class: {32: np.float64(0.6810035842293907), 5: np.float64(0.0), 6: np.float64(0.46153846153846156), 10: np.float64(0.6206896551724138), 16: np.float64(0.5), 17: np.float64(0.4528301886792453), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5210843373493976
Weighted-average F1 score: 0.49451131130646986
F1 score per class: {32: np.float64(0.7833333333333333), 5: np.float64(0.0), 6: np.float64(0.45714285714285713), 10: np.float64(0.6206896551724138), 16: np.float64(0.5), 17: np.float64(0.37037037037037035), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5557461406518011
Weighted-average F1 score: 0.5313615231058789

F1 score per class: {32: np.float64(0.8737864077669902), 5: np.float64(0.5102040816326531), 6: np.float64(0.08928571428571429), 10: np.float64(0.6274509803921569), 16: np.float64(0.06896551724137931), 17: np.float64(0.2608695652173913), 18: np.float64(0.7469879518072289), 19: np.float64(0.2978723404255319), 24: np.float64(0.7407407407407407), 26: np.float64(0.8934010152284264), 29: np.float64(0.7947598253275109)}
Micro-average F1 score: 0.6666666666666666
Weighted-average F1 score: 0.7062421812594892
F1 score per class: {32: np.float64(0.6484641638225256), 5: np.float64(0.5410628019323671), 6: np.float64(0.42038216560509556), 10: np.float64(0.5806451612903226), 16: np.float64(0.14634146341463414), 17: np.float64(0.384), 18: np.float64(0.6713286713286714), 19: np.float64(0.21359223300970873), 24: np.float64(0.7010309278350515), 26: np.float64(0.9073170731707317), 29: np.float64(0.7509881422924901)}
Micro-average F1 score: 0.6147455867082036
Weighted-average F1 score: 0.6034925063583838
F1 score per class: {32: np.float64(0.7704918032786885), 5: np.float64(0.5436893203883495), 6: np.float64(0.41830065359477125), 10: np.float64(0.5806451612903226), 16: np.float64(0.15384615384615385), 17: np.float64(0.33707865168539325), 18: np.float64(0.6861313868613139), 19: np.float64(0.3055555555555556), 24: np.float64(0.7040816326530612), 26: np.float64(0.9019607843137255), 29: np.float64(0.7800829875518672)}
Micro-average F1 score: 0.6494382022471911
Weighted-average F1 score: 0.6478197391482128

F1 score per class: {32: np.float64(0.7725321888412017), 5: np.float64(0.0), 6: np.float64(0.08849557522123894), 10: np.float64(0.41025641025641024), 16: np.float64(0.125), 17: np.float64(0.19672131147540983), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.4097222222222222
Weighted-average F1 score: 0.4306194758715782
F1 score per class: {32: np.float64(0.547550432276657), 5: np.float64(0.0), 6: np.float64(0.3793103448275862), 10: np.float64(0.4), 16: np.float64(0.2857142857142857), 17: np.float64(0.27586206896551724), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.36886993603411516
Weighted-average F1 score: 0.3452199352967114
F1 score per class: {32: np.float64(0.6351351351351351), 5: np.float64(0.0), 6: np.float64(0.38323353293413176), 10: np.float64(0.4044943820224719), 16: np.float64(0.3), 17: np.float64(0.24390243902439024), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.40198511166253104
Weighted-average F1 score: 0.3741583235632014

F1 score per class: {32: np.float64(0.7692307692307693), 5: np.float64(0.352112676056338), 6: np.float64(0.08620689655172414), 10: np.float64(0.3902439024390244), 16: np.float64(0.047619047619047616), 17: np.float64(0.18461538461538463), 18: np.float64(0.6739130434782609), 19: np.float64(0.15384615384615385), 24: np.float64(0.6451612903225806), 26: np.float64(0.7892376681614349), 29: np.float64(0.6232876712328768)}
Micro-average F1 score: 0.5379812695109261
Weighted-average F1 score: 0.5481818351018257
F1 score per class: {32: np.float64(0.5), 5: np.float64(0.3393939393939394), 6: np.float64(0.3188405797101449), 10: np.float64(0.3564356435643564), 16: np.float64(0.09523809523809523), 17: np.float64(0.22325581395348837), 18: np.float64(0.5853658536585366), 19: np.float64(0.12222222222222222), 24: np.float64(0.5964912280701754), 26: np.float64(0.7591836734693878), 29: np.float64(0.5688622754491018)}
Micro-average F1 score: 0.4534661049406358
Weighted-average F1 score: 0.43763102242406093
F1 score per class: {32: np.float64(0.5987261146496815), 5: np.float64(0.3404255319148936), 6: np.float64(0.3282051282051282), 10: np.float64(0.36), 16: np.float64(0.10344827586206896), 17: np.float64(0.21428571428571427), 18: np.float64(0.6025641025641025), 19: np.float64(0.16541353383458646), 24: np.float64(0.5974025974025974), 26: np.float64(0.7763713080168776), 29: np.float64(0.5856697819314641)}
Micro-average F1 score: 0.4877637130801688
Weighted-average F1 score: 0.4761589429004904
cur_acc_wo_na:  ['0.7621', '0.5210']
his_acc_wo_na:  ['0.7621', '0.6667']
cur_acc des_wo_na:  ['0.7447', '0.5211']
his_acc des_wo_na:  ['0.7447', '0.6147']
cur_acc rrf_wo_na:  ['0.7551', '0.5557']
his_acc rrf_wo_na:  ['0.7551', '0.6494']
cur_acc_w_na:  ['0.6385', '0.4097']
his_acc_w_na:  ['0.6385', '0.5380']
cur_acc des_w_na:  ['0.6070', '0.3689']
his_acc des_w_na:  ['0.6070', '0.4535']
cur_acc rrf_w_na:  ['0.6177', '0.4020']
his_acc rrf_w_na:  ['0.6177', '0.4878']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 131.0470241CurrentTrain: epoch  0, batch     1 | loss: 139.2807589CurrentTrain: epoch  0, batch     2 | loss: 150.3655352CurrentTrain: epoch  0, batch     3 | loss: 119.2035905CurrentTrain: epoch  0, batch     4 | loss: 41.3147296CurrentTrain: epoch  1, batch     0 | loss: 132.8099277CurrentTrain: epoch  1, batch     1 | loss: 125.0277785CurrentTrain: epoch  1, batch     2 | loss: 136.9483616CurrentTrain: epoch  1, batch     3 | loss: 127.9605990CurrentTrain: epoch  1, batch     4 | loss: 39.1971660CurrentTrain: epoch  2, batch     0 | loss: 143.6562445CurrentTrain: epoch  2, batch     1 | loss: 138.9983117CurrentTrain: epoch  2, batch     2 | loss: 143.8844304CurrentTrain: epoch  2, batch     3 | loss: 103.9655867CurrentTrain: epoch  2, batch     4 | loss: 27.2622670CurrentTrain: epoch  3, batch     0 | loss: 130.2929488CurrentTrain: epoch  3, batch     1 | loss: 116.1699627CurrentTrain: epoch  3, batch     2 | loss: 146.5684857CurrentTrain: epoch  3, batch     3 | loss: 124.2839893CurrentTrain: epoch  3, batch     4 | loss: 17.7471740CurrentTrain: epoch  4, batch     0 | loss: 147.5084935CurrentTrain: epoch  4, batch     1 | loss: 121.2028541CurrentTrain: epoch  4, batch     2 | loss: 106.0247634CurrentTrain: epoch  4, batch     3 | loss: 127.0606278CurrentTrain: epoch  4, batch     4 | loss: 41.9186399CurrentTrain: epoch  5, batch     0 | loss: 118.2679503CurrentTrain: epoch  5, batch     1 | loss: 137.6331820CurrentTrain: epoch  5, batch     2 | loss: 132.3259028CurrentTrain: epoch  5, batch     3 | loss: 127.0744894CurrentTrain: epoch  5, batch     4 | loss: 47.5216804CurrentTrain: epoch  6, batch     0 | loss: 113.7430600CurrentTrain: epoch  6, batch     1 | loss: 129.3246104CurrentTrain: epoch  6, batch     2 | loss: 122.1942861CurrentTrain: epoch  6, batch     3 | loss: 146.1639330CurrentTrain: epoch  6, batch     4 | loss: 20.6623015CurrentTrain: epoch  7, batch     0 | loss: 144.1879329CurrentTrain: epoch  7, batch     1 | loss: 144.6601687CurrentTrain: epoch  7, batch     2 | loss: 95.2384831CurrentTrain: epoch  7, batch     3 | loss: 164.6502766CurrentTrain: epoch  7, batch     4 | loss: 27.4179092CurrentTrain: epoch  8, batch     0 | loss: 139.1115153CurrentTrain: epoch  8, batch     1 | loss: 127.7374853CurrentTrain: epoch  8, batch     2 | loss: 107.3567916CurrentTrain: epoch  8, batch     3 | loss: 117.0410170CurrentTrain: epoch  8, batch     4 | loss: 30.9318754CurrentTrain: epoch  9, batch     0 | loss: 124.8555592CurrentTrain: epoch  9, batch     1 | loss: 120.2996426CurrentTrain: epoch  9, batch     2 | loss: 117.3399981CurrentTrain: epoch  9, batch     3 | loss: 123.8014547CurrentTrain: epoch  9, batch     4 | loss: 32.2057029
MemoryTrain:  epoch  0, batch     0 | loss: 1.4982227MemoryTrain:  epoch  1, batch     0 | loss: 1.4100405MemoryTrain:  epoch  2, batch     0 | loss: 1.0647878MemoryTrain:  epoch  3, batch     0 | loss: 0.8858462MemoryTrain:  epoch  4, batch     0 | loss: 0.7450834MemoryTrain:  epoch  5, batch     0 | loss: 0.5858225MemoryTrain:  epoch  6, batch     0 | loss: 0.5288064MemoryTrain:  epoch  7, batch     0 | loss: 0.4073241MemoryTrain:  epoch  8, batch     0 | loss: 0.3508522MemoryTrain:  epoch  9, batch     0 | loss: 0.3081348

F1 score per class: {32: np.float64(0.47058823529411764), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.6153846153846154), 39: np.float64(0.543046357615894), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.25806451612903225), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.17142857142857143)}
Micro-average F1 score: 0.4576659038901602
Weighted-average F1 score: 0.3800078341187391
F1 score per class: {32: np.float64(0.5384615384615384), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.5806451612903226), 11: np.float64(0.6067415730337079), 12: np.float64(0.0), 10: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.37037037037037035), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.35555555555555557)}
Micro-average F1 score: 0.45857418111753373
Weighted-average F1 score: 0.3781405797206208
F1 score per class: {32: np.float64(0.5555555555555556), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.5822784810126582), 11: np.float64(0.6057142857142858), 12: np.float64(0.0), 10: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.3125), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.35)}
Micro-average F1 score: 0.4773662551440329
Weighted-average F1 score: 0.4037006183500281

F1 score per class: {32: np.float64(0.42105263157894735), 2: np.float64(0.9117647058823529), 5: np.float64(0.5288461538461539), 6: np.float64(0.07547169811320754), 39: np.float64(0.3779527559055118), 11: np.float64(0.34309623430962344), 12: np.float64(0.4897959183673469), 10: np.float64(0.0), 16: np.float64(0.038461538461538464), 17: np.float64(0.7698744769874477), 18: np.float64(0.38095238095238093), 19: np.float64(0.7283236994219653), 24: np.float64(0.1), 26: np.float64(0.8022598870056498), 28: np.float64(0.759493670886076), 29: np.float64(0.13043478260869565)}
Micro-average F1 score: 0.5520149953139644
Weighted-average F1 score: 0.5561440203952676
F1 score per class: {32: np.float64(0.45161290322580644), 2: np.float64(0.6575342465753424), 5: np.float64(0.5511811023622047), 6: np.float64(0.35135135135135137), 39: np.float64(0.391304347826087), 11: np.float64(0.34177215189873417), 12: np.float64(0.6153846153846154), 10: np.float64(0.0), 16: np.float64(0.2857142857142857), 17: np.float64(0.7153846153846154), 18: np.float64(0.2127659574468085), 19: np.float64(0.7204301075268817), 24: np.float64(0.16666666666666666), 26: np.float64(0.8202247191011236), 28: np.float64(0.6375838926174496), 29: np.float64(0.24242424242424243)}
Micro-average F1 score: 0.5299882399059193
Weighted-average F1 score: 0.517792233801183
F1 score per class: {32: np.float64(0.5), 2: np.float64(0.811965811965812), 5: np.float64(0.5569620253164557), 6: np.float64(0.25806451612903225), 39: np.float64(0.38016528925619836), 11: np.float64(0.34868421052631576), 12: np.float64(0.5306122448979592), 10: np.float64(0.0), 16: np.float64(0.2903225806451613), 17: np.float64(0.7401574803149606), 18: np.float64(0.3389830508474576), 19: np.float64(0.717391304347826), 24: np.float64(0.136986301369863), 26: np.float64(0.8202247191011236), 28: np.float64(0.6738351254480287), 29: np.float64(0.23333333333333334)}
Micro-average F1 score: 0.5506756756756757
Weighted-average F1 score: 0.5433154098943244

F1 score per class: {32: np.float64(0.3333333333333333), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.5133689839572193), 39: np.float64(0.44565217391304346), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.14545454545454545), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0967741935483871)}
Micro-average F1 score: 0.33112582781456956
Weighted-average F1 score: 0.2720515245380431
F1 score per class: {32: np.float64(0.3111111111111111), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.4891304347826087), 11: np.float64(0.484304932735426), 12: np.float64(0.0), 10: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.17857142857142858), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.21333333333333335)}
Micro-average F1 score: 0.31029986962190353
Weighted-average F1 score: 0.2542167707488134
F1 score per class: {32: np.float64(0.38461538461538464), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.48677248677248675), 11: np.float64(0.4818181818181818), 12: np.float64(0.0), 10: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.15151515151515152), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.2)}
Micro-average F1 score: 0.32492997198879553
Weighted-average F1 score: 0.2697142289061481

F1 score per class: {32: np.float64(0.2857142857142857), 2: np.float64(0.8017241379310345), 5: np.float64(0.31976744186046513), 6: np.float64(0.07547169811320754), 39: np.float64(0.28152492668621704), 11: np.float64(0.18061674008810572), 12: np.float64(0.3380281690140845), 10: np.float64(0.0), 16: np.float64(0.02666666666666667), 17: np.float64(0.696969696969697), 18: np.float64(0.2191780821917808), 19: np.float64(0.6666666666666666), 24: np.float64(0.05517241379310345), 26: np.float64(0.7357512953367875), 28: np.float64(0.5825242718446602), 29: np.float64(0.061855670103092786)}
Micro-average F1 score: 0.4017735334242838
Weighted-average F1 score: 0.3795336670613822
F1 score per class: {32: np.float64(0.22950819672131148), 2: np.float64(0.4444444444444444), 5: np.float64(0.31890660592255127), 6: np.float64(0.27807486631016043), 39: np.float64(0.30303030303030304), 10: np.float64(0.1888111888111888), 12: np.float64(0.4155844155844156), 11: np.float64(0.0), 16: np.float64(0.16417910447761194), 17: np.float64(0.6391752577319587), 18: np.float64(0.11834319526627218), 19: np.float64(0.6442307692307693), 24: np.float64(0.09433962264150944), 26: np.float64(0.7487179487179487), 28: np.float64(0.475), 29: np.float64(0.1322314049586777)}
Micro-average F1 score: 0.3654054054054054
Weighted-average F1 score: 0.34471654557029724
F1 score per class: {32: np.float64(0.3333333333333333), 2: np.float64(0.5654761904761905), 5: np.float64(0.3316582914572864), 6: np.float64(0.24060150375939848), 39: np.float64(0.2893081761006289), 11: np.float64(0.1889483065953654), 12: np.float64(0.3611111111111111), 10: np.float64(0.0), 16: np.float64(0.16363636363636364), 17: np.float64(0.6643109540636042), 18: np.float64(0.17857142857142858), 19: np.float64(0.6407766990291263), 24: np.float64(0.07246376811594203), 26: np.float64(0.7487179487179487), 28: np.float64(0.5150684931506849), 29: np.float64(0.11965811965811966)}
Micro-average F1 score: 0.38522895125553913
Weighted-average F1 score: 0.36409272911293356
cur_acc_wo_na:  ['0.7621', '0.5210', '0.4577']
his_acc_wo_na:  ['0.7621', '0.6667', '0.5520']
cur_acc des_wo_na:  ['0.7447', '0.5211', '0.4586']
his_acc des_wo_na:  ['0.7447', '0.6147', '0.5300']
cur_acc rrf_wo_na:  ['0.7551', '0.5557', '0.4774']
his_acc rrf_wo_na:  ['0.7551', '0.6494', '0.5507']
cur_acc_w_na:  ['0.6385', '0.4097', '0.3311']
his_acc_w_na:  ['0.6385', '0.5380', '0.4018']
cur_acc des_w_na:  ['0.6070', '0.3689', '0.3103']
his_acc des_w_na:  ['0.6070', '0.4535', '0.3654']
cur_acc rrf_w_na:  ['0.6177', '0.4020', '0.3249']
his_acc rrf_w_na:  ['0.6177', '0.4878', '0.3852']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 147.8068269CurrentTrain: epoch  0, batch     1 | loss: 161.4446209CurrentTrain: epoch  0, batch     2 | loss: 134.2580938CurrentTrain: epoch  0, batch     3 | loss: 134.2626349CurrentTrain: epoch  1, batch     0 | loss: 122.3607395CurrentTrain: epoch  1, batch     1 | loss: 127.1696605CurrentTrain: epoch  1, batch     2 | loss: 145.4360778CurrentTrain: epoch  1, batch     3 | loss: 117.2942828CurrentTrain: epoch  2, batch     0 | loss: 148.5712579CurrentTrain: epoch  2, batch     1 | loss: 128.3849622CurrentTrain: epoch  2, batch     2 | loss: 132.2140710CurrentTrain: epoch  2, batch     3 | loss: 110.6211119CurrentTrain: epoch  3, batch     0 | loss: 144.6885105CurrentTrain: epoch  3, batch     1 | loss: 138.2996085CurrentTrain: epoch  3, batch     2 | loss: 127.2603573CurrentTrain: epoch  3, batch     3 | loss: 105.0618420CurrentTrain: epoch  4, batch     0 | loss: 142.8069914CurrentTrain: epoch  4, batch     1 | loss: 134.6367954CurrentTrain: epoch  4, batch     2 | loss: 116.3260600CurrentTrain: epoch  4, batch     3 | loss: 109.5696477CurrentTrain: epoch  5, batch     0 | loss: 125.3799780CurrentTrain: epoch  5, batch     1 | loss: 151.3246856CurrentTrain: epoch  5, batch     2 | loss: 133.5517594CurrentTrain: epoch  5, batch     3 | loss: 96.6099366CurrentTrain: epoch  6, batch     0 | loss: 105.0785261CurrentTrain: epoch  6, batch     1 | loss: 123.6030519CurrentTrain: epoch  6, batch     2 | loss: 114.4829555CurrentTrain: epoch  6, batch     3 | loss: 165.9299315CurrentTrain: epoch  7, batch     0 | loss: 139.6090877CurrentTrain: epoch  7, batch     1 | loss: 139.4711163CurrentTrain: epoch  7, batch     2 | loss: 115.9291347CurrentTrain: epoch  7, batch     3 | loss: 105.7901403CurrentTrain: epoch  8, batch     0 | loss: 108.2518517CurrentTrain: epoch  8, batch     1 | loss: 107.6095489CurrentTrain: epoch  8, batch     2 | loss: 130.1773538CurrentTrain: epoch  8, batch     3 | loss: 115.0696120CurrentTrain: epoch  9, batch     0 | loss: 103.6281993CurrentTrain: epoch  9, batch     1 | loss: 93.8607201CurrentTrain: epoch  9, batch     2 | loss: 195.1219378CurrentTrain: epoch  9, batch     3 | loss: 131.3836583
MemoryTrain:  epoch  0, batch     0 | loss: 1.2436132MemoryTrain:  epoch  1, batch     0 | loss: 1.1583501MemoryTrain:  epoch  2, batch     0 | loss: 0.8510950MemoryTrain:  epoch  3, batch     0 | loss: 0.7489108MemoryTrain:  epoch  4, batch     0 | loss: 0.5736822MemoryTrain:  epoch  5, batch     0 | loss: 0.5158833MemoryTrain:  epoch  6, batch     0 | loss: 0.4555754MemoryTrain:  epoch  7, batch     0 | loss: 0.3777560MemoryTrain:  epoch  8, batch     0 | loss: 0.3346353MemoryTrain:  epoch  9, batch     0 | loss: 0.3386662

F1 score per class: {0: np.float64(0.835820895522388), 2: np.float64(0.0), 4: np.float64(0.8603351955307262), 5: np.float64(0.0), 6: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.2857142857142857), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.5205479452054794), 23: np.float64(0.8536585365853658), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.6571428571428571
Weighted-average F1 score: 0.5457540680116502
F1 score per class: {0: np.float64(0.8148148148148148), 2: np.float64(0.0), 4: np.float64(0.8393782383419689), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.26666666666666666), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.5054945054945055), 23: np.float64(0.7441860465116279), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5445859872611465
Weighted-average F1 score: 0.43120985497045455
F1 score per class: {0: np.float64(0.8450704225352113), 2: np.float64(0.0), 4: np.float64(0.8804347826086957), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.26666666666666666), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.48936170212765956), 23: np.float64(0.7804878048780488), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5823223570190641
Weighted-average F1 score: 0.45799003690971585

F1 score per class: {0: np.float64(0.691358024691358), 2: np.float64(0.48), 4: np.float64(0.8555555555555555), 5: np.float64(0.832579185520362), 6: np.float64(0.5361702127659574), 10: np.float64(0.16216216216216217), 11: np.float64(0.3794466403162055), 12: np.float64(0.32160804020100503), 13: np.float64(0.044444444444444446), 16: np.float64(0.6037735849056604), 17: np.float64(0.0), 18: np.float64(0.25396825396825395), 19: np.float64(0.75), 21: np.float64(0.3114754098360656), 23: np.float64(0.8235294117647058), 24: np.float64(0.0), 26: np.float64(0.7314285714285714), 28: np.float64(0.14634146341463414), 29: np.float64(0.8465608465608465), 32: np.float64(0.7385892116182573), 39: np.float64(0.15384615384615385)}
Micro-average F1 score: 0.5705794947994056
Weighted-average F1 score: 0.5591669753749706
F1 score per class: {0: np.float64(0.5454545454545454), 2: np.float64(0.3181818181818182), 4: np.float64(0.7641509433962265), 5: np.float64(0.5969230769230769), 6: np.float64(0.48366013071895425), 10: np.float64(0.38095238095238093), 11: np.float64(0.3597122302158273), 12: np.float64(0.3503184713375796), 13: np.float64(0.06666666666666667), 16: np.float64(0.6428571428571429), 17: np.float64(0.0), 18: np.float64(0.25806451612903225), 19: np.float64(0.6931407942238267), 21: np.float64(0.24864864864864866), 23: np.float64(0.6956521739130435), 24: np.float64(0.23076923076923078), 26: np.float64(0.6598984771573604), 28: np.float64(0.16326530612244897), 29: np.float64(0.8315789473684211), 32: np.float64(0.6418918918918919), 39: np.float64(0.21782178217821782)}
Micro-average F1 score: 0.50767004341534
Weighted-average F1 score: 0.4864841085721949
F1 score per class: {0: np.float64(0.625), 2: np.float64(0.358974358974359), 4: np.float64(0.8571428571428571), 5: np.float64(0.7404580152671756), 6: np.float64(0.5106382978723404), 10: np.float64(0.33766233766233766), 11: np.float64(0.35587188612099646), 12: np.float64(0.35335689045936397), 13: np.float64(0.04938271604938271), 16: np.float64(0.6181818181818182), 17: np.float64(0.0), 18: np.float64(0.358974358974359), 19: np.float64(0.7121212121212122), 21: np.float64(0.25842696629213485), 23: np.float64(0.7441860465116279), 24: np.float64(0.17391304347826086), 26: np.float64(0.7096774193548387), 28: np.float64(0.125), 29: np.float64(0.8359788359788359), 32: np.float64(0.6934306569343066), 39: np.float64(0.2222222222222222)}
Micro-average F1 score: 0.5395614871306006
Weighted-average F1 score: 0.5135720517600214

F1 score per class: {0: np.float64(0.7887323943661971), 2: np.float64(0.0), 4: np.float64(0.8191489361702128), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.17391304347826086), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.36538461538461536), 23: np.float64(0.7865168539325843), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5039123630672926
Weighted-average F1 score: 0.3860124758049728
F1 score per class: {0: np.float64(0.7415730337078652), 2: np.float64(0.0), 4: np.float64(0.7714285714285715), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.17391304347826086), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3709677419354839), 23: np.float64(0.6666666666666666), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.37831858407079644
Weighted-average F1 score: 0.28321058780588776
F1 score per class: {0: np.float64(0.7792207792207793), 2: np.float64(0.0), 4: np.float64(0.8350515463917526), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.16), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.36507936507936506), 23: np.float64(0.7032967032967034), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.41379310344827586
Weighted-average F1 score: 0.3015055256034637

F1 score per class: {0: np.float64(0.5957446808510638), 2: np.float64(0.2926829268292683), 4: np.float64(0.7623762376237624), 5: np.float64(0.6433566433566433), 6: np.float64(0.30656934306569344), 10: np.float64(0.15254237288135594), 11: np.float64(0.2882882882882883), 12: np.float64(0.1855072463768116), 13: np.float64(0.024096385542168676), 16: np.float64(0.3950617283950617), 17: np.float64(0.0), 18: np.float64(0.14678899082568808), 19: np.float64(0.6619217081850534), 21: np.float64(0.19895287958115182), 23: np.float64(0.7216494845360825), 24: np.float64(0.0), 26: np.float64(0.6597938144329897), 28: np.float64(0.08955223880597014), 29: np.float64(0.7407407407407407), 32: np.float64(0.5760517799352751), 39: np.float64(0.08333333333333333)}
Micro-average F1 score: 0.4187568157033806
Weighted-average F1 score: 0.3933044215114604
F1 score per class: {0: np.float64(0.42857142857142855), 2: np.float64(0.19718309859154928), 4: np.float64(0.6183206106870229), 5: np.float64(0.3688212927756654), 6: np.float64(0.26763110307414106), 10: np.float64(0.2647058823529412), 11: np.float64(0.2840909090909091), 12: np.float64(0.18003273322422259), 13: np.float64(0.039603960396039604), 16: np.float64(0.41379310344827586), 17: np.float64(0.0), 18: np.float64(0.14285714285714285), 19: np.float64(0.5907692307692308), 21: np.float64(0.15593220338983052), 23: np.float64(0.5765765765765766), 24: np.float64(0.13953488372093023), 26: np.float64(0.5803571428571429), 28: np.float64(0.07407407407407407), 29: np.float64(0.7348837209302326), 32: np.float64(0.47381546134663344), 39: np.float64(0.10891089108910891)}
Micro-average F1 score: 0.33959341723136494
Weighted-average F1 score: 0.3176436912216853
F1 score per class: {0: np.float64(0.5128205128205128), 2: np.float64(0.2222222222222222), 4: np.float64(0.7431192660550459), 5: np.float64(0.4674698795180723), 6: np.float64(0.28857715430861725), 10: np.float64(0.2708333333333333), 11: np.float64(0.27624309392265195), 12: np.float64(0.18083182640144665), 13: np.float64(0.02702702702702703), 16: np.float64(0.40476190476190477), 17: np.float64(0.0), 18: np.float64(0.1686746987951807), 19: np.float64(0.6084142394822006), 21: np.float64(0.1602787456445993), 23: np.float64(0.6213592233009708), 24: np.float64(0.1111111111111111), 26: np.float64(0.616822429906542), 28: np.float64(0.06349206349206349), 29: np.float64(0.7314814814814815), 32: np.float64(0.510752688172043), 39: np.float64(0.10666666666666667)}
Micro-average F1 score: 0.3653184165232358
Weighted-average F1 score: 0.3379775309838235
cur_acc_wo_na:  ['0.7621', '0.5210', '0.4577', '0.6571']
his_acc_wo_na:  ['0.7621', '0.6667', '0.5520', '0.5706']
cur_acc des_wo_na:  ['0.7447', '0.5211', '0.4586', '0.5446']
his_acc des_wo_na:  ['0.7447', '0.6147', '0.5300', '0.5077']
cur_acc rrf_wo_na:  ['0.7551', '0.5557', '0.4774', '0.5823']
his_acc rrf_wo_na:  ['0.7551', '0.6494', '0.5507', '0.5396']
cur_acc_w_na:  ['0.6385', '0.4097', '0.3311', '0.5039']
his_acc_w_na:  ['0.6385', '0.5380', '0.4018', '0.4188']
cur_acc des_w_na:  ['0.6070', '0.3689', '0.3103', '0.3783']
his_acc des_w_na:  ['0.6070', '0.4535', '0.3654', '0.3396']
cur_acc rrf_w_na:  ['0.6177', '0.4020', '0.3249', '0.4138']
his_acc rrf_w_na:  ['0.6177', '0.4878', '0.3852', '0.3653']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 119.3477149CurrentTrain: epoch  0, batch     1 | loss: 150.3124994CurrentTrain: epoch  0, batch     2 | loss: 132.0372876CurrentTrain: epoch  0, batch     3 | loss: 107.0333343CurrentTrain: epoch  1, batch     0 | loss: 132.4099939CurrentTrain: epoch  1, batch     1 | loss: 114.4843006CurrentTrain: epoch  1, batch     2 | loss: 173.7701452CurrentTrain: epoch  1, batch     3 | loss: 77.1061118CurrentTrain: epoch  2, batch     0 | loss: 142.1602481CurrentTrain: epoch  2, batch     1 | loss: 121.1733734CurrentTrain: epoch  2, batch     2 | loss: 111.0074520CurrentTrain: epoch  2, batch     3 | loss: 100.6173865CurrentTrain: epoch  3, batch     0 | loss: 122.7030467CurrentTrain: epoch  3, batch     1 | loss: 119.1719131CurrentTrain: epoch  3, batch     2 | loss: 124.8910260CurrentTrain: epoch  3, batch     3 | loss: 108.2464615CurrentTrain: epoch  4, batch     0 | loss: 122.9201657CurrentTrain: epoch  4, batch     1 | loss: 134.0623953CurrentTrain: epoch  4, batch     2 | loss: 108.7571208CurrentTrain: epoch  4, batch     3 | loss: 79.9969100CurrentTrain: epoch  5, batch     0 | loss: 128.2226058CurrentTrain: epoch  5, batch     1 | loss: 111.8779446CurrentTrain: epoch  5, batch     2 | loss: 123.9502223CurrentTrain: epoch  5, batch     3 | loss: 101.4045267CurrentTrain: epoch  6, batch     0 | loss: 107.2254721CurrentTrain: epoch  6, batch     1 | loss: 108.3204712CurrentTrain: epoch  6, batch     2 | loss: 147.5314867CurrentTrain: epoch  6, batch     3 | loss: 83.1879388CurrentTrain: epoch  7, batch     0 | loss: 114.0325347CurrentTrain: epoch  7, batch     1 | loss: 121.9199616CurrentTrain: epoch  7, batch     2 | loss: 136.2083887CurrentTrain: epoch  7, batch     3 | loss: 87.6062404CurrentTrain: epoch  8, batch     0 | loss: 142.1114815CurrentTrain: epoch  8, batch     1 | loss: 106.9427534CurrentTrain: epoch  8, batch     2 | loss: 113.3079216CurrentTrain: epoch  8, batch     3 | loss: 92.2857910CurrentTrain: epoch  9, batch     0 | loss: 122.9231392CurrentTrain: epoch  9, batch     1 | loss: 123.4670727CurrentTrain: epoch  9, batch     2 | loss: 125.7914545CurrentTrain: epoch  9, batch     3 | loss: 64.8031234
MemoryTrain:  epoch  0, batch     0 | loss: 1.0137594MemoryTrain:  epoch  1, batch     0 | loss: 0.9764199MemoryTrain:  epoch  2, batch     0 | loss: 0.7601898MemoryTrain:  epoch  3, batch     0 | loss: 0.6656539MemoryTrain:  epoch  4, batch     0 | loss: 0.5151369MemoryTrain:  epoch  5, batch     0 | loss: 0.4117439MemoryTrain:  epoch  6, batch     0 | loss: 0.4183737MemoryTrain:  epoch  7, batch     0 | loss: 0.3298068MemoryTrain:  epoch  8, batch     0 | loss: 0.2835099MemoryTrain:  epoch  9, batch     0 | loss: 0.2620338

F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.8), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.4), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.4225352112676056), 37: np.float64(0.5405405405405406), 38: np.float64(0.7636363636363637), 39: np.float64(0.0)}
Micro-average F1 score: 0.424390243902439
Weighted-average F1 score: 0.33414571105790186
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.631578947368421), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.6190476190476191), 26: np.float64(0.0), 28: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.7289719626168224), 37: np.float64(0.5714285714285714), 38: np.float64(0.8), 39: np.float64(0.0)}
Micro-average F1 score: 0.4642233856893543
Weighted-average F1 score: 0.3592216396684607
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.6), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.5974025974025974), 26: np.float64(0.0), 28: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6436781609195402), 37: np.float64(0.5846153846153846), 38: np.float64(0.7868852459016393), 39: np.float64(0.0)}
Micro-average F1 score: 0.4621359223300971
Weighted-average F1 score: 0.35349607887260964

F1 score per class: {0: np.float64(0.7160493827160493), 2: np.float64(0.42857142857142855), 4: np.float64(0.7730061349693251), 5: np.float64(0.8193832599118943), 6: np.float64(0.5084745762711864), 10: np.float64(0.07476635514018691), 11: np.float64(0.43548387096774194), 12: np.float64(0.28415300546448086), 13: np.float64(0.0380952380952381), 15: np.float64(0.25806451612903225), 16: np.float64(0.6101694915254238), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.7142857142857143), 21: np.float64(0.3076923076923077), 23: np.float64(0.8045977011494253), 24: np.float64(0.0), 25: np.float64(0.4), 26: np.float64(0.7191011235955056), 28: np.float64(0.16), 29: np.float64(0.8541666666666666), 32: np.float64(0.7109375), 35: np.float64(0.32967032967032966), 37: np.float64(0.17142857142857143), 38: np.float64(0.3181818181818182), 39: np.float64(0.16279069767441862)}
Micro-average F1 score: 0.4911206368646663
Weighted-average F1 score: 0.4698150624133506
F1 score per class: {0: np.float64(0.5517241379310345), 2: np.float64(0.2692307692307692), 4: np.float64(0.7956989247311828), 5: np.float64(0.5764705882352941), 6: np.float64(0.4873417721518987), 10: np.float64(0.28), 11: np.float64(0.4580152671755725), 12: np.float64(0.3176470588235294), 13: np.float64(0.05172413793103448), 15: np.float64(0.2926829268292683), 16: np.float64(0.6349206349206349), 17: np.float64(0.0), 18: np.float64(0.1694915254237288), 19: np.float64(0.6813186813186813), 21: np.float64(0.19913419913419914), 23: np.float64(0.8), 24: np.float64(0.24242424242424243), 25: np.float64(0.6190476190476191), 26: np.float64(0.6865671641791045), 28: np.float64(0.14035087719298245), 29: np.float64(0.8333333333333334), 32: np.float64(0.6946564885496184), 35: np.float64(0.35454545454545455), 37: np.float64(0.14901960784313725), 38: np.float64(0.26229508196721313), 39: np.float64(0.2)}
Micro-average F1 score: 0.4440879926672777
Weighted-average F1 score: 0.4069736495533141
F1 score per class: {0: np.float64(0.6336633663366337), 2: np.float64(0.42424242424242425), 4: np.float64(0.8555555555555555), 5: np.float64(0.7245283018867924), 6: np.float64(0.4878048780487805), 10: np.float64(0.12280701754385964), 11: np.float64(0.4461538461538462), 12: np.float64(0.3541666666666667), 13: np.float64(0.034782608695652174), 15: np.float64(0.2033898305084746), 16: np.float64(0.6349206349206349), 17: np.float64(0.0), 18: np.float64(0.1568627450980392), 19: np.float64(0.6814814814814815), 21: np.float64(0.23529411764705882), 23: np.float64(0.8043478260869565), 24: np.float64(0.0), 25: np.float64(0.5974025974025974), 26: np.float64(0.7263157894736842), 28: np.float64(0.14545454545454545), 29: np.float64(0.8333333333333334), 32: np.float64(0.6596491228070176), 35: np.float64(0.3916083916083916), 37: np.float64(0.1523046092184369), 38: np.float64(0.24489795918367346), 39: np.float64(0.1651376146788991)}
Micro-average F1 score: 0.4588938714499253
Weighted-average F1 score: 0.421800293655736

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.6153846153846154), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.37681159420289856), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.375), 37: np.float64(0.46153846153846156), 38: np.float64(0.56), 39: np.float64(0.0)}
Micro-average F1 score: 0.3157894736842105
Weighted-average F1 score: 0.24501326644370125
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.5454545454545454), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5306122448979592), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.5954198473282443), 37: np.float64(0.4840764331210191), 38: np.float64(0.5393258426966292), 39: np.float64(0.0)}
Micro-average F1 score: 0.31516587677725116
Weighted-average F1 score: 0.24640979162403337
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.46153846153846156), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.5411764705882353), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.56), 37: np.float64(0.4935064935064935), 38: np.float64(0.5274725274725275), 39: np.float64(0.0)}
Micro-average F1 score: 0.3169107856191744
Weighted-average F1 score: 0.24055239733528508

F1 score per class: {0: np.float64(0.5979381443298969), 2: np.float64(0.2857142857142857), 4: np.float64(0.7241379310344828), 5: np.float64(0.6940298507462687), 6: np.float64(0.3), 10: np.float64(0.07407407407407407), 11: np.float64(0.34394904458598724), 12: np.float64(0.16828478964401294), 13: np.float64(0.02127659574468085), 15: np.float64(0.15384615384615385), 16: np.float64(0.3711340206185567), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.6164383561643836), 21: np.float64(0.18497109826589594), 23: np.float64(0.7142857142857143), 24: np.float64(0.0), 25: np.float64(0.37681159420289856), 26: np.float64(0.64), 28: np.float64(0.10526315789473684), 29: np.float64(0.70995670995671), 32: np.float64(0.5368731563421829), 35: np.float64(0.22727272727272727), 37: np.float64(0.11342155009451796), 38: np.float64(0.1826086956521739), 39: np.float64(0.07734806629834254)}
Micro-average F1 score: 0.3521405049396268
Weighted-average F1 score: 0.3221868096605086
F1 score per class: {0: np.float64(0.43243243243243246), 2: np.float64(0.17073170731707318), 4: np.float64(0.7219512195121951), 5: np.float64(0.39357429718875503), 6: np.float64(0.27017543859649124), 10: np.float64(0.21), 11: np.float64(0.3508771929824561), 12: np.float64(0.16119402985074627), 13: np.float64(0.02926829268292683), 15: np.float64(0.19047619047619047), 16: np.float64(0.37735849056603776), 17: np.float64(0.0), 18: np.float64(0.10752688172043011), 19: np.float64(0.5740740740740741), 21: np.float64(0.12169312169312169), 23: np.float64(0.6222222222222222), 24: np.float64(0.12121212121212122), 25: np.float64(0.5), 26: np.float64(0.5847457627118644), 28: np.float64(0.07142857142857142), 29: np.float64(0.7017543859649122), 32: np.float64(0.5170454545454546), 35: np.float64(0.22285714285714286), 37: np.float64(0.09908735332464146), 38: np.float64(0.14457831325301204), 39: np.float64(0.0989010989010989)}
Micro-average F1 score: 0.2937253713246438
Weighted-average F1 score: 0.2661251861129661
F1 score per class: {0: np.float64(0.5289256198347108), 2: np.float64(0.25925925925925924), 4: np.float64(0.8148148148148148), 5: np.float64(0.5274725274725275), 6: np.float64(0.2834008097165992), 10: np.float64(0.112), 11: np.float64(0.3431952662721893), 12: np.float64(0.17616580310880828), 13: np.float64(0.018779342723004695), 15: np.float64(0.13043478260869565), 16: np.float64(0.38095238095238093), 17: np.float64(0.0), 18: np.float64(0.0963855421686747), 19: np.float64(0.573208722741433), 21: np.float64(0.13836477987421383), 23: np.float64(0.6271186440677966), 24: np.float64(0.0), 25: np.float64(0.5348837209302325), 26: np.float64(0.6301369863013698), 28: np.float64(0.08421052631578947), 29: np.float64(0.6986899563318777), 32: np.float64(0.49343832020997375), 35: np.float64(0.2557077625570776), 37: np.float64(0.10228802153432032), 38: np.float64(0.1329639889196676), 39: np.float64(0.0782608695652174)}
Micro-average F1 score: 0.30921604834648314
Weighted-average F1 score: 0.27776272761668264
cur_acc_wo_na:  ['0.7621', '0.5210', '0.4577', '0.6571', '0.4244']
his_acc_wo_na:  ['0.7621', '0.6667', '0.5520', '0.5706', '0.4911']
cur_acc des_wo_na:  ['0.7447', '0.5211', '0.4586', '0.5446', '0.4642']
his_acc des_wo_na:  ['0.7447', '0.6147', '0.5300', '0.5077', '0.4441']
cur_acc rrf_wo_na:  ['0.7551', '0.5557', '0.4774', '0.5823', '0.4621']
his_acc rrf_wo_na:  ['0.7551', '0.6494', '0.5507', '0.5396', '0.4589']
cur_acc_w_na:  ['0.6385', '0.4097', '0.3311', '0.5039', '0.3158']
his_acc_w_na:  ['0.6385', '0.5380', '0.4018', '0.4188', '0.3521']
cur_acc des_w_na:  ['0.6070', '0.3689', '0.3103', '0.3783', '0.3152']
his_acc des_w_na:  ['0.6070', '0.4535', '0.3654', '0.3396', '0.2937']
cur_acc rrf_w_na:  ['0.6177', '0.4020', '0.3249', '0.4138', '0.3169']
his_acc rrf_w_na:  ['0.6177', '0.4878', '0.3852', '0.3653', '0.3092']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 150.3099350CurrentTrain: epoch  0, batch     1 | loss: 145.7307439CurrentTrain: epoch  0, batch     2 | loss: 120.8685819CurrentTrain: epoch  0, batch     3 | loss: 85.9656459CurrentTrain: epoch  1, batch     0 | loss: 119.9844378CurrentTrain: epoch  1, batch     1 | loss: 125.9860968CurrentTrain: epoch  1, batch     2 | loss: 125.2013106CurrentTrain: epoch  1, batch     3 | loss: 78.8389557CurrentTrain: epoch  2, batch     0 | loss: 107.2578433CurrentTrain: epoch  2, batch     1 | loss: 149.3075259CurrentTrain: epoch  2, batch     2 | loss: 128.1822439CurrentTrain: epoch  2, batch     3 | loss: 78.1867994CurrentTrain: epoch  3, batch     0 | loss: 108.1264164CurrentTrain: epoch  3, batch     1 | loss: 145.4839880CurrentTrain: epoch  3, batch     2 | loss: 124.0270250CurrentTrain: epoch  3, batch     3 | loss: 73.8139751CurrentTrain: epoch  4, batch     0 | loss: 109.0563400CurrentTrain: epoch  4, batch     1 | loss: 121.1270215CurrentTrain: epoch  4, batch     2 | loss: 106.3336779CurrentTrain: epoch  4, batch     3 | loss: 123.0423490CurrentTrain: epoch  5, batch     0 | loss: 126.1334060CurrentTrain: epoch  5, batch     1 | loss: 118.0927426CurrentTrain: epoch  5, batch     2 | loss: 145.2791656CurrentTrain: epoch  5, batch     3 | loss: 69.6511936CurrentTrain: epoch  6, batch     0 | loss: 124.1411026CurrentTrain: epoch  6, batch     1 | loss: 137.8951263CurrentTrain: epoch  6, batch     2 | loss: 109.9354558CurrentTrain: epoch  6, batch     3 | loss: 66.0933565CurrentTrain: epoch  7, batch     0 | loss: 120.8834151CurrentTrain: epoch  7, batch     1 | loss: 127.2241947CurrentTrain: epoch  7, batch     2 | loss: 93.6558364CurrentTrain: epoch  7, batch     3 | loss: 94.6020654CurrentTrain: epoch  8, batch     0 | loss: 128.7078536CurrentTrain: epoch  8, batch     1 | loss: 132.5312825CurrentTrain: epoch  8, batch     2 | loss: 120.8299866CurrentTrain: epoch  8, batch     3 | loss: 73.3258023CurrentTrain: epoch  9, batch     0 | loss: 114.0843249CurrentTrain: epoch  9, batch     1 | loss: 143.5331699CurrentTrain: epoch  9, batch     2 | loss: 132.2525927CurrentTrain: epoch  9, batch     3 | loss: 52.2622501
MemoryTrain:  epoch  0, batch     0 | loss: 0.7708000MemoryTrain:  epoch  1, batch     0 | loss: 0.7456113MemoryTrain:  epoch  2, batch     0 | loss: 0.6002281MemoryTrain:  epoch  3, batch     0 | loss: 0.4609754MemoryTrain:  epoch  4, batch     0 | loss: 0.4209113MemoryTrain:  epoch  5, batch     0 | loss: 0.3248503MemoryTrain:  epoch  6, batch     0 | loss: 0.3161440MemoryTrain:  epoch  7, batch     0 | loss: 0.2508963MemoryTrain:  epoch  8, batch     0 | loss: 0.2441772MemoryTrain:  epoch  9, batch     0 | loss: 0.2226271

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.5210084033613446), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.8301886792452831), 21: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.918918918918919), 32: np.float64(0.0), 33: np.float64(0.35294117647058826), 35: np.float64(0.0), 36: np.float64(0.5252525252525253), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5182012847965739
Weighted-average F1 score: 0.4193205575473866
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.6878980891719745), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.7663551401869159), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8181818181818182), 32: np.float64(0.0), 33: np.float64(0.35294117647058826), 35: np.float64(0.0), 36: np.float64(0.6771653543307087), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.49226006191950467
Weighted-average F1 score: 0.3777743526132984
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.6623376623376623), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.7735849056603774), 21: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.85), 32: np.float64(0.0), 33: np.float64(0.3157894736842105), 35: np.float64(0.0), 36: np.float64(0.703125), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.510569105691057
Weighted-average F1 score: 0.3972581516522465

F1 score per class: {0: np.float64(0.7142857142857143), 2: np.float64(0.4444444444444444), 4: np.float64(0.8235294117647058), 5: np.float64(0.8034188034188035), 6: np.float64(0.543778801843318), 8: np.float64(0.3333333333333333), 10: np.float64(0.12727272727272726), 11: np.float64(0.3140495867768595), 12: np.float64(0.1388888888888889), 13: np.float64(0.05970149253731343), 15: np.float64(0.3888888888888889), 16: np.float64(0.6122448979591837), 17: np.float64(0.0), 18: np.float64(0.08), 19: np.float64(0.7533632286995515), 20: np.float64(0.4230769230769231), 21: np.float64(0.25396825396825395), 23: np.float64(0.7555555555555555), 24: np.float64(0.0), 25: np.float64(0.3225806451612903), 26: np.float64(0.7065217391304348), 28: np.float64(0.17391304347826086), 29: np.float64(0.8167539267015707), 30: np.float64(0.8717948717948718), 32: np.float64(0.6984126984126984), 33: np.float64(0.17647058823529413), 35: np.float64(0.35555555555555557), 36: np.float64(0.33986928104575165), 37: np.float64(0.3333333333333333), 38: np.float64(0.40860215053763443), 39: np.float64(0.10752688172043011)}
Micro-average F1 score: 0.5041630778064886
Weighted-average F1 score: 0.5103488992457461
F1 score per class: {0: np.float64(0.5645161290322581), 2: np.float64(0.20689655172413793), 4: np.float64(0.8324324324324325), 5: np.float64(0.5380434782608695), 6: np.float64(0.4745762711864407), 8: np.float64(0.28272251308900526), 10: np.float64(0.2236842105263158), 11: np.float64(0.43209876543209874), 12: np.float64(0.2727272727272727), 13: np.float64(0.08333333333333333), 15: np.float64(0.26666666666666666), 16: np.float64(0.5573770491803278), 17: np.float64(0.0), 18: np.float64(0.2033898305084746), 19: np.float64(0.6717557251908397), 20: np.float64(0.3778801843317972), 21: np.float64(0.2541436464088398), 23: np.float64(0.7238095238095238), 24: np.float64(0.3783783783783784), 25: np.float64(0.48717948717948717), 26: np.float64(0.6836734693877551), 28: np.float64(0.16216216216216217), 29: np.float64(0.8324873096446701), 30: np.float64(0.46153846153846156), 32: np.float64(0.7), 33: np.float64(0.10909090909090909), 35: np.float64(0.39603960396039606), 36: np.float64(0.3173431734317343), 37: np.float64(0.22545454545454546), 38: np.float64(0.2613065326633166), 39: np.float64(0.11688311688311688)}
Micro-average F1 score: 0.43321883208729034
Weighted-average F1 score: 0.40825850868448355
F1 score per class: {0: np.float64(0.6153846153846154), 2: np.float64(0.3076923076923077), 4: np.float64(0.8681318681318682), 5: np.float64(0.7058823529411765), 6: np.float64(0.512396694214876), 8: np.float64(0.28895184135977336), 10: np.float64(0.19402985074626866), 11: np.float64(0.4), 12: np.float64(0.2894736842105263), 13: np.float64(0.07272727272727272), 15: np.float64(0.2545454545454545), 16: np.float64(0.576271186440678), 17: np.float64(0.0), 18: np.float64(0.18867924528301888), 19: np.float64(0.6846153846153846), 20: np.float64(0.37104072398190047), 21: np.float64(0.3007518796992481), 23: np.float64(0.7789473684210526), 24: np.float64(0.0), 25: np.float64(0.48), 26: np.float64(0.6907216494845361), 28: np.float64(0.16216216216216217), 29: np.float64(0.8350515463917526), 30: np.float64(0.5074626865671642), 32: np.float64(0.673992673992674), 33: np.float64(0.1016949152542373), 35: np.float64(0.38095238095238093), 36: np.float64(0.3345724907063197), 37: np.float64(0.23938223938223938), 38: np.float64(0.2891566265060241), 39: np.float64(0.11764705882352941)}
Micro-average F1 score: 0.4553846153846154
Weighted-average F1 score: 0.4321123083624014

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.4732824427480916), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5432098765432098), 21: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8717948717948718), 32: np.float64(0.0), 33: np.float64(0.3), 35: np.float64(0.0), 36: np.float64(0.4262295081967213), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.34620886981402005
Weighted-average F1 score: 0.2699477322627886
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.5567010309278351), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7058823529411765), 32: np.float64(0.0), 33: np.float64(0.3), 35: np.float64(0.0), 36: np.float64(0.5119047619047619), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.30665380906460943
Weighted-average F1 score: 0.24244384305613986
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.5483870967741935), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7906976744186046), 32: np.float64(0.0), 33: np.float64(0.2608695652173913), 35: np.float64(0.0), 36: np.float64(0.5202312138728323), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.3250517598343685
Weighted-average F1 score: 0.2589830802916171

F1 score per class: {0: np.float64(0.594059405940594), 2: np.float64(0.2727272727272727), 4: np.float64(0.7692307692307693), 5: np.float64(0.6596491228070176), 6: np.float64(0.31891891891891894), 8: np.float64(0.21830985915492956), 10: np.float64(0.125), 11: np.float64(0.2714285714285714), 12: np.float64(0.08849557522123894), 13: np.float64(0.031007751937984496), 15: np.float64(0.25), 16: np.float64(0.37037037037037035), 17: np.float64(0.0), 18: np.float64(0.05555555555555555), 19: np.float64(0.6746987951807228), 20: np.float64(0.19642857142857142), 21: np.float64(0.1797752808988764), 23: np.float64(0.6868686868686869), 24: np.float64(0.0), 25: np.float64(0.30303030303030304), 26: np.float64(0.6220095693779905), 28: np.float64(0.10526315789473684), 29: np.float64(0.6872246696035242), 30: np.float64(0.8095238095238095), 32: np.float64(0.5207100591715976), 33: np.float64(0.10714285714285714), 35: np.float64(0.2601626016260163), 36: np.float64(0.25742574257425743), 37: np.float64(0.2134387351778656), 38: np.float64(0.24836601307189543), 39: np.float64(0.058823529411764705)}
Micro-average F1 score: 0.35990981758557083
Weighted-average F1 score: 0.34073313223754925
F1 score per class: {0: np.float64(0.42168674698795183), 2: np.float64(0.14285714285714285), 4: np.float64(0.7777777777777778), 5: np.float64(0.33962264150943394), 6: np.float64(0.27383863080684595), 8: np.float64(0.15561959654178675), 10: np.float64(0.18181818181818182), 11: np.float64(0.3286384976525822), 12: np.float64(0.15034168564920272), 13: np.float64(0.045454545454545456), 15: np.float64(0.17647058823529413), 16: np.float64(0.35789473684210527), 17: np.float64(0.0), 18: np.float64(0.12121212121212122), 19: np.float64(0.5770491803278689), 20: np.float64(0.1782608695652174), 21: np.float64(0.15916955017301038), 23: np.float64(0.5467625899280576), 24: np.float64(0.19444444444444445), 25: np.float64(0.4578313253012048), 26: np.float64(0.5775862068965517), 28: np.float64(0.08333333333333333), 29: np.float64(0.6861924686192469), 30: np.float64(0.34951456310679613), 32: np.float64(0.5126760563380282), 33: np.float64(0.0759493670886076), 35: np.float64(0.24691358024691357), 36: np.float64(0.22933333333333333), 37: np.float64(0.13507625272331156), 38: np.float64(0.14772727272727273), 39: np.float64(0.05921052631578947)}
Micro-average F1 score: 0.2821795209265596
Weighted-average F1 score: 0.2602689651053018
F1 score per class: {0: np.float64(0.48484848484848486), 2: np.float64(0.19672131147540983), 4: np.float64(0.8102564102564103), 5: np.float64(0.518918918918919), 6: np.float64(0.30317848410757947), 8: np.float64(0.16748768472906403), 10: np.float64(0.16883116883116883), 11: np.float64(0.3218390804597701), 12: np.float64(0.15639810426540285), 13: np.float64(0.037383177570093455), 15: np.float64(0.1590909090909091), 16: np.float64(0.3617021276595745), 17: np.float64(0.0), 18: np.float64(0.12345679012345678), 19: np.float64(0.5874587458745875), 20: np.float64(0.1726315789473684), 21: np.float64(0.17467248908296942), 23: np.float64(0.6434782608695652), 24: np.float64(0.0), 25: np.float64(0.45), 26: np.float64(0.5826086956521739), 28: np.float64(0.08571428571428572), 29: np.float64(0.6864406779661016), 30: np.float64(0.4146341463414634), 32: np.float64(0.4932975871313673), 33: np.float64(0.06818181818181818), 35: np.float64(0.23829787234042554), 36: np.float64(0.2356020942408377), 37: np.float64(0.14285714285714285), 38: np.float64(0.1708185053380783), 39: np.float64(0.05787781350482315)}
Micro-average F1 score: 0.30182083029861617
Weighted-average F1 score: 0.2774816045767898
cur_acc_wo_na:  ['0.7621', '0.5210', '0.4577', '0.6571', '0.4244', '0.5182']
his_acc_wo_na:  ['0.7621', '0.6667', '0.5520', '0.5706', '0.4911', '0.5042']
cur_acc des_wo_na:  ['0.7447', '0.5211', '0.4586', '0.5446', '0.4642', '0.4923']
his_acc des_wo_na:  ['0.7447', '0.6147', '0.5300', '0.5077', '0.4441', '0.4332']
cur_acc rrf_wo_na:  ['0.7551', '0.5557', '0.4774', '0.5823', '0.4621', '0.5106']
his_acc rrf_wo_na:  ['0.7551', '0.6494', '0.5507', '0.5396', '0.4589', '0.4554']
cur_acc_w_na:  ['0.6385', '0.4097', '0.3311', '0.5039', '0.3158', '0.3462']
his_acc_w_na:  ['0.6385', '0.5380', '0.4018', '0.4188', '0.3521', '0.3599']
cur_acc des_w_na:  ['0.6070', '0.3689', '0.3103', '0.3783', '0.3152', '0.3067']
his_acc des_w_na:  ['0.6070', '0.4535', '0.3654', '0.3396', '0.2937', '0.2822']
cur_acc rrf_w_na:  ['0.6177', '0.4020', '0.3249', '0.4138', '0.3169', '0.3251']
his_acc rrf_w_na:  ['0.6177', '0.4878', '0.3852', '0.3653', '0.3092', '0.3018']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 146.2854469CurrentTrain: epoch  0, batch     1 | loss: 111.6971052CurrentTrain: epoch  0, batch     2 | loss: 136.4593290CurrentTrain: epoch  0, batch     3 | loss: 14.8578762CurrentTrain: epoch  1, batch     0 | loss: 100.0254683CurrentTrain: epoch  1, batch     1 | loss: 112.3633499CurrentTrain: epoch  1, batch     2 | loss: 152.4484640CurrentTrain: epoch  1, batch     3 | loss: 24.5292890CurrentTrain: epoch  2, batch     0 | loss: 108.3741792CurrentTrain: epoch  2, batch     1 | loss: 119.1725100CurrentTrain: epoch  2, batch     2 | loss: 111.5114006CurrentTrain: epoch  2, batch     3 | loss: 20.3143385CurrentTrain: epoch  3, batch     0 | loss: 124.2686589CurrentTrain: epoch  3, batch     1 | loss: 113.6017549CurrentTrain: epoch  3, batch     2 | loss: 123.1579017CurrentTrain: epoch  3, batch     3 | loss: 21.6993473CurrentTrain: epoch  4, batch     0 | loss: 112.7596268CurrentTrain: epoch  4, batch     1 | loss: 110.3651932CurrentTrain: epoch  4, batch     2 | loss: 114.9266937CurrentTrain: epoch  4, batch     3 | loss: 6.3546440CurrentTrain: epoch  5, batch     0 | loss: 105.7735437CurrentTrain: epoch  5, batch     1 | loss: 108.3363863CurrentTrain: epoch  5, batch     2 | loss: 115.1406456CurrentTrain: epoch  5, batch     3 | loss: 18.6915108CurrentTrain: epoch  6, batch     0 | loss: 118.0604013CurrentTrain: epoch  6, batch     1 | loss: 94.3270622CurrentTrain: epoch  6, batch     2 | loss: 123.5394151CurrentTrain: epoch  6, batch     3 | loss: 4.7144355CurrentTrain: epoch  7, batch     0 | loss: 116.8042090CurrentTrain: epoch  7, batch     1 | loss: 121.6938260CurrentTrain: epoch  7, batch     2 | loss: 91.4670596CurrentTrain: epoch  7, batch     3 | loss: 17.8928454CurrentTrain: epoch  8, batch     0 | loss: 91.2769842CurrentTrain: epoch  8, batch     1 | loss: 133.1438792CurrentTrain: epoch  8, batch     2 | loss: 117.0580877CurrentTrain: epoch  8, batch     3 | loss: 6.3656057CurrentTrain: epoch  9, batch     0 | loss: 97.9159498CurrentTrain: epoch  9, batch     1 | loss: 112.0386714CurrentTrain: epoch  9, batch     2 | loss: 101.5920213CurrentTrain: epoch  9, batch     3 | loss: 7.7599726
MemoryTrain:  epoch  0, batch     0 | loss: 0.7412948MemoryTrain:  epoch  1, batch     0 | loss: 0.6132640MemoryTrain:  epoch  2, batch     0 | loss: 0.4660025MemoryTrain:  epoch  3, batch     0 | loss: 0.4169620MemoryTrain:  epoch  4, batch     0 | loss: 0.3420838MemoryTrain:  epoch  5, batch     0 | loss: 0.2802404MemoryTrain:  epoch  6, batch     0 | loss: 0.2570497MemoryTrain:  epoch  7, batch     0 | loss: 0.2417077MemoryTrain:  epoch  8, batch     0 | loss: 0.1681499MemoryTrain:  epoch  9, batch     0 | loss: 0.1671714

F1 score per class: {0: np.float64(0.0), 32: np.float64(0.0), 6: np.float64(0.6), 7: np.float64(0.9387755102040817), 40: np.float64(0.0), 9: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.4), 26: np.float64(0.6666666666666666), 27: np.float64(0.0), 31: np.float64(0.1565217391304348)}
Micro-average F1 score: 0.3010752688172043
Weighted-average F1 score: 0.23887894024539985
F1 score per class: {0: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7272727272727273), 8: np.float64(0.0), 9: np.float64(0.6944444444444444), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.5142857142857142), 31: np.float64(0.6666666666666666), 32: np.float64(0.0), 33: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.42857142857142855)}
Micro-average F1 score: 0.41739130434782606
Weighted-average F1 score: 0.36859816470206075
F1 score per class: {0: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7272727272727273), 8: np.float64(0.0), 9: np.float64(0.9056603773584906), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.5142857142857142), 30: np.float64(0.0), 31: np.float64(0.6666666666666666), 32: np.float64(0.0), 33: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.4)}
Micro-average F1 score: 0.43260188087774293
Weighted-average F1 score: 0.3687678972354536

F1 score per class: {0: np.float64(0.5483870967741935), 2: np.float64(0.5), 4: np.float64(0.7133757961783439), 5: np.float64(0.7866108786610879), 6: np.float64(0.32857142857142857), 7: np.float64(0.047244094488188976), 8: np.float64(0.2222222222222222), 9: np.float64(0.9387755102040817), 10: np.float64(0.038461538461538464), 11: np.float64(0.36065573770491804), 12: np.float64(0.16666666666666666), 13: np.float64(0.06896551724137931), 15: np.float64(0.42424242424242425), 16: np.float64(0.6296296296296297), 17: np.float64(0.0), 18: np.float64(0.11764705882352941), 19: np.float64(0.5925925925925926), 20: np.float64(0.4935064935064935), 21: np.float64(0.09302325581395349), 23: np.float64(0.7209302325581395), 24: np.float64(0.0), 25: np.float64(0.3125), 26: np.float64(0.6745562130177515), 27: np.float64(0.24489795918367346), 28: np.float64(0.2857142857142857), 29: np.float64(0.8042328042328042), 30: np.float64(0.8888888888888888), 31: np.float64(0.5), 32: np.float64(0.7373271889400922), 33: np.float64(0.1935483870967742), 35: np.float64(0.14285714285714285), 36: np.float64(0.44680851063829785), 37: np.float64(0.34615384615384615), 38: np.float64(0.3111111111111111), 39: np.float64(0.05405405405405406), 40: np.float64(0.07894736842105263)}
Micro-average F1 score: 0.4490632318501171
Weighted-average F1 score: 0.45523781249108763
F1 score per class: {0: np.float64(0.6060606060606061), 2: np.float64(0.2926829268292683), 4: np.float64(0.7976878612716763), 5: np.float64(0.5297297297297298), 6: np.float64(0.36470588235294116), 7: np.float64(0.07142857142857142), 8: np.float64(0.3125), 9: np.float64(0.5681818181818182), 10: np.float64(0.1206896551724138), 11: np.float64(0.34831460674157305), 12: np.float64(0.17647058823529413), 13: np.float64(0.07017543859649122), 15: np.float64(0.3076923076923077), 16: np.float64(0.6071428571428571), 17: np.float64(0.0), 18: np.float64(0.16666666666666666), 19: np.float64(0.5758754863813229), 20: np.float64(0.39069767441860465), 21: np.float64(0.22058823529411764), 23: np.float64(0.7551020408163265), 24: np.float64(0.14285714285714285), 25: np.float64(0.5), 26: np.float64(0.6737967914438503), 27: np.float64(0.2535211267605634), 28: np.float64(0.15384615384615385), 29: np.float64(0.8125), 30: np.float64(0.7555555555555555), 31: np.float64(0.16666666666666666), 32: np.float64(0.6854838709677419), 33: np.float64(0.10526315789473684), 35: np.float64(0.48951048951048953), 36: np.float64(0.4263959390862944), 37: np.float64(0.21016949152542372), 38: np.float64(0.34146341463414637), 39: np.float64(0.1111111111111111), 40: np.float64(0.2129032258064516)}
Micro-average F1 score: 0.4162819974821653
Weighted-average F1 score: 0.395936748524104
F1 score per class: {0: np.float64(0.6410256410256411), 2: np.float64(0.3448275862068966), 4: np.float64(0.8323699421965318), 5: np.float64(0.6808510638297872), 6: np.float64(0.3592814371257485), 7: np.float64(0.06837606837606838), 8: np.float64(0.31137724550898205), 9: np.float64(0.8727272727272727), 10: np.float64(0.09090909090909091), 11: np.float64(0.35443037974683544), 12: np.float64(0.16149068322981366), 13: np.float64(0.06779661016949153), 15: np.float64(0.30434782608695654), 16: np.float64(0.5964912280701754), 17: np.float64(0.0), 18: np.float64(0.1095890410958904), 19: np.float64(0.6), 20: np.float64(0.4444444444444444), 21: np.float64(0.23404255319148937), 23: np.float64(0.7555555555555555), 24: np.float64(0.0), 25: np.float64(0.4657534246575342), 26: np.float64(0.6666666666666666), 27: np.float64(0.2465753424657534), 28: np.float64(0.15789473684210525), 29: np.float64(0.8167539267015707), 30: np.float64(0.7391304347826086), 31: np.float64(0.3333333333333333), 32: np.float64(0.6511627906976745), 33: np.float64(0.11320754716981132), 35: np.float64(0.43564356435643564), 36: np.float64(0.45614035087719296), 37: np.float64(0.21678321678321677), 38: np.float64(0.33766233766233766), 39: np.float64(0.12307692307692308), 40: np.float64(0.19254658385093168)}
Micro-average F1 score: 0.4314087759815243
Weighted-average F1 score: 0.4113850602890653

F1 score per class: {0: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.5), 6: np.float64(0.92), 7: np.float64(0.0), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.34285714285714286), 21: np.float64(0.6666666666666666), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.13333333333333333)}
Micro-average F1 score: 0.2641509433962264
Weighted-average F1 score: 0.20942577030812326
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5714285714285714), 8: np.float64(0.0), 9: np.float64(0.6172839506172839), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.47368421052631576), 28: np.float64(0.0), 31: np.float64(0.5), 32: np.float64(0.0), 33: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.3473684210526316)}
Micro-average F1 score: 0.3235955056179775
Weighted-average F1 score: 0.2849381482126487
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5714285714285714), 8: np.float64(0.0), 9: np.float64(0.8421052631578947), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.46153846153846156), 30: np.float64(0.0), 31: np.float64(0.5), 32: np.float64(0.0), 33: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.32460732984293195)}
Micro-average F1 score: 0.3415841584158416
Weighted-average F1 score: 0.29025800645321553

F1 score per class: {0: np.float64(0.4657534246575342), 2: np.float64(0.2857142857142857), 4: np.float64(0.6706586826347305), 5: np.float64(0.632996632996633), 6: np.float64(0.233502538071066), 7: np.float64(0.02510460251046025), 8: np.float64(0.205607476635514), 9: np.float64(0.92), 10: np.float64(0.038461538461538464), 11: np.float64(0.32592592592592595), 12: np.float64(0.10837438423645321), 13: np.float64(0.042105263157894736), 15: np.float64(0.2692307692307692), 16: np.float64(0.3953488372093023), 17: np.float64(0.0), 18: np.float64(0.08), 19: np.float64(0.547945205479452), 20: np.float64(0.2360248447204969), 21: np.float64(0.08), 23: np.float64(0.6666666666666666), 24: np.float64(0.0), 25: np.float64(0.29411764705882354), 26: np.float64(0.6), 27: np.float64(0.17647058823529413), 28: np.float64(0.17391304347826086), 29: np.float64(0.6846846846846847), 30: np.float64(0.8205128205128205), 31: np.float64(0.25), 32: np.float64(0.5653710247349824), 33: np.float64(0.16666666666666666), 35: np.float64(0.11594202898550725), 36: np.float64(0.34146341463414637), 37: np.float64(0.23376623376623376), 38: np.float64(0.2222222222222222), 39: np.float64(0.03278688524590164), 40: np.float64(0.0594059405940594)}
Micro-average F1 score: 0.34180035650623886
Weighted-average F1 score: 0.3256677664824628
F1 score per class: {0: np.float64(0.47244094488188976), 2: np.float64(0.18461538461538463), 4: np.float64(0.75), 5: np.float64(0.34146341463414637), 6: np.float64(0.23048327137546468), 7: np.float64(0.03864734299516908), 8: np.float64(0.2023121387283237), 9: np.float64(0.4807692307692308), 10: np.float64(0.10687022900763359), 11: np.float64(0.28837209302325584), 12: np.float64(0.11235955056179775), 13: np.float64(0.039603960396039604), 15: np.float64(0.21052631578947367), 16: np.float64(0.4), 17: np.float64(0.0), 18: np.float64(0.09937888198757763), 19: np.float64(0.5174825174825175), 20: np.float64(0.19310344827586207), 21: np.float64(0.13953488372093023), 23: np.float64(0.592), 24: np.float64(0.11428571428571428), 25: np.float64(0.47058823529411764), 26: np.float64(0.5833333333333334), 27: np.float64(0.17307692307692307), 28: np.float64(0.08), 29: np.float64(0.7027027027027027), 30: np.float64(0.6938775510204082), 31: np.float64(0.1111111111111111), 32: np.float64(0.5182926829268293), 33: np.float64(0.06521739130434782), 35: np.float64(0.3465346534653465), 36: np.float64(0.328125), 37: np.float64(0.13716814159292035), 38: np.float64(0.21705426356589147), 39: np.float64(0.06611570247933884), 40: np.float64(0.15566037735849056)}
Micro-average F1 score: 0.2925390740194633
Weighted-average F1 score: 0.27080870962543996
F1 score per class: {0: np.float64(0.5208333333333334), 2: np.float64(0.2127659574468085), 4: np.float64(0.7783783783783784), 5: np.float64(0.4549763033175355), 6: np.float64(0.22988505747126436), 7: np.float64(0.0365296803652968), 8: np.float64(0.23423423423423423), 9: np.float64(0.8), 10: np.float64(0.08620689655172414), 11: np.float64(0.3010752688172043), 12: np.float64(0.09961685823754789), 13: np.float64(0.03571428571428571), 15: np.float64(0.175), 16: np.float64(0.3953488372093023), 17: np.float64(0.0), 18: np.float64(0.0784313725490196), 19: np.float64(0.5454545454545454), 20: np.float64(0.2028985507246377), 21: np.float64(0.15384615384615385), 23: np.float64(0.6476190476190476), 24: np.float64(0.0), 25: np.float64(0.44155844155844154), 26: np.float64(0.5767441860465117), 27: np.float64(0.16216216216216217), 28: np.float64(0.08695652173913043), 29: np.float64(0.7058823529411765), 30: np.float64(0.68), 31: np.float64(0.18181818181818182), 32: np.float64(0.49122807017543857), 33: np.float64(0.07058823529411765), 35: np.float64(0.3055555555555556), 36: np.float64(0.3406113537117904), 37: np.float64(0.13507625272331156), 38: np.float64(0.2184873949579832), 39: np.float64(0.07207207207207207), 40: np.float64(0.14123006833712984)}
Micro-average F1 score: 0.3056782850597284
Weighted-average F1 score: 0.2811515358574561
cur_acc_wo_na:  ['0.7621', '0.5210', '0.4577', '0.6571', '0.4244', '0.5182', '0.3011']
his_acc_wo_na:  ['0.7621', '0.6667', '0.5520', '0.5706', '0.4911', '0.5042', '0.4491']
cur_acc des_wo_na:  ['0.7447', '0.5211', '0.4586', '0.5446', '0.4642', '0.4923', '0.4174']
his_acc des_wo_na:  ['0.7447', '0.6147', '0.5300', '0.5077', '0.4441', '0.4332', '0.4163']
cur_acc rrf_wo_na:  ['0.7551', '0.5557', '0.4774', '0.5823', '0.4621', '0.5106', '0.4326']
his_acc rrf_wo_na:  ['0.7551', '0.6494', '0.5507', '0.5396', '0.4589', '0.4554', '0.4314']
cur_acc_w_na:  ['0.6385', '0.4097', '0.3311', '0.5039', '0.3158', '0.3462', '0.2642']
his_acc_w_na:  ['0.6385', '0.5380', '0.4018', '0.4188', '0.3521', '0.3599', '0.3418']
cur_acc des_w_na:  ['0.6070', '0.3689', '0.3103', '0.3783', '0.3152', '0.3067', '0.3236']
his_acc des_w_na:  ['0.6070', '0.4535', '0.3654', '0.3396', '0.2937', '0.2822', '0.2925']
cur_acc rrf_w_na:  ['0.6177', '0.4020', '0.3249', '0.4138', '0.3169', '0.3251', '0.3416']
his_acc rrf_w_na:  ['0.6177', '0.4878', '0.3852', '0.3653', '0.3092', '0.3018', '0.3057']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 148.1839805CurrentTrain: epoch  0, batch     1 | loss: 148.3109713CurrentTrain: epoch  0, batch     2 | loss: 131.3916120CurrentTrain: epoch  0, batch     3 | loss: 162.3167868CurrentTrain: epoch  0, batch     4 | loss: 90.6008741CurrentTrain: epoch  1, batch     0 | loss: 135.2716661CurrentTrain: epoch  1, batch     1 | loss: 136.8971002CurrentTrain: epoch  1, batch     2 | loss: 116.2700199CurrentTrain: epoch  1, batch     3 | loss: 174.6367296CurrentTrain: epoch  1, batch     4 | loss: 101.7803588CurrentTrain: epoch  2, batch     0 | loss: 133.8638015CurrentTrain: epoch  2, batch     1 | loss: 146.8922781CurrentTrain: epoch  2, batch     2 | loss: 120.5400807CurrentTrain: epoch  2, batch     3 | loss: 152.2634533CurrentTrain: epoch  2, batch     4 | loss: 70.2167218CurrentTrain: epoch  3, batch     0 | loss: 157.7855269CurrentTrain: epoch  3, batch     1 | loss: 128.4005786CurrentTrain: epoch  3, batch     2 | loss: 121.5034166CurrentTrain: epoch  3, batch     3 | loss: 107.0548542CurrentTrain: epoch  3, batch     4 | loss: 100.8693196CurrentTrain: epoch  4, batch     0 | loss: 111.5419729CurrentTrain: epoch  4, batch     1 | loss: 145.1755442CurrentTrain: epoch  4, batch     2 | loss: 152.1631629CurrentTrain: epoch  4, batch     3 | loss: 160.7509053CurrentTrain: epoch  4, batch     4 | loss: 60.3186589CurrentTrain: epoch  5, batch     0 | loss: 126.1965886CurrentTrain: epoch  5, batch     1 | loss: 144.9195808CurrentTrain: epoch  5, batch     2 | loss: 124.4186775CurrentTrain: epoch  5, batch     3 | loss: 125.4625232CurrentTrain: epoch  5, batch     4 | loss: 80.7271375CurrentTrain: epoch  6, batch     0 | loss: 128.8482986CurrentTrain: epoch  6, batch     1 | loss: 113.1208716CurrentTrain: epoch  6, batch     2 | loss: 116.0345486CurrentTrain: epoch  6, batch     3 | loss: 126.8622723CurrentTrain: epoch  6, batch     4 | loss: 112.4954018CurrentTrain: epoch  7, batch     0 | loss: 116.5324265CurrentTrain: epoch  7, batch     1 | loss: 126.8342194CurrentTrain: epoch  7, batch     2 | loss: 135.3781886CurrentTrain: epoch  7, batch     3 | loss: 131.5379963CurrentTrain: epoch  7, batch     4 | loss: 111.0863803CurrentTrain: epoch  8, batch     0 | loss: 146.8325052CurrentTrain: epoch  8, batch     1 | loss: 140.7377690CurrentTrain: epoch  8, batch     2 | loss: 149.3651950CurrentTrain: epoch  8, batch     3 | loss: 129.4755310CurrentTrain: epoch  8, batch     4 | loss: 66.4253427CurrentTrain: epoch  9, batch     0 | loss: 143.0113884CurrentTrain: epoch  9, batch     1 | loss: 125.4538145CurrentTrain: epoch  9, batch     2 | loss: 105.0985780CurrentTrain: epoch  9, batch     3 | loss: 140.3100921CurrentTrain: epoch  9, batch     4 | loss: 88.3043331
MemoryTrain:  epoch  0, batch     0 | loss: 1.0922763MemoryTrain:  epoch  1, batch     0 | loss: 0.9646571MemoryTrain:  epoch  2, batch     0 | loss: 0.8227585MemoryTrain:  epoch  3, batch     0 | loss: 0.6207566MemoryTrain:  epoch  4, batch     0 | loss: 0.4672464MemoryTrain:  epoch  5, batch     0 | loss: 0.4081179MemoryTrain:  epoch  6, batch     0 | loss: 0.3410230MemoryTrain:  epoch  7, batch     0 | loss: 0.3321289MemoryTrain:  epoch  8, batch     0 | loss: 0.2993689MemoryTrain:  epoch  9, batch     0 | loss: 0.2489700

F1 score per class: {1: np.float64(0.21978021978021978), 3: np.float64(0.7125), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.06329113924050633), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.559322033898305), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.608), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3576923076923077
Weighted-average F1 score: 0.30216415539014124
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.25), 3: np.float64(0.6179775280898876), 6: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.08333333333333333), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5381818181818182), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.532258064516129), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3140495867768595
Weighted-average F1 score: 0.2653596316763479
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.24210526315789474), 3: np.float64(0.6551724137931034), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 14: np.float64(0.08064516129032258), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5313653136531366), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.5581395348837209), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3350694444444444
Weighted-average F1 score: 0.287749103468603

F1 score per class: {0: np.float64(0.509090909090909), 1: np.float64(0.16129032258064516), 2: np.float64(0.5), 3: np.float64(0.456), 4: np.float64(0.6666666666666666), 5: np.float64(0.8430493273542601), 6: np.float64(0.3576158940397351), 7: np.float64(0.07079646017699115), 8: np.float64(0.3050847457627119), 9: np.float64(0.8888888888888888), 10: np.float64(0.019417475728155338), 11: np.float64(0.20202020202020202), 12: np.float64(0.2119205298013245), 13: np.float64(0.06060606060606061), 14: np.float64(0.026246719160104987), 15: np.float64(0.5217391304347826), 16: np.float64(0.6666666666666666), 17: np.float64(0.0), 18: np.float64(0.03225806451612903), 19: np.float64(0.5338078291814946), 20: np.float64(0.45962732919254656), 21: np.float64(0.0), 22: np.float64(0.5057471264367817), 23: np.float64(0.7916666666666666), 24: np.float64(0.0), 25: np.float64(0.3225806451612903), 26: np.float64(0.6931818181818182), 27: np.float64(0.0), 28: np.float64(0.25), 29: np.float64(0.774869109947644), 30: np.float64(0.8888888888888888), 31: np.float64(0.0), 32: np.float64(0.5757575757575758), 33: np.float64(0.3157894736842105), 34: np.float64(0.14476190476190476), 35: np.float64(0.14084507042253522), 36: np.float64(0.3058823529411765), 37: np.float64(0.45528455284552843), 38: np.float64(0.18461538461538463), 39: np.float64(0.08163265306122448), 40: np.float64(0.09966777408637874)}
Micro-average F1 score: 0.36006924408540103
Weighted-average F1 score: 0.32979224587448464
F1 score per class: {0: np.float64(0.5925925925925926), 1: np.float64(0.17647058823529413), 2: np.float64(0.3076923076923077), 3: np.float64(0.3559870550161812), 4: np.float64(0.783625730994152), 5: np.float64(0.49370277078085645), 6: np.float64(0.3675675675675676), 7: np.float64(0.08602150537634409), 8: np.float64(0.3041825095057034), 9: np.float64(0.4032258064516129), 10: np.float64(0.15517241379310345), 11: np.float64(0.08602150537634409), 12: np.float64(0.24468085106382978), 13: np.float64(0.0851063829787234), 14: np.float64(0.045714285714285714), 15: np.float64(0.32432432432432434), 16: np.float64(0.6296296296296297), 17: np.float64(0.0), 18: np.float64(0.1746031746031746), 19: np.float64(0.5087108013937283), 20: np.float64(0.39111111111111113), 21: np.float64(0.08333333333333333), 22: np.float64(0.4), 23: np.float64(0.7339449541284404), 24: np.float64(0.0), 25: np.float64(0.5128205128205128), 26: np.float64(0.7225130890052356), 27: np.float64(0.0), 28: np.float64(0.125), 29: np.float64(0.7835051546391752), 30: np.float64(0.8), 31: np.float64(0.10526315789473684), 32: np.float64(0.5307443365695793), 33: np.float64(0.10714285714285714), 34: np.float64(0.13807531380753138), 35: np.float64(0.30344827586206896), 36: np.float64(0.39461883408071746), 37: np.float64(0.26382978723404255), 38: np.float64(0.24074074074074073), 39: np.float64(0.11904761904761904), 40: np.float64(0.22699386503067484)}
Micro-average F1 score: 0.3566227730441518
Weighted-average F1 score: 0.34043615749860767
F1 score per class: {0: np.float64(0.6153846153846154), 1: np.float64(0.17490494296577946), 2: np.float64(0.3225806451612903), 3: np.float64(0.37254901960784315), 4: np.float64(0.8023952095808383), 5: np.float64(0.6736842105263158), 6: np.float64(0.38202247191011235), 7: np.float64(0.07766990291262135), 8: np.float64(0.3626373626373626), 9: np.float64(0.819672131147541), 10: np.float64(0.09090909090909091), 11: np.float64(0.10638297872340426), 12: np.float64(0.2541436464088398), 13: np.float64(0.06451612903225806), 14: np.float64(0.03802281368821293), 15: np.float64(0.3), 16: np.float64(0.6538461538461539), 17: np.float64(0.0), 18: np.float64(0.1592920353982301), 19: np.float64(0.5481481481481482), 20: np.float64(0.3942307692307692), 21: np.float64(0.0), 22: np.float64(0.4311377245508982), 23: np.float64(0.7628865979381443), 24: np.float64(0.0), 25: np.float64(0.45714285714285713), 26: np.float64(0.7058823529411765), 27: np.float64(0.0), 28: np.float64(0.13043478260869565), 29: np.float64(0.7897435897435897), 30: np.float64(0.8780487804878049), 31: np.float64(0.14285714285714285), 32: np.float64(0.5436241610738255), 33: np.float64(0.15), 34: np.float64(0.1316270566727605), 35: np.float64(0.24242424242424243), 36: np.float64(0.49673202614379086), 37: np.float64(0.3333333333333333), 38: np.float64(0.21359223300970873), 39: np.float64(0.12048192771084337), 40: np.float64(0.21022727272727273)}
Micro-average F1 score: 0.3666055657390435
Weighted-average F1 score: 0.3421916487366384

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.12578616352201258), 3: np.float64(0.6031746031746031), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.04739336492890995), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.4520547945205479), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.4779874213836478), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.24619457313037724
Weighted-average F1 score: 0.2076814341532244
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.14328358208955225), 2: np.float64(0.0), 3: np.float64(0.4263565891472868), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.07142857142857142), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.41456582633053224), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.3905325443786982), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.202991452991453
Weighted-average F1 score: 0.1774819084862846
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.1373134328358209), 3: np.float64(0.4541832669322709), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.062111801242236024), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.4114285714285714), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.4161849710982659), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.21771009588268472
Weighted-average F1 score: 0.19218966352202607

F1 score per class: {0: np.float64(0.417910447761194), 1: np.float64(0.09070294784580499), 2: np.float64(0.2857142857142857), 3: np.float64(0.32386363636363635), 4: np.float64(0.6289308176100629), 5: np.float64(0.6738351254480287), 6: np.float64(0.23376623376623376), 7: np.float64(0.0380952380952381), 8: np.float64(0.2589928057553957), 9: np.float64(0.8421052631578947), 10: np.float64(0.019417475728155338), 11: np.float64(0.19047619047619047), 12: np.float64(0.12121212121212122), 13: np.float64(0.030534351145038167), 14: np.float64(0.019157088122605363), 15: np.float64(0.3870967741935484), 16: np.float64(0.425), 17: np.float64(0.0), 18: np.float64(0.02197802197802198), 19: np.float64(0.48859934853420195), 20: np.float64(0.2276923076923077), 21: np.float64(0.0), 22: np.float64(0.37393767705382436), 23: np.float64(0.6972477064220184), 24: np.float64(0.0), 25: np.float64(0.3125), 26: np.float64(0.6039603960396039), 27: np.float64(0.0), 28: np.float64(0.17391304347826086), 29: np.float64(0.6434782608695652), 30: np.float64(0.8205128205128205), 31: np.float64(0.0), 32: np.float64(0.41643835616438357), 33: np.float64(0.1875), 34: np.float64(0.09806451612903226), 35: np.float64(0.11235955056179775), 36: np.float64(0.24528301886792453), 37: np.float64(0.345679012345679), 38: np.float64(0.12631578947368421), 39: np.float64(0.043010752688172046), 40: np.float64(0.06944444444444445)}
Micro-average F1 score: 0.2598195697432339
Weighted-average F1 score: 0.23356017309166874
F1 score per class: {0: np.float64(0.42953020134228187), 1: np.float64(0.09696969696969697), 2: np.float64(0.19672131147540983), 3: np.float64(0.21696252465483234), 4: np.float64(0.7403314917127072), 5: np.float64(0.30672926447574334), 6: np.float64(0.2222222222222222), 7: np.float64(0.044444444444444446), 8: np.float64(0.1834862385321101), 9: np.float64(0.30864197530864196), 10: np.float64(0.14516129032258066), 11: np.float64(0.08), 12: np.float64(0.13068181818181818), 13: np.float64(0.047058823529411764), 14: np.float64(0.037209302325581395), 15: np.float64(0.23529411764705882), 16: np.float64(0.40476190476190477), 17: np.float64(0.0), 18: np.float64(0.102803738317757), 19: np.float64(0.4492307692307692), 20: np.float64(0.19088937093275488), 21: np.float64(0.06666666666666667), 22: np.float64(0.2781954887218045), 23: np.float64(0.4819277108433735), 24: np.float64(0.0), 25: np.float64(0.4819277108433735), 26: np.float64(0.6133333333333333), 27: np.float64(0.0), 28: np.float64(0.06382978723404255), 29: np.float64(0.6608695652173913), 30: np.float64(0.7058823529411765), 31: np.float64(0.044444444444444446), 32: np.float64(0.3787528868360277), 33: np.float64(0.06741573033707865), 34: np.float64(0.09192200557103064), 35: np.float64(0.2146341463414634), 36: np.float64(0.2543352601156069), 37: np.float64(0.17318435754189945), 38: np.float64(0.1566265060240964), 39: np.float64(0.06802721088435375), 40: np.float64(0.15845824411134904)}
Micro-average F1 score: 0.23827761101335265
Weighted-average F1 score: 0.22345226854032563
F1 score per class: {0: np.float64(0.4485981308411215), 1: np.float64(0.09368635437881874), 2: np.float64(0.20408163265306123), 3: np.float64(0.23123732251521298), 4: np.float64(0.7570621468926554), 5: np.float64(0.463768115942029), 6: np.float64(0.23208191126279865), 7: np.float64(0.041025641025641026), 8: np.float64(0.26294820717131473), 9: np.float64(0.7692307692307693), 10: np.float64(0.08849557522123894), 11: np.float64(0.09900990099009901), 12: np.float64(0.1329479768786127), 13: np.float64(0.03225806451612903), 14: np.float64(0.02967359050445104), 15: np.float64(0.21428571428571427), 16: np.float64(0.40963855421686746), 17: np.float64(0.0), 18: np.float64(0.0962566844919786), 19: np.float64(0.49498327759197325), 20: np.float64(0.1774891774891775), 21: np.float64(0.0), 22: np.float64(0.2962962962962963), 23: np.float64(0.5736434108527132), 24: np.float64(0.0), 25: np.float64(0.43243243243243246), 26: np.float64(0.6111111111111112), 27: np.float64(0.0), 28: np.float64(0.07317073170731707), 29: np.float64(0.6637931034482759), 30: np.float64(0.8181818181818182), 31: np.float64(0.06896551724137931), 32: np.float64(0.38207547169811323), 33: np.float64(0.09090909090909091), 34: np.float64(0.08791208791208792), 35: np.float64(0.17518248175182483), 36: np.float64(0.3179916317991632), 37: np.float64(0.22535211267605634), 38: np.float64(0.13836477987421383), 39: np.float64(0.0684931506849315), 40: np.float64(0.14453125)}
Micro-average F1 score: 0.24841915085817526
Weighted-average F1 score: 0.2282103393027562
cur_acc_wo_na:  ['0.7621', '0.5210', '0.4577', '0.6571', '0.4244', '0.5182', '0.3011', '0.3577']
his_acc_wo_na:  ['0.7621', '0.6667', '0.5520', '0.5706', '0.4911', '0.5042', '0.4491', '0.3601']
cur_acc des_wo_na:  ['0.7447', '0.5211', '0.4586', '0.5446', '0.4642', '0.4923', '0.4174', '0.3140']
his_acc des_wo_na:  ['0.7447', '0.6147', '0.5300', '0.5077', '0.4441', '0.4332', '0.4163', '0.3566']
cur_acc rrf_wo_na:  ['0.7551', '0.5557', '0.4774', '0.5823', '0.4621', '0.5106', '0.4326', '0.3351']
his_acc rrf_wo_na:  ['0.7551', '0.6494', '0.5507', '0.5396', '0.4589', '0.4554', '0.4314', '0.3666']
cur_acc_w_na:  ['0.6385', '0.4097', '0.3311', '0.5039', '0.3158', '0.3462', '0.2642', '0.2462']
his_acc_w_na:  ['0.6385', '0.5380', '0.4018', '0.4188', '0.3521', '0.3599', '0.3418', '0.2598']
cur_acc des_w_na:  ['0.6070', '0.3689', '0.3103', '0.3783', '0.3152', '0.3067', '0.3236', '0.2030']
his_acc des_w_na:  ['0.6070', '0.4535', '0.3654', '0.3396', '0.2937', '0.2822', '0.2925', '0.2383']
cur_acc rrf_w_na:  ['0.6177', '0.4020', '0.3249', '0.4138', '0.3169', '0.3251', '0.3416', '0.2177']
his_acc rrf_w_na:  ['0.6177', '0.4878', '0.3852', '0.3653', '0.3092', '0.3018', '0.3057', '0.2484']
--------Round  3
seed:  400
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 0 1 2 5 3 4 6]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 145.1171985CurrentTrain: epoch  0, batch     1 | loss: 227.9389183CurrentTrain: epoch  0, batch     2 | loss: 157.5798950CurrentTrain: epoch  0, batch     3 | loss: 141.8745020CurrentTrain: epoch  0, batch     4 | loss: 118.4661239CurrentTrain: epoch  0, batch     5 | loss: 129.9049522CurrentTrain: epoch  0, batch     6 | loss: 118.3149013CurrentTrain: epoch  0, batch     7 | loss: 158.7731296CurrentTrain: epoch  0, batch     8 | loss: 150.0597863CurrentTrain: epoch  0, batch     9 | loss: 154.8211173CurrentTrain: epoch  0, batch    10 | loss: 182.4744636CurrentTrain: epoch  0, batch    11 | loss: 156.2115262CurrentTrain: epoch  0, batch    12 | loss: 143.8775283CurrentTrain: epoch  0, batch    13 | loss: 185.0280126CurrentTrain: epoch  0, batch    14 | loss: 161.8726065CurrentTrain: epoch  0, batch    15 | loss: 124.5374711CurrentTrain: epoch  0, batch    16 | loss: 143.8388752CurrentTrain: epoch  0, batch    17 | loss: 120.0398591CurrentTrain: epoch  0, batch    18 | loss: 140.0367678CurrentTrain: epoch  0, batch    19 | loss: 158.5587030CurrentTrain: epoch  0, batch    20 | loss: 126.7635900CurrentTrain: epoch  0, batch    21 | loss: 183.6015278CurrentTrain: epoch  0, batch    22 | loss: 102.4151773CurrentTrain: epoch  0, batch    23 | loss: 142.4270795CurrentTrain: epoch  0, batch    24 | loss: 161.5039429CurrentTrain: epoch  0, batch    25 | loss: 145.2662061CurrentTrain: epoch  0, batch    26 | loss: 119.3878508CurrentTrain: epoch  0, batch    27 | loss: 125.9640359CurrentTrain: epoch  0, batch    28 | loss: 154.8718155CurrentTrain: epoch  0, batch    29 | loss: 142.5898229CurrentTrain: epoch  0, batch    30 | loss: 158.2083331CurrentTrain: epoch  0, batch    31 | loss: 116.0028461CurrentTrain: epoch  0, batch    32 | loss: 152.2649926CurrentTrain: epoch  0, batch    33 | loss: 164.8454938CurrentTrain: epoch  0, batch    34 | loss: 122.8182447CurrentTrain: epoch  0, batch    35 | loss: 178.8951104CurrentTrain: epoch  0, batch    36 | loss: 136.8174008CurrentTrain: epoch  0, batch    37 | loss: 144.4041661CurrentTrain: epoch  0, batch    38 | loss: 122.2548615CurrentTrain: epoch  0, batch    39 | loss: 139.7912101CurrentTrain: epoch  0, batch    40 | loss: 125.7491470CurrentTrain: epoch  0, batch    41 | loss: 132.5774500CurrentTrain: epoch  0, batch    42 | loss: 145.8378148CurrentTrain: epoch  0, batch    43 | loss: 180.2434833CurrentTrain: epoch  0, batch    44 | loss: 141.3436849CurrentTrain: epoch  0, batch    45 | loss: 170.5885302CurrentTrain: epoch  0, batch    46 | loss: 157.6884580CurrentTrain: epoch  0, batch    47 | loss: 135.7545024CurrentTrain: epoch  0, batch    48 | loss: 162.6577861CurrentTrain: epoch  0, batch    49 | loss: 141.1513762CurrentTrain: epoch  0, batch    50 | loss: 115.6288459CurrentTrain: epoch  0, batch    51 | loss: 141.9633560CurrentTrain: epoch  0, batch    52 | loss: 104.8962557CurrentTrain: epoch  0, batch    53 | loss: 129.1049355CurrentTrain: epoch  0, batch    54 | loss: 174.7906007CurrentTrain: epoch  0, batch    55 | loss: 117.1573673CurrentTrain: epoch  0, batch    56 | loss: 142.3500872CurrentTrain: epoch  0, batch    57 | loss: 161.4256719CurrentTrain: epoch  0, batch    58 | loss: 215.6708189CurrentTrain: epoch  0, batch    59 | loss: 175.2695107CurrentTrain: epoch  0, batch    60 | loss: 140.3309053CurrentTrain: epoch  0, batch    61 | loss: 123.6200425CurrentTrain: epoch  0, batch    62 | loss: 221.9182550CurrentTrain: epoch  0, batch    63 | loss: 159.8947249CurrentTrain: epoch  0, batch    64 | loss: 120.6264549CurrentTrain: epoch  0, batch    65 | loss: 127.9422304CurrentTrain: epoch  0, batch    66 | loss: 158.7892836CurrentTrain: epoch  0, batch    67 | loss: 148.0613493CurrentTrain: epoch  0, batch    68 | loss: 133.7271736CurrentTrain: epoch  0, batch    69 | loss: 177.6320393CurrentTrain: epoch  0, batch    70 | loss: 127.3362448CurrentTrain: epoch  0, batch    71 | loss: 101.0572672CurrentTrain: epoch  0, batch    72 | loss: 157.0020677CurrentTrain: epoch  0, batch    73 | loss: 133.2535875CurrentTrain: epoch  0, batch    74 | loss: 144.2488635CurrentTrain: epoch  0, batch    75 | loss: 144.4116212CurrentTrain: epoch  0, batch    76 | loss: 129.1577098CurrentTrain: epoch  0, batch    77 | loss: 117.7902678CurrentTrain: epoch  0, batch    78 | loss: 110.1992504CurrentTrain: epoch  0, batch    79 | loss: 137.7013111CurrentTrain: epoch  0, batch    80 | loss: 123.5426785CurrentTrain: epoch  0, batch    81 | loss: 116.6932692CurrentTrain: epoch  0, batch    82 | loss: 130.4298954CurrentTrain: epoch  0, batch    83 | loss: 107.3748707CurrentTrain: epoch  0, batch    84 | loss: 137.8806968CurrentTrain: epoch  0, batch    85 | loss: 143.5661460CurrentTrain: epoch  0, batch    86 | loss: 123.2358169CurrentTrain: epoch  0, batch    87 | loss: 155.6113652CurrentTrain: epoch  0, batch    88 | loss: 130.6807369CurrentTrain: epoch  0, batch    89 | loss: 175.2118934CurrentTrain: epoch  0, batch    90 | loss: 178.4746056CurrentTrain: epoch  0, batch    91 | loss: 158.4392376CurrentTrain: epoch  0, batch    92 | loss: 112.3629505CurrentTrain: epoch  0, batch    93 | loss: 124.0610006CurrentTrain: epoch  0, batch    94 | loss: 120.4245253CurrentTrain: epoch  0, batch    95 | loss: 128.0293325CurrentTrain: epoch  1, batch     0 | loss: 110.5886718CurrentTrain: epoch  1, batch     1 | loss: 131.3979923CurrentTrain: epoch  1, batch     2 | loss: 100.8798695CurrentTrain: epoch  1, batch     3 | loss: 152.2250606CurrentTrain: epoch  1, batch     4 | loss: 125.7814986CurrentTrain: epoch  1, batch     5 | loss: 131.4986850CurrentTrain: epoch  1, batch     6 | loss: 145.0296964CurrentTrain: epoch  1, batch     7 | loss: 136.1719547CurrentTrain: epoch  1, batch     8 | loss: 106.4980087CurrentTrain: epoch  1, batch     9 | loss: 122.6920045CurrentTrain: epoch  1, batch    10 | loss: 115.3387258CurrentTrain: epoch  1, batch    11 | loss: 180.8889426CurrentTrain: epoch  1, batch    12 | loss: 126.3763260CurrentTrain: epoch  1, batch    13 | loss: 145.8433012CurrentTrain: epoch  1, batch    14 | loss: 128.3380172CurrentTrain: epoch  1, batch    15 | loss: 142.8712989CurrentTrain: epoch  1, batch    16 | loss: 139.3840272CurrentTrain: epoch  1, batch    17 | loss: 135.9613455CurrentTrain: epoch  1, batch    18 | loss: 132.7124198CurrentTrain: epoch  1, batch    19 | loss: 152.6598284CurrentTrain: epoch  1, batch    20 | loss: 118.2697993CurrentTrain: epoch  1, batch    21 | loss: 116.2338150CurrentTrain: epoch  1, batch    22 | loss: 179.2815085CurrentTrain: epoch  1, batch    23 | loss: 183.2984167CurrentTrain: epoch  1, batch    24 | loss: 116.0323570CurrentTrain: epoch  1, batch    25 | loss: 118.1190126CurrentTrain: epoch  1, batch    26 | loss: 154.8464559CurrentTrain: epoch  1, batch    27 | loss: 114.7975841CurrentTrain: epoch  1, batch    28 | loss: 124.7862371CurrentTrain: epoch  1, batch    29 | loss: 180.8986650CurrentTrain: epoch  1, batch    30 | loss: 115.3153179CurrentTrain: epoch  1, batch    31 | loss: 119.7711007CurrentTrain: epoch  1, batch    32 | loss: 141.9595643CurrentTrain: epoch  1, batch    33 | loss: 113.3456359CurrentTrain: epoch  1, batch    34 | loss: 131.6103875CurrentTrain: epoch  1, batch    35 | loss: 176.8931290CurrentTrain: epoch  1, batch    36 | loss: 174.6624313CurrentTrain: epoch  1, batch    37 | loss: 225.7638574CurrentTrain: epoch  1, batch    38 | loss: 131.9033269CurrentTrain: epoch  1, batch    39 | loss: 124.6058441CurrentTrain: epoch  1, batch    40 | loss: 135.1601100CurrentTrain: epoch  1, batch    41 | loss: 126.4402416CurrentTrain: epoch  1, batch    42 | loss: 133.8445164CurrentTrain: epoch  1, batch    43 | loss: 97.5127165CurrentTrain: epoch  1, batch    44 | loss: 177.3322845CurrentTrain: epoch  1, batch    45 | loss: 144.9623708CurrentTrain: epoch  1, batch    46 | loss: 177.2860577CurrentTrain: epoch  1, batch    47 | loss: 117.4933126CurrentTrain: epoch  1, batch    48 | loss: 110.2005591CurrentTrain: epoch  1, batch    49 | loss: 143.9010681CurrentTrain: epoch  1, batch    50 | loss: 110.4549197CurrentTrain: epoch  1, batch    51 | loss: 118.3177760CurrentTrain: epoch  1, batch    52 | loss: 176.1407458CurrentTrain: epoch  1, batch    53 | loss: 132.9143656CurrentTrain: epoch  1, batch    54 | loss: 135.5238374CurrentTrain: epoch  1, batch    55 | loss: 169.5489461CurrentTrain: epoch  1, batch    56 | loss: 144.2738364CurrentTrain: epoch  1, batch    57 | loss: 103.9120769CurrentTrain: epoch  1, batch    58 | loss: 153.7595599CurrentTrain: epoch  1, batch    59 | loss: 116.0525581CurrentTrain: epoch  1, batch    60 | loss: 106.7065513CurrentTrain: epoch  1, batch    61 | loss: 120.9628311CurrentTrain: epoch  1, batch    62 | loss: 135.8497864CurrentTrain: epoch  1, batch    63 | loss: 127.2021373CurrentTrain: epoch  1, batch    64 | loss: 116.6221463CurrentTrain: epoch  1, batch    65 | loss: 140.0606690CurrentTrain: epoch  1, batch    66 | loss: 99.3437954CurrentTrain: epoch  1, batch    67 | loss: 147.5324689CurrentTrain: epoch  1, batch    68 | loss: 92.1228110CurrentTrain: epoch  1, batch    69 | loss: 160.8547124CurrentTrain: epoch  1, batch    70 | loss: 180.1964005CurrentTrain: epoch  1, batch    71 | loss: 102.4237575CurrentTrain: epoch  1, batch    72 | loss: 181.2706752CurrentTrain: epoch  1, batch    73 | loss: 179.0197233CurrentTrain: epoch  1, batch    74 | loss: 109.5283572CurrentTrain: epoch  1, batch    75 | loss: 120.1807555CurrentTrain: epoch  1, batch    76 | loss: 128.1760738CurrentTrain: epoch  1, batch    77 | loss: 124.6814464CurrentTrain: epoch  1, batch    78 | loss: 155.9572910CurrentTrain: epoch  1, batch    79 | loss: 124.1436757CurrentTrain: epoch  1, batch    80 | loss: 105.0181239CurrentTrain: epoch  1, batch    81 | loss: 172.8322948CurrentTrain: epoch  1, batch    82 | loss: 118.6559718CurrentTrain: epoch  1, batch    83 | loss: 148.3195665CurrentTrain: epoch  1, batch    84 | loss: 111.4624418CurrentTrain: epoch  1, batch    85 | loss: 131.2546601CurrentTrain: epoch  1, batch    86 | loss: 133.4652457CurrentTrain: epoch  1, batch    87 | loss: 129.6567104CurrentTrain: epoch  1, batch    88 | loss: 131.3506027CurrentTrain: epoch  1, batch    89 | loss: 121.6869832CurrentTrain: epoch  1, batch    90 | loss: 144.3866580CurrentTrain: epoch  1, batch    91 | loss: 131.6970003CurrentTrain: epoch  1, batch    92 | loss: 127.5672697CurrentTrain: epoch  1, batch    93 | loss: 144.6602612CurrentTrain: epoch  1, batch    94 | loss: 131.2073276CurrentTrain: epoch  1, batch    95 | loss: 90.2625270CurrentTrain: epoch  2, batch     0 | loss: 131.8972943CurrentTrain: epoch  2, batch     1 | loss: 122.0348423CurrentTrain: epoch  2, batch     2 | loss: 102.4915592CurrentTrain: epoch  2, batch     3 | loss: 101.2511523CurrentTrain: epoch  2, batch     4 | loss: 138.0963302CurrentTrain: epoch  2, batch     5 | loss: 151.4837809CurrentTrain: epoch  2, batch     6 | loss: 123.8065113CurrentTrain: epoch  2, batch     7 | loss: 116.6460969CurrentTrain: epoch  2, batch     8 | loss: 112.0047786CurrentTrain: epoch  2, batch     9 | loss: 147.7663812CurrentTrain: epoch  2, batch    10 | loss: 114.1641823CurrentTrain: epoch  2, batch    11 | loss: 128.3622477CurrentTrain: epoch  2, batch    12 | loss: 104.6929767CurrentTrain: epoch  2, batch    13 | loss: 115.7554046CurrentTrain: epoch  2, batch    14 | loss: 146.7356468CurrentTrain: epoch  2, batch    15 | loss: 102.1949359CurrentTrain: epoch  2, batch    16 | loss: 105.8868062CurrentTrain: epoch  2, batch    17 | loss: 205.0538020CurrentTrain: epoch  2, batch    18 | loss: 122.4534386CurrentTrain: epoch  2, batch    19 | loss: 155.6711327CurrentTrain: epoch  2, batch    20 | loss: 118.2715443CurrentTrain: epoch  2, batch    21 | loss: 136.2289550CurrentTrain: epoch  2, batch    22 | loss: 111.8889536CurrentTrain: epoch  2, batch    23 | loss: 122.2023321CurrentTrain: epoch  2, batch    24 | loss: 113.1930540CurrentTrain: epoch  2, batch    25 | loss: 121.8596974CurrentTrain: epoch  2, batch    26 | loss: 146.2608291CurrentTrain: epoch  2, batch    27 | loss: 108.2366696CurrentTrain: epoch  2, batch    28 | loss: 139.8251320CurrentTrain: epoch  2, batch    29 | loss: 111.3581662CurrentTrain: epoch  2, batch    30 | loss: 130.9902391CurrentTrain: epoch  2, batch    31 | loss: 147.4591337CurrentTrain: epoch  2, batch    32 | loss: 117.3387437CurrentTrain: epoch  2, batch    33 | loss: 122.1159170CurrentTrain: epoch  2, batch    34 | loss: 129.7286386CurrentTrain: epoch  2, batch    35 | loss: 130.3079950CurrentTrain: epoch  2, batch    36 | loss: 125.6166758CurrentTrain: epoch  2, batch    37 | loss: 170.4821267CurrentTrain: epoch  2, batch    38 | loss: 111.4011843CurrentTrain: epoch  2, batch    39 | loss: 142.8015079CurrentTrain: epoch  2, batch    40 | loss: 142.3974896CurrentTrain: epoch  2, batch    41 | loss: 119.2148002CurrentTrain: epoch  2, batch    42 | loss: 113.9084516CurrentTrain: epoch  2, batch    43 | loss: 120.4504687CurrentTrain: epoch  2, batch    44 | loss: 152.6649595CurrentTrain: epoch  2, batch    45 | loss: 127.1888218CurrentTrain: epoch  2, batch    46 | loss: 155.5097443CurrentTrain: epoch  2, batch    47 | loss: 148.7891538CurrentTrain: epoch  2, batch    48 | loss: 146.6545880CurrentTrain: epoch  2, batch    49 | loss: 153.4564314CurrentTrain: epoch  2, batch    50 | loss: 106.2786384CurrentTrain: epoch  2, batch    51 | loss: 112.7778330CurrentTrain: epoch  2, batch    52 | loss: 139.1582293CurrentTrain: epoch  2, batch    53 | loss: 122.2042015CurrentTrain: epoch  2, batch    54 | loss: 147.1945695CurrentTrain: epoch  2, batch    55 | loss: 129.0172643CurrentTrain: epoch  2, batch    56 | loss: 173.1413635CurrentTrain: epoch  2, batch    57 | loss: 145.0786049CurrentTrain: epoch  2, batch    58 | loss: 134.1648607CurrentTrain: epoch  2, batch    59 | loss: 140.0785349CurrentTrain: epoch  2, batch    60 | loss: 134.9989813CurrentTrain: epoch  2, batch    61 | loss: 141.7412656CurrentTrain: epoch  2, batch    62 | loss: 129.1104584CurrentTrain: epoch  2, batch    63 | loss: 144.2226914CurrentTrain: epoch  2, batch    64 | loss: 137.3953739CurrentTrain: epoch  2, batch    65 | loss: 133.2577596CurrentTrain: epoch  2, batch    66 | loss: 150.7680171CurrentTrain: epoch  2, batch    67 | loss: 152.6109579CurrentTrain: epoch  2, batch    68 | loss: 173.2129727CurrentTrain: epoch  2, batch    69 | loss: 150.4580335CurrentTrain: epoch  2, batch    70 | loss: 101.1391774CurrentTrain: epoch  2, batch    71 | loss: 142.0309375CurrentTrain: epoch  2, batch    72 | loss: 199.5109678CurrentTrain: epoch  2, batch    73 | loss: 137.7799554CurrentTrain: epoch  2, batch    74 | loss: 128.2513234CurrentTrain: epoch  2, batch    75 | loss: 115.5912172CurrentTrain: epoch  2, batch    76 | loss: 150.1423727CurrentTrain: epoch  2, batch    77 | loss: 115.5865112CurrentTrain: epoch  2, batch    78 | loss: 109.7348897CurrentTrain: epoch  2, batch    79 | loss: 143.5637440CurrentTrain: epoch  2, batch    80 | loss: 211.1296362CurrentTrain: epoch  2, batch    81 | loss: 128.6424581CurrentTrain: epoch  2, batch    82 | loss: 134.5360805CurrentTrain: epoch  2, batch    83 | loss: 86.0322991CurrentTrain: epoch  2, batch    84 | loss: 135.4669282CurrentTrain: epoch  2, batch    85 | loss: 95.6244187CurrentTrain: epoch  2, batch    86 | loss: 119.3530376CurrentTrain: epoch  2, batch    87 | loss: 124.9864339CurrentTrain: epoch  2, batch    88 | loss: 160.8051403CurrentTrain: epoch  2, batch    89 | loss: 176.1562173CurrentTrain: epoch  2, batch    90 | loss: 164.1557344CurrentTrain: epoch  2, batch    91 | loss: 154.0901824CurrentTrain: epoch  2, batch    92 | loss: 148.3677838CurrentTrain: epoch  2, batch    93 | loss: 153.0564370CurrentTrain: epoch  2, batch    94 | loss: 119.2615778CurrentTrain: epoch  2, batch    95 | loss: 114.4821078CurrentTrain: epoch  3, batch     0 | loss: 97.2601356CurrentTrain: epoch  3, batch     1 | loss: 109.6695644CurrentTrain: epoch  3, batch     2 | loss: 108.4958347CurrentTrain: epoch  3, batch     3 | loss: 124.0112328CurrentTrain: epoch  3, batch     4 | loss: 104.4440565CurrentTrain: epoch  3, batch     5 | loss: 122.6829421CurrentTrain: epoch  3, batch     6 | loss: 150.5602321CurrentTrain: epoch  3, batch     7 | loss: 120.0052827CurrentTrain: epoch  3, batch     8 | loss: 103.9566399CurrentTrain: epoch  3, batch     9 | loss: 154.3655640CurrentTrain: epoch  3, batch    10 | loss: 130.9839782CurrentTrain: epoch  3, batch    11 | loss: 128.1915456CurrentTrain: epoch  3, batch    12 | loss: 131.9565434CurrentTrain: epoch  3, batch    13 | loss: 154.4579184CurrentTrain: epoch  3, batch    14 | loss: 136.4876865CurrentTrain: epoch  3, batch    15 | loss: 154.0373290CurrentTrain: epoch  3, batch    16 | loss: 147.8014985CurrentTrain: epoch  3, batch    17 | loss: 123.0439545CurrentTrain: epoch  3, batch    18 | loss: 124.1651361CurrentTrain: epoch  3, batch    19 | loss: 135.0809396CurrentTrain: epoch  3, batch    20 | loss: 123.7369824CurrentTrain: epoch  3, batch    21 | loss: 99.8218767CurrentTrain: epoch  3, batch    22 | loss: 141.8674475CurrentTrain: epoch  3, batch    23 | loss: 203.0287394CurrentTrain: epoch  3, batch    24 | loss: 125.7290371CurrentTrain: epoch  3, batch    25 | loss: 148.6646940CurrentTrain: epoch  3, batch    26 | loss: 133.1717835CurrentTrain: epoch  3, batch    27 | loss: 171.0397751CurrentTrain: epoch  3, batch    28 | loss: 108.7941990CurrentTrain: epoch  3, batch    29 | loss: 140.3523963CurrentTrain: epoch  3, batch    30 | loss: 134.2566646CurrentTrain: epoch  3, batch    31 | loss: 101.7510122CurrentTrain: epoch  3, batch    32 | loss: 152.4572648CurrentTrain: epoch  3, batch    33 | loss: 125.1124960CurrentTrain: epoch  3, batch    34 | loss: 114.2092204CurrentTrain: epoch  3, batch    35 | loss: 110.4384279CurrentTrain: epoch  3, batch    36 | loss: 132.9484877CurrentTrain: epoch  3, batch    37 | loss: 106.4280872CurrentTrain: epoch  3, batch    38 | loss: 148.1974570CurrentTrain: epoch  3, batch    39 | loss: 138.3178164CurrentTrain: epoch  3, batch    40 | loss: 140.8814288CurrentTrain: epoch  3, batch    41 | loss: 119.5366752CurrentTrain: epoch  3, batch    42 | loss: 129.4545581CurrentTrain: epoch  3, batch    43 | loss: 133.1242339CurrentTrain: epoch  3, batch    44 | loss: 117.9354187CurrentTrain: epoch  3, batch    45 | loss: 125.4079797CurrentTrain: epoch  3, batch    46 | loss: 108.2958504CurrentTrain: epoch  3, batch    47 | loss: 122.6742162CurrentTrain: epoch  3, batch    48 | loss: 124.5274388CurrentTrain: epoch  3, batch    49 | loss: 143.9506470CurrentTrain: epoch  3, batch    50 | loss: 125.5360623CurrentTrain: epoch  3, batch    51 | loss: 131.4466290CurrentTrain: epoch  3, batch    52 | loss: 151.0228349CurrentTrain: epoch  3, batch    53 | loss: 94.5295693CurrentTrain: epoch  3, batch    54 | loss: 101.1120796CurrentTrain: epoch  3, batch    55 | loss: 120.9021796CurrentTrain: epoch  3, batch    56 | loss: 121.6504360CurrentTrain: epoch  3, batch    57 | loss: 153.4165025CurrentTrain: epoch  3, batch    58 | loss: 198.8533604CurrentTrain: epoch  3, batch    59 | loss: 114.9090735CurrentTrain: epoch  3, batch    60 | loss: 143.3743908CurrentTrain: epoch  3, batch    61 | loss: 138.1011733CurrentTrain: epoch  3, batch    62 | loss: 173.5240751CurrentTrain: epoch  3, batch    63 | loss: 127.3935609CurrentTrain: epoch  3, batch    64 | loss: 109.3078650CurrentTrain: epoch  3, batch    65 | loss: 116.4176195CurrentTrain: epoch  3, batch    66 | loss: 102.6910714CurrentTrain: epoch  3, batch    67 | loss: 168.0286067CurrentTrain: epoch  3, batch    68 | loss: 150.1163717CurrentTrain: epoch  3, batch    69 | loss: 151.8331541CurrentTrain: epoch  3, batch    70 | loss: 100.5312457CurrentTrain: epoch  3, batch    71 | loss: 121.8565408CurrentTrain: epoch  3, batch    72 | loss: 126.0124963CurrentTrain: epoch  3, batch    73 | loss: 134.6841542CurrentTrain: epoch  3, batch    74 | loss: 103.3513800CurrentTrain: epoch  3, batch    75 | loss: 126.6227121CurrentTrain: epoch  3, batch    76 | loss: 165.0925933CurrentTrain: epoch  3, batch    77 | loss: 107.3593343CurrentTrain: epoch  3, batch    78 | loss: 111.1185384CurrentTrain: epoch  3, batch    79 | loss: 126.8559568CurrentTrain: epoch  3, batch    80 | loss: 136.0926026CurrentTrain: epoch  3, batch    81 | loss: 117.1288824CurrentTrain: epoch  3, batch    82 | loss: 95.8478599CurrentTrain: epoch  3, batch    83 | loss: 134.7332926CurrentTrain: epoch  3, batch    84 | loss: 149.2987225CurrentTrain: epoch  3, batch    85 | loss: 110.7650220CurrentTrain: epoch  3, batch    86 | loss: 127.9579500CurrentTrain: epoch  3, batch    87 | loss: 138.3642296CurrentTrain: epoch  3, batch    88 | loss: 141.8277184CurrentTrain: epoch  3, batch    89 | loss: 167.9642526CurrentTrain: epoch  3, batch    90 | loss: 109.8545563CurrentTrain: epoch  3, batch    91 | loss: 147.7454900CurrentTrain: epoch  3, batch    92 | loss: 123.6482785CurrentTrain: epoch  3, batch    93 | loss: 98.7841188CurrentTrain: epoch  3, batch    94 | loss: 116.0230158CurrentTrain: epoch  3, batch    95 | loss: 118.1667978CurrentTrain: epoch  4, batch     0 | loss: 136.6474570CurrentTrain: epoch  4, batch     1 | loss: 132.2231155CurrentTrain: epoch  4, batch     2 | loss: 98.4475494CurrentTrain: epoch  4, batch     3 | loss: 177.0677268CurrentTrain: epoch  4, batch     4 | loss: 129.3617300CurrentTrain: epoch  4, batch     5 | loss: 132.3808640CurrentTrain: epoch  4, batch     6 | loss: 123.4282052CurrentTrain: epoch  4, batch     7 | loss: 102.3440369CurrentTrain: epoch  4, batch     8 | loss: 136.3980212CurrentTrain: epoch  4, batch     9 | loss: 96.6766121CurrentTrain: epoch  4, batch    10 | loss: 135.7287353CurrentTrain: epoch  4, batch    11 | loss: 127.6539418CurrentTrain: epoch  4, batch    12 | loss: 112.7180764CurrentTrain: epoch  4, batch    13 | loss: 161.8046557CurrentTrain: epoch  4, batch    14 | loss: 122.6159576CurrentTrain: epoch  4, batch    15 | loss: 109.8523023CurrentTrain: epoch  4, batch    16 | loss: 144.9506563CurrentTrain: epoch  4, batch    17 | loss: 126.8579131CurrentTrain: epoch  4, batch    18 | loss: 100.3760832CurrentTrain: epoch  4, batch    19 | loss: 113.1001792CurrentTrain: epoch  4, batch    20 | loss: 110.3591128CurrentTrain: epoch  4, batch    21 | loss: 94.5430928CurrentTrain: epoch  4, batch    22 | loss: 125.1522769CurrentTrain: epoch  4, batch    23 | loss: 120.6696891CurrentTrain: epoch  4, batch    24 | loss: 168.7340443CurrentTrain: epoch  4, batch    25 | loss: 115.9027806CurrentTrain: epoch  4, batch    26 | loss: 133.0177873CurrentTrain: epoch  4, batch    27 | loss: 115.4734569CurrentTrain: epoch  4, batch    28 | loss: 131.3239620CurrentTrain: epoch  4, batch    29 | loss: 167.4849588CurrentTrain: epoch  4, batch    30 | loss: 133.5439673CurrentTrain: epoch  4, batch    31 | loss: 144.1065196CurrentTrain: epoch  4, batch    32 | loss: 126.8177741CurrentTrain: epoch  4, batch    33 | loss: 141.1635302CurrentTrain: epoch  4, batch    34 | loss: 138.1820413CurrentTrain: epoch  4, batch    35 | loss: 125.9039726CurrentTrain: epoch  4, batch    36 | loss: 150.5843281CurrentTrain: epoch  4, batch    37 | loss: 116.9845141CurrentTrain: epoch  4, batch    38 | loss: 167.1694130CurrentTrain: epoch  4, batch    39 | loss: 133.3119668CurrentTrain: epoch  4, batch    40 | loss: 162.0228043CurrentTrain: epoch  4, batch    41 | loss: 126.6338144CurrentTrain: epoch  4, batch    42 | loss: 107.3381393CurrentTrain: epoch  4, batch    43 | loss: 165.8251262CurrentTrain: epoch  4, batch    44 | loss: 129.7732465CurrentTrain: epoch  4, batch    45 | loss: 144.3299674CurrentTrain: epoch  4, batch    46 | loss: 122.2384610CurrentTrain: epoch  4, batch    47 | loss: 107.5662316CurrentTrain: epoch  4, batch    48 | loss: 117.6070693CurrentTrain: epoch  4, batch    49 | loss: 126.5753473CurrentTrain: epoch  4, batch    50 | loss: 125.2055699CurrentTrain: epoch  4, batch    51 | loss: 149.0292892CurrentTrain: epoch  4, batch    52 | loss: 108.8167775CurrentTrain: epoch  4, batch    53 | loss: 119.7846903CurrentTrain: epoch  4, batch    54 | loss: 150.1636284CurrentTrain: epoch  4, batch    55 | loss: 115.8622889CurrentTrain: epoch  4, batch    56 | loss: 124.4604139CurrentTrain: epoch  4, batch    57 | loss: 129.4109439CurrentTrain: epoch  4, batch    58 | loss: 113.0663150CurrentTrain: epoch  4, batch    59 | loss: 110.6440516CurrentTrain: epoch  4, batch    60 | loss: 155.4170427CurrentTrain: epoch  4, batch    61 | loss: 112.3024863CurrentTrain: epoch  4, batch    62 | loss: 114.9528047CurrentTrain: epoch  4, batch    63 | loss: 127.6821660CurrentTrain: epoch  4, batch    64 | loss: 133.9462426CurrentTrain: epoch  4, batch    65 | loss: 114.3868505CurrentTrain: epoch  4, batch    66 | loss: 118.6221893CurrentTrain: epoch  4, batch    67 | loss: 111.1446043CurrentTrain: epoch  4, batch    68 | loss: 127.8111875CurrentTrain: epoch  4, batch    69 | loss: 133.7084500CurrentTrain: epoch  4, batch    70 | loss: 113.3806902CurrentTrain: epoch  4, batch    71 | loss: 138.9115135CurrentTrain: epoch  4, batch    72 | loss: 127.1490567CurrentTrain: epoch  4, batch    73 | loss: 113.0651568CurrentTrain: epoch  4, batch    74 | loss: 141.7639101CurrentTrain: epoch  4, batch    75 | loss: 101.6037109CurrentTrain: epoch  4, batch    76 | loss: 150.6204519CurrentTrain: epoch  4, batch    77 | loss: 116.6272045CurrentTrain: epoch  4, batch    78 | loss: 170.8012248CurrentTrain: epoch  4, batch    79 | loss: 117.9372109CurrentTrain: epoch  4, batch    80 | loss: 123.4208316CurrentTrain: epoch  4, batch    81 | loss: 111.4230379CurrentTrain: epoch  4, batch    82 | loss: 108.1550691CurrentTrain: epoch  4, batch    83 | loss: 125.6129680CurrentTrain: epoch  4, batch    84 | loss: 139.0042275CurrentTrain: epoch  4, batch    85 | loss: 107.3301762CurrentTrain: epoch  4, batch    86 | loss: 205.0866379CurrentTrain: epoch  4, batch    87 | loss: 142.2619666CurrentTrain: epoch  4, batch    88 | loss: 123.2102030CurrentTrain: epoch  4, batch    89 | loss: 112.9967731CurrentTrain: epoch  4, batch    90 | loss: 134.3905366CurrentTrain: epoch  4, batch    91 | loss: 111.9900243CurrentTrain: epoch  4, batch    92 | loss: 141.0267027CurrentTrain: epoch  4, batch    93 | loss: 124.3519345CurrentTrain: epoch  4, batch    94 | loss: 120.0199671CurrentTrain: epoch  4, batch    95 | loss: 123.4873127CurrentTrain: epoch  5, batch     0 | loss: 96.3292839CurrentTrain: epoch  5, batch     1 | loss: 127.6180087CurrentTrain: epoch  5, batch     2 | loss: 121.4487256CurrentTrain: epoch  5, batch     3 | loss: 128.4787023CurrentTrain: epoch  5, batch     4 | loss: 140.8427180CurrentTrain: epoch  5, batch     5 | loss: 195.7186777CurrentTrain: epoch  5, batch     6 | loss: 169.3109583CurrentTrain: epoch  5, batch     7 | loss: 133.0680897CurrentTrain: epoch  5, batch     8 | loss: 132.9511062CurrentTrain: epoch  5, batch     9 | loss: 194.3754781CurrentTrain: epoch  5, batch    10 | loss: 136.9327621CurrentTrain: epoch  5, batch    11 | loss: 97.7564070CurrentTrain: epoch  5, batch    12 | loss: 132.6800295CurrentTrain: epoch  5, batch    13 | loss: 121.6155116CurrentTrain: epoch  5, batch    14 | loss: 130.3003479CurrentTrain: epoch  5, batch    15 | loss: 126.4629254CurrentTrain: epoch  5, batch    16 | loss: 140.1483173CurrentTrain: epoch  5, batch    17 | loss: 129.6014577CurrentTrain: epoch  5, batch    18 | loss: 126.3277543CurrentTrain: epoch  5, batch    19 | loss: 115.5690030CurrentTrain: epoch  5, batch    20 | loss: 133.4074799CurrentTrain: epoch  5, batch    21 | loss: 142.8268371CurrentTrain: epoch  5, batch    22 | loss: 136.0901571CurrentTrain: epoch  5, batch    23 | loss: 122.1840720CurrentTrain: epoch  5, batch    24 | loss: 147.0466293CurrentTrain: epoch  5, batch    25 | loss: 101.8256542CurrentTrain: epoch  5, batch    26 | loss: 117.1662123CurrentTrain: epoch  5, batch    27 | loss: 132.2438849CurrentTrain: epoch  5, batch    28 | loss: 98.6923651CurrentTrain: epoch  5, batch    29 | loss: 104.9209886CurrentTrain: epoch  5, batch    30 | loss: 91.1481489CurrentTrain: epoch  5, batch    31 | loss: 107.7446004CurrentTrain: epoch  5, batch    32 | loss: 119.9279107CurrentTrain: epoch  5, batch    33 | loss: 124.3569655CurrentTrain: epoch  5, batch    34 | loss: 111.3385656CurrentTrain: epoch  5, batch    35 | loss: 125.0658195CurrentTrain: epoch  5, batch    36 | loss: 130.2093379CurrentTrain: epoch  5, batch    37 | loss: 145.9282015CurrentTrain: epoch  5, batch    38 | loss: 130.0893807CurrentTrain: epoch  5, batch    39 | loss: 116.7734402CurrentTrain: epoch  5, batch    40 | loss: 96.2896223CurrentTrain: epoch  5, batch    41 | loss: 155.1464124CurrentTrain: epoch  5, batch    42 | loss: 142.2679013CurrentTrain: epoch  5, batch    43 | loss: 126.4943838CurrentTrain: epoch  5, batch    44 | loss: 136.0697637CurrentTrain: epoch  5, batch    45 | loss: 136.3984724CurrentTrain: epoch  5, batch    46 | loss: 128.9632653CurrentTrain: epoch  5, batch    47 | loss: 99.5316518CurrentTrain: epoch  5, batch    48 | loss: 121.9265595CurrentTrain: epoch  5, batch    49 | loss: 137.1130157CurrentTrain: epoch  5, batch    50 | loss: 135.8476647CurrentTrain: epoch  5, batch    51 | loss: 130.3672304CurrentTrain: epoch  5, batch    52 | loss: 132.0296297CurrentTrain: epoch  5, batch    53 | loss: 163.9741479CurrentTrain: epoch  5, batch    54 | loss: 129.2208131CurrentTrain: epoch  5, batch    55 | loss: 119.8628776CurrentTrain: epoch  5, batch    56 | loss: 132.4996804CurrentTrain: epoch  5, batch    57 | loss: 117.3244960CurrentTrain: epoch  5, batch    58 | loss: 142.6198341CurrentTrain: epoch  5, batch    59 | loss: 169.3822407CurrentTrain: epoch  5, batch    60 | loss: 117.2462661CurrentTrain: epoch  5, batch    61 | loss: 123.8336549CurrentTrain: epoch  5, batch    62 | loss: 138.7565653CurrentTrain: epoch  5, batch    63 | loss: 110.9823541CurrentTrain: epoch  5, batch    64 | loss: 129.4812345CurrentTrain: epoch  5, batch    65 | loss: 105.7201122CurrentTrain: epoch  5, batch    66 | loss: 113.6811057CurrentTrain: epoch  5, batch    67 | loss: 117.2567190CurrentTrain: epoch  5, batch    68 | loss: 116.9655620CurrentTrain: epoch  5, batch    69 | loss: 109.5008901CurrentTrain: epoch  5, batch    70 | loss: 142.3851333CurrentTrain: epoch  5, batch    71 | loss: 125.3013356CurrentTrain: epoch  5, batch    72 | loss: 107.5481562CurrentTrain: epoch  5, batch    73 | loss: 146.7378093CurrentTrain: epoch  5, batch    74 | loss: 112.1534931CurrentTrain: epoch  5, batch    75 | loss: 161.7339899CurrentTrain: epoch  5, batch    76 | loss: 107.4584106CurrentTrain: epoch  5, batch    77 | loss: 158.7271736CurrentTrain: epoch  5, batch    78 | loss: 142.4105975CurrentTrain: epoch  5, batch    79 | loss: 118.3904879CurrentTrain: epoch  5, batch    80 | loss: 119.4682160CurrentTrain: epoch  5, batch    81 | loss: 123.0239905CurrentTrain: epoch  5, batch    82 | loss: 111.9628335CurrentTrain: epoch  5, batch    83 | loss: 133.7919100CurrentTrain: epoch  5, batch    84 | loss: 124.8324153CurrentTrain: epoch  5, batch    85 | loss: 101.7981963CurrentTrain: epoch  5, batch    86 | loss: 132.6743676CurrentTrain: epoch  5, batch    87 | loss: 128.7123884CurrentTrain: epoch  5, batch    88 | loss: 171.4828193CurrentTrain: epoch  5, batch    89 | loss: 104.9449559CurrentTrain: epoch  5, batch    90 | loss: 122.8209907CurrentTrain: epoch  5, batch    91 | loss: 114.2364305CurrentTrain: epoch  5, batch    92 | loss: 140.6390139CurrentTrain: epoch  5, batch    93 | loss: 93.9714437CurrentTrain: epoch  5, batch    94 | loss: 116.8342836CurrentTrain: epoch  5, batch    95 | loss: 119.3658934CurrentTrain: epoch  6, batch     0 | loss: 114.7381291CurrentTrain: epoch  6, batch     1 | loss: 122.7462695CurrentTrain: epoch  6, batch     2 | loss: 135.4730281CurrentTrain: epoch  6, batch     3 | loss: 114.5832865CurrentTrain: epoch  6, batch     4 | loss: 91.4183232CurrentTrain: epoch  6, batch     5 | loss: 111.1388596CurrentTrain: epoch  6, batch     6 | loss: 127.3912948CurrentTrain: epoch  6, batch     7 | loss: 121.8123768CurrentTrain: epoch  6, batch     8 | loss: 130.6676404CurrentTrain: epoch  6, batch     9 | loss: 142.1721885CurrentTrain: epoch  6, batch    10 | loss: 109.6749114CurrentTrain: epoch  6, batch    11 | loss: 103.1809668CurrentTrain: epoch  6, batch    12 | loss: 148.9333876CurrentTrain: epoch  6, batch    13 | loss: 127.5800895CurrentTrain: epoch  6, batch    14 | loss: 142.4867957CurrentTrain: epoch  6, batch    15 | loss: 121.6995907CurrentTrain: epoch  6, batch    16 | loss: 100.3508778CurrentTrain: epoch  6, batch    17 | loss: 119.7651827CurrentTrain: epoch  6, batch    18 | loss: 106.4472386CurrentTrain: epoch  6, batch    19 | loss: 139.7570191CurrentTrain: epoch  6, batch    20 | loss: 99.0754596CurrentTrain: epoch  6, batch    21 | loss: 121.2898731CurrentTrain: epoch  6, batch    22 | loss: 114.3900360CurrentTrain: epoch  6, batch    23 | loss: 98.0260689CurrentTrain: epoch  6, batch    24 | loss: 129.4721970CurrentTrain: epoch  6, batch    25 | loss: 107.9745569CurrentTrain: epoch  6, batch    26 | loss: 99.2622599CurrentTrain: epoch  6, batch    27 | loss: 126.5061215CurrentTrain: epoch  6, batch    28 | loss: 102.1758907CurrentTrain: epoch  6, batch    29 | loss: 136.4979164CurrentTrain: epoch  6, batch    30 | loss: 119.6862149CurrentTrain: epoch  6, batch    31 | loss: 110.8188613CurrentTrain: epoch  6, batch    32 | loss: 173.1091052CurrentTrain: epoch  6, batch    33 | loss: 122.6683371CurrentTrain: epoch  6, batch    34 | loss: 148.2927375CurrentTrain: epoch  6, batch    35 | loss: 100.1780547CurrentTrain: epoch  6, batch    36 | loss: 138.3614506CurrentTrain: epoch  6, batch    37 | loss: 104.1270124CurrentTrain: epoch  6, batch    38 | loss: 119.9182743CurrentTrain: epoch  6, batch    39 | loss: 138.9248728CurrentTrain: epoch  6, batch    40 | loss: 128.1234604CurrentTrain: epoch  6, batch    41 | loss: 124.4947723CurrentTrain: epoch  6, batch    42 | loss: 151.5831059CurrentTrain: epoch  6, batch    43 | loss: 120.7909346CurrentTrain: epoch  6, batch    44 | loss: 135.6540585CurrentTrain: epoch  6, batch    45 | loss: 162.1126224CurrentTrain: epoch  6, batch    46 | loss: 125.3024068CurrentTrain: epoch  6, batch    47 | loss: 201.8360981CurrentTrain: epoch  6, batch    48 | loss: 206.5309899CurrentTrain: epoch  6, batch    49 | loss: 200.5313497CurrentTrain: epoch  6, batch    50 | loss: 103.0183429CurrentTrain: epoch  6, batch    51 | loss: 125.1302132CurrentTrain: epoch  6, batch    52 | loss: 127.8812442CurrentTrain: epoch  6, batch    53 | loss: 145.8104480CurrentTrain: epoch  6, batch    54 | loss: 106.0789310CurrentTrain: epoch  6, batch    55 | loss: 105.5716163CurrentTrain: epoch  6, batch    56 | loss: 122.1119396CurrentTrain: epoch  6, batch    57 | loss: 128.7589778CurrentTrain: epoch  6, batch    58 | loss: 100.7165552CurrentTrain: epoch  6, batch    59 | loss: 143.0256017CurrentTrain: epoch  6, batch    60 | loss: 122.3366741CurrentTrain: epoch  6, batch    61 | loss: 125.7827429CurrentTrain: epoch  6, batch    62 | loss: 140.3485835CurrentTrain: epoch  6, batch    63 | loss: 95.2641242CurrentTrain: epoch  6, batch    64 | loss: 134.4346254CurrentTrain: epoch  6, batch    65 | loss: 94.5625020CurrentTrain: epoch  6, batch    66 | loss: 122.2296954CurrentTrain: epoch  6, batch    67 | loss: 119.0252696CurrentTrain: epoch  6, batch    68 | loss: 107.5540328CurrentTrain: epoch  6, batch    69 | loss: 99.8193933CurrentTrain: epoch  6, batch    70 | loss: 125.1236008CurrentTrain: epoch  6, batch    71 | loss: 131.4209327CurrentTrain: epoch  6, batch    72 | loss: 152.6931020CurrentTrain: epoch  6, batch    73 | loss: 89.4912441CurrentTrain: epoch  6, batch    74 | loss: 165.3012430CurrentTrain: epoch  6, batch    75 | loss: 111.6411275CurrentTrain: epoch  6, batch    76 | loss: 132.4244690CurrentTrain: epoch  6, batch    77 | loss: 135.6669587CurrentTrain: epoch  6, batch    78 | loss: 125.3598994CurrentTrain: epoch  6, batch    79 | loss: 119.2999251CurrentTrain: epoch  6, batch    80 | loss: 112.6335180CurrentTrain: epoch  6, batch    81 | loss: 150.5002679CurrentTrain: epoch  6, batch    82 | loss: 113.6163784CurrentTrain: epoch  6, batch    83 | loss: 207.4708689CurrentTrain: epoch  6, batch    84 | loss: 125.0739098CurrentTrain: epoch  6, batch    85 | loss: 126.6488860CurrentTrain: epoch  6, batch    86 | loss: 162.8837661CurrentTrain: epoch  6, batch    87 | loss: 124.5735049CurrentTrain: epoch  6, batch    88 | loss: 96.3419616CurrentTrain: epoch  6, batch    89 | loss: 108.4234998CurrentTrain: epoch  6, batch    90 | loss: 107.6711498CurrentTrain: epoch  6, batch    91 | loss: 137.6739510CurrentTrain: epoch  6, batch    92 | loss: 125.6396484CurrentTrain: epoch  6, batch    93 | loss: 141.3704883CurrentTrain: epoch  6, batch    94 | loss: 88.6801922CurrentTrain: epoch  6, batch    95 | loss: 114.1734795CurrentTrain: epoch  7, batch     0 | loss: 106.6464178CurrentTrain: epoch  7, batch     1 | loss: 97.0493568CurrentTrain: epoch  7, batch     2 | loss: 140.7494867CurrentTrain: epoch  7, batch     3 | loss: 130.5202568CurrentTrain: epoch  7, batch     4 | loss: 130.0634592CurrentTrain: epoch  7, batch     5 | loss: 119.9660370CurrentTrain: epoch  7, batch     6 | loss: 104.4841620CurrentTrain: epoch  7, batch     7 | loss: 143.7782684CurrentTrain: epoch  7, batch     8 | loss: 151.9771575CurrentTrain: epoch  7, batch     9 | loss: 130.4711442CurrentTrain: epoch  7, batch    10 | loss: 112.7489023CurrentTrain: epoch  7, batch    11 | loss: 142.2880878CurrentTrain: epoch  7, batch    12 | loss: 92.9446402CurrentTrain: epoch  7, batch    13 | loss: 124.3382938CurrentTrain: epoch  7, batch    14 | loss: 111.8506341CurrentTrain: epoch  7, batch    15 | loss: 122.8821976CurrentTrain: epoch  7, batch    16 | loss: 113.9085870CurrentTrain: epoch  7, batch    17 | loss: 140.5632979CurrentTrain: epoch  7, batch    18 | loss: 116.0674864CurrentTrain: epoch  7, batch    19 | loss: 134.4609132CurrentTrain: epoch  7, batch    20 | loss: 142.5002701CurrentTrain: epoch  7, batch    21 | loss: 163.8882040CurrentTrain: epoch  7, batch    22 | loss: 136.0334328CurrentTrain: epoch  7, batch    23 | loss: 114.8899301CurrentTrain: epoch  7, batch    24 | loss: 103.8030784CurrentTrain: epoch  7, batch    25 | loss: 138.2781698CurrentTrain: epoch  7, batch    26 | loss: 145.4841115CurrentTrain: epoch  7, batch    27 | loss: 139.0013144CurrentTrain: epoch  7, batch    28 | loss: 108.7892533CurrentTrain: epoch  7, batch    29 | loss: 144.1878188CurrentTrain: epoch  7, batch    30 | loss: 106.9971364CurrentTrain: epoch  7, batch    31 | loss: 95.5167438CurrentTrain: epoch  7, batch    32 | loss: 169.7984724CurrentTrain: epoch  7, batch    33 | loss: 101.4192839CurrentTrain: epoch  7, batch    34 | loss: 99.6998626CurrentTrain: epoch  7, batch    35 | loss: 162.1475965CurrentTrain: epoch  7, batch    36 | loss: 146.1071049CurrentTrain: epoch  7, batch    37 | loss: 105.2211269CurrentTrain: epoch  7, batch    38 | loss: 93.2800358CurrentTrain: epoch  7, batch    39 | loss: 131.9421143CurrentTrain: epoch  7, batch    40 | loss: 124.2893811CurrentTrain: epoch  7, batch    41 | loss: 111.2965082CurrentTrain: epoch  7, batch    42 | loss: 137.3122190CurrentTrain: epoch  7, batch    43 | loss: 149.1881083CurrentTrain: epoch  7, batch    44 | loss: 144.8858103CurrentTrain: epoch  7, batch    45 | loss: 105.2792764CurrentTrain: epoch  7, batch    46 | loss: 108.7627044CurrentTrain: epoch  7, batch    47 | loss: 145.2981530CurrentTrain: epoch  7, batch    48 | loss: 100.2131331CurrentTrain: epoch  7, batch    49 | loss: 109.8284954CurrentTrain: epoch  7, batch    50 | loss: 146.1777386CurrentTrain: epoch  7, batch    51 | loss: 150.0445340CurrentTrain: epoch  7, batch    52 | loss: 111.0471886CurrentTrain: epoch  7, batch    53 | loss: 165.7121824CurrentTrain: epoch  7, batch    54 | loss: 113.7814477CurrentTrain: epoch  7, batch    55 | loss: 98.4805382CurrentTrain: epoch  7, batch    56 | loss: 102.7659726CurrentTrain: epoch  7, batch    57 | loss: 110.6337705CurrentTrain: epoch  7, batch    58 | loss: 108.2256834CurrentTrain: epoch  7, batch    59 | loss: 122.8038664CurrentTrain: epoch  7, batch    60 | loss: 124.0001119CurrentTrain: epoch  7, batch    61 | loss: 119.0066663CurrentTrain: epoch  7, batch    62 | loss: 106.0890265CurrentTrain: epoch  7, batch    63 | loss: 121.0666195CurrentTrain: epoch  7, batch    64 | loss: 145.1360993CurrentTrain: epoch  7, batch    65 | loss: 141.7173835CurrentTrain: epoch  7, batch    66 | loss: 105.6207100CurrentTrain: epoch  7, batch    67 | loss: 125.7356834CurrentTrain: epoch  7, batch    68 | loss: 146.5196685CurrentTrain: epoch  7, batch    69 | loss: 140.2690975CurrentTrain: epoch  7, batch    70 | loss: 108.3298869CurrentTrain: epoch  7, batch    71 | loss: 142.8909029CurrentTrain: epoch  7, batch    72 | loss: 119.7938146CurrentTrain: epoch  7, batch    73 | loss: 121.9834777CurrentTrain: epoch  7, batch    74 | loss: 128.2130694CurrentTrain: epoch  7, batch    75 | loss: 115.0762836CurrentTrain: epoch  7, batch    76 | loss: 118.3286691CurrentTrain: epoch  7, batch    77 | loss: 140.8735119CurrentTrain: epoch  7, batch    78 | loss: 137.3896644