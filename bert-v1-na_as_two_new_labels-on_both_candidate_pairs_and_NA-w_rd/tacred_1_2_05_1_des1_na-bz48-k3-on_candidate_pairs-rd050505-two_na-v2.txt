#############params############
cuda
Task=Tacred, 5-shot
Encoding model: bert
pattern=hybridprompt
mem=1, margin=0.3, gen=0, gen_num=2
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 127.7220815CurrentTrain: epoch  0, batch     1 | loss: 90.8537670CurrentTrain: epoch  0, batch     2 | loss: 78.5323921CurrentTrain: epoch  0, batch     3 | loss: 88.1128571CurrentTrain: epoch  0, batch     4 | loss: 87.4117280CurrentTrain: epoch  0, batch     5 | loss: 87.5333214CurrentTrain: epoch  0, batch     6 | loss: 102.3014731CurrentTrain: epoch  0, batch     7 | loss: 100.8056232CurrentTrain: epoch  0, batch     8 | loss: 86.0447957CurrentTrain: epoch  0, batch     9 | loss: 86.6402145CurrentTrain: epoch  0, batch    10 | loss: 77.1439328CurrentTrain: epoch  0, batch    11 | loss: 101.0717962CurrentTrain: epoch  0, batch    12 | loss: 99.3287881CurrentTrain: epoch  0, batch    13 | loss: 193.6430926CurrentTrain: epoch  0, batch    14 | loss: 100.5473317CurrentTrain: epoch  0, batch    15 | loss: 86.6449568CurrentTrain: epoch  0, batch    16 | loss: 86.5268141CurrentTrain: epoch  0, batch    17 | loss: 118.3328572CurrentTrain: epoch  0, batch    18 | loss: 99.6282163CurrentTrain: epoch  0, batch    19 | loss: 86.3030368CurrentTrain: epoch  0, batch    20 | loss: 146.9915411CurrentTrain: epoch  0, batch    21 | loss: 146.0146033CurrentTrain: epoch  0, batch    22 | loss: 193.6439938CurrentTrain: epoch  0, batch    23 | loss: 146.0423845CurrentTrain: epoch  0, batch    24 | loss: 99.5199866CurrentTrain: epoch  0, batch    25 | loss: 192.0097653CurrentTrain: epoch  0, batch    26 | loss: 86.0187017CurrentTrain: epoch  0, batch    27 | loss: 117.9216637CurrentTrain: epoch  0, batch    28 | loss: 145.0175038CurrentTrain: epoch  0, batch    29 | loss: 98.7948389CurrentTrain: epoch  0, batch    30 | loss: 145.8730963CurrentTrain: epoch  0, batch    31 | loss: 145.7998216CurrentTrain: epoch  0, batch    32 | loss: 117.3520937CurrentTrain: epoch  0, batch    33 | loss: 85.1911073CurrentTrain: epoch  0, batch    34 | loss: 146.7689917CurrentTrain: epoch  0, batch    35 | loss: 85.3717775CurrentTrain: epoch  0, batch    36 | loss: 84.9059110CurrentTrain: epoch  0, batch    37 | loss: 98.6630096CurrentTrain: epoch  0, batch    38 | loss: 97.9597963CurrentTrain: epoch  0, batch    39 | loss: 84.6973671CurrentTrain: epoch  0, batch    40 | loss: 117.2859446CurrentTrain: epoch  0, batch    41 | loss: 85.9399880CurrentTrain: epoch  0, batch    42 | loss: 84.7489946CurrentTrain: epoch  0, batch    43 | loss: 74.3029010CurrentTrain: epoch  0, batch    44 | loss: 97.7797129CurrentTrain: epoch  0, batch    45 | loss: 82.9831611CurrentTrain: epoch  0, batch    46 | loss: 114.9301514CurrentTrain: epoch  0, batch    47 | loss: 83.4750115CurrentTrain: epoch  0, batch    48 | loss: 97.0654257CurrentTrain: epoch  0, batch    49 | loss: 97.5463982CurrentTrain: epoch  0, batch    50 | loss: 97.1173311CurrentTrain: epoch  0, batch    51 | loss: 97.5744960CurrentTrain: epoch  0, batch    52 | loss: 96.5210653CurrentTrain: epoch  0, batch    53 | loss: 143.4349095CurrentTrain: epoch  0, batch    54 | loss: 115.8313110CurrentTrain: epoch  0, batch    55 | loss: 82.3607249CurrentTrain: epoch  0, batch    56 | loss: 83.7162996CurrentTrain: epoch  0, batch    57 | loss: 95.7088784CurrentTrain: epoch  0, batch    58 | loss: 94.7578587CurrentTrain: epoch  0, batch    59 | loss: 95.8697010CurrentTrain: epoch  0, batch    60 | loss: 93.7021047CurrentTrain: epoch  0, batch    61 | loss: 96.0936507CurrentTrain: epoch  0, batch    62 | loss: 83.0658204CurrentTrain: epoch  0, batch    63 | loss: 112.5762518CurrentTrain: epoch  0, batch    64 | loss: 94.8880371CurrentTrain: epoch  0, batch    65 | loss: 71.5070593CurrentTrain: epoch  0, batch    66 | loss: 91.2670019CurrentTrain: epoch  0, batch    67 | loss: 94.8744973CurrentTrain: epoch  0, batch    68 | loss: 82.7126615CurrentTrain: epoch  0, batch    69 | loss: 141.3598899CurrentTrain: epoch  0, batch    70 | loss: 118.0962400CurrentTrain: epoch  0, batch    71 | loss: 82.7629536CurrentTrain: epoch  0, batch    72 | loss: 96.8317535CurrentTrain: epoch  0, batch    73 | loss: 113.1297511CurrentTrain: epoch  0, batch    74 | loss: 142.8965795CurrentTrain: epoch  0, batch    75 | loss: 95.8275130CurrentTrain: epoch  0, batch    76 | loss: 110.3827453CurrentTrain: epoch  0, batch    77 | loss: 92.9402052CurrentTrain: epoch  0, batch    78 | loss: 112.1313197CurrentTrain: epoch  0, batch    79 | loss: 112.0232035CurrentTrain: epoch  0, batch    80 | loss: 79.7002386CurrentTrain: epoch  0, batch    81 | loss: 93.0355828CurrentTrain: epoch  0, batch    82 | loss: 111.7535893CurrentTrain: epoch  0, batch    83 | loss: 93.3605341CurrentTrain: epoch  0, batch    84 | loss: 108.7136492CurrentTrain: epoch  0, batch    85 | loss: 80.1620752CurrentTrain: epoch  0, batch    86 | loss: 136.3403675CurrentTrain: epoch  0, batch    87 | loss: 81.3434996CurrentTrain: epoch  0, batch    88 | loss: 80.1902484CurrentTrain: epoch  0, batch    89 | loss: 65.9283851CurrentTrain: epoch  0, batch    90 | loss: 92.6883445CurrentTrain: epoch  0, batch    91 | loss: 80.5605219CurrentTrain: epoch  0, batch    92 | loss: 89.9550952CurrentTrain: epoch  0, batch    93 | loss: 136.2417680CurrentTrain: epoch  0, batch    94 | loss: 79.4368533CurrentTrain: epoch  0, batch    95 | loss: 94.1028033CurrentTrain: epoch  1, batch     0 | loss: 79.1429669CurrentTrain: epoch  1, batch     1 | loss: 93.0247809CurrentTrain: epoch  1, batch     2 | loss: 79.0163414CurrentTrain: epoch  1, batch     3 | loss: 79.0209095CurrentTrain: epoch  1, batch     4 | loss: 87.7541311CurrentTrain: epoch  1, batch     5 | loss: 76.2606386CurrentTrain: epoch  1, batch     6 | loss: 94.2187478CurrentTrain: epoch  1, batch     7 | loss: 136.8310789CurrentTrain: epoch  1, batch     8 | loss: 69.3790603CurrentTrain: epoch  1, batch     9 | loss: 106.9774350CurrentTrain: epoch  1, batch    10 | loss: 90.8905436CurrentTrain: epoch  1, batch    11 | loss: 77.5357204CurrentTrain: epoch  1, batch    12 | loss: 76.0211653CurrentTrain: epoch  1, batch    13 | loss: 109.6709184CurrentTrain: epoch  1, batch    14 | loss: 105.1983362CurrentTrain: epoch  1, batch    15 | loss: 93.1846833CurrentTrain: epoch  1, batch    16 | loss: 134.8801358CurrentTrain: epoch  1, batch    17 | loss: 76.3148647CurrentTrain: epoch  1, batch    18 | loss: 86.3018538CurrentTrain: epoch  1, batch    19 | loss: 109.4442914CurrentTrain: epoch  1, batch    20 | loss: 139.8958346CurrentTrain: epoch  1, batch    21 | loss: 78.9517428CurrentTrain: epoch  1, batch    22 | loss: 75.3826283CurrentTrain: epoch  1, batch    23 | loss: 89.8832138CurrentTrain: epoch  1, batch    24 | loss: 134.8857564CurrentTrain: epoch  1, batch    25 | loss: 90.5308116CurrentTrain: epoch  1, batch    26 | loss: 65.7775832CurrentTrain: epoch  1, batch    27 | loss: 75.5091261CurrentTrain: epoch  1, batch    28 | loss: 64.9733965CurrentTrain: epoch  1, batch    29 | loss: 66.4604193CurrentTrain: epoch  1, batch    30 | loss: 91.9495896CurrentTrain: epoch  1, batch    31 | loss: 89.3838674CurrentTrain: epoch  1, batch    32 | loss: 110.9344328CurrentTrain: epoch  1, batch    33 | loss: 93.4560238CurrentTrain: epoch  1, batch    34 | loss: 104.0894502CurrentTrain: epoch  1, batch    35 | loss: 137.7108432CurrentTrain: epoch  1, batch    36 | loss: 77.8256685CurrentTrain: epoch  1, batch    37 | loss: 89.3017208CurrentTrain: epoch  1, batch    38 | loss: 92.1261048CurrentTrain: epoch  1, batch    39 | loss: 65.5486245CurrentTrain: epoch  1, batch    40 | loss: 73.0859956CurrentTrain: epoch  1, batch    41 | loss: 73.7284734CurrentTrain: epoch  1, batch    42 | loss: 80.6756952CurrentTrain: epoch  1, batch    43 | loss: 88.8225415CurrentTrain: epoch  1, batch    44 | loss: 135.9653326CurrentTrain: epoch  1, batch    45 | loss: 89.0180744CurrentTrain: epoch  1, batch    46 | loss: 108.8275860CurrentTrain: epoch  1, batch    47 | loss: 72.7471184CurrentTrain: epoch  1, batch    48 | loss: 91.0108875CurrentTrain: epoch  1, batch    49 | loss: 90.2786367CurrentTrain: epoch  1, batch    50 | loss: 88.3684180CurrentTrain: epoch  1, batch    51 | loss: 112.2827300CurrentTrain: epoch  1, batch    52 | loss: 111.3170320CurrentTrain: epoch  1, batch    53 | loss: 136.9346198CurrentTrain: epoch  1, batch    54 | loss: 79.1999905CurrentTrain: epoch  1, batch    55 | loss: 90.4883873CurrentTrain: epoch  1, batch    56 | loss: 88.1583225CurrentTrain: epoch  1, batch    57 | loss: 107.9655738CurrentTrain: epoch  1, batch    58 | loss: 90.4222978CurrentTrain: epoch  1, batch    59 | loss: 73.6062589CurrentTrain: epoch  1, batch    60 | loss: 87.4736655CurrentTrain: epoch  1, batch    61 | loss: 134.7719461CurrentTrain: epoch  1, batch    62 | loss: 140.0039162CurrentTrain: epoch  1, batch    63 | loss: 73.8148961CurrentTrain: epoch  1, batch    64 | loss: 88.5552007CurrentTrain: epoch  1, batch    65 | loss: 108.8201444CurrentTrain: epoch  1, batch    66 | loss: 66.6320474CurrentTrain: epoch  1, batch    67 | loss: 135.5569589CurrentTrain: epoch  1, batch    68 | loss: 72.5329299CurrentTrain: epoch  1, batch    69 | loss: 80.5790771CurrentTrain: epoch  1, batch    70 | loss: 72.7461847CurrentTrain: epoch  1, batch    71 | loss: 87.3252302CurrentTrain: epoch  1, batch    72 | loss: 108.6865097CurrentTrain: epoch  1, batch    73 | loss: 101.3689726CurrentTrain: epoch  1, batch    74 | loss: 106.1957457CurrentTrain: epoch  1, batch    75 | loss: 85.8196550CurrentTrain: epoch  1, batch    76 | loss: 92.7409466CurrentTrain: epoch  1, batch    77 | loss: 91.9555429CurrentTrain: epoch  1, batch    78 | loss: 85.3544729CurrentTrain: epoch  1, batch    79 | loss: 89.4683257CurrentTrain: epoch  1, batch    80 | loss: 67.0911222CurrentTrain: epoch  1, batch    81 | loss: 103.5734269CurrentTrain: epoch  1, batch    82 | loss: 75.3524268CurrentTrain: epoch  1, batch    83 | loss: 183.4092867CurrentTrain: epoch  1, batch    84 | loss: 106.4944708CurrentTrain: epoch  1, batch    85 | loss: 72.2608271CurrentTrain: epoch  1, batch    86 | loss: 66.1773024CurrentTrain: epoch  1, batch    87 | loss: 76.7558047CurrentTrain: epoch  1, batch    88 | loss: 109.5815370CurrentTrain: epoch  1, batch    89 | loss: 87.6933806CurrentTrain: epoch  1, batch    90 | loss: 76.2144519CurrentTrain: epoch  1, batch    91 | loss: 89.1836800CurrentTrain: epoch  1, batch    92 | loss: 88.6509461CurrentTrain: epoch  1, batch    93 | loss: 136.1138869CurrentTrain: epoch  1, batch    94 | loss: 92.5413507CurrentTrain: epoch  1, batch    95 | loss: 70.4866658CurrentTrain: epoch  2, batch     0 | loss: 63.4633098CurrentTrain: epoch  2, batch     1 | loss: 105.7368118CurrentTrain: epoch  2, batch     2 | loss: 87.9546061CurrentTrain: epoch  2, batch     3 | loss: 90.1068765CurrentTrain: epoch  2, batch     4 | loss: 137.6658622CurrentTrain: epoch  2, batch     5 | loss: 73.0990314CurrentTrain: epoch  2, batch     6 | loss: 131.3547898CurrentTrain: epoch  2, batch     7 | loss: 83.3046115CurrentTrain: epoch  2, batch     8 | loss: 107.0784879CurrentTrain: epoch  2, batch     9 | loss: 62.4952450CurrentTrain: epoch  2, batch    10 | loss: 101.0796931CurrentTrain: epoch  2, batch    11 | loss: 62.2289126CurrentTrain: epoch  2, batch    12 | loss: 65.4728160CurrentTrain: epoch  2, batch    13 | loss: 103.9472830CurrentTrain: epoch  2, batch    14 | loss: 107.7845101CurrentTrain: epoch  2, batch    15 | loss: 109.7401944CurrentTrain: epoch  2, batch    16 | loss: 83.4526651CurrentTrain: epoch  2, batch    17 | loss: 89.1495954CurrentTrain: epoch  2, batch    18 | loss: 85.8061097CurrentTrain: epoch  2, batch    19 | loss: 103.8104434CurrentTrain: epoch  2, batch    20 | loss: 74.6673806CurrentTrain: epoch  2, batch    21 | loss: 104.1491261CurrentTrain: epoch  2, batch    22 | loss: 75.1399246CurrentTrain: epoch  2, batch    23 | loss: 84.4782021CurrentTrain: epoch  2, batch    24 | loss: 83.4086524CurrentTrain: epoch  2, batch    25 | loss: 83.8499715CurrentTrain: epoch  2, batch    26 | loss: 88.7956152CurrentTrain: epoch  2, batch    27 | loss: 80.6821377CurrentTrain: epoch  2, batch    28 | loss: 106.0968266CurrentTrain: epoch  2, batch    29 | loss: 103.3705155CurrentTrain: epoch  2, batch    30 | loss: 88.7178713CurrentTrain: epoch  2, batch    31 | loss: 85.6052760CurrentTrain: epoch  2, batch    32 | loss: 77.4165059CurrentTrain: epoch  2, batch    33 | loss: 109.8571778CurrentTrain: epoch  2, batch    34 | loss: 106.9290625CurrentTrain: epoch  2, batch    35 | loss: 104.2080637CurrentTrain: epoch  2, batch    36 | loss: 87.8919282CurrentTrain: epoch  2, batch    37 | loss: 102.3097045CurrentTrain: epoch  2, batch    38 | loss: 72.6079286CurrentTrain: epoch  2, batch    39 | loss: 105.0300757CurrentTrain: epoch  2, batch    40 | loss: 61.6446638CurrentTrain: epoch  2, batch    41 | loss: 108.2886584CurrentTrain: epoch  2, batch    42 | loss: 103.9935896CurrentTrain: epoch  2, batch    43 | loss: 74.3707029CurrentTrain: epoch  2, batch    44 | loss: 84.6875300CurrentTrain: epoch  2, batch    45 | loss: 74.0963901CurrentTrain: epoch  2, batch    46 | loss: 88.4529904CurrentTrain: epoch  2, batch    47 | loss: 75.9096039CurrentTrain: epoch  2, batch    48 | loss: 132.7969806CurrentTrain: epoch  2, batch    49 | loss: 134.5012011CurrentTrain: epoch  2, batch    50 | loss: 71.2079723CurrentTrain: epoch  2, batch    51 | loss: 138.1367055CurrentTrain: epoch  2, batch    52 | loss: 73.5084339CurrentTrain: epoch  2, batch    53 | loss: 88.8806826CurrentTrain: epoch  2, batch    54 | loss: 106.7674333CurrentTrain: epoch  2, batch    55 | loss: 86.6584963CurrentTrain: epoch  2, batch    56 | loss: 84.9611096CurrentTrain: epoch  2, batch    57 | loss: 69.7430491CurrentTrain: epoch  2, batch    58 | loss: 76.2138674CurrentTrain: epoch  2, batch    59 | loss: 73.5382963CurrentTrain: epoch  2, batch    60 | loss: 86.5169683CurrentTrain: epoch  2, batch    61 | loss: 69.4141255CurrentTrain: epoch  2, batch    62 | loss: 83.5098702CurrentTrain: epoch  2, batch    63 | loss: 71.0163127CurrentTrain: epoch  2, batch    64 | loss: 70.6454187CurrentTrain: epoch  2, batch    65 | loss: 84.0823176CurrentTrain: epoch  2, batch    66 | loss: 137.0294522CurrentTrain: epoch  2, batch    67 | loss: 106.2393961CurrentTrain: epoch  2, batch    68 | loss: 71.8083975CurrentTrain: epoch  2, batch    69 | loss: 70.4371825CurrentTrain: epoch  2, batch    70 | loss: 89.8489276CurrentTrain: epoch  2, batch    71 | loss: 73.1203134CurrentTrain: epoch  2, batch    72 | loss: 185.4762149CurrentTrain: epoch  2, batch    73 | loss: 85.9117725CurrentTrain: epoch  2, batch    74 | loss: 84.5886976CurrentTrain: epoch  2, batch    75 | loss: 84.1333203CurrentTrain: epoch  2, batch    76 | loss: 103.3354243CurrentTrain: epoch  2, batch    77 | loss: 62.8983265CurrentTrain: epoch  2, batch    78 | loss: 88.5238066CurrentTrain: epoch  2, batch    79 | loss: 84.4302745CurrentTrain: epoch  2, batch    80 | loss: 71.1574474CurrentTrain: epoch  2, batch    81 | loss: 86.9617291CurrentTrain: epoch  2, batch    82 | loss: 107.3554352CurrentTrain: epoch  2, batch    83 | loss: 107.6274277CurrentTrain: epoch  2, batch    84 | loss: 75.0236745CurrentTrain: epoch  2, batch    85 | loss: 134.6869707CurrentTrain: epoch  2, batch    86 | loss: 61.6066712CurrentTrain: epoch  2, batch    87 | loss: 63.1303072CurrentTrain: epoch  2, batch    88 | loss: 64.8103332CurrentTrain: epoch  2, batch    89 | loss: 100.9763148CurrentTrain: epoch  2, batch    90 | loss: 85.4208509CurrentTrain: epoch  2, batch    91 | loss: 75.4495391CurrentTrain: epoch  2, batch    92 | loss: 74.1512195CurrentTrain: epoch  2, batch    93 | loss: 88.1906817CurrentTrain: epoch  2, batch    94 | loss: 86.5698235CurrentTrain: epoch  2, batch    95 | loss: 72.1637415CurrentTrain: epoch  3, batch     0 | loss: 86.3063992CurrentTrain: epoch  3, batch     1 | loss: 102.5932586CurrentTrain: epoch  3, batch     2 | loss: 86.7361085CurrentTrain: epoch  3, batch     3 | loss: 88.4704270CurrentTrain: epoch  3, batch     4 | loss: 82.1571262CurrentTrain: epoch  3, batch     5 | loss: 100.4267660CurrentTrain: epoch  3, batch     6 | loss: 81.8782020CurrentTrain: epoch  3, batch     7 | loss: 61.9005272CurrentTrain: epoch  3, batch     8 | loss: 74.3793400CurrentTrain: epoch  3, batch     9 | loss: 125.7092998CurrentTrain: epoch  3, batch    10 | loss: 74.8935262CurrentTrain: epoch  3, batch    11 | loss: 81.1958725CurrentTrain: epoch  3, batch    12 | loss: 103.7434880CurrentTrain: epoch  3, batch    13 | loss: 103.3126357CurrentTrain: epoch  3, batch    14 | loss: 84.7167128CurrentTrain: epoch  3, batch    15 | loss: 104.7373334CurrentTrain: epoch  3, batch    16 | loss: 100.0572734CurrentTrain: epoch  3, batch    17 | loss: 69.0516127CurrentTrain: epoch  3, batch    18 | loss: 72.6540423CurrentTrain: epoch  3, batch    19 | loss: 73.9276542CurrentTrain: epoch  3, batch    20 | loss: 106.1061653CurrentTrain: epoch  3, batch    21 | loss: 81.4207789CurrentTrain: epoch  3, batch    22 | loss: 106.0723841CurrentTrain: epoch  3, batch    23 | loss: 86.6700244CurrentTrain: epoch  3, batch    24 | loss: 72.6840790CurrentTrain: epoch  3, batch    25 | loss: 86.8822255CurrentTrain: epoch  3, batch    26 | loss: 103.9046155CurrentTrain: epoch  3, batch    27 | loss: 107.4420069CurrentTrain: epoch  3, batch    28 | loss: 104.8666779CurrentTrain: epoch  3, batch    29 | loss: 73.0003615CurrentTrain: epoch  3, batch    30 | loss: 89.3440586CurrentTrain: epoch  3, batch    31 | loss: 81.7727104CurrentTrain: epoch  3, batch    32 | loss: 83.0590073CurrentTrain: epoch  3, batch    33 | loss: 131.5467375CurrentTrain: epoch  3, batch    34 | loss: 85.4139772CurrentTrain: epoch  3, batch    35 | loss: 126.8503981CurrentTrain: epoch  3, batch    36 | loss: 60.3985350CurrentTrain: epoch  3, batch    37 | loss: 130.4108237CurrentTrain: epoch  3, batch    38 | loss: 67.0239118CurrentTrain: epoch  3, batch    39 | loss: 86.4331303CurrentTrain: epoch  3, batch    40 | loss: 82.2893020CurrentTrain: epoch  3, batch    41 | loss: 81.7247513CurrentTrain: epoch  3, batch    42 | loss: 87.4331997CurrentTrain: epoch  3, batch    43 | loss: 70.2550035CurrentTrain: epoch  3, batch    44 | loss: 65.4904100CurrentTrain: epoch  3, batch    45 | loss: 73.0062250CurrentTrain: epoch  3, batch    46 | loss: 103.4462046CurrentTrain: epoch  3, batch    47 | loss: 86.3613572CurrentTrain: epoch  3, batch    48 | loss: 131.0283102CurrentTrain: epoch  3, batch    49 | loss: 62.1635747CurrentTrain: epoch  3, batch    50 | loss: 73.6459344CurrentTrain: epoch  3, batch    51 | loss: 75.4154136CurrentTrain: epoch  3, batch    52 | loss: 133.3571180CurrentTrain: epoch  3, batch    53 | loss: 74.9668043CurrentTrain: epoch  3, batch    54 | loss: 104.8821651CurrentTrain: epoch  3, batch    55 | loss: 79.2336341CurrentTrain: epoch  3, batch    56 | loss: 72.9141982CurrentTrain: epoch  3, batch    57 | loss: 75.4122489CurrentTrain: epoch  3, batch    58 | loss: 84.4280919CurrentTrain: epoch  3, batch    59 | loss: 127.2484958CurrentTrain: epoch  3, batch    60 | loss: 86.3606168CurrentTrain: epoch  3, batch    61 | loss: 71.3181997CurrentTrain: epoch  3, batch    62 | loss: 79.8141637CurrentTrain: epoch  3, batch    63 | loss: 103.0517283CurrentTrain: epoch  3, batch    64 | loss: 81.5772097CurrentTrain: epoch  3, batch    65 | loss: 104.0652922CurrentTrain: epoch  3, batch    66 | loss: 105.1438355CurrentTrain: epoch  3, batch    67 | loss: 71.5221063CurrentTrain: epoch  3, batch    68 | loss: 84.4302801CurrentTrain: epoch  3, batch    69 | loss: 68.7495783CurrentTrain: epoch  3, batch    70 | loss: 83.7632950CurrentTrain: epoch  3, batch    71 | loss: 59.8892883CurrentTrain: epoch  3, batch    72 | loss: 74.2086931CurrentTrain: epoch  3, batch    73 | loss: 57.8042102CurrentTrain: epoch  3, batch    74 | loss: 86.9560377CurrentTrain: epoch  3, batch    75 | loss: 106.6521319CurrentTrain: epoch  3, batch    76 | loss: 96.9078245CurrentTrain: epoch  3, batch    77 | loss: 85.3908460CurrentTrain: epoch  3, batch    78 | loss: 128.9429918CurrentTrain: epoch  3, batch    79 | loss: 81.0959516CurrentTrain: epoch  3, batch    80 | loss: 103.0019002CurrentTrain: epoch  3, batch    81 | loss: 62.9450834CurrentTrain: epoch  3, batch    82 | loss: 109.7592402CurrentTrain: epoch  3, batch    83 | loss: 80.5348866CurrentTrain: epoch  3, batch    84 | loss: 71.5835728CurrentTrain: epoch  3, batch    85 | loss: 107.4225309CurrentTrain: epoch  3, batch    86 | loss: 72.3382689CurrentTrain: epoch  3, batch    87 | loss: 85.8928282CurrentTrain: epoch  3, batch    88 | loss: 68.6304847CurrentTrain: epoch  3, batch    89 | loss: 69.4889061CurrentTrain: epoch  3, batch    90 | loss: 97.2023327CurrentTrain: epoch  3, batch    91 | loss: 100.9376678CurrentTrain: epoch  3, batch    92 | loss: 75.0590572CurrentTrain: epoch  3, batch    93 | loss: 84.3951678CurrentTrain: epoch  3, batch    94 | loss: 106.2425463CurrentTrain: epoch  3, batch    95 | loss: 54.3190094CurrentTrain: epoch  4, batch     0 | loss: 80.9853863CurrentTrain: epoch  4, batch     1 | loss: 103.5994543CurrentTrain: epoch  4, batch     2 | loss: 98.9482350CurrentTrain: epoch  4, batch     3 | loss: 76.2773616CurrentTrain: epoch  4, batch     4 | loss: 131.7211485CurrentTrain: epoch  4, batch     5 | loss: 96.0808934CurrentTrain: epoch  4, batch     6 | loss: 71.7722704CurrentTrain: epoch  4, batch     7 | loss: 66.0371740CurrentTrain: epoch  4, batch     8 | loss: 103.8573851CurrentTrain: epoch  4, batch     9 | loss: 131.6617851CurrentTrain: epoch  4, batch    10 | loss: 103.2820615CurrentTrain: epoch  4, batch    11 | loss: 70.2007412CurrentTrain: epoch  4, batch    12 | loss: 82.4184455CurrentTrain: epoch  4, batch    13 | loss: 71.2516139CurrentTrain: epoch  4, batch    14 | loss: 80.8825955CurrentTrain: epoch  4, batch    15 | loss: 102.6258793CurrentTrain: epoch  4, batch    16 | loss: 100.8968209CurrentTrain: epoch  4, batch    17 | loss: 128.2134560CurrentTrain: epoch  4, batch    18 | loss: 79.5569275CurrentTrain: epoch  4, batch    19 | loss: 82.3672154CurrentTrain: epoch  4, batch    20 | loss: 77.4925696CurrentTrain: epoch  4, batch    21 | loss: 70.6568983CurrentTrain: epoch  4, batch    22 | loss: 105.4681934CurrentTrain: epoch  4, batch    23 | loss: 74.4510018CurrentTrain: epoch  4, batch    24 | loss: 93.2851733CurrentTrain: epoch  4, batch    25 | loss: 104.2724380CurrentTrain: epoch  4, batch    26 | loss: 84.9697705CurrentTrain: epoch  4, batch    27 | loss: 63.0030200CurrentTrain: epoch  4, batch    28 | loss: 96.7982039CurrentTrain: epoch  4, batch    29 | loss: 84.0197712CurrentTrain: epoch  4, batch    30 | loss: 85.0812432CurrentTrain: epoch  4, batch    31 | loss: 71.7909559CurrentTrain: epoch  4, batch    32 | loss: 95.0570507CurrentTrain: epoch  4, batch    33 | loss: 57.8615467CurrentTrain: epoch  4, batch    34 | loss: 101.2884722CurrentTrain: epoch  4, batch    35 | loss: 84.2403473CurrentTrain: epoch  4, batch    36 | loss: 72.4285692CurrentTrain: epoch  4, batch    37 | loss: 61.7599854CurrentTrain: epoch  4, batch    38 | loss: 83.7650512CurrentTrain: epoch  4, batch    39 | loss: 72.9707294CurrentTrain: epoch  4, batch    40 | loss: 82.8033698CurrentTrain: epoch  4, batch    41 | loss: 70.1930629CurrentTrain: epoch  4, batch    42 | loss: 86.1511761CurrentTrain: epoch  4, batch    43 | loss: 60.1942427CurrentTrain: epoch  4, batch    44 | loss: 68.1250290CurrentTrain: epoch  4, batch    45 | loss: 84.9135238CurrentTrain: epoch  4, batch    46 | loss: 72.3871674CurrentTrain: epoch  4, batch    47 | loss: 99.3681658CurrentTrain: epoch  4, batch    48 | loss: 75.3179585CurrentTrain: epoch  4, batch    49 | loss: 83.7869582CurrentTrain: epoch  4, batch    50 | loss: 79.8105114CurrentTrain: epoch  4, batch    51 | loss: 72.3001916CurrentTrain: epoch  4, batch    52 | loss: 81.7386320CurrentTrain: epoch  4, batch    53 | loss: 127.8398582CurrentTrain: epoch  4, batch    54 | loss: 82.9590439CurrentTrain: epoch  4, batch    55 | loss: 104.1293984CurrentTrain: epoch  4, batch    56 | loss: 131.7434623CurrentTrain: epoch  4, batch    57 | loss: 72.4333353CurrentTrain: epoch  4, batch    58 | loss: 128.0371827CurrentTrain: epoch  4, batch    59 | loss: 102.0708716CurrentTrain: epoch  4, batch    60 | loss: 83.0993818CurrentTrain: epoch  4, batch    61 | loss: 59.3668740CurrentTrain: epoch  4, batch    62 | loss: 58.2505360CurrentTrain: epoch  4, batch    63 | loss: 68.9806815CurrentTrain: epoch  4, batch    64 | loss: 85.5055168CurrentTrain: epoch  4, batch    65 | loss: 127.4753049CurrentTrain: epoch  4, batch    66 | loss: 72.1453125CurrentTrain: epoch  4, batch    67 | loss: 72.0223155CurrentTrain: epoch  4, batch    68 | loss: 101.9048384CurrentTrain: epoch  4, batch    69 | loss: 70.4165880CurrentTrain: epoch  4, batch    70 | loss: 93.3081856CurrentTrain: epoch  4, batch    71 | loss: 103.5107811CurrentTrain: epoch  4, batch    72 | loss: 66.7717100CurrentTrain: epoch  4, batch    73 | loss: 73.8690854CurrentTrain: epoch  4, batch    74 | loss: 131.4484037CurrentTrain: epoch  4, batch    75 | loss: 83.1985159CurrentTrain: epoch  4, batch    76 | loss: 131.4411342CurrentTrain: epoch  4, batch    77 | loss: 99.6431297CurrentTrain: epoch  4, batch    78 | loss: 69.9713216CurrentTrain: epoch  4, batch    79 | loss: 98.5171089CurrentTrain: epoch  4, batch    80 | loss: 71.5517849CurrentTrain: epoch  4, batch    81 | loss: 130.8326146CurrentTrain: epoch  4, batch    82 | loss: 79.6089496CurrentTrain: epoch  4, batch    83 | loss: 71.0464623CurrentTrain: epoch  4, batch    84 | loss: 76.0576579CurrentTrain: epoch  4, batch    85 | loss: 85.0497965CurrentTrain: epoch  4, batch    86 | loss: 108.0405794CurrentTrain: epoch  4, batch    87 | loss: 124.4941069CurrentTrain: epoch  4, batch    88 | loss: 102.5623210CurrentTrain: epoch  4, batch    89 | loss: 71.0794468CurrentTrain: epoch  4, batch    90 | loss: 121.1154688CurrentTrain: epoch  4, batch    91 | loss: 96.2113336CurrentTrain: epoch  4, batch    92 | loss: 86.4512494CurrentTrain: epoch  4, batch    93 | loss: 79.6214798CurrentTrain: epoch  4, batch    94 | loss: 90.1272404CurrentTrain: epoch  4, batch    95 | loss: 59.7497923CurrentTrain: epoch  5, batch     0 | loss: 80.6745227CurrentTrain: epoch  5, batch     1 | loss: 81.8086655CurrentTrain: epoch  5, batch     2 | loss: 99.1303264CurrentTrain: epoch  5, batch     3 | loss: 84.9263271CurrentTrain: epoch  5, batch     4 | loss: 78.6425256CurrentTrain: epoch  5, batch     5 | loss: 68.6597551CurrentTrain: epoch  5, batch     6 | loss: 127.9489345CurrentTrain: epoch  5, batch     7 | loss: 79.5123983CurrentTrain: epoch  5, batch     8 | loss: 80.6526808CurrentTrain: epoch  5, batch     9 | loss: 77.8829764CurrentTrain: epoch  5, batch    10 | loss: 71.4237225CurrentTrain: epoch  5, batch    11 | loss: 102.1171847CurrentTrain: epoch  5, batch    12 | loss: 129.7165721CurrentTrain: epoch  5, batch    13 | loss: 66.8749684CurrentTrain: epoch  5, batch    14 | loss: 97.7462600CurrentTrain: epoch  5, batch    15 | loss: 65.9297248CurrentTrain: epoch  5, batch    16 | loss: 82.2442827CurrentTrain: epoch  5, batch    17 | loss: 67.0855673CurrentTrain: epoch  5, batch    18 | loss: 83.5610194CurrentTrain: epoch  5, batch    19 | loss: 99.7338416CurrentTrain: epoch  5, batch    20 | loss: 81.9542177CurrentTrain: epoch  5, batch    21 | loss: 65.6476628CurrentTrain: epoch  5, batch    22 | loss: 83.5597551CurrentTrain: epoch  5, batch    23 | loss: 95.4622745CurrentTrain: epoch  5, batch    24 | loss: 59.1967271CurrentTrain: epoch  5, batch    25 | loss: 83.1572236CurrentTrain: epoch  5, batch    26 | loss: 102.5664171CurrentTrain: epoch  5, batch    27 | loss: 97.2368356CurrentTrain: epoch  5, batch    28 | loss: 129.3108396CurrentTrain: epoch  5, batch    29 | loss: 268.4045253CurrentTrain: epoch  5, batch    30 | loss: 72.1031464CurrentTrain: epoch  5, batch    31 | loss: 168.3049540CurrentTrain: epoch  5, batch    32 | loss: 66.6947672CurrentTrain: epoch  5, batch    33 | loss: 75.6692635CurrentTrain: epoch  5, batch    34 | loss: 79.9931539CurrentTrain: epoch  5, batch    35 | loss: 62.7920810CurrentTrain: epoch  5, batch    36 | loss: 126.9074592CurrentTrain: epoch  5, batch    37 | loss: 81.2714361CurrentTrain: epoch  5, batch    38 | loss: 93.6385324CurrentTrain: epoch  5, batch    39 | loss: 100.9736083CurrentTrain: epoch  5, batch    40 | loss: 79.8973455CurrentTrain: epoch  5, batch    41 | loss: 102.3364613CurrentTrain: epoch  5, batch    42 | loss: 130.1404135CurrentTrain: epoch  5, batch    43 | loss: 70.5246279CurrentTrain: epoch  5, batch    44 | loss: 68.2337667CurrentTrain: epoch  5, batch    45 | loss: 82.5058759CurrentTrain: epoch  5, batch    46 | loss: 84.5820862CurrentTrain: epoch  5, batch    47 | loss: 68.3367260CurrentTrain: epoch  5, batch    48 | loss: 64.2004497CurrentTrain: epoch  5, batch    49 | loss: 72.1309379CurrentTrain: epoch  5, batch    50 | loss: 60.7657902CurrentTrain: epoch  5, batch    51 | loss: 81.8810941CurrentTrain: epoch  5, batch    52 | loss: 83.5436822CurrentTrain: epoch  5, batch    53 | loss: 75.8996075CurrentTrain: epoch  5, batch    54 | loss: 85.8101942CurrentTrain: epoch  5, batch    55 | loss: 102.1574715CurrentTrain: epoch  5, batch    56 | loss: 130.4886322CurrentTrain: epoch  5, batch    57 | loss: 84.2959963CurrentTrain: epoch  5, batch    58 | loss: 84.6760417CurrentTrain: epoch  5, batch    59 | loss: 128.3671217CurrentTrain: epoch  5, batch    60 | loss: 100.7088695CurrentTrain: epoch  5, batch    61 | loss: 79.9438964CurrentTrain: epoch  5, batch    62 | loss: 100.0597946CurrentTrain: epoch  5, batch    63 | loss: 84.4062335CurrentTrain: epoch  5, batch    64 | loss: 56.3331679CurrentTrain: epoch  5, batch    65 | loss: 77.4520731CurrentTrain: epoch  5, batch    66 | loss: 78.7332477CurrentTrain: epoch  5, batch    67 | loss: 79.7066513CurrentTrain: epoch  5, batch    68 | loss: 64.0836808CurrentTrain: epoch  5, batch    69 | loss: 80.6194588CurrentTrain: epoch  5, batch    70 | loss: 100.6500363CurrentTrain: epoch  5, batch    71 | loss: 102.0757521CurrentTrain: epoch  5, batch    72 | loss: 100.5272394CurrentTrain: epoch  5, batch    73 | loss: 78.9365151CurrentTrain: epoch  5, batch    74 | loss: 65.0360053CurrentTrain: epoch  5, batch    75 | loss: 68.3666923CurrentTrain: epoch  5, batch    76 | loss: 128.7333965CurrentTrain: epoch  5, batch    77 | loss: 83.6649493CurrentTrain: epoch  5, batch    78 | loss: 78.4024812CurrentTrain: epoch  5, batch    79 | loss: 81.2464440CurrentTrain: epoch  5, batch    80 | loss: 97.2612769CurrentTrain: epoch  5, batch    81 | loss: 99.3011227CurrentTrain: epoch  5, batch    82 | loss: 81.6471189CurrentTrain: epoch  5, batch    83 | loss: 102.3657548CurrentTrain: epoch  5, batch    84 | loss: 97.8233337CurrentTrain: epoch  5, batch    85 | loss: 84.5554619CurrentTrain: epoch  5, batch    86 | loss: 102.3520334CurrentTrain: epoch  5, batch    87 | loss: 67.0705510CurrentTrain: epoch  5, batch    88 | loss: 103.6373263CurrentTrain: epoch  5, batch    89 | loss: 78.8837150CurrentTrain: epoch  5, batch    90 | loss: 80.0097772CurrentTrain: epoch  5, batch    91 | loss: 86.6649516CurrentTrain: epoch  5, batch    92 | loss: 81.9540979CurrentTrain: epoch  5, batch    93 | loss: 68.7924266CurrentTrain: epoch  5, batch    94 | loss: 125.3067875CurrentTrain: epoch  5, batch    95 | loss: 61.0104236CurrentTrain: epoch  6, batch     0 | loss: 58.0285483CurrentTrain: epoch  6, batch     1 | loss: 80.5255901CurrentTrain: epoch  6, batch     2 | loss: 77.4466225CurrentTrain: epoch  6, batch     3 | loss: 100.2792112CurrentTrain: epoch  6, batch     4 | loss: 127.9185764CurrentTrain: epoch  6, batch     5 | loss: 172.8123851CurrentTrain: epoch  6, batch     6 | loss: 83.2225628CurrentTrain: epoch  6, batch     7 | loss: 83.0557432CurrentTrain: epoch  6, batch     8 | loss: 99.0636325CurrentTrain: epoch  6, batch     9 | loss: 83.8784080CurrentTrain: epoch  6, batch    10 | loss: 124.5181339CurrentTrain: epoch  6, batch    11 | loss: 81.8828325CurrentTrain: epoch  6, batch    12 | loss: 102.1863033CurrentTrain: epoch  6, batch    13 | loss: 98.9878870CurrentTrain: epoch  6, batch    14 | loss: 59.6141346CurrentTrain: epoch  6, batch    15 | loss: 76.7902464CurrentTrain: epoch  6, batch    16 | loss: 67.2576822CurrentTrain: epoch  6, batch    17 | loss: 81.5501303CurrentTrain: epoch  6, batch    18 | loss: 66.6853755CurrentTrain: epoch  6, batch    19 | loss: 66.4584268CurrentTrain: epoch  6, batch    20 | loss: 67.8872057CurrentTrain: epoch  6, batch    21 | loss: 82.3840086CurrentTrain: epoch  6, batch    22 | loss: 83.3898971CurrentTrain: epoch  6, batch    23 | loss: 96.2104306CurrentTrain: epoch  6, batch    24 | loss: 100.0283077CurrentTrain: epoch  6, batch    25 | loss: 67.4106356CurrentTrain: epoch  6, batch    26 | loss: 67.1099163CurrentTrain: epoch  6, batch    27 | loss: 69.3563106CurrentTrain: epoch  6, batch    28 | loss: 72.5599840CurrentTrain: epoch  6, batch    29 | loss: 93.5648855CurrentTrain: epoch  6, batch    30 | loss: 99.2476849CurrentTrain: epoch  6, batch    31 | loss: 57.3862956CurrentTrain: epoch  6, batch    32 | loss: 97.3307588CurrentTrain: epoch  6, batch    33 | loss: 84.1560452CurrentTrain: epoch  6, batch    34 | loss: 97.4569582CurrentTrain: epoch  6, batch    35 | loss: 65.9271763CurrentTrain: epoch  6, batch    36 | loss: 67.2960368CurrentTrain: epoch  6, batch    37 | loss: 72.1648955CurrentTrain: epoch  6, batch    38 | loss: 99.3270311CurrentTrain: epoch  6, batch    39 | loss: 78.2624743CurrentTrain: epoch  6, batch    40 | loss: 67.4870741CurrentTrain: epoch  6, batch    41 | loss: 97.0838445CurrentTrain: epoch  6, batch    42 | loss: 77.5798073CurrentTrain: epoch  6, batch    43 | loss: 58.5892174CurrentTrain: epoch  6, batch    44 | loss: 55.8013667CurrentTrain: epoch  6, batch    45 | loss: 81.7154150CurrentTrain: epoch  6, batch    46 | loss: 78.3660384CurrentTrain: epoch  6, batch    47 | loss: 131.3556528CurrentTrain: epoch  6, batch    48 | loss: 72.1798671CurrentTrain: epoch  6, batch    49 | loss: 66.1486394CurrentTrain: epoch  6, batch    50 | loss: 99.6205376CurrentTrain: epoch  6, batch    51 | loss: 98.0702283CurrentTrain: epoch  6, batch    52 | loss: 124.3738779CurrentTrain: epoch  6, batch    53 | loss: 100.6010137CurrentTrain: epoch  6, batch    54 | loss: 82.3536488CurrentTrain: epoch  6, batch    55 | loss: 82.6704866CurrentTrain: epoch  6, batch    56 | loss: 103.0985324CurrentTrain: epoch  6, batch    57 | loss: 63.1737439CurrentTrain: epoch  6, batch    58 | loss: 99.9845359CurrentTrain: epoch  6, batch    59 | loss: 58.9483348CurrentTrain: epoch  6, batch    60 | loss: 79.7582926CurrentTrain: epoch  6, batch    61 | loss: 83.0239271CurrentTrain: epoch  6, batch    62 | loss: 101.4807124CurrentTrain: epoch  6, batch    63 | loss: 82.2640179CurrentTrain: epoch  6, batch    64 | loss: 79.8611993CurrentTrain: epoch  6, batch    65 | loss: 101.8652232CurrentTrain: epoch  6, batch    66 | loss: 81.4519912CurrentTrain: epoch  6, batch    67 | loss: 80.2055724CurrentTrain: epoch  6, batch    68 | loss: 100.9063527CurrentTrain: epoch  6, batch    69 | loss: 79.3306760CurrentTrain: epoch  6, batch    70 | loss: 99.2669228CurrentTrain: epoch  6, batch    71 | loss: 55.9382277CurrentTrain: epoch  6, batch    72 | loss: 68.0968471CurrentTrain: epoch  6, batch    73 | loss: 63.3333909CurrentTrain: epoch  6, batch    74 | loss: 101.4757777CurrentTrain: epoch  6, batch    75 | loss: 99.6075249CurrentTrain: epoch  6, batch    76 | loss: 55.9854639CurrentTrain: epoch  6, batch    77 | loss: 58.2229888CurrentTrain: epoch  6, batch    78 | loss: 98.4327715CurrentTrain: epoch  6, batch    79 | loss: 97.4155027CurrentTrain: epoch  6, batch    80 | loss: 79.9255100CurrentTrain: epoch  6, batch    81 | loss: 58.0740553CurrentTrain: epoch  6, batch    82 | loss: 71.7895915CurrentTrain: epoch  6, batch    83 | loss: 95.4469816CurrentTrain: epoch  6, batch    84 | loss: 81.4188264CurrentTrain: epoch  6, batch    85 | loss: 59.3320895CurrentTrain: epoch  6, batch    86 | loss: 79.5887599CurrentTrain: epoch  6, batch    87 | loss: 98.7523294CurrentTrain: epoch  6, batch    88 | loss: 87.8985148CurrentTrain: epoch  6, batch    89 | loss: 100.8643334CurrentTrain: epoch  6, batch    90 | loss: 98.3694088CurrentTrain: epoch  6, batch    91 | loss: 61.1862922CurrentTrain: epoch  6, batch    92 | loss: 80.0903492CurrentTrain: epoch  6, batch    93 | loss: 80.6276161CurrentTrain: epoch  6, batch    94 | loss: 69.4477520CurrentTrain: epoch  6, batch    95 | loss: 101.0926676CurrentTrain: epoch  7, batch     0 | loss: 79.3612380CurrentTrain: epoch  7, batch     1 | loss: 96.9225868CurrentTrain: epoch  7, batch     2 | loss: 82.4173524CurrentTrain: epoch  7, batch     3 | loss: 80.2137708CurrentTrain: epoch  7, batch     4 | loss: 78.8047270CurrentTrain: epoch  7, batch     5 | loss: 96.1179190CurrentTrain: epoch  7, batch     6 | loss: 81.4462118CurrentTrain: epoch  7, batch     7 | loss: 81.2174094CurrentTrain: epoch  7, batch     8 | loss: 67.1548328CurrentTrain: epoch  7, batch     9 | loss: 65.0343098CurrentTrain: epoch  7, batch    10 | loss: 65.8015301CurrentTrain: epoch  7, batch    11 | loss: 68.2557421CurrentTrain: epoch  7, batch    12 | loss: 98.4697723CurrentTrain: epoch  7, batch    13 | loss: 81.7340536CurrentTrain: epoch  7, batch    14 | loss: 80.8265955CurrentTrain: epoch  7, batch    15 | loss: 67.9976976CurrentTrain: epoch  7, batch    16 | loss: 102.9756066CurrentTrain: epoch  7, batch    17 | loss: 74.2848550CurrentTrain: epoch  7, batch    18 | loss: 67.6387990CurrentTrain: epoch  7, batch    19 | loss: 63.5495408CurrentTrain: epoch  7, batch    20 | loss: 75.3476137CurrentTrain: epoch  7, batch    21 | loss: 77.3400920CurrentTrain: epoch  7, batch    22 | loss: 100.3906469CurrentTrain: epoch  7, batch    23 | loss: 96.6940651CurrentTrain: epoch  7, batch    24 | loss: 66.7180510CurrentTrain: epoch  7, batch    25 | loss: 56.7856099CurrentTrain: epoch  7, batch    26 | loss: 80.2448176CurrentTrain: epoch  7, batch    27 | loss: 98.0530931CurrentTrain: epoch  7, batch    28 | loss: 67.5338147CurrentTrain: epoch  7, batch    29 | loss: 101.4329318CurrentTrain: epoch  7, batch    30 | loss: 80.8480453CurrentTrain: epoch  7, batch    31 | loss: 83.9925821CurrentTrain: epoch  7, batch    32 | loss: 120.6030543CurrentTrain: epoch  7, batch    33 | loss: 80.9022561CurrentTrain: epoch  7, batch    34 | loss: 85.2613683CurrentTrain: epoch  7, batch    35 | loss: 97.4041505CurrentTrain: epoch  7, batch    36 | loss: 79.4081824CurrentTrain: epoch  7, batch    37 | loss: 82.9272087CurrentTrain: epoch  7, batch    38 | loss: 81.7874139CurrentTrain: epoch  7, batch    39 | loss: 102.0097423CurrentTrain: epoch  7, batch    40 | loss: 79.3804591CurrentTrain: epoch  7, batch    41 | loss: 64.0349241CurrentTrain: epoch  7, batch    42 | loss: 94.6478674CurrentTrain: epoch  7, batch    43 | loss: 65.7741652CurrentTrain: epoch  7, batch    44 | loss: 78.3044136CurrentTrain: epoch  7, batch    45 | loss: 98.1388134CurrentTrain: epoch  7, batch    46 | loss: 71.4255257CurrentTrain: epoch  7, batch    47 | loss: 75.0859758CurrentTrain: epoch  7, batch    48 | loss: 123.2250145CurrentTrain: epoch  7, batch    49 | loss: 57.9308482CurrentTrain: epoch  7, batch    50 | loss: 91.9150565CurrentTrain: epoch  7, batch    51 | loss: 76.2137288CurrentTrain: epoch  7, batch    52 | loss: 68.0687192CurrentTrain: epoch  7, batch    53 | loss: 98.7251681CurrentTrain: epoch  7, batch    54 | loss: 65.7362824CurrentTrain: epoch  7, batch    55 | loss: 99.0944823CurrentTrain: epoch  7, batch    56 | loss: 94.7006997CurrentTrain: epoch  7, batch    57 | loss: 81.0352114CurrentTrain: epoch  7, batch    58 | loss: 79.6208674CurrentTrain: epoch  7, batch    59 | loss: 126.0127683CurrentTrain: epoch  7, batch    60 | loss: 65.5484598CurrentTrain: epoch  7, batch    61 | loss: 67.7734016CurrentTrain: epoch  7, batch    62 | loss: 120.0551764CurrentTrain: epoch  7, batch    63 | loss: 80.8131047CurrentTrain: epoch  7, batch    64 | loss: 62.5239390CurrentTrain: epoch  7, batch    65 | loss: 74.0471198CurrentTrain: epoch  7, batch    66 | loss: 80.3442574CurrentTrain: epoch  7, batch    67 | loss: 80.0265565CurrentTrain: epoch  7, batch    68 | loss: 63.0227394CurrentTrain: epoch  7, batch    69 | loss: 79.4771076CurrentTrain: epoch  7, batch    70 | loss: 69.8250860CurrentTrain: epoch  7, batch    71 | loss: 98.6193697CurrentTrain: epoch  7, batch    72 | loss: 66.7019138CurrentTrain: epoch  7, batch    73 | loss: 77.8805031CurrentTrain: epoch  7, batch    74 | loss: 55.8739331CurrentTrain: epoch  7, batch    75 | loss: 65.3643182CurrentTrain: epoch  7, batch    76 | loss: 69.9215003CurrentTrain: epoch  7, batch    77 | loss: 99.2995301CurrentTrain: epoch  7, batch    78 | loss: 85.6717246CurrentTrain: epoch  7, batch    79 | loss: 126.8705669CurrentTrain: epoch  7, batch    80 | loss: 69.3284709CurrentTrain: epoch  7, batch    81 | loss: 65.7674288CurrentTrain: epoch  7, batch    82 | loss: 78.8329643CurrentTrain: epoch  7, batch    83 | loss: 64.3203801CurrentTrain: epoch  7, batch    84 | loss: 79.4301846CurrentTrain: epoch  7, batch    85 | loss: 83.7878048CurrentTrain: epoch  7, batch    86 | loss: 66.0409632CurrentTrain: epoch  7, batch    87 | loss: 98.8909868CurrentTrain: epoch  7, batch    88 | loss: 92.8093339CurrentTrain: epoch  7, batch    89 | loss: 127.4313253CurrentTrain: epoch  7, batch    90 | loss: 80.0052513CurrentTrain: epoch  7, batch    91 | loss: 81.5677902CurrentTrain: epoch  7, batch    92 | loss: 100.2072087CurrentTrain: epoch  7, batch    93 | loss: 58.8496926CurrentTrain: epoch  7, batch    94 | loss: 59.5139300CurrentTrain: epoch  7, batch    95 | loss: 83.3046851CurrentTrain: epoch  8, batch     0 | loss: 68.6672433CurrentTrain: epoch  8, batch     1 | loss: 64.7467534CurrentTrain: epoch  8, batch     2 | loss: 93.9423706CurrentTrain: epoch  8, batch     3 | loss: 126.6013137CurrentTrain: epoch  8, batch     4 | loss: 80.6333201CurrentTrain: epoch  8, batch     5 | loss: 69.2819354CurrentTrain: epoch  8, batch     6 | loss: 81.7645544CurrentTrain: epoch  8, batch     7 | loss: 76.1713933CurrentTrain: epoch  8, batch     8 | loss: 66.6613995CurrentTrain: epoch  8, batch     9 | loss: 96.8753880CurrentTrain: epoch  8, batch    10 | loss: 74.8902803CurrentTrain: epoch  8, batch    11 | loss: 76.8998434CurrentTrain: epoch  8, batch    12 | loss: 76.9775262CurrentTrain: epoch  8, batch    13 | loss: 91.8864611CurrentTrain: epoch  8, batch    14 | loss: 77.2356988CurrentTrain: epoch  8, batch    15 | loss: 78.6070129CurrentTrain: epoch  8, batch    16 | loss: 93.8819880CurrentTrain: epoch  8, batch    17 | loss: 79.1326117CurrentTrain: epoch  8, batch    18 | loss: 98.0798141CurrentTrain: epoch  8, batch    19 | loss: 66.0238179CurrentTrain: epoch  8, batch    20 | loss: 77.0971492CurrentTrain: epoch  8, batch    21 | loss: 76.3889112CurrentTrain: epoch  8, batch    22 | loss: 91.9972632CurrentTrain: epoch  8, batch    23 | loss: 67.0234621CurrentTrain: epoch  8, batch    24 | loss: 63.9066562CurrentTrain: epoch  8, batch    25 | loss: 95.2974142CurrentTrain: epoch  8, batch    26 | loss: 64.4942436CurrentTrain: epoch  8, batch    27 | loss: 78.3016661CurrentTrain: epoch  8, batch    28 | loss: 66.2691847CurrentTrain: epoch  8, batch    29 | loss: 67.6146015CurrentTrain: epoch  8, batch    30 | loss: 102.2688834CurrentTrain: epoch  8, batch    31 | loss: 54.2341739CurrentTrain: epoch  8, batch    32 | loss: 168.8845732CurrentTrain: epoch  8, batch    33 | loss: 96.5305303CurrentTrain: epoch  8, batch    34 | loss: 94.5531473CurrentTrain: epoch  8, batch    35 | loss: 64.9548641CurrentTrain: epoch  8, batch    36 | loss: 94.0488518CurrentTrain: epoch  8, batch    37 | loss: 67.0074483CurrentTrain: epoch  8, batch    38 | loss: 77.4390702CurrentTrain: epoch  8, batch    39 | loss: 80.3187135CurrentTrain: epoch  8, batch    40 | loss: 80.3173602CurrentTrain: epoch  8, batch    41 | loss: 98.4373706CurrentTrain: epoch  8, batch    42 | loss: 78.8876799CurrentTrain: epoch  8, batch    43 | loss: 103.4978986CurrentTrain: epoch  8, batch    44 | loss: 123.2444375CurrentTrain: epoch  8, batch    45 | loss: 80.9777334CurrentTrain: epoch  8, batch    46 | loss: 64.6090860CurrentTrain: epoch  8, batch    47 | loss: 81.7664123CurrentTrain: epoch  8, batch    48 | loss: 64.5385653CurrentTrain: epoch  8, batch    49 | loss: 74.9415469CurrentTrain: epoch  8, batch    50 | loss: 94.8858773CurrentTrain: epoch  8, batch    51 | loss: 62.5202516CurrentTrain: epoch  8, batch    52 | loss: 79.2210642CurrentTrain: epoch  8, batch    53 | loss: 84.3534484CurrentTrain: epoch  8, batch    54 | loss: 97.2718202CurrentTrain: epoch  8, batch    55 | loss: 95.2256659CurrentTrain: epoch  8, batch    56 | loss: 67.8896574CurrentTrain: epoch  8, batch    57 | loss: 64.7437736CurrentTrain: epoch  8, batch    58 | loss: 79.5359551CurrentTrain: epoch  8, batch    59 | loss: 55.0519289CurrentTrain: epoch  8, batch    60 | loss: 122.7735268CurrentTrain: epoch  8, batch    61 | loss: 96.6729604CurrentTrain: epoch  8, batch    62 | loss: 56.9025696CurrentTrain: epoch  8, batch    63 | loss: 80.5068283CurrentTrain: epoch  8, batch    64 | loss: 78.6101465CurrentTrain: epoch  8, batch    65 | loss: 79.7461457CurrentTrain: epoch  8, batch    66 | loss: 73.2179128CurrentTrain: epoch  8, batch    67 | loss: 92.4695706CurrentTrain: epoch  8, batch    68 | loss: 94.8546769CurrentTrain: epoch  8, batch    69 | loss: 81.4368029CurrentTrain: epoch  8, batch    70 | loss: 94.6965306CurrentTrain: epoch  8, batch    71 | loss: 123.3531560CurrentTrain: epoch  8, batch    72 | loss: 75.7409800CurrentTrain: epoch  8, batch    73 | loss: 78.5330861CurrentTrain: epoch  8, batch    74 | loss: 96.8986583CurrentTrain: epoch  8, batch    75 | loss: 78.2868665CurrentTrain: epoch  8, batch    76 | loss: 56.5530097CurrentTrain: epoch  8, batch    77 | loss: 122.8056870CurrentTrain: epoch  8, batch    78 | loss: 63.7190375CurrentTrain: epoch  8, batch    79 | loss: 69.0774226CurrentTrain: epoch  8, batch    80 | loss: 93.2695773CurrentTrain: epoch  8, batch    81 | loss: 79.3800693CurrentTrain: epoch  8, batch    82 | loss: 67.2386988CurrentTrain: epoch  8, batch    83 | loss: 65.8159798CurrentTrain: epoch  8, batch    84 | loss: 125.9308576CurrentTrain: epoch  8, batch    85 | loss: 119.3979732CurrentTrain: epoch  8, batch    86 | loss: 98.1398858CurrentTrain: epoch  8, batch    87 | loss: 79.2962187CurrentTrain: epoch  8, batch    88 | loss: 52.3090163CurrentTrain: epoch  8, batch    89 | loss: 76.6935992CurrentTrain: epoch  8, batch    90 | loss: 76.1352929CurrentTrain: epoch  8, batch    91 | loss: 83.7967311CurrentTrain: epoch  8, batch    92 | loss: 80.2860971CurrentTrain: epoch  8, batch    93 | loss: 76.7172126CurrentTrain: epoch  8, batch    94 | loss: 98.2691660CurrentTrain: epoch  8, batch    95 | loss: 101.6290601CurrentTrain: epoch  9, batch     0 | loss: 66.5529377CurrentTrain: epoch  9, batch     1 | loss: 117.4289745CurrentTrain: epoch  9, batch     2 | loss: 75.3863449CurrentTrain: epoch  9, batch     3 | loss: 65.7752347CurrentTrain: epoch  9, batch     4 | loss: 77.7097156CurrentTrain: epoch  9, batch     5 | loss: 53.0916710CurrentTrain: epoch  9, batch     6 | loss: 98.9644694CurrentTrain: epoch  9, batch     7 | loss: 75.3852829CurrentTrain: epoch  9, batch     8 | loss: 96.1119090CurrentTrain: epoch  9, batch     9 | loss: 65.0499365CurrentTrain: epoch  9, batch    10 | loss: 98.6234796CurrentTrain: epoch  9, batch    11 | loss: 67.4417443CurrentTrain: epoch  9, batch    12 | loss: 92.3358792CurrentTrain: epoch  9, batch    13 | loss: 97.2972206CurrentTrain: epoch  9, batch    14 | loss: 96.5384254CurrentTrain: epoch  9, batch    15 | loss: 75.7185087CurrentTrain: epoch  9, batch    16 | loss: 128.3556770CurrentTrain: epoch  9, batch    17 | loss: 78.6564506CurrentTrain: epoch  9, batch    18 | loss: 77.5501808CurrentTrain: epoch  9, batch    19 | loss: 80.5538653CurrentTrain: epoch  9, batch    20 | loss: 64.4193017CurrentTrain: epoch  9, batch    21 | loss: 95.0358305CurrentTrain: epoch  9, batch    22 | loss: 66.9022537CurrentTrain: epoch  9, batch    23 | loss: 67.1448781CurrentTrain: epoch  9, batch    24 | loss: 122.6168004CurrentTrain: epoch  9, batch    25 | loss: 93.5128936CurrentTrain: epoch  9, batch    26 | loss: 61.3541045CurrentTrain: epoch  9, batch    27 | loss: 117.8727649CurrentTrain: epoch  9, batch    28 | loss: 64.6801860CurrentTrain: epoch  9, batch    29 | loss: 66.7556640CurrentTrain: epoch  9, batch    30 | loss: 64.0437514CurrentTrain: epoch  9, batch    31 | loss: 80.3462492CurrentTrain: epoch  9, batch    32 | loss: 94.3197881CurrentTrain: epoch  9, batch    33 | loss: 69.2086329CurrentTrain: epoch  9, batch    34 | loss: 61.9590062CurrentTrain: epoch  9, batch    35 | loss: 120.5126294CurrentTrain: epoch  9, batch    36 | loss: 81.3738662CurrentTrain: epoch  9, batch    37 | loss: 78.9496079CurrentTrain: epoch  9, batch    38 | loss: 81.5113266CurrentTrain: epoch  9, batch    39 | loss: 66.7537193CurrentTrain: epoch  9, batch    40 | loss: 62.0839877CurrentTrain: epoch  9, batch    41 | loss: 79.7031831CurrentTrain: epoch  9, batch    42 | loss: 61.8935043CurrentTrain: epoch  9, batch    43 | loss: 62.9735783CurrentTrain: epoch  9, batch    44 | loss: 124.0346365CurrentTrain: epoch  9, batch    45 | loss: 67.6443576CurrentTrain: epoch  9, batch    46 | loss: 81.0213535CurrentTrain: epoch  9, batch    47 | loss: 97.9780135CurrentTrain: epoch  9, batch    48 | loss: 77.5698989CurrentTrain: epoch  9, batch    49 | loss: 65.4311753CurrentTrain: epoch  9, batch    50 | loss: 73.8543900CurrentTrain: epoch  9, batch    51 | loss: 77.5871727CurrentTrain: epoch  9, batch    52 | loss: 67.0517327CurrentTrain: epoch  9, batch    53 | loss: 80.4985069CurrentTrain: epoch  9, batch    54 | loss: 66.8365373CurrentTrain: epoch  9, batch    55 | loss: 63.4253135CurrentTrain: epoch  9, batch    56 | loss: 81.4821037CurrentTrain: epoch  9, batch    57 | loss: 52.3246428CurrentTrain: epoch  9, batch    58 | loss: 92.5257489CurrentTrain: epoch  9, batch    59 | loss: 95.1841827CurrentTrain: epoch  9, batch    60 | loss: 71.7482999CurrentTrain: epoch  9, batch    61 | loss: 54.7860642CurrentTrain: epoch  9, batch    62 | loss: 96.2866322CurrentTrain: epoch  9, batch    63 | loss: 63.5766751CurrentTrain: epoch  9, batch    64 | loss: 56.0997827CurrentTrain: epoch  9, batch    65 | loss: 93.8767140CurrentTrain: epoch  9, batch    66 | loss: 94.6284611CurrentTrain: epoch  9, batch    67 | loss: 74.7514204CurrentTrain: epoch  9, batch    68 | loss: 123.5289261CurrentTrain: epoch  9, batch    69 | loss: 96.2436019CurrentTrain: epoch  9, batch    70 | loss: 76.9503056CurrentTrain: epoch  9, batch    71 | loss: 95.4839529CurrentTrain: epoch  9, batch    72 | loss: 64.1185981CurrentTrain: epoch  9, batch    73 | loss: 95.5395541CurrentTrain: epoch  9, batch    74 | loss: 127.8552519CurrentTrain: epoch  9, batch    75 | loss: 99.9446687CurrentTrain: epoch  9, batch    76 | loss: 94.4122297CurrentTrain: epoch  9, batch    77 | loss: 63.8185478CurrentTrain: epoch  9, batch    78 | loss: 123.2129094CurrentTrain: epoch  9, batch    79 | loss: 77.9969581CurrentTrain: epoch  9, batch    80 | loss: 55.6621090CurrentTrain: epoch  9, batch    81 | loss: 54.4071103CurrentTrain: epoch  9, batch    82 | loss: 99.6025830CurrentTrain: epoch  9, batch    83 | loss: 123.3068807CurrentTrain: epoch  9, batch    84 | loss: 123.6901059CurrentTrain: epoch  9, batch    85 | loss: 67.1798299CurrentTrain: epoch  9, batch    86 | loss: 75.7738103CurrentTrain: epoch  9, batch    87 | loss: 65.9701373CurrentTrain: epoch  9, batch    88 | loss: 127.3761471CurrentTrain: epoch  9, batch    89 | loss: 58.2390622CurrentTrain: epoch  9, batch    90 | loss: 79.8031808CurrentTrain: epoch  9, batch    91 | loss: 78.5079896CurrentTrain: epoch  9, batch    92 | loss: 54.6496331CurrentTrain: epoch  9, batch    93 | loss: 66.1309776CurrentTrain: epoch  9, batch    94 | loss: 91.5313225CurrentTrain: epoch  9, batch    95 | loss: 64.7733009

F1 score per class: {32: np.float64(0.532608695652174), 6: np.float64(0.8390243902439024), 19: np.float64(0.35294117647058826), 24: np.float64(0.7272727272727273), 26: np.float64(0.8947368421052632), 29: np.float64(0.8198198198198198)}
Micro-average F1 score: 0.7534246575342466
Weighted-average F1 score: 0.7585333557820253
F1 score per class: {32: np.float64(0.6153846153846154), 6: np.float64(0.8202764976958525), 19: np.float64(0.2318840579710145), 24: np.float64(0.7150259067357513), 26: np.float64(0.9230769230769231), 29: np.float64(0.8309178743961353)}
Micro-average F1 score: 0.7441016333938294
Weighted-average F1 score: 0.7283525774445103
F1 score per class: {32: np.float64(0.6226415094339622), 6: np.float64(0.819047619047619), 19: np.float64(0.3018867924528302), 24: np.float64(0.7150259067357513), 26: np.float64(0.9230769230769231), 29: np.float64(0.8075117370892019)}
Micro-average F1 score: 0.7527881040892194
Weighted-average F1 score: 0.7452252118234827

F1 score per class: {32: np.float64(0.532608695652174), 6: np.float64(0.8390243902439024), 19: np.float64(0.35294117647058826), 24: np.float64(0.7272727272727273), 26: np.float64(0.8947368421052632), 29: np.float64(0.8198198198198198)}
Micro-average F1 score: 0.7534246575342466
Weighted-average F1 score: 0.7585333557820253
F1 score per class: {32: np.float64(0.6153846153846154), 6: np.float64(0.8202764976958525), 19: np.float64(0.2318840579710145), 24: np.float64(0.7150259067357513), 26: np.float64(0.9230769230769231), 29: np.float64(0.8309178743961353)}
Micro-average F1 score: 0.7441016333938294
Weighted-average F1 score: 0.7283525774445103
F1 score per class: {32: np.float64(0.6226415094339622), 6: np.float64(0.819047619047619), 19: np.float64(0.3018867924528302), 24: np.float64(0.7150259067357513), 26: np.float64(0.9230769230769231), 29: np.float64(0.8075117370892019)}
Micro-average F1 score: 0.7527881040892194
Weighted-average F1 score: 0.7452252118234827

F1 score per class: {32: np.float64(0.4016393442622951), 6: np.float64(0.7962962962962963), 19: np.float64(0.23076923076923078), 24: np.float64(0.6601941747572816), 26: np.float64(0.8173076923076923), 29: np.float64(0.6086956521739131)}
Micro-average F1 score: 0.6285714285714286
Weighted-average F1 score: 0.6187168852424414
F1 score per class: {32: np.float64(0.43037974683544306), 6: np.float64(0.7672413793103449), 19: np.float64(0.13559322033898305), 24: np.float64(0.6359447004608295), 26: np.float64(0.8333333333333334), 29: np.float64(0.6590038314176245)}
Micro-average F1 score: 0.6029411764705882
Weighted-average F1 score: 0.5759727112804522
F1 score per class: {32: np.float64(0.43853820598006643), 6: np.float64(0.7678571428571429), 19: np.float64(0.17777777777777778), 24: np.float64(0.6388888888888888), 26: np.float64(0.8333333333333334), 29: np.float64(0.6417910447761194)}
Micro-average F1 score: 0.6159695817490495
Weighted-average F1 score: 0.5956827332703198

F1 score per class: {32: np.float64(0.4016393442622951), 6: np.float64(0.7962962962962963), 19: np.float64(0.23076923076923078), 24: np.float64(0.6601941747572816), 26: np.float64(0.8173076923076923), 29: np.float64(0.6086956521739131)}
Micro-average F1 score: 0.6285714285714286
Weighted-average F1 score: 0.6187168852424414
F1 score per class: {32: np.float64(0.43037974683544306), 6: np.float64(0.7672413793103449), 19: np.float64(0.13559322033898305), 24: np.float64(0.6359447004608295), 26: np.float64(0.8333333333333334), 29: np.float64(0.6590038314176245)}
Micro-average F1 score: 0.6029411764705882
Weighted-average F1 score: 0.5759727112804522
F1 score per class: {32: np.float64(0.43853820598006643), 6: np.float64(0.7678571428571429), 19: np.float64(0.17777777777777778), 24: np.float64(0.6388888888888888), 26: np.float64(0.8333333333333334), 29: np.float64(0.6417910447761194)}
Micro-average F1 score: 0.6159695817490495
Weighted-average F1 score: 0.5956827332703198
cur_acc_wo_na:  ['0.7534']
his_acc_wo_na:  ['0.7534']
cur_acc des_wo_na:  ['0.7441']
his_acc des_wo_na:  ['0.7441']
cur_acc rrf_wo_na:  ['0.7528']
his_acc rrf_wo_na:  ['0.7528']
cur_acc_w_na:  ['0.6286']
his_acc_w_na:  ['0.6286']
cur_acc des_w_na:  ['0.6029']
his_acc des_w_na:  ['0.6029']
cur_acc rrf_w_na:  ['0.6160']
his_acc rrf_w_na:  ['0.6160']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 83.5328456CurrentTrain: epoch  0, batch     1 | loss: 149.0361042CurrentTrain: epoch  0, batch     2 | loss: 110.5350074CurrentTrain: epoch  0, batch     3 | loss: 112.9979568CurrentTrain: epoch  0, batch     4 | loss: 24.1850848CurrentTrain: epoch  1, batch     0 | loss: 109.0277902CurrentTrain: epoch  1, batch     1 | loss: 87.8929247CurrentTrain: epoch  1, batch     2 | loss: 109.0571162CurrentTrain: epoch  1, batch     3 | loss: 85.6355650CurrentTrain: epoch  1, batch     4 | loss: 26.7127936CurrentTrain: epoch  2, batch     0 | loss: 134.4121677CurrentTrain: epoch  2, batch     1 | loss: 75.1078268CurrentTrain: epoch  2, batch     2 | loss: 86.2268666CurrentTrain: epoch  2, batch     3 | loss: 85.4769286CurrentTrain: epoch  2, batch     4 | loss: 18.9483590CurrentTrain: epoch  3, batch     0 | loss: 84.8514447CurrentTrain: epoch  3, batch     1 | loss: 84.8655147CurrentTrain: epoch  3, batch     2 | loss: 84.0835502CurrentTrain: epoch  3, batch     3 | loss: 103.4092974CurrentTrain: epoch  3, batch     4 | loss: 25.9151239CurrentTrain: epoch  4, batch     0 | loss: 86.0730740CurrentTrain: epoch  4, batch     1 | loss: 102.3393669CurrentTrain: epoch  4, batch     2 | loss: 68.5217288CurrentTrain: epoch  4, batch     3 | loss: 99.1119288CurrentTrain: epoch  4, batch     4 | loss: 13.6924185CurrentTrain: epoch  5, batch     0 | loss: 79.2171312CurrentTrain: epoch  5, batch     1 | loss: 80.3372366CurrentTrain: epoch  5, batch     2 | loss: 79.5118123CurrentTrain: epoch  5, batch     3 | loss: 128.2725113CurrentTrain: epoch  5, batch     4 | loss: 16.5968175CurrentTrain: epoch  6, batch     0 | loss: 79.0264704CurrentTrain: epoch  6, batch     1 | loss: 100.0102527CurrentTrain: epoch  6, batch     2 | loss: 79.7644429CurrentTrain: epoch  6, batch     3 | loss: 94.9959862CurrentTrain: epoch  6, batch     4 | loss: 24.1371316CurrentTrain: epoch  7, batch     0 | loss: 119.6539451CurrentTrain: epoch  7, batch     1 | loss: 91.1884296CurrentTrain: epoch  7, batch     2 | loss: 98.3080342CurrentTrain: epoch  7, batch     3 | loss: 78.7197150CurrentTrain: epoch  7, batch     4 | loss: 15.3833918CurrentTrain: epoch  8, batch     0 | loss: 93.2609678CurrentTrain: epoch  8, batch     1 | loss: 65.3043067CurrentTrain: epoch  8, batch     2 | loss: 80.2855388CurrentTrain: epoch  8, batch     3 | loss: 120.6580337CurrentTrain: epoch  8, batch     4 | loss: 15.1337406CurrentTrain: epoch  9, batch     0 | loss: 79.2012104CurrentTrain: epoch  9, batch     1 | loss: 75.6485589CurrentTrain: epoch  9, batch     2 | loss: 76.2058758CurrentTrain: epoch  9, batch     3 | loss: 65.5804364CurrentTrain: epoch  9, batch     4 | loss: 40.4705816
MemoryTrain:  epoch  0, batch     0 | loss: 2.2230027MemoryTrain:  epoch  1, batch     0 | loss: 1.8753804MemoryTrain:  epoch  2, batch     0 | loss: 1.5178755MemoryTrain:  epoch  3, batch     0 | loss: 1.2901958MemoryTrain:  epoch  4, batch     0 | loss: 0.9706542MemoryTrain:  epoch  5, batch     0 | loss: 0.8270814MemoryTrain:  epoch  6, batch     0 | loss: 0.6198923MemoryTrain:  epoch  7, batch     0 | loss: 0.5000530MemoryTrain:  epoch  8, batch     0 | loss: 0.5420887MemoryTrain:  epoch  9, batch     0 | loss: 0.4164647

F1 score per class: {32: np.float64(0.6666666666666666), 2: np.float64(0.0), 6: np.float64(0.624113475177305), 39: np.float64(0.55), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.3333333333333333), 24: np.float64(0.0), 28: np.float64(0.38461538461538464)}
Micro-average F1 score: 0.515
Weighted-average F1 score: 0.45318636537632656
F1 score per class: {32: np.float64(0.6956521739130435), 2: np.float64(0.0), 6: np.float64(0.5238095238095238), 39: np.float64(0.5365853658536586), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.45454545454545453), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.42105263157894735)}
Micro-average F1 score: 0.4537037037037037
Weighted-average F1 score: 0.3777195083366655
F1 score per class: {32: np.float64(0.6666666666666666), 2: np.float64(0.0), 6: np.float64(0.5203252032520326), 39: np.float64(0.5443786982248521), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.4166666666666667), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.35)}
Micro-average F1 score: 0.46080760095011875
Weighted-average F1 score: 0.39376326216832974

F1 score per class: {32: np.float64(0.631578947368421), 2: np.float64(0.6350710900473934), 6: np.float64(0.5605095541401274), 39: np.float64(0.36213991769547327), 11: np.float64(0.8075117370892019), 12: np.float64(0.38095238095238093), 19: np.float64(0.7444444444444445), 24: np.float64(0.20512820512820512), 26: np.float64(0.8852459016393442), 28: np.float64(0.7679324894514767), 29: np.float64(0.3333333333333333)}
Micro-average F1 score: 0.6473616473616474
Weighted-average F1 score: 0.6335269957255623
F1 score per class: {32: np.float64(0.6153846153846154), 2: np.float64(0.6290322580645161), 6: np.float64(0.48175182481751827), 39: np.float64(0.34509803921568627), 11: np.float64(0.7876106194690266), 12: np.float64(0.2571428571428571), 19: np.float64(0.7391304347826086), 24: np.float64(0.3225806451612903), 26: np.float64(0.8842105263157894), 28: np.float64(0.7330677290836654), 29: np.float64(0.3137254901960784)}
Micro-average F1 score: 0.6207309766327141
Weighted-average F1 score: 0.6058487593689493
F1 score per class: {32: np.float64(0.6086956521739131), 2: np.float64(0.6371681415929203), 6: np.float64(0.4740740740740741), 39: np.float64(0.33948339483394835), 11: np.float64(0.7982062780269058), 12: np.float64(0.34782608695652173), 19: np.float64(0.7391304347826086), 24: np.float64(0.2631578947368421), 26: np.float64(0.8829787234042553), 28: np.float64(0.7244094488188977), 29: np.float64(0.27450980392156865)}
Micro-average F1 score: 0.6211104331909701
Weighted-average F1 score: 0.6058273930021603

F1 score per class: {32: np.float64(0.46153846153846156), 2: np.float64(0.0), 6: np.float64(0.5238095238095238), 39: np.float64(0.4756756756756757), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.18604651162790697), 26: np.float64(0.0), 28: np.float64(0.24390243902439024)}
Micro-average F1 score: 0.389413988657845
Weighted-average F1 score: 0.3331623933676886
F1 score per class: {32: np.float64(0.43243243243243246), 2: np.float64(0.0), 6: np.float64(0.44), 39: np.float64(0.4536082474226804), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.22727272727272727), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.26229508196721313)}
Micro-average F1 score: 0.32558139534883723
Weighted-average F1 score: 0.2677205493475647
F1 score per class: {32: np.float64(0.4827586206896552), 2: np.float64(0.0), 6: np.float64(0.43537414965986393), 39: np.float64(0.46), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.20833333333333334), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.208955223880597)}
Micro-average F1 score: 0.3356401384083045
Weighted-average F1 score: 0.2806412463585795

F1 score per class: {32: np.float64(0.42857142857142855), 2: np.float64(0.40978593272171254), 6: np.float64(0.4536082474226804), 39: np.float64(0.2430939226519337), 11: np.float64(0.7445887445887446), 12: np.float64(0.25), 19: np.float64(0.6802030456852792), 24: np.float64(0.12307692307692308), 26: np.float64(0.8181818181818182), 28: np.float64(0.5565749235474006), 29: np.float64(0.18867924528301888)}
Micro-average F1 score: 0.4916911045943304
Weighted-average F1 score: 0.46513091505988896
F1 score per class: {32: np.float64(0.35555555555555557), 2: np.float64(0.39097744360902253), 6: np.float64(0.39285714285714285), 39: np.float64(0.2359249329758713), 11: np.float64(0.7355371900826446), 12: np.float64(0.144), 19: np.float64(0.6507177033492823), 24: np.float64(0.1724137931034483), 26: np.float64(0.8115942028985508), 28: np.float64(0.5476190476190477), 29: np.float64(0.1797752808988764)}
Micro-average F1 score: 0.4602398933807197
Weighted-average F1 score: 0.4323007629443314
F1 score per class: {32: np.float64(0.42424242424242425), 2: np.float64(0.4022346368715084), 6: np.float64(0.3855421686746988), 39: np.float64(0.23232323232323232), 11: np.float64(0.7416666666666667), 12: np.float64(0.20253164556962025), 19: np.float64(0.6570048309178744), 24: np.float64(0.14084507042253522), 26: np.float64(0.8137254901960784), 28: np.float64(0.5395894428152492), 29: np.float64(0.15053763440860216)}
Micro-average F1 score: 0.46526508226691043
Weighted-average F1 score: 0.4374361270117367
cur_acc_wo_na:  ['0.7534', '0.5150']
his_acc_wo_na:  ['0.7534', '0.6474']
cur_acc des_wo_na:  ['0.7441', '0.4537']
his_acc des_wo_na:  ['0.7441', '0.6207']
cur_acc rrf_wo_na:  ['0.7528', '0.4608']
his_acc rrf_wo_na:  ['0.7528', '0.6211']
cur_acc_w_na:  ['0.6286', '0.3894']
his_acc_w_na:  ['0.6286', '0.4917']
cur_acc des_w_na:  ['0.6029', '0.3256']
his_acc des_w_na:  ['0.6029', '0.4602']
cur_acc rrf_w_na:  ['0.6160', '0.3356']
his_acc rrf_w_na:  ['0.6160', '0.4653']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 117.2527657CurrentTrain: epoch  0, batch     1 | loss: 79.5687539CurrentTrain: epoch  0, batch     2 | loss: 117.4368418CurrentTrain: epoch  0, batch     3 | loss: 8.8804139CurrentTrain: epoch  1, batch     0 | loss: 76.9088317CurrentTrain: epoch  1, batch     1 | loss: 72.6586676CurrentTrain: epoch  1, batch     2 | loss: 85.2736166CurrentTrain: epoch  1, batch     3 | loss: 12.6515901CurrentTrain: epoch  2, batch     0 | loss: 70.2245975CurrentTrain: epoch  2, batch     1 | loss: 85.8801418CurrentTrain: epoch  2, batch     2 | loss: 73.5364743CurrentTrain: epoch  2, batch     3 | loss: 12.1943868CurrentTrain: epoch  3, batch     0 | loss: 123.3132932CurrentTrain: epoch  3, batch     1 | loss: 81.6504217CurrentTrain: epoch  3, batch     2 | loss: 63.5891112CurrentTrain: epoch  3, batch     3 | loss: 17.4874727CurrentTrain: epoch  4, batch     0 | loss: 126.4621034CurrentTrain: epoch  4, batch     1 | loss: 64.2448849CurrentTrain: epoch  4, batch     2 | loss: 66.6190821CurrentTrain: epoch  4, batch     3 | loss: 6.3461525CurrentTrain: epoch  5, batch     0 | loss: 64.4508956CurrentTrain: epoch  5, batch     1 | loss: 93.7655747CurrentTrain: epoch  5, batch     2 | loss: 77.0131370CurrentTrain: epoch  5, batch     3 | loss: 9.8760496CurrentTrain: epoch  6, batch     0 | loss: 65.9747882CurrentTrain: epoch  6, batch     1 | loss: 90.6253604CurrentTrain: epoch  6, batch     2 | loss: 74.5143631CurrentTrain: epoch  6, batch     3 | loss: 19.5605286CurrentTrain: epoch  7, batch     0 | loss: 71.5149943CurrentTrain: epoch  7, batch     1 | loss: 91.7439522CurrentTrain: epoch  7, batch     2 | loss: 73.5065333CurrentTrain: epoch  7, batch     3 | loss: 9.9265050CurrentTrain: epoch  8, batch     0 | loss: 95.9168303CurrentTrain: epoch  8, batch     1 | loss: 74.4843317CurrentTrain: epoch  8, batch     2 | loss: 57.3072478CurrentTrain: epoch  8, batch     3 | loss: 8.5119563CurrentTrain: epoch  9, batch     0 | loss: 63.2534828CurrentTrain: epoch  9, batch     1 | loss: 90.8434841CurrentTrain: epoch  9, batch     2 | loss: 60.8344459CurrentTrain: epoch  9, batch     3 | loss: 9.4700988
MemoryTrain:  epoch  0, batch     0 | loss: 1.1551656MemoryTrain:  epoch  1, batch     0 | loss: 0.9251607MemoryTrain:  epoch  2, batch     0 | loss: 0.7877177MemoryTrain:  epoch  3, batch     0 | loss: 0.7041157MemoryTrain:  epoch  4, batch     0 | loss: 0.5854988MemoryTrain:  epoch  5, batch     0 | loss: 0.4463488MemoryTrain:  epoch  6, batch     0 | loss: 0.4339355MemoryTrain:  epoch  7, batch     0 | loss: 0.3556502MemoryTrain:  epoch  8, batch     0 | loss: 0.3159684MemoryTrain:  epoch  9, batch     0 | loss: 0.2620071

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5714285714285714), 7: np.float64(0.8928571428571429), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.38095238095238093), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.27692307692307694)}
Micro-average F1 score: 0.35507246376811596
Weighted-average F1 score: 0.29719395830506945
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.3333333333333333), 7: np.float64(0.704225352112676), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.5454545454545454), 26: np.float64(0.0), 27: np.float64(0.4), 28: np.float64(0.0), 31: np.float64(0.24793388429752067)}
Micro-average F1 score: 0.31893687707641194
Weighted-average F1 score: 0.27418749173937573
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.3333333333333333), 7: np.float64(0.746268656716418), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.5714285714285714), 26: np.float64(0.0), 27: np.float64(0.5), 28: np.float64(0.0), 31: np.float64(0.23809523809523808)}
Micro-average F1 score: 0.3254237288135593
Weighted-average F1 score: 0.27796298695944116

F1 score per class: {32: np.float64(0.47058823529411764), 2: np.float64(0.45161290322580644), 6: np.float64(0.047619047619047616), 7: np.float64(0.8928571428571429), 40: np.float64(0.5507246376811594), 11: np.float64(0.2482758620689655), 12: np.float64(0.6428571428571429), 39: np.float64(0.17391304347826086), 9: np.float64(0.6787878787878788), 19: np.float64(0.27586206896551724), 24: np.float64(0.43478260869565216), 26: np.float64(0.8409090909090909), 27: np.float64(0.0), 28: np.float64(0.7982062780269058), 29: np.float64(0.2857142857142857), 31: np.float64(0.14814814814814814)}
Micro-average F1 score: 0.5161656267725468
Weighted-average F1 score: 0.4863099392583895
F1 score per class: {32: np.float64(0.5925925925925926), 2: np.float64(0.5217391304347826), 6: np.float64(0.03636363636363636), 7: np.float64(0.6578947368421053), 40: np.float64(0.49612403100775193), 9: np.float64(0.28125), 12: np.float64(0.5773195876288659), 11: np.float64(0.2222222222222222), 39: np.float64(0.7159090909090909), 19: np.float64(0.36363636363636365), 24: np.float64(0.23255813953488372), 26: np.float64(0.8539325842696629), 27: np.float64(0.13333333333333333), 28: np.float64(0.7964601769911505), 29: np.float64(0.3157894736842105), 31: np.float64(0.14634146341463414)}
Micro-average F1 score: 0.5157563025210085
Weighted-average F1 score: 0.4898698356324062
F1 score per class: {32: np.float64(0.5263157894736842), 2: np.float64(0.5082872928176796), 6: np.float64(0.03571428571428571), 7: np.float64(0.7352941176470589), 40: np.float64(0.47244094488188976), 11: np.float64(0.28901734104046245), 12: np.float64(0.6064981949458483), 39: np.float64(0.27586206896551724), 9: np.float64(0.7159090909090909), 19: np.float64(0.35294117647058826), 24: np.float64(0.24390243902439024), 26: np.float64(0.847457627118644), 27: np.float64(0.2), 28: np.float64(0.8), 29: np.float64(0.34285714285714286), 31: np.float64(0.13392857142857142)}
Micro-average F1 score: 0.519438444924406
Weighted-average F1 score: 0.49336969697275534

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.8333333333333334), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.36363636363636365), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.23684210526315788)}
Micro-average F1 score: 0.30434782608695654
Weighted-average F1 score: 0.25481152619310515
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.2857142857142857), 7: np.float64(0.6172839506172839), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 11: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.5217391304347826), 26: np.float64(0.0), 27: np.float64(0.25), 28: np.float64(0.0), 31: np.float64(0.2127659574468085)}
Micro-average F1 score: 0.2689075630252101
Weighted-average F1 score: 0.23362696318248571
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.2857142857142857), 7: np.float64(0.6756756756756757), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 11: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.5217391304347826), 26: np.float64(0.0), 27: np.float64(0.5), 28: np.float64(0.0), 31: np.float64(0.2054794520547945)}
Micro-average F1 score: 0.27988338192419826
Weighted-average F1 score: 0.2412604784649904

F1 score per class: {32: np.float64(0.32), 2: np.float64(0.29914529914529914), 6: np.float64(0.03125), 7: np.float64(0.8333333333333334), 40: np.float64(0.4634146341463415), 11: np.float64(0.21052631578947367), 12: np.float64(0.6090225563909775), 39: np.float64(0.13793103448275862), 9: np.float64(0.6292134831460674), 19: np.float64(0.2222222222222222), 24: np.float64(0.20833333333333334), 26: np.float64(0.783068783068783), 27: np.float64(0.0), 28: np.float64(0.5836065573770491), 29: np.float64(0.16326530612244897), 31: np.float64(0.11392405063291139)}
Micro-average F1 score: 0.4126984126984127
Weighted-average F1 score: 0.38108377557732115
F1 score per class: {32: np.float64(0.38095238095238093), 2: np.float64(0.3344947735191638), 6: np.float64(0.02247191011235955), 7: np.float64(0.5494505494505495), 40: np.float64(0.4050632911392405), 11: np.float64(0.21176470588235294), 12: np.float64(0.5316455696202531), 9: np.float64(0.15384615384615385), 39: np.float64(0.6631578947368421), 19: np.float64(0.2926829268292683), 24: np.float64(0.10869565217391304), 26: np.float64(0.7875647668393783), 27: np.float64(0.08695652173913043), 28: np.float64(0.6206896551724138), 29: np.float64(0.1643835616438356), 31: np.float64(0.1171875)}
Micro-average F1 score: 0.4011437908496732
Weighted-average F1 score: 0.3730171205986001
F1 score per class: {32: np.float64(0.35714285714285715), 2: np.float64(0.3262411347517731), 6: np.float64(0.02197802197802198), 7: np.float64(0.6578947368421053), 40: np.float64(0.38961038961038963), 11: np.float64(0.2304147465437788), 12: np.float64(0.5637583892617449), 39: np.float64(0.2), 9: np.float64(0.6631578947368421), 19: np.float64(0.2727272727272727), 24: np.float64(0.11494252873563218), 26: np.float64(0.7936507936507936), 27: np.float64(0.16666666666666666), 28: np.float64(0.6164383561643836), 29: np.float64(0.1791044776119403), 31: np.float64(0.10714285714285714)}
Micro-average F1 score: 0.4098849595227951
Weighted-average F1 score: 0.3808336966178671
cur_acc_wo_na:  ['0.7534', '0.5150', '0.3551']
his_acc_wo_na:  ['0.7534', '0.6474', '0.5162']
cur_acc des_wo_na:  ['0.7441', '0.4537', '0.3189']
his_acc des_wo_na:  ['0.7441', '0.6207', '0.5158']
cur_acc rrf_wo_na:  ['0.7528', '0.4608', '0.3254']
his_acc rrf_wo_na:  ['0.7528', '0.6211', '0.5194']
cur_acc_w_na:  ['0.6286', '0.3894', '0.3043']
his_acc_w_na:  ['0.6286', '0.4917', '0.4127']
cur_acc des_w_na:  ['0.6029', '0.3256', '0.2689']
his_acc des_w_na:  ['0.6029', '0.4602', '0.4011']
cur_acc rrf_w_na:  ['0.6160', '0.3356', '0.2799']
his_acc rrf_w_na:  ['0.6160', '0.4653', '0.4099']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 87.5674322CurrentTrain: epoch  0, batch     1 | loss: 92.9768028CurrentTrain: epoch  0, batch     2 | loss: 117.3342994CurrentTrain: epoch  0, batch     3 | loss: 129.9754256CurrentTrain: epoch  1, batch     0 | loss: 75.5134526CurrentTrain: epoch  1, batch     1 | loss: 107.4426469CurrentTrain: epoch  1, batch     2 | loss: 85.3919707CurrentTrain: epoch  1, batch     3 | loss: 75.4268846CurrentTrain: epoch  2, batch     0 | loss: 86.5486221CurrentTrain: epoch  2, batch     1 | loss: 72.4314477CurrentTrain: epoch  2, batch     2 | loss: 71.5003225CurrentTrain: epoch  2, batch     3 | loss: 89.0877127CurrentTrain: epoch  3, batch     0 | loss: 102.4763494CurrentTrain: epoch  3, batch     1 | loss: 82.3802277CurrentTrain: epoch  3, batch     2 | loss: 83.5949696CurrentTrain: epoch  3, batch     3 | loss: 57.2326898CurrentTrain: epoch  4, batch     0 | loss: 80.9612456CurrentTrain: epoch  4, batch     1 | loss: 97.1567054CurrentTrain: epoch  4, batch     2 | loss: 125.8952869CurrentTrain: epoch  4, batch     3 | loss: 51.0893202CurrentTrain: epoch  5, batch     0 | loss: 98.5964769CurrentTrain: epoch  5, batch     1 | loss: 76.5774178CurrentTrain: epoch  5, batch     2 | loss: 98.7036585CurrentTrain: epoch  5, batch     3 | loss: 44.1562021CurrentTrain: epoch  6, batch     0 | loss: 127.1184785CurrentTrain: epoch  6, batch     1 | loss: 88.1712198CurrentTrain: epoch  6, batch     2 | loss: 79.9191566CurrentTrain: epoch  6, batch     3 | loss: 63.4579937CurrentTrain: epoch  7, batch     0 | loss: 78.2732620CurrentTrain: epoch  7, batch     1 | loss: 62.8500686CurrentTrain: epoch  7, batch     2 | loss: 79.8022508CurrentTrain: epoch  7, batch     3 | loss: 52.5594803CurrentTrain: epoch  8, batch     0 | loss: 95.2494426CurrentTrain: epoch  8, batch     1 | loss: 65.8667136CurrentTrain: epoch  8, batch     2 | loss: 75.3881687CurrentTrain: epoch  8, batch     3 | loss: 64.0647334CurrentTrain: epoch  9, batch     0 | loss: 77.3177394CurrentTrain: epoch  9, batch     1 | loss: 92.9587296CurrentTrain: epoch  9, batch     2 | loss: 63.5646842CurrentTrain: epoch  9, batch     3 | loss: 79.9221942
MemoryTrain:  epoch  0, batch     0 | loss: 0.9552192MemoryTrain:  epoch  1, batch     0 | loss: 0.8255992MemoryTrain:  epoch  2, batch     0 | loss: 0.6780276MemoryTrain:  epoch  3, batch     0 | loss: 0.5705918MemoryTrain:  epoch  4, batch     0 | loss: 0.4511432MemoryTrain:  epoch  5, batch     0 | loss: 0.3783068MemoryTrain:  epoch  6, batch     0 | loss: 0.3130370MemoryTrain:  epoch  7, batch     0 | loss: 0.2842132MemoryTrain:  epoch  8, batch     0 | loss: 0.2541858MemoryTrain:  epoch  9, batch     0 | loss: 0.2200066

F1 score per class: {32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.8333333333333334), 6: np.float64(0.0), 11: np.float64(0.56), 7: np.float64(0.0), 12: np.float64(0.0), 40: np.float64(0.0), 15: np.float64(0.7578947368421053), 19: np.float64(0.4824120603015075), 25: np.float64(0.5333333333333333), 27: np.float64(0.0), 28: np.float64(0.0)}
Micro-average F1 score: 0.522633744855967
Weighted-average F1 score: 0.4702315022326159
F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.6956521739130435), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.7291666666666666), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.7706422018348624), 37: np.float64(0.5222929936305732), 38: np.float64(0.6521739130434783), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5340909090909091
Weighted-average F1 score: 0.4532893275766762
F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.6153846153846154), 19: np.float64(0.0), 25: np.float64(0.7032967032967034), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.7777777777777778), 37: np.float64(0.49142857142857144), 38: np.float64(0.5957446808510638), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5335892514395394
Weighted-average F1 score: 0.4670046664328579

F1 score per class: {2: np.float64(0.5454545454545454), 6: np.float64(0.455026455026455), 7: np.float64(0.05063291139240506), 9: np.float64(0.8064516129032258), 11: np.float64(0.38181818181818183), 12: np.float64(0.12403100775193798), 15: np.float64(0.39215686274509803), 19: np.float64(0.6058394160583942), 24: np.float64(0.1), 25: np.float64(0.56), 26: np.float64(0.7134502923976608), 27: np.float64(0.3018867924528302), 28: np.float64(0.358974358974359), 29: np.float64(0.8681318681318682), 31: np.float64(0.2222222222222222), 32: np.float64(0.7309236947791165), 35: np.float64(0.5106382978723404), 37: np.float64(0.1979381443298969), 38: np.float64(0.375), 39: np.float64(0.08695652173913043), 40: np.float64(0.1388888888888889)}
Micro-average F1 score: 0.43813847900113506
Weighted-average F1 score: 0.40689297004290853
F1 score per class: {2: np.float64(0.5), 6: np.float64(0.42201834862385323), 7: np.float64(0.04819277108433735), 9: np.float64(0.5617977528089888), 11: np.float64(0.5432098765432098), 12: np.float64(0.233502538071066), 15: np.float64(0.3018867924528302), 19: np.float64(0.5382059800664452), 24: np.float64(0.2564102564102564), 25: np.float64(0.7291666666666666), 26: np.float64(0.7243243243243244), 27: np.float64(0.2962962962962963), 28: np.float64(0.2), 29: np.float64(0.875), 31: np.float64(0.1111111111111111), 32: np.float64(0.714859437751004), 35: np.float64(0.4329896907216495), 37: np.float64(0.25076452599388377), 38: np.float64(0.5), 39: np.float64(0.3076923076923077), 40: np.float64(0.17297297297297298)}
Micro-average F1 score: 0.460289445817155
Weighted-average F1 score: 0.43101379506744947
F1 score per class: {2: np.float64(0.56), 6: np.float64(0.42105263157894735), 7: np.float64(0.05), 9: np.float64(0.7246376811594203), 11: np.float64(0.5241379310344828), 12: np.float64(0.20915032679738563), 15: np.float64(0.24615384615384617), 19: np.float64(0.5491525423728814), 24: np.float64(0.18181818181818182), 25: np.float64(0.7032967032967034), 26: np.float64(0.73224043715847), 27: np.float64(0.3), 28: np.float64(0.22950819672131148), 29: np.float64(0.8723404255319149), 31: np.float64(0.11764705882352941), 32: np.float64(0.714859437751004), 35: np.float64(0.42424242424242425), 37: np.float64(0.23180592991913745), 38: np.float64(0.45901639344262296), 39: np.float64(0.3076923076923077), 40: np.float64(0.15023474178403756)}
Micro-average F1 score: 0.4516821760916249
Weighted-average F1 score: 0.4194419144923859

F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.5405405405405406), 19: np.float64(0.0), 25: np.float64(0.5060240963855421), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6206896551724138), 37: np.float64(0.35036496350364965), 38: np.float64(0.4067796610169492), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3708029197080292
Weighted-average F1 score: 0.326889340599297
F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.43243243243243246), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.625), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6222222222222222), 37: np.float64(0.4293193717277487), 38: np.float64(0.5660377358490566), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.39275766016713093
Weighted-average F1 score: 0.33236774358782173
F1 score per class: {2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 15: np.float64(0.41025641025641024), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.6274509803921569), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6176470588235294), 37: np.float64(0.3891402714932127), 38: np.float64(0.509090909090909), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3909985935302391
Weighted-average F1 score: 0.33758239837824616

F1 score per class: {2: np.float64(0.34285714285714286), 6: np.float64(0.29553264604810997), 7: np.float64(0.028368794326241134), 9: np.float64(0.746268656716418), 11: np.float64(0.3652173913043478), 12: np.float64(0.10256410256410256), 15: np.float64(0.20618556701030927), 19: np.float64(0.564625850340136), 24: np.float64(0.09090909090909091), 25: np.float64(0.5060240963855421), 26: np.float64(0.6524064171122995), 27: np.float64(0.1797752808988764), 28: np.float64(0.16091954022988506), 29: np.float64(0.7669902912621359), 31: np.float64(0.16666666666666666), 32: np.float64(0.5465465465465466), 35: np.float64(0.3317972350230415), 37: np.float64(0.10738255033557047), 38: np.float64(0.24489795918367346), 39: np.float64(0.058823529411764705), 40: np.float64(0.09202453987730061)}
Micro-average F1 score: 0.3060253699788584
Weighted-average F1 score: 0.2705313130430695
F1 score per class: {2: np.float64(0.26229508196721313), 6: np.float64(0.27299703264094954), 7: np.float64(0.02702702702702703), 9: np.float64(0.45871559633027525), 11: np.float64(0.43564356435643564), 12: np.float64(0.16370106761565836), 15: np.float64(0.16161616161616163), 19: np.float64(0.48214285714285715), 24: np.float64(0.16666666666666666), 25: np.float64(0.6194690265486725), 26: np.float64(0.6473429951690821), 27: np.float64(0.1839080459770115), 28: np.float64(0.09523809523809523), 29: np.float64(0.7567567567567568), 31: np.float64(0.06451612903225806), 32: np.float64(0.541033434650456), 35: np.float64(0.27906976744186046), 37: np.float64(0.15708812260536398), 38: np.float64(0.3488372093023256), 39: np.float64(0.16901408450704225), 40: np.float64(0.12598425196850394)}
Micro-average F1 score: 0.32747363134103463
Weighted-average F1 score: 0.3004692318341259
F1 score per class: {2: np.float64(0.34146341463414637), 6: np.float64(0.27586206896551724), 7: np.float64(0.027586206896551724), 9: np.float64(0.6578947368421053), 11: np.float64(0.4393063583815029), 12: np.float64(0.15609756097560976), 15: np.float64(0.12903225806451613), 19: np.float64(0.49846153846153846), 24: np.float64(0.14814814814814814), 25: np.float64(0.6213592233009708), 26: np.float64(0.6600985221674877), 27: np.float64(0.18181818181818182), 28: np.float64(0.112), 29: np.float64(0.7699530516431925), 31: np.float64(0.08695652173913043), 32: np.float64(0.5297619047619048), 35: np.float64(0.2709677419354839), 37: np.float64(0.1402936378466558), 38: np.float64(0.30434782608695654), 39: np.float64(0.19047619047619047), 40: np.float64(0.10738255033557047)}
Micro-average F1 score: 0.32251469460771787
Weighted-average F1 score: 0.29135707803051786
cur_acc_wo_na:  ['0.7534', '0.5150', '0.3551', '0.5226']
his_acc_wo_na:  ['0.7534', '0.6474', '0.5162', '0.4381']
cur_acc des_wo_na:  ['0.7441', '0.4537', '0.3189', '0.5341']
his_acc des_wo_na:  ['0.7441', '0.6207', '0.5158', '0.4603']
cur_acc rrf_wo_na:  ['0.7528', '0.4608', '0.3254', '0.5336']
his_acc rrf_wo_na:  ['0.7528', '0.6211', '0.5194', '0.4517']
cur_acc_w_na:  ['0.6286', '0.3894', '0.3043', '0.3708']
his_acc_w_na:  ['0.6286', '0.4917', '0.4127', '0.3060']
cur_acc des_w_na:  ['0.6029', '0.3256', '0.2689', '0.3928']
his_acc des_w_na:  ['0.6029', '0.4602', '0.4011', '0.3275']
cur_acc rrf_w_na:  ['0.6160', '0.3356', '0.2799', '0.3910']
his_acc rrf_w_na:  ['0.6160', '0.4653', '0.4099', '0.3225']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 141.4585154CurrentTrain: epoch  0, batch     1 | loss: 104.6281494CurrentTrain: epoch  0, batch     2 | loss: 103.3145803CurrentTrain: epoch  0, batch     3 | loss: 114.9919235CurrentTrain: epoch  0, batch     4 | loss: 77.9669497CurrentTrain: epoch  1, batch     0 | loss: 91.4469104CurrentTrain: epoch  1, batch     1 | loss: 110.5456421CurrentTrain: epoch  1, batch     2 | loss: 77.4323206CurrentTrain: epoch  1, batch     3 | loss: 106.9378198CurrentTrain: epoch  1, batch     4 | loss: 105.3682220CurrentTrain: epoch  2, batch     0 | loss: 88.2584914CurrentTrain: epoch  2, batch     1 | loss: 88.9217470CurrentTrain: epoch  2, batch     2 | loss: 75.8092217CurrentTrain: epoch  2, batch     3 | loss: 85.9734300CurrentTrain: epoch  2, batch     4 | loss: 101.0953779CurrentTrain: epoch  3, batch     0 | loss: 68.8729365CurrentTrain: epoch  3, batch     1 | loss: 103.7272994CurrentTrain: epoch  3, batch     2 | loss: 88.3839768CurrentTrain: epoch  3, batch     3 | loss: 105.1335164CurrentTrain: epoch  3, batch     4 | loss: 149.1437667CurrentTrain: epoch  4, batch     0 | loss: 81.4738063CurrentTrain: epoch  4, batch     1 | loss: 103.9388548CurrentTrain: epoch  4, batch     2 | loss: 83.6261567CurrentTrain: epoch  4, batch     3 | loss: 83.2838607CurrentTrain: epoch  4, batch     4 | loss: 70.8511560CurrentTrain: epoch  5, batch     0 | loss: 129.0426869CurrentTrain: epoch  5, batch     1 | loss: 67.0138494CurrentTrain: epoch  5, batch     2 | loss: 99.0652326CurrentTrain: epoch  5, batch     3 | loss: 98.1976318CurrentTrain: epoch  5, batch     4 | loss: 71.1630454CurrentTrain: epoch  6, batch     0 | loss: 98.5449855CurrentTrain: epoch  6, batch     1 | loss: 70.6683897CurrentTrain: epoch  6, batch     2 | loss: 99.1967543CurrentTrain: epoch  6, batch     3 | loss: 98.9196311CurrentTrain: epoch  6, batch     4 | loss: 36.5688017CurrentTrain: epoch  7, batch     0 | loss: 95.4618361CurrentTrain: epoch  7, batch     1 | loss: 81.2281292CurrentTrain: epoch  7, batch     2 | loss: 78.7787065CurrentTrain: epoch  7, batch     3 | loss: 96.6334486CurrentTrain: epoch  7, batch     4 | loss: 53.4031419CurrentTrain: epoch  8, batch     0 | loss: 96.3559327CurrentTrain: epoch  8, batch     1 | loss: 67.0744813CurrentTrain: epoch  8, batch     2 | loss: 95.8832036CurrentTrain: epoch  8, batch     3 | loss: 74.9506760CurrentTrain: epoch  8, batch     4 | loss: 52.6459842CurrentTrain: epoch  9, batch     0 | loss: 76.6695990CurrentTrain: epoch  9, batch     1 | loss: 63.1211144CurrentTrain: epoch  9, batch     2 | loss: 80.0083120CurrentTrain: epoch  9, batch     3 | loss: 120.6964870CurrentTrain: epoch  9, batch     4 | loss: 71.1811358
MemoryTrain:  epoch  0, batch     0 | loss: 1.3057210MemoryTrain:  epoch  1, batch     0 | loss: 1.1343109MemoryTrain:  epoch  2, batch     0 | loss: 0.9451058MemoryTrain:  epoch  3, batch     0 | loss: 0.8320634MemoryTrain:  epoch  4, batch     0 | loss: 0.6637949MemoryTrain:  epoch  5, batch     0 | loss: 0.5908911MemoryTrain:  epoch  6, batch     0 | loss: 0.5270608MemoryTrain:  epoch  7, batch     0 | loss: 0.4159411MemoryTrain:  epoch  8, batch     0 | loss: 0.3135299MemoryTrain:  epoch  9, batch     0 | loss: 0.2870392

F1 score per class: {1: np.float64(0.175), 3: np.float64(0.631578947368421), 6: np.float64(0.0), 7: np.float64(0.0), 14: np.float64(0.1282051282051282), 19: np.float64(0.0), 22: np.float64(0.5473684210526316), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6842105263157895), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3800995024875622
Weighted-average F1 score: 0.3356395578767975
F1 score per class: {1: np.float64(0.22857142857142856), 2: np.float64(0.0), 3: np.float64(0.5930232558139535), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.058823529411764705), 19: np.float64(0.0), 22: np.float64(0.5387453874538746), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6710526315789473), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3381725021349274
Weighted-average F1 score: 0.2933399249521183
F1 score per class: {1: np.float64(0.21714285714285714), 3: np.float64(0.6296296296296297), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 14: np.float64(0.0625), 19: np.float64(0.0), 22: np.float64(0.5300353356890459), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6623376623376623), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.34973637961335674
Weighted-average F1 score: 0.3063006033441618

F1 score per class: {1: np.float64(0.14285714285714285), 2: np.float64(0.47058823529411764), 3: np.float64(0.4827586206896552), 6: np.float64(0.4), 7: np.float64(0.05194805194805195), 9: np.float64(0.7692307692307693), 11: np.float64(0.10752688172043011), 12: np.float64(0.017857142857142856), 14: np.float64(0.11904761904761904), 15: np.float64(0.7619047619047619), 19: np.float64(0.5487364620938628), 22: np.float64(0.4508670520231214), 24: np.float64(0.0), 25: np.float64(0.5789473684210527), 26: np.float64(0.7272727272727273), 27: np.float64(0.0), 28: np.float64(0.2), 29: np.float64(0.8324324324324325), 31: np.float64(0.2222222222222222), 32: np.float64(0.5882352941176471), 34: np.float64(0.22958057395143489), 35: np.float64(0.16260162601626016), 37: np.float64(0.23809523809523808), 38: np.float64(0.36363636363636365), 39: np.float64(0.13793103448275862), 40: np.float64(0.21052631578947367)}
Micro-average F1 score: 0.375
Weighted-average F1 score: 0.3643942654062508
F1 score per class: {1: np.float64(0.16877637130801687), 2: np.float64(0.4827586206896552), 3: np.float64(0.3893129770992366), 6: np.float64(0.43636363636363634), 7: np.float64(0.05555555555555555), 9: np.float64(0.5263157894736842), 11: np.float64(0.0851063829787234), 12: np.float64(0.23529411764705882), 14: np.float64(0.04081632653061224), 15: np.float64(0.48), 19: np.float64(0.5161290322580645), 22: np.float64(0.45625), 24: np.float64(0.07142857142857142), 25: np.float64(0.7311827956989247), 26: np.float64(0.7362637362637363), 27: np.float64(0.0), 28: np.float64(0.13793103448275862), 29: np.float64(0.8601036269430051), 31: np.float64(0.06451612903225806), 32: np.float64(0.5714285714285714), 34: np.float64(0.23394495412844038), 35: np.float64(0.21978021978021978), 37: np.float64(0.17391304347826086), 38: np.float64(0.43037974683544306), 39: np.float64(0.13793103448275862), 40: np.float64(0.22702702702702704)}
Micro-average F1 score: 0.36968018131453034
Weighted-average F1 score: 0.35321054421197656
F1 score per class: {1: np.float64(0.1589958158995816), 2: np.float64(0.5714285714285714), 3: np.float64(0.4322033898305085), 6: np.float64(0.45918367346938777), 7: np.float64(0.05405405405405406), 9: np.float64(0.7142857142857143), 11: np.float64(0.0851063829787234), 12: np.float64(0.12030075187969924), 14: np.float64(0.045454545454545456), 15: np.float64(0.631578947368421), 19: np.float64(0.5306122448979592), 22: np.float64(0.4297994269340974), 24: np.float64(0.0), 25: np.float64(0.6904761904761905), 26: np.float64(0.7292817679558011), 27: np.float64(0.0), 28: np.float64(0.16), 29: np.float64(0.8586387434554974), 31: np.float64(0.08333333333333333), 32: np.float64(0.5650557620817844), 34: np.float64(0.22717149220489977), 35: np.float64(0.1827956989247312), 37: np.float64(0.15217391304347827), 38: np.float64(0.3835616438356164), 39: np.float64(0.13333333333333333), 40: np.float64(0.21782178217821782)}
Micro-average F1 score: 0.36477007014809043
Weighted-average F1 score: 0.3487983822883837

F1 score per class: {1: np.float64(0.10108303249097472), 2: np.float64(0.0), 3: np.float64(0.5419354838709678), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.12048192771084337), 19: np.float64(0.0), 22: np.float64(0.4148936170212766), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.48372093023255813), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2629043358568479
Weighted-average F1 score: 0.23202679685584426
F1 score per class: {1: np.float64(0.12698412698412698), 2: np.float64(0.0), 3: np.float64(0.44541484716157204), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.048), 15: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.42318840579710143), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.46153846153846156), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.22423556058890148
Weighted-average F1 score: 0.19902264580542794
F1 score per class: {1: np.float64(0.12063492063492064), 2: np.float64(0.0), 3: np.float64(0.4788732394366197), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.05357142857142857), 19: np.float64(0.0), 22: np.float64(0.40431266846361186), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.4657534246575342), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.235781990521327
Weighted-average F1 score: 0.2111935495050606

F1 score per class: {1: np.float64(0.07887323943661972), 2: np.float64(0.2857142857142857), 3: np.float64(0.3574468085106383), 6: np.float64(0.27467811158798283), 7: np.float64(0.028368794326241134), 9: np.float64(0.6944444444444444), 11: np.float64(0.10752688172043011), 12: np.float64(0.01694915254237288), 14: np.float64(0.10526315789473684), 15: np.float64(0.5333333333333333), 19: np.float64(0.5049833887043189), 22: np.float64(0.3203285420944558), 24: np.float64(0.0), 25: np.float64(0.5238095238095238), 26: np.float64(0.6632124352331606), 27: np.float64(0.0), 28: np.float64(0.1188118811881188), 29: np.float64(0.7230046948356808), 31: np.float64(0.15384615384615385), 32: np.float64(0.4560260586319218), 34: np.float64(0.13612565445026178), 35: np.float64(0.11904761904761904), 37: np.float64(0.1519756838905775), 38: np.float64(0.2777777777777778), 39: np.float64(0.08888888888888889), 40: np.float64(0.15503875968992248)}
Micro-average F1 score: 0.2715894868585732
Weighted-average F1 score: 0.25315440921301846
F1 score per class: {1: np.float64(0.09280742459396751), 2: np.float64(0.2857142857142857), 3: np.float64(0.2649350649350649), 6: np.float64(0.25806451612903225), 7: np.float64(0.032520325203252036), 9: np.float64(0.4065040650406504), 11: np.float64(0.08333333333333333), 12: np.float64(0.1660377358490566), 14: np.float64(0.030927835051546393), 15: np.float64(0.3076923076923077), 19: np.float64(0.463768115942029), 22: np.float64(0.3325740318906606), 24: np.float64(0.06060606060606061), 25: np.float64(0.6181818181818182), 26: np.float64(0.6600985221674877), 27: np.float64(0.0), 28: np.float64(0.07453416149068323), 29: np.float64(0.7377777777777778), 31: np.float64(0.03333333333333333), 32: np.float64(0.42696629213483145), 34: np.float64(0.14127423822714683), 35: np.float64(0.1384083044982699), 37: np.float64(0.13145539906103287), 38: np.float64(0.2833333333333333), 39: np.float64(0.0784313725490196), 40: np.float64(0.17573221757322174)}
Micro-average F1 score: 0.2590893046240734
Weighted-average F1 score: 0.24219983217457908
F1 score per class: {1: np.float64(0.08775981524249422), 2: np.float64(0.32432432432432434), 3: np.float64(0.2982456140350877), 6: np.float64(0.27692307692307694), 7: np.float64(0.03125), 9: np.float64(0.6410256410256411), 11: np.float64(0.08421052631578947), 12: np.float64(0.1038961038961039), 14: np.float64(0.036585365853658534), 15: np.float64(0.4), 19: np.float64(0.47560975609756095), 22: np.float64(0.3048780487804878), 24: np.float64(0.0), 25: np.float64(0.6041666666666666), 26: np.float64(0.66), 27: np.float64(0.0), 28: np.float64(0.08888888888888889), 29: np.float64(0.7354260089686099), 31: np.float64(0.058823529411764705), 32: np.float64(0.4233983286908078), 34: np.float64(0.13654618473895583), 35: np.float64(0.11971830985915492), 37: np.float64(0.11155378486055777), 38: np.float64(0.27722772277227725), 39: np.float64(0.07272727272727272), 40: np.float64(0.16666666666666666)}
Micro-average F1 score: 0.2598075499629904
Weighted-average F1 score: 0.24234981880210857
cur_acc_wo_na:  ['0.7534', '0.5150', '0.3551', '0.5226', '0.3801']
his_acc_wo_na:  ['0.7534', '0.6474', '0.5162', '0.4381', '0.3750']
cur_acc des_wo_na:  ['0.7441', '0.4537', '0.3189', '0.5341', '0.3382']
his_acc des_wo_na:  ['0.7441', '0.6207', '0.5158', '0.4603', '0.3697']
cur_acc rrf_wo_na:  ['0.7528', '0.4608', '0.3254', '0.5336', '0.3497']
his_acc rrf_wo_na:  ['0.7528', '0.6211', '0.5194', '0.4517', '0.3648']
cur_acc_w_na:  ['0.6286', '0.3894', '0.3043', '0.3708', '0.2629']
his_acc_w_na:  ['0.6286', '0.4917', '0.4127', '0.3060', '0.2716']
cur_acc des_w_na:  ['0.6029', '0.3256', '0.2689', '0.3928', '0.2242']
his_acc des_w_na:  ['0.6029', '0.4602', '0.4011', '0.3275', '0.2591']
cur_acc rrf_w_na:  ['0.6160', '0.3356', '0.2799', '0.3910', '0.2358']
his_acc rrf_w_na:  ['0.6160', '0.4653', '0.4099', '0.3225', '0.2598']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 89.2450168CurrentTrain: epoch  0, batch     1 | loss: 88.4389172CurrentTrain: epoch  0, batch     2 | loss: 150.0131298CurrentTrain: epoch  0, batch     3 | loss: 84.7613140CurrentTrain: epoch  1, batch     0 | loss: 133.9789690CurrentTrain: epoch  1, batch     1 | loss: 78.3566944CurrentTrain: epoch  1, batch     2 | loss: 88.5452053CurrentTrain: epoch  1, batch     3 | loss: 115.0603547CurrentTrain: epoch  2, batch     0 | loss: 108.3228304CurrentTrain: epoch  2, batch     1 | loss: 103.6613038CurrentTrain: epoch  2, batch     2 | loss: 73.7779768CurrentTrain: epoch  2, batch     3 | loss: 71.3855469CurrentTrain: epoch  3, batch     0 | loss: 85.6801076CurrentTrain: epoch  3, batch     1 | loss: 177.8463584CurrentTrain: epoch  3, batch     2 | loss: 70.2711571CurrentTrain: epoch  3, batch     3 | loss: 67.8216087CurrentTrain: epoch  4, batch     0 | loss: 100.9447538CurrentTrain: epoch  4, batch     1 | loss: 79.8127271CurrentTrain: epoch  4, batch     2 | loss: 83.8375577CurrentTrain: epoch  4, batch     3 | loss: 70.4234346CurrentTrain: epoch  5, batch     0 | loss: 78.7277675CurrentTrain: epoch  5, batch     1 | loss: 102.8630222CurrentTrain: epoch  5, batch     2 | loss: 82.7630095CurrentTrain: epoch  5, batch     3 | loss: 63.6393302CurrentTrain: epoch  6, batch     0 | loss: 124.4751201CurrentTrain: epoch  6, batch     1 | loss: 76.2722273CurrentTrain: epoch  6, batch     2 | loss: 81.5831214CurrentTrain: epoch  6, batch     3 | loss: 66.6742792CurrentTrain: epoch  7, batch     0 | loss: 68.8496174CurrentTrain: epoch  7, batch     1 | loss: 81.6519213CurrentTrain: epoch  7, batch     2 | loss: 80.0916867CurrentTrain: epoch  7, batch     3 | loss: 63.5104317CurrentTrain: epoch  8, batch     0 | loss: 66.5529976CurrentTrain: epoch  8, batch     1 | loss: 65.8195124CurrentTrain: epoch  8, batch     2 | loss: 78.1889419CurrentTrain: epoch  8, batch     3 | loss: 137.0625122CurrentTrain: epoch  9, batch     0 | loss: 64.4172373CurrentTrain: epoch  9, batch     1 | loss: 67.3612284CurrentTrain: epoch  9, batch     2 | loss: 79.5219406CurrentTrain: epoch  9, batch     3 | loss: 66.1547406
MemoryTrain:  epoch  0, batch     0 | loss: 1.1150772MemoryTrain:  epoch  1, batch     0 | loss: 0.9636307MemoryTrain:  epoch  2, batch     0 | loss: 0.7953827MemoryTrain:  epoch  3, batch     0 | loss: 0.6528898MemoryTrain:  epoch  4, batch     0 | loss: 0.5699225MemoryTrain:  epoch  5, batch     0 | loss: 0.4769165MemoryTrain:  epoch  6, batch     0 | loss: 0.4043345MemoryTrain:  epoch  7, batch     0 | loss: 0.3673067MemoryTrain:  epoch  8, batch     0 | loss: 0.3403854MemoryTrain:  epoch  9, batch     0 | loss: 0.3089629

F1 score per class: {0: np.float64(0.7741935483870968), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7878787878787878), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.375), 14: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.43137254901960786), 22: np.float64(0.0), 23: np.float64(0.8260869565217391), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5032894736842105
Weighted-average F1 score: 0.3724054740867759
F1 score per class: {0: np.float64(0.7070707070707071), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7885714285714286), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.4), 14: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.5490196078431373), 22: np.float64(0.0), 23: np.float64(0.8131868131868132), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4773413897280967
Weighted-average F1 score: 0.34783224642154636
F1 score per class: {0: np.float64(0.7070707070707071), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8117647058823529), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.4), 14: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.5490196078431373), 22: np.float64(0.0), 23: np.float64(0.8131868131868132), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4952978056426332
Weighted-average F1 score: 0.36225484494552884

F1 score per class: {0: np.float64(0.3444976076555024), 1: np.float64(0.17518248175182483), 2: np.float64(0.5), 3: np.float64(0.5098039215686274), 4: np.float64(0.7878787878787878), 6: np.float64(0.46153846153846156), 7: np.float64(0.06666666666666667), 9: np.float64(0.7142857142857143), 11: np.float64(0.06593406593406594), 12: np.float64(0.017391304347826087), 13: np.float64(0.07228915662650602), 14: np.float64(0.06741573033707865), 15: np.float64(0.6666666666666666), 19: np.float64(0.531986531986532), 21: np.float64(0.12941176470588237), 22: np.float64(0.5134099616858238), 23: np.float64(0.6909090909090909), 24: np.float64(0.0), 25: np.float64(0.5), 26: np.float64(0.6871165644171779), 27: np.float64(0.0), 28: np.float64(0.23076923076923078), 29: np.float64(0.8350515463917526), 31: np.float64(0.09090909090909091), 32: np.float64(0.5362318840579711), 34: np.float64(0.16778523489932887), 35: np.float64(0.12903225806451613), 37: np.float64(0.25806451612903225), 38: np.float64(0.48), 39: np.float64(0.13793103448275862), 40: np.float64(0.17272727272727273)}
Micro-average F1 score: 0.3662987159270106
Weighted-average F1 score: 0.3411277014871308
F1 score per class: {0: np.float64(0.30973451327433627), 1: np.float64(0.16), 2: np.float64(0.24), 3: np.float64(0.3384615384615385), 4: np.float64(0.770949720670391), 6: np.float64(0.3902439024390244), 7: np.float64(0.05333333333333334), 9: np.float64(0.42016806722689076), 11: np.float64(0.02247191011235955), 12: np.float64(0.22535211267605634), 13: np.float64(0.075), 14: np.float64(0.03680981595092025), 15: np.float64(0.631578947368421), 19: np.float64(0.47477744807121663), 21: np.float64(0.16184971098265896), 22: np.float64(0.5021645021645021), 23: np.float64(0.74), 24: np.float64(0.0), 25: np.float64(0.7708333333333334), 26: np.float64(0.7182320441988951), 27: np.float64(0.0), 28: np.float64(0.10526315789473684), 29: np.float64(0.8282828282828283), 31: np.float64(0.04878048780487805), 32: np.float64(0.5448028673835126), 34: np.float64(0.2334096109839817), 35: np.float64(0.2145922746781116), 37: np.float64(0.176), 38: np.float64(0.4507042253521127), 39: np.float64(0.13793103448275862), 40: np.float64(0.22115384615384615)}
Micro-average F1 score: 0.3575533661740558
Weighted-average F1 score: 0.33196579126279424
F1 score per class: {0: np.float64(0.29535864978902954), 1: np.float64(0.15602836879432624), 2: np.float64(0.34285714285714286), 3: np.float64(0.35797665369649806), 4: np.float64(0.8117647058823529), 6: np.float64(0.4069264069264069), 7: np.float64(0.058823529411764705), 9: np.float64(0.6944444444444444), 11: np.float64(0.02247191011235955), 12: np.float64(0.15384615384615385), 13: np.float64(0.07894736842105263), 14: np.float64(0.04225352112676056), 15: np.float64(0.7058823529411765), 19: np.float64(0.4831804281345566), 21: np.float64(0.14432989690721648), 22: np.float64(0.5163934426229508), 23: np.float64(0.7326732673267327), 24: np.float64(0.0), 25: np.float64(0.6987951807228916), 26: np.float64(0.7078651685393258), 27: np.float64(0.0), 28: np.float64(0.10204081632653061), 29: np.float64(0.8121827411167513), 31: np.float64(0.0625), 32: np.float64(0.5473684210526316), 34: np.float64(0.2236842105263158), 35: np.float64(0.1890547263681592), 37: np.float64(0.16058394160583941), 38: np.float64(0.4117647058823529), 39: np.float64(0.13793103448275862), 40: np.float64(0.19742489270386265)}
Micro-average F1 score: 0.3573694227109325
Weighted-average F1 score: 0.3310083849351167

F1 score per class: {0: np.float64(0.6923076923076923), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7602339181286549), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.2), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.2972972972972973), 22: np.float64(0.0), 23: np.float64(0.7307692307692307), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.37317073170731707
Weighted-average F1 score: 0.266331422515633
F1 score per class: {0: np.float64(0.6194690265486725), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7540983606557377), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.18181818181818182), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.358974358974359), 22: np.float64(0.0), 23: np.float64(0.6851851851851852), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3446019629225736
Weighted-average F1 score: 0.24882182239759768
F1 score per class: {0: np.float64(0.6363636363636364), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7796610169491526), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.18181818181818182), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.35443037974683544), 22: np.float64(0.0), 23: np.float64(0.6915887850467289), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3607305936073059
Weighted-average F1 score: 0.25927947893474257

F1 score per class: {0: np.float64(0.2315112540192926), 1: np.float64(0.09393346379647749), 2: np.float64(0.3076923076923077), 3: np.float64(0.3701067615658363), 4: np.float64(0.7386363636363636), 6: np.float64(0.28125), 7: np.float64(0.042105263157894736), 9: np.float64(0.6493506493506493), 11: np.float64(0.06593406593406594), 12: np.float64(0.01652892561983471), 13: np.float64(0.03409090909090909), 14: np.float64(0.05714285714285714), 15: np.float64(0.46153846153846156), 19: np.float64(0.47878787878787876), 21: np.float64(0.08118081180811808), 22: np.float64(0.39644970414201186), 23: np.float64(0.59375), 24: np.float64(0.0), 25: np.float64(0.47368421052631576), 26: np.float64(0.6256983240223464), 27: np.float64(0.0), 28: np.float64(0.15384615384615385), 29: np.float64(0.6952789699570815), 31: np.float64(0.04878048780487805), 32: np.float64(0.38046272493573263), 34: np.float64(0.10741138560687433), 35: np.float64(0.0851063829787234), 37: np.float64(0.1606425702811245), 38: np.float64(0.36923076923076925), 39: np.float64(0.10256410256410256), 40: np.float64(0.13427561837455831)}
Micro-average F1 score: 0.2620467365028203
Weighted-average F1 score: 0.23757619352089276
F1 score per class: {0: np.float64(0.2028985507246377), 1: np.float64(0.088), 2: np.float64(0.14634146341463414), 3: np.float64(0.22), 4: np.float64(0.6602870813397129), 6: np.float64(0.22119815668202766), 7: np.float64(0.032), 9: np.float64(0.3225806451612903), 11: np.float64(0.02247191011235955), 12: np.float64(0.15483870967741936), 13: np.float64(0.03614457831325301), 14: np.float64(0.029556650246305417), 15: np.float64(0.42857142857142855), 19: np.float64(0.4071246819338422), 21: np.float64(0.09688581314878893), 22: np.float64(0.4013840830449827), 23: np.float64(0.5736434108527132), 24: np.float64(0.0), 25: np.float64(0.6115702479338843), 26: np.float64(0.6467661691542289), 27: np.float64(0.0), 28: np.float64(0.07042253521126761), 29: np.float64(0.7008547008547008), 31: np.float64(0.025974025974025976), 32: np.float64(0.39790575916230364), 34: np.float64(0.14186369958275383), 35: np.float64(0.13404825737265416), 37: np.float64(0.125), 38: np.float64(0.2962962962962963), 39: np.float64(0.07407407407407407), 40: np.float64(0.1597222222222222)}
Micro-average F1 score: 0.24646293152235427
Weighted-average F1 score: 0.2256902771170935
F1 score per class: {0: np.float64(0.19607843137254902), 1: np.float64(0.08494208494208494), 2: np.float64(0.2033898305084746), 3: np.float64(0.2365038560411311), 4: np.float64(0.745945945945946), 6: np.float64(0.23267326732673269), 7: np.float64(0.03508771929824561), 9: np.float64(0.6097560975609756), 11: np.float64(0.02247191011235955), 12: np.float64(0.12290502793296089), 13: np.float64(0.03680981595092025), 14: np.float64(0.03488372093023256), 15: np.float64(0.46153846153846156), 19: np.float64(0.42021276595744683), 21: np.float64(0.0851063829787234), 22: np.float64(0.4158415841584158), 23: np.float64(0.592), 24: np.float64(0.0), 25: np.float64(0.5979381443298969), 26: np.float64(0.6428571428571429), 27: np.float64(0.0), 28: np.float64(0.06802721088435375), 29: np.float64(0.6808510638297872), 31: np.float64(0.037037037037037035), 32: np.float64(0.40102827763496146), 34: np.float64(0.13545816733067728), 35: np.float64(0.11838006230529595), 37: np.float64(0.11398963730569948), 38: np.float64(0.2857142857142857), 39: np.float64(0.07142857142857142), 40: np.float64(0.14285714285714285)}
Micro-average F1 score: 0.249225777908863
Weighted-average F1 score: 0.2255843679790299
cur_acc_wo_na:  ['0.7534', '0.5150', '0.3551', '0.5226', '0.3801', '0.5033']
his_acc_wo_na:  ['0.7534', '0.6474', '0.5162', '0.4381', '0.3750', '0.3663']
cur_acc des_wo_na:  ['0.7441', '0.4537', '0.3189', '0.5341', '0.3382', '0.4773']
his_acc des_wo_na:  ['0.7441', '0.6207', '0.5158', '0.4603', '0.3697', '0.3576']
cur_acc rrf_wo_na:  ['0.7528', '0.4608', '0.3254', '0.5336', '0.3497', '0.4953']
his_acc rrf_wo_na:  ['0.7528', '0.6211', '0.5194', '0.4517', '0.3648', '0.3574']
cur_acc_w_na:  ['0.6286', '0.3894', '0.3043', '0.3708', '0.2629', '0.3732']
his_acc_w_na:  ['0.6286', '0.4917', '0.4127', '0.3060', '0.2716', '0.2620']
cur_acc des_w_na:  ['0.6029', '0.3256', '0.2689', '0.3928', '0.2242', '0.3446']
his_acc des_w_na:  ['0.6029', '0.4602', '0.4011', '0.3275', '0.2591', '0.2465']
cur_acc rrf_w_na:  ['0.6160', '0.3356', '0.2799', '0.3910', '0.2358', '0.3607']
his_acc rrf_w_na:  ['0.6160', '0.4653', '0.4099', '0.3225', '0.2598', '0.2492']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 107.3476801CurrentTrain: epoch  0, batch     1 | loss: 93.6240219CurrentTrain: epoch  0, batch     2 | loss: 90.7670658CurrentTrain: epoch  0, batch     3 | loss: 86.5030979CurrentTrain: epoch  1, batch     0 | loss: 107.2217800CurrentTrain: epoch  1, batch     1 | loss: 89.3357997CurrentTrain: epoch  1, batch     2 | loss: 76.3231982CurrentTrain: epoch  1, batch     3 | loss: 49.6492565CurrentTrain: epoch  2, batch     0 | loss: 74.2071925CurrentTrain: epoch  2, batch     1 | loss: 82.5456005CurrentTrain: epoch  2, batch     2 | loss: 85.0734151CurrentTrain: epoch  2, batch     3 | loss: 59.8159457CurrentTrain: epoch  3, batch     0 | loss: 68.4298629CurrentTrain: epoch  3, batch     1 | loss: 82.8827663CurrentTrain: epoch  3, batch     2 | loss: 68.9302219CurrentTrain: epoch  3, batch     3 | loss: 58.1766017CurrentTrain: epoch  4, batch     0 | loss: 124.8882633CurrentTrain: epoch  4, batch     1 | loss: 82.1930395CurrentTrain: epoch  4, batch     2 | loss: 66.5781525CurrentTrain: epoch  4, batch     3 | loss: 47.2241403CurrentTrain: epoch  5, batch     0 | loss: 98.2949813CurrentTrain: epoch  5, batch     1 | loss: 70.5467029CurrentTrain: epoch  5, batch     2 | loss: 92.9059121CurrentTrain: epoch  5, batch     3 | loss: 45.0284293CurrentTrain: epoch  6, batch     0 | loss: 64.7578903CurrentTrain: epoch  6, batch     1 | loss: 99.3635567CurrentTrain: epoch  6, batch     2 | loss: 92.8887573CurrentTrain: epoch  6, batch     3 | loss: 55.5209636CurrentTrain: epoch  7, batch     0 | loss: 63.2760406CurrentTrain: epoch  7, batch     1 | loss: 75.7259004CurrentTrain: epoch  7, batch     2 | loss: 80.7971232CurrentTrain: epoch  7, batch     3 | loss: 46.0467683CurrentTrain: epoch  8, batch     0 | loss: 76.1331469CurrentTrain: epoch  8, batch     1 | loss: 75.8064071CurrentTrain: epoch  8, batch     2 | loss: 78.2018191CurrentTrain: epoch  8, batch     3 | loss: 55.9997208CurrentTrain: epoch  9, batch     0 | loss: 75.1462133CurrentTrain: epoch  9, batch     1 | loss: 74.0755657CurrentTrain: epoch  9, batch     2 | loss: 62.7603244CurrentTrain: epoch  9, batch     3 | loss: 72.2441803
MemoryTrain:  epoch  0, batch     0 | loss: 0.7133400MemoryTrain:  epoch  1, batch     0 | loss: 0.6113871MemoryTrain:  epoch  2, batch     0 | loss: 0.4807220MemoryTrain:  epoch  3, batch     0 | loss: 0.4144175MemoryTrain:  epoch  4, batch     0 | loss: 0.3530665MemoryTrain:  epoch  5, batch     0 | loss: 0.3262577MemoryTrain:  epoch  6, batch     0 | loss: 0.3422080MemoryTrain:  epoch  7, batch     0 | loss: 0.2536900MemoryTrain:  epoch  8, batch     0 | loss: 0.2389979MemoryTrain:  epoch  9, batch     0 | loss: 0.2324925

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.5620915032679739), 13: np.float64(0.0), 20: np.float64(0.6744186046511628), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8333333333333334), 32: np.float64(0.0), 33: np.float64(0.47058823529411764), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.4090909090909091), 37: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.43687374749499
Weighted-average F1 score: 0.328515595755831
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.5897435897435898), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 20: np.float64(0.7339449541284404), 21: np.float64(0.0), 22: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7659574468085106), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.3333333333333333), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.7801418439716312), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5046728971962616
Weighted-average F1 score: 0.40605479768777963
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.5786163522012578), 9: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 20: np.float64(0.75), 21: np.float64(0.0), 22: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8), 32: np.float64(0.0), 33: np.float64(0.4), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.6605504587155964), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.47538200339558573
Weighted-average F1 score: 0.36155236088399095

F1 score per class: {0: np.float64(0.4166666666666667), 1: np.float64(0.1890909090909091), 2: np.float64(0.5), 3: np.float64(0.3795620437956204), 4: np.float64(0.8117647058823529), 6: np.float64(0.36257309941520466), 7: np.float64(0.0), 8: np.float64(0.2654320987654321), 9: np.float64(0.7142857142857143), 11: np.float64(0.06593406593406594), 12: np.float64(0.017857142857142856), 13: np.float64(0.07692307692307693), 14: np.float64(0.07228915662650602), 15: np.float64(0.6666666666666666), 19: np.float64(0.5144694533762058), 20: np.float64(0.6170212765957447), 21: np.float64(0.12030075187969924), 22: np.float64(0.5903083700440529), 23: np.float64(0.7157894736842105), 24: np.float64(0.0), 25: np.float64(0.45714285714285713), 26: np.float64(0.6966292134831461), 27: np.float64(0.0), 28: np.float64(0.34782608695652173), 29: np.float64(0.8235294117647058), 30: np.float64(0.8333333333333334), 31: np.float64(0.07407407407407407), 32: np.float64(0.5270758122743683), 33: np.float64(0.11594202898550725), 34: np.float64(0.24512534818941503), 35: np.float64(0.16666666666666666), 36: np.float64(0.37894736842105264), 37: np.float64(0.2916666666666667), 38: np.float64(0.30303030303030304), 39: np.float64(0.0), 40: np.float64(0.20618556701030927)}
Micro-average F1 score: 0.38772787905735884
Weighted-average F1 score: 0.3737980175768719
F1 score per class: {0: np.float64(0.2517985611510791), 1: np.float64(0.17164179104477612), 2: np.float64(0.27450980392156865), 3: np.float64(0.37545126353790614), 4: np.float64(0.8350515463917526), 6: np.float64(0.4484304932735426), 7: np.float64(0.037037037037037035), 8: np.float64(0.24146981627296588), 9: np.float64(0.42735042735042733), 11: np.float64(0.08695652173913043), 12: np.float64(0.19), 13: np.float64(0.0), 14: np.float64(0.05172413793103448), 15: np.float64(0.5), 19: np.float64(0.46070460704607047), 20: np.float64(0.47337278106508873), 21: np.float64(0.11049723756906077), 22: np.float64(0.5149253731343284), 23: np.float64(0.7184466019417476), 24: np.float64(0.0), 25: np.float64(0.6373626373626373), 26: np.float64(0.6994535519125683), 27: np.float64(0.0), 28: np.float64(0.20408163265306123), 29: np.float64(0.8115942028985508), 30: np.float64(0.37894736842105264), 31: np.float64(0.02857142857142857), 32: np.float64(0.538961038961039), 33: np.float64(0.0821917808219178), 34: np.float64(0.2848297213622291), 35: np.float64(0.1862348178137652), 36: np.float64(0.5238095238095238), 37: np.float64(0.14754098360655737), 38: np.float64(0.4482758620689655), 39: np.float64(0.16666666666666666), 40: np.float64(0.20606060606060606)}
Micro-average F1 score: 0.370042492917847
Weighted-average F1 score: 0.35246479358410376
F1 score per class: {0: np.float64(0.2845528455284553), 1: np.float64(0.16546762589928057), 2: np.float64(0.34285714285714286), 3: np.float64(0.4230769230769231), 4: np.float64(0.8901098901098901), 6: np.float64(0.4339622641509434), 7: np.float64(0.04), 8: np.float64(0.23711340206185566), 9: np.float64(0.6666666666666666), 11: np.float64(0.08695652173913043), 12: np.float64(0.12121212121212122), 13: np.float64(0.0), 14: np.float64(0.05084745762711865), 15: np.float64(0.5217391304347826), 19: np.float64(0.4857142857142857), 20: np.float64(0.5454545454545454), 21: np.float64(0.08465608465608465), 22: np.float64(0.5440613026819924), 23: np.float64(0.7578947368421053), 24: np.float64(0.0), 25: np.float64(0.6190476190476191), 26: np.float64(0.7032967032967034), 27: np.float64(0.0), 28: np.float64(0.2), 29: np.float64(0.8095238095238095), 30: np.float64(0.4864864864864865), 31: np.float64(0.05), 32: np.float64(0.5222929936305732), 33: np.float64(0.09876543209876543), 34: np.float64(0.26436781609195403), 35: np.float64(0.18099547511312217), 36: np.float64(0.549618320610687), 37: np.float64(0.18055555555555555), 38: np.float64(0.45454545454545453), 39: np.float64(0.21052631578947367), 40: np.float64(0.19791666666666666)}
Micro-average F1 score: 0.3786869647954329
Weighted-average F1 score: 0.35749539210525544

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.4387755102040816), 13: np.float64(0.0), 20: np.float64(0.5420560747663551), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7894736842105263), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.32), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.3302752293577982), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.31412103746397696
Weighted-average F1 score: 0.24377967710253032
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.42201834862385323), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5594405594405595), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.72), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.2222222222222222), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.5759162303664922), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.33505687693898656
Weighted-average F1 score: 0.27917365204218036
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.4144144144144144), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5714285714285714), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7659574468085106), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.25), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.5034965034965035), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.319634703196347
Weighted-average F1 score: 0.2558780292328041

F1 score per class: {0: np.float64(0.2777777777777778), 1: np.float64(0.10256410256410256), 2: np.float64(0.2631578947368421), 3: np.float64(0.2736842105263158), 4: np.float64(0.7752808988764045), 6: np.float64(0.2246376811594203), 7: np.float64(0.0), 8: np.float64(0.15693430656934307), 9: np.float64(0.6410256410256411), 11: np.float64(0.06593406593406594), 12: np.float64(0.017094017094017096), 13: np.float64(0.04081632653061224), 14: np.float64(0.06315789473684211), 15: np.float64(0.48), 19: np.float64(0.463768115942029), 20: np.float64(0.3431952662721893), 21: np.float64(0.0761904761904762), 22: np.float64(0.4785714285714286), 23: np.float64(0.6415094339622641), 24: np.float64(0.0), 25: np.float64(0.43243243243243246), 26: np.float64(0.6262626262626263), 27: np.float64(0.0), 28: np.float64(0.2222222222222222), 29: np.float64(0.6857142857142857), 30: np.float64(0.7317073170731707), 31: np.float64(0.04), 32: np.float64(0.37532133676092544), 33: np.float64(0.07272727272727272), 34: np.float64(0.1461794019933555), 35: np.float64(0.11764705882352941), 36: np.float64(0.2706766917293233), 37: np.float64(0.21105527638190955), 38: np.float64(0.2631578947368421), 39: np.float64(0.0), 40: np.float64(0.15625)}
Micro-average F1 score: 0.27739780499443295
Weighted-average F1 score: 0.2573699751685161
F1 score per class: {0: np.float64(0.166270783847981), 1: np.float64(0.09504132231404959), 2: np.float64(0.16470588235294117), 3: np.float64(0.24186046511627907), 4: np.float64(0.7297297297297297), 6: np.float64(0.2724795640326976), 7: np.float64(0.023809523809523808), 8: np.float64(0.13918305597579425), 9: np.float64(0.31645569620253167), 11: np.float64(0.08695652173913043), 12: np.float64(0.13523131672597866), 13: np.float64(0.0), 14: np.float64(0.043478260869565216), 15: np.float64(0.375), 19: np.float64(0.39443155452436196), 20: np.float64(0.25477707006369427), 21: np.float64(0.06802721088435375), 22: np.float64(0.40828402366863903), 23: np.float64(0.5481481481481482), 24: np.float64(0.0), 25: np.float64(0.5742574257425742), 26: np.float64(0.6274509803921569), 27: np.float64(0.0), 28: np.float64(0.10752688172043011), 29: np.float64(0.6666666666666666), 30: np.float64(0.28346456692913385), 31: np.float64(0.01652892561983471), 32: np.float64(0.3933649289099526), 33: np.float64(0.05042016806722689), 34: np.float64(0.17196261682242991), 35: np.float64(0.11886304909560723), 36: np.float64(0.3416149068322981), 37: np.float64(0.10778443113772455), 38: np.float64(0.30952380952380953), 39: np.float64(0.125), 40: np.float64(0.15454545454545454)}
Micro-average F1 score: 0.25391811444538936
Weighted-average F1 score: 0.23775796135581484
F1 score per class: {0: np.float64(0.19021739130434784), 1: np.float64(0.09090909090909091), 2: np.float64(0.2033898305084746), 3: np.float64(0.284789644012945), 4: np.float64(0.84375), 6: np.float64(0.26822157434402333), 7: np.float64(0.02531645569620253), 8: np.float64(0.13569321533923304), 9: np.float64(0.5882352941176471), 11: np.float64(0.08695652173913043), 12: np.float64(0.10126582278481013), 13: np.float64(0.0), 14: np.float64(0.0425531914893617), 15: np.float64(0.375), 19: np.float64(0.42606516290726815), 20: np.float64(0.28125), 21: np.float64(0.053156146179401995), 22: np.float64(0.4409937888198758), 23: np.float64(0.5853658536585366), 24: np.float64(0.0), 25: np.float64(0.5591397849462365), 26: np.float64(0.6336633663366337), 27: np.float64(0.0), 28: np.float64(0.10869565217391304), 29: np.float64(0.6666666666666666), 30: np.float64(0.375), 31: np.float64(0.02702702702702703), 32: np.float64(0.3813953488372093), 33: np.float64(0.05755395683453238), 34: np.float64(0.1616871704745167), 35: np.float64(0.11494252873563218), 36: np.float64(0.36), 37: np.float64(0.12745098039215685), 38: np.float64(0.3076923076923077), 39: np.float64(0.17391304347826086), 40: np.float64(0.1450381679389313)}
Micro-average F1 score: 0.26298400951499934
Weighted-average F1 score: 0.24260531374561023
cur_acc_wo_na:  ['0.7534', '0.5150', '0.3551', '0.5226', '0.3801', '0.5033', '0.4369']
his_acc_wo_na:  ['0.7534', '0.6474', '0.5162', '0.4381', '0.3750', '0.3663', '0.3877']
cur_acc des_wo_na:  ['0.7441', '0.4537', '0.3189', '0.5341', '0.3382', '0.4773', '0.5047']
his_acc des_wo_na:  ['0.7441', '0.6207', '0.5158', '0.4603', '0.3697', '0.3576', '0.3700']
cur_acc rrf_wo_na:  ['0.7528', '0.4608', '0.3254', '0.5336', '0.3497', '0.4953', '0.4754']
his_acc rrf_wo_na:  ['0.7528', '0.6211', '0.5194', '0.4517', '0.3648', '0.3574', '0.3787']
cur_acc_w_na:  ['0.6286', '0.3894', '0.3043', '0.3708', '0.2629', '0.3732', '0.3141']
his_acc_w_na:  ['0.6286', '0.4917', '0.4127', '0.3060', '0.2716', '0.2620', '0.2774']
cur_acc des_w_na:  ['0.6029', '0.3256', '0.2689', '0.3928', '0.2242', '0.3446', '0.3351']
his_acc des_w_na:  ['0.6029', '0.4602', '0.4011', '0.3275', '0.2591', '0.2465', '0.2539']
cur_acc rrf_w_na:  ['0.6160', '0.3356', '0.2799', '0.3910', '0.2358', '0.3607', '0.3196']
his_acc rrf_w_na:  ['0.6160', '0.4653', '0.4099', '0.3225', '0.2598', '0.2492', '0.2630']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 123.9856773CurrentTrain: epoch  0, batch     1 | loss: 144.5197131CurrentTrain: epoch  0, batch     2 | loss: 112.3001410CurrentTrain: epoch  0, batch     3 | loss: 84.2178235CurrentTrain: epoch  0, batch     4 | loss: 64.8118335CurrentTrain: epoch  1, batch     0 | loss: 91.0668951CurrentTrain: epoch  1, batch     1 | loss: 94.0032786CurrentTrain: epoch  1, batch     2 | loss: 111.3926566CurrentTrain: epoch  1, batch     3 | loss: 131.0290421CurrentTrain: epoch  1, batch     4 | loss: 111.9606981CurrentTrain: epoch  2, batch     0 | loss: 112.6430264CurrentTrain: epoch  2, batch     1 | loss: 129.4569612CurrentTrain: epoch  2, batch     2 | loss: 103.3267980CurrentTrain: epoch  2, batch     3 | loss: 105.1291838CurrentTrain: epoch  2, batch     4 | loss: 52.7162913CurrentTrain: epoch  3, batch     0 | loss: 81.7565875CurrentTrain: epoch  3, batch     1 | loss: 103.4986736CurrentTrain: epoch  3, batch     2 | loss: 83.9789799CurrentTrain: epoch  3, batch     3 | loss: 102.5989097CurrentTrain: epoch  3, batch     4 | loss: 89.2542430CurrentTrain: epoch  4, batch     0 | loss: 84.4065697CurrentTrain: epoch  4, batch     1 | loss: 70.3535292CurrentTrain: epoch  4, batch     2 | loss: 104.3632901CurrentTrain: epoch  4, batch     3 | loss: 80.9735452CurrentTrain: epoch  4, batch     4 | loss: 170.8623788CurrentTrain: epoch  5, batch     0 | loss: 81.7721813CurrentTrain: epoch  5, batch     1 | loss: 81.3015476CurrentTrain: epoch  5, batch     2 | loss: 82.6432570CurrentTrain: epoch  5, batch     3 | loss: 102.5531272CurrentTrain: epoch  5, batch     4 | loss: 51.8275851CurrentTrain: epoch  6, batch     0 | loss: 79.8149628CurrentTrain: epoch  6, batch     1 | loss: 84.0541163CurrentTrain: epoch  6, batch     2 | loss: 69.1675483CurrentTrain: epoch  6, batch     3 | loss: 96.5970682CurrentTrain: epoch  6, batch     4 | loss: 81.0206492CurrentTrain: epoch  7, batch     0 | loss: 96.1010544CurrentTrain: epoch  7, batch     1 | loss: 78.2687905CurrentTrain: epoch  7, batch     2 | loss: 129.1200099CurrentTrain: epoch  7, batch     3 | loss: 65.7388666CurrentTrain: epoch  7, batch     4 | loss: 61.7184874CurrentTrain: epoch  8, batch     0 | loss: 96.7812186CurrentTrain: epoch  8, batch     1 | loss: 79.1022809CurrentTrain: epoch  8, batch     2 | loss: 97.1941256CurrentTrain: epoch  8, batch     3 | loss: 77.4180926CurrentTrain: epoch  8, batch     4 | loss: 50.2500712CurrentTrain: epoch  9, batch     0 | loss: 96.2479700CurrentTrain: epoch  9, batch     1 | loss: 92.1628491CurrentTrain: epoch  9, batch     2 | loss: 74.8453100CurrentTrain: epoch  9, batch     3 | loss: 97.3089624CurrentTrain: epoch  9, batch     4 | loss: 59.2543868
MemoryTrain:  epoch  0, batch     0 | loss: 0.9708649MemoryTrain:  epoch  1, batch     0 | loss: 0.8017905MemoryTrain:  epoch  2, batch     0 | loss: 0.6229492MemoryTrain:  epoch  3, batch     0 | loss: 0.5152829MemoryTrain:  epoch  4, batch     0 | loss: 0.3960701MemoryTrain:  epoch  5, batch     0 | loss: 0.3535967MemoryTrain:  epoch  6, batch     0 | loss: 0.3630815MemoryTrain:  epoch  7, batch     0 | loss: 0.2671787MemoryTrain:  epoch  8, batch     0 | loss: 0.2600093MemoryTrain:  epoch  9, batch     0 | loss: 0.2443140

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.9064039408866995), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.3225806451612903), 11: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.7169811320754716), 17: np.float64(0.7142857142857143), 18: np.float64(0.25287356321839083), 20: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.49830508474576274
Weighted-average F1 score: 0.426137624730207
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.6464646464646465), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.5352112676056338), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.7027027027027027), 17: np.float64(0.75), 18: np.float64(0.21621621621621623), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.425629290617849
Weighted-average F1 score: 0.3645507149028276
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.7084870848708487), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.547945205479452), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.7076923076923077), 17: np.float64(0.6666666666666666), 18: np.float64(0.2727272727272727), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.46017699115044247
Weighted-average F1 score: 0.39035940319085743

F1 score per class: {0: np.float64(0.5343511450381679), 1: np.float64(0.16279069767441862), 2: np.float64(0.5263157894736842), 3: np.float64(0.3357664233576642), 4: np.float64(0.7904191616766467), 5: np.float64(0.7419354838709677), 6: np.float64(0.2692307692307692), 7: np.float64(0.0), 8: np.float64(0.2857142857142857), 9: np.float64(0.6756756756756757), 10: np.float64(0.21978021978021978), 11: np.float64(0.022222222222222223), 12: np.float64(0.0), 13: np.float64(0.08333333333333333), 14: np.float64(0.07894736842105263), 15: np.float64(0.5882352941176471), 16: np.float64(0.6666666666666666), 17: np.float64(0.4), 18: np.float64(0.14965986394557823), 19: np.float64(0.5033112582781457), 20: np.float64(0.5154639175257731), 21: np.float64(0.13793103448275862), 22: np.float64(0.5617021276595745), 23: np.float64(0.7446808510638298), 24: np.float64(0.0), 25: np.float64(0.3582089552238806), 26: np.float64(0.6666666666666666), 27: np.float64(0.0), 28: np.float64(0.26666666666666666), 29: np.float64(0.821256038647343), 30: np.float64(0.7777777777777778), 31: np.float64(0.08695652173913043), 32: np.float64(0.5099601593625498), 33: np.float64(0.10344827586206896), 34: np.float64(0.20710059171597633), 35: np.float64(0.15625), 36: np.float64(0.1794871794871795), 37: np.float64(0.26666666666666666), 38: np.float64(0.1875), 39: np.float64(0.21052631578947367), 40: np.float64(0.2430939226519337)}
Micro-average F1 score: 0.38592132505175986
Weighted-average F1 score: 0.3831164187179211
F1 score per class: {0: np.float64(0.29045643153526973), 1: np.float64(0.17228464419475656), 2: np.float64(0.26666666666666666), 3: np.float64(0.37037037037037035), 4: np.float64(0.85), 5: np.float64(0.4507042253521127), 6: np.float64(0.4214876033057851), 7: np.float64(0.0392156862745098), 8: np.float64(0.2926829268292683), 9: np.float64(0.3546099290780142), 10: np.float64(0.37623762376237624), 11: np.float64(0.2376237623762376), 12: np.float64(0.24896265560165975), 13: np.float64(0.2), 14: np.float64(0.05042016806722689), 15: np.float64(0.5), 16: np.float64(0.5531914893617021), 17: np.float64(0.24), 18: np.float64(0.12232415902140673), 19: np.float64(0.43116883116883115), 20: np.float64(0.4175824175824176), 21: np.float64(0.1476510067114094), 22: np.float64(0.4748201438848921), 23: np.float64(0.6363636363636364), 24: np.float64(0.0), 25: np.float64(0.5348837209302325), 26: np.float64(0.6878306878306878), 27: np.float64(0.0), 28: np.float64(0.18181818181818182), 29: np.float64(0.8173076923076923), 30: np.float64(0.4444444444444444), 31: np.float64(0.03333333333333333), 32: np.float64(0.531986531986532), 33: np.float64(0.08450704225352113), 34: np.float64(0.31451612903225806), 35: np.float64(0.24535315985130113), 36: np.float64(0.5034965034965035), 37: np.float64(0.14102564102564102), 38: np.float64(0.4507042253521127), 39: np.float64(0.125), 40: np.float64(0.14772727272727273)}
Micro-average F1 score: 0.36731588557516737
Weighted-average F1 score: 0.3496058191194342
F1 score per class: {0: np.float64(0.31718061674008813), 1: np.float64(0.15942028985507245), 2: np.float64(0.35294117647058826), 3: np.float64(0.39106145251396646), 4: np.float64(0.8571428571428571), 5: np.float64(0.5092838196286472), 6: np.float64(0.411214953271028), 7: np.float64(0.038461538461538464), 8: np.float64(0.2887323943661972), 9: np.float64(0.625), 10: np.float64(0.36036036036036034), 11: np.float64(0.10638297872340426), 12: np.float64(0.14285714285714285), 13: np.float64(0.2), 14: np.float64(0.05357142857142857), 15: np.float64(0.5454545454545454), 16: np.float64(0.5822784810126582), 17: np.float64(0.24390243902439024), 18: np.float64(0.14937759336099585), 19: np.float64(0.45054945054945056), 20: np.float64(0.5333333333333333), 21: np.float64(0.1375), 22: np.float64(0.4944649446494465), 23: np.float64(0.7), 24: np.float64(0.0), 25: np.float64(0.5384615384615384), 26: np.float64(0.6914893617021277), 27: np.float64(0.0), 28: np.float64(0.1702127659574468), 29: np.float64(0.819047619047619), 30: np.float64(0.6296296296296297), 31: np.float64(0.05128205128205128), 32: np.float64(0.528169014084507), 33: np.float64(0.08108108108108109), 34: np.float64(0.23423423423423423), 35: np.float64(0.20304568527918782), 36: np.float64(0.47058823529411764), 37: np.float64(0.1610738255033557), 38: np.float64(0.4166666666666667), 39: np.float64(0.18181818181818182), 40: np.float64(0.13541666666666666)}
Micro-average F1 score: 0.37441235728676964
Weighted-average F1 score: 0.3572579722888543

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.7131782945736435), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.30303030303030304), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.475), 17: np.float64(0.5), 18: np.float64(0.20952380952380953), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3387096774193548
Weighted-average F1 score: 0.28019722852571693
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.49104859335038364), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.48717948717948717), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.45217391304347826), 17: np.float64(0.42857142857142855), 18: np.float64(0.16806722689075632), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2749445676274945
Weighted-average F1 score: 0.23262427511941294
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.5454545454545454), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.4968944099378882), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.4423076923076923), 17: np.float64(0.4), 18: np.float64(0.2033898305084746), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3020746887966805
Weighted-average F1 score: 0.2533589342978604

F1 score per class: {0: np.float64(0.35175879396984927), 1: np.float64(0.08879492600422834), 2: np.float64(0.2857142857142857), 3: np.float64(0.24468085106382978), 4: np.float64(0.7457627118644068), 5: np.float64(0.49595687331536387), 6: np.float64(0.17872340425531916), 7: np.float64(0.0), 8: np.float64(0.1763085399449036), 9: np.float64(0.5952380952380952), 10: np.float64(0.16736401673640167), 11: np.float64(0.022222222222222223), 12: np.float64(0.0), 13: np.float64(0.0425531914893617), 14: np.float64(0.07142857142857142), 15: np.float64(0.5), 16: np.float64(0.4175824175824176), 17: np.float64(0.2127659574468085), 18: np.float64(0.10679611650485436), 19: np.float64(0.45103857566765576), 20: np.float64(0.2808988764044944), 21: np.float64(0.08839779005524862), 22: np.float64(0.4536082474226804), 23: np.float64(0.6730769230769231), 24: np.float64(0.0), 25: np.float64(0.34782608695652173), 26: np.float64(0.59), 27: np.float64(0.0), 28: np.float64(0.17391304347826086), 29: np.float64(0.6666666666666666), 30: np.float64(0.6511627906976745), 31: np.float64(0.044444444444444446), 32: np.float64(0.39384615384615385), 33: np.float64(0.06741573033707865), 34: np.float64(0.12216404886561955), 35: np.float64(0.11363636363636363), 36: np.float64(0.15053763440860216), 37: np.float64(0.1893491124260355), 38: np.float64(0.16216216216216217), 39: np.float64(0.16666666666666666), 40: np.float64(0.2)}
Micro-average F1 score: 0.27992191019672624
Weighted-average F1 score: 0.2675532385261784
F1 score per class: {0: np.float64(0.19886363636363635), 1: np.float64(0.09274193548387097), 2: np.float64(0.16901408450704225), 3: np.float64(0.22922636103151864), 4: np.float64(0.7359307359307359), 5: np.float64(0.2727272727272727), 6: np.float64(0.2388758782201405), 7: np.float64(0.023809523809523808), 8: np.float64(0.18064516129032257), 9: np.float64(0.25773195876288657), 10: np.float64(0.2593856655290102), 11: np.float64(0.22429906542056074), 12: np.float64(0.15113350125944586), 13: np.float64(0.1111111111111111), 14: np.float64(0.041379310344827586), 15: np.float64(0.4), 16: np.float64(0.3270440251572327), 17: np.float64(0.1111111111111111), 18: np.float64(0.08620689655172414), 19: np.float64(0.3624454148471616), 20: np.float64(0.2367601246105919), 21: np.float64(0.088), 22: np.float64(0.3656509695290859), 23: np.float64(0.445859872611465), 24: np.float64(0.0), 25: np.float64(0.4946236559139785), 26: np.float64(0.6074766355140186), 27: np.float64(0.0), 28: np.float64(0.1038961038961039), 29: np.float64(0.6415094339622641), 30: np.float64(0.3), 31: np.float64(0.019230769230769232), 32: np.float64(0.3969849246231156), 33: np.float64(0.04580152671755725), 34: np.float64(0.17488789237668162), 35: np.float64(0.16019417475728157), 36: np.float64(0.3302752293577982), 37: np.float64(0.09691629955947137), 38: np.float64(0.2689075630252101), 39: np.float64(0.07692307692307693), 40: np.float64(0.10483870967741936)}
Micro-average F1 score: 0.24579981671927503
Weighted-average F1 score: 0.2320196623463348
F1 score per class: {0: np.float64(0.21621621621621623), 1: np.float64(0.0874751491053678), 2: np.float64(0.2222222222222222), 3: np.float64(0.2661596958174905), 4: np.float64(0.8064516129032258), 5: np.float64(0.31527093596059114), 6: np.float64(0.23529411764705882), 7: np.float64(0.024691358024691357), 8: np.float64(0.1722689075630252), 9: np.float64(0.5376344086021505), 10: np.float64(0.25157232704402516), 11: np.float64(0.10204081632653061), 12: np.float64(0.10416666666666667), 13: np.float64(0.1111111111111111), 14: np.float64(0.043795620437956206), 15: np.float64(0.42857142857142855), 16: np.float64(0.32857142857142857), 17: np.float64(0.11627906976744186), 18: np.float64(0.09863013698630137), 19: np.float64(0.3840749414519906), 20: np.float64(0.277992277992278), 21: np.float64(0.08494208494208494), 22: np.float64(0.38285714285714284), 23: np.float64(0.5223880597014925), 24: np.float64(0.0), 25: np.float64(0.5060240963855421), 26: np.float64(0.6161137440758294), 27: np.float64(0.0), 28: np.float64(0.10126582278481013), 29: np.float64(0.6441947565543071), 30: np.float64(0.4473684210526316), 31: np.float64(0.029850746268656716), 32: np.float64(0.391644908616188), 33: np.float64(0.0425531914893617), 34: np.float64(0.14233576642335766), 35: np.float64(0.1342281879194631), 36: np.float64(0.3221476510067114), 37: np.float64(0.11059907834101383), 38: np.float64(0.26666666666666666), 39: np.float64(0.125), 40: np.float64(0.09454545454545454)}
Micro-average F1 score: 0.25520714122224764
Weighted-average F1 score: 0.23963894282885406
cur_acc_wo_na:  ['0.7534', '0.5150', '0.3551', '0.5226', '0.3801', '0.5033', '0.4369', '0.4983']
his_acc_wo_na:  ['0.7534', '0.6474', '0.5162', '0.4381', '0.3750', '0.3663', '0.3877', '0.3859']
cur_acc des_wo_na:  ['0.7441', '0.4537', '0.3189', '0.5341', '0.3382', '0.4773', '0.5047', '0.4256']
his_acc des_wo_na:  ['0.7441', '0.6207', '0.5158', '0.4603', '0.3697', '0.3576', '0.3700', '0.3673']
cur_acc rrf_wo_na:  ['0.7528', '0.4608', '0.3254', '0.5336', '0.3497', '0.4953', '0.4754', '0.4602']
his_acc rrf_wo_na:  ['0.7528', '0.6211', '0.5194', '0.4517', '0.3648', '0.3574', '0.3787', '0.3744']
cur_acc_w_na:  ['0.6286', '0.3894', '0.3043', '0.3708', '0.2629', '0.3732', '0.3141', '0.3387']
his_acc_w_na:  ['0.6286', '0.4917', '0.4127', '0.3060', '0.2716', '0.2620', '0.2774', '0.2799']
cur_acc des_w_na:  ['0.6029', '0.3256', '0.2689', '0.3928', '0.2242', '0.3446', '0.3351', '0.2749']
his_acc des_w_na:  ['0.6029', '0.4602', '0.4011', '0.3275', '0.2591', '0.2465', '0.2539', '0.2458']
cur_acc rrf_w_na:  ['0.6160', '0.3356', '0.2799', '0.3910', '0.2358', '0.3607', '0.3196', '0.3021']
his_acc rrf_w_na:  ['0.6160', '0.4653', '0.4099', '0.3225', '0.2598', '0.2492', '0.2630', '0.2552']
--------Round  1
seed:  200
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 6 3 2 4 0 5 1]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 129.7528089CurrentTrain: epoch  0, batch     1 | loss: 89.8079110CurrentTrain: epoch  0, batch     2 | loss: 78.5067588CurrentTrain: epoch  0, batch     3 | loss: 120.6109242CurrentTrain: epoch  0, batch     4 | loss: 77.6800952CurrentTrain: epoch  0, batch     5 | loss: 148.4673567CurrentTrain: epoch  0, batch     6 | loss: 88.1462033CurrentTrain: epoch  0, batch     7 | loss: 100.0827582CurrentTrain: epoch  0, batch     8 | loss: 86.3163774CurrentTrain: epoch  0, batch     9 | loss: 119.1538339CurrentTrain: epoch  0, batch    10 | loss: 90.2354299CurrentTrain: epoch  0, batch    11 | loss: 100.1165170CurrentTrain: epoch  0, batch    12 | loss: 86.2371420CurrentTrain: epoch  0, batch    13 | loss: 145.8798494CurrentTrain: epoch  0, batch    14 | loss: 99.9984768CurrentTrain: epoch  0, batch    15 | loss: 100.5109528CurrentTrain: epoch  0, batch    16 | loss: 99.2668395CurrentTrain: epoch  0, batch    17 | loss: 75.9962448CurrentTrain: epoch  0, batch    18 | loss: 86.9984949CurrentTrain: epoch  0, batch    19 | loss: 99.2953868CurrentTrain: epoch  0, batch    20 | loss: 118.9839478CurrentTrain: epoch  0, batch    21 | loss: 119.4681551CurrentTrain: epoch  0, batch    22 | loss: 99.3535456CurrentTrain: epoch  0, batch    23 | loss: 99.0104017CurrentTrain: epoch  0, batch    24 | loss: 86.3479546CurrentTrain: epoch  0, batch    25 | loss: 117.6062072CurrentTrain: epoch  0, batch    26 | loss: 99.0878794CurrentTrain: epoch  0, batch    27 | loss: 98.9808818CurrentTrain: epoch  0, batch    28 | loss: 85.6927197CurrentTrain: epoch  0, batch    29 | loss: 98.6412265CurrentTrain: epoch  0, batch    30 | loss: 98.3251377CurrentTrain: epoch  0, batch    31 | loss: 117.3555477CurrentTrain: epoch  0, batch    32 | loss: 83.7066984CurrentTrain: epoch  0, batch    33 | loss: 98.2256706CurrentTrain: epoch  0, batch    34 | loss: 117.3555203CurrentTrain: epoch  0, batch    35 | loss: 99.4834832CurrentTrain: epoch  0, batch    36 | loss: 98.6423635CurrentTrain: epoch  0, batch    37 | loss: 97.9692025CurrentTrain: epoch  0, batch    38 | loss: 84.8209255CurrentTrain: epoch  0, batch    39 | loss: 97.7070556CurrentTrain: epoch  0, batch    40 | loss: 145.4375894CurrentTrain: epoch  0, batch    41 | loss: 98.8129117CurrentTrain: epoch  0, batch    42 | loss: 96.9284844CurrentTrain: epoch  0, batch    43 | loss: 96.8239939CurrentTrain: epoch  0, batch    44 | loss: 114.6367516CurrentTrain: epoch  0, batch    45 | loss: 116.1486269CurrentTrain: epoch  0, batch    46 | loss: 141.8273066CurrentTrain: epoch  0, batch    47 | loss: 93.7630493CurrentTrain: epoch  0, batch    48 | loss: 83.8802174CurrentTrain: epoch  0, batch    49 | loss: 96.2989832CurrentTrain: epoch  0, batch    50 | loss: 73.0496893CurrentTrain: epoch  0, batch    51 | loss: 116.2620842CurrentTrain: epoch  0, batch    52 | loss: 82.4094312CurrentTrain: epoch  0, batch    53 | loss: 81.4347282CurrentTrain: epoch  0, batch    54 | loss: 73.0990681CurrentTrain: epoch  0, batch    55 | loss: 191.7030016CurrentTrain: epoch  0, batch    56 | loss: 142.8432095CurrentTrain: epoch  0, batch    57 | loss: 191.7440929CurrentTrain: epoch  0, batch    58 | loss: 112.7345144CurrentTrain: epoch  0, batch    59 | loss: 115.7143294CurrentTrain: epoch  0, batch    60 | loss: 139.1958657CurrentTrain: epoch  0, batch    61 | loss: 71.4637321CurrentTrain: epoch  0, batch    62 | loss: 191.6324283CurrentTrain: epoch  0, batch    63 | loss: 113.0708030CurrentTrain: epoch  0, batch    64 | loss: 81.9867963CurrentTrain: epoch  0, batch    65 | loss: 94.6671145CurrentTrain: epoch  0, batch    66 | loss: 137.5325713CurrentTrain: epoch  0, batch    67 | loss: 94.8084335CurrentTrain: epoch  0, batch    68 | loss: 82.4165387CurrentTrain: epoch  0, batch    69 | loss: 142.1581889CurrentTrain: epoch  0, batch    70 | loss: 94.2384590CurrentTrain: epoch  0, batch    71 | loss: 79.1495629CurrentTrain: epoch  0, batch    72 | loss: 96.2669601CurrentTrain: epoch  0, batch    73 | loss: 94.8186895CurrentTrain: epoch  0, batch    74 | loss: 114.1004059CurrentTrain: epoch  0, batch    75 | loss: 112.0571414CurrentTrain: epoch  0, batch    76 | loss: 141.0552288CurrentTrain: epoch  0, batch    77 | loss: 111.2723386CurrentTrain: epoch  0, batch    78 | loss: 109.7510254CurrentTrain: epoch  0, batch    79 | loss: 91.4596372CurrentTrain: epoch  0, batch    80 | loss: 81.4394515CurrentTrain: epoch  0, batch    81 | loss: 78.7284524CurrentTrain: epoch  0, batch    82 | loss: 92.4486180CurrentTrain: epoch  0, batch    83 | loss: 82.1960404CurrentTrain: epoch  0, batch    84 | loss: 79.6114846CurrentTrain: epoch  0, batch    85 | loss: 111.4400760CurrentTrain: epoch  0, batch    86 | loss: 79.9979469CurrentTrain: epoch  0, batch    87 | loss: 111.2130747CurrentTrain: epoch  0, batch    88 | loss: 76.6425880CurrentTrain: epoch  0, batch    89 | loss: 112.4616617CurrentTrain: epoch  0, batch    90 | loss: 91.8926337CurrentTrain: epoch  0, batch    91 | loss: 91.8069254CurrentTrain: epoch  0, batch    92 | loss: 89.1976558CurrentTrain: epoch  0, batch    93 | loss: 95.6450718CurrentTrain: epoch  0, batch    94 | loss: 138.4119357CurrentTrain: epoch  0, batch    95 | loss: 113.6934911CurrentTrain: epoch  1, batch     0 | loss: 90.3357503CurrentTrain: epoch  1, batch     1 | loss: 76.1801634CurrentTrain: epoch  1, batch     2 | loss: 113.6471069CurrentTrain: epoch  1, batch     3 | loss: 75.3958241CurrentTrain: epoch  1, batch     4 | loss: 108.9106115CurrentTrain: epoch  1, batch     5 | loss: 108.8955784CurrentTrain: epoch  1, batch     6 | loss: 134.0138458CurrentTrain: epoch  1, batch     7 | loss: 136.4291144CurrentTrain: epoch  1, batch     8 | loss: 142.5191069CurrentTrain: epoch  1, batch     9 | loss: 111.5813951CurrentTrain: epoch  1, batch    10 | loss: 92.1688076CurrentTrain: epoch  1, batch    11 | loss: 74.2230738CurrentTrain: epoch  1, batch    12 | loss: 112.2741721CurrentTrain: epoch  1, batch    13 | loss: 80.9868831CurrentTrain: epoch  1, batch    14 | loss: 90.7485119CurrentTrain: epoch  1, batch    15 | loss: 91.3258744CurrentTrain: epoch  1, batch    16 | loss: 107.2874828CurrentTrain: epoch  1, batch    17 | loss: 87.9379063CurrentTrain: epoch  1, batch    18 | loss: 88.1789094CurrentTrain: epoch  1, batch    19 | loss: 77.4248504CurrentTrain: epoch  1, batch    20 | loss: 77.4304974CurrentTrain: epoch  1, batch    21 | loss: 134.8860208CurrentTrain: epoch  1, batch    22 | loss: 74.0004171CurrentTrain: epoch  1, batch    23 | loss: 89.3078263CurrentTrain: epoch  1, batch    24 | loss: 73.3838566CurrentTrain: epoch  1, batch    25 | loss: 86.7051798CurrentTrain: epoch  1, batch    26 | loss: 87.7804017CurrentTrain: epoch  1, batch    27 | loss: 107.2274467CurrentTrain: epoch  1, batch    28 | loss: 137.2728226CurrentTrain: epoch  1, batch    29 | loss: 80.2328328CurrentTrain: epoch  1, batch    30 | loss: 89.1136899CurrentTrain: epoch  1, batch    31 | loss: 89.6971813CurrentTrain: epoch  1, batch    32 | loss: 77.1709179CurrentTrain: epoch  1, batch    33 | loss: 67.4512655CurrentTrain: epoch  1, batch    34 | loss: 135.8957770CurrentTrain: epoch  1, batch    35 | loss: 109.9953427CurrentTrain: epoch  1, batch    36 | loss: 76.5673091CurrentTrain: epoch  1, batch    37 | loss: 109.5877422CurrentTrain: epoch  1, batch    38 | loss: 142.1092499CurrentTrain: epoch  1, batch    39 | loss: 89.7477411CurrentTrain: epoch  1, batch    40 | loss: 86.1271657CurrentTrain: epoch  1, batch    41 | loss: 90.7041745CurrentTrain: epoch  1, batch    42 | loss: 109.4746742CurrentTrain: epoch  1, batch    43 | loss: 78.1472068CurrentTrain: epoch  1, batch    44 | loss: 106.0512076CurrentTrain: epoch  1, batch    45 | loss: 108.3173746CurrentTrain: epoch  1, batch    46 | loss: 184.4068376CurrentTrain: epoch  1, batch    47 | loss: 89.9463047CurrentTrain: epoch  1, batch    48 | loss: 92.3423710CurrentTrain: epoch  1, batch    49 | loss: 87.6556049CurrentTrain: epoch  1, batch    50 | loss: 106.8175298CurrentTrain: epoch  1, batch    51 | loss: 91.9462386CurrentTrain: epoch  1, batch    52 | loss: 136.3682435CurrentTrain: epoch  1, batch    53 | loss: 86.3330195CurrentTrain: epoch  1, batch    54 | loss: 86.6315352CurrentTrain: epoch  1, batch    55 | loss: 90.7100039CurrentTrain: epoch  1, batch    56 | loss: 76.0320172CurrentTrain: epoch  1, batch    57 | loss: 73.4857759CurrentTrain: epoch  1, batch    58 | loss: 109.6310222CurrentTrain: epoch  1, batch    59 | loss: 105.3836640CurrentTrain: epoch  1, batch    60 | loss: 72.6667493CurrentTrain: epoch  1, batch    61 | loss: 63.6973683CurrentTrain: epoch  1, batch    62 | loss: 110.4437207CurrentTrain: epoch  1, batch    63 | loss: 114.1470224CurrentTrain: epoch  1, batch    64 | loss: 76.7073109CurrentTrain: epoch  1, batch    65 | loss: 87.5628746CurrentTrain: epoch  1, batch    66 | loss: 105.6433251CurrentTrain: epoch  1, batch    67 | loss: 71.7471266CurrentTrain: epoch  1, batch    68 | loss: 89.7850455CurrentTrain: epoch  1, batch    69 | loss: 76.1027215CurrentTrain: epoch  1, batch    70 | loss: 110.4713771CurrentTrain: epoch  1, batch    71 | loss: 74.3350517CurrentTrain: epoch  1, batch    72 | loss: 106.2201358CurrentTrain: epoch  1, batch    73 | loss: 82.9898310CurrentTrain: epoch  1, batch    74 | loss: 86.9767518CurrentTrain: epoch  1, batch    75 | loss: 75.1093812CurrentTrain: epoch  1, batch    76 | loss: 86.5642609CurrentTrain: epoch  1, batch    77 | loss: 71.3533966CurrentTrain: epoch  1, batch    78 | loss: 89.5773669CurrentTrain: epoch  1, batch    79 | loss: 105.4895480CurrentTrain: epoch  1, batch    80 | loss: 87.0714636CurrentTrain: epoch  1, batch    81 | loss: 106.0175175CurrentTrain: epoch  1, batch    82 | loss: 78.5637081CurrentTrain: epoch  1, batch    83 | loss: 86.1949797CurrentTrain: epoch  1, batch    84 | loss: 75.8196513CurrentTrain: epoch  1, batch    85 | loss: 77.2026794CurrentTrain: epoch  1, batch    86 | loss: 89.3238413CurrentTrain: epoch  1, batch    87 | loss: 75.9353925CurrentTrain: epoch  1, batch    88 | loss: 102.1896343CurrentTrain: epoch  1, batch    89 | loss: 87.4152235CurrentTrain: epoch  1, batch    90 | loss: 77.4976232CurrentTrain: epoch  1, batch    91 | loss: 89.8189323CurrentTrain: epoch  1, batch    92 | loss: 88.4048485CurrentTrain: epoch  1, batch    93 | loss: 85.2071866CurrentTrain: epoch  1, batch    94 | loss: 88.9201845CurrentTrain: epoch  1, batch    95 | loss: 72.3316420CurrentTrain: epoch  2, batch     0 | loss: 65.4249945CurrentTrain: epoch  2, batch     1 | loss: 63.2623121CurrentTrain: epoch  2, batch     2 | loss: 83.1691617CurrentTrain: epoch  2, batch     3 | loss: 74.2239230CurrentTrain: epoch  2, batch     4 | loss: 61.5214204CurrentTrain: epoch  2, batch     5 | loss: 105.0210226CurrentTrain: epoch  2, batch     6 | loss: 76.0329760CurrentTrain: epoch  2, batch     7 | loss: 87.2680092CurrentTrain: epoch  2, batch     8 | loss: 135.7572474CurrentTrain: epoch  2, batch     9 | loss: 86.0039286CurrentTrain: epoch  2, batch    10 | loss: 82.4133635CurrentTrain: epoch  2, batch    11 | loss: 74.3289487CurrentTrain: epoch  2, batch    12 | loss: 63.9206590CurrentTrain: epoch  2, batch    13 | loss: 103.7990948CurrentTrain: epoch  2, batch    14 | loss: 84.4013291CurrentTrain: epoch  2, batch    15 | loss: 103.0065934CurrentTrain: epoch  2, batch    16 | loss: 62.4820167CurrentTrain: epoch  2, batch    17 | loss: 102.8536714CurrentTrain: epoch  2, batch    18 | loss: 131.0062392CurrentTrain: epoch  2, batch    19 | loss: 85.9817734CurrentTrain: epoch  2, batch    20 | loss: 87.9524647CurrentTrain: epoch  2, batch    21 | loss: 103.4125651CurrentTrain: epoch  2, batch    22 | loss: 92.7839892CurrentTrain: epoch  2, batch    23 | loss: 62.3140383CurrentTrain: epoch  2, batch    24 | loss: 62.3317138CurrentTrain: epoch  2, batch    25 | loss: 87.0130223CurrentTrain: epoch  2, batch    26 | loss: 69.1131871CurrentTrain: epoch  2, batch    27 | loss: 83.6618536CurrentTrain: epoch  2, batch    28 | loss: 76.5274300CurrentTrain: epoch  2, batch    29 | loss: 86.9158371CurrentTrain: epoch  2, batch    30 | loss: 85.7517744CurrentTrain: epoch  2, batch    31 | loss: 85.8141837CurrentTrain: epoch  2, batch    32 | loss: 109.6016525CurrentTrain: epoch  2, batch    33 | loss: 132.2027375CurrentTrain: epoch  2, batch    34 | loss: 87.2436852CurrentTrain: epoch  2, batch    35 | loss: 88.4298173CurrentTrain: epoch  2, batch    36 | loss: 128.4653487CurrentTrain: epoch  2, batch    37 | loss: 102.6251064CurrentTrain: epoch  2, batch    38 | loss: 85.6749474CurrentTrain: epoch  2, batch    39 | loss: 106.5964581CurrentTrain: epoch  2, batch    40 | loss: 86.1151773CurrentTrain: epoch  2, batch    41 | loss: 70.6811600CurrentTrain: epoch  2, batch    42 | loss: 64.7502192CurrentTrain: epoch  2, batch    43 | loss: 69.4772476CurrentTrain: epoch  2, batch    44 | loss: 130.8474941CurrentTrain: epoch  2, batch    45 | loss: 91.0215757CurrentTrain: epoch  2, batch    46 | loss: 87.1435037CurrentTrain: epoch  2, batch    47 | loss: 83.7389279CurrentTrain: epoch  2, batch    48 | loss: 129.9316982CurrentTrain: epoch  2, batch    49 | loss: 63.6992661CurrentTrain: epoch  2, batch    50 | loss: 107.9040099CurrentTrain: epoch  2, batch    51 | loss: 87.3057353CurrentTrain: epoch  2, batch    52 | loss: 105.4501183CurrentTrain: epoch  2, batch    53 | loss: 63.6486137CurrentTrain: epoch  2, batch    54 | loss: 107.1578903CurrentTrain: epoch  2, batch    55 | loss: 86.2366392CurrentTrain: epoch  2, batch    56 | loss: 104.7722761CurrentTrain: epoch  2, batch    57 | loss: 84.2124815CurrentTrain: epoch  2, batch    58 | loss: 84.2876510CurrentTrain: epoch  2, batch    59 | loss: 103.3253705CurrentTrain: epoch  2, batch    60 | loss: 100.9907265CurrentTrain: epoch  2, batch    61 | loss: 107.0002125CurrentTrain: epoch  2, batch    62 | loss: 74.0203249CurrentTrain: epoch  2, batch    63 | loss: 86.0292033CurrentTrain: epoch  2, batch    64 | loss: 61.6889563CurrentTrain: epoch  2, batch    65 | loss: 104.7592992CurrentTrain: epoch  2, batch    66 | loss: 70.1562558CurrentTrain: epoch  2, batch    67 | loss: 90.2080631CurrentTrain: epoch  2, batch    68 | loss: 72.6259968CurrentTrain: epoch  2, batch    69 | loss: 75.7785909CurrentTrain: epoch  2, batch    70 | loss: 135.3121575CurrentTrain: epoch  2, batch    71 | loss: 70.6244168CurrentTrain: epoch  2, batch    72 | loss: 82.9516837CurrentTrain: epoch  2, batch    73 | loss: 132.9452650CurrentTrain: epoch  2, batch    74 | loss: 84.4369803CurrentTrain: epoch  2, batch    75 | loss: 74.2565592CurrentTrain: epoch  2, batch    76 | loss: 105.2102935CurrentTrain: epoch  2, batch    77 | loss: 88.2869888CurrentTrain: epoch  2, batch    78 | loss: 103.9894484CurrentTrain: epoch  2, batch    79 | loss: 74.1052103CurrentTrain: epoch  2, batch    80 | loss: 133.4052754CurrentTrain: epoch  2, batch    81 | loss: 72.3281398CurrentTrain: epoch  2, batch    82 | loss: 91.6622662CurrentTrain: epoch  2, batch    83 | loss: 77.4751582CurrentTrain: epoch  2, batch    84 | loss: 70.3621600CurrentTrain: epoch  2, batch    85 | loss: 86.2979796CurrentTrain: epoch  2, batch    86 | loss: 137.0446988CurrentTrain: epoch  2, batch    87 | loss: 106.9995328CurrentTrain: epoch  2, batch    88 | loss: 85.4179613CurrentTrain: epoch  2, batch    89 | loss: 84.8214873CurrentTrain: epoch  2, batch    90 | loss: 73.3448949CurrentTrain: epoch  2, batch    91 | loss: 88.1479223CurrentTrain: epoch  2, batch    92 | loss: 105.5700331CurrentTrain: epoch  2, batch    93 | loss: 136.2668031CurrentTrain: epoch  2, batch    94 | loss: 75.2148185CurrentTrain: epoch  2, batch    95 | loss: 109.2133579CurrentTrain: epoch  3, batch     0 | loss: 137.1241201CurrentTrain: epoch  3, batch     1 | loss: 69.6200426CurrentTrain: epoch  3, batch     2 | loss: 62.5551656CurrentTrain: epoch  3, batch     3 | loss: 70.9304500CurrentTrain: epoch  3, batch     4 | loss: 104.4638509CurrentTrain: epoch  3, batch     5 | loss: 71.5438738CurrentTrain: epoch  3, batch     6 | loss: 70.7040638CurrentTrain: epoch  3, batch     7 | loss: 128.9566580CurrentTrain: epoch  3, batch     8 | loss: 81.6408837CurrentTrain: epoch  3, batch     9 | loss: 61.1903224CurrentTrain: epoch  3, batch    10 | loss: 87.8407457CurrentTrain: epoch  3, batch    11 | loss: 100.1089503CurrentTrain: epoch  3, batch    12 | loss: 71.7233055CurrentTrain: epoch  3, batch    13 | loss: 104.5116793CurrentTrain: epoch  3, batch    14 | loss: 73.3026261CurrentTrain: epoch  3, batch    15 | loss: 71.8046944CurrentTrain: epoch  3, batch    16 | loss: 88.3474493CurrentTrain: epoch  3, batch    17 | loss: 72.1982271CurrentTrain: epoch  3, batch    18 | loss: 84.3387703CurrentTrain: epoch  3, batch    19 | loss: 105.8063530CurrentTrain: epoch  3, batch    20 | loss: 84.4049205CurrentTrain: epoch  3, batch    21 | loss: 89.3770388CurrentTrain: epoch  3, batch    22 | loss: 79.8497744CurrentTrain: epoch  3, batch    23 | loss: 128.8371096CurrentTrain: epoch  3, batch    24 | loss: 68.3187898CurrentTrain: epoch  3, batch    25 | loss: 102.0007748CurrentTrain: epoch  3, batch    26 | loss: 102.4776204CurrentTrain: epoch  3, batch    27 | loss: 60.3362617CurrentTrain: epoch  3, batch    28 | loss: 83.4560806CurrentTrain: epoch  3, batch    29 | loss: 72.0790894CurrentTrain: epoch  3, batch    30 | loss: 130.9432843CurrentTrain: epoch  3, batch    31 | loss: 103.9740561CurrentTrain: epoch  3, batch    32 | loss: 136.9206169CurrentTrain: epoch  3, batch    33 | loss: 101.2414634CurrentTrain: epoch  3, batch    34 | loss: 104.3291219CurrentTrain: epoch  3, batch    35 | loss: 83.1284674CurrentTrain: epoch  3, batch    36 | loss: 100.1085733CurrentTrain: epoch  3, batch    37 | loss: 70.1621194CurrentTrain: epoch  3, batch    38 | loss: 73.4982388CurrentTrain: epoch  3, batch    39 | loss: 86.0374042CurrentTrain: epoch  3, batch    40 | loss: 57.6687230CurrentTrain: epoch  3, batch    41 | loss: 61.7561225CurrentTrain: epoch  3, batch    42 | loss: 133.9909700CurrentTrain: epoch  3, batch    43 | loss: 90.3612637CurrentTrain: epoch  3, batch    44 | loss: 100.3266036CurrentTrain: epoch  3, batch    45 | loss: 57.0078041CurrentTrain: epoch  3, batch    46 | loss: 128.4036950CurrentTrain: epoch  3, batch    47 | loss: 100.0784428CurrentTrain: epoch  3, batch    48 | loss: 82.2380734CurrentTrain: epoch  3, batch    49 | loss: 82.1575755CurrentTrain: epoch  3, batch    50 | loss: 100.0605439CurrentTrain: epoch  3, batch    51 | loss: 69.2298251CurrentTrain: epoch  3, batch    52 | loss: 104.6147207CurrentTrain: epoch  3, batch    53 | loss: 71.5349362CurrentTrain: epoch  3, batch    54 | loss: 72.5850314CurrentTrain: epoch  3, batch    55 | loss: 102.8087124CurrentTrain: epoch  3, batch    56 | loss: 101.8014494CurrentTrain: epoch  3, batch    57 | loss: 84.5893732CurrentTrain: epoch  3, batch    58 | loss: 71.0321953CurrentTrain: epoch  3, batch    59 | loss: 102.6844941CurrentTrain: epoch  3, batch    60 | loss: 85.6299321CurrentTrain: epoch  3, batch    61 | loss: 85.7910995CurrentTrain: epoch  3, batch    62 | loss: 81.4415474CurrentTrain: epoch  3, batch    63 | loss: 83.1950947CurrentTrain: epoch  3, batch    64 | loss: 82.0264036CurrentTrain: epoch  3, batch    65 | loss: 63.5627625CurrentTrain: epoch  3, batch    66 | loss: 86.9155154CurrentTrain: epoch  3, batch    67 | loss: 70.2157818CurrentTrain: epoch  3, batch    68 | loss: 102.0573851CurrentTrain: epoch  3, batch    69 | loss: 61.5751851CurrentTrain: epoch  3, batch    70 | loss: 86.9693605CurrentTrain: epoch  3, batch    71 | loss: 94.9226355CurrentTrain: epoch  3, batch    72 | loss: 72.2014240CurrentTrain: epoch  3, batch    73 | loss: 86.1832944CurrentTrain: epoch  3, batch    74 | loss: 70.5640435CurrentTrain: epoch  3, batch    75 | loss: 80.2114473CurrentTrain: epoch  3, batch    76 | loss: 86.2424852CurrentTrain: epoch  3, batch    77 | loss: 89.7606026CurrentTrain: epoch  3, batch    78 | loss: 104.4332187CurrentTrain: epoch  3, batch    79 | loss: 100.9525207CurrentTrain: epoch  3, batch    80 | loss: 82.7317250CurrentTrain: epoch  3, batch    81 | loss: 100.6569798CurrentTrain: epoch  3, batch    82 | loss: 74.4549700CurrentTrain: epoch  3, batch    83 | loss: 132.4039326CurrentTrain: epoch  3, batch    84 | loss: 81.2572451CurrentTrain: epoch  3, batch    85 | loss: 86.4125833CurrentTrain: epoch  3, batch    86 | loss: 82.5317941CurrentTrain: epoch  3, batch    87 | loss: 106.9197579CurrentTrain: epoch  3, batch    88 | loss: 171.6893337CurrentTrain: epoch  3, batch    89 | loss: 89.1076757CurrentTrain: epoch  3, batch    90 | loss: 88.1825160CurrentTrain: epoch  3, batch    91 | loss: 103.9295565CurrentTrain: epoch  3, batch    92 | loss: 102.7521261CurrentTrain: epoch  3, batch    93 | loss: 97.7936316CurrentTrain: epoch  3, batch    94 | loss: 84.7511906CurrentTrain: epoch  3, batch    95 | loss: 73.6111385CurrentTrain: epoch  4, batch     0 | loss: 78.8206594CurrentTrain: epoch  4, batch     1 | loss: 97.2978339CurrentTrain: epoch  4, batch     2 | loss: 81.2687850CurrentTrain: epoch  4, batch     3 | loss: 69.6604254CurrentTrain: epoch  4, batch     4 | loss: 132.4099357CurrentTrain: epoch  4, batch     5 | loss: 127.6809879CurrentTrain: epoch  4, batch     6 | loss: 81.8457269CurrentTrain: epoch  4, batch     7 | loss: 82.9849932CurrentTrain: epoch  4, batch     8 | loss: 68.7550521CurrentTrain: epoch  4, batch     9 | loss: 103.1278374CurrentTrain: epoch  4, batch    10 | loss: 99.7806529CurrentTrain: epoch  4, batch    11 | loss: 100.5640305CurrentTrain: epoch  4, batch    12 | loss: 71.6865105CurrentTrain: epoch  4, batch    13 | loss: 76.0864264CurrentTrain: epoch  4, batch    14 | loss: 84.7755345CurrentTrain: epoch  4, batch    15 | loss: 58.2277919CurrentTrain: epoch  4, batch    16 | loss: 132.0585436CurrentTrain: epoch  4, batch    17 | loss: 70.9003399CurrentTrain: epoch  4, batch    18 | loss: 126.3836747CurrentTrain: epoch  4, batch    19 | loss: 99.0232924CurrentTrain: epoch  4, batch    20 | loss: 86.1814969CurrentTrain: epoch  4, batch    21 | loss: 82.3281385CurrentTrain: epoch  4, batch    22 | loss: 84.1326273CurrentTrain: epoch  4, batch    23 | loss: 77.8735373CurrentTrain: epoch  4, batch    24 | loss: 84.4237982CurrentTrain: epoch  4, batch    25 | loss: 85.1485066CurrentTrain: epoch  4, batch    26 | loss: 69.8334292CurrentTrain: epoch  4, batch    27 | loss: 81.9032772CurrentTrain: epoch  4, batch    28 | loss: 74.7014124CurrentTrain: epoch  4, batch    29 | loss: 85.3433016CurrentTrain: epoch  4, batch    30 | loss: 103.6653133CurrentTrain: epoch  4, batch    31 | loss: 68.3856128CurrentTrain: epoch  4, batch    32 | loss: 82.3191415CurrentTrain: epoch  4, batch    33 | loss: 82.3555225CurrentTrain: epoch  4, batch    34 | loss: 101.6399862CurrentTrain: epoch  4, batch    35 | loss: 66.0632658CurrentTrain: epoch  4, batch    36 | loss: 82.6939883CurrentTrain: epoch  4, batch    37 | loss: 96.8707732CurrentTrain: epoch  4, batch    38 | loss: 68.6514803CurrentTrain: epoch  4, batch    39 | loss: 70.4747224CurrentTrain: epoch  4, batch    40 | loss: 85.6865260CurrentTrain: epoch  4, batch    41 | loss: 80.8350338CurrentTrain: epoch  4, batch    42 | loss: 79.1018697CurrentTrain: epoch  4, batch    43 | loss: 82.6222630CurrentTrain: epoch  4, batch    44 | loss: 99.8826671CurrentTrain: epoch  4, batch    45 | loss: 72.0506339CurrentTrain: epoch  4, batch    46 | loss: 64.4928787CurrentTrain: epoch  4, batch    47 | loss: 79.5332319CurrentTrain: epoch  4, batch    48 | loss: 57.5757141CurrentTrain: epoch  4, batch    49 | loss: 82.2055894CurrentTrain: epoch  4, batch    50 | loss: 68.6149024CurrentTrain: epoch  4, batch    51 | loss: 84.8432963CurrentTrain: epoch  4, batch    52 | loss: 84.0976351CurrentTrain: epoch  4, batch    53 | loss: 85.0138167CurrentTrain: epoch  4, batch    54 | loss: 102.1537763CurrentTrain: epoch  4, batch    55 | loss: 100.3977478CurrentTrain: epoch  4, batch    56 | loss: 125.0157590CurrentTrain: epoch  4, batch    57 | loss: 68.0824556CurrentTrain: epoch  4, batch    58 | loss: 80.5125848CurrentTrain: epoch  4, batch    59 | loss: 71.1290201CurrentTrain: epoch  4, batch    60 | loss: 61.5730614CurrentTrain: epoch  4, batch    61 | loss: 87.2975331CurrentTrain: epoch  4, batch    62 | loss: 82.4915827CurrentTrain: epoch  4, batch    63 | loss: 70.5208850CurrentTrain: epoch  4, batch    64 | loss: 88.0376365CurrentTrain: epoch  4, batch    65 | loss: 82.1134601CurrentTrain: epoch  4, batch    66 | loss: 101.0160239CurrentTrain: epoch  4, batch    67 | loss: 70.6065978CurrentTrain: epoch  4, batch    68 | loss: 80.6426466CurrentTrain: epoch  4, batch    69 | loss: 106.3254196CurrentTrain: epoch  4, batch    70 | loss: 81.0899847CurrentTrain: epoch  4, batch    71 | loss: 135.2187050CurrentTrain: epoch  4, batch    72 | loss: 129.4771910CurrentTrain: epoch  4, batch    73 | loss: 100.0478475CurrentTrain: epoch  4, batch    74 | loss: 84.6138001CurrentTrain: epoch  4, batch    75 | loss: 84.8793809CurrentTrain: epoch  4, batch    76 | loss: 97.1540853CurrentTrain: epoch  4, batch    77 | loss: 97.3780692CurrentTrain: epoch  4, batch    78 | loss: 133.2509482CurrentTrain: epoch  4, batch    79 | loss: 126.5992452CurrentTrain: epoch  4, batch    80 | loss: 84.2086114CurrentTrain: epoch  4, batch    81 | loss: 79.3324724CurrentTrain: epoch  4, batch    82 | loss: 64.5395332CurrentTrain: epoch  4, batch    83 | loss: 102.1830002CurrentTrain: epoch  4, batch    84 | loss: 89.6807331CurrentTrain: epoch  4, batch    85 | loss: 102.6102646CurrentTrain: epoch  4, batch    86 | loss: 102.0438266CurrentTrain: epoch  4, batch    87 | loss: 71.6083895CurrentTrain: epoch  4, batch    88 | loss: 96.3184896CurrentTrain: epoch  4, batch    89 | loss: 102.8278579CurrentTrain: epoch  4, batch    90 | loss: 123.6069915CurrentTrain: epoch  4, batch    91 | loss: 83.1528472CurrentTrain: epoch  4, batch    92 | loss: 120.8677353CurrentTrain: epoch  4, batch    93 | loss: 102.4968736CurrentTrain: epoch  4, batch    94 | loss: 59.0630082CurrentTrain: epoch  4, batch    95 | loss: 70.1762884CurrentTrain: epoch  5, batch     0 | loss: 60.2182683CurrentTrain: epoch  5, batch     1 | loss: 100.3982958CurrentTrain: epoch  5, batch     2 | loss: 83.8844102CurrentTrain: epoch  5, batch     3 | loss: 99.1133562CurrentTrain: epoch  5, batch     4 | loss: 101.6584196CurrentTrain: epoch  5, batch     5 | loss: 81.8607367CurrentTrain: epoch  5, batch     6 | loss: 125.0687776CurrentTrain: epoch  5, batch     7 | loss: 80.9656474CurrentTrain: epoch  5, batch     8 | loss: 69.1370607CurrentTrain: epoch  5, batch     9 | loss: 56.3140169CurrentTrain: epoch  5, batch    10 | loss: 82.6263655CurrentTrain: epoch  5, batch    11 | loss: 124.1662777CurrentTrain: epoch  5, batch    12 | loss: 68.4460505CurrentTrain: epoch  5, batch    13 | loss: 103.4067234CurrentTrain: epoch  5, batch    14 | loss: 71.4431177CurrentTrain: epoch  5, batch    15 | loss: 98.8981935CurrentTrain: epoch  5, batch    16 | loss: 81.5430507CurrentTrain: epoch  5, batch    17 | loss: 71.7830182CurrentTrain: epoch  5, batch    18 | loss: 81.7242181CurrentTrain: epoch  5, batch    19 | loss: 83.2225020CurrentTrain: epoch  5, batch    20 | loss: 98.0383361CurrentTrain: epoch  5, batch    21 | loss: 70.2858935CurrentTrain: epoch  5, batch    22 | loss: 81.6128961CurrentTrain: epoch  5, batch    23 | loss: 99.4182821CurrentTrain: epoch  5, batch    24 | loss: 77.8828318CurrentTrain: epoch  5, batch    25 | loss: 64.2922318CurrentTrain: epoch  5, batch    26 | loss: 71.1146633CurrentTrain: epoch  5, batch    27 | loss: 102.4975961CurrentTrain: epoch  5, batch    28 | loss: 104.1221893CurrentTrain: epoch  5, batch    29 | loss: 81.0457842CurrentTrain: epoch  5, batch    30 | loss: 100.7102115CurrentTrain: epoch  5, batch    31 | loss: 70.0438369CurrentTrain: epoch  5, batch    32 | loss: 80.5320997CurrentTrain: epoch  5, batch    33 | loss: 69.2517806CurrentTrain: epoch  5, batch    34 | loss: 83.4319850CurrentTrain: epoch  5, batch    35 | loss: 79.5301980CurrentTrain: epoch  5, batch    36 | loss: 69.7675328CurrentTrain: epoch  5, batch    37 | loss: 101.9487111CurrentTrain: epoch  5, batch    38 | loss: 86.1245869CurrentTrain: epoch  5, batch    39 | loss: 95.6470678CurrentTrain: epoch  5, batch    40 | loss: 68.5695248CurrentTrain: epoch  5, batch    41 | loss: 102.6715129CurrentTrain: epoch  5, batch    42 | loss: 81.3945498CurrentTrain: epoch  5, batch    43 | loss: 76.9538125CurrentTrain: epoch  5, batch    44 | loss: 65.7048887CurrentTrain: epoch  5, batch    45 | loss: 64.2494097CurrentTrain: epoch  5, batch    46 | loss: 101.0711401CurrentTrain: epoch  5, batch    47 | loss: 129.7953322CurrentTrain: epoch  5, batch    48 | loss: 66.0075150CurrentTrain: epoch  5, batch    49 | loss: 69.4548701CurrentTrain: epoch  5, batch    50 | loss: 60.1627181CurrentTrain: epoch  5, batch    51 | loss: 99.3114494CurrentTrain: epoch  5, batch    52 | loss: 124.3517168CurrentTrain: epoch  5, batch    53 | loss: 69.1343709CurrentTrain: epoch  5, batch    54 | loss: 102.7382106CurrentTrain: epoch  5, batch    55 | loss: 95.7950807CurrentTrain: epoch  5, batch    56 | loss: 66.9524530CurrentTrain: epoch  5, batch    57 | loss: 100.2591325CurrentTrain: epoch  5, batch    58 | loss: 66.6620806CurrentTrain: epoch  5, batch    59 | loss: 71.9186577CurrentTrain: epoch  5, batch    60 | loss: 97.2159105CurrentTrain: epoch  5, batch    61 | loss: 61.7706147CurrentTrain: epoch  5, batch    62 | loss: 71.3642868CurrentTrain: epoch  5, batch    63 | loss: 82.8103194CurrentTrain: epoch  5, batch    64 | loss: 123.8505605CurrentTrain: epoch  5, batch    65 | loss: 66.4925842CurrentTrain: epoch  5, batch    66 | loss: 130.6761595CurrentTrain: epoch  5, batch    67 | loss: 69.2281248CurrentTrain: epoch  5, batch    68 | loss: 96.6847264CurrentTrain: epoch  5, batch    69 | loss: 78.0302250CurrentTrain: epoch  5, batch    70 | loss: 124.7085872CurrentTrain: epoch  5, batch    71 | loss: 94.5274016CurrentTrain: epoch  5, batch    72 | loss: 122.7743470CurrentTrain: epoch  5, batch    73 | loss: 73.0313156CurrentTrain: epoch  5, batch    74 | loss: 81.2574316CurrentTrain: epoch  5, batch    75 | loss: 71.4562600CurrentTrain: epoch  5, batch    76 | loss: 80.0740970CurrentTrain: epoch  5, batch    77 | loss: 66.2747857CurrentTrain: epoch  5, batch    78 | loss: 70.8407904CurrentTrain: epoch  5, batch    79 | loss: 68.5622894CurrentTrain: epoch  5, batch    80 | loss: 103.2918619CurrentTrain: epoch  5, batch    81 | loss: 84.0163714CurrentTrain: epoch  5, batch    82 | loss: 95.8337244CurrentTrain: epoch  5, batch    83 | loss: 81.3325218CurrentTrain: epoch  5, batch    84 | loss: 98.5810458CurrentTrain: epoch  5, batch    85 | loss: 123.2375275CurrentTrain: epoch  5, batch    86 | loss: 92.2776448CurrentTrain: epoch  5, batch    87 | loss: 83.5972763CurrentTrain: epoch  5, batch    88 | loss: 80.3807576CurrentTrain: epoch  5, batch    89 | loss: 82.3139687CurrentTrain: epoch  5, batch    90 | loss: 126.0263792CurrentTrain: epoch  5, batch    91 | loss: 96.0275247CurrentTrain: epoch  5, batch    92 | loss: 79.9348818CurrentTrain: epoch  5, batch    93 | loss: 97.7298100CurrentTrain: epoch  5, batch    94 | loss: 82.8324860CurrentTrain: epoch  5, batch    95 | loss: 85.3275075CurrentTrain: epoch  6, batch     0 | loss: 66.6495676CurrentTrain: epoch  6, batch     1 | loss: 68.7137057CurrentTrain: epoch  6, batch     2 | loss: 78.0068144CurrentTrain: epoch  6, batch     3 | loss: 69.5768328CurrentTrain: epoch  6, batch     4 | loss: 91.4158118CurrentTrain: epoch  6, batch     5 | loss: 65.3783281CurrentTrain: epoch  6, batch     6 | loss: 80.3563163CurrentTrain: epoch  6, batch     7 | loss: 80.0654511CurrentTrain: epoch  6, batch     8 | loss: 69.8654608CurrentTrain: epoch  6, batch     9 | loss: 99.9575703CurrentTrain: epoch  6, batch    10 | loss: 53.2797135CurrentTrain: epoch  6, batch    11 | loss: 127.8849375CurrentTrain: epoch  6, batch    12 | loss: 100.6728527CurrentTrain: epoch  6, batch    13 | loss: 67.3935462CurrentTrain: epoch  6, batch    14 | loss: 96.2297864CurrentTrain: epoch  6, batch    15 | loss: 65.1828553CurrentTrain: epoch  6, batch    16 | loss: 81.7629669CurrentTrain: epoch  6, batch    17 | loss: 104.3886704CurrentTrain: epoch  6, batch    18 | loss: 82.6571066CurrentTrain: epoch  6, batch    19 | loss: 81.0179333CurrentTrain: epoch  6, batch    20 | loss: 77.3451198CurrentTrain: epoch  6, batch    21 | loss: 82.2381927CurrentTrain: epoch  6, batch    22 | loss: 76.1579500CurrentTrain: epoch  6, batch    23 | loss: 77.9172577CurrentTrain: epoch  6, batch    24 | loss: 97.5988143CurrentTrain: epoch  6, batch    25 | loss: 80.6244530CurrentTrain: epoch  6, batch    26 | loss: 79.7449786CurrentTrain: epoch  6, batch    27 | loss: 129.0644975CurrentTrain: epoch  6, batch    28 | loss: 64.3001010CurrentTrain: epoch  6, batch    29 | loss: 81.8989976CurrentTrain: epoch  6, batch    30 | loss: 74.5088567CurrentTrain: epoch  6, batch    31 | loss: 66.3831933CurrentTrain: epoch  6, batch    32 | loss: 125.5796578CurrentTrain: epoch  6, batch    33 | loss: 79.9346930CurrentTrain: epoch  6, batch    34 | loss: 82.6014462CurrentTrain: epoch  6, batch    35 | loss: 98.9199657CurrentTrain: epoch  6, batch    36 | loss: 68.8187818CurrentTrain: epoch  6, batch    37 | loss: 90.1988613CurrentTrain: epoch  6, batch    38 | loss: 55.9616479CurrentTrain: epoch  6, batch    39 | loss: 103.3088724CurrentTrain: epoch  6, batch    40 | loss: 67.3440336CurrentTrain: epoch  6, batch    41 | loss: 61.3444351CurrentTrain: epoch  6, batch    42 | loss: 81.8649090CurrentTrain: epoch  6, batch    43 | loss: 58.2242334CurrentTrain: epoch  6, batch    44 | loss: 66.7882313CurrentTrain: epoch  6, batch    45 | loss: 99.1939007CurrentTrain: epoch  6, batch    46 | loss: 66.2067852CurrentTrain: epoch  6, batch    47 | loss: 101.0337966CurrentTrain: epoch  6, batch    48 | loss: 100.6232824CurrentTrain: epoch  6, batch    49 | loss: 99.6609962CurrentTrain: epoch  6, batch    50 | loss: 70.1629011CurrentTrain: epoch  6, batch    51 | loss: 69.0908021CurrentTrain: epoch  6, batch    52 | loss: 67.5596226CurrentTrain: epoch  6, batch    53 | loss: 127.8037310CurrentTrain: epoch  6, batch    54 | loss: 68.1448103CurrentTrain: epoch  6, batch    55 | loss: 95.6729544CurrentTrain: epoch  6, batch    56 | loss: 81.7327172CurrentTrain: epoch  6, batch    57 | loss: 82.6212390CurrentTrain: epoch  6, batch    58 | loss: 86.8230277CurrentTrain: epoch  6, batch    59 | loss: 78.8269193CurrentTrain: epoch  6, batch    60 | loss: 82.0488525CurrentTrain: epoch  6, batch    61 | loss: 68.6186792CurrentTrain: epoch  6, batch    62 | loss: 78.9954840CurrentTrain: epoch  6, batch    63 | loss: 82.6897351CurrentTrain: epoch  6, batch    64 | loss: 95.8045224CurrentTrain: epoch  6, batch    65 | loss: 64.7767959CurrentTrain: epoch  6, batch    66 | loss: 102.2759386CurrentTrain: epoch  6, batch    67 | loss: 98.1361326CurrentTrain: epoch  6, batch    68 | loss: 95.1421107CurrentTrain: epoch  6, batch    69 | loss: 94.0927736CurrentTrain: epoch  6, batch    70 | loss: 77.0621845CurrentTrain: epoch  6, batch    71 | loss: 66.1717572CurrentTrain: epoch  6, batch    72 | loss: 125.5473077CurrentTrain: epoch  6, batch    73 | loss: 95.9500734CurrentTrain: epoch  6, batch    74 | loss: 83.0763419CurrentTrain: epoch  6, batch    75 | loss: 98.6560747CurrentTrain: epoch  6, batch    76 | loss: 124.0122145CurrentTrain: epoch  6, batch    77 | loss: 84.3258216CurrentTrain: epoch  6, batch    78 | loss: 81.1876575CurrentTrain: epoch  6, batch    79 | loss: 80.6311077CurrentTrain: epoch  6, batch    80 | loss: 65.9085300CurrentTrain: epoch  6, batch    81 | loss: 103.2636397CurrentTrain: epoch  6, batch    82 | loss: 67.2211872CurrentTrain: epoch  6, batch    83 | loss: 97.0398064CurrentTrain: epoch  6, batch    84 | loss: 96.5498135CurrentTrain: epoch  6, batch    85 | loss: 76.2558092CurrentTrain: epoch  6, batch    86 | loss: 79.1137047CurrentTrain: epoch  6, batch    87 | loss: 103.2004537CurrentTrain: epoch  6, batch    88 | loss: 79.6090839CurrentTrain: epoch  6, batch    89 | loss: 61.1696710CurrentTrain: epoch  6, batch    90 | loss: 123.0047557CurrentTrain: epoch  6, batch    91 | loss: 101.3018588CurrentTrain: epoch  6, batch    92 | loss: 82.9580410CurrentTrain: epoch  6, batch    93 | loss: 76.1790058CurrentTrain: epoch  6, batch    94 | loss: 80.1827152CurrentTrain: epoch  6, batch    95 | loss: 67.6550978CurrentTrain: epoch  7, batch     0 | loss: 66.3585781CurrentTrain: epoch  7, batch     1 | loss: 76.4455015CurrentTrain: epoch  7, batch     2 | loss: 64.7044215CurrentTrain: epoch  7, batch     3 | loss: 80.3239965CurrentTrain: epoch  7, batch     4 | loss: 79.5657897CurrentTrain: epoch  7, batch     5 | loss: 98.2489205CurrentTrain: epoch  7, batch     6 | loss: 121.7686131CurrentTrain: epoch  7, batch     7 | loss: 76.6075349CurrentTrain: epoch  7, batch     8 | loss: 63.6944131CurrentTrain: epoch  7, batch     9 | loss: 66.8234776CurrentTrain: epoch  7, batch    10 | loss: 57.9766020CurrentTrain: epoch  7, batch    11 | loss: 78.7983067CurrentTrain: epoch  7, batch    12 | loss: 98.3170354CurrentTrain: epoch  7, batch    13 | loss: 56.2488759CurrentTrain: epoch  7, batch    14 | loss: 65.8016955CurrentTrain: epoch  7, batch    15 | loss: 76.6422718CurrentTrain: epoch  7, batch    16 | loss: 76.5920120CurrentTrain: epoch  7, batch    17 | loss: 67.4073913CurrentTrain: epoch  7, batch    18 | loss: 125.6415562CurrentTrain: epoch  7, batch    19 | loss: 92.9672844CurrentTrain: epoch  7, batch    20 | loss: 69.7592267CurrentTrain: epoch  7, batch    21 | loss: 69.0603495CurrentTrain: epoch  7, batch    22 | loss: 77.4989352CurrentTrain: epoch  7, batch    23 | loss: 99.1135280CurrentTrain: epoch  7, batch    24 | loss: 78.7490132CurrentTrain: epoch  7, batch    25 | loss: 79.7232507CurrentTrain: epoch  7, batch    26 | loss: 98.8737991CurrentTrain: epoch  7, batch    27 | loss: 120.6115058CurrentTrain: epoch  7, batch    28 | loss: 81.2858650CurrentTrain: epoch  7, batch    29 | loss: 92.3015525CurrentTrain: epoch  7, batch    30 | loss: 54.9219146CurrentTrain: epoch  7, batch    31 | loss: 82.6364721CurrentTrain: epoch  7, batch    32 | loss: 99.2089681CurrentTrain: epoch  7, batch    33 | loss: 78.6538978CurrentTrain: epoch  7, batch    34 | loss: 76.5102417CurrentTrain: epoch  7, batch    35 | loss: 123.4807492CurrentTrain: epoch  7, batch    36 | loss: 77.8314391CurrentTrain: epoch  7, batch    37 | loss: 79.3016369CurrentTrain: epoch  7, batch    38 | loss: 94.2382714CurrentTrain: epoch  7, batch    39 | loss: 68.8575340CurrentTrain: epoch  7, batch    40 | loss: 81.7220793CurrentTrain: epoch  7, batch    41 | loss: 117.5793636CurrentTrain: epoch  7, batch    42 | loss: 68.2481052CurrentTrain: epoch  7, batch    43 | loss: 95.9229084CurrentTrain: epoch  7, batch    44 | loss: 95.5926678CurrentTrain: epoch  7, batch    45 | loss: 78.2442890CurrentTrain: epoch  7, batch    46 | loss: 98.1112363CurrentTrain: epoch  7, batch    47 | loss: 100.6712673CurrentTrain: epoch  7, batch    48 | loss: 95.1216433CurrentTrain: epoch  7, batch    49 | loss: 71.5664981CurrentTrain: epoch  7, batch    50 | loss: 57.7046419CurrentTrain: epoch  7, batch    51 | loss: 95.8418221CurrentTrain: epoch  7, batch    52 | loss: 77.7325082CurrentTrain: epoch  7, batch    53 | loss: 82.9596410CurrentTrain: epoch  7, batch    54 | loss: 63.5141554CurrentTrain: epoch  7, batch    55 | loss: 76.8450009CurrentTrain: epoch  7, batch    56 | loss: 77.1658193CurrentTrain: epoch  7, batch    57 | loss: 95.6372952CurrentTrain: epoch  7, batch    58 | loss: 96.0379682CurrentTrain: epoch  7, batch    59 | loss: 74.7437726CurrentTrain: epoch  7, batch    60 | loss: 76.0757201CurrentTrain: epoch  7, batch    61 | loss: 81.4419707CurrentTrain: epoch  7, batch    62 | loss: 78.7134602CurrentTrain: epoch  7, batch    63 | loss: 98.3633963CurrentTrain: epoch  7, batch    64 | loss: 67.8948003CurrentTrain: epoch  7, batch    65 | loss: 77.7214558CurrentTrain: epoch  7, batch    66 | loss: 97.6407662CurrentTrain: epoch  7, batch    67 | loss: 98.0507081CurrentTrain: epoch  7, batch    68 | loss: 77.9416535CurrentTrain: epoch  7, batch    69 | loss: 66.1690205CurrentTrain: epoch  7, batch    70 | loss: 64.7926612CurrentTrain: epoch  7, batch    71 | loss: 58.7815766CurrentTrain: epoch  7, batch    72 | loss: 99.0305845CurrentTrain: epoch  7, batch    73 | loss: 77.7912101CurrentTrain: epoch  7, batch    74 | loss: 82.7654784CurrentTrain: epoch  7, batch    75 | loss: 76.8743722CurrentTrain: epoch  7, batch    76 | loss: 128.3399471CurrentTrain: epoch  7, batch    77 | loss: 66.9149520CurrentTrain: epoch  7, batch    78 | loss: 121.6788996CurrentTrain: epoch  7, batch    79 | loss: 82.2725250CurrentTrain: epoch  7, batch    80 | loss: 129.7573225CurrentTrain: epoch  7, batch    81 | loss: 56.7056427CurrentTrain: epoch  7, batch    82 | loss: 67.2193221CurrentTrain: epoch  7, batch    83 | loss: 55.2914997CurrentTrain: epoch  7, batch    84 | loss: 67.1901089CurrentTrain: epoch  7, batch    85 | loss: 124.5790062CurrentTrain: epoch  7, batch    86 | loss: 59.5200413CurrentTrain: epoch  7, batch    87 | loss: 128.3195172CurrentTrain: epoch  7, batch    88 | loss: 80.3017636CurrentTrain: epoch  7, batch    89 | loss: 78.5723474CurrentTrain: epoch  7, batch    90 | loss: 128.1679844CurrentTrain: epoch  7, batch    91 | loss: 79.2941250CurrentTrain: epoch  7, batch    92 | loss: 54.5068352CurrentTrain: epoch  7, batch    93 | loss: 90.3086784CurrentTrain: epoch  7, batch    94 | loss: 77.8816991CurrentTrain: epoch  7, batch    95 | loss: 144.4635196CurrentTrain: epoch  8, batch     0 | loss: 76.0914076CurrentTrain: epoch  8, batch     1 | loss: 66.5703094CurrentTrain: epoch  8, batch     2 | loss: 59.3763345CurrentTrain: epoch  8, batch     3 | loss: 78.0473761CurrentTrain: epoch  8, batch     4 | loss: 65.5961793CurrentTrain: epoch  8, batch     5 | loss: 77.9456876CurrentTrain: epoch  8, batch     6 | loss: 61.8858402CurrentTrain: epoch  8, batch     7 | loss: 81.5279037CurrentTrain: epoch  8, batch     8 | loss: 78.3126555CurrentTrain: epoch  8, batch     9 | loss: 57.5548888CurrentTrain: epoch  8, batch    10 | loss: 79.1165387CurrentTrain: epoch  8, batch    11 | loss: 61.9201552CurrentTrain: epoch  8, batch    12 | loss: 80.2877504CurrentTrain: epoch  8, batch    13 | loss: 94.6205284CurrentTrain: epoch  8, batch    14 | loss: 98.6227689CurrentTrain: epoch  8, batch    15 | loss: 64.7745731CurrentTrain: epoch  8, batch    16 | loss: 122.7032483CurrentTrain: epoch  8, batch    17 | loss: 80.4272475CurrentTrain: epoch  8, batch    18 | loss: 81.6651373CurrentTrain: epoch  8, batch    19 | loss: 114.0447975CurrentTrain: epoch  8, batch    20 | loss: 77.0121751CurrentTrain: epoch  8, batch    21 | loss: 81.6214899CurrentTrain: epoch  8, batch    22 | loss: 76.8235100CurrentTrain: epoch  8, batch    23 | loss: 95.3744725CurrentTrain: epoch  8, batch    24 | loss: 78.4813698CurrentTrain: epoch  8, batch    25 | loss: 78.9633963CurrentTrain: epoch  8, batch    26 | loss: 97.3190799CurrentTrain: epoch  8, batch    27 | loss: 79.1966451CurrentTrain: epoch  8, batch    28 | loss: 98.3541659CurrentTrain: epoch  8, batch    29 | loss: 78.1825698CurrentTrain: epoch  8, batch    30 | loss: 78.2648680CurrentTrain: epoch  8, batch    31 | loss: 58.0249399CurrentTrain: epoch  8, batch    32 | loss: 62.7299039CurrentTrain: epoch  8, batch    33 | loss: 119.3609645CurrentTrain: epoch  8, batch    34 | loss: 122.7749764CurrentTrain: epoch  8, batch    35 | loss: 94.4828995CurrentTrain: epoch  8, batch    36 | loss: 91.5016392CurrentTrain: epoch  8, batch    37 | loss: 80.5722586CurrentTrain: epoch  8, batch    38 | loss: 79.8080052CurrentTrain: epoch  8, batch    39 | loss: 81.7763619CurrentTrain: epoch  8, batch    40 | loss: 79.1001441CurrentTrain: epoch  8, batch    41 | loss: 79.0330265CurrentTrain: epoch  8, batch    42 | loss: 65.8925501CurrentTrain: epoch  8, batch    43 | loss: 125.7882598CurrentTrain: epoch  8, batch    44 | loss: 124.6919183CurrentTrain: epoch  8, batch    45 | loss: 61.2029145CurrentTrain: epoch  8, batch    46 | loss: 58.3668656CurrentTrain: epoch  8, batch    47 | loss: 79.1227442CurrentTrain: epoch  8, batch    48 | loss: 82.4778827CurrentTrain: epoch  8, batch    49 | loss: 69.3906541CurrentTrain: epoch  8, batch    50 | loss: 53.8743063CurrentTrain: epoch  8, batch    51 | loss: 93.0059540CurrentTrain: epoch  8, batch    52 | loss: 121.4188206CurrentTrain: epoch  8, batch    53 | loss: 76.9294765CurrentTrain: epoch  8, batch    54 | loss: 70.1835769CurrentTrain: epoch  8, batch    55 | loss: 64.9067311CurrentTrain: epoch  8, batch    56 | loss: 64.5317135CurrentTrain: epoch  8, batch    57 | loss: 77.6254649CurrentTrain: epoch  8, batch    58 | loss: 61.3241314CurrentTrain: epoch  8, batch    59 | loss: 84.3830779CurrentTrain: epoch  8, batch    60 | loss: 98.4355328CurrentTrain: epoch  8, batch    61 | loss: 66.4730785CurrentTrain: epoch  8, batch    62 | loss: 123.4083884CurrentTrain: epoch  8, batch    63 | loss: 68.9557406CurrentTrain: epoch  8, batch    64 | loss: 97.7799778CurrentTrain: epoch  8, batch    65 | loss: 56.1711853CurrentTrain: epoch  8, batch    66 | loss: 94.8643719CurrentTrain: epoch  8, batch    67 | loss: 96.7197957CurrentTrain: epoch  8, batch    68 | loss: 95.0401459CurrentTrain: epoch  8, batch    69 | loss: 95.3096619CurrentTrain: epoch  8, batch    70 | loss: 62.0009570CurrentTrain: epoch  8, batch    71 | loss: 52.3732733CurrentTrain: epoch  8, batch    72 | loss: 91.9100650CurrentTrain: epoch  8, batch    73 | loss: 77.8565048CurrentTrain: epoch  8, batch    74 | loss: 82.5579635CurrentTrain: epoch  8, batch    75 | loss: 98.1766550CurrentTrain: epoch  8, batch    76 | loss: 80.3216958CurrentTrain: epoch  8, batch    77 | loss: 98.1275784CurrentTrain: epoch  8, batch    78 | loss: 70.4225405CurrentTrain: epoch  8, batch    79 | loss: 74.8989603CurrentTrain: epoch  8, batch    80 | loss: 75.8498220CurrentTrain: epoch  8, batch    81 | loss: 79.8575677CurrentTrain: epoch  8, batch    82 | loss: 66.3776113CurrentTrain: epoch  8, batch    83 | loss: 169.5013984CurrentTrain: epoch  8, batch    84 | loss: 66.7327009CurrentTrain: epoch  8, batch    85 | loss: 78.4870809CurrentTrain: epoch  8, batch    86 | loss: 66.3639397CurrentTrain: epoch  8, batch    87 | loss: 64.8416817CurrentTrain: epoch  8, batch    88 | loss: 82.1221896CurrentTrain: epoch  8, batch    89 | loss: 93.2618800CurrentTrain: epoch  8, batch    90 | loss: 61.6538640CurrentTrain: epoch  8, batch    91 | loss: 82.9549498CurrentTrain: epoch  8, batch    92 | loss: 67.0961620CurrentTrain: epoch  8, batch    93 | loss: 100.9357570CurrentTrain: epoch  8, batch    94 | loss: 66.0984021CurrentTrain: epoch  8, batch    95 | loss: 79.4325168CurrentTrain: epoch  9, batch     0 | loss: 92.2657902CurrentTrain: epoch  9, batch     1 | loss: 63.2280723CurrentTrain: epoch  9, batch     2 | loss: 94.6083528CurrentTrain: epoch  9, batch     3 | loss: 56.8890756CurrentTrain: epoch  9, batch     4 | loss: 95.2879704CurrentTrain: epoch  9, batch     5 | loss: 63.5683150CurrentTrain: epoch  9, batch     6 | loss: 62.5187303CurrentTrain: epoch  9, batch     7 | loss: 96.1852973CurrentTrain: epoch  9, batch     8 | loss: 93.1882900CurrentTrain: epoch  9, batch     9 | loss: 80.8991886CurrentTrain: epoch  9, batch    10 | loss: 97.4625284CurrentTrain: epoch  9, batch    11 | loss: 122.0166364CurrentTrain: epoch  9, batch    12 | loss: 95.3905688CurrentTrain: epoch  9, batch    13 | loss: 94.3140208CurrentTrain: epoch  9, batch    14 | loss: 94.0718187CurrentTrain: epoch  9, batch    15 | loss: 65.5709947CurrentTrain: epoch  9, batch    16 | loss: 76.0311626CurrentTrain: epoch  9, batch    17 | loss: 127.0402270CurrentTrain: epoch  9, batch    18 | loss: 81.5135324CurrentTrain: epoch  9, batch    19 | loss: 93.5485512CurrentTrain: epoch  9, batch    20 | loss: 88.9755862CurrentTrain: epoch  9, batch    21 | loss: 59.6491872CurrentTrain: epoch  9, batch    22 | loss: 75.8122420CurrentTrain: epoch  9, batch    23 | loss: 99.0289038CurrentTrain: epoch  9, batch    24 | loss: 96.8463312CurrentTrain: epoch  9, batch    25 | loss: 95.7676661CurrentTrain: epoch  9, batch    26 | loss: 77.8269742CurrentTrain: epoch  9, batch    27 | loss: 66.4576250CurrentTrain: epoch  9, batch    28 | loss: 65.5454344CurrentTrain: epoch  9, batch    29 | loss: 80.2257200CurrentTrain: epoch  9, batch    30 | loss: 58.3591652CurrentTrain: epoch  9, batch    31 | loss: 95.2394162CurrentTrain: epoch  9, batch    32 | loss: 65.9957336CurrentTrain: epoch  9, batch    33 | loss: 76.1167664CurrentTrain: epoch  9, batch    34 | loss: 117.9129649CurrentTrain: epoch  9, batch    35 | loss: 77.9778501CurrentTrain: epoch  9, batch    36 | loss: 63.3854605CurrentTrain: epoch  9, batch    37 | loss: 168.7668511CurrentTrain: epoch  9, batch    38 | loss: 78.9611758CurrentTrain: epoch  9, batch    39 | loss: 74.0331533CurrentTrain: epoch  9, batch    40 | loss: 101.3485805CurrentTrain: epoch  9, batch    41 | loss: 67.1221200CurrentTrain: epoch  9, batch    42 | loss: 62.9198029CurrentTrain: epoch  9, batch    43 | loss: 57.4319312CurrentTrain: epoch  9, batch    44 | loss: 74.6356535CurrentTrain: epoch  9, batch    45 | loss: 68.2658936CurrentTrain: epoch  9, batch    46 | loss: 120.5009195CurrentTrain: epoch  9, batch    47 | loss: 128.2043570CurrentTrain: epoch  9, batch    48 | loss: 80.9092828CurrentTrain: epoch  9, batch    49 | loss: 66.5496295CurrentTrain: epoch  9, batch    50 | loss: 76.4087135CurrentTrain: epoch  9, batch    51 | loss: 71.8531308CurrentTrain: epoch  9, batch    52 | loss: 70.8535243CurrentTrain: epoch  9, batch    53 | loss: 92.9940828CurrentTrain: epoch  9, batch    54 | loss: 63.6470121CurrentTrain: epoch  9, batch    55 | loss: 78.7711194CurrentTrain: epoch  9, batch    56 | loss: 65.2535547CurrentTrain: epoch  9, batch    57 | loss: 76.1934258CurrentTrain: epoch  9, batch    58 | loss: 64.7889657CurrentTrain: epoch  9, batch    59 | loss: 73.0214870CurrentTrain: epoch  9, batch    60 | loss: 93.3540710CurrentTrain: epoch  9, batch    61 | loss: 94.6206666CurrentTrain: epoch  9, batch    62 | loss: 72.8329000CurrentTrain: epoch  9, batch    63 | loss: 95.2081733CurrentTrain: epoch  9, batch    64 | loss: 164.2736160CurrentTrain: epoch  9, batch    65 | loss: 78.8286874CurrentTrain: epoch  9, batch    66 | loss: 97.1703473CurrentTrain: epoch  9, batch    67 | loss: 77.3554858CurrentTrain: epoch  9, batch    68 | loss: 76.2536152CurrentTrain: epoch  9, batch    69 | loss: 66.1741772CurrentTrain: epoch  9, batch    70 | loss: 75.0617492CurrentTrain: epoch  9, batch    71 | loss: 73.3478364CurrentTrain: epoch  9, batch    72 | loss: 64.7325422CurrentTrain: epoch  9, batch    73 | loss: 62.9177810CurrentTrain: epoch  9, batch    74 | loss: 77.3499257CurrentTrain: epoch  9, batch    75 | loss: 58.1806725CurrentTrain: epoch  9, batch    76 | loss: 75.8931812CurrentTrain: epoch  9, batch    77 | loss: 63.9166246CurrentTrain: epoch  9, batch    78 | loss: 97.1549540CurrentTrain: epoch  9, batch    79 | loss: 77.3104969CurrentTrain: epoch  9, batch    80 | loss: 121.3147159CurrentTrain: epoch  9, batch    81 | loss: 75.6215070CurrentTrain: epoch  9, batch    82 | loss: 95.0950192CurrentTrain: epoch  9, batch    83 | loss: 62.4860632CurrentTrain: epoch  9, batch    84 | loss: 99.2883417CurrentTrain: epoch  9, batch    85 | loss: 66.2392757CurrentTrain: epoch  9, batch    86 | loss: 73.5710725CurrentTrain: epoch  9, batch    87 | loss: 82.7237339CurrentTrain: epoch  9, batch    88 | loss: 66.1664549CurrentTrain: epoch  9, batch    89 | loss: 172.2762873CurrentTrain: epoch  9, batch    90 | loss: 66.5174733CurrentTrain: epoch  9, batch    91 | loss: 74.8660217CurrentTrain: epoch  9, batch    92 | loss: 65.4870377CurrentTrain: epoch  9, batch    93 | loss: 78.5027117CurrentTrain: epoch  9, batch    94 | loss: 63.8343987CurrentTrain: epoch  9, batch    95 | loss: 81.1049078

F1 score per class: {32: np.float64(0.5333333333333333), 6: np.float64(0.8127853881278538), 19: np.float64(0.36363636363636365), 24: np.float64(0.7558139534883721), 26: np.float64(0.94), 29: np.float64(0.8195121951219512)}
Micro-average F1 score: 0.7607843137254902
Weighted-average F1 score: 0.7635658534808654
F1 score per class: {32: np.float64(0.6350710900473934), 6: np.float64(0.8088888888888889), 19: np.float64(0.25287356321839083), 24: np.float64(0.7472527472527473), 26: np.float64(0.9346733668341709), 29: np.float64(0.8018433179723502)}
Micro-average F1 score: 0.743978590544157
Weighted-average F1 score: 0.7241713677653631
F1 score per class: {32: np.float64(0.6411483253588517), 6: np.float64(0.8125), 19: np.float64(0.30303030303030304), 24: np.float64(0.7513812154696132), 26: np.float64(0.9346733668341709), 29: np.float64(0.8130841121495327)}
Micro-average F1 score: 0.7612076852698993
Weighted-average F1 score: 0.7500291348943265

F1 score per class: {32: np.float64(0.5333333333333333), 6: np.float64(0.8127853881278538), 19: np.float64(0.36363636363636365), 24: np.float64(0.7558139534883721), 26: np.float64(0.94), 29: np.float64(0.8195121951219512)}
Micro-average F1 score: 0.7607843137254902
Weighted-average F1 score: 0.7635658534808654
F1 score per class: {32: np.float64(0.6350710900473934), 6: np.float64(0.8088888888888889), 19: np.float64(0.25287356321839083), 24: np.float64(0.7472527472527473), 26: np.float64(0.9346733668341709), 29: np.float64(0.8018433179723502)}
Micro-average F1 score: 0.743978590544157
Weighted-average F1 score: 0.7241713677653631
F1 score per class: {32: np.float64(0.6411483253588517), 6: np.float64(0.8125), 19: np.float64(0.30303030303030304), 24: np.float64(0.7513812154696132), 26: np.float64(0.9346733668341709), 29: np.float64(0.8130841121495327)}
Micro-average F1 score: 0.7612076852698993
Weighted-average F1 score: 0.7500291348943265

F1 score per class: {32: np.float64(0.4192139737991266), 6: np.float64(0.7542372881355932), 19: np.float64(0.21052631578947367), 24: np.float64(0.6989247311827957), 26: np.float64(0.8623853211009175), 29: np.float64(0.6774193548387096)}
Micro-average F1 score: 0.6504610226320201
Weighted-average F1 score: 0.6385073472741856
F1 score per class: {32: np.float64(0.4589041095890411), 6: np.float64(0.7398373983739838), 19: np.float64(0.14012738853503184), 24: np.float64(0.6834170854271356), 26: np.float64(0.8493150684931506), 29: np.float64(0.6420664206642066)}
Micro-average F1 score: 0.6026011560693642
Weighted-average F1 score: 0.5705816382813137
F1 score per class: {32: np.float64(0.46206896551724136), 6: np.float64(0.7489711934156379), 19: np.float64(0.16), 24: np.float64(0.6868686868686869), 26: np.float64(0.8493150684931506), 29: np.float64(0.651685393258427)}
Micro-average F1 score: 0.6199701937406855
Weighted-average F1 score: 0.5937245985979195

F1 score per class: {32: np.float64(0.4192139737991266), 6: np.float64(0.7542372881355932), 19: np.float64(0.21052631578947367), 24: np.float64(0.6989247311827957), 26: np.float64(0.8623853211009175), 29: np.float64(0.6774193548387096)}
Micro-average F1 score: 0.6504610226320201
Weighted-average F1 score: 0.6385073472741856
F1 score per class: {32: np.float64(0.4589041095890411), 6: np.float64(0.7398373983739838), 19: np.float64(0.14012738853503184), 24: np.float64(0.6834170854271356), 26: np.float64(0.8493150684931506), 29: np.float64(0.6420664206642066)}
Micro-average F1 score: 0.6026011560693642
Weighted-average F1 score: 0.5705816382813137
F1 score per class: {32: np.float64(0.46206896551724136), 6: np.float64(0.7489711934156379), 19: np.float64(0.16), 24: np.float64(0.6868686868686869), 26: np.float64(0.8493150684931506), 29: np.float64(0.651685393258427)}
Micro-average F1 score: 0.6199701937406855
Weighted-average F1 score: 0.5937245985979195
cur_acc_wo_na:  ['0.7608']
his_acc_wo_na:  ['0.7608']
cur_acc des_wo_na:  ['0.7440']
his_acc des_wo_na:  ['0.7440']
cur_acc rrf_wo_na:  ['0.7612']
his_acc rrf_wo_na:  ['0.7612']
cur_acc_w_na:  ['0.6505']
his_acc_w_na:  ['0.6505']
cur_acc des_w_na:  ['0.6026']
his_acc des_w_na:  ['0.6026']
cur_acc rrf_w_na:  ['0.6200']
his_acc rrf_w_na:  ['0.6200']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 81.1594556CurrentTrain: epoch  0, batch     1 | loss: 97.5371617CurrentTrain: epoch  0, batch     2 | loss: 95.6730889CurrentTrain: epoch  0, batch     3 | loss: 67.4950033CurrentTrain: epoch  1, batch     0 | loss: 136.4508029CurrentTrain: epoch  1, batch     1 | loss: 70.9268411CurrentTrain: epoch  1, batch     2 | loss: 108.7653999CurrentTrain: epoch  1, batch     3 | loss: 63.0716802CurrentTrain: epoch  2, batch     0 | loss: 101.6655627CurrentTrain: epoch  2, batch     1 | loss: 88.4713203CurrentTrain: epoch  2, batch     2 | loss: 83.2919294CurrentTrain: epoch  2, batch     3 | loss: 61.0497441CurrentTrain: epoch  3, batch     0 | loss: 101.6950629CurrentTrain: epoch  3, batch     1 | loss: 67.9407035CurrentTrain: epoch  3, batch     2 | loss: 101.7907723CurrentTrain: epoch  3, batch     3 | loss: 59.5513178CurrentTrain: epoch  4, batch     0 | loss: 94.6289928CurrentTrain: epoch  4, batch     1 | loss: 96.9888068CurrentTrain: epoch  4, batch     2 | loss: 67.5224775CurrentTrain: epoch  4, batch     3 | loss: 79.4276728CurrentTrain: epoch  5, batch     0 | loss: 124.6004110CurrentTrain: epoch  5, batch     1 | loss: 80.3415295CurrentTrain: epoch  5, batch     2 | loss: 68.0275133CurrentTrain: epoch  5, batch     3 | loss: 44.1745802CurrentTrain: epoch  6, batch     0 | loss: 69.0809048CurrentTrain: epoch  6, batch     1 | loss: 67.1780146CurrentTrain: epoch  6, batch     2 | loss: 64.6626332CurrentTrain: epoch  6, batch     3 | loss: 101.7611813CurrentTrain: epoch  7, batch     0 | loss: 118.3544286CurrentTrain: epoch  7, batch     1 | loss: 77.4437642CurrentTrain: epoch  7, batch     2 | loss: 77.0345060CurrentTrain: epoch  7, batch     3 | loss: 45.6664892CurrentTrain: epoch  8, batch     0 | loss: 91.8250098CurrentTrain: epoch  8, batch     1 | loss: 114.5770158CurrentTrain: epoch  8, batch     2 | loss: 93.2956625CurrentTrain: epoch  8, batch     3 | loss: 37.9073733CurrentTrain: epoch  9, batch     0 | loss: 64.0996976CurrentTrain: epoch  9, batch     1 | loss: 63.3610429CurrentTrain: epoch  9, batch     2 | loss: 97.8482798CurrentTrain: epoch  9, batch     3 | loss: 53.4415551
MemoryTrain:  epoch  0, batch     0 | loss: 1.4443372MemoryTrain:  epoch  1, batch     0 | loss: 1.2223555MemoryTrain:  epoch  2, batch     0 | loss: 1.0208648MemoryTrain:  epoch  3, batch     0 | loss: 0.7711215MemoryTrain:  epoch  4, batch     0 | loss: 0.6377373MemoryTrain:  epoch  5, batch     0 | loss: 0.5424980MemoryTrain:  epoch  6, batch     0 | loss: 0.4362898MemoryTrain:  epoch  7, batch     0 | loss: 0.4266002MemoryTrain:  epoch  8, batch     0 | loss: 0.3785877MemoryTrain:  epoch  9, batch     0 | loss: 0.2961444

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.38461538461538464), 36: np.float64(0.0), 6: np.float64(0.6), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.8421052631578947), 26: np.float64(0.0), 29: np.float64(0.42857142857142855), 30: np.float64(0.6607142857142857)}
Micro-average F1 score: 0.5172413793103449
Weighted-average F1 score: 0.4692841444270016
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.6347305389221557), 36: np.float64(0.0), 6: np.float64(0.7735849056603774), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.6181818181818182), 26: np.float64(0.0), 29: np.float64(0.4444444444444444), 30: np.float64(0.7439024390243902)}
Micro-average F1 score: 0.6058519793459552
Weighted-average F1 score: 0.551660962947691
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.6545454545454545), 36: np.float64(0.0), 6: np.float64(0.7878787878787878), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.7083333333333334), 26: np.float64(0.0), 29: np.float64(0.4444444444444444), 30: np.float64(0.7763157894736842)}
Micro-average F1 score: 0.634862385321101
Weighted-average F1 score: 0.5759627366524785

F1 score per class: {32: np.float64(0.5591397849462365), 33: np.float64(0.3105590062111801), 36: np.float64(0.8157894736842105), 6: np.float64(0.5783132530120482), 8: np.float64(0.3076923076923077), 19: np.float64(0.7252747252747253), 20: np.float64(0.9261083743842364), 24: np.float64(0.8421052631578947), 26: np.float64(0.7685589519650655), 29: np.float64(0.3157894736842105), 30: np.float64(0.6166666666666667)}
Micro-average F1 score: 0.6774193548387096
Weighted-average F1 score: 0.6852727037345177
F1 score per class: {32: np.float64(0.5910931174089069), 33: np.float64(0.4690265486725664), 36: np.float64(0.7421875), 6: np.float64(0.7130434782608696), 8: np.float64(0.27848101265822783), 19: np.float64(0.7021276595744681), 20: np.float64(0.8878504672897196), 24: np.float64(0.40476190476190477), 26: np.float64(0.7532467532467533), 29: np.float64(0.2962962962962963), 30: np.float64(0.6354166666666666)}
Micro-average F1 score: 0.6487358795051102
Weighted-average F1 score: 0.6341928453169973
F1 score per class: {32: np.float64(0.5714285714285714), 33: np.float64(0.5023255813953489), 36: np.float64(0.7569721115537849), 6: np.float64(0.75), 8: np.float64(0.31746031746031744), 19: np.float64(0.7058823529411765), 20: np.float64(0.8962264150943396), 24: np.float64(0.5396825396825397), 26: np.float64(0.7532467532467533), 29: np.float64(0.2857142857142857), 30: np.float64(0.6941176470588235)}
Micro-average F1 score: 0.6746438746438747
Weighted-average F1 score: 0.6655200115939569

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.33557046979865773), 36: np.float64(0.0), 6: np.float64(0.46601941747572817), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.7804878048780488), 26: np.float64(0.0), 29: np.float64(0.42857142857142855), 30: np.float64(0.4966442953020134)}
Micro-average F1 score: 0.3977272727272727
Weighted-average F1 score: 0.3546520737566259
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.4690265486725664), 36: np.float64(0.0), 6: np.float64(0.6029411764705882), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.5230769230769231), 26: np.float64(0.0), 29: np.float64(0.38095238095238093), 30: np.float64(0.47470817120622566)}
Micro-average F1 score: 0.41755634638196915
Weighted-average F1 score: 0.38560514542412044
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.5023255813953489), 36: np.float64(0.0), 6: np.float64(0.6141732283464567), 8: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.6415094339622641), 26: np.float64(0.0), 29: np.float64(0.38095238095238093), 30: np.float64(0.5152838427947598)}
Micro-average F1 score: 0.4470284237726098
Weighted-average F1 score: 0.4083948149466938

F1 score per class: {32: np.float64(0.42448979591836733), 33: np.float64(0.24154589371980675), 36: np.float64(0.7410358565737052), 6: np.float64(0.41739130434782606), 8: np.float64(0.1791044776119403), 19: np.float64(0.6502463054187192), 20: np.float64(0.8103448275862069), 24: np.float64(0.7804878048780488), 26: np.float64(0.5770491803278689), 29: np.float64(0.25), 30: np.float64(0.45121951219512196)}
Micro-average F1 score: 0.5436893203883495
Weighted-average F1 score: 0.5384573926668329
F1 score per class: {32: np.float64(0.3978201634877384), 33: np.float64(0.31085043988269795), 36: np.float64(0.6397306397306397), 6: np.float64(0.5030674846625767), 8: np.float64(0.14965986394557823), 19: np.float64(0.6139534883720931), 20: np.float64(0.7723577235772358), 24: np.float64(0.3148148148148148), 26: np.float64(0.58), 29: np.float64(0.2222222222222222), 30: np.float64(0.3885350318471338)}
Micro-average F1 score: 0.47592738752959746
Weighted-average F1 score: 0.4574264163036943
F1 score per class: {32: np.float64(0.39520958083832336), 33: np.float64(0.33962264150943394), 36: np.float64(0.6462585034013606), 6: np.float64(0.5234899328859061), 8: np.float64(0.16393442622950818), 19: np.float64(0.616822429906542), 20: np.float64(0.7818930041152263), 24: np.float64(0.4473684210526316), 26: np.float64(0.5742574257425742), 29: np.float64(0.21621621621621623), 30: np.float64(0.4338235294117647)}
Micro-average F1 score: 0.5012701100762066
Weighted-average F1 score: 0.48624703302529965
cur_acc_wo_na:  ['0.7608', '0.5172']
his_acc_wo_na:  ['0.7608', '0.6774']
cur_acc des_wo_na:  ['0.7440', '0.6059']
his_acc des_wo_na:  ['0.7440', '0.6487']
cur_acc rrf_wo_na:  ['0.7612', '0.6349']
his_acc rrf_wo_na:  ['0.7612', '0.6746']
cur_acc_w_na:  ['0.6505', '0.3977']
his_acc_w_na:  ['0.6505', '0.5437']
cur_acc des_w_na:  ['0.6026', '0.4176']
his_acc des_w_na:  ['0.6026', '0.4759']
cur_acc rrf_w_na:  ['0.6200', '0.4470']
his_acc rrf_w_na:  ['0.6200', '0.5013']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 105.0621664CurrentTrain: epoch  0, batch     1 | loss: 97.5703458CurrentTrain: epoch  0, batch     2 | loss: 90.0462139CurrentTrain: epoch  0, batch     3 | loss: 113.3451588CurrentTrain: epoch  0, batch     4 | loss: 21.1288519CurrentTrain: epoch  1, batch     0 | loss: 112.7864473CurrentTrain: epoch  1, batch     1 | loss: 73.0776742CurrentTrain: epoch  1, batch     2 | loss: 88.7796168CurrentTrain: epoch  1, batch     3 | loss: 85.6865090CurrentTrain: epoch  1, batch     4 | loss: 19.9931091CurrentTrain: epoch  2, batch     0 | loss: 85.9490961CurrentTrain: epoch  2, batch     1 | loss: 86.4838178CurrentTrain: epoch  2, batch     2 | loss: 81.8378494CurrentTrain: epoch  2, batch     3 | loss: 126.8128957CurrentTrain: epoch  2, batch     4 | loss: 43.7034807CurrentTrain: epoch  3, batch     0 | loss: 71.4419837CurrentTrain: epoch  3, batch     1 | loss: 70.6927888CurrentTrain: epoch  3, batch     2 | loss: 100.3972816CurrentTrain: epoch  3, batch     3 | loss: 99.9683884CurrentTrain: epoch  3, batch     4 | loss: 17.9069464CurrentTrain: epoch  4, batch     0 | loss: 85.9459947CurrentTrain: epoch  4, batch     1 | loss: 99.7894193CurrentTrain: epoch  4, batch     2 | loss: 80.4179411CurrentTrain: epoch  4, batch     3 | loss: 76.2396101CurrentTrain: epoch  4, batch     4 | loss: 24.4735742CurrentTrain: epoch  5, batch     0 | loss: 67.5639372CurrentTrain: epoch  5, batch     1 | loss: 96.9150350CurrentTrain: epoch  5, batch     2 | loss: 84.2764998CurrentTrain: epoch  5, batch     3 | loss: 70.2896626CurrentTrain: epoch  5, batch     4 | loss: 13.0243957CurrentTrain: epoch  6, batch     0 | loss: 95.8631082CurrentTrain: epoch  6, batch     1 | loss: 62.2434795CurrentTrain: epoch  6, batch     2 | loss: 79.8174539CurrentTrain: epoch  6, batch     3 | loss: 124.6399404CurrentTrain: epoch  6, batch     4 | loss: 25.7035519CurrentTrain: epoch  7, batch     0 | loss: 121.0198633CurrentTrain: epoch  7, batch     1 | loss: 122.6907903CurrentTrain: epoch  7, batch     2 | loss: 65.1974540CurrentTrain: epoch  7, batch     3 | loss: 65.0572136CurrentTrain: epoch  7, batch     4 | loss: 18.5910645CurrentTrain: epoch  8, batch     0 | loss: 75.8984940CurrentTrain: epoch  8, batch     1 | loss: 121.2518037CurrentTrain: epoch  8, batch     2 | loss: 61.9786091CurrentTrain: epoch  8, batch     3 | loss: 95.5868165CurrentTrain: epoch  8, batch     4 | loss: 24.1383495CurrentTrain: epoch  9, batch     0 | loss: 65.7298408CurrentTrain: epoch  9, batch     1 | loss: 118.6420070CurrentTrain: epoch  9, batch     2 | loss: 94.8184684CurrentTrain: epoch  9, batch     3 | loss: 76.7945965CurrentTrain: epoch  9, batch     4 | loss: 8.9050742
MemoryTrain:  epoch  0, batch     0 | loss: 1.3060099MemoryTrain:  epoch  1, batch     0 | loss: 1.2177073MemoryTrain:  epoch  2, batch     0 | loss: 0.8942579MemoryTrain:  epoch  3, batch     0 | loss: 0.6795961MemoryTrain:  epoch  4, batch     0 | loss: 0.5555074MemoryTrain:  epoch  5, batch     0 | loss: 0.4876215MemoryTrain:  epoch  6, batch     0 | loss: 0.4244794MemoryTrain:  epoch  7, batch     0 | loss: 0.4238403MemoryTrain:  epoch  8, batch     0 | loss: 0.3916048MemoryTrain:  epoch  9, batch     0 | loss: 0.3220399

F1 score per class: {32: np.float64(0.6363636363636364), 33: np.float64(0.0), 2: np.float64(0.0), 6: np.float64(0.5343511450381679), 39: np.float64(0.6770833333333334), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.35714285714285715), 20: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.6)}
Micro-average F1 score: 0.5488372093023256
Weighted-average F1 score: 0.494238627103755
F1 score per class: {32: np.float64(0.5333333333333333), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.48), 6: np.float64(0.6010928961748634), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.4), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.5)}
Micro-average F1 score: 0.41188118811881186
Weighted-average F1 score: 0.3169605258129848
F1 score per class: {32: np.float64(0.6086956521739131), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.5039370078740157), 6: np.float64(0.6021505376344086), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.4), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.5714285714285714)}
Micro-average F1 score: 0.4553191489361702
Weighted-average F1 score: 0.3695626640401615

F1 score per class: {32: np.float64(0.5833333333333334), 33: np.float64(0.48484848484848486), 2: np.float64(0.30344827586206896), 36: np.float64(0.37433155080213903), 6: np.float64(0.4166666666666667), 39: np.float64(0.8019323671497585), 8: np.float64(0.5747126436781609), 11: np.float64(0.3), 12: np.float64(0.7374301675977654), 19: np.float64(0.09523809523809523), 20: np.float64(0.8617021276595744), 24: np.float64(0.8421052631578947), 26: np.float64(0.7183673469387755), 28: np.float64(0.3333333333333333), 29: np.float64(0.2631578947368421), 30: np.float64(0.3870967741935484)}
Micro-average F1 score: 0.5451880801172447
Weighted-average F1 score: 0.5296422307877184
F1 score per class: {32: np.float64(0.37209302325581395), 33: np.float64(0.6026200873362445), 2: np.float64(0.3218390804597701), 36: np.float64(0.36585365853658536), 6: np.float64(0.34375), 39: np.float64(0.7368421052631579), 8: np.float64(0.5740740740740741), 11: np.float64(0.24096385542168675), 12: np.float64(0.7243243243243244), 19: np.float64(0.17142857142857143), 20: np.float64(0.851063829787234), 24: np.float64(0.5483870967741935), 26: np.float64(0.6904761904761905), 28: np.float64(0.2727272727272727), 29: np.float64(0.6037735849056604), 30: np.float64(0.25)}
Micro-average F1 score: 0.5319327731092437
Weighted-average F1 score: 0.5070837338470393
F1 score per class: {32: np.float64(0.4827586206896552), 33: np.float64(0.5608465608465608), 2: np.float64(0.32710280373831774), 36: np.float64(0.367816091954023), 6: np.float64(0.3373493975903614), 39: np.float64(0.7426160337552743), 8: np.float64(0.5918367346938775), 11: np.float64(0.3018867924528302), 12: np.float64(0.7403314917127072), 19: np.float64(0.13186813186813187), 20: np.float64(0.851063829787234), 24: np.float64(0.6666666666666666), 26: np.float64(0.6823529411764706), 28: np.float64(0.2727272727272727), 29: np.float64(0.5052631578947369), 30: np.float64(0.3)}
Micro-average F1 score: 0.5316117542297417
Weighted-average F1 score: 0.5067870717150937

F1 score per class: {32: np.float64(0.4), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.4697986577181208), 6: np.float64(0.5485232067510548), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.14492753623188406), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.42857142857142855)}
Micro-average F1 score: 0.3979763912310287
Weighted-average F1 score: 0.34504271966803424
F1 score per class: {32: np.float64(0.34782608695652173), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.4), 6: np.float64(0.48672566371681414), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.20689655172413793), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.43478260869565216)}
Micro-average F1 score: 0.28454172366621067
Weighted-average F1 score: 0.22120091779331574
F1 score per class: {32: np.float64(0.358974358974359), 33: np.float64(0.0), 2: np.float64(0.0), 36: np.float64(0.42105263157894735), 6: np.float64(0.48695652173913045), 39: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 19: np.float64(0.1935483870967742), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.5)}
Micro-average F1 score: 0.3179791976225854
Weighted-average F1 score: 0.2565474888096832

F1 score per class: {32: np.float64(0.3181818181818182), 33: np.float64(0.365296803652968), 2: np.float64(0.23157894736842105), 36: np.float64(0.30434782608695654), 6: np.float64(0.23049645390070922), 39: np.float64(0.7545454545454545), 8: np.float64(0.42735042735042733), 11: np.float64(0.2033898305084746), 12: np.float64(0.676923076923077), 19: np.float64(0.047619047619047616), 20: np.float64(0.7788461538461539), 24: np.float64(0.7804878048780488), 26: np.float64(0.5253731343283582), 28: np.float64(0.2727272727272727), 29: np.float64(0.22988505747126436), 30: np.float64(0.16666666666666666)}
Micro-average F1 score: 0.3967294703163882
Weighted-average F1 score: 0.3642243060477233
F1 score per class: {32: np.float64(0.1951219512195122), 33: np.float64(0.3954154727793696), 2: np.float64(0.19672131147540983), 36: np.float64(0.28846153846153844), 6: np.float64(0.20146520146520147), 39: np.float64(0.6594202898550725), 8: np.float64(0.40522875816993464), 11: np.float64(0.1360544217687075), 12: np.float64(0.6411483253588517), 19: np.float64(0.08695652173913043), 20: np.float64(0.7692307692307693), 24: np.float64(0.44155844155844154), 26: np.float64(0.5117647058823529), 28: np.float64(0.23076923076923078), 29: np.float64(0.47058823529411764), 30: np.float64(0.13513513513513514)}
Micro-average F1 score: 0.37279151943462896
Weighted-average F1 score: 0.34438822582843376
F1 score per class: {32: np.float64(0.25), 33: np.float64(0.3925925925925926), 2: np.float64(0.20588235294117646), 36: np.float64(0.2882882882882883), 6: np.float64(0.19823008849557522), 39: np.float64(0.6666666666666666), 8: np.float64(0.4264705882352941), 11: np.float64(0.17582417582417584), 12: np.float64(0.6633663366336634), 19: np.float64(0.06936416184971098), 20: np.float64(0.7692307692307693), 24: np.float64(0.6274509803921569), 26: np.float64(0.5058139534883721), 28: np.float64(0.23076923076923078), 29: np.float64(0.40336134453781514), 30: np.float64(0.16666666666666666)}
Micro-average F1 score: 0.38037591589678243
Weighted-average F1 score: 0.35004594512600234
cur_acc_wo_na:  ['0.7608', '0.5172', '0.5488']
his_acc_wo_na:  ['0.7608', '0.6774', '0.5452']
cur_acc des_wo_na:  ['0.7440', '0.6059', '0.4119']
his_acc des_wo_na:  ['0.7440', '0.6487', '0.5319']
cur_acc rrf_wo_na:  ['0.7612', '0.6349', '0.4553']
his_acc rrf_wo_na:  ['0.7612', '0.6746', '0.5316']
cur_acc_w_na:  ['0.6505', '0.3977', '0.3980']
his_acc_w_na:  ['0.6505', '0.5437', '0.3967']
cur_acc des_w_na:  ['0.6026', '0.4176', '0.2845']
his_acc des_w_na:  ['0.6026', '0.4759', '0.3728']
cur_acc rrf_w_na:  ['0.6200', '0.4470', '0.3180']
his_acc rrf_w_na:  ['0.6200', '0.5013', '0.3804']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 89.5081077CurrentTrain: epoch  0, batch     1 | loss: 115.9742168CurrentTrain: epoch  0, batch     2 | loss: 119.9493272CurrentTrain: epoch  0, batch     3 | loss: 146.4664878CurrentTrain: epoch  0, batch     4 | loss: 91.4047726CurrentTrain: epoch  1, batch     0 | loss: 87.3145067CurrentTrain: epoch  1, batch     1 | loss: 96.4614625CurrentTrain: epoch  1, batch     2 | loss: 104.3303924CurrentTrain: epoch  1, batch     3 | loss: 131.0927345CurrentTrain: epoch  1, batch     4 | loss: 66.7238975CurrentTrain: epoch  2, batch     0 | loss: 86.6748798CurrentTrain: epoch  2, batch     1 | loss: 105.4041570CurrentTrain: epoch  2, batch     2 | loss: 85.7488680CurrentTrain: epoch  2, batch     3 | loss: 105.3837113CurrentTrain: epoch  2, batch     4 | loss: 84.2256016CurrentTrain: epoch  3, batch     0 | loss: 71.7041278CurrentTrain: epoch  3, batch     1 | loss: 84.3405792CurrentTrain: epoch  3, batch     2 | loss: 105.1265629CurrentTrain: epoch  3, batch     3 | loss: 84.7474769CurrentTrain: epoch  3, batch     4 | loss: 54.3034358CurrentTrain: epoch  4, batch     0 | loss: 100.4062199CurrentTrain: epoch  4, batch     1 | loss: 99.9423001CurrentTrain: epoch  4, batch     2 | loss: 71.1263515CurrentTrain: epoch  4, batch     3 | loss: 85.1901855CurrentTrain: epoch  4, batch     4 | loss: 64.9424209CurrentTrain: epoch  5, batch     0 | loss: 128.0650600CurrentTrain: epoch  5, batch     1 | loss: 81.8206399CurrentTrain: epoch  5, batch     2 | loss: 82.5392116CurrentTrain: epoch  5, batch     3 | loss: 98.5379629CurrentTrain: epoch  5, batch     4 | loss: 50.6213689CurrentTrain: epoch  6, batch     0 | loss: 76.9004139CurrentTrain: epoch  6, batch     1 | loss: 100.1683703CurrentTrain: epoch  6, batch     2 | loss: 96.9969458CurrentTrain: epoch  6, batch     3 | loss: 78.5927639CurrentTrain: epoch  6, batch     4 | loss: 105.4064192CurrentTrain: epoch  7, batch     0 | loss: 63.5906937CurrentTrain: epoch  7, batch     1 | loss: 98.4009968CurrentTrain: epoch  7, batch     2 | loss: 93.6621093CurrentTrain: epoch  7, batch     3 | loss: 97.7091113CurrentTrain: epoch  7, batch     4 | loss: 107.6496815CurrentTrain: epoch  8, batch     0 | loss: 62.7317615CurrentTrain: epoch  8, batch     1 | loss: 98.7315490CurrentTrain: epoch  8, batch     2 | loss: 67.0754235CurrentTrain: epoch  8, batch     3 | loss: 124.5897295CurrentTrain: epoch  8, batch     4 | loss: 76.2710161CurrentTrain: epoch  9, batch     0 | loss: 76.8261231CurrentTrain: epoch  9, batch     1 | loss: 78.5120412CurrentTrain: epoch  9, batch     2 | loss: 79.8106219CurrentTrain: epoch  9, batch     3 | loss: 121.5952910CurrentTrain: epoch  9, batch     4 | loss: 47.8445893
MemoryTrain:  epoch  0, batch     0 | loss: 1.3213861MemoryTrain:  epoch  1, batch     0 | loss: 1.2399957MemoryTrain:  epoch  2, batch     0 | loss: 0.9166191MemoryTrain:  epoch  3, batch     0 | loss: 0.7103104MemoryTrain:  epoch  4, batch     0 | loss: 0.6304820MemoryTrain:  epoch  5, batch     0 | loss: 0.5517082MemoryTrain:  epoch  6, batch     0 | loss: 0.4553346MemoryTrain:  epoch  7, batch     0 | loss: 0.4168193MemoryTrain:  epoch  8, batch     0 | loss: 0.3842324MemoryTrain:  epoch  9, batch     0 | loss: 0.2864412

F1 score per class: {32: np.float64(0.0), 2: np.float64(0.9313725490196079), 5: np.float64(0.0), 6: np.float64(0.2975206611570248), 39: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.7), 12: np.float64(0.6666666666666666), 16: np.float64(0.36), 17: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5769980506822612
Weighted-average F1 score: 0.5602982235541635
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.7918367346938775), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.45112781954887216), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.7164179104477612), 17: np.float64(0.7058823529411765), 18: np.float64(0.5789473684210527), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5637795275590551
Weighted-average F1 score: 0.5137521266134893
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.8135593220338984), 6: np.float64(0.0), 10: np.float64(0.47058823529411764), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.7272727272727273), 17: np.float64(0.75), 18: np.float64(0.5074626865671642), 19: np.float64(0.0), 20: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5747126436781609
Weighted-average F1 score: 0.5232460752133079

F1 score per class: {2: np.float64(0.45454545454545453), 5: np.float64(0.867579908675799), 6: np.float64(0.38961038961038963), 8: np.float64(0.04819277108433735), 10: np.float64(0.1978021978021978), 11: np.float64(0.21052631578947367), 12: np.float64(0.31527093596059114), 16: np.float64(0.5753424657534246), 17: np.float64(0.4), 18: np.float64(0.2465753424657534), 19: np.float64(0.7962962962962963), 20: np.float64(0.5176470588235295), 24: np.float64(0.26666666666666666), 26: np.float64(0.7241379310344828), 28: np.float64(0.10309278350515463), 29: np.float64(0.8315789473684211), 30: np.float64(0.8333333333333334), 32: np.float64(0.6929133858267716), 33: np.float64(0.35294117647058826), 36: np.float64(0.3076923076923077), 39: np.float64(0.23076923076923078)}
Micro-average F1 score: 0.5131854332356635
Weighted-average F1 score: 0.5337508895222465
F1 score per class: {2: np.float64(0.4666666666666667), 5: np.float64(0.671280276816609), 6: np.float64(0.5836909871244635), 8: np.float64(0.31007751937984496), 10: np.float64(0.3448275862068966), 11: np.float64(0.19230769230769232), 12: np.float64(0.34210526315789475), 16: np.float64(0.5714285714285714), 17: np.float64(0.34285714285714286), 18: np.float64(0.2716049382716049), 19: np.float64(0.7209302325581395), 20: np.float64(0.5510204081632653), 24: np.float64(0.24096385542168675), 26: np.float64(0.6974358974358974), 28: np.float64(0.15384615384615385), 29: np.float64(0.851063829787234), 30: np.float64(0.5161290322580645), 32: np.float64(0.6875), 33: np.float64(0.35294117647058826), 36: np.float64(0.5321100917431193), 39: np.float64(0.23529411764705882)}
Micro-average F1 score: 0.5160418777440055
Weighted-average F1 score: 0.5091286392710898
F1 score per class: {2: np.float64(0.5), 5: np.float64(0.7164179104477612), 6: np.float64(0.4659090909090909), 8: np.float64(0.15053763440860216), 10: np.float64(0.31527093596059114), 11: np.float64(0.22085889570552147), 12: np.float64(0.3333333333333333), 16: np.float64(0.5783132530120482), 17: np.float64(0.375), 18: np.float64(0.272), 19: np.float64(0.7583333333333333), 20: np.float64(0.5494505494505495), 24: np.float64(0.28), 26: np.float64(0.7052631578947368), 28: np.float64(0.10416666666666667), 29: np.float64(0.8449197860962567), 30: np.float64(0.7111111111111111), 32: np.float64(0.6641221374045801), 33: np.float64(0.3333333333333333), 36: np.float64(0.5242718446601942), 39: np.float64(0.22857142857142856)}
Micro-average F1 score: 0.5078571428571429
Weighted-average F1 score: 0.5039859383891221

F1 score per class: {32: np.float64(0.0), 2: np.float64(0.7509881422924901), 36: np.float64(0.0), 5: np.float64(0.2647058823529412), 6: np.float64(0.0), 39: np.float64(0.0), 10: np.float64(0.5), 11: np.float64(0.5), 12: np.float64(0.2465753424657534), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.39946018893387314
Weighted-average F1 score: 0.3565748599230623
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.5878787878787879), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.4), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.46601941747572817), 17: np.float64(0.5217391304347826), 18: np.float64(0.3384615384615385), 19: np.float64(0.0), 20: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.3587174348697395
Weighted-average F1 score: 0.3158072154998053
F1 score per class: {2: np.float64(0.0), 5: np.float64(0.6075949367088608), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.3878787878787879), 11: np.float64(0.0), 12: np.float64(0.0), 16: np.float64(0.47058823529411764), 17: np.float64(0.5454545454545454), 18: np.float64(0.30357142857142855), 19: np.float64(0.0), 20: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 36: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.36803364879074657
Weighted-average F1 score: 0.3262129580980413

F1 score per class: {2: np.float64(0.2702702702702703), 5: np.float64(0.6188925081433225), 6: np.float64(0.28708133971291866), 8: np.float64(0.04819277108433735), 10: np.float64(0.16289592760180996), 11: np.float64(0.1711229946524064), 12: np.float64(0.18658892128279883), 16: np.float64(0.38181818181818183), 17: np.float64(0.24390243902439024), 18: np.float64(0.15517241379310345), 19: np.float64(0.7350427350427351), 20: np.float64(0.3893805309734513), 24: np.float64(0.19047619047619047), 26: np.float64(0.6596858638743456), 28: np.float64(0.05319148936170213), 29: np.float64(0.7214611872146118), 30: np.float64(0.7894736842105263), 32: np.float64(0.5269461077844312), 33: np.float64(0.3), 36: np.float64(0.26373626373626374), 39: np.float64(0.11320754716981132)}
Micro-average F1 score: 0.385898646521876
Weighted-average F1 score: 0.3792977096303752
F1 score per class: {2: np.float64(0.2641509433962264), 5: np.float64(0.42920353982300885), 6: np.float64(0.35142118863049093), 8: np.float64(0.2631578947368421), 10: np.float64(0.2564102564102564), 11: np.float64(0.1694915254237288), 12: np.float64(0.19152854511970535), 16: np.float64(0.3356643356643357), 17: np.float64(0.21052631578947367), 18: np.float64(0.14332247557003258), 19: np.float64(0.6220735785953178), 20: np.float64(0.34838709677419355), 24: np.float64(0.13793103448275862), 26: np.float64(0.5862068965517241), 28: np.float64(0.07633587786259542), 29: np.float64(0.7655502392344498), 30: np.float64(0.4444444444444444), 32: np.float64(0.5365853658536586), 33: np.float64(0.2857142857142857), 36: np.float64(0.38926174496644295), 39: np.float64(0.11267605633802817)}
Micro-average F1 score: 0.3539495019689599
Weighted-average F1 score: 0.3376061333730093
F1 score per class: {2: np.float64(0.2857142857142857), 5: np.float64(0.45823389021479716), 6: np.float64(0.31906614785992216), 8: np.float64(0.14583333333333334), 10: np.float64(0.2191780821917808), 11: np.float64(0.19672131147540983), 12: np.float64(0.184070796460177), 16: np.float64(0.3356643356643357), 17: np.float64(0.22641509433962265), 18: np.float64(0.14468085106382977), 19: np.float64(0.6791044776119403), 20: np.float64(0.352112676056338), 24: np.float64(0.18181818181818182), 26: np.float64(0.6175115207373272), 28: np.float64(0.055248618784530384), 29: np.float64(0.7669902912621359), 30: np.float64(0.64), 32: np.float64(0.5014409221902018), 33: np.float64(0.2727272727272727), 36: np.float64(0.38848920863309355), 39: np.float64(0.10666666666666667)}
Micro-average F1 score: 0.35408366533864544
Weighted-average F1 score: 0.336674496365222
cur_acc_wo_na:  ['0.7608', '0.5172', '0.5488', '0.5770']
his_acc_wo_na:  ['0.7608', '0.6774', '0.5452', '0.5132']
cur_acc des_wo_na:  ['0.7440', '0.6059', '0.4119', '0.5638']
his_acc des_wo_na:  ['0.7440', '0.6487', '0.5319', '0.5160']
cur_acc rrf_wo_na:  ['0.7612', '0.6349', '0.4553', '0.5747']
his_acc rrf_wo_na:  ['0.7612', '0.6746', '0.5316', '0.5079']
cur_acc_w_na:  ['0.6505', '0.3977', '0.3980', '0.3995']
his_acc_w_na:  ['0.6505', '0.5437', '0.3967', '0.3859']
cur_acc des_w_na:  ['0.6026', '0.4176', '0.2845', '0.3587']
his_acc des_w_na:  ['0.6026', '0.4759', '0.3728', '0.3539']
cur_acc rrf_w_na:  ['0.6200', '0.4470', '0.3180', '0.3680']
his_acc rrf_w_na:  ['0.6200', '0.5013', '0.3804', '0.3541']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 89.6230221CurrentTrain: epoch  0, batch     1 | loss: 101.7306127CurrentTrain: epoch  0, batch     2 | loss: 85.5494399CurrentTrain: epoch  0, batch     3 | loss: 144.0799256CurrentTrain: epoch  0, batch     4 | loss: 71.3613184CurrentTrain: epoch  1, batch     0 | loss: 82.9750736CurrentTrain: epoch  1, batch     1 | loss: 106.0507787CurrentTrain: epoch  1, batch     2 | loss: 178.8891417CurrentTrain: epoch  1, batch     3 | loss: 90.2902689CurrentTrain: epoch  1, batch     4 | loss: 61.0234723CurrentTrain: epoch  2, batch     0 | loss: 87.5256924CurrentTrain: epoch  2, batch     1 | loss: 89.6611260CurrentTrain: epoch  2, batch     2 | loss: 88.4781268CurrentTrain: epoch  2, batch     3 | loss: 103.0799006CurrentTrain: epoch  2, batch     4 | loss: 74.4308758CurrentTrain: epoch  3, batch     0 | loss: 69.0524320CurrentTrain: epoch  3, batch     1 | loss: 71.6671442CurrentTrain: epoch  3, batch     2 | loss: 89.0197714CurrentTrain: epoch  3, batch     3 | loss: 87.0467046CurrentTrain: epoch  3, batch     4 | loss: 146.9375493CurrentTrain: epoch  4, batch     0 | loss: 83.8410343CurrentTrain: epoch  4, batch     1 | loss: 83.6654860CurrentTrain: epoch  4, batch     2 | loss: 83.8199632CurrentTrain: epoch  4, batch     3 | loss: 82.9173959CurrentTrain: epoch  4, batch     4 | loss: 69.3742252CurrentTrain: epoch  5, batch     0 | loss: 83.3111528CurrentTrain: epoch  5, batch     1 | loss: 128.6098849CurrentTrain: epoch  5, batch     2 | loss: 97.4742893CurrentTrain: epoch  5, batch     3 | loss: 67.3494274CurrentTrain: epoch  5, batch     4 | loss: 48.0314555CurrentTrain: epoch  6, batch     0 | loss: 79.9552406CurrentTrain: epoch  6, batch     1 | loss: 83.6164723CurrentTrain: epoch  6, batch     2 | loss: 68.1664173CurrentTrain: epoch  6, batch     3 | loss: 80.9816240CurrentTrain: epoch  6, batch     4 | loss: 55.2101284CurrentTrain: epoch  7, batch     0 | loss: 78.1043997CurrentTrain: epoch  7, batch     1 | loss: 80.3139354CurrentTrain: epoch  7, batch     2 | loss: 81.5022938CurrentTrain: epoch  7, batch     3 | loss: 69.0816918CurrentTrain: epoch  7, batch     4 | loss: 68.2583198CurrentTrain: epoch  8, batch     0 | loss: 93.8642600CurrentTrain: epoch  8, batch     1 | loss: 123.6537504CurrentTrain: epoch  8, batch     2 | loss: 119.5021757CurrentTrain: epoch  8, batch     3 | loss: 66.3107547CurrentTrain: epoch  8, batch     4 | loss: 50.6448234CurrentTrain: epoch  9, batch     0 | loss: 67.3194673CurrentTrain: epoch  9, batch     1 | loss: 81.5330508CurrentTrain: epoch  9, batch     2 | loss: 76.2231943CurrentTrain: epoch  9, batch     3 | loss: 95.1701270CurrentTrain: epoch  9, batch     4 | loss: 68.6292091
MemoryTrain:  epoch  0, batch     0 | loss: 1.2071288MemoryTrain:  epoch  1, batch     0 | loss: 1.0419135MemoryTrain:  epoch  2, batch     0 | loss: 0.8207973MemoryTrain:  epoch  3, batch     0 | loss: 0.7330030MemoryTrain:  epoch  4, batch     0 | loss: 0.5776310MemoryTrain:  epoch  5, batch     0 | loss: 0.5594413MemoryTrain:  epoch  6, batch     0 | loss: 0.4329268MemoryTrain:  epoch  7, batch     0 | loss: 0.3680901MemoryTrain:  epoch  8, batch     0 | loss: 0.3157950MemoryTrain:  epoch  9, batch     0 | loss: 0.2713168

F1 score per class: {1: np.float64(0.19393939393939394), 3: np.float64(0.6813186813186813), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.1348314606741573), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.48028673835125446), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.656934306569343)}
Micro-average F1 score: 0.40454076367389064
Weighted-average F1 score: 0.3755254369653318
F1 score per class: {1: np.float64(0.21965317919075145), 2: np.float64(0.0), 3: np.float64(0.6160337552742616), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.07142857142857142), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.45021645021645024), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6438356164383562)}
Micro-average F1 score: 0.34598411297440423
Weighted-average F1 score: 0.31260673016302715
F1 score per class: {1: np.float64(0.22857142857142856), 3: np.float64(0.64), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0761904761904762), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.46545454545454545), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6344827586206897)}
Micro-average F1 score: 0.3779816513761468
Weighted-average F1 score: 0.3524726122482666

F1 score per class: {1: np.float64(0.16243654822335024), 2: np.float64(0.56), 3: np.float64(0.5391304347826087), 5: np.float64(0.8761904761904762), 6: np.float64(0.46153846153846156), 8: np.float64(0.046511627906976744), 10: np.float64(0.35294117647058826), 11: np.float64(0.112), 12: np.float64(0.34782608695652173), 14: np.float64(0.11650485436893204), 16: np.float64(0.56), 17: np.float64(0.3), 18: np.float64(0.038461538461538464), 19: np.float64(0.6944444444444444), 20: np.float64(0.44155844155844154), 22: np.float64(0.3952802359882006), 24: np.float64(0.1), 26: np.float64(0.7252747252747253), 28: np.float64(0.08888888888888889), 29: np.float64(0.8241206030150754), 30: np.float64(0.8648648648648649), 32: np.float64(0.627906976744186), 33: np.float64(0.4), 34: np.float64(0.21377672209026127), 36: np.float64(0.1917808219178082), 39: np.float64(0.2)}
Micro-average F1 score: 0.42987641053197206
Weighted-average F1 score: 0.420083842838443
F1 score per class: {1: np.float64(0.18269230769230768), 2: np.float64(0.4375), 3: np.float64(0.4294117647058823), 5: np.float64(0.7), 6: np.float64(0.5101214574898786), 8: np.float64(0.3181818181818182), 10: np.float64(0.3865546218487395), 11: np.float64(0.10218978102189781), 12: np.float64(0.3611111111111111), 14: np.float64(0.045454545454545456), 16: np.float64(0.6419753086419753), 17: np.float64(0.2777777777777778), 18: np.float64(0.2), 19: np.float64(0.6169491525423729), 20: np.float64(0.5054945054945055), 22: np.float64(0.38235294117647056), 24: np.float64(0.10526315789473684), 26: np.float64(0.6868686868686869), 28: np.float64(0.13333333333333333), 29: np.float64(0.8121827411167513), 30: np.float64(0.6792452830188679), 32: np.float64(0.5512820512820513), 33: np.float64(0.35294117647058826), 34: np.float64(0.19789473684210526), 36: np.float64(0.5614035087719298), 39: np.float64(0.2)}
Micro-average F1 score: 0.41585903083700443
Weighted-average F1 score: 0.39808471591692557
F1 score per class: {1: np.float64(0.18867924528301888), 2: np.float64(0.4666666666666667), 3: np.float64(0.46006389776357826), 5: np.float64(0.7578125), 6: np.float64(0.5025641025641026), 8: np.float64(0.19801980198019803), 10: np.float64(0.36585365853658536), 11: np.float64(0.10852713178294573), 12: np.float64(0.34965034965034963), 14: np.float64(0.058394160583941604), 16: np.float64(0.6172839506172839), 17: np.float64(0.3333333333333333), 18: np.float64(0.14925373134328357), 19: np.float64(0.6304347826086957), 20: np.float64(0.4772727272727273), 22: np.float64(0.375366568914956), 24: np.float64(0.07692307692307693), 26: np.float64(0.7021276595744681), 28: np.float64(0.11764705882352941), 29: np.float64(0.8080808080808081), 30: np.float64(0.85), 32: np.float64(0.5802047781569966), 33: np.float64(0.375), 34: np.float64(0.17692307692307693), 36: np.float64(0.3488372093023256), 39: np.float64(0.24390243902439024)}
Micro-average F1 score: 0.41390498261877173
Weighted-average F1 score: 0.3987426093737253

F1 score per class: {1: np.float64(0.11072664359861592), 2: np.float64(0.0), 3: np.float64(0.5511111111111111), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.12903225806451613), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.3701657458563536), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.5)}
Micro-average F1 score: 0.27703180212014133
Weighted-average F1 score: 0.25132494588145005
F1 score per class: {1: np.float64(0.12140575079872204), 2: np.float64(0.0), 3: np.float64(0.40331491712707185), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.05952380952380952), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.3561643835616438), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.47474747474747475)}
Micro-average F1 score: 0.2237442922374429
Weighted-average F1 score: 0.20451972895861223
F1 score per class: {1: np.float64(0.12779552715654952), 2: np.float64(0.0), 3: np.float64(0.43902439024390244), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.06956521739130435), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.3565459610027855), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.4623115577889447)}
Micro-average F1 score: 0.24729891956782712
Weighted-average F1 score: 0.2305232211248529

F1 score per class: {1: np.float64(0.0896358543417367), 2: np.float64(0.2978723404255319), 3: np.float64(0.36470588235294116), 5: np.float64(0.6548042704626335), 6: np.float64(0.3170731707317073), 8: np.float64(0.04597701149425287), 10: np.float64(0.25161290322580643), 11: np.float64(0.10606060606060606), 12: np.float64(0.1782178217821782), 14: np.float64(0.1016949152542373), 16: np.float64(0.35294117647058826), 17: np.float64(0.1875), 18: np.float64(0.030303030303030304), 19: np.float64(0.6276150627615062), 20: np.float64(0.3269230769230769), 22: np.float64(0.2894168466522678), 24: np.float64(0.1), 26: np.float64(0.6534653465346535), 28: np.float64(0.04819277108433735), 29: np.float64(0.703862660944206), 30: np.float64(0.8205128205128205), 32: np.float64(0.4807121661721068), 33: np.float64(0.35294117647058826), 34: np.float64(0.1232876712328767), 36: np.float64(0.16666666666666666), 39: np.float64(0.10714285714285714)}
Micro-average F1 score: 0.30120481927710846
Weighted-average F1 score: 0.2836079070788662
F1 score per class: {1: np.float64(0.09743589743589744), 2: np.float64(0.23728813559322035), 3: np.float64(0.24373956594323873), 5: np.float64(0.4260869565217391), 6: np.float64(0.2971698113207547), 8: np.float64(0.25925925925925924), 10: np.float64(0.26062322946175637), 11: np.float64(0.09090909090909091), 12: np.float64(0.17962003454231434), 14: np.float64(0.03663003663003663), 16: np.float64(0.37681159420289856), 17: np.float64(0.16393442622950818), 18: np.float64(0.11464968152866242), 19: np.float64(0.527536231884058), 20: np.float64(0.3262411347517731), 22: np.float64(0.27956989247311825), 24: np.float64(0.075), 26: np.float64(0.576271186440678), 28: np.float64(0.06976744186046512), 29: np.float64(0.7174887892376681), 30: np.float64(0.5901639344262295), 32: np.float64(0.4047058823529412), 33: np.float64(0.2857142857142857), 34: np.float64(0.11648079306071871), 36: np.float64(0.4), 39: np.float64(0.10666666666666667)}
Micro-average F1 score: 0.2725566623357875
Weighted-average F1 score: 0.2580916879497659
F1 score per class: {1: np.float64(0.10335917312661498), 2: np.float64(0.2692307692307692), 3: np.float64(0.2706766917293233), 5: np.float64(0.48743718592964824), 6: np.float64(0.31921824104234525), 8: np.float64(0.17543859649122806), 10: np.float64(0.24324324324324326), 11: np.float64(0.09929078014184398), 12: np.float64(0.17391304347826086), 14: np.float64(0.049079754601226995), 16: np.float64(0.3816793893129771), 17: np.float64(0.18518518518518517), 18: np.float64(0.09803921568627451), 19: np.float64(0.5576923076923077), 20: np.float64(0.328125), 22: np.float64(0.2689075630252101), 24: np.float64(0.07142857142857142), 26: np.float64(0.5972850678733032), 28: np.float64(0.0639269406392694), 29: np.float64(0.7174887892376681), 30: np.float64(0.8095238095238095), 32: np.float64(0.4187192118226601), 33: np.float64(0.3157894736842105), 34: np.float64(0.1013215859030837), 36: np.float64(0.2777777777777778), 39: np.float64(0.11904761904761904)}
Micro-average F1 score: 0.27476923076923077
Weighted-average F1 score: 0.25885699220356406
cur_acc_wo_na:  ['0.7608', '0.5172', '0.5488', '0.5770', '0.4045']
his_acc_wo_na:  ['0.7608', '0.6774', '0.5452', '0.5132', '0.4299']
cur_acc des_wo_na:  ['0.7440', '0.6059', '0.4119', '0.5638', '0.3460']
his_acc des_wo_na:  ['0.7440', '0.6487', '0.5319', '0.5160', '0.4159']
cur_acc rrf_wo_na:  ['0.7612', '0.6349', '0.4553', '0.5747', '0.3780']
his_acc rrf_wo_na:  ['0.7612', '0.6746', '0.5316', '0.5079', '0.4139']
cur_acc_w_na:  ['0.6505', '0.3977', '0.3980', '0.3995', '0.2770']
his_acc_w_na:  ['0.6505', '0.5437', '0.3967', '0.3859', '0.3012']
cur_acc des_w_na:  ['0.6026', '0.4176', '0.2845', '0.3587', '0.2237']
his_acc des_w_na:  ['0.6026', '0.4759', '0.3728', '0.3539', '0.2726']
cur_acc rrf_w_na:  ['0.6200', '0.4470', '0.3180', '0.3680', '0.2473']
his_acc rrf_w_na:  ['0.6200', '0.5013', '0.3804', '0.3541', '0.2748']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 87.1189093CurrentTrain: epoch  0, batch     1 | loss: 103.2941159CurrentTrain: epoch  0, batch     2 | loss: 76.8644066CurrentTrain: epoch  0, batch     3 | loss: 17.2593478CurrentTrain: epoch  1, batch     0 | loss: 79.9051941CurrentTrain: epoch  1, batch     1 | loss: 72.9730500CurrentTrain: epoch  1, batch     2 | loss: 103.5401644CurrentTrain: epoch  1, batch     3 | loss: 14.3685518CurrentTrain: epoch  2, batch     0 | loss: 73.3238364CurrentTrain: epoch  2, batch     1 | loss: 66.8956003CurrentTrain: epoch  2, batch     2 | loss: 87.4348233CurrentTrain: epoch  2, batch     3 | loss: 11.8775259CurrentTrain: epoch  3, batch     0 | loss: 80.9787005CurrentTrain: epoch  3, batch     1 | loss: 67.1084950CurrentTrain: epoch  3, batch     2 | loss: 97.6538548CurrentTrain: epoch  3, batch     3 | loss: 20.4202923CurrentTrain: epoch  4, batch     0 | loss: 83.0431576CurrentTrain: epoch  4, batch     1 | loss: 66.4480214CurrentTrain: epoch  4, batch     2 | loss: 63.9337596CurrentTrain: epoch  4, batch     3 | loss: 6.4677828CurrentTrain: epoch  5, batch     0 | loss: 63.5978207CurrentTrain: epoch  5, batch     1 | loss: 78.9398777CurrentTrain: epoch  5, batch     2 | loss: 76.2595723CurrentTrain: epoch  5, batch     3 | loss: 21.9713959CurrentTrain: epoch  6, batch     0 | loss: 65.6031641CurrentTrain: epoch  6, batch     1 | loss: 66.7725931CurrentTrain: epoch  6, batch     2 | loss: 65.2566352CurrentTrain: epoch  6, batch     3 | loss: 4.6526722CurrentTrain: epoch  7, batch     0 | loss: 62.1977642CurrentTrain: epoch  7, batch     1 | loss: 64.9873815CurrentTrain: epoch  7, batch     2 | loss: 66.0100330CurrentTrain: epoch  7, batch     3 | loss: 19.4549985CurrentTrain: epoch  8, batch     0 | loss: 63.1552730CurrentTrain: epoch  8, batch     1 | loss: 61.7451769CurrentTrain: epoch  8, batch     2 | loss: 75.2834974CurrentTrain: epoch  8, batch     3 | loss: 21.0633571CurrentTrain: epoch  9, batch     0 | loss: 62.8784016CurrentTrain: epoch  9, batch     1 | loss: 62.1160542CurrentTrain: epoch  9, batch     2 | loss: 61.3906494CurrentTrain: epoch  9, batch     3 | loss: 15.8178675
MemoryTrain:  epoch  0, batch     0 | loss: 0.8455406MemoryTrain:  epoch  1, batch     0 | loss: 0.6622119MemoryTrain:  epoch  2, batch     0 | loss: 0.5913671MemoryTrain:  epoch  3, batch     0 | loss: 0.4487884MemoryTrain:  epoch  4, batch     0 | loss: 0.3471765MemoryTrain:  epoch  5, batch     0 | loss: 0.3127005MemoryTrain:  epoch  6, batch     0 | loss: 0.2441768MemoryTrain:  epoch  7, batch     0 | loss: 0.2093317MemoryTrain:  epoch  8, batch     0 | loss: 0.1955577MemoryTrain:  epoch  9, batch     0 | loss: 0.1830951

F1 score per class: {32: np.float64(0.0), 1: np.float64(0.0), 34: np.float64(0.8), 3: np.float64(0.7936507936507936), 7: np.float64(0.0), 40: np.float64(0.0), 9: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.5), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.30434782608695654)}
Micro-average F1 score: 0.3322475570032573
Weighted-average F1 score: 0.2884426279335042
F1 score per class: {32: np.float64(0.0), 1: np.float64(0.0), 34: np.float64(0.0), 3: np.float64(0.7272727272727273), 6: np.float64(0.6756756756756757), 7: np.float64(0.0), 40: np.float64(0.0), 9: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.15384615384615385), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.5793103448275863)}
Micro-average F1 score: 0.43243243243243246
Weighted-average F1 score: 0.3794304705027426
F1 score per class: {32: np.float64(0.0), 1: np.float64(0.0), 34: np.float64(0.7272727272727273), 3: np.float64(0.7246376811594203), 7: np.float64(0.0), 40: np.float64(0.0), 9: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.2857142857142857), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.581081081081081)}
Micro-average F1 score: 0.45768025078369906
Weighted-average F1 score: 0.4070151930173139

F1 score per class: {1: np.float64(0.136986301369863), 2: np.float64(0.45454545454545453), 3: np.float64(0.5497630331753555), 5: np.float64(0.7550200803212851), 6: np.float64(0.07547169811320754), 7: np.float64(0.05228758169934641), 8: np.float64(0.024390243902439025), 9: np.float64(0.7575757575757576), 10: np.float64(0.20606060606060606), 11: np.float64(0.11023622047244094), 12: np.float64(0.04225352112676056), 14: np.float64(0.06578947368421052), 16: np.float64(0.5797101449275363), 17: np.float64(0.15384615384615385), 18: np.float64(0.06557377049180328), 19: np.float64(0.5668016194331984), 20: np.float64(0.5348837209302325), 22: np.float64(0.4158415841584158), 24: np.float64(0.1), 26: np.float64(0.6547619047619048), 27: np.float64(0.0), 28: np.float64(0.15053763440860216), 29: np.float64(0.7182320441988951), 30: np.float64(0.8333333333333334), 31: np.float64(0.13333333333333333), 32: np.float64(0.6070038910505836), 33: np.float64(0.4), 34: np.float64(0.22279792746113988), 36: np.float64(0.21621621621621623), 39: np.float64(0.09523809523809523), 40: np.float64(0.08860759493670886)}
Micro-average F1 score: 0.33575229801644896
Weighted-average F1 score: 0.322839992009285
F1 score per class: {1: np.float64(0.17040358744394618), 2: np.float64(0.4), 3: np.float64(0.5338345864661654), 5: np.float64(0.6233766233766234), 6: np.float64(0.2706766917293233), 7: np.float64(0.05442176870748299), 8: np.float64(0.2803738317757009), 9: np.float64(0.4672897196261682), 10: np.float64(0.3048780487804878), 11: np.float64(0.06504065040650407), 12: np.float64(0.16042780748663102), 14: np.float64(0.050761421319796954), 16: np.float64(0.56), 17: np.float64(0.32), 18: np.float64(0.14285714285714285), 19: np.float64(0.550185873605948), 20: np.float64(0.5773195876288659), 22: np.float64(0.379746835443038), 24: np.float64(0.14634146341463414), 26: np.float64(0.6918918918918919), 27: np.float64(0.0), 28: np.float64(0.12), 29: np.float64(0.735632183908046), 30: np.float64(0.7391304347826086), 31: np.float64(0.02531645569620253), 32: np.float64(0.5878136200716846), 33: np.float64(0.4), 34: np.float64(0.20042643923240938), 36: np.float64(0.4854368932038835), 39: np.float64(0.13793103448275862), 40: np.float64(0.28378378378378377)}
Micro-average F1 score: 0.3617158870446217
Weighted-average F1 score: 0.3424582337395952
F1 score per class: {1: np.float64(0.17040358744394618), 2: np.float64(0.46153846153846156), 3: np.float64(0.532319391634981), 5: np.float64(0.6689895470383276), 6: np.float64(0.18487394957983194), 7: np.float64(0.05161290322580645), 8: np.float64(0.13186813186813187), 9: np.float64(0.5494505494505495), 10: np.float64(0.28735632183908044), 11: np.float64(0.06611570247933884), 12: np.float64(0.15053763440860216), 14: np.float64(0.07766990291262135), 16: np.float64(0.5675675675675675), 17: np.float64(0.42105263157894735), 18: np.float64(0.15), 19: np.float64(0.6065573770491803), 20: np.float64(0.5494505494505495), 22: np.float64(0.3793103448275862), 24: np.float64(0.08695652173913043), 26: np.float64(0.6966292134831461), 27: np.float64(0.0), 28: np.float64(0.1320754716981132), 29: np.float64(0.7272727272727273), 30: np.float64(0.8205128205128205), 31: np.float64(0.06896551724137931), 32: np.float64(0.5955882352941176), 33: np.float64(0.4), 34: np.float64(0.18585858585858586), 36: np.float64(0.3170731707317073), 39: np.float64(0.14814814814814814), 40: np.float64(0.2529411764705882)}
Micro-average F1 score: 0.35687235464468703
Weighted-average F1 score: 0.3414341484175372

F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.8), 9: np.float64(0.746268656716418), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.5), 32: np.float64(0.0), 34: np.float64(0.0), 40: np.float64(0.267515923566879)}
Micro-average F1 score: 0.2756756756756757
Weighted-average F1 score: 0.23205442235478657
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7272727272727273), 9: np.float64(0.5747126436781609), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.10526315789473684), 32: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 40: np.float64(0.5316455696202531)}
Micro-average F1 score: 0.34285714285714286
Weighted-average F1 score: 0.29104144633345586
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7272727272727273), 9: np.float64(0.6578947368421053), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.25), 32: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 40: np.float64(0.5276073619631901)}
Micro-average F1 score: 0.369620253164557
Weighted-average F1 score: 0.3163027494385932

F1 score per class: {1: np.float64(0.07692307692307693), 2: np.float64(0.2564102564102564), 3: np.float64(0.3790849673202614), 5: np.float64(0.5402298850574713), 6: np.float64(0.07017543859649122), 7: np.float64(0.027586206896551724), 8: np.float64(0.024390243902439025), 9: np.float64(0.6578947368421053), 10: np.float64(0.17989417989417988), 11: np.float64(0.1), 12: np.float64(0.031578947368421054), 14: np.float64(0.05405405405405406), 16: np.float64(0.37383177570093457), 17: np.float64(0.09523809523809523), 18: np.float64(0.043478260869565216), 19: np.float64(0.5405405405405406), 20: np.float64(0.3511450381679389), 22: np.float64(0.3146067415730337), 24: np.float64(0.09523809523809523), 26: np.float64(0.6010928961748634), 27: np.float64(0.0), 28: np.float64(0.08139534883720931), 29: np.float64(0.6467661691542289), 30: np.float64(0.7894736842105263), 31: np.float64(0.08333333333333333), 32: np.float64(0.46987951807228917), 33: np.float64(0.375), 34: np.float64(0.13230769230769232), 36: np.float64(0.1839080459770115), 39: np.float64(0.06451612903225806), 40: np.float64(0.06965174129353234)}
Micro-average F1 score: 0.24754770822186553
Weighted-average F1 score: 0.23067639546993637
F1 score per class: {1: np.float64(0.09523809523809523), 2: np.float64(0.21875), 3: np.float64(0.31277533039647576), 5: np.float64(0.37209302325581395), 6: np.float64(0.22085889570552147), 7: np.float64(0.026755852842809364), 8: np.float64(0.24390243902439024), 9: np.float64(0.36496350364963503), 10: np.float64(0.24154589371980675), 11: np.float64(0.06060606060606061), 12: np.float64(0.10238907849829351), 14: np.float64(0.0423728813559322), 16: np.float64(0.358974358974359), 17: np.float64(0.19047619047619047), 18: np.float64(0.0875), 19: np.float64(0.5016949152542373), 20: np.float64(0.32941176470588235), 22: np.float64(0.2727272727272727), 24: np.float64(0.11538461538461539), 26: np.float64(0.5953488372093023), 27: np.float64(0.0), 28: np.float64(0.06091370558375635), 29: np.float64(0.6666666666666666), 30: np.float64(0.68), 31: np.float64(0.013513513513513514), 32: np.float64(0.44324324324324327), 33: np.float64(0.3333333333333333), 34: np.float64(0.12384716732542819), 36: np.float64(0.3472222222222222), 39: np.float64(0.08163265306122448), 40: np.float64(0.22641509433962265)}
Micro-average F1 score: 0.24940546967895363
Weighted-average F1 score: 0.2323935769984241
F1 score per class: {1: np.float64(0.09523809523809523), 2: np.float64(0.24489795918367346), 3: np.float64(0.3211009174311927), 5: np.float64(0.4129032258064516), 6: np.float64(0.16541353383458646), 7: np.float64(0.024464831804281346), 8: np.float64(0.1276595744680851), 9: np.float64(0.45045045045045046), 10: np.float64(0.22935779816513763), 11: np.float64(0.06153846153846154), 12: np.float64(0.09688581314878893), 14: np.float64(0.06374501992031872), 16: np.float64(0.3559322033898305), 17: np.float64(0.25), 18: np.float64(0.0916030534351145), 19: np.float64(0.5714285714285714), 20: np.float64(0.32679738562091504), 22: np.float64(0.27586206896551724), 24: np.float64(0.07407407407407407), 26: np.float64(0.6262626262626263), 27: np.float64(0.0), 28: np.float64(0.06796116504854369), 29: np.float64(0.6597938144329897), 30: np.float64(0.7804878048780488), 31: np.float64(0.038461538461538464), 32: np.float64(0.44505494505494503), 33: np.float64(0.3333333333333333), 34: np.float64(0.1141439205955335), 36: np.float64(0.2549019607843137), 39: np.float64(0.08163265306122448), 40: np.float64(0.19861431870669746)}
Micro-average F1 score: 0.24914463452566096
Weighted-average F1 score: 0.23203057634440888
cur_acc_wo_na:  ['0.7608', '0.5172', '0.5488', '0.5770', '0.4045', '0.3322']
his_acc_wo_na:  ['0.7608', '0.6774', '0.5452', '0.5132', '0.4299', '0.3358']
cur_acc des_wo_na:  ['0.7440', '0.6059', '0.4119', '0.5638', '0.3460', '0.4324']
his_acc des_wo_na:  ['0.7440', '0.6487', '0.5319', '0.5160', '0.4159', '0.3617']
cur_acc rrf_wo_na:  ['0.7612', '0.6349', '0.4553', '0.5747', '0.3780', '0.4577']
his_acc rrf_wo_na:  ['0.7612', '0.6746', '0.5316', '0.5079', '0.4139', '0.3569']
cur_acc_w_na:  ['0.6505', '0.3977', '0.3980', '0.3995', '0.2770', '0.2757']
his_acc_w_na:  ['0.6505', '0.5437', '0.3967', '0.3859', '0.3012', '0.2475']
cur_acc des_w_na:  ['0.6026', '0.4176', '0.2845', '0.3587', '0.2237', '0.3429']
his_acc des_w_na:  ['0.6026', '0.4759', '0.3728', '0.3539', '0.2726', '0.2494']
cur_acc rrf_w_na:  ['0.6200', '0.4470', '0.3180', '0.3680', '0.2473', '0.3696']
his_acc rrf_w_na:  ['0.6200', '0.5013', '0.3804', '0.3541', '0.2748', '0.2491']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 97.4417980CurrentTrain: epoch  0, batch     1 | loss: 86.1234497CurrentTrain: epoch  0, batch     2 | loss: 86.1476237CurrentTrain: epoch  0, batch     3 | loss: 74.6287380CurrentTrain: epoch  1, batch     0 | loss: 77.6233540CurrentTrain: epoch  1, batch     1 | loss: 90.2525583CurrentTrain: epoch  1, batch     2 | loss: 87.9930121CurrentTrain: epoch  1, batch     3 | loss: 69.2969638CurrentTrain: epoch  2, batch     0 | loss: 70.4142107CurrentTrain: epoch  2, batch     1 | loss: 72.0258023CurrentTrain: epoch  2, batch     2 | loss: 84.4917688CurrentTrain: epoch  2, batch     3 | loss: 90.0043538CurrentTrain: epoch  3, batch     0 | loss: 79.7795567CurrentTrain: epoch  3, batch     1 | loss: 67.7332688CurrentTrain: epoch  3, batch     2 | loss: 102.3962862CurrentTrain: epoch  3, batch     3 | loss: 47.7155187CurrentTrain: epoch  4, batch     0 | loss: 76.9976522CurrentTrain: epoch  4, batch     1 | loss: 78.3048226CurrentTrain: epoch  4, batch     2 | loss: 96.9196160CurrentTrain: epoch  4, batch     3 | loss: 57.8825585CurrentTrain: epoch  5, batch     0 | loss: 65.0566545CurrentTrain: epoch  5, batch     1 | loss: 96.9132654CurrentTrain: epoch  5, batch     2 | loss: 79.1106158CurrentTrain: epoch  5, batch     3 | loss: 86.1871957CurrentTrain: epoch  6, batch     0 | loss: 63.6452305CurrentTrain: epoch  6, batch     1 | loss: 99.9753602CurrentTrain: epoch  6, batch     2 | loss: 81.0971249CurrentTrain: epoch  6, batch     3 | loss: 44.5044653CurrentTrain: epoch  7, batch     0 | loss: 78.0774627CurrentTrain: epoch  7, batch     1 | loss: 76.1032623CurrentTrain: epoch  7, batch     2 | loss: 66.0937968CurrentTrain: epoch  7, batch     3 | loss: 64.1212931CurrentTrain: epoch  8, batch     0 | loss: 119.5778943CurrentTrain: epoch  8, batch     1 | loss: 78.1421354CurrentTrain: epoch  8, batch     2 | loss: 67.2658437CurrentTrain: epoch  8, batch     3 | loss: 66.3747953CurrentTrain: epoch  9, batch     0 | loss: 62.4913320CurrentTrain: epoch  9, batch     1 | loss: 74.0711533CurrentTrain: epoch  9, batch     2 | loss: 79.9197283CurrentTrain: epoch  9, batch     3 | loss: 53.0110396
MemoryTrain:  epoch  0, batch     0 | loss: 0.9009483MemoryTrain:  epoch  1, batch     0 | loss: 0.7976664MemoryTrain:  epoch  2, batch     0 | loss: 0.6478070MemoryTrain:  epoch  3, batch     0 | loss: 0.5754468MemoryTrain:  epoch  4, batch     0 | loss: 0.4605864MemoryTrain:  epoch  5, batch     0 | loss: 0.4055989MemoryTrain:  epoch  6, batch     0 | loss: 0.3653597MemoryTrain:  epoch  7, batch     0 | loss: 0.3259216MemoryTrain:  epoch  8, batch     0 | loss: 0.2743284MemoryTrain:  epoch  9, batch     0 | loss: 0.2351014

F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.8181818181818182), 16: np.float64(0.0), 19: np.float64(0.0), 25: np.float64(0.4), 26: np.float64(0.0), 28: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.803921568627451), 37: np.float64(0.6041666666666666), 38: np.float64(0.47368421052631576), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.48095238095238096
Weighted-average F1 score: 0.3767352690568264
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.7272727272727273), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5063291139240507), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.7920792079207921), 36: np.float64(0.0), 37: np.float64(0.47706422018348627), 38: np.float64(0.6363636363636364), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3898916967509025
Weighted-average F1 score: 0.2707084537395771
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.782608695652174), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 25: np.float64(0.4594594594594595), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.7884615384615384), 36: np.float64(0.0), 37: np.float64(0.5192307692307693), 38: np.float64(0.6046511627906976), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4246031746031746
Weighted-average F1 score: 0.31018615174277964

F1 score per class: {1: np.float64(0.16877637130801687), 2: np.float64(0.43478260869565216), 3: np.float64(0.40993788819875776), 5: np.float64(0.8193832599118943), 6: np.float64(0.11009174311926606), 7: np.float64(0.038461538461538464), 8: np.float64(0.047058823529411764), 9: np.float64(0.7936507936507936), 10: np.float64(0.23255813953488372), 11: np.float64(0.11965811965811966), 12: np.float64(0.08), 14: np.float64(0.04918032786885246), 15: np.float64(0.35294117647058826), 16: np.float64(0.6024096385542169), 17: np.float64(0.0), 18: np.float64(0.04), 19: np.float64(0.5689655172413793), 20: np.float64(0.1694915254237288), 22: np.float64(0.3541666666666667), 24: np.float64(0.09523809523809523), 25: np.float64(0.4), 26: np.float64(0.6818181818181818), 27: np.float64(0.0), 28: np.float64(0.1518987341772152), 29: np.float64(0.8163265306122449), 30: np.float64(0.8648648648648649), 31: np.float64(0.0), 32: np.float64(0.5833333333333334), 33: np.float64(0.4), 34: np.float64(0.28169014084507044), 35: np.float64(0.34893617021276596), 36: np.float64(0.029850746268656716), 37: np.float64(0.19863013698630136), 38: np.float64(0.36), 39: np.float64(0.0), 40: np.float64(0.20114942528735633)}
Micro-average F1 score: 0.34858992140545536
Weighted-average F1 score: 0.3516635693494554
F1 score per class: {1: np.float64(0.15702479338842976), 2: np.float64(0.4117647058823529), 3: np.float64(0.43795620437956206), 5: np.float64(0.60625), 6: np.float64(0.33112582781456956), 7: np.float64(0.04), 8: np.float64(0.2857142857142857), 9: np.float64(0.4), 10: np.float64(0.3490566037735849), 11: np.float64(0.09448818897637795), 12: np.float64(0.2048780487804878), 14: np.float64(0.07531380753138076), 15: np.float64(0.34782608695652173), 16: np.float64(0.5148514851485149), 17: np.float64(0.0), 18: np.float64(0.19298245614035087), 19: np.float64(0.5047923322683706), 20: np.float64(0.5128205128205128), 22: np.float64(0.3459915611814346), 24: np.float64(0.11764705882352941), 25: np.float64(0.49382716049382713), 26: np.float64(0.6842105263157895), 27: np.float64(0.0), 28: np.float64(0.12), 29: np.float64(0.7936507936507936), 30: np.float64(0.7391304347826086), 31: np.float64(0.03076923076923077), 32: np.float64(0.60431654676259), 33: np.float64(0.375), 34: np.float64(0.22033898305084745), 35: np.float64(0.3418803418803419), 36: np.float64(0.35051546391752575), 37: np.float64(0.14647887323943662), 38: np.float64(0.36363636363636365), 39: np.float64(0.0), 40: np.float64(0.2508250825082508)}
Micro-average F1 score: 0.3438395415472779
Weighted-average F1 score: 0.3245137864353422
F1 score per class: {1: np.float64(0.18106995884773663), 2: np.float64(0.4666666666666667), 3: np.float64(0.4701195219123506), 5: np.float64(0.6884057971014492), 6: np.float64(0.24), 7: np.float64(0.03636363636363636), 8: np.float64(0.13861386138613863), 9: np.float64(0.5882352941176471), 10: np.float64(0.31313131313131315), 11: np.float64(0.112), 12: np.float64(0.20588235294117646), 14: np.float64(0.05660377358490566), 15: np.float64(0.32727272727272727), 16: np.float64(0.5252525252525253), 17: np.float64(0.0), 18: np.float64(0.2318840579710145), 19: np.float64(0.5467128027681661), 20: np.float64(0.5135135135135135), 22: np.float64(0.3565217391304348), 24: np.float64(0.08695652173913043), 25: np.float64(0.4594594594594595), 26: np.float64(0.6956521739130435), 27: np.float64(0.0), 28: np.float64(0.12244897959183673), 29: np.float64(0.7894736842105263), 30: np.float64(0.8292682926829268), 31: np.float64(0.07407407407407407), 32: np.float64(0.5971223021582733), 33: np.float64(0.375), 34: np.float64(0.22570532915360503), 35: np.float64(0.3416666666666667), 36: np.float64(0.22784810126582278), 37: np.float64(0.1447721179624665), 38: np.float64(0.33766233766233766), 39: np.float64(0.0), 40: np.float64(0.2275449101796407)}
Micro-average F1 score: 0.34777629318572245
Weighted-average F1 score: 0.3319231129665908

F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.6), 16: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 25: np.float64(0.3939393939393939), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.7256637168141593), 37: np.float64(0.5043478260869565), 38: np.float64(0.45), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.36462093862815886
Weighted-average F1 score: 0.2709502334062663
F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.5), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.4819277108433735), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.6779661016949152), 36: np.float64(0.0), 37: np.float64(0.39097744360902253), 38: np.float64(0.5490196078431373), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2710163111668758
Weighted-average F1 score: 0.1888125708281119
F1 score per class: {1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.5625), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 25: np.float64(0.4358974358974359), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.6890756302521008), 36: np.float64(0.0), 37: np.float64(0.4251968503937008), 38: np.float64(0.52), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.29763560500695413
Weighted-average F1 score: 0.21330823391284584

F1 score per class: {1: np.float64(0.09592326139088729), 2: np.float64(0.2564102564102564), 3: np.float64(0.29596412556053814), 5: np.float64(0.6714801444043321), 6: np.float64(0.1016949152542373), 7: np.float64(0.020066889632107024), 8: np.float64(0.045454545454545456), 9: np.float64(0.6666666666666666), 10: np.float64(0.2), 11: np.float64(0.11764705882352941), 12: np.float64(0.05286343612334802), 14: np.float64(0.040268456375838924), 15: np.float64(0.23076923076923078), 16: np.float64(0.37037037037037035), 17: np.float64(0.0), 18: np.float64(0.03278688524590164), 19: np.float64(0.5301204819277109), 20: np.float64(0.13333333333333333), 22: np.float64(0.27091633466135456), 24: np.float64(0.09523809523809523), 25: np.float64(0.3939393939393939), 26: np.float64(0.6153846153846154), 27: np.float64(0.0), 28: np.float64(0.075), 29: np.float64(0.7111111111111111), 30: np.float64(0.8205128205128205), 31: np.float64(0.0), 32: np.float64(0.4463768115942029), 33: np.float64(0.375), 34: np.float64(0.16393442622950818), 35: np.float64(0.22404371584699453), 36: np.float64(0.028985507246376812), 37: np.float64(0.11553784860557768), 38: np.float64(0.21176470588235294), 39: np.float64(0.0), 40: np.float64(0.15418502202643172)}
Micro-average F1 score: 0.25451476793248945
Weighted-average F1 score: 0.24190779091331607
F1 score per class: {1: np.float64(0.08388520971302428), 2: np.float64(0.2222222222222222), 3: np.float64(0.28776978417266186), 5: np.float64(0.420824295010846), 6: np.float64(0.26455026455026454), 7: np.float64(0.019230769230769232), 8: np.float64(0.23841059602649006), 9: np.float64(0.2824858757062147), 10: np.float64(0.23492063492063492), 11: np.float64(0.08888888888888889), 12: np.float64(0.11444141689373297), 14: np.float64(0.06315789473684211), 15: np.float64(0.21052631578947367), 16: np.float64(0.31137724550898205), 17: np.float64(0.0), 18: np.float64(0.1073170731707317), 19: np.float64(0.4450704225352113), 20: np.float64(0.32), 22: np.float64(0.2523076923076923), 24: np.float64(0.08955223880597014), 25: np.float64(0.43478260869565216), 26: np.float64(0.5855855855855856), 27: np.float64(0.0), 28: np.float64(0.05853658536585366), 29: np.float64(0.6880733944954128), 30: np.float64(0.6666666666666666), 31: np.float64(0.01639344262295082), 32: np.float64(0.4528301886792453), 33: np.float64(0.2608695652173913), 34: np.float64(0.13660245183887915), 35: np.float64(0.21333333333333335), 36: np.float64(0.2446043165467626), 37: np.float64(0.09269162210338681), 38: np.float64(0.20437956204379562), 39: np.float64(0.0), 40: np.float64(0.18052256532066507)}
Micro-average F1 score: 0.23380418899171942
Weighted-average F1 score: 0.2179571384314082
F1 score per class: {1: np.float64(0.09799554565701558), 2: np.float64(0.27450980392156865), 3: np.float64(0.32065217391304346), 5: np.float64(0.4896907216494845), 6: np.float64(0.20833333333333334), 7: np.float64(0.017543859649122806), 8: np.float64(0.12612612612612611), 9: np.float64(0.47619047619047616), 10: np.float64(0.23308270676691728), 11: np.float64(0.10687022900763359), 12: np.float64(0.11444141689373297), 14: np.float64(0.04580152671755725), 15: np.float64(0.20454545454545456), 16: np.float64(0.325), 17: np.float64(0.0), 18: np.float64(0.13114754098360656), 19: np.float64(0.5031847133757962), 20: np.float64(0.31932773109243695), 22: np.float64(0.26198083067092653), 24: np.float64(0.07142857142857142), 25: np.float64(0.39080459770114945), 26: np.float64(0.6124401913875598), 27: np.float64(0.0), 28: np.float64(0.056338028169014086), 29: np.float64(0.6880733944954128), 30: np.float64(0.7727272727272727), 31: np.float64(0.04), 32: np.float64(0.4450402144772118), 33: np.float64(0.24), 34: np.float64(0.13714285714285715), 35: np.float64(0.21188630490956073), 36: np.float64(0.19148936170212766), 37: np.float64(0.08866995073891626), 38: np.float64(0.1897810218978102), 39: np.float64(0.0), 40: np.float64(0.16101694915254236)}
Micro-average F1 score: 0.23873165618448638
Weighted-average F1 score: 0.22206735652804535
cur_acc_wo_na:  ['0.7608', '0.5172', '0.5488', '0.5770', '0.4045', '0.3322', '0.4810']
his_acc_wo_na:  ['0.7608', '0.6774', '0.5452', '0.5132', '0.4299', '0.3358', '0.3486']
cur_acc des_wo_na:  ['0.7440', '0.6059', '0.4119', '0.5638', '0.3460', '0.4324', '0.3899']
his_acc des_wo_na:  ['0.7440', '0.6487', '0.5319', '0.5160', '0.4159', '0.3617', '0.3438']
cur_acc rrf_wo_na:  ['0.7612', '0.6349', '0.4553', '0.5747', '0.3780', '0.4577', '0.4246']
his_acc rrf_wo_na:  ['0.7612', '0.6746', '0.5316', '0.5079', '0.4139', '0.3569', '0.3478']
cur_acc_w_na:  ['0.6505', '0.3977', '0.3980', '0.3995', '0.2770', '0.2757', '0.3646']
his_acc_w_na:  ['0.6505', '0.5437', '0.3967', '0.3859', '0.3012', '0.2475', '0.2545']
cur_acc des_w_na:  ['0.6026', '0.4176', '0.2845', '0.3587', '0.2237', '0.3429', '0.2710']
his_acc des_w_na:  ['0.6026', '0.4759', '0.3728', '0.3539', '0.2726', '0.2494', '0.2338']
cur_acc rrf_w_na:  ['0.6200', '0.4470', '0.3180', '0.3680', '0.2473', '0.3696', '0.2976']
his_acc rrf_w_na:  ['0.6200', '0.5013', '0.3804', '0.3541', '0.2748', '0.2491', '0.2387']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 96.4209785CurrentTrain: epoch  0, batch     1 | loss: 153.0550886CurrentTrain: epoch  0, batch     2 | loss: 85.7223152CurrentTrain: epoch  0, batch     3 | loss: 80.7245824CurrentTrain: epoch  1, batch     0 | loss: 91.0752372CurrentTrain: epoch  1, batch     1 | loss: 81.1858765CurrentTrain: epoch  1, batch     2 | loss: 78.5162595CurrentTrain: epoch  1, batch     3 | loss: 71.5845150CurrentTrain: epoch  2, batch     0 | loss: 110.4971038CurrentTrain: epoch  2, batch     1 | loss: 75.5343494CurrentTrain: epoch  2, batch     2 | loss: 83.4084801CurrentTrain: epoch  2, batch     3 | loss: 84.5253465CurrentTrain: epoch  3, batch     0 | loss: 105.6271396CurrentTrain: epoch  3, batch     1 | loss: 88.0026943CurrentTrain: epoch  3, batch     2 | loss: 78.7494823CurrentTrain: epoch  3, batch     3 | loss: 65.7170424CurrentTrain: epoch  4, batch     0 | loss: 81.1406457CurrentTrain: epoch  4, batch     1 | loss: 97.4668410CurrentTrain: epoch  4, batch     2 | loss: 129.5381695CurrentTrain: epoch  4, batch     3 | loss: 66.2709792CurrentTrain: epoch  5, batch     0 | loss: 77.4947968CurrentTrain: epoch  5, batch     1 | loss: 81.1867321CurrentTrain: epoch  5, batch     2 | loss: 86.5043168CurrentTrain: epoch  5, batch     3 | loss: 76.3086555CurrentTrain: epoch  6, batch     0 | loss: 101.2174277CurrentTrain: epoch  6, batch     1 | loss: 67.4257006CurrentTrain: epoch  6, batch     2 | loss: 77.5927455CurrentTrain: epoch  6, batch     3 | loss: 64.7633056CurrentTrain: epoch  7, batch     0 | loss: 82.0416393CurrentTrain: epoch  7, batch     1 | loss: 66.4635278CurrentTrain: epoch  7, batch     2 | loss: 76.1976448CurrentTrain: epoch  7, batch     3 | loss: 79.5534027CurrentTrain: epoch  8, batch     0 | loss: 102.2113869CurrentTrain: epoch  8, batch     1 | loss: 77.4989544CurrentTrain: epoch  8, batch     2 | loss: 79.0464433CurrentTrain: epoch  8, batch     3 | loss: 59.5092091CurrentTrain: epoch  9, batch     0 | loss: 66.2087588CurrentTrain: epoch  9, batch     1 | loss: 74.8858254CurrentTrain: epoch  9, batch     2 | loss: 99.1400981CurrentTrain: epoch  9, batch     3 | loss: 76.0667998
MemoryTrain:  epoch  0, batch     0 | loss: 0.8573301MemoryTrain:  epoch  1, batch     0 | loss: 0.7359675MemoryTrain:  epoch  2, batch     0 | loss: 0.6048330MemoryTrain:  epoch  3, batch     0 | loss: 0.4474872MemoryTrain:  epoch  4, batch     0 | loss: 0.3947366MemoryTrain:  epoch  5, batch     0 | loss: 0.3423687MemoryTrain:  epoch  6, batch     0 | loss: 0.3006669MemoryTrain:  epoch  7, batch     0 | loss: 0.2777815MemoryTrain:  epoch  8, batch     0 | loss: 0.2553027MemoryTrain:  epoch  9, batch     0 | loss: 0.2228544

F1 score per class: {0: np.float64(0.88), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.9090909090909091), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.13333333333333333), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.32558139534883723), 23: np.float64(0.7415730337078652), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.6411290322580645
Weighted-average F1 score: 0.5395553861744885
F1 score per class: {0: np.float64(0.7070707070707071), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8393782383419689), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.07407407407407407), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.5373134328358209), 22: np.float64(0.0), 23: np.float64(0.8089887640449438), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5181818181818182
Weighted-average F1 score: 0.401934093876804
F1 score per class: {0: np.float64(0.7586206896551724), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8541666666666666), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.07142857142857142), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.5714285714285714), 22: np.float64(0.0), 23: np.float64(0.7777777777777778), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5502471169686985
Weighted-average F1 score: 0.42864957025609257

F1 score per class: {0: np.float64(0.4583333333333333), 1: np.float64(0.15873015873015872), 2: np.float64(0.3870967741935484), 3: np.float64(0.4155844155844156), 4: np.float64(0.9042553191489362), 5: np.float64(0.8157894736842105), 6: np.float64(0.10714285714285714), 7: np.float64(0.041379310344827586), 8: np.float64(0.023809523809523808), 9: np.float64(0.78125), 10: np.float64(0.15827338129496402), 11: np.float64(0.11666666666666667), 12: np.float64(0.0), 13: np.float64(0.014814814814814815), 14: np.float64(0.02564102564102564), 15: np.float64(0.4666666666666667), 16: np.float64(0.5970149253731343), 17: np.float64(0.0), 18: np.float64(0.1111111111111111), 19: np.float64(0.5701357466063348), 20: np.float64(0.2857142857142857), 21: np.float64(0.07179487179487179), 22: np.float64(0.05084745762711865), 23: np.float64(0.6666666666666666), 24: np.float64(0.1), 25: np.float64(0.44776119402985076), 26: np.float64(0.6744186046511628), 27: np.float64(0.0), 28: np.float64(0.16129032258064516), 29: np.float64(0.79), 30: np.float64(0.8648648648648649), 31: np.float64(0.0), 32: np.float64(0.5824561403508772), 33: np.float64(0.375), 34: np.float64(0.2781456953642384), 35: np.float64(0.4095238095238095), 36: np.float64(0.029850746268656716), 37: np.float64(0.22033898305084745), 38: np.float64(0.3404255319148936), 39: np.float64(0.0), 40: np.float64(0.27049180327868855)}
Micro-average F1 score: 0.3686814368681437
Weighted-average F1 score: 0.37628757996129986
F1 score per class: {0: np.float64(0.20771513353115728), 1: np.float64(0.17543859649122806), 2: np.float64(0.22641509433962265), 3: np.float64(0.40131578947368424), 4: np.float64(0.8140703517587939), 5: np.float64(0.6295081967213115), 6: np.float64(0.2028985507246377), 7: np.float64(0.04145077720207254), 8: np.float64(0.25196850393700787), 9: np.float64(0.46296296296296297), 10: np.float64(0.2717391304347826), 11: np.float64(0.112), 12: np.float64(0.15555555555555556), 13: np.float64(0.009389671361502348), 14: np.float64(0.06557377049180328), 15: np.float64(0.42857142857142855), 16: np.float64(0.5647058823529412), 17: np.float64(0.0), 18: np.float64(0.25), 19: np.float64(0.5277777777777778), 20: np.float64(0.4835164835164835), 21: np.float64(0.12903225806451613), 22: np.float64(0.1095890410958904), 23: np.float64(0.6728971962616822), 24: np.float64(0.08695652173913043), 25: np.float64(0.5542168674698795), 26: np.float64(0.6403940886699507), 27: np.float64(0.0), 28: np.float64(0.11267605633802817), 29: np.float64(0.8), 30: np.float64(0.723404255319149), 31: np.float64(0.10526315789473684), 32: np.float64(0.5742574257425742), 33: np.float64(0.35294117647058826), 34: np.float64(0.2653061224489796), 35: np.float64(0.32684824902723736), 36: np.float64(0.32608695652173914), 37: np.float64(0.18556701030927836), 38: np.float64(0.34782608695652173), 39: np.float64(0.1111111111111111), 40: np.float64(0.3157894736842105)}
Micro-average F1 score: 0.3429302623160589
Weighted-average F1 score: 0.323589999510063
F1 score per class: {0: np.float64(0.2907488986784141), 1: np.float64(0.17316017316017315), 2: np.float64(0.25), 3: np.float64(0.4892703862660944), 4: np.float64(0.8367346938775511), 5: np.float64(0.7084870848708487), 6: np.float64(0.16), 7: np.float64(0.0427807486631016), 8: np.float64(0.06741573033707865), 9: np.float64(0.6944444444444444), 10: np.float64(0.2711864406779661), 11: np.float64(0.11290322580645161), 12: np.float64(0.16304347826086957), 13: np.float64(0.00966183574879227), 14: np.float64(0.03636363636363636), 15: np.float64(0.45161290322580644), 16: np.float64(0.5925925925925926), 17: np.float64(0.0), 18: np.float64(0.2647058823529412), 19: np.float64(0.5747126436781609), 20: np.float64(0.4819277108433735), 21: np.float64(0.11940298507462686), 22: np.float64(0.08888888888888889), 23: np.float64(0.660377358490566), 24: np.float64(0.09523809523809523), 25: np.float64(0.5405405405405406), 26: np.float64(0.6526315789473685), 27: np.float64(0.0), 28: np.float64(0.125), 29: np.float64(0.8020833333333334), 30: np.float64(0.8292682926829268), 31: np.float64(0.15384615384615385), 32: np.float64(0.5667752442996743), 33: np.float64(0.3333333333333333), 34: np.float64(0.2857142857142857), 35: np.float64(0.3464566929133858), 36: np.float64(0.28205128205128205), 37: np.float64(0.20422535211267606), 38: np.float64(0.3373493975903614), 39: np.float64(0.10526315789473684), 40: np.float64(0.2968197879858657)}
Micro-average F1 score: 0.3574660633484163
Weighted-average F1 score: 0.3410790191788878

F1 score per class: {0: np.float64(0.8354430379746836), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8629441624365483), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.06451612903225806), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.23333333333333334), 23: np.float64(0.6875), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.49074074074074076
Weighted-average F1 score: 0.3759948069457646
F1 score per class: {0: np.float64(0.6363636363636364), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.7980295566502463), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.03636363636363636), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.3956043956043956), 22: np.float64(0.0), 23: np.float64(0.6666666666666666), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.37012987012987014
Weighted-average F1 score: 0.2768078153560128
F1 score per class: {0: np.float64(0.6947368421052632), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8078817733990148), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.03508771929824561), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.38095238095238093), 22: np.float64(0.0), 23: np.float64(0.6422018348623854), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.39294117647058824
Weighted-average F1 score: 0.29418747755183594

F1 score per class: {0: np.float64(0.3055555555555556), 1: np.float64(0.08645533141210375), 2: np.float64(0.23076923076923078), 3: np.float64(0.29767441860465116), 4: np.float64(0.8333333333333334), 5: np.float64(0.6619217081850534), 6: np.float64(0.1), 7: np.float64(0.02158273381294964), 8: np.float64(0.022727272727272728), 9: np.float64(0.6944444444444444), 10: np.float64(0.14864864864864866), 11: np.float64(0.10071942446043165), 12: np.float64(0.0), 13: np.float64(0.007142857142857143), 14: np.float64(0.022222222222222223), 15: np.float64(0.2692307692307692), 16: np.float64(0.40816326530612246), 17: np.float64(0.0), 18: np.float64(0.06666666666666667), 19: np.float64(0.5361702127659574), 20: np.float64(0.2), 21: np.float64(0.04827586206896552), 22: np.float64(0.046875), 23: np.float64(0.5409836065573771), 24: np.float64(0.09523809523809523), 25: np.float64(0.43478260869565216), 26: np.float64(0.5979381443298969), 27: np.float64(0.0), 28: np.float64(0.08928571428571429), 29: np.float64(0.6781115879828327), 30: np.float64(0.8), 31: np.float64(0.0), 32: np.float64(0.4356955380577428), 33: np.float64(0.3333333333333333), 34: np.float64(0.17721518987341772), 35: np.float64(0.26461538461538464), 36: np.float64(0.028985507246376812), 37: np.float64(0.14484679665738162), 38: np.float64(0.2318840579710145), 39: np.float64(0.0), 40: np.float64(0.22758620689655173)}
Micro-average F1 score: 0.2733652312599681
Weighted-average F1 score: 0.26118811790543306
F1 score per class: {0: np.float64(0.13618677042801555), 1: np.float64(0.09280742459396751), 2: np.float64(0.13953488372093023), 3: np.float64(0.2525879917184265), 4: np.float64(0.7136563876651982), 5: np.float64(0.43243243243243246), 6: np.float64(0.1686746987951807), 7: np.float64(0.01990049751243781), 8: np.float64(0.2077922077922078), 9: np.float64(0.36231884057971014), 10: np.float64(0.199203187250996), 11: np.float64(0.10852713178294573), 12: np.float64(0.1003584229390681), 13: np.float64(0.004739336492890996), 14: np.float64(0.057971014492753624), 15: np.float64(0.3076923076923077), 16: np.float64(0.32), 17: np.float64(0.0), 18: np.float64(0.1256544502617801), 19: np.float64(0.4691358024691358), 20: np.float64(0.2716049382716049), 21: np.float64(0.08737864077669903), 22: np.float64(0.0893854748603352), 23: np.float64(0.5034965034965035), 24: np.float64(0.06896551724137931), 25: np.float64(0.5227272727272727), 26: np.float64(0.5394190871369294), 27: np.float64(0.0), 28: np.float64(0.05128205128205128), 29: np.float64(0.6666666666666666), 30: np.float64(0.6181818181818182), 31: np.float64(0.046511627906976744), 32: np.float64(0.41626794258373206), 33: np.float64(0.23076923076923078), 34: np.float64(0.16352201257861634), 35: np.float64(0.20638820638820637), 36: np.float64(0.24), 37: np.float64(0.11713665943600868), 38: np.float64(0.19631901840490798), 39: np.float64(0.08), 40: np.float64(0.24778761061946902)}
Micro-average F1 score: 0.23289159243971322
Weighted-average F1 score: 0.215477104024684
F1 score per class: {0: np.float64(0.18384401114206128), 1: np.float64(0.09433962264150944), 2: np.float64(0.15789473684210525), 3: np.float64(0.3202247191011236), 4: np.float64(0.7488584474885844), 5: np.float64(0.5), 6: np.float64(0.14285714285714285), 7: np.float64(0.02077922077922078), 8: np.float64(0.061855670103092786), 9: np.float64(0.5882352941176471), 10: np.float64(0.21145374449339208), 11: np.float64(0.10852713178294573), 12: np.float64(0.1056338028169014), 13: np.float64(0.004629629629629629), 14: np.float64(0.032520325203252036), 15: np.float64(0.2978723404255319), 16: np.float64(0.3356643356643357), 17: np.float64(0.0), 18: np.float64(0.1232876712328767), 19: np.float64(0.5300353356890459), 20: np.float64(0.27586206896551724), 21: np.float64(0.08020050125313283), 22: np.float64(0.07453416149068323), 23: np.float64(0.49645390070921985), 24: np.float64(0.09090909090909091), 25: np.float64(0.47619047619047616), 26: np.float64(0.5662100456621004), 27: np.float64(0.0), 28: np.float64(0.06134969325153374), 29: np.float64(0.6754385964912281), 30: np.float64(0.7727272727272727), 31: np.float64(0.07407407407407407), 32: np.float64(0.4182692307692308), 33: np.float64(0.2222222222222222), 34: np.float64(0.16551724137931034), 35: np.float64(0.2141119221411192), 36: np.float64(0.25287356321839083), 37: np.float64(0.1226215644820296), 38: np.float64(0.18666666666666668), 39: np.float64(0.07692307692307693), 40: np.float64(0.23529411764705882)}
Micro-average F1 score: 0.24443651076996312
Weighted-average F1 score: 0.22562913694731168
cur_acc_wo_na:  ['0.7608', '0.5172', '0.5488', '0.5770', '0.4045', '0.3322', '0.4810', '0.6411']
his_acc_wo_na:  ['0.7608', '0.6774', '0.5452', '0.5132', '0.4299', '0.3358', '0.3486', '0.3687']
cur_acc des_wo_na:  ['0.7440', '0.6059', '0.4119', '0.5638', '0.3460', '0.4324', '0.3899', '0.5182']
his_acc des_wo_na:  ['0.7440', '0.6487', '0.5319', '0.5160', '0.4159', '0.3617', '0.3438', '0.3429']
cur_acc rrf_wo_na:  ['0.7612', '0.6349', '0.4553', '0.5747', '0.3780', '0.4577', '0.4246', '0.5502']
his_acc rrf_wo_na:  ['0.7612', '0.6746', '0.5316', '0.5079', '0.4139', '0.3569', '0.3478', '0.3575']
cur_acc_w_na:  ['0.6505', '0.3977', '0.3980', '0.3995', '0.2770', '0.2757', '0.3646', '0.4907']
his_acc_w_na:  ['0.6505', '0.5437', '0.3967', '0.3859', '0.3012', '0.2475', '0.2545', '0.2734']
cur_acc des_w_na:  ['0.6026', '0.4176', '0.2845', '0.3587', '0.2237', '0.3429', '0.2710', '0.3701']
his_acc des_w_na:  ['0.6026', '0.4759', '0.3728', '0.3539', '0.2726', '0.2494', '0.2338', '0.2329']
cur_acc rrf_w_na:  ['0.6200', '0.4470', '0.3180', '0.3680', '0.2473', '0.3696', '0.2976', '0.3929']
his_acc rrf_w_na:  ['0.6200', '0.5013', '0.3804', '0.3541', '0.2748', '0.2491', '0.2387', '0.2444']
--------Round  2
seed:  300
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 2 3 1 5 6 0 4]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 84.9187680CurrentTrain: epoch  0, batch     1 | loss: 80.0199978CurrentTrain: epoch  0, batch     2 | loss: 102.9457867CurrentTrain: epoch  0, batch     3 | loss: 102.5281812CurrentTrain: epoch  0, batch     4 | loss: 87.8082038CurrentTrain: epoch  0, batch     5 | loss: 119.6328846CurrentTrain: epoch  0, batch     6 | loss: 100.7057848CurrentTrain: epoch  0, batch     7 | loss: 119.5316946CurrentTrain: epoch  0, batch     8 | loss: 86.4099428CurrentTrain: epoch  0, batch     9 | loss: 119.0478053CurrentTrain: epoch  0, batch    10 | loss: 86.2000083CurrentTrain: epoch  0, batch    11 | loss: 86.7335103CurrentTrain: epoch  0, batch    12 | loss: 86.6683440CurrentTrain: epoch  0, batch    13 | loss: 119.0058283CurrentTrain: epoch  0, batch    14 | loss: 147.1399947CurrentTrain: epoch  0, batch    15 | loss: 118.1817342CurrentTrain: epoch  0, batch    16 | loss: 118.7256320CurrentTrain: epoch  0, batch    17 | loss: 99.7998787CurrentTrain: epoch  0, batch    18 | loss: 146.1597182CurrentTrain: epoch  0, batch    19 | loss: 100.2008405CurrentTrain: epoch  0, batch    20 | loss: 76.3631628CurrentTrain: epoch  0, batch    21 | loss: 88.1269900CurrentTrain: epoch  0, batch    22 | loss: 86.9986979CurrentTrain: epoch  0, batch    23 | loss: 117.9520208CurrentTrain: epoch  0, batch    24 | loss: 117.1197408CurrentTrain: epoch  0, batch    25 | loss: 117.7597435CurrentTrain: epoch  0, batch    26 | loss: 85.2126467CurrentTrain: epoch  0, batch    27 | loss: 193.2707986CurrentTrain: epoch  0, batch    28 | loss: 99.2459605CurrentTrain: epoch  0, batch    29 | loss: 99.6039982CurrentTrain: epoch  0, batch    30 | loss: 99.2192926CurrentTrain: epoch  0, batch    31 | loss: 85.5366719CurrentTrain: epoch  0, batch    32 | loss: 118.3739336CurrentTrain: epoch  0, batch    33 | loss: 84.9945147CurrentTrain: epoch  0, batch    34 | loss: 98.7332437CurrentTrain: epoch  0, batch    35 | loss: 98.7354712CurrentTrain: epoch  0, batch    36 | loss: 117.7523000CurrentTrain: epoch  0, batch    37 | loss: 97.3122916CurrentTrain: epoch  0, batch    38 | loss: 98.3881965CurrentTrain: epoch  0, batch    39 | loss: 116.4831429CurrentTrain: epoch  0, batch    40 | loss: 84.6533132CurrentTrain: epoch  0, batch    41 | loss: 98.6010665CurrentTrain: epoch  0, batch    42 | loss: 146.7404844CurrentTrain: epoch  0, batch    43 | loss: 117.3025780CurrentTrain: epoch  0, batch    44 | loss: 98.1511438CurrentTrain: epoch  0, batch    45 | loss: 97.8169316CurrentTrain: epoch  0, batch    46 | loss: 84.4188934CurrentTrain: epoch  0, batch    47 | loss: 97.1033893CurrentTrain: epoch  0, batch    48 | loss: 97.2299848CurrentTrain: epoch  0, batch    49 | loss: 97.0385384CurrentTrain: epoch  0, batch    50 | loss: 85.0370591CurrentTrain: epoch  0, batch    51 | loss: 116.9927158CurrentTrain: epoch  0, batch    52 | loss: 73.3928127CurrentTrain: epoch  0, batch    53 | loss: 116.9571940CurrentTrain: epoch  0, batch    54 | loss: 95.5225839CurrentTrain: epoch  0, batch    55 | loss: 114.5598693CurrentTrain: epoch  0, batch    56 | loss: 143.7436872CurrentTrain: epoch  0, batch    57 | loss: 71.1116787CurrentTrain: epoch  0, batch    58 | loss: 114.4533783CurrentTrain: epoch  0, batch    59 | loss: 80.4369899CurrentTrain: epoch  0, batch    60 | loss: 114.1338427CurrentTrain: epoch  0, batch    61 | loss: 96.4346030CurrentTrain: epoch  0, batch    62 | loss: 96.1101344CurrentTrain: epoch  0, batch    63 | loss: 70.9212957CurrentTrain: epoch  0, batch    64 | loss: 114.6551841CurrentTrain: epoch  0, batch    65 | loss: 92.4424030CurrentTrain: epoch  0, batch    66 | loss: 95.9603015CurrentTrain: epoch  0, batch    67 | loss: 139.3209380CurrentTrain: epoch  0, batch    68 | loss: 111.4751610CurrentTrain: epoch  0, batch    69 | loss: 81.9943559CurrentTrain: epoch  0, batch    70 | loss: 78.2724603CurrentTrain: epoch  0, batch    71 | loss: 80.4069608CurrentTrain: epoch  0, batch    72 | loss: 115.8023921CurrentTrain: epoch  0, batch    73 | loss: 95.2705177CurrentTrain: epoch  0, batch    74 | loss: 77.8411088CurrentTrain: epoch  0, batch    75 | loss: 93.6180985CurrentTrain: epoch  0, batch    76 | loss: 70.7540697CurrentTrain: epoch  0, batch    77 | loss: 94.6750389CurrentTrain: epoch  0, batch    78 | loss: 81.8651328CurrentTrain: epoch  0, batch    79 | loss: 114.6223270CurrentTrain: epoch  0, batch    80 | loss: 94.2405008CurrentTrain: epoch  0, batch    81 | loss: 93.6410439CurrentTrain: epoch  0, batch    82 | loss: 82.1762774CurrentTrain: epoch  0, batch    83 | loss: 89.1485012CurrentTrain: epoch  0, batch    84 | loss: 111.7065442CurrentTrain: epoch  0, batch    85 | loss: 92.9460507CurrentTrain: epoch  0, batch    86 | loss: 91.2194375CurrentTrain: epoch  0, batch    87 | loss: 111.3347827CurrentTrain: epoch  0, batch    88 | loss: 94.1210962CurrentTrain: epoch  0, batch    89 | loss: 111.1485411CurrentTrain: epoch  0, batch    90 | loss: 92.2613774CurrentTrain: epoch  0, batch    91 | loss: 78.5373530CurrentTrain: epoch  0, batch    92 | loss: 80.0321951CurrentTrain: epoch  0, batch    93 | loss: 94.5649414CurrentTrain: epoch  0, batch    94 | loss: 92.5733750CurrentTrain: epoch  0, batch    95 | loss: 118.3611172CurrentTrain: epoch  1, batch     0 | loss: 78.9225374CurrentTrain: epoch  1, batch     1 | loss: 78.1650505CurrentTrain: epoch  1, batch     2 | loss: 111.0761205CurrentTrain: epoch  1, batch     3 | loss: 79.2543597CurrentTrain: epoch  1, batch     4 | loss: 76.5683043CurrentTrain: epoch  1, batch     5 | loss: 106.9450440CurrentTrain: epoch  1, batch     6 | loss: 93.6121142CurrentTrain: epoch  1, batch     7 | loss: 75.9554863CurrentTrain: epoch  1, batch     8 | loss: 80.8383739CurrentTrain: epoch  1, batch     9 | loss: 93.3446964CurrentTrain: epoch  1, batch    10 | loss: 107.4971623CurrentTrain: epoch  1, batch    11 | loss: 113.3000698CurrentTrain: epoch  1, batch    12 | loss: 108.4427548CurrentTrain: epoch  1, batch    13 | loss: 110.4966208CurrentTrain: epoch  1, batch    14 | loss: 91.5611413CurrentTrain: epoch  1, batch    15 | loss: 142.9260375CurrentTrain: epoch  1, batch    16 | loss: 90.0479665CurrentTrain: epoch  1, batch    17 | loss: 102.9768638CurrentTrain: epoch  1, batch    18 | loss: 106.5636261CurrentTrain: epoch  1, batch    19 | loss: 89.4031032CurrentTrain: epoch  1, batch    20 | loss: 187.7652355CurrentTrain: epoch  1, batch    21 | loss: 110.1586692CurrentTrain: epoch  1, batch    22 | loss: 92.9710052CurrentTrain: epoch  1, batch    23 | loss: 103.7425671CurrentTrain: epoch  1, batch    24 | loss: 108.4271339CurrentTrain: epoch  1, batch    25 | loss: 89.4019327CurrentTrain: epoch  1, batch    26 | loss: 82.2149672CurrentTrain: epoch  1, batch    27 | loss: 66.7917799CurrentTrain: epoch  1, batch    28 | loss: 108.2580153CurrentTrain: epoch  1, batch    29 | loss: 74.8813428CurrentTrain: epoch  1, batch    30 | loss: 77.3754648CurrentTrain: epoch  1, batch    31 | loss: 89.9015317CurrentTrain: epoch  1, batch    32 | loss: 67.5838548CurrentTrain: epoch  1, batch    33 | loss: 76.4972530CurrentTrain: epoch  1, batch    34 | loss: 88.9476479CurrentTrain: epoch  1, batch    35 | loss: 93.2576478CurrentTrain: epoch  1, batch    36 | loss: 89.1835803CurrentTrain: epoch  1, batch    37 | loss: 78.5992084CurrentTrain: epoch  1, batch    38 | loss: 67.8834336CurrentTrain: epoch  1, batch    39 | loss: 73.2971864CurrentTrain: epoch  1, batch    40 | loss: 84.9938174CurrentTrain: epoch  1, batch    41 | loss: 109.6750121CurrentTrain: epoch  1, batch    42 | loss: 83.2556928CurrentTrain: epoch  1, batch    43 | loss: 108.5052432CurrentTrain: epoch  1, batch    44 | loss: 75.3655729CurrentTrain: epoch  1, batch    45 | loss: 108.3294038CurrentTrain: epoch  1, batch    46 | loss: 68.0815522CurrentTrain: epoch  1, batch    47 | loss: 75.6241794CurrentTrain: epoch  1, batch    48 | loss: 91.7726976CurrentTrain: epoch  1, batch    49 | loss: 107.3455400CurrentTrain: epoch  1, batch    50 | loss: 71.3485724CurrentTrain: epoch  1, batch    51 | loss: 74.7471253CurrentTrain: epoch  1, batch    52 | loss: 110.4335206CurrentTrain: epoch  1, batch    53 | loss: 106.5197468CurrentTrain: epoch  1, batch    54 | loss: 86.8901597CurrentTrain: epoch  1, batch    55 | loss: 138.0857582CurrentTrain: epoch  1, batch    56 | loss: 90.6997005CurrentTrain: epoch  1, batch    57 | loss: 110.7101729CurrentTrain: epoch  1, batch    58 | loss: 183.8049322CurrentTrain: epoch  1, batch    59 | loss: 90.1127105CurrentTrain: epoch  1, batch    60 | loss: 110.0569172CurrentTrain: epoch  1, batch    61 | loss: 64.7737904CurrentTrain: epoch  1, batch    62 | loss: 77.8170697CurrentTrain: epoch  1, batch    63 | loss: 105.9202852CurrentTrain: epoch  1, batch    64 | loss: 91.3266894CurrentTrain: epoch  1, batch    65 | loss: 102.9952108CurrentTrain: epoch  1, batch    66 | loss: 72.8738314CurrentTrain: epoch  1, batch    67 | loss: 83.9500389CurrentTrain: epoch  1, batch    68 | loss: 133.9488151CurrentTrain: epoch  1, batch    69 | loss: 92.2174719CurrentTrain: epoch  1, batch    70 | loss: 90.2612212CurrentTrain: epoch  1, batch    71 | loss: 98.5250236CurrentTrain: epoch  1, batch    72 | loss: 86.2060949CurrentTrain: epoch  1, batch    73 | loss: 75.3943453CurrentTrain: epoch  1, batch    74 | loss: 106.4140705CurrentTrain: epoch  1, batch    75 | loss: 87.8473413CurrentTrain: epoch  1, batch    76 | loss: 108.8232684CurrentTrain: epoch  1, batch    77 | loss: 102.2312801CurrentTrain: epoch  1, batch    78 | loss: 77.7127057CurrentTrain: epoch  1, batch    79 | loss: 90.4013712CurrentTrain: epoch  1, batch    80 | loss: 84.5451833CurrentTrain: epoch  1, batch    81 | loss: 109.1588421CurrentTrain: epoch  1, batch    82 | loss: 68.7592797CurrentTrain: epoch  1, batch    83 | loss: 106.5343487CurrentTrain: epoch  1, batch    84 | loss: 89.2546608CurrentTrain: epoch  1, batch    85 | loss: 137.4095525CurrentTrain: epoch  1, batch    86 | loss: 73.6329255CurrentTrain: epoch  1, batch    87 | loss: 61.8666412CurrentTrain: epoch  1, batch    88 | loss: 106.3972799CurrentTrain: epoch  1, batch    89 | loss: 137.3861855CurrentTrain: epoch  1, batch    90 | loss: 87.3952309CurrentTrain: epoch  1, batch    91 | loss: 89.2614213CurrentTrain: epoch  1, batch    92 | loss: 75.9791308CurrentTrain: epoch  1, batch    93 | loss: 75.3320803CurrentTrain: epoch  1, batch    94 | loss: 72.9170728CurrentTrain: epoch  1, batch    95 | loss: 74.6399456CurrentTrain: epoch  2, batch     0 | loss: 85.6088147CurrentTrain: epoch  2, batch     1 | loss: 89.0120646CurrentTrain: epoch  2, batch     2 | loss: 80.5175845CurrentTrain: epoch  2, batch     3 | loss: 63.1140811CurrentTrain: epoch  2, batch     4 | loss: 130.4989723CurrentTrain: epoch  2, batch     5 | loss: 72.0065559CurrentTrain: epoch  2, batch     6 | loss: 61.9156630CurrentTrain: epoch  2, batch     7 | loss: 102.6447899CurrentTrain: epoch  2, batch     8 | loss: 87.7307186CurrentTrain: epoch  2, batch     9 | loss: 107.6404138CurrentTrain: epoch  2, batch    10 | loss: 82.8027343CurrentTrain: epoch  2, batch    11 | loss: 107.7676564CurrentTrain: epoch  2, batch    12 | loss: 136.1480797CurrentTrain: epoch  2, batch    13 | loss: 135.6334513CurrentTrain: epoch  2, batch    14 | loss: 87.3375702CurrentTrain: epoch  2, batch    15 | loss: 102.6127139CurrentTrain: epoch  2, batch    16 | loss: 103.5357938CurrentTrain: epoch  2, batch    17 | loss: 74.1945751CurrentTrain: epoch  2, batch    18 | loss: 86.0937042CurrentTrain: epoch  2, batch    19 | loss: 104.3053889CurrentTrain: epoch  2, batch    20 | loss: 179.2066361CurrentTrain: epoch  2, batch    21 | loss: 100.5204084CurrentTrain: epoch  2, batch    22 | loss: 107.1996351CurrentTrain: epoch  2, batch    23 | loss: 137.8810714CurrentTrain: epoch  2, batch    24 | loss: 103.9228573CurrentTrain: epoch  2, batch    25 | loss: 64.9207708CurrentTrain: epoch  2, batch    26 | loss: 88.5594018CurrentTrain: epoch  2, batch    27 | loss: 72.2011264CurrentTrain: epoch  2, batch    28 | loss: 91.9784432CurrentTrain: epoch  2, batch    29 | loss: 81.9204187CurrentTrain: epoch  2, batch    30 | loss: 132.4715521CurrentTrain: epoch  2, batch    31 | loss: 80.4393037CurrentTrain: epoch  2, batch    32 | loss: 87.9706211CurrentTrain: epoch  2, batch    33 | loss: 73.3902669CurrentTrain: epoch  2, batch    34 | loss: 89.4522882CurrentTrain: epoch  2, batch    35 | loss: 74.5486233CurrentTrain: epoch  2, batch    36 | loss: 72.6312315CurrentTrain: epoch  2, batch    37 | loss: 87.6259076CurrentTrain: epoch  2, batch    38 | loss: 86.8560236CurrentTrain: epoch  2, batch    39 | loss: 136.7597733CurrentTrain: epoch  2, batch    40 | loss: 104.4725937CurrentTrain: epoch  2, batch    41 | loss: 106.8417151CurrentTrain: epoch  2, batch    42 | loss: 88.0534048CurrentTrain: epoch  2, batch    43 | loss: 70.8453245CurrentTrain: epoch  2, batch    44 | loss: 103.4464796CurrentTrain: epoch  2, batch    45 | loss: 131.2440474CurrentTrain: epoch  2, batch    46 | loss: 86.2058001CurrentTrain: epoch  2, batch    47 | loss: 82.1348352CurrentTrain: epoch  2, batch    48 | loss: 86.0639196CurrentTrain: epoch  2, batch    49 | loss: 178.2310919CurrentTrain: epoch  2, batch    50 | loss: 102.3260948CurrentTrain: epoch  2, batch    51 | loss: 104.7275823CurrentTrain: epoch  2, batch    52 | loss: 89.0558833CurrentTrain: epoch  2, batch    53 | loss: 88.3092536CurrentTrain: epoch  2, batch    54 | loss: 72.0013213CurrentTrain: epoch  2, batch    55 | loss: 85.6111991CurrentTrain: epoch  2, batch    56 | loss: 66.9848938CurrentTrain: epoch  2, batch    57 | loss: 134.8256708CurrentTrain: epoch  2, batch    58 | loss: 99.6361802CurrentTrain: epoch  2, batch    59 | loss: 76.2113360CurrentTrain: epoch  2, batch    60 | loss: 89.9221798CurrentTrain: epoch  2, batch    61 | loss: 84.0721613CurrentTrain: epoch  2, batch    62 | loss: 74.6188982CurrentTrain: epoch  2, batch    63 | loss: 85.6954151CurrentTrain: epoch  2, batch    64 | loss: 102.7099795CurrentTrain: epoch  2, batch    65 | loss: 86.3639101CurrentTrain: epoch  2, batch    66 | loss: 70.7423519CurrentTrain: epoch  2, batch    67 | loss: 83.4954299CurrentTrain: epoch  2, batch    68 | loss: 93.1892063CurrentTrain: epoch  2, batch    69 | loss: 109.1223745CurrentTrain: epoch  2, batch    70 | loss: 84.5595626CurrentTrain: epoch  2, batch    71 | loss: 135.9331998CurrentTrain: epoch  2, batch    72 | loss: 132.0787190CurrentTrain: epoch  2, batch    73 | loss: 84.5425998CurrentTrain: epoch  2, batch    74 | loss: 90.8746983CurrentTrain: epoch  2, batch    75 | loss: 91.8220646CurrentTrain: epoch  2, batch    76 | loss: 74.3779219CurrentTrain: epoch  2, batch    77 | loss: 88.0819540CurrentTrain: epoch  2, batch    78 | loss: 84.6447518CurrentTrain: epoch  2, batch    79 | loss: 88.7516583CurrentTrain: epoch  2, batch    80 | loss: 81.8305565CurrentTrain: epoch  2, batch    81 | loss: 70.9065024CurrentTrain: epoch  2, batch    82 | loss: 104.2657938CurrentTrain: epoch  2, batch    83 | loss: 74.0976098CurrentTrain: epoch  2, batch    84 | loss: 87.1228382CurrentTrain: epoch  2, batch    85 | loss: 72.6420804CurrentTrain: epoch  2, batch    86 | loss: 84.0350187CurrentTrain: epoch  2, batch    87 | loss: 84.1051273CurrentTrain: epoch  2, batch    88 | loss: 102.2815149CurrentTrain: epoch  2, batch    89 | loss: 57.7893234CurrentTrain: epoch  2, batch    90 | loss: 103.7661517CurrentTrain: epoch  2, batch    91 | loss: 70.9362102CurrentTrain: epoch  2, batch    92 | loss: 83.5839831CurrentTrain: epoch  2, batch    93 | loss: 81.0641508CurrentTrain: epoch  2, batch    94 | loss: 180.2105302CurrentTrain: epoch  2, batch    95 | loss: 60.3194703CurrentTrain: epoch  3, batch     0 | loss: 86.4135756CurrentTrain: epoch  3, batch     1 | loss: 72.1432078CurrentTrain: epoch  3, batch     2 | loss: 135.4551471CurrentTrain: epoch  3, batch     3 | loss: 59.3346968CurrentTrain: epoch  3, batch     4 | loss: 64.0591830CurrentTrain: epoch  3, batch     5 | loss: 105.8729726CurrentTrain: epoch  3, batch     6 | loss: 70.3323654CurrentTrain: epoch  3, batch     7 | loss: 102.4566232CurrentTrain: epoch  3, batch     8 | loss: 103.9244019CurrentTrain: epoch  3, batch     9 | loss: 103.0478471CurrentTrain: epoch  3, batch    10 | loss: 84.9938278CurrentTrain: epoch  3, batch    11 | loss: 85.4971770CurrentTrain: epoch  3, batch    12 | loss: 63.1811146CurrentTrain: epoch  3, batch    13 | loss: 133.4875318CurrentTrain: epoch  3, batch    14 | loss: 133.7729663CurrentTrain: epoch  3, batch    15 | loss: 71.1853474CurrentTrain: epoch  3, batch    16 | loss: 100.1599483CurrentTrain: epoch  3, batch    17 | loss: 106.0422656CurrentTrain: epoch  3, batch    18 | loss: 85.2504263CurrentTrain: epoch  3, batch    19 | loss: 100.3962012CurrentTrain: epoch  3, batch    20 | loss: 69.6218247CurrentTrain: epoch  3, batch    21 | loss: 99.3289199CurrentTrain: epoch  3, batch    22 | loss: 102.7463874CurrentTrain: epoch  3, batch    23 | loss: 103.8456414CurrentTrain: epoch  3, batch    24 | loss: 102.6232036CurrentTrain: epoch  3, batch    25 | loss: 90.4477956CurrentTrain: epoch  3, batch    26 | loss: 83.9590373CurrentTrain: epoch  3, batch    27 | loss: 88.6716627CurrentTrain: epoch  3, batch    28 | loss: 67.1052349CurrentTrain: epoch  3, batch    29 | loss: 103.8599419CurrentTrain: epoch  3, batch    30 | loss: 130.3951818CurrentTrain: epoch  3, batch    31 | loss: 61.9802173CurrentTrain: epoch  3, batch    32 | loss: 103.7771254CurrentTrain: epoch  3, batch    33 | loss: 81.9359779CurrentTrain: epoch  3, batch    34 | loss: 100.8121743CurrentTrain: epoch  3, batch    35 | loss: 76.1187074CurrentTrain: epoch  3, batch    36 | loss: 70.9076874CurrentTrain: epoch  3, batch    37 | loss: 71.7568410CurrentTrain: epoch  3, batch    38 | loss: 100.5644909CurrentTrain: epoch  3, batch    39 | loss: 58.6164725CurrentTrain: epoch  3, batch    40 | loss: 71.0062908CurrentTrain: epoch  3, batch    41 | loss: 85.0450708CurrentTrain: epoch  3, batch    42 | loss: 70.1507244CurrentTrain: epoch  3, batch    43 | loss: 106.8783999CurrentTrain: epoch  3, batch    44 | loss: 100.8702835CurrentTrain: epoch  3, batch    45 | loss: 105.7353461CurrentTrain: epoch  3, batch    46 | loss: 61.2747833CurrentTrain: epoch  3, batch    47 | loss: 63.8359948CurrentTrain: epoch  3, batch    48 | loss: 75.9473931CurrentTrain: epoch  3, batch    49 | loss: 69.2508700CurrentTrain: epoch  3, batch    50 | loss: 62.1359128CurrentTrain: epoch  3, batch    51 | loss: 72.7888129CurrentTrain: epoch  3, batch    52 | loss: 66.7488692CurrentTrain: epoch  3, batch    53 | loss: 82.5516541CurrentTrain: epoch  3, batch    54 | loss: 85.7651953CurrentTrain: epoch  3, batch    55 | loss: 61.0897813CurrentTrain: epoch  3, batch    56 | loss: 82.4823004CurrentTrain: epoch  3, batch    57 | loss: 98.0886645CurrentTrain: epoch  3, batch    58 | loss: 103.9509551CurrentTrain: epoch  3, batch    59 | loss: 88.1271918CurrentTrain: epoch  3, batch    60 | loss: 80.7765212CurrentTrain: epoch  3, batch    61 | loss: 67.9514016CurrentTrain: epoch  3, batch    62 | loss: 73.5899692CurrentTrain: epoch  3, batch    63 | loss: 138.9140446CurrentTrain: epoch  3, batch    64 | loss: 70.1341944CurrentTrain: epoch  3, batch    65 | loss: 127.9609844CurrentTrain: epoch  3, batch    66 | loss: 127.2830883CurrentTrain: epoch  3, batch    67 | loss: 85.3502963CurrentTrain: epoch  3, batch    68 | loss: 73.1219844CurrentTrain: epoch  3, batch    69 | loss: 86.4160221CurrentTrain: epoch  3, batch    70 | loss: 101.5628407CurrentTrain: epoch  3, batch    71 | loss: 101.2629898CurrentTrain: epoch  3, batch    72 | loss: 81.1210161CurrentTrain: epoch  3, batch    73 | loss: 71.0523465CurrentTrain: epoch  3, batch    74 | loss: 86.5017599CurrentTrain: epoch  3, batch    75 | loss: 103.0405021CurrentTrain: epoch  3, batch    76 | loss: 69.9635228CurrentTrain: epoch  3, batch    77 | loss: 68.1871503CurrentTrain: epoch  3, batch    78 | loss: 104.6620954CurrentTrain: epoch  3, batch    79 | loss: 86.1641502CurrentTrain: epoch  3, batch    80 | loss: 103.8733177CurrentTrain: epoch  3, batch    81 | loss: 72.7491621CurrentTrain: epoch  3, batch    82 | loss: 73.7944685CurrentTrain: epoch  3, batch    83 | loss: 75.2058899CurrentTrain: epoch  3, batch    84 | loss: 70.4670104CurrentTrain: epoch  3, batch    85 | loss: 104.6670564CurrentTrain: epoch  3, batch    86 | loss: 63.8876610CurrentTrain: epoch  3, batch    87 | loss: 87.9717286CurrentTrain: epoch  3, batch    88 | loss: 127.0314681CurrentTrain: epoch  3, batch    89 | loss: 86.8424601CurrentTrain: epoch  3, batch    90 | loss: 70.8628192CurrentTrain: epoch  3, batch    91 | loss: 71.1110816CurrentTrain: epoch  3, batch    92 | loss: 71.4435920CurrentTrain: epoch  3, batch    93 | loss: 69.6025095CurrentTrain: epoch  3, batch    94 | loss: 105.8586508CurrentTrain: epoch  3, batch    95 | loss: 67.9414138CurrentTrain: epoch  4, batch     0 | loss: 68.7202898CurrentTrain: epoch  4, batch     1 | loss: 101.4019328CurrentTrain: epoch  4, batch     2 | loss: 68.8297941CurrentTrain: epoch  4, batch     3 | loss: 85.9792163CurrentTrain: epoch  4, batch     4 | loss: 61.3406693CurrentTrain: epoch  4, batch     5 | loss: 69.7900741CurrentTrain: epoch  4, batch     6 | loss: 85.8213777CurrentTrain: epoch  4, batch     7 | loss: 80.7509158CurrentTrain: epoch  4, batch     8 | loss: 69.7389834CurrentTrain: epoch  4, batch     9 | loss: 76.1997995CurrentTrain: epoch  4, batch    10 | loss: 74.2273586CurrentTrain: epoch  4, batch    11 | loss: 78.6656051CurrentTrain: epoch  4, batch    12 | loss: 74.4760767CurrentTrain: epoch  4, batch    13 | loss: 128.2214382CurrentTrain: epoch  4, batch    14 | loss: 103.2315108CurrentTrain: epoch  4, batch    15 | loss: 85.5830420CurrentTrain: epoch  4, batch    16 | loss: 81.9745142CurrentTrain: epoch  4, batch    17 | loss: 85.0719635CurrentTrain: epoch  4, batch    18 | loss: 100.7746475CurrentTrain: epoch  4, batch    19 | loss: 127.0994599CurrentTrain: epoch  4, batch    20 | loss: 79.8340666CurrentTrain: epoch  4, batch    21 | loss: 126.6212234CurrentTrain: epoch  4, batch    22 | loss: 70.7535304CurrentTrain: epoch  4, batch    23 | loss: 86.1140400CurrentTrain: epoch  4, batch    24 | loss: 82.0908471CurrentTrain: epoch  4, batch    25 | loss: 68.3401258CurrentTrain: epoch  4, batch    26 | loss: 76.5810065CurrentTrain: epoch  4, batch    27 | loss: 84.2374111CurrentTrain: epoch  4, batch    28 | loss: 103.7673212CurrentTrain: epoch  4, batch    29 | loss: 68.5673658CurrentTrain: epoch  4, batch    30 | loss: 95.6868714CurrentTrain: epoch  4, batch    31 | loss: 71.7251238CurrentTrain: epoch  4, batch    32 | loss: 101.1124217CurrentTrain: epoch  4, batch    33 | loss: 62.4883461CurrentTrain: epoch  4, batch    34 | loss: 96.8194852CurrentTrain: epoch  4, batch    35 | loss: 89.4466332CurrentTrain: epoch  4, batch    36 | loss: 129.6215668CurrentTrain: epoch  4, batch    37 | loss: 104.6869946CurrentTrain: epoch  4, batch    38 | loss: 103.9649789CurrentTrain: epoch  4, batch    39 | loss: 100.2872933CurrentTrain: epoch  4, batch    40 | loss: 85.0737242CurrentTrain: epoch  4, batch    41 | loss: 82.2876272CurrentTrain: epoch  4, batch    42 | loss: 96.6099792CurrentTrain: epoch  4, batch    43 | loss: 103.0259282CurrentTrain: epoch  4, batch    44 | loss: 133.2578462CurrentTrain: epoch  4, batch    45 | loss: 82.6409181CurrentTrain: epoch  4, batch    46 | loss: 83.1788518CurrentTrain: epoch  4, batch    47 | loss: 105.0186669CurrentTrain: epoch  4, batch    48 | loss: 129.5393059CurrentTrain: epoch  4, batch    49 | loss: 81.9166267CurrentTrain: epoch  4, batch    50 | loss: 92.3533952CurrentTrain: epoch  4, batch    51 | loss: 128.0046068CurrentTrain: epoch  4, batch    52 | loss: 83.4284966CurrentTrain: epoch  4, batch    53 | loss: 69.9009155CurrentTrain: epoch  4, batch    54 | loss: 62.1866779CurrentTrain: epoch  4, batch    55 | loss: 102.5172351CurrentTrain: epoch  4, batch    56 | loss: 79.5882748CurrentTrain: epoch  4, batch    57 | loss: 74.8428507CurrentTrain: epoch  4, batch    58 | loss: 67.3552115CurrentTrain: epoch  4, batch    59 | loss: 101.2268305CurrentTrain: epoch  4, batch    60 | loss: 71.2701505CurrentTrain: epoch  4, batch    61 | loss: 83.8397575CurrentTrain: epoch  4, batch    62 | loss: 82.1019932CurrentTrain: epoch  4, batch    63 | loss: 81.9688932CurrentTrain: epoch  4, batch    64 | loss: 71.2625344CurrentTrain: epoch  4, batch    65 | loss: 68.8403343CurrentTrain: epoch  4, batch    66 | loss: 101.8370692CurrentTrain: epoch  4, batch    67 | loss: 81.2152308CurrentTrain: epoch  4, batch    68 | loss: 60.8731188CurrentTrain: epoch  4, batch    69 | loss: 127.9859623CurrentTrain: epoch  4, batch    70 | loss: 81.3745723CurrentTrain: epoch  4, batch    71 | loss: 127.6480824CurrentTrain: epoch  4, batch    72 | loss: 58.7963766CurrentTrain: epoch  4, batch    73 | loss: 125.9531976CurrentTrain: epoch  4, batch    74 | loss: 61.5263036CurrentTrain: epoch  4, batch    75 | loss: 73.1114312CurrentTrain: epoch  4, batch    76 | loss: 68.8388593CurrentTrain: epoch  4, batch    77 | loss: 105.7987039CurrentTrain: epoch  4, batch    78 | loss: 104.8283204CurrentTrain: epoch  4, batch    79 | loss: 83.1331521CurrentTrain: epoch  4, batch    80 | loss: 74.3166732CurrentTrain: epoch  4, batch    81 | loss: 104.4052048CurrentTrain: epoch  4, batch    82 | loss: 77.7813892CurrentTrain: epoch  4, batch    83 | loss: 101.3664834CurrentTrain: epoch  4, batch    84 | loss: 71.5448058CurrentTrain: epoch  4, batch    85 | loss: 99.4287362CurrentTrain: epoch  4, batch    86 | loss: 104.7153226CurrentTrain: epoch  4, batch    87 | loss: 98.7426490CurrentTrain: epoch  4, batch    88 | loss: 101.8461534CurrentTrain: epoch  4, batch    89 | loss: 100.3009452CurrentTrain: epoch  4, batch    90 | loss: 98.0702816CurrentTrain: epoch  4, batch    91 | loss: 85.4977031CurrentTrain: epoch  4, batch    92 | loss: 101.5822909CurrentTrain: epoch  4, batch    93 | loss: 67.7309597CurrentTrain: epoch  4, batch    94 | loss: 71.0469407CurrentTrain: epoch  4, batch    95 | loss: 66.1735774CurrentTrain: epoch  5, batch     0 | loss: 100.2263634CurrentTrain: epoch  5, batch     1 | loss: 69.1276174CurrentTrain: epoch  5, batch     2 | loss: 97.0667449CurrentTrain: epoch  5, batch     3 | loss: 120.6400794CurrentTrain: epoch  5, batch     4 | loss: 70.2638506CurrentTrain: epoch  5, batch     5 | loss: 94.6324057CurrentTrain: epoch  5, batch     6 | loss: 101.7122552CurrentTrain: epoch  5, batch     7 | loss: 84.0142515CurrentTrain: epoch  5, batch     8 | loss: 65.7191202CurrentTrain: epoch  5, batch     9 | loss: 58.7298121CurrentTrain: epoch  5, batch    10 | loss: 100.8416812CurrentTrain: epoch  5, batch    11 | loss: 99.4667562CurrentTrain: epoch  5, batch    12 | loss: 66.5078504CurrentTrain: epoch  5, batch    13 | loss: 95.2432504CurrentTrain: epoch  5, batch    14 | loss: 105.2303530CurrentTrain: epoch  5, batch    15 | loss: 68.4447815CurrentTrain: epoch  5, batch    16 | loss: 127.2395447CurrentTrain: epoch  5, batch    17 | loss: 80.2856198CurrentTrain: epoch  5, batch    18 | loss: 96.9341037CurrentTrain: epoch  5, batch    19 | loss: 105.1519140CurrentTrain: epoch  5, batch    20 | loss: 85.4861212CurrentTrain: epoch  5, batch    21 | loss: 78.2493120CurrentTrain: epoch  5, batch    22 | loss: 82.4875096CurrentTrain: epoch  5, batch    23 | loss: 80.1037876CurrentTrain: epoch  5, batch    24 | loss: 67.5388285CurrentTrain: epoch  5, batch    25 | loss: 99.1895438CurrentTrain: epoch  5, batch    26 | loss: 78.6652613CurrentTrain: epoch  5, batch    27 | loss: 67.0062544CurrentTrain: epoch  5, batch    28 | loss: 128.5519403CurrentTrain: epoch  5, batch    29 | loss: 70.3349461CurrentTrain: epoch  5, batch    30 | loss: 92.4842768CurrentTrain: epoch  5, batch    31 | loss: 80.8460771CurrentTrain: epoch  5, batch    32 | loss: 71.8623797CurrentTrain: epoch  5, batch    33 | loss: 92.2357358CurrentTrain: epoch  5, batch    34 | loss: 99.1033426CurrentTrain: epoch  5, batch    35 | loss: 57.3600182CurrentTrain: epoch  5, batch    36 | loss: 68.1579173CurrentTrain: epoch  5, batch    37 | loss: 127.0790198CurrentTrain: epoch  5, batch    38 | loss: 79.9096823CurrentTrain: epoch  5, batch    39 | loss: 65.1056027CurrentTrain: epoch  5, batch    40 | loss: 131.7400181CurrentTrain: epoch  5, batch    41 | loss: 80.9549848CurrentTrain: epoch  5, batch    42 | loss: 82.4733990CurrentTrain: epoch  5, batch    43 | loss: 65.0937964CurrentTrain: epoch  5, batch    44 | loss: 101.9342616CurrentTrain: epoch  5, batch    45 | loss: 79.4047304CurrentTrain: epoch  5, batch    46 | loss: 69.8298370CurrentTrain: epoch  5, batch    47 | loss: 70.2129653CurrentTrain: epoch  5, batch    48 | loss: 104.2389948CurrentTrain: epoch  5, batch    49 | loss: 54.6207508CurrentTrain: epoch  5, batch    50 | loss: 96.1212862CurrentTrain: epoch  5, batch    51 | loss: 73.0413737CurrentTrain: epoch  5, batch    52 | loss: 85.8831713CurrentTrain: epoch  5, batch    53 | loss: 83.9604399CurrentTrain: epoch  5, batch    54 | loss: 82.9316956CurrentTrain: epoch  5, batch    55 | loss: 123.5740719CurrentTrain: epoch  5, batch    56 | loss: 178.4143067CurrentTrain: epoch  5, batch    57 | loss: 69.1553238CurrentTrain: epoch  5, batch    58 | loss: 82.6067343CurrentTrain: epoch  5, batch    59 | loss: 84.6068463CurrentTrain: epoch  5, batch    60 | loss: 64.5860784CurrentTrain: epoch  5, batch    61 | loss: 98.2595694CurrentTrain: epoch  5, batch    62 | loss: 97.8056187CurrentTrain: epoch  5, batch    63 | loss: 68.7091094CurrentTrain: epoch  5, batch    64 | loss: 79.6806683CurrentTrain: epoch  5, batch    65 | loss: 171.7208998CurrentTrain: epoch  5, batch    66 | loss: 80.8958464CurrentTrain: epoch  5, batch    67 | loss: 101.6202227CurrentTrain: epoch  5, batch    68 | loss: 68.2429764CurrentTrain: epoch  5, batch    69 | loss: 81.0998306CurrentTrain: epoch  5, batch    70 | loss: 73.9722586CurrentTrain: epoch  5, batch    71 | loss: 171.8900947CurrentTrain: epoch  5, batch    72 | loss: 59.0012399CurrentTrain: epoch  5, batch    73 | loss: 98.9774988CurrentTrain: epoch  5, batch    74 | loss: 70.0988078CurrentTrain: epoch  5, batch    75 | loss: 72.4735428CurrentTrain: epoch  5, batch    76 | loss: 70.0543920CurrentTrain: epoch  5, batch    77 | loss: 67.3067105CurrentTrain: epoch  5, batch    78 | loss: 71.6295926CurrentTrain: epoch  5, batch    79 | loss: 59.9227392CurrentTrain: epoch  5, batch    80 | loss: 94.2808189CurrentTrain: epoch  5, batch    81 | loss: 72.1661785CurrentTrain: epoch  5, batch    82 | loss: 77.9428327CurrentTrain: epoch  5, batch    83 | loss: 70.7297293CurrentTrain: epoch  5, batch    84 | loss: 97.4167404CurrentTrain: epoch  5, batch    85 | loss: 103.3330981CurrentTrain: epoch  5, batch    86 | loss: 83.8481791CurrentTrain: epoch  5, batch    87 | loss: 86.7119264CurrentTrain: epoch  5, batch    88 | loss: 83.3149024CurrentTrain: epoch  5, batch    89 | loss: 79.9603640CurrentTrain: epoch  5, batch    90 | loss: 84.4675530CurrentTrain: epoch  5, batch    91 | loss: 101.7860112CurrentTrain: epoch  5, batch    92 | loss: 85.0893811CurrentTrain: epoch  5, batch    93 | loss: 71.8472086CurrentTrain: epoch  5, batch    94 | loss: 98.2789483CurrentTrain: epoch  5, batch    95 | loss: 69.1441796CurrentTrain: epoch  6, batch     0 | loss: 100.6845153CurrentTrain: epoch  6, batch     1 | loss: 75.5129713CurrentTrain: epoch  6, batch     2 | loss: 82.2903864CurrentTrain: epoch  6, batch     3 | loss: 77.7218042CurrentTrain: epoch  6, batch     4 | loss: 79.1908879CurrentTrain: epoch  6, batch     5 | loss: 98.0877995CurrentTrain: epoch  6, batch     6 | loss: 84.4128018CurrentTrain: epoch  6, batch     7 | loss: 81.0651087CurrentTrain: epoch  6, batch     8 | loss: 99.8113774CurrentTrain: epoch  6, batch     9 | loss: 121.0410677CurrentTrain: epoch  6, batch    10 | loss: 80.8629366CurrentTrain: epoch  6, batch    11 | loss: 105.5100558CurrentTrain: epoch  6, batch    12 | loss: 81.7449123CurrentTrain: epoch  6, batch    13 | loss: 82.3402477CurrentTrain: epoch  6, batch    14 | loss: 64.0586549CurrentTrain: epoch  6, batch    15 | loss: 122.8246613CurrentTrain: epoch  6, batch    16 | loss: 95.2915029CurrentTrain: epoch  6, batch    17 | loss: 117.5165611CurrentTrain: epoch  6, batch    18 | loss: 129.7334479CurrentTrain: epoch  6, batch    19 | loss: 69.1391686CurrentTrain: epoch  6, batch    20 | loss: 173.7684351CurrentTrain: epoch  6, batch    21 | loss: 83.7837417CurrentTrain: epoch  6, batch    22 | loss: 78.3198125CurrentTrain: epoch  6, batch    23 | loss: 100.1592925CurrentTrain: epoch  6, batch    24 | loss: 65.2560243CurrentTrain: epoch  6, batch    25 | loss: 101.6751322CurrentTrain: epoch  6, batch    26 | loss: 66.4738048CurrentTrain: epoch  6, batch    27 | loss: 63.2411400CurrentTrain: epoch  6, batch    28 | loss: 78.5180017CurrentTrain: epoch  6, batch    29 | loss: 126.7539920CurrentTrain: epoch  6, batch    30 | loss: 71.0067498CurrentTrain: epoch  6, batch    31 | loss: 67.8248666CurrentTrain: epoch  6, batch    32 | loss: 70.0084340CurrentTrain: epoch  6, batch    33 | loss: 128.4068816CurrentTrain: epoch  6, batch    34 | loss: 82.3868516CurrentTrain: epoch  6, batch    35 | loss: 64.9919079CurrentTrain: epoch  6, batch    36 | loss: 100.8513827CurrentTrain: epoch  6, batch    37 | loss: 123.2167609CurrentTrain: epoch  6, batch    38 | loss: 101.3955668CurrentTrain: epoch  6, batch    39 | loss: 68.3378442CurrentTrain: epoch  6, batch    40 | loss: 98.3767698CurrentTrain: epoch  6, batch    41 | loss: 99.8935989CurrentTrain: epoch  6, batch    42 | loss: 58.8582872CurrentTrain: epoch  6, batch    43 | loss: 77.3347721CurrentTrain: epoch  6, batch    44 | loss: 77.8048397CurrentTrain: epoch  6, batch    45 | loss: 56.6817392CurrentTrain: epoch  6, batch    46 | loss: 70.2820332CurrentTrain: epoch  6, batch    47 | loss: 75.8149612CurrentTrain: epoch  6, batch    48 | loss: 67.5534187CurrentTrain: epoch  6, batch    49 | loss: 124.7418960CurrentTrain: epoch  6, batch    50 | loss: 119.9570346CurrentTrain: epoch  6, batch    51 | loss: 61.1131454CurrentTrain: epoch  6, batch    52 | loss: 65.1513302CurrentTrain: epoch  6, batch    53 | loss: 66.9247317CurrentTrain: epoch  6, batch    54 | loss: 82.5019674CurrentTrain: epoch  6, batch    55 | loss: 121.9922937CurrentTrain: epoch  6, batch    56 | loss: 123.7490656CurrentTrain: epoch  6, batch    57 | loss: 81.8982410CurrentTrain: epoch  6, batch    58 | loss: 96.1564194CurrentTrain: epoch  6, batch    59 | loss: 99.9660372CurrentTrain: epoch  6, batch    60 | loss: 101.5587756CurrentTrain: epoch  6, batch    61 | loss: 68.4225320CurrentTrain: epoch  6, batch    62 | loss: 75.9578356CurrentTrain: epoch  6, batch    63 | loss: 79.6505042CurrentTrain: epoch  6, batch    64 | loss: 77.0914002CurrentTrain: epoch  6, batch    65 | loss: 101.8350556CurrentTrain: epoch  6, batch    66 | loss: 79.3455677CurrentTrain: epoch  6, batch    67 | loss: 93.4812362CurrentTrain: epoch  6, batch    68 | loss: 83.9399760CurrentTrain: epoch  6, batch    69 | loss: 95.4310637CurrentTrain: epoch  6, batch    70 | loss: 98.8636398CurrentTrain: epoch  6, batch    71 | loss: 94.4754095CurrentTrain: epoch  6, batch    72 | loss: 55.7259188CurrentTrain: epoch  6, batch    73 | loss: 84.2713190CurrentTrain: epoch  6, batch    74 | loss: 101.6989019CurrentTrain: epoch  6, batch    75 | loss: 71.4046110CurrentTrain: epoch  6, batch    76 | loss: 80.6270515CurrentTrain: epoch  6, batch    77 | loss: 102.8662243CurrentTrain: epoch  6, batch    78 | loss: 99.7218792CurrentTrain: epoch  6, batch    79 | loss: 96.7363369CurrentTrain: epoch  6, batch    80 | loss: 97.7114059CurrentTrain: epoch  6, batch    81 | loss: 71.7054298CurrentTrain: epoch  6, batch    82 | loss: 79.9237396CurrentTrain: epoch  6, batch    83 | loss: 66.4049208CurrentTrain: epoch  6, batch    84 | loss: 97.1864948CurrentTrain: epoch  6, batch    85 | loss: 75.5763774CurrentTrain: epoch  6, batch    86 | loss: 98.2854370CurrentTrain: epoch  6, batch    87 | loss: 98.1438693CurrentTrain: epoch  6, batch    88 | loss: 119.7679102CurrentTrain: epoch  6, batch    89 | loss: 72.6880254CurrentTrain: epoch  6, batch    90 | loss: 63.7419849CurrentTrain: epoch  6, batch    91 | loss: 122.3327730CurrentTrain: epoch  6, batch    92 | loss: 66.5939321CurrentTrain: epoch  6, batch    93 | loss: 64.5547036CurrentTrain: epoch  6, batch    94 | loss: 64.5814047CurrentTrain: epoch  6, batch    95 | loss: 108.6614386CurrentTrain: epoch  7, batch     0 | loss: 62.3284548CurrentTrain: epoch  7, batch     1 | loss: 67.7501142CurrentTrain: epoch  7, batch     2 | loss: 124.2710410CurrentTrain: epoch  7, batch     3 | loss: 97.0101578CurrentTrain: epoch  7, batch     4 | loss: 121.4748497CurrentTrain: epoch  7, batch     5 | loss: 80.5699517CurrentTrain: epoch  7, batch     6 | loss: 77.3358657CurrentTrain: epoch  7, batch     7 | loss: 94.8936887CurrentTrain: epoch  7, batch     8 | loss: 54.1256440CurrentTrain: epoch  7, batch     9 | loss: 64.4064225CurrentTrain: epoch  7, batch    10 | loss: 119.5057041CurrentTrain: epoch  7, batch    11 | loss: 125.9437275CurrentTrain: epoch  7, batch    12 | loss: 77.2826163CurrentTrain: epoch  7, batch    13 | loss: 81.4856770CurrentTrain: epoch  7, batch    14 | loss: 54.7163207CurrentTrain: epoch  7, batch    15 | loss: 99.0651777CurrentTrain: epoch  7, batch    16 | loss: 65.2792606CurrentTrain: epoch  7, batch    17 | loss: 104.1687652CurrentTrain: epoch  7, batch    18 | loss: 66.3742973CurrentTrain: epoch  7, batch    19 | loss: 94.7133353CurrentTrain: epoch  7, batch    20 | loss: 97.3126255CurrentTrain: epoch  7, batch    21 | loss: 82.5269700CurrentTrain: epoch  7, batch    22 | loss: 95.5167486CurrentTrain: epoch  7, batch    23 | loss: 82.0405526CurrentTrain: epoch  7, batch    24 | loss: 121.6914853CurrentTrain: epoch  7, batch    25 | loss: 75.2150229CurrentTrain: epoch  7, batch    26 | loss: 82.4662848CurrentTrain: epoch  7, batch    27 | loss: 57.0209331CurrentTrain: epoch  7, batch    28 | loss: 56.6601077CurrentTrain: epoch  7, batch    29 | loss: 63.7371978CurrentTrain: epoch  7, batch    30 | loss: 97.2007901CurrentTrain: epoch  7, batch    31 | loss: 68.5302636CurrentTrain: epoch  7, batch    32 | loss: 94.5053610CurrentTrain: epoch  7, batch    33 | loss: 96.6194916CurrentTrain: epoch  7, batch    34 | loss: 98.6609565CurrentTrain: epoch  7, batch    35 | loss: 81.2061635CurrentTrain: epoch  7, batch    36 | loss: 76.1681774CurrentTrain: epoch  7, batch    37 | loss: 62.9973818CurrentTrain: epoch  7, batch    38 | loss: 77.6192370CurrentTrain: epoch  7, batch    39 | loss: 76.3373786CurrentTrain: epoch  7, batch    40 | loss: 129.5799038CurrentTrain: epoch  7, batch    41 | loss: 79.0794195CurrentTrain: epoch  7, batch    42 | loss: 78.7719090CurrentTrain: epoch  7, batch    43 | loss: 126.2623470CurrentTrain: epoch  7, batch    44 | loss: 56.6868974CurrentTrain: epoch  7, batch    45 | loss: 103.6139217CurrentTrain: epoch  7, batch    46 | loss: 64.4347755CurrentTrain: epoch  7, batch    47 | loss: 80.2073632CurrentTrain: epoch  7, batch    48 | loss: 80.6184821CurrentTrain: epoch  7, batch    49 | loss: 125.5134461CurrentTrain: epoch  7, batch    50 | loss: 100.4320225CurrentTrain: epoch  7, batch    51 | loss: 102.6091438CurrentTrain: epoch  7, batch    52 | loss: 76.1354277CurrentTrain: epoch  7, batch    53 | loss: 122.8651060CurrentTrain: epoch  7, batch    54 | loss: 81.1464044CurrentTrain: epoch  7, batch    55 | loss: 80.8746116CurrentTrain: epoch  7, batch    56 | loss: 65.1385125CurrentTrain: epoch  7, batch    57 | loss: 125.1389787CurrentTrain: epoch  7, batch    58 | loss: 68.8121328CurrentTrain: epoch  7, batch    59 | loss: 81.0736623CurrentTrain: epoch  7, batch    60 | loss: 93.8262606CurrentTrain: epoch  7, batch    61 | loss: 79.3139738CurrentTrain: epoch  7, batch    62 | loss: 97.8306929CurrentTrain: epoch  7, batch    63 | loss: 80.6177968CurrentTrain: epoch  7, batch    64 | loss: 56.4655091CurrentTrain: epoch  7, batch    65 | loss: 77.3746292CurrentTrain: epoch  7, batch    66 | loss: 68.1206939CurrentTrain: epoch  7, batch    67 | loss: 82.2746814CurrentTrain: epoch  7, batch    68 | loss: 78.8865571CurrentTrain: epoch  7, batch    69 | loss: 99.1964200CurrentTrain: epoch  7, batch    70 | loss: 80.2263639CurrentTrain: epoch  7, batch    71 | loss: 55.2636179CurrentTrain: epoch  7, batch    72 | loss: 77.8899615CurrentTrain: epoch  7, batch    73 | loss: 78.5178265CurrentTrain: epoch  7, batch    74 | loss: 122.8668632CurrentTrain: epoch  7, batch    75 | loss: 94.7617808CurrentTrain: epoch  7, batch    76 | loss: 80.5716436CurrentTrain: epoch  7, batch    77 | loss: 58.5284619CurrentTrain: epoch  7, batch    78 | loss: 261.2313241CurrentTrain: epoch  7, batch    79 | loss: 80.6817702CurrentTrain: epoch  7, batch    80 | loss: 78.6158627CurrentTrain: epoch  7, batch    81 | loss: 62.5507917CurrentTrain: epoch  7, batch    82 | loss: 101.7066612CurrentTrain: epoch  7, batch    83 | loss: 77.5278387CurrentTrain: epoch  7, batch    84 | loss: 80.4826732CurrentTrain: epoch  7, batch    85 | loss: 78.7414048CurrentTrain: epoch  7, batch    86 | loss: 126.5786656CurrentTrain: epoch  7, batch    87 | loss: 98.6747930CurrentTrain: epoch  7, batch    88 | loss: 123.3254256CurrentTrain: epoch  7, batch    89 | loss: 79.0211051CurrentTrain: epoch  7, batch    90 | loss: 79.8425341CurrentTrain: epoch  7, batch    91 | loss: 126.3186531CurrentTrain: epoch  7, batch    92 | loss: 125.5633837CurrentTrain: epoch  7, batch    93 | loss: 64.5660999CurrentTrain: epoch  7, batch    94 | loss: 52.0410502CurrentTrain: epoch  7, batch    95 | loss: 101.5805631CurrentTrain: epoch  8, batch     0 | loss: 100.2296047CurrentTrain: epoch  8, batch     1 | loss: 97.6991408CurrentTrain: epoch  8, batch     2 | loss: 79.5917955CurrentTrain: epoch  8, batch     3 | loss: 64.7781237CurrentTrain: epoch  8, batch     4 | loss: 67.5100235CurrentTrain: epoch  8, batch     5 | loss: 93.6412629CurrentTrain: epoch  8, batch     6 | loss: 77.9822870CurrentTrain: epoch  8, batch     7 | loss: 127.1364221CurrentTrain: epoch  8, batch     8 | loss: 66.9119211CurrentTrain: epoch  8, batch     9 | loss: 62.7578688CurrentTrain: epoch  8, batch    10 | loss: 59.1478901CurrentTrain: epoch  8, batch    11 | loss: 63.8892560CurrentTrain: epoch  8, batch    12 | loss: 64.2648686CurrentTrain: epoch  8, batch    13 | loss: 170.4998739CurrentTrain: epoch  8, batch    14 | loss: 79.1154089CurrentTrain: epoch  8, batch    15 | loss: 79.2217115CurrentTrain: epoch  8, batch    16 | loss: 125.6125031CurrentTrain: epoch  8, batch    17 | loss: 97.1576920CurrentTrain: epoch  8, batch    18 | loss: 97.2551622CurrentTrain: epoch  8, batch    19 | loss: 65.7326233CurrentTrain: epoch  8, batch    20 | loss: 53.9647839CurrentTrain: epoch  8, batch    21 | loss: 63.8060275CurrentTrain: epoch  8, batch    22 | loss: 124.8166768CurrentTrain: epoch  8, batch    23 | loss: 75.7989772CurrentTrain: epoch  8, batch    24 | loss: 97.8946112CurrentTrain: epoch  8, batch    25 | loss: 65.1546532CurrentTrain: epoch  8, batch    26 | loss: 95.7441211CurrentTrain: epoch  8, batch    27 | loss: 121.3473959CurrentTrain: epoch  8, batch    28 | loss: 80.9759468CurrentTrain: epoch  8, batch    29 | loss: 91.4967715CurrentTrain: epoch  8, batch    30 | loss: 68.6863099CurrentTrain: epoch  8, batch    31 | loss: 125.3084346CurrentTrain: epoch  8, batch    32 | loss: 123.7002358CurrentTrain: epoch  8, batch    33 | loss: 93.4618287CurrentTrain: epoch  8, batch    34 | loss: 127.0282943CurrentTrain: epoch  8, batch    35 | loss: 120.2943593CurrentTrain: epoch  8, batch    36 | loss: 77.2112737CurrentTrain: epoch  8, batch    37 | loss: 95.1229892CurrentTrain: epoch  8, batch    38 | loss: 125.0093164CurrentTrain: epoch  8, batch    39 | loss: 79.7423308CurrentTrain: epoch  8, batch    40 | loss: 78.0788195CurrentTrain: epoch  8, batch    41 | loss: 62.4452130CurrentTrain: epoch  8, batch    42 | loss: 168.7959119CurrentTrain: epoch  8, batch    43 | loss: 94.2167891CurrentTrain: epoch  8, batch    44 | loss: 95.9307229CurrentTrain: epoch  8, batch    45 | loss: 78.5998756CurrentTrain: epoch  8, batch    46 | loss: 80.4160177CurrentTrain: epoch  8, batch    47 | loss: 123.6368233CurrentTrain: epoch  8, batch    48 | loss: 77.0819438CurrentTrain: epoch  8, batch    49 | loss: 67.6856402CurrentTrain: epoch  8, batch    50 | loss: 68.5174986CurrentTrain: epoch  8, batch    51 | loss: 67.7049215CurrentTrain: epoch  8, batch    52 | loss: 63.7236696CurrentTrain: epoch  8, batch    53 | loss: 102.7954015CurrentTrain: epoch  8, batch    54 | loss: 97.5020724CurrentTrain: epoch  8, batch    55 | loss: 78.5297174CurrentTrain: epoch  8, batch    56 | loss: 80.7357119CurrentTrain: epoch  8, batch    57 | loss: 90.6091252CurrentTrain: epoch  8, batch    58 | loss: 94.7081894CurrentTrain: epoch  8, batch    59 | loss: 121.3523330CurrentTrain: epoch  8, batch    60 | loss: 75.9139879CurrentTrain: epoch  8, batch    61 | loss: 99.8622411CurrentTrain: epoch  8, batch    62 | loss: 63.9442897CurrentTrain: epoch  8, batch    63 | loss: 67.8293812CurrentTrain: epoch  8, batch    64 | loss: 77.2163404CurrentTrain: epoch  8, batch    65 | loss: 95.9672003CurrentTrain: epoch  8, batch    66 | loss: 65.6994451CurrentTrain: epoch  8, batch    67 | loss: 76.6825049CurrentTrain: epoch  8, batch    68 | loss: 78.0872207CurrentTrain: epoch  8, batch    69 | loss: 68.2154344CurrentTrain: epoch  8, batch    70 | loss: 71.7218645CurrentTrain: epoch  8, batch    71 | loss: 66.5755953CurrentTrain: epoch  8, batch    72 | loss: 129.1601050CurrentTrain: epoch  8, batch    73 | loss: 66.1694217CurrentTrain: epoch  8, batch    74 | loss: 75.4386895CurrentTrain: epoch  8, batch    75 | loss: 99.1261920CurrentTrain: epoch  8, batch    76 | loss: 79.1414142CurrentTrain: epoch  8, batch    77 | loss: 66.1864638CurrentTrain: epoch  8, batch    78 | loss: 63.7670112CurrentTrain: epoch  8, batch    79 | loss: 53.9248525CurrentTrain: epoch  8, batch    80 | loss: 78.7937396CurrentTrain: epoch  8, batch    81 | loss: 64.6220267CurrentTrain: epoch  8, batch    82 | loss: 65.3361458CurrentTrain: epoch  8, batch    83 | loss: 63.7110093CurrentTrain: epoch  8, batch    84 | loss: 96.0196884CurrentTrain: epoch  8, batch    85 | loss: 78.8175468CurrentTrain: epoch  8, batch    86 | loss: 56.4717620CurrentTrain: epoch  8, batch    87 | loss: 77.3213245CurrentTrain: epoch  8, batch    88 | loss: 80.0301919CurrentTrain: epoch  8, batch    89 | loss: 66.5476140CurrentTrain: epoch  8, batch    90 | loss: 125.1397336CurrentTrain: epoch  8, batch    91 | loss: 63.8434961CurrentTrain: epoch  8, batch    92 | loss: 67.6023885CurrentTrain: epoch  8, batch    93 | loss: 97.6612060CurrentTrain: epoch  8, batch    94 | loss: 98.0325643CurrentTrain: epoch  8, batch    95 | loss: 82.3681204CurrentTrain: epoch  9, batch     0 | loss: 119.1790806CurrentTrain: epoch  9, batch     1 | loss: 79.4023959CurrentTrain: epoch  9, batch     2 | loss: 67.3425510CurrentTrain: epoch  9, batch     3 | loss: 119.9501648CurrentTrain: epoch  9, batch     4 | loss: 164.3878650CurrentTrain: epoch  9, batch     5 | loss: 97.3775305CurrentTrain: epoch  9, batch     6 | loss: 103.8139277CurrentTrain: epoch  9, batch     7 | loss: 64.2554806CurrentTrain: epoch  9, batch     8 | loss: 79.9471111CurrentTrain: epoch  9, batch     9 | loss: 81.2090901CurrentTrain: epoch  9, batch    10 | loss: 66.6976368CurrentTrain: epoch  9, batch    11 | loss: 78.0160877CurrentTrain: epoch  9, batch    12 | loss: 65.8153591CurrentTrain: epoch  9, batch    13 | loss: 78.9276882CurrentTrain: epoch  9, batch    14 | loss: 92.6159954CurrentTrain: epoch  9, batch    15 | loss: 56.7285446CurrentTrain: epoch  9, batch    16 | loss: 124.4152402CurrentTrain: epoch  9, batch    17 | loss: 122.6102529CurrentTrain: epoch  9, batch    18 | loss: 73.0051230CurrentTrain: epoch  9, batch    19 | loss: 95.9756114CurrentTrain: epoch  9, batch    20 | loss: 78.1705573CurrentTrain: epoch  9, batch    21 | loss: 95.8018511CurrentTrain: epoch  9, batch    22 | loss: 74.3231978CurrentTrain: epoch  9, batch    23 | loss: 91.0921903CurrentTrain: epoch  9, batch    24 | loss: 94.5114382CurrentTrain: epoch  9, batch    25 | loss: 97.5557508CurrentTrain: epoch  9, batch    26 | loss: 80.8620725CurrentTrain: epoch  9, batch    27 | loss: 167.8583602CurrentTrain: epoch  9, batch    28 | loss: 66.7193750CurrentTrain: epoch  9, batch    29 | loss: 93.3322947CurrentTrain: epoch  9, batch    30 | loss: 76.5707085CurrentTrain: epoch  9, batch    31 | loss: 72.9025394CurrentTrain: epoch  9, batch    32 | loss: 74.2863117CurrentTrain: epoch  9, batch    33 | loss: 76.0903112CurrentTrain: epoch  9, batch    34 | loss: 65.6557816CurrentTrain: epoch  9, batch    35 | loss: 65.9475820CurrentTrain: epoch  9, batch    36 | loss: 77.5502502CurrentTrain: epoch  9, batch    37 | loss: 65.3642467CurrentTrain: epoch  9, batch    38 | loss: 74.2982230CurrentTrain: epoch  9, batch    39 | loss: 98.6895093CurrentTrain: epoch  9, batch    40 | loss: 80.4007061CurrentTrain: epoch  9, batch    41 | loss: 74.7053093CurrentTrain: epoch  9, batch    42 | loss: 75.2045274CurrentTrain: epoch  9, batch    43 | loss: 66.9654884CurrentTrain: epoch  9, batch    44 | loss: 52.6696029CurrentTrain: epoch  9, batch    45 | loss: 65.8324431CurrentTrain: epoch  9, batch    46 | loss: 80.1154147CurrentTrain: epoch  9, batch    47 | loss: 57.0761147CurrentTrain: epoch  9, batch    48 | loss: 75.7712093CurrentTrain: epoch  9, batch    49 | loss: 74.0268640CurrentTrain: epoch  9, batch    50 | loss: 67.2420436CurrentTrain: epoch  9, batch    51 | loss: 68.1841322CurrentTrain: epoch  9, batch    52 | loss: 96.3810958CurrentTrain: epoch  9, batch    53 | loss: 98.0060151CurrentTrain: epoch  9, batch    54 | loss: 73.2562621CurrentTrain: epoch  9, batch    55 | loss: 77.1306800CurrentTrain: epoch  9, batch    56 | loss: 124.6311704CurrentTrain: epoch  9, batch    57 | loss: 75.7229347CurrentTrain: epoch  9, batch    58 | loss: 95.6713782CurrentTrain: epoch  9, batch    59 | loss: 74.0233202CurrentTrain: epoch  9, batch    60 | loss: 53.2460749CurrentTrain: epoch  9, batch    61 | loss: 77.5219799CurrentTrain: epoch  9, batch    62 | loss: 75.2706188CurrentTrain: epoch  9, batch    63 | loss: 97.4976371CurrentTrain: epoch  9, batch    64 | loss: 118.1557953CurrentTrain: epoch  9, batch    65 | loss: 123.2522031CurrentTrain: epoch  9, batch    66 | loss: 122.1463371CurrentTrain: epoch  9, batch    67 | loss: 78.4966464CurrentTrain: epoch  9, batch    68 | loss: 74.4867360CurrentTrain: epoch  9, batch    69 | loss: 63.2087686CurrentTrain: epoch  9, batch    70 | loss: 74.2752513CurrentTrain: epoch  9, batch    71 | loss: 66.8195040CurrentTrain: epoch  9, batch    72 | loss: 78.1615436CurrentTrain: epoch  9, batch    73 | loss: 117.1893866CurrentTrain: epoch  9, batch    74 | loss: 56.1465084CurrentTrain: epoch  9, batch    75 | loss: 61.8160172CurrentTrain: epoch  9, batch    76 | loss: 78.0961089CurrentTrain: epoch  9, batch    77 | loss: 62.4367423CurrentTrain: epoch  9, batch    78 | loss: 68.5631615CurrentTrain: epoch  9, batch    79 | loss: 56.4810036CurrentTrain: epoch  9, batch    80 | loss: 92.5149177CurrentTrain: epoch  9, batch    81 | loss: 97.4537156CurrentTrain: epoch  9, batch    82 | loss: 67.4314069CurrentTrain: epoch  9, batch    83 | loss: 67.4948399CurrentTrain: epoch  9, batch    84 | loss: 74.6001323CurrentTrain: epoch  9, batch    85 | loss: 81.2148655CurrentTrain: epoch  9, batch    86 | loss: 57.5200629CurrentTrain: epoch  9, batch    87 | loss: 122.0341465CurrentTrain: epoch  9, batch    88 | loss: 53.1815143CurrentTrain: epoch  9, batch    89 | loss: 56.4155840CurrentTrain: epoch  9, batch    90 | loss: 67.9179918CurrentTrain: epoch  9, batch    91 | loss: 118.5115502CurrentTrain: epoch  9, batch    92 | loss: 124.8277056CurrentTrain: epoch  9, batch    93 | loss: 61.6898772CurrentTrain: epoch  9, batch    94 | loss: 81.3751029CurrentTrain: epoch  9, batch    95 | loss: 108.7825130

F1 score per class: {32: np.float64(0.5699481865284974), 6: np.float64(0.8301886792452831), 19: np.float64(0.41025641025641024), 24: np.float64(0.7431693989071039), 26: np.float64(0.9292929292929293), 29: np.float64(0.8310502283105022)}
Micro-average F1 score: 0.7701149425287356
Weighted-average F1 score: 0.7723392440816598
F1 score per class: {32: np.float64(0.59), 6: np.float64(0.7666666666666667), 19: np.float64(0.21052631578947367), 24: np.float64(0.7457627118644068), 26: np.float64(0.9285714285714286), 29: np.float64(0.8348623853211009)}
Micro-average F1 score: 0.7353206865401988
Weighted-average F1 score: 0.7192261580194044
F1 score per class: {32: np.float64(0.5870646766169154), 6: np.float64(0.7982456140350878), 19: np.float64(0.27586206896551724), 24: np.float64(0.7457627118644068), 26: np.float64(0.9285714285714286), 29: np.float64(0.8256880733944955)}
Micro-average F1 score: 0.75139146567718
Weighted-average F1 score: 0.743752200554263

F1 score per class: {32: np.float64(0.5699481865284974), 6: np.float64(0.8301886792452831), 19: np.float64(0.41025641025641024), 24: np.float64(0.7431693989071039), 26: np.float64(0.9292929292929293), 29: np.float64(0.8310502283105022)}
Micro-average F1 score: 0.7701149425287356
Weighted-average F1 score: 0.7723392440816598
F1 score per class: {32: np.float64(0.59), 6: np.float64(0.7666666666666667), 19: np.float64(0.21052631578947367), 24: np.float64(0.7457627118644068), 26: np.float64(0.9285714285714286), 29: np.float64(0.8348623853211009)}
Micro-average F1 score: 0.7353206865401988
Weighted-average F1 score: 0.7192261580194044
F1 score per class: {32: np.float64(0.5870646766169154), 6: np.float64(0.7982456140350878), 19: np.float64(0.27586206896551724), 24: np.float64(0.7457627118644068), 26: np.float64(0.9285714285714286), 29: np.float64(0.8256880733944955)}
Micro-average F1 score: 0.75139146567718
Weighted-average F1 score: 0.743752200554263

F1 score per class: {32: np.float64(0.4166666666666667), 6: np.float64(0.7719298245614035), 19: np.float64(0.22535211267605634), 24: np.float64(0.6868686868686869), 26: np.float64(0.8518518518518519), 29: np.float64(0.6408450704225352)}
Micro-average F1 score: 0.6375892149088025
Weighted-average F1 score: 0.6233209312714892
F1 score per class: {32: np.float64(0.44360902255639095), 6: np.float64(0.7022900763358778), 19: np.float64(0.11851851851851852), 24: np.float64(0.6875), 26: np.float64(0.8584905660377359), 29: np.float64(0.6453900709219859)}
Micro-average F1 score: 0.603409933283914
Weighted-average F1 score: 0.575377488666026
F1 score per class: {32: np.float64(0.4419475655430712), 6: np.float64(0.7368421052631579), 19: np.float64(0.14414414414414414), 24: np.float64(0.6875), 26: np.float64(0.8584905660377359), 29: np.float64(0.6382978723404256)}
Micro-average F1 score: 0.6178489702517163
Weighted-average F1 score: 0.5940701065409412

F1 score per class: {32: np.float64(0.4166666666666667), 6: np.float64(0.7719298245614035), 19: np.float64(0.22535211267605634), 24: np.float64(0.6868686868686869), 26: np.float64(0.8518518518518519), 29: np.float64(0.6408450704225352)}
Micro-average F1 score: 0.6375892149088025
Weighted-average F1 score: 0.6233209312714892
F1 score per class: {32: np.float64(0.44360902255639095), 6: np.float64(0.7022900763358778), 19: np.float64(0.11851851851851852), 24: np.float64(0.6875), 26: np.float64(0.8584905660377359), 29: np.float64(0.6453900709219859)}
Micro-average F1 score: 0.603409933283914
Weighted-average F1 score: 0.575377488666026
F1 score per class: {32: np.float64(0.4419475655430712), 6: np.float64(0.7368421052631579), 19: np.float64(0.14414414414414414), 24: np.float64(0.6875), 26: np.float64(0.8584905660377359), 29: np.float64(0.6382978723404256)}
Micro-average F1 score: 0.6178489702517163
Weighted-average F1 score: 0.5940701065409412
cur_acc_wo_na:  ['0.7701']
his_acc_wo_na:  ['0.7701']
cur_acc des_wo_na:  ['0.7353']
his_acc des_wo_na:  ['0.7353']
cur_acc rrf_wo_na:  ['0.7514']
his_acc rrf_wo_na:  ['0.7514']
cur_acc_w_na:  ['0.6376']
his_acc_w_na:  ['0.6376']
cur_acc des_w_na:  ['0.6034']
his_acc des_w_na:  ['0.6034']
cur_acc rrf_w_na:  ['0.6178']
his_acc rrf_w_na:  ['0.6178']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 93.8010178CurrentTrain: epoch  0, batch     1 | loss: 120.5645059CurrentTrain: epoch  0, batch     2 | loss: 117.4878758CurrentTrain: epoch  0, batch     3 | loss: 119.5029327CurrentTrain: epoch  0, batch     4 | loss: 58.9159554CurrentTrain: epoch  1, batch     0 | loss: 90.1511907CurrentTrain: epoch  1, batch     1 | loss: 106.6617335CurrentTrain: epoch  1, batch     2 | loss: 111.9913008CurrentTrain: epoch  1, batch     3 | loss: 86.5957185CurrentTrain: epoch  1, batch     4 | loss: 88.8930646CurrentTrain: epoch  2, batch     0 | loss: 86.0249780CurrentTrain: epoch  2, batch     1 | loss: 106.6413446CurrentTrain: epoch  2, batch     2 | loss: 105.9299607CurrentTrain: epoch  2, batch     3 | loss: 84.4222387CurrentTrain: epoch  2, batch     4 | loss: 84.0573424CurrentTrain: epoch  3, batch     0 | loss: 266.7134409CurrentTrain: epoch  3, batch     1 | loss: 82.9348246CurrentTrain: epoch  3, batch     2 | loss: 84.2754763CurrentTrain: epoch  3, batch     3 | loss: 104.4231243CurrentTrain: epoch  3, batch     4 | loss: 54.4727955CurrentTrain: epoch  4, batch     0 | loss: 73.1432271CurrentTrain: epoch  4, batch     1 | loss: 97.6150910CurrentTrain: epoch  4, batch     2 | loss: 128.5535274CurrentTrain: epoch  4, batch     3 | loss: 84.3802661CurrentTrain: epoch  4, batch     4 | loss: 82.5763398CurrentTrain: epoch  5, batch     0 | loss: 103.2532094CurrentTrain: epoch  5, batch     1 | loss: 83.0245672CurrentTrain: epoch  5, batch     2 | loss: 122.6262612CurrentTrain: epoch  5, batch     3 | loss: 79.9883062CurrentTrain: epoch  5, batch     4 | loss: 77.9884735CurrentTrain: epoch  6, batch     0 | loss: 78.7274839CurrentTrain: epoch  6, batch     1 | loss: 124.3819644CurrentTrain: epoch  6, batch     2 | loss: 79.2313007CurrentTrain: epoch  6, batch     3 | loss: 124.8699152CurrentTrain: epoch  6, batch     4 | loss: 63.5864945CurrentTrain: epoch  7, batch     0 | loss: 67.8007193CurrentTrain: epoch  7, batch     1 | loss: 99.9714295CurrentTrain: epoch  7, batch     2 | loss: 65.5497494CurrentTrain: epoch  7, batch     3 | loss: 82.2058345CurrentTrain: epoch  7, batch     4 | loss: 161.5451433CurrentTrain: epoch  8, batch     0 | loss: 66.4334387CurrentTrain: epoch  8, batch     1 | loss: 124.8032763CurrentTrain: epoch  8, batch     2 | loss: 67.9237685CurrentTrain: epoch  8, batch     3 | loss: 79.4962875CurrentTrain: epoch  8, batch     4 | loss: 73.2050702CurrentTrain: epoch  9, batch     0 | loss: 64.4500461CurrentTrain: epoch  9, batch     1 | loss: 80.7573901CurrentTrain: epoch  9, batch     2 | loss: 78.3325422CurrentTrain: epoch  9, batch     3 | loss: 96.3816406CurrentTrain: epoch  9, batch     4 | loss: 76.6913969
MemoryTrain:  epoch  0, batch     0 | loss: 2.0258665MemoryTrain:  epoch  1, batch     0 | loss: 1.6774951MemoryTrain:  epoch  2, batch     0 | loss: 1.4963386MemoryTrain:  epoch  3, batch     0 | loss: 1.1635643MemoryTrain:  epoch  4, batch     0 | loss: 0.8989483MemoryTrain:  epoch  5, batch     0 | loss: 0.8482138MemoryTrain:  epoch  6, batch     0 | loss: 0.6545584MemoryTrain:  epoch  7, batch     0 | loss: 0.4888612MemoryTrain:  epoch  8, batch     0 | loss: 0.3902623MemoryTrain:  epoch  9, batch     0 | loss: 0.3197782

F1 score per class: {32: np.float64(0.8942307692307693), 5: np.float64(0.0), 6: np.float64(0.09523809523809523), 10: np.float64(0.5957446808510638), 16: np.float64(0.0), 17: np.float64(0.2608695652173913), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5232815964523282
Weighted-average F1 score: 0.6258777097973609
F1 score per class: {32: np.float64(0.7421875), 5: np.float64(0.0), 6: np.float64(0.49645390070921985), 10: np.float64(0.5666666666666667), 16: np.float64(0.36363636363636365), 17: np.float64(0.5230769230769231), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.564625850340136
Weighted-average F1 score: 0.540093866995207
F1 score per class: {32: np.float64(0.7916666666666666), 5: np.float64(0.0), 6: np.float64(0.3779527559055118), 10: np.float64(0.5517241379310345), 16: np.float64(0.36363636363636365), 17: np.float64(0.5079365079365079), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5604395604395604
Weighted-average F1 score: 0.557110946438789

F1 score per class: {32: np.float64(0.8942307692307693), 5: np.float64(0.543778801843318), 6: np.float64(0.09523809523809523), 10: np.float64(0.5957446808510638), 16: np.float64(0.0), 17: np.float64(0.24), 18: np.float64(0.7755102040816326), 19: np.float64(0.34782608695652173), 24: np.float64(0.7351351351351352), 26: np.float64(0.8979591836734694), 29: np.float64(0.7796610169491526)}
Micro-average F1 score: 0.6799742433998712
Weighted-average F1 score: 0.7257384313492667
F1 score per class: {32: np.float64(0.7037037037037037), 5: np.float64(0.5925925925925926), 6: np.float64(0.44871794871794873), 10: np.float64(0.5396825396825397), 16: np.float64(0.17391304347826086), 17: np.float64(0.4657534246575342), 18: np.float64(0.7058823529411765), 19: np.float64(0.2597402597402597), 24: np.float64(0.7216494845360825), 26: np.float64(0.8932038834951457), 29: np.float64(0.7430830039525692)}
Micro-average F1 score: 0.6566833056017748
Weighted-average F1 score: 0.6575349930987553
F1 score per class: {32: np.float64(0.7755102040816326), 5: np.float64(0.5963302752293578), 6: np.float64(0.34532374100719426), 10: np.float64(0.5333333333333333), 16: np.float64(0.18181818181818182), 17: np.float64(0.45714285714285713), 18: np.float64(0.7307692307692307), 19: np.float64(0.3225806451612903), 24: np.float64(0.7216494845360825), 26: np.float64(0.8921568627450981), 29: np.float64(0.7530364372469636)}
Micro-average F1 score: 0.6705403834979663
Weighted-average F1 score: 0.681947438484241

F1 score per class: {32: np.float64(0.7717842323651453), 5: np.float64(0.0), 6: np.float64(0.09433962264150944), 10: np.float64(0.3835616438356164), 16: np.float64(0.0), 17: np.float64(0.1875), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.40480274442538594
Weighted-average F1 score: 0.42652529375982423
F1 score per class: {32: np.float64(0.5705705705705706), 5: np.float64(0.0), 6: np.float64(0.42168674698795183), 10: np.float64(0.37777777777777777), 16: np.float64(0.2222222222222222), 17: np.float64(0.4), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.4129353233830846
Weighted-average F1 score: 0.3875775282401789
F1 score per class: {32: np.float64(0.6168831168831169), 5: np.float64(0.0), 6: np.float64(0.3333333333333333), 10: np.float64(0.3595505617977528), 16: np.float64(0.21052631578947367), 17: np.float64(0.35555555555555557), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.40854472630173566
Weighted-average F1 score: 0.3914197584075298

F1 score per class: {32: np.float64(0.7654320987654321), 5: np.float64(0.3522388059701492), 6: np.float64(0.09174311926605505), 10: np.float64(0.3684210526315789), 16: np.float64(0.0), 17: np.float64(0.17142857142857143), 18: np.float64(0.6959706959706959), 19: np.float64(0.18823529411764706), 24: np.float64(0.6507177033492823), 26: np.float64(0.7927927927927928), 29: np.float64(0.5897435897435898)}
Micro-average F1 score: 0.5390505359877489
Weighted-average F1 score: 0.5505170775950885
F1 score per class: {32: np.float64(0.5234159779614325), 5: np.float64(0.38323353293413176), 6: np.float64(0.3482587064676617), 10: np.float64(0.3469387755102041), 16: np.float64(0.10810810810810811), 17: np.float64(0.33663366336633666), 18: np.float64(0.6193548387096774), 19: np.float64(0.136986301369863), 24: np.float64(0.625), 26: np.float64(0.757201646090535), 29: np.float64(0.5513196480938416)}
Micro-average F1 score: 0.493744787322769
Weighted-average F1 score: 0.4843636095802873
F1 score per class: {32: np.float64(0.5846153846153846), 5: np.float64(0.38922155688622756), 6: np.float64(0.27906976744186046), 10: np.float64(0.32989690721649484), 16: np.float64(0.10810810810810811), 17: np.float64(0.3076923076923077), 18: np.float64(0.6418918918918919), 19: np.float64(0.16806722689075632), 24: np.float64(0.6306306306306306), 26: np.float64(0.7777777777777778), 29: np.float64(0.5568862275449101)}
Micro-average F1 score: 0.5074758135444152
Weighted-average F1 score: 0.5018317369344696
cur_acc_wo_na:  ['0.7701', '0.5233']
his_acc_wo_na:  ['0.7701', '0.6800']
cur_acc des_wo_na:  ['0.7353', '0.5646']
his_acc des_wo_na:  ['0.7353', '0.6567']
cur_acc rrf_wo_na:  ['0.7514', '0.5604']
his_acc rrf_wo_na:  ['0.7514', '0.6705']
cur_acc_w_na:  ['0.6376', '0.4048']
his_acc_w_na:  ['0.6376', '0.5391']
cur_acc des_w_na:  ['0.6034', '0.4129']
his_acc des_w_na:  ['0.6034', '0.4937']
cur_acc rrf_w_na:  ['0.6178', '0.4085']
his_acc rrf_w_na:  ['0.6178', '0.5075']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 80.9527858CurrentTrain: epoch  0, batch     1 | loss: 97.5123136CurrentTrain: epoch  0, batch     2 | loss: 113.5946898CurrentTrain: epoch  0, batch     3 | loss: 80.1273983CurrentTrain: epoch  0, batch     4 | loss: 40.8467538CurrentTrain: epoch  1, batch     0 | loss: 91.9921417CurrentTrain: epoch  1, batch     1 | loss: 78.5551067CurrentTrain: epoch  1, batch     2 | loss: 91.1951453CurrentTrain: epoch  1, batch     3 | loss: 85.4429691CurrentTrain: epoch  1, batch     4 | loss: 39.0159449CurrentTrain: epoch  2, batch     0 | loss: 100.9368471CurrentTrain: epoch  2, batch     1 | loss: 88.4024332CurrentTrain: epoch  2, batch     2 | loss: 103.3471558CurrentTrain: epoch  2, batch     3 | loss: 67.4985253CurrentTrain: epoch  2, batch     4 | loss: 25.0970617CurrentTrain: epoch  3, batch     0 | loss: 84.4024390CurrentTrain: epoch  3, batch     1 | loss: 71.9820569CurrentTrain: epoch  3, batch     2 | loss: 100.5836473CurrentTrain: epoch  3, batch     3 | loss: 82.2883122CurrentTrain: epoch  3, batch     4 | loss: 13.2439843CurrentTrain: epoch  4, batch     0 | loss: 101.1118421CurrentTrain: epoch  4, batch     1 | loss: 80.2077127CurrentTrain: epoch  4, batch     2 | loss: 64.6914320CurrentTrain: epoch  4, batch     3 | loss: 82.0695309CurrentTrain: epoch  4, batch     4 | loss: 40.9878740CurrentTrain: epoch  5, batch     0 | loss: 79.2425149CurrentTrain: epoch  5, batch     1 | loss: 95.6759985CurrentTrain: epoch  5, batch     2 | loss: 94.5852519CurrentTrain: epoch  5, batch     3 | loss: 78.1939388CurrentTrain: epoch  5, batch     4 | loss: 40.6225661CurrentTrain: epoch  6, batch     0 | loss: 64.9281073CurrentTrain: epoch  6, batch     1 | loss: 80.6395811CurrentTrain: epoch  6, batch     2 | loss: 77.3759817CurrentTrain: epoch  6, batch     3 | loss: 98.8017395CurrentTrain: epoch  6, batch     4 | loss: 15.8501417CurrentTrain: epoch  7, batch     0 | loss: 95.0014518CurrentTrain: epoch  7, batch     1 | loss: 96.7608152CurrentTrain: epoch  7, batch     2 | loss: 70.2537753CurrentTrain: epoch  7, batch     3 | loss: 122.4599106CurrentTrain: epoch  7, batch     4 | loss: 23.6513545CurrentTrain: epoch  8, batch     0 | loss: 96.6209897CurrentTrain: epoch  8, batch     1 | loss: 90.4435974CurrentTrain: epoch  8, batch     2 | loss: 65.0366329CurrentTrain: epoch  8, batch     3 | loss: 65.6859969CurrentTrain: epoch  8, batch     4 | loss: 24.6179171CurrentTrain: epoch  9, batch     0 | loss: 77.3939581CurrentTrain: epoch  9, batch     1 | loss: 74.6680625CurrentTrain: epoch  9, batch     2 | loss: 74.7722145CurrentTrain: epoch  9, batch     3 | loss: 78.0427267CurrentTrain: epoch  9, batch     4 | loss: 25.6300491
MemoryTrain:  epoch  0, batch     0 | loss: 1.2823455MemoryTrain:  epoch  1, batch     0 | loss: 1.2258961MemoryTrain:  epoch  2, batch     0 | loss: 0.8595287MemoryTrain:  epoch  3, batch     0 | loss: 0.6871748MemoryTrain:  epoch  4, batch     0 | loss: 0.6009503MemoryTrain:  epoch  5, batch     0 | loss: 0.4685267MemoryTrain:  epoch  6, batch     0 | loss: 0.4356295MemoryTrain:  epoch  7, batch     0 | loss: 0.3498144MemoryTrain:  epoch  8, batch     0 | loss: 0.3074812MemoryTrain:  epoch  9, batch     0 | loss: 0.2645884

F1 score per class: {32: np.float64(0.6), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.5774647887323944), 39: np.float64(0.4507042253521127), 11: np.float64(0.0), 12: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.2702702702702703), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.3225806451612903)}
Micro-average F1 score: 0.43734643734643736
Weighted-average F1 score: 0.3725233237336053
F1 score per class: {32: np.float64(0.5384615384615384), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.5147058823529411), 11: np.float64(0.6321243523316062), 12: np.float64(0.0), 10: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.2857142857142857), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.24242424242424243)}
Micro-average F1 score: 0.43545279383429675
Weighted-average F1 score: 0.3565587986465768
F1 score per class: {32: np.float64(0.6666666666666666), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.5633802816901409), 11: np.float64(0.6214689265536724), 12: np.float64(0.0), 10: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.26666666666666666), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.24242424242424243)}
Micro-average F1 score: 0.46764091858037576
Weighted-average F1 score: 0.3874937301101064

F1 score per class: {32: np.float64(0.5217391304347826), 2: np.float64(0.8975609756097561), 5: np.float64(0.5462962962962963), 6: np.float64(0.038834951456310676), 39: np.float64(0.4), 11: np.float64(0.3333333333333333), 12: np.float64(0.358974358974359), 10: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.774468085106383), 18: np.float64(0.35), 19: np.float64(0.7262569832402235), 24: np.float64(0.10638297872340426), 26: np.float64(0.8415300546448088), 28: np.float64(0.7389558232931727), 29: np.float64(0.2631578947368421)}
Micro-average F1 score: 0.5671059053196681
Weighted-average F1 score: 0.5895523092690393
F1 score per class: {32: np.float64(0.4117647058823529), 2: np.float64(0.6959706959706959), 5: np.float64(0.5461254612546126), 6: np.float64(0.32432432432432434), 39: np.float64(0.4), 11: np.float64(0.35777126099706746), 12: np.float64(0.46808510638297873), 10: np.float64(0.0), 16: np.float64(0.3389830508474576), 17: np.float64(0.749003984063745), 18: np.float64(0.23809523809523808), 19: np.float64(0.7368421052631579), 24: np.float64(0.15), 26: np.float64(0.8415300546448088), 28: np.float64(0.6025641025641025), 29: np.float64(0.20512820512820512)}
Micro-average F1 score: 0.5384615384615384
Weighted-average F1 score: 0.5291560913745468
F1 score per class: {32: np.float64(0.5833333333333334), 2: np.float64(0.7800829875518672), 5: np.float64(0.5714285714285714), 6: np.float64(0.18181818181818182), 39: np.float64(0.40816326530612246), 11: np.float64(0.3971119133574007), 12: np.float64(0.4782608695652174), 10: np.float64(0.0), 16: np.float64(0.2127659574468085), 17: np.float64(0.7611336032388664), 18: np.float64(0.3448275862068966), 19: np.float64(0.7351351351351352), 24: np.float64(0.125), 26: np.float64(0.8415300546448088), 28: np.float64(0.6484641638225256), 29: np.float64(0.2)}
Micro-average F1 score: 0.5606585788561526
Weighted-average F1 score: 0.5628834814587745

F1 score per class: {32: np.float64(0.41379310344827586), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.4880952380952381), 39: np.float64(0.3878787878787879), 11: np.float64(0.0), 12: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.136986301369863), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.2222222222222222)}
Micro-average F1 score: 0.31393298059964725
Weighted-average F1 score: 0.2538178184098729
F1 score per class: {32: np.float64(0.358974358974359), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.45751633986928103), 11: np.float64(0.4899598393574297), 12: np.float64(0.0), 10: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.1643835616438356), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.16666666666666666)}
Micro-average F1 score: 0.29815303430079154
Weighted-average F1 score: 0.2409339649322951
F1 score per class: {32: np.float64(0.4117647058823529), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 39: np.float64(0.4819277108433735), 11: np.float64(0.49107142857142855), 12: np.float64(0.0), 10: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.14814814814814814), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.16666666666666666)}
Micro-average F1 score: 0.32230215827338127
Weighted-average F1 score: 0.2631487767167659

F1 score per class: {32: np.float64(0.35294117647058826), 2: np.float64(0.7666666666666667), 5: np.float64(0.3268698060941828), 6: np.float64(0.038461538461538464), 39: np.float64(0.27796610169491526), 11: np.float64(0.191044776119403), 12: np.float64(0.2978723404255319), 10: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.7054263565891473), 18: np.float64(0.2222222222222222), 19: np.float64(0.6632653061224489), 24: np.float64(0.056818181818181816), 26: np.float64(0.77), 28: np.float64(0.5508982035928144), 29: np.float64(0.14705882352941177)}
Micro-average F1 score: 0.41828653707703384
Weighted-average F1 score: 0.40660040107720613
F1 score per class: {32: np.float64(0.23728813559322035), 2: np.float64(0.48346055979643765), 5: np.float64(0.3162393162393162), 6: np.float64(0.25396825396825395), 39: np.float64(0.3056768558951965), 11: np.float64(0.19092331768388107), 12: np.float64(0.3283582089552239), 10: np.float64(0.0), 16: np.float64(0.1652892561983471), 17: np.float64(0.6690391459074733), 18: np.float64(0.14084507042253522), 19: np.float64(0.6422018348623854), 24: np.float64(0.0821917808219178), 26: np.float64(0.7661691542288557), 28: np.float64(0.4486873508353222), 29: np.float64(0.11428571428571428)}
Micro-average F1 score: 0.3677154582763338
Weighted-average F1 score: 0.3471373034998163
F1 score per class: {32: np.float64(0.3111111111111111), 2: np.float64(0.5449275362318841), 5: np.float64(0.33980582524271846), 6: np.float64(0.15942028985507245), 39: np.float64(0.2888086642599278), 11: np.float64(0.20220588235294118), 12: np.float64(0.3728813559322034), 10: np.float64(0.0), 16: np.float64(0.12195121951219512), 17: np.float64(0.6861313868613139), 18: np.float64(0.20408163265306123), 19: np.float64(0.6507177033492823), 24: np.float64(0.06857142857142857), 26: np.float64(0.7661691542288557), 28: np.float64(0.4810126582278481), 29: np.float64(0.1111111111111111)}
Micro-average F1 score: 0.3876572798082684
Weighted-average F1 score: 0.37043852117777865
cur_acc_wo_na:  ['0.7701', '0.5233', '0.4373']
his_acc_wo_na:  ['0.7701', '0.6800', '0.5671']
cur_acc des_wo_na:  ['0.7353', '0.5646', '0.4355']
his_acc des_wo_na:  ['0.7353', '0.6567', '0.5385']
cur_acc rrf_wo_na:  ['0.7514', '0.5604', '0.4676']
his_acc rrf_wo_na:  ['0.7514', '0.6705', '0.5607']
cur_acc_w_na:  ['0.6376', '0.4048', '0.3139']
his_acc_w_na:  ['0.6376', '0.5391', '0.4183']
cur_acc des_w_na:  ['0.6034', '0.4129', '0.2982']
his_acc des_w_na:  ['0.6034', '0.4937', '0.3677']
cur_acc rrf_w_na:  ['0.6178', '0.4085', '0.3223']
his_acc rrf_w_na:  ['0.6178', '0.5075', '0.3877']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 114.7089127CurrentTrain: epoch  0, batch     1 | loss: 121.6239859CurrentTrain: epoch  0, batch     2 | loss: 99.3085886CurrentTrain: epoch  0, batch     3 | loss: 104.5231037CurrentTrain: epoch  1, batch     0 | loss: 93.0256238CurrentTrain: epoch  1, batch     1 | loss: 81.7587702CurrentTrain: epoch  1, batch     2 | loss: 105.9655079CurrentTrain: epoch  1, batch     3 | loss: 80.9414673CurrentTrain: epoch  2, batch     0 | loss: 106.9774901CurrentTrain: epoch  2, batch     1 | loss: 85.0958312CurrentTrain: epoch  2, batch     2 | loss: 91.2094925CurrentTrain: epoch  2, batch     3 | loss: 84.8913804CurrentTrain: epoch  3, batch     0 | loss: 105.4969981CurrentTrain: epoch  3, batch     1 | loss: 103.0848487CurrentTrain: epoch  3, batch     2 | loss: 87.8287580CurrentTrain: epoch  3, batch     3 | loss: 77.6447739CurrentTrain: epoch  4, batch     0 | loss: 101.6844405CurrentTrain: epoch  4, batch     1 | loss: 85.7121453CurrentTrain: epoch  4, batch     2 | loss: 83.5718529CurrentTrain: epoch  4, batch     3 | loss: 68.7617394CurrentTrain: epoch  5, batch     0 | loss: 82.0582080CurrentTrain: epoch  5, batch     1 | loss: 122.9568831CurrentTrain: epoch  5, batch     2 | loss: 100.0539446CurrentTrain: epoch  5, batch     3 | loss: 58.9482521CurrentTrain: epoch  6, batch     0 | loss: 65.5640494CurrentTrain: epoch  6, batch     1 | loss: 84.2752866CurrentTrain: epoch  6, batch     2 | loss: 78.9418784CurrentTrain: epoch  6, batch     3 | loss: 143.1311916CurrentTrain: epoch  7, batch     0 | loss: 99.6647544CurrentTrain: epoch  7, batch     1 | loss: 97.5422568CurrentTrain: epoch  7, batch     2 | loss: 79.0982801CurrentTrain: epoch  7, batch     3 | loss: 78.9506821CurrentTrain: epoch  8, batch     0 | loss: 68.0912050CurrentTrain: epoch  8, batch     1 | loss: 67.4997424CurrentTrain: epoch  8, batch     2 | loss: 82.3124327CurrentTrain: epoch  8, batch     3 | loss: 79.5835717CurrentTrain: epoch  9, batch     0 | loss: 66.0824956CurrentTrain: epoch  9, batch     1 | loss: 62.4758175CurrentTrain: epoch  9, batch     2 | loss: 171.0879844CurrentTrain: epoch  9, batch     3 | loss: 101.9901088
MemoryTrain:  epoch  0, batch     0 | loss: 1.2176113MemoryTrain:  epoch  1, batch     0 | loss: 1.0375996MemoryTrain:  epoch  2, batch     0 | loss: 0.8181829MemoryTrain:  epoch  3, batch     0 | loss: 0.6607247MemoryTrain:  epoch  4, batch     0 | loss: 0.6222408MemoryTrain:  epoch  5, batch     0 | loss: 0.5979509MemoryTrain:  epoch  6, batch     0 | loss: 0.5050900MemoryTrain:  epoch  7, batch     0 | loss: 0.4367613MemoryTrain:  epoch  8, batch     0 | loss: 0.3828187MemoryTrain:  epoch  9, batch     0 | loss: 0.3661758

F1 score per class: {0: np.float64(0.8695652173913043), 2: np.float64(0.0), 4: np.float64(0.8457142857142858), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.3076923076923077), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.5641025641025641), 23: np.float64(0.8470588235294118), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.6393762183235867
Weighted-average F1 score: 0.5201954015480198
F1 score per class: {0: np.float64(0.8148148148148148), 2: np.float64(0.0), 4: np.float64(0.8359788359788359), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.3333333333333333), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.4421052631578947), 23: np.float64(0.7586206896551724), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5428109854604201
Weighted-average F1 score: 0.4291400150767261
F1 score per class: {0: np.float64(0.8311688311688312), 2: np.float64(0.0), 4: np.float64(0.850828729281768), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.2857142857142857), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.4375), 23: np.float64(0.7857142857142857), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5602716468590832
Weighted-average F1 score: 0.43968628038328894

F1 score per class: {0: np.float64(0.8), 2: np.float64(0.4375), 4: np.float64(0.8457142857142858), 5: np.float64(0.8867924528301887), 6: np.float64(0.5263157894736842), 10: np.float64(0.11009174311926606), 11: np.float64(0.39316239316239315), 12: np.float64(0.31351351351351353), 13: np.float64(0.04878048780487805), 16: np.float64(0.3333333333333333), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.7591836734693878), 21: np.float64(0.36065573770491804), 23: np.float64(0.7741935483870968), 24: np.float64(0.2727272727272727), 26: np.float64(0.7085714285714285), 28: np.float64(0.16666666666666666), 29: np.float64(0.8497409326424871), 32: np.float64(0.6891385767790262), 39: np.float64(0.18604651162790697)}
Micro-average F1 score: 0.573720397249809
Weighted-average F1 score: 0.5763895792802146
F1 score per class: {0: np.float64(0.584070796460177), 2: np.float64(0.2978723404255319), 4: np.float64(0.8020304568527918), 5: np.float64(0.6643598615916955), 6: np.float64(0.5121107266435986), 10: np.float64(0.36024844720496896), 11: np.float64(0.3894736842105263), 12: np.float64(0.3484848484848485), 13: np.float64(0.09090909090909091), 16: np.float64(0.41509433962264153), 17: np.float64(0.0), 18: np.float64(0.37681159420289856), 19: np.float64(0.6962962962962963), 21: np.float64(0.1917808219178082), 23: np.float64(0.7415730337078652), 24: np.float64(0.35714285714285715), 26: np.float64(0.696969696969697), 28: np.float64(0.1388888888888889), 29: np.float64(0.8272251308900523), 32: np.float64(0.617363344051447), 39: np.float64(0.16666666666666666)}
Micro-average F1 score: 0.5273474549478343
Weighted-average F1 score: 0.5074634226904705
F1 score per class: {0: np.float64(0.6464646464646465), 2: np.float64(0.358974358974359), 4: np.float64(0.8415300546448088), 5: np.float64(0.7470817120622568), 6: np.float64(0.5298507462686567), 10: np.float64(0.265625), 11: np.float64(0.39436619718309857), 12: np.float64(0.35537190082644626), 13: np.float64(0.056338028169014086), 16: np.float64(0.42857142857142855), 17: np.float64(0.0), 18: np.float64(0.18867924528301888), 19: np.float64(0.7014925373134329), 21: np.float64(0.1935483870967742), 23: np.float64(0.7586206896551724), 24: np.float64(0.35714285714285715), 26: np.float64(0.7150259067357513), 28: np.float64(0.15384615384615385), 29: np.float64(0.8333333333333334), 32: np.float64(0.6229508196721312), 39: np.float64(0.17543859649122806)}
Micro-average F1 score: 0.5358090185676393
Weighted-average F1 score: 0.5165614099353751

F1 score per class: {0: np.float64(0.821917808219178), 2: np.float64(0.0), 4: np.float64(0.8131868131868132), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.19047619047619047), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.3963963963963964), 23: np.float64(0.782608695652174), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.4837758112094395
Weighted-average F1 score: 0.36298489484909974
F1 score per class: {0: np.float64(0.7415730337078652), 2: np.float64(0.0), 4: np.float64(0.7783251231527094), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.26666666666666666), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.32061068702290074), 23: np.float64(0.6804123711340206), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.39069767441860465
Weighted-average F1 score: 0.2929338115049935
F1 score per class: {0: np.float64(0.7710843373493976), 2: np.float64(0.0), 4: np.float64(0.806282722513089), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.17391304347826086), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.32558139534883723), 23: np.float64(0.7021276595744681), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.40993788819875776
Weighted-average F1 score: 0.30235729708300535

F1 score per class: {0: np.float64(0.6976744186046512), 2: np.float64(0.2857142857142857), 4: np.float64(0.7872340425531915), 5: np.float64(0.7014925373134329), 6: np.float64(0.30303030303030304), 10: np.float64(0.10344827586206896), 11: np.float64(0.26436781609195403), 12: np.float64(0.17575757575757575), 13: np.float64(0.027210884353741496), 16: np.float64(0.2727272727272727), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.6666666666666666), 21: np.float64(0.21256038647342995), 23: np.float64(0.6666666666666666), 24: np.float64(0.2), 26: np.float64(0.6458333333333334), 28: np.float64(0.10526315789473684), 29: np.float64(0.7522935779816514), 32: np.float64(0.48293963254593175), 39: np.float64(0.09302325581395349)}
Micro-average F1 score: 0.4169905607995558
Weighted-average F1 score: 0.39531264113868386
F1 score per class: {0: np.float64(0.4782608695652174), 2: np.float64(0.18421052631578946), 4: np.float64(0.6810344827586207), 5: np.float64(0.4314606741573034), 6: np.float64(0.2840690978886756), 10: np.float64(0.26605504587155965), 11: np.float64(0.30327868852459017), 12: np.float64(0.19047619047619047), 13: np.float64(0.05970149253731343), 16: np.float64(0.27848101265822783), 17: np.float64(0.0), 18: np.float64(0.1793103448275862), 19: np.float64(0.6025641025641025), 21: np.float64(0.125), 23: np.float64(0.6346153846153846), 24: np.float64(0.21739130434782608), 26: np.float64(0.6), 28: np.float64(0.07246376811594203), 29: np.float64(0.7214611872146118), 32: np.float64(0.42761692650334077), 39: np.float64(0.09259259259259259)}
Micro-average F1 score: 0.36190062920373184
Weighted-average F1 score: 0.33966402966770687
F1 score per class: {0: np.float64(0.5565217391304348), 2: np.float64(0.20588235294117646), 4: np.float64(0.7549019607843137), 5: np.float64(0.49612403100775193), 6: np.float64(0.30148619957537154), 10: np.float64(0.22666666666666666), 11: np.float64(0.27722772277227725), 12: np.float64(0.19282511210762332), 13: np.float64(0.03389830508474576), 16: np.float64(0.32142857142857145), 17: np.float64(0.0), 18: np.float64(0.11494252873563218), 19: np.float64(0.6084142394822006), 21: np.float64(0.12727272727272726), 23: np.float64(0.6534653465346535), 24: np.float64(0.23255813953488372), 26: np.float64(0.6272727272727273), 28: np.float64(0.07936507936507936), 29: np.float64(0.7207207207207207), 32: np.float64(0.4328018223234624), 39: np.float64(0.09345794392523364)}
Micro-average F1 score: 0.37416068534382957
Weighted-average F1 score: 0.3493795983318453
cur_acc_wo_na:  ['0.7701', '0.5233', '0.4373', '0.6394']
his_acc_wo_na:  ['0.7701', '0.6800', '0.5671', '0.5737']
cur_acc des_wo_na:  ['0.7353', '0.5646', '0.4355', '0.5428']
his_acc des_wo_na:  ['0.7353', '0.6567', '0.5385', '0.5273']
cur_acc rrf_wo_na:  ['0.7514', '0.5604', '0.4676', '0.5603']
his_acc rrf_wo_na:  ['0.7514', '0.6705', '0.5607', '0.5358']
cur_acc_w_na:  ['0.6376', '0.4048', '0.3139', '0.4838']
his_acc_w_na:  ['0.6376', '0.5391', '0.4183', '0.4170']
cur_acc des_w_na:  ['0.6034', '0.4129', '0.2982', '0.3907']
his_acc des_w_na:  ['0.6034', '0.4937', '0.3677', '0.3619']
cur_acc rrf_w_na:  ['0.6178', '0.4085', '0.3223', '0.4099']
his_acc rrf_w_na:  ['0.6178', '0.5075', '0.3877', '0.3742']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 76.0504460CurrentTrain: epoch  0, batch     1 | loss: 115.6467005CurrentTrain: epoch  0, batch     2 | loss: 94.1125755CurrentTrain: epoch  0, batch     3 | loss: 78.6690506CurrentTrain: epoch  1, batch     0 | loss: 91.1233070CurrentTrain: epoch  1, batch     1 | loss: 73.5570097CurrentTrain: epoch  1, batch     2 | loss: 134.1320988CurrentTrain: epoch  1, batch     3 | loss: 55.3259067CurrentTrain: epoch  2, batch     0 | loss: 100.6524065CurrentTrain: epoch  2, batch     1 | loss: 79.6522591CurrentTrain: epoch  2, batch     2 | loss: 71.4556395CurrentTrain: epoch  2, batch     3 | loss: 73.1729287CurrentTrain: epoch  3, batch     0 | loss: 83.0472323CurrentTrain: epoch  3, batch     1 | loss: 79.8411295CurrentTrain: epoch  3, batch     2 | loss: 82.7711745CurrentTrain: epoch  3, batch     3 | loss: 85.4823204CurrentTrain: epoch  4, batch     0 | loss: 80.9975996CurrentTrain: epoch  4, batch     1 | loss: 85.5425536CurrentTrain: epoch  4, batch     2 | loss: 68.2549716CurrentTrain: epoch  4, batch     3 | loss: 52.1565403CurrentTrain: epoch  5, batch     0 | loss: 79.9577361CurrentTrain: epoch  5, batch     1 | loss: 75.3325846CurrentTrain: epoch  5, batch     2 | loss: 80.6220463CurrentTrain: epoch  5, batch     3 | loss: 68.8961533CurrentTrain: epoch  6, batch     0 | loss: 73.0748868CurrentTrain: epoch  6, batch     1 | loss: 67.3216565CurrentTrain: epoch  6, batch     2 | loss: 100.0687893CurrentTrain: epoch  6, batch     3 | loss: 53.7119609CurrentTrain: epoch  7, batch     0 | loss: 76.5852909CurrentTrain: epoch  7, batch     1 | loss: 78.7015167CurrentTrain: epoch  7, batch     2 | loss: 94.3534495CurrentTrain: epoch  7, batch     3 | loss: 63.2650227CurrentTrain: epoch  8, batch     0 | loss: 95.5971770CurrentTrain: epoch  8, batch     1 | loss: 64.1642177CurrentTrain: epoch  8, batch     2 | loss: 74.4841339CurrentTrain: epoch  8, batch     3 | loss: 64.2223849CurrentTrain: epoch  9, batch     0 | loss: 77.3164039CurrentTrain: epoch  9, batch     1 | loss: 77.0553760CurrentTrain: epoch  9, batch     2 | loss: 80.2155845CurrentTrain: epoch  9, batch     3 | loss: 46.4351997
MemoryTrain:  epoch  0, batch     0 | loss: 0.9818434MemoryTrain:  epoch  1, batch     0 | loss: 0.9522301MemoryTrain:  epoch  2, batch     0 | loss: 0.7498482MemoryTrain:  epoch  3, batch     0 | loss: 0.6489100MemoryTrain:  epoch  4, batch     0 | loss: 0.5787772MemoryTrain:  epoch  5, batch     0 | loss: 0.4866923MemoryTrain:  epoch  6, batch     0 | loss: 0.4303303MemoryTrain:  epoch  7, batch     0 | loss: 0.3435924MemoryTrain:  epoch  8, batch     0 | loss: 0.2836566MemoryTrain:  epoch  9, batch     0 | loss: 0.2826812

F1 score per class: {5: np.float64(0.0), 6: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.8), 17: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.42424242424242425), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.4810126582278481), 37: np.float64(0.6593406593406593), 38: np.float64(0.5714285714285714), 39: np.float64(0.0)}
Micro-average F1 score: 0.40987654320987654
Weighted-average F1 score: 0.2737613176928143
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.7058823529411765), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5526315789473685), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.7070707070707071), 37: np.float64(0.6851851851851852), 38: np.float64(0.6923076923076923), 39: np.float64(0.0)}
Micro-average F1 score: 0.45792563600782776
Weighted-average F1 score: 0.32789678002900813
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.631578947368421), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5555555555555556), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6373626373626373), 37: np.float64(0.6470588235294118), 38: np.float64(0.6666666666666666), 39: np.float64(0.0)}
Micro-average F1 score: 0.4342379958246347
Weighted-average F1 score: 0.29784039947302526

F1 score per class: {0: np.float64(0.8169014084507042), 2: np.float64(0.4), 4: np.float64(0.8165680473372781), 5: np.float64(0.8103448275862069), 6: np.float64(0.4978540772532189), 10: np.float64(0.11320754716981132), 11: np.float64(0.22099447513812154), 12: np.float64(0.2603550295857988), 13: np.float64(0.035398230088495575), 15: np.float64(0.26229508196721313), 16: np.float64(0.42105263157894735), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.7131782945736435), 21: np.float64(0.25263157894736843), 23: np.float64(0.7816091954022989), 24: np.float64(0.3076923076923077), 25: np.float64(0.42424242424242425), 26: np.float64(0.7222222222222222), 28: np.float64(0.18181818181818182), 29: np.float64(0.8350515463917526), 32: np.float64(0.6480836236933798), 35: np.float64(0.2814814814814815), 37: np.float64(0.26666666666666666), 38: np.float64(0.32432432432432434), 39: np.float64(0.21621621621621623)}
Micro-average F1 score: 0.49872935196950446
Weighted-average F1 score: 0.4921380418481925
F1 score per class: {0: np.float64(0.6285714285714286), 2: np.float64(0.2545454545454545), 4: np.float64(0.7934782608695652), 5: np.float64(0.5962732919254659), 6: np.float64(0.46258503401360546), 10: np.float64(0.26666666666666666), 11: np.float64(0.2676056338028169), 12: np.float64(0.3292181069958848), 13: np.float64(0.06315789473684211), 15: np.float64(0.375), 16: np.float64(0.5), 17: np.float64(0.0), 18: np.float64(0.3283582089552239), 19: np.float64(0.6816479400749064), 21: np.float64(0.16521739130434782), 23: np.float64(0.6881720430107527), 24: np.float64(0.29411764705882354), 25: np.float64(0.5454545454545454), 26: np.float64(0.6956521739130435), 28: np.float64(0.14814814814814814), 29: np.float64(0.85), 32: np.float64(0.6762589928057554), 35: np.float64(0.35), 37: np.float64(0.2132564841498559), 38: np.float64(0.32432432432432434), 39: np.float64(0.23728813559322035)}
Micro-average F1 score: 0.4644308943089431
Weighted-average F1 score: 0.43851010950023395
F1 score per class: {0: np.float64(0.7294117647058823), 2: np.float64(0.2978723404255319), 4: np.float64(0.8181818181818182), 5: np.float64(0.7037037037037037), 6: np.float64(0.5035971223021583), 10: np.float64(0.15625), 11: np.float64(0.24203821656050956), 12: np.float64(0.329004329004329), 13: np.float64(0.05217391304347826), 15: np.float64(0.3333333333333333), 16: np.float64(0.43478260869565216), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.6765799256505576), 21: np.float64(0.2), 23: np.float64(0.7010309278350515), 24: np.float64(0.3125), 25: np.float64(0.5555555555555556), 26: np.float64(0.71875), 28: np.float64(0.17391304347826086), 29: np.float64(0.8367346938775511), 32: np.float64(0.6549295774647887), 35: np.float64(0.3240223463687151), 37: np.float64(0.20121951219512196), 38: np.float64(0.2857142857142857), 39: np.float64(0.22580645161290322)}
Micro-average F1 score: 0.4683853459972863
Weighted-average F1 score: 0.44593847394169794

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.64), 17: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.3888888888888889), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.3877551020408163), 37: np.float64(0.5454545454545454), 38: np.float64(0.5454545454545454), 39: np.float64(0.0)}
Micro-average F1 score: 0.3126177024482109
Weighted-average F1 score: 0.21697656840513982
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.6), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.4772727272727273), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.5691056910569106), 37: np.float64(0.5692307692307692), 38: np.float64(0.5373134328358209), 39: np.float64(0.0)}
Micro-average F1 score: 0.31283422459893045
Weighted-average F1 score: 0.22844388604143806
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.5), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.49382716049382713), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.5087719298245614), 37: np.float64(0.5196850393700787), 38: np.float64(0.5333333333333333), 39: np.float64(0.0)}
Micro-average F1 score: 0.30364963503649633
Weighted-average F1 score: 0.2174776519374593

F1 score per class: {0: np.float64(0.6987951807228916), 2: np.float64(0.2641509433962264), 4: np.float64(0.7796610169491526), 5: np.float64(0.6666666666666666), 6: np.float64(0.2936708860759494), 10: np.float64(0.10714285714285714), 11: np.float64(0.17699115044247787), 12: np.float64(0.15602836879432624), 13: np.float64(0.0196078431372549), 15: np.float64(0.14285714285714285), 16: np.float64(0.3333333333333333), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.6072607260726073), 21: np.float64(0.17266187050359713), 23: np.float64(0.7010309278350515), 24: np.float64(0.20512820512820512), 25: np.float64(0.3888888888888889), 26: np.float64(0.6280193236714976), 28: np.float64(0.13333333333333333), 29: np.float64(0.7043478260869566), 32: np.float64(0.484375), 35: np.float64(0.1784037558685446), 37: np.float64(0.1411764705882353), 38: np.float64(0.23529411764705882), 39: np.float64(0.12307692307692308)}
Micro-average F1 score: 0.36150126640571034
Weighted-average F1 score: 0.3378430596825885
F1 score per class: {0: np.float64(0.4925373134328358), 2: np.float64(0.15053763440860216), 4: np.float64(0.7263681592039801), 5: np.float64(0.4201312910284464), 6: np.float64(0.26153846153846155), 10: np.float64(0.19469026548672566), 11: np.float64(0.22485207100591717), 12: np.float64(0.17699115044247787), 13: np.float64(0.04054054054054054), 15: np.float64(0.21818181818181817), 16: np.float64(0.32989690721649484), 17: np.float64(0.0), 18: np.float64(0.171875), 19: np.float64(0.5777777777777777), 21: np.float64(0.10614525139664804), 23: np.float64(0.5663716814159292), 24: np.float64(0.16666666666666666), 25: np.float64(0.4375), 26: np.float64(0.5737051792828686), 28: np.float64(0.06837606837606838), 29: np.float64(0.7053941908713693), 32: np.float64(0.49343832020997375), 35: np.float64(0.22012578616352202), 37: np.float64(0.12736660929432014), 38: np.float64(0.1925133689839572), 39: np.float64(0.11764705882352941)}
Micro-average F1 score: 0.31355060034305315
Weighted-average F1 score: 0.29000846009682224
F1 score per class: {0: np.float64(0.6078431372549019), 2: np.float64(0.1891891891891892), 4: np.float64(0.7619047619047619), 5: np.float64(0.5), 6: np.float64(0.2892561983471074), 10: np.float64(0.13245033112582782), 11: np.float64(0.19487179487179487), 12: np.float64(0.17715617715617715), 13: np.float64(0.031088082901554404), 15: np.float64(0.1875), 16: np.float64(0.30303030303030304), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.56875), 21: np.float64(0.12582781456953643), 23: np.float64(0.5811965811965812), 24: np.float64(0.19607843137254902), 25: np.float64(0.47058823529411764), 26: np.float64(0.6160714285714286), 28: np.float64(0.09302325581395349), 29: np.float64(0.6949152542372882), 32: np.float64(0.47692307692307695), 35: np.float64(0.20350877192982456), 37: np.float64(0.11538461538461539), 38: np.float64(0.1702127659574468), 39: np.float64(0.1076923076923077)}
Micro-average F1 score: 0.3199851687059696
Weighted-average F1 score: 0.2950145326458988
cur_acc_wo_na:  ['0.7701', '0.5233', '0.4373', '0.6394', '0.4099']
his_acc_wo_na:  ['0.7701', '0.6800', '0.5671', '0.5737', '0.4987']
cur_acc des_wo_na:  ['0.7353', '0.5646', '0.4355', '0.5428', '0.4579']
his_acc des_wo_na:  ['0.7353', '0.6567', '0.5385', '0.5273', '0.4644']
cur_acc rrf_wo_na:  ['0.7514', '0.5604', '0.4676', '0.5603', '0.4342']
his_acc rrf_wo_na:  ['0.7514', '0.6705', '0.5607', '0.5358', '0.4684']
cur_acc_w_na:  ['0.6376', '0.4048', '0.3139', '0.4838', '0.3126']
his_acc_w_na:  ['0.6376', '0.5391', '0.4183', '0.4170', '0.3615']
cur_acc des_w_na:  ['0.6034', '0.4129', '0.2982', '0.3907', '0.3128']
his_acc des_w_na:  ['0.6034', '0.4937', '0.3677', '0.3619', '0.3136']
cur_acc rrf_w_na:  ['0.6178', '0.4085', '0.3223', '0.4099', '0.3036']
his_acc rrf_w_na:  ['0.6178', '0.5075', '0.3877', '0.3742', '0.3200']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 97.7206990CurrentTrain: epoch  0, batch     1 | loss: 99.8455795CurrentTrain: epoch  0, batch     2 | loss: 77.6442307CurrentTrain: epoch  0, batch     3 | loss: 58.2104439CurrentTrain: epoch  1, batch     0 | loss: 73.9363282CurrentTrain: epoch  1, batch     1 | loss: 74.6718261CurrentTrain: epoch  1, batch     2 | loss: 84.1164701CurrentTrain: epoch  1, batch     3 | loss: 53.9440880CurrentTrain: epoch  2, batch     0 | loss: 70.6547552CurrentTrain: epoch  2, batch     1 | loss: 104.0300023CurrentTrain: epoch  2, batch     2 | loss: 85.6039485CurrentTrain: epoch  2, batch     3 | loss: 50.0384408CurrentTrain: epoch  3, batch     0 | loss: 69.2506901CurrentTrain: epoch  3, batch     1 | loss: 101.7086256CurrentTrain: epoch  3, batch     2 | loss: 81.8815032CurrentTrain: epoch  3, batch     3 | loss: 48.4729435CurrentTrain: epoch  4, batch     0 | loss: 68.3041964CurrentTrain: epoch  4, batch     1 | loss: 80.3206283CurrentTrain: epoch  4, batch     2 | loss: 66.4176141CurrentTrain: epoch  4, batch     3 | loss: 105.0299089CurrentTrain: epoch  5, batch     0 | loss: 91.9237465CurrentTrain: epoch  5, batch     1 | loss: 79.1644476CurrentTrain: epoch  5, batch     2 | loss: 98.6590000CurrentTrain: epoch  5, batch     3 | loss: 47.1705630CurrentTrain: epoch  6, batch     0 | loss: 79.8990299CurrentTrain: epoch  6, batch     1 | loss: 95.2843811CurrentTrain: epoch  6, batch     2 | loss: 67.2175324CurrentTrain: epoch  6, batch     3 | loss: 51.8057815CurrentTrain: epoch  7, batch     0 | loss: 77.5632170CurrentTrain: epoch  7, batch     1 | loss: 80.9724759CurrentTrain: epoch  7, batch     2 | loss: 60.7630064CurrentTrain: epoch  7, batch     3 | loss: 58.6156965CurrentTrain: epoch  8, batch     0 | loss: 92.5477432CurrentTrain: epoch  8, batch     1 | loss: 91.7938657CurrentTrain: epoch  8, batch     2 | loss: 88.6366068CurrentTrain: epoch  8, batch     3 | loss: 46.8058418CurrentTrain: epoch  9, batch     0 | loss: 75.2826101CurrentTrain: epoch  9, batch     1 | loss: 97.8734891CurrentTrain: epoch  9, batch     2 | loss: 91.5252048CurrentTrain: epoch  9, batch     3 | loss: 34.9336611
MemoryTrain:  epoch  0, batch     0 | loss: 0.7760745MemoryTrain:  epoch  1, batch     0 | loss: 0.7037617MemoryTrain:  epoch  2, batch     0 | loss: 0.5742693MemoryTrain:  epoch  3, batch     0 | loss: 0.4390280MemoryTrain:  epoch  4, batch     0 | loss: 0.4017926MemoryTrain:  epoch  5, batch     0 | loss: 0.3113063MemoryTrain:  epoch  6, batch     0 | loss: 0.3214215MemoryTrain:  epoch  7, batch     0 | loss: 0.2743002MemoryTrain:  epoch  8, batch     0 | loss: 0.2168861MemoryTrain:  epoch  9, batch     0 | loss: 0.1964846

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.42201834862385323), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.831858407079646), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8947368421052632), 32: np.float64(0.0), 33: np.float64(0.4), 35: np.float64(0.0), 36: np.float64(0.5242718446601942), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.4957627118644068
Weighted-average F1 score: 0.41034945241325393
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.6756756756756757), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.7592592592592593), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8372093023255814), 32: np.float64(0.0), 33: np.float64(0.47619047619047616), 35: np.float64(0.0), 36: np.float64(0.7285714285714285), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5263157894736842
Weighted-average F1 score: 0.4167663737431179
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.6805555555555556), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.7454545454545455), 21: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.9230769230769231), 32: np.float64(0.0), 33: np.float64(0.47619047619047616), 35: np.float64(0.0), 36: np.float64(0.6504065040650406), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.5177664974619289
Weighted-average F1 score: 0.4025474125016808

F1 score per class: {0: np.float64(0.7901234567901234), 2: np.float64(0.3783783783783784), 4: np.float64(0.8235294117647058), 5: np.float64(0.8173913043478261), 6: np.float64(0.4578313253012048), 8: np.float64(0.2967741935483871), 10: np.float64(0.057692307692307696), 11: np.float64(0.22448979591836735), 12: np.float64(0.20359281437125748), 13: np.float64(0.05405405405405406), 15: np.float64(0.36363636363636365), 16: np.float64(0.125), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.7413793103448276), 20: np.float64(0.4372093023255814), 21: np.float64(0.20408163265306123), 23: np.float64(0.7391304347826086), 24: np.float64(0.16), 25: np.float64(0.3225806451612903), 26: np.float64(0.6956521739130435), 28: np.float64(0.2727272727272727), 29: np.float64(0.8383838383838383), 30: np.float64(0.8717948717948718), 32: np.float64(0.6279863481228669), 33: np.float64(0.13636363636363635), 35: np.float64(0.2857142857142857), 36: np.float64(0.3375), 37: np.float64(0.38095238095238093), 38: np.float64(0.3333333333333333), 39: np.float64(0.06060606060606061)}
Micro-average F1 score: 0.48878665899942497
Weighted-average F1 score: 0.5047464039531143
F1 score per class: {0: np.float64(0.5573770491803278), 2: np.float64(0.19718309859154928), 4: np.float64(0.8172043010752689), 5: np.float64(0.5657142857142857), 6: np.float64(0.47058823529411764), 8: np.float64(0.33112582781456956), 10: np.float64(0.2948717948717949), 11: np.float64(0.28169014084507044), 12: np.float64(0.27149321266968324), 13: np.float64(0.08888888888888889), 15: np.float64(0.2727272727272727), 16: np.float64(0.47619047619047616), 17: np.float64(0.0), 18: np.float64(0.30303030303030304), 19: np.float64(0.6943396226415094), 20: np.float64(0.4659090909090909), 21: np.float64(0.16161616161616163), 23: np.float64(0.7021276595744681), 24: np.float64(0.34782608695652173), 25: np.float64(0.46153846153846156), 26: np.float64(0.6634146341463415), 28: np.float64(0.17647058823529413), 29: np.float64(0.8365384615384616), 30: np.float64(0.5454545454545454), 32: np.float64(0.6596491228070176), 33: np.float64(0.18181818181818182), 35: np.float64(0.3804347826086957), 36: np.float64(0.3591549295774648), 37: np.float64(0.2638888888888889), 38: np.float64(0.3448275862068966), 39: np.float64(0.1643835616438356)}
Micro-average F1 score: 0.459800086918731
Weighted-average F1 score: 0.4452978616516966
F1 score per class: {0: np.float64(0.6), 2: np.float64(0.2916666666666667), 4: np.float64(0.8539325842696629), 5: np.float64(0.697841726618705), 6: np.float64(0.477124183006536), 8: np.float64(0.35251798561151076), 10: np.float64(0.27586206896551724), 11: np.float64(0.2658959537572254), 12: np.float64(0.2643171806167401), 13: np.float64(0.07692307692307693), 15: np.float64(0.25), 16: np.float64(0.45), 17: np.float64(0.0), 18: np.float64(0.17777777777777778), 19: np.float64(0.6946564885496184), 20: np.float64(0.43157894736842106), 21: np.float64(0.2054794520547945), 23: np.float64(0.7096774193548387), 24: np.float64(0.3157894736842105), 25: np.float64(0.4383561643835616), 26: np.float64(0.6868686868686869), 28: np.float64(0.16216216216216217), 29: np.float64(0.8431372549019608), 30: np.float64(0.7346938775510204), 32: np.float64(0.6308724832214765), 33: np.float64(0.15873015873015872), 35: np.float64(0.42028985507246375), 36: np.float64(0.3225806451612903), 37: np.float64(0.2702702702702703), 38: np.float64(0.37209302325581395), 39: np.float64(0.16901408450704225)}
Micro-average F1 score: 0.47388059701492535
Weighted-average F1 score: 0.46113656441418205

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.39316239316239315), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5465116279069767), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.85), 32: np.float64(0.0), 33: np.float64(0.4), 35: np.float64(0.0), 36: np.float64(0.40601503759398494), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.34210526315789475
Weighted-average F1 score: 0.27658990235246445
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.5617977528089888), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5503355704697986), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.7058823529411765), 32: np.float64(0.0), 33: np.float64(0.47619047619047616), 35: np.float64(0.0), 36: np.float64(0.5483870967741935), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.34126163391933817
Weighted-average F1 score: 0.2716478979429734
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.5833333333333334), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.5290322580645161), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8181818181818182), 32: np.float64(0.0), 33: np.float64(0.47619047619047616), 35: np.float64(0.0), 36: np.float64(0.47619047619047616), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0)}
Micro-average F1 score: 0.344206974128234
Weighted-average F1 score: 0.27047133260242395

F1 score per class: {0: np.float64(0.5925925925925926), 2: np.float64(0.23333333333333334), 4: np.float64(0.7777777777777778), 5: np.float64(0.6714285714285714), 6: np.float64(0.26697892271662765), 8: np.float64(0.2072072072072072), 10: np.float64(0.05555555555555555), 11: np.float64(0.176), 12: np.float64(0.11724137931034483), 13: np.float64(0.029850746268656716), 15: np.float64(0.2222222222222222), 16: np.float64(0.11764705882352941), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.6564885496183206), 20: np.float64(0.2088888888888889), 21: np.float64(0.17543859649122806), 23: np.float64(0.6601941747572816), 24: np.float64(0.1111111111111111), 25: np.float64(0.30303030303030304), 26: np.float64(0.6124401913875598), 28: np.float64(0.16216216216216217), 29: np.float64(0.7063829787234043), 30: np.float64(0.8292682926829268), 32: np.float64(0.467005076142132), 33: np.float64(0.10526315789473684), 35: np.float64(0.2028985507246377), 36: np.float64(0.24107142857142858), 37: np.float64(0.2702702702702703), 38: np.float64(0.2545454545454545), 39: np.float64(0.0425531914893617)}
Micro-average F1 score: 0.35572295459301106
Weighted-average F1 score: 0.3438526461950763
F1 score per class: {0: np.float64(0.43037974683544306), 2: np.float64(0.13725490196078433), 4: np.float64(0.7715736040609137), 5: np.float64(0.3619744058500914), 6: np.float64(0.2691588785046729), 8: np.float64(0.19801980198019803), 10: np.float64(0.21800947867298578), 11: np.float64(0.22988505747126436), 12: np.float64(0.15584415584415584), 13: np.float64(0.05405405405405406), 15: np.float64(0.17142857142857143), 16: np.float64(0.3157894736842105), 17: np.float64(0.0), 18: np.float64(0.19230769230769232), 19: np.float64(0.6052631578947368), 20: np.float64(0.22777777777777777), 21: np.float64(0.10884353741496598), 23: np.float64(0.5409836065573771), 24: np.float64(0.21052631578947367), 25: np.float64(0.4235294117647059), 26: np.float64(0.5573770491803278), 28: np.float64(0.08823529411764706), 29: np.float64(0.6666666666666666), 30: np.float64(0.4186046511627907), 32: np.float64(0.48205128205128206), 33: np.float64(0.136986301369863), 35: np.float64(0.23026315789473684), 36: np.float64(0.24343675417661098), 37: np.float64(0.15637860082304528), 38: np.float64(0.20618556701030927), 39: np.float64(0.08275862068965517)}
Micro-average F1 score: 0.308860020434973
Weighted-average F1 score: 0.2919400871193157
F1 score per class: {0: np.float64(0.45517241379310347), 2: np.float64(0.1917808219178082), 4: np.float64(0.8), 5: np.float64(0.5159574468085106), 6: np.float64(0.2744360902255639), 8: np.float64(0.21350762527233116), 10: np.float64(0.22598870056497175), 11: np.float64(0.2081447963800905), 12: np.float64(0.14962593516209477), 13: np.float64(0.041237113402061855), 15: np.float64(0.1518987341772152), 16: np.float64(0.35294117647058826), 17: np.float64(0.0), 18: np.float64(0.12698412698412698), 19: np.float64(0.5986842105263158), 20: np.float64(0.20971867007672634), 21: np.float64(0.1282051282051282), 23: np.float64(0.5945945945945946), 24: np.float64(0.2033898305084746), 25: np.float64(0.4155844155844156), 26: np.float64(0.5811965811965812), 28: np.float64(0.08695652173913043), 29: np.float64(0.6771653543307087), 30: np.float64(0.5806451612903226), 32: np.float64(0.45965770171149145), 33: np.float64(0.12195121951219512), 35: np.float64(0.2761904761904762), 36: np.float64(0.21164021164021163), 37: np.float64(0.16877637130801687), 38: np.float64(0.2206896551724138), 39: np.float64(0.08391608391608392)}
Micro-average F1 score: 0.32320661682837604
Weighted-average F1 score: 0.3040714260581558
cur_acc_wo_na:  ['0.7701', '0.5233', '0.4373', '0.6394', '0.4099', '0.4958']
his_acc_wo_na:  ['0.7701', '0.6800', '0.5671', '0.5737', '0.4987', '0.4888']
cur_acc des_wo_na:  ['0.7353', '0.5646', '0.4355', '0.5428', '0.4579', '0.5263']
his_acc des_wo_na:  ['0.7353', '0.6567', '0.5385', '0.5273', '0.4644', '0.4598']
cur_acc rrf_wo_na:  ['0.7514', '0.5604', '0.4676', '0.5603', '0.4342', '0.5178']
his_acc rrf_wo_na:  ['0.7514', '0.6705', '0.5607', '0.5358', '0.4684', '0.4739']
cur_acc_w_na:  ['0.6376', '0.4048', '0.3139', '0.4838', '0.3126', '0.3421']
his_acc_w_na:  ['0.6376', '0.5391', '0.4183', '0.4170', '0.3615', '0.3557']
cur_acc des_w_na:  ['0.6034', '0.4129', '0.2982', '0.3907', '0.3128', '0.3413']
his_acc des_w_na:  ['0.6034', '0.4937', '0.3677', '0.3619', '0.3136', '0.3089']
cur_acc rrf_w_na:  ['0.6178', '0.4085', '0.3223', '0.4099', '0.3036', '0.3442']
his_acc rrf_w_na:  ['0.6178', '0.5075', '0.3877', '0.3742', '0.3200', '0.3232']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 107.0406996CurrentTrain: epoch  0, batch     1 | loss: 84.9621321CurrentTrain: epoch  0, batch     2 | loss: 93.7839699CurrentTrain: epoch  0, batch     3 | loss: 13.3027846CurrentTrain: epoch  1, batch     0 | loss: 72.8353517CurrentTrain: epoch  1, batch     1 | loss: 76.3871756CurrentTrain: epoch  1, batch     2 | loss: 112.0681306CurrentTrain: epoch  1, batch     3 | loss: 24.4909450CurrentTrain: epoch  2, batch     0 | loss: 72.4740293CurrentTrain: epoch  2, batch     1 | loss: 82.2725949CurrentTrain: epoch  2, batch     2 | loss: 71.1539321CurrentTrain: epoch  2, batch     3 | loss: 20.1920682CurrentTrain: epoch  3, batch     0 | loss: 82.9659754CurrentTrain: epoch  3, batch     1 | loss: 79.6488579CurrentTrain: epoch  3, batch     2 | loss: 95.1334280CurrentTrain: epoch  3, batch     3 | loss: 21.7163661CurrentTrain: epoch  4, batch     0 | loss: 77.6426737CurrentTrain: epoch  4, batch     1 | loss: 70.5019540CurrentTrain: epoch  4, batch     2 | loss: 66.9292679CurrentTrain: epoch  4, batch     3 | loss: 5.3448473CurrentTrain: epoch  5, batch     0 | loss: 66.3339941CurrentTrain: epoch  5, batch     1 | loss: 75.7732298CurrentTrain: epoch  5, batch     2 | loss: 77.0179200CurrentTrain: epoch  5, batch     3 | loss: 18.6393308CurrentTrain: epoch  6, batch     0 | loss: 68.7825323CurrentTrain: epoch  6, batch     1 | loss: 62.3172031CurrentTrain: epoch  6, batch     2 | loss: 79.7234875CurrentTrain: epoch  6, batch     3 | loss: 3.9875837CurrentTrain: epoch  7, batch     0 | loss: 75.7917203CurrentTrain: epoch  7, batch     1 | loss: 79.8383214CurrentTrain: epoch  7, batch     2 | loss: 61.3465568CurrentTrain: epoch  7, batch     3 | loss: 17.6339472CurrentTrain: epoch  8, batch     0 | loss: 60.1186742CurrentTrain: epoch  8, batch     1 | loss: 93.8574961CurrentTrain: epoch  8, batch     2 | loss: 75.6226246CurrentTrain: epoch  8, batch     3 | loss: 5.3183428CurrentTrain: epoch  9, batch     0 | loss: 61.8226783CurrentTrain: epoch  9, batch     1 | loss: 65.7032408CurrentTrain: epoch  9, batch     2 | loss: 61.5614132CurrentTrain: epoch  9, batch     3 | loss: 5.9689481
MemoryTrain:  epoch  0, batch     0 | loss: 0.8036737MemoryTrain:  epoch  1, batch     0 | loss: 0.6059844MemoryTrain:  epoch  2, batch     0 | loss: 0.5389550MemoryTrain:  epoch  3, batch     0 | loss: 0.4311275MemoryTrain:  epoch  4, batch     0 | loss: 0.3318657MemoryTrain:  epoch  5, batch     0 | loss: 0.2922805MemoryTrain:  epoch  6, batch     0 | loss: 0.2337604MemoryTrain:  epoch  7, batch     0 | loss: 0.2073129MemoryTrain:  epoch  8, batch     0 | loss: 0.1749950MemoryTrain:  epoch  9, batch     0 | loss: 0.1639987

F1 score per class: {0: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6), 6: np.float64(0.9433962264150944), 7: np.float64(0.0), 40: np.float64(0.0), 9: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.5714285714285714), 21: np.float64(0.6666666666666666), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.20512820512820512)}
Micro-average F1 score: 0.3234323432343234
Weighted-average F1 score: 0.252704102659179
F1 score per class: {0: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6), 8: np.float64(0.0), 9: np.float64(0.6493506493506493), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.5925925925925926), 31: np.float64(0.4), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.352)}
Micro-average F1 score: 0.33618233618233617
Weighted-average F1 score: 0.2771189004775503
F1 score per class: {0: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6), 8: np.float64(0.0), 9: np.float64(0.8928571428571429), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.6666666666666666), 31: np.float64(0.6666666666666666), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.3308270676691729)}
Micro-average F1 score: 0.3663663663663664
Weighted-average F1 score: 0.2889930305215092

F1 score per class: {0: np.float64(0.4852941176470588), 2: np.float64(0.3783783783783784), 4: np.float64(0.7951807228915663), 5: np.float64(0.8103448275862069), 6: np.float64(0.176), 7: np.float64(0.029556650246305417), 8: np.float64(0.13186813186813187), 9: np.float64(0.9433962264150944), 10: np.float64(0.0196078431372549), 11: np.float64(0.23232323232323232), 12: np.float64(0.24161073825503357), 13: np.float64(0.05194805194805195), 15: np.float64(0.4117647058823529), 16: np.float64(0.32432432432432434), 17: np.float64(0.0), 18: np.float64(0.08163265306122448), 19: np.float64(0.5928571428571429), 20: np.float64(0.45), 21: np.float64(0.05), 23: np.float64(0.7555555555555555), 24: np.float64(0.09523809523809523), 25: np.float64(0.3125), 26: np.float64(0.6060606060606061), 27: np.float64(0.38095238095238093), 28: np.float64(0.2857142857142857), 29: np.float64(0.8383838383838383), 30: np.float64(0.8571428571428571), 31: np.float64(0.5), 32: np.float64(0.6901960784313725), 33: np.float64(0.15384615384615385), 35: np.float64(0.325), 36: np.float64(0.4077669902912621), 37: np.float64(0.4444444444444444), 38: np.float64(0.16216216216216217), 39: np.float64(0.10526315789473684), 40: np.float64(0.08163265306122448)}
Micro-average F1 score: 0.4234115475876615
Weighted-average F1 score: 0.4207666890662221
F1 score per class: {0: np.float64(0.44594594594594594), 2: np.float64(0.17073170731707318), 4: np.float64(0.7954545454545454), 5: np.float64(0.5808383233532934), 6: np.float64(0.2465753424657534), 7: np.float64(0.031746031746031744), 8: np.float64(0.33986928104575165), 9: np.float64(0.5376344086021505), 10: np.float64(0.16363636363636364), 11: np.float64(0.3391812865497076), 12: np.float64(0.16), 13: np.float64(0.02666666666666667), 15: np.float64(0.2608695652173913), 16: np.float64(0.4262295081967213), 17: np.float64(0.16666666666666666), 18: np.float64(0.21311475409836064), 19: np.float64(0.5342465753424658), 20: np.float64(0.4), 21: np.float64(0.1506849315068493), 23: np.float64(0.6363636363636364), 24: np.float64(0.22857142857142856), 25: np.float64(0.47368421052631576), 26: np.float64(0.6571428571428571), 27: np.float64(0.32), 28: np.float64(0.1111111111111111), 29: np.float64(0.83), 30: np.float64(0.7441860465116279), 31: np.float64(0.07692307692307693), 32: np.float64(0.6848249027237354), 33: np.float64(0.1), 35: np.float64(0.45517241379310347), 36: np.float64(0.5161290322580645), 37: np.float64(0.26993865030674846), 38: np.float64(0.3582089552238806), 39: np.float64(0.07692307692307693), 40: np.float64(0.16417910447761194)}
Micro-average F1 score: 0.405674359517256
Weighted-average F1 score: 0.3855804124229832
F1 score per class: {0: np.float64(0.43137254901960786), 2: np.float64(0.23728813559322035), 4: np.float64(0.8304093567251462), 5: np.float64(0.7032967032967034), 6: np.float64(0.25), 7: np.float64(0.03076923076923077), 8: np.float64(0.2857142857142857), 9: np.float64(0.847457627118644), 10: np.float64(0.12844036697247707), 11: np.float64(0.2857142857142857), 12: np.float64(0.16666666666666666), 13: np.float64(0.046511627906976744), 15: np.float64(0.2608695652173913), 16: np.float64(0.3902439024390244), 17: np.float64(0.16666666666666666), 18: np.float64(0.21818181818181817), 19: np.float64(0.5571428571428572), 20: np.float64(0.39111111111111113), 21: np.float64(0.1411764705882353), 23: np.float64(0.6265060240963856), 24: np.float64(0.125), 25: np.float64(0.4507042253521127), 26: np.float64(0.67), 27: np.float64(0.3389830508474576), 28: np.float64(0.1509433962264151), 29: np.float64(0.8341708542713567), 30: np.float64(0.8421052631578947), 31: np.float64(0.2222222222222222), 32: np.float64(0.6492537313432836), 33: np.float64(0.09375), 35: np.float64(0.37168141592920356), 36: np.float64(0.3850267379679144), 37: np.float64(0.3076923076923077), 38: np.float64(0.3333333333333333), 39: np.float64(0.08695652173913043), 40: np.float64(0.1456953642384106)}
Micro-average F1 score: 0.4094955489614243
Weighted-average F1 score: 0.39022477034657305

F1 score per class: {0: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.5), 6: np.float64(0.8928571428571429), 7: np.float64(0.0), 40: np.float64(0.0), 9: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.5161290322580645), 21: np.float64(0.6666666666666666), 26: np.float64(0.0), 27: np.float64(0.0), 31: np.float64(0.17142857142857143)}
Micro-average F1 score: 0.2692307692307692
Weighted-average F1 score: 0.21034224270353302
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.46153846153846156), 8: np.float64(0.0), 9: np.float64(0.5813953488372093), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.5161290322580645), 28: np.float64(0.0), 31: np.float64(0.3333333333333333), 32: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.29333333333333333)}
Micro-average F1 score: 0.2599118942731278
Weighted-average F1 score: 0.2154500525583885
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.42857142857142855), 8: np.float64(0.0), 9: np.float64(0.8064516129032258), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.5882352941176471), 31: np.float64(0.5), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.27672955974842767)}
Micro-average F1 score: 0.2857142857142857
Weighted-average F1 score: 0.22819403206145844

F1 score per class: {0: np.float64(0.37714285714285717), 2: np.float64(0.2413793103448276), 4: np.float64(0.7542857142857143), 5: np.float64(0.6505190311418685), 6: np.float64(0.14864864864864866), 7: np.float64(0.015113350125944584), 8: np.float64(0.125), 9: np.float64(0.8928571428571429), 10: np.float64(0.019230769230769232), 11: np.float64(0.1862348178137652), 12: np.float64(0.14007782101167315), 13: np.float64(0.03125), 15: np.float64(0.25925925925925924), 16: np.float64(0.2608695652173913), 17: np.float64(0.0), 18: np.float64(0.05194805194805195), 19: np.float64(0.5424836601307189), 20: np.float64(0.2054794520547945), 21: np.float64(0.045454545454545456), 23: np.float64(0.6868686868686869), 24: np.float64(0.07407407407407407), 25: np.float64(0.29411764705882354), 26: np.float64(0.5319148936170213), 27: np.float64(0.2909090909090909), 28: np.float64(0.18181818181818182), 29: np.float64(0.70042194092827), 30: np.float64(0.8108108108108109), 31: np.float64(0.25), 32: np.float64(0.5086705202312138), 33: np.float64(0.12244897959183673), 35: np.float64(0.25742574257425743), 36: np.float64(0.2937062937062937), 37: np.float64(0.3333333333333333), 38: np.float64(0.13043478260869565), 39: np.float64(0.10526315789473684), 40: np.float64(0.061224489795918366)}
Micro-average F1 score: 0.315149136577708
Weighted-average F1 score: 0.2961233212481634
F1 score per class: {0: np.float64(0.3283582089552239), 2: np.float64(0.112), 4: np.float64(0.7407407407407407), 5: np.float64(0.3702290076335878), 6: np.float64(0.18848167539267016), 7: np.float64(0.015665796344647518), 8: np.float64(0.25), 9: np.float64(0.45871559633027525), 10: np.float64(0.15), 11: np.float64(0.26605504587155965), 12: np.float64(0.0979020979020979), 13: np.float64(0.015384615384615385), 15: np.float64(0.17647058823529413), 16: np.float64(0.2826086956521739), 17: np.float64(0.15384615384615385), 18: np.float64(0.14285714285714285), 19: np.float64(0.48297213622291024), 20: np.float64(0.1925601750547046), 21: np.float64(0.1004566210045662), 23: np.float64(0.5045045045045045), 24: np.float64(0.16666666666666666), 25: np.float64(0.45), 26: np.float64(0.5476190476190477), 27: np.float64(0.2222222222222222), 28: np.float64(0.05714285714285714), 29: np.float64(0.680327868852459), 30: np.float64(0.6808510638297872), 31: np.float64(0.05), 32: np.float64(0.5176470588235295), 33: np.float64(0.075), 35: np.float64(0.32673267326732675), 36: np.float64(0.366412213740458), 37: np.float64(0.1660377358490566), 38: np.float64(0.23300970873786409), 39: np.float64(0.04878048780487805), 40: np.float64(0.11924119241192412)}
Micro-average F1 score: 0.28452628452628453
Weighted-average F1 score: 0.26349889610510235
F1 score per class: {0: np.float64(0.3235294117647059), 2: np.float64(0.16470588235294117), 4: np.float64(0.7888888888888889), 5: np.float64(0.48120300751879697), 6: np.float64(0.19148936170212766), 7: np.float64(0.015228426395939087), 8: np.float64(0.22929936305732485), 9: np.float64(0.7352941176470589), 10: np.float64(0.11764705882352941), 11: np.float64(0.2196078431372549), 12: np.float64(0.10071942446043165), 13: np.float64(0.025806451612903226), 15: np.float64(0.16901408450704225), 16: np.float64(0.3137254901960784), 17: np.float64(0.15384615384615385), 18: np.float64(0.1348314606741573), 19: np.float64(0.5048543689320388), 20: np.float64(0.18565400843881857), 21: np.float64(0.0916030534351145), 23: np.float64(0.5416666666666666), 24: np.float64(0.09523809523809523), 25: np.float64(0.4266666666666667), 26: np.float64(0.575107296137339), 27: np.float64(0.23255813953488372), 28: np.float64(0.08602150537634409), 29: np.float64(0.6887966804979253), 30: np.float64(0.8), 31: np.float64(0.11764705882352941), 32: np.float64(0.4915254237288136), 33: np.float64(0.06521739130434782), 35: np.float64(0.2709677419354839), 36: np.float64(0.2801556420233463), 37: np.float64(0.19383259911894274), 38: np.float64(0.21951219512195122), 39: np.float64(0.05714285714285714), 40: np.float64(0.10526315789473684)}
Micro-average F1 score: 0.29109200064903457
Weighted-average F1 score: 0.26726615722088626
cur_acc_wo_na:  ['0.7701', '0.5233', '0.4373', '0.6394', '0.4099', '0.4958', '0.3234']
his_acc_wo_na:  ['0.7701', '0.6800', '0.5671', '0.5737', '0.4987', '0.4888', '0.4234']
cur_acc des_wo_na:  ['0.7353', '0.5646', '0.4355', '0.5428', '0.4579', '0.5263', '0.3362']
his_acc des_wo_na:  ['0.7353', '0.6567', '0.5385', '0.5273', '0.4644', '0.4598', '0.4057']
cur_acc rrf_wo_na:  ['0.7514', '0.5604', '0.4676', '0.5603', '0.4342', '0.5178', '0.3664']
his_acc rrf_wo_na:  ['0.7514', '0.6705', '0.5607', '0.5358', '0.4684', '0.4739', '0.4095']
cur_acc_w_na:  ['0.6376', '0.4048', '0.3139', '0.4838', '0.3126', '0.3421', '0.2692']
his_acc_w_na:  ['0.6376', '0.5391', '0.4183', '0.4170', '0.3615', '0.3557', '0.3151']
cur_acc des_w_na:  ['0.6034', '0.4129', '0.2982', '0.3907', '0.3128', '0.3413', '0.2599']
his_acc des_w_na:  ['0.6034', '0.4937', '0.3677', '0.3619', '0.3136', '0.3089', '0.2845']
cur_acc rrf_w_na:  ['0.6178', '0.4085', '0.3223', '0.4099', '0.3036', '0.3442', '0.2857']
his_acc rrf_w_na:  ['0.6178', '0.5075', '0.3877', '0.3742', '0.3200', '0.3232', '0.2911']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 101.6961152CurrentTrain: epoch  0, batch     1 | loss: 103.0791409CurrentTrain: epoch  0, batch     2 | loss: 87.4084211CurrentTrain: epoch  0, batch     3 | loss: 115.3980529CurrentTrain: epoch  0, batch     4 | loss: 64.3619004CurrentTrain: epoch  1, batch     0 | loss: 94.9502863CurrentTrain: epoch  1, batch     1 | loss: 88.5955481CurrentTrain: epoch  1, batch     2 | loss: 76.8592979CurrentTrain: epoch  1, batch     3 | loss: 136.8304635CurrentTrain: epoch  1, batch     4 | loss: 80.4180398CurrentTrain: epoch  2, batch     0 | loss: 88.8562127CurrentTrain: epoch  2, batch     1 | loss: 105.6580542CurrentTrain: epoch  2, batch     2 | loss: 73.9477060CurrentTrain: epoch  2, batch     3 | loss: 104.8380911CurrentTrain: epoch  2, batch     4 | loss: 49.3167387CurrentTrain: epoch  3, batch     0 | loss: 108.1053938CurrentTrain: epoch  3, batch     1 | loss: 86.4498288CurrentTrain: epoch  3, batch     2 | loss: 72.0931227CurrentTrain: epoch  3, batch     3 | loss: 68.8692017CurrentTrain: epoch  3, batch     4 | loss: 71.0308024CurrentTrain: epoch  4, batch     0 | loss: 68.7076675CurrentTrain: epoch  4, batch     1 | loss: 100.1270408CurrentTrain: epoch  4, batch     2 | loss: 103.8213041CurrentTrain: epoch  4, batch     3 | loss: 126.9128133CurrentTrain: epoch  4, batch     4 | loss: 39.6991691CurrentTrain: epoch  5, batch     0 | loss: 80.4372735CurrentTrain: epoch  5, batch     1 | loss: 101.6079071CurrentTrain: epoch  5, batch     2 | loss: 80.1240419CurrentTrain: epoch  5, batch     3 | loss: 82.0838034CurrentTrain: epoch  5, batch     4 | loss: 55.3419657CurrentTrain: epoch  6, batch     0 | loss: 83.7807924CurrentTrain: epoch  6, batch     1 | loss: 69.0038525CurrentTrain: epoch  6, batch     2 | loss: 68.7798853CurrentTrain: epoch  6, batch     3 | loss: 80.0591915CurrentTrain: epoch  6, batch     4 | loss: 94.9849351CurrentTrain: epoch  7, batch     0 | loss: 76.6573554CurrentTrain: epoch  7, batch     1 | loss: 81.9104039CurrentTrain: epoch  7, batch     2 | loss: 95.1978706CurrentTrain: epoch  7, batch     3 | loss: 94.2537924CurrentTrain: epoch  7, batch     4 | loss: 94.8589414CurrentTrain: epoch  8, batch     0 | loss: 97.6600118CurrentTrain: epoch  8, batch     1 | loss: 96.3891571CurrentTrain: epoch  8, batch     2 | loss: 122.7515492CurrentTrain: epoch  8, batch     3 | loss: 89.8468063CurrentTrain: epoch  8, batch     4 | loss: 43.9426120CurrentTrain: epoch  9, batch     0 | loss: 94.2218297CurrentTrain: epoch  9, batch     1 | loss: 78.1541741CurrentTrain: epoch  9, batch     2 | loss: 66.3026235CurrentTrain: epoch  9, batch     3 | loss: 95.6113374CurrentTrain: epoch  9, batch     4 | loss: 67.3969068
MemoryTrain:  epoch  0, batch     0 | loss: 1.0163982MemoryTrain:  epoch  1, batch     0 | loss: 0.9240409MemoryTrain:  epoch  2, batch     0 | loss: 0.7311184MemoryTrain:  epoch  3, batch     0 | loss: 0.5934448MemoryTrain:  epoch  4, batch     0 | loss: 0.4804735MemoryTrain:  epoch  5, batch     0 | loss: 0.4290105MemoryTrain:  epoch  6, batch     0 | loss: 0.3356021MemoryTrain:  epoch  7, batch     0 | loss: 0.3252747MemoryTrain:  epoch  8, batch     0 | loss: 0.2867502MemoryTrain:  epoch  9, batch     0 | loss: 0.2383932

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.20930232558139536), 3: np.float64(0.6666666666666666), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.06896551724137931), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.5617021276595745), 23: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6299212598425197), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.34990439770554493
Weighted-average F1 score: 0.29449827436911863
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.24864864864864866), 3: np.float64(0.6125), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.061224489795918366), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5670498084291188), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6578947368421053), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.334453781512605
Weighted-average F1 score: 0.2835293385158027
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.23204419889502761), 3: np.float64(0.6134969325153374), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.06956521739130435), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5538461538461539), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6351351351351351), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3370981754995656
Weighted-average F1 score: 0.28818467263249065

F1 score per class: {0: np.float64(0.5245901639344263), 1: np.float64(0.16071428571428573), 2: np.float64(0.4), 3: np.float64(0.40441176470588236), 4: np.float64(0.75), 5: np.float64(0.8440366972477065), 6: np.float64(0.1791044776119403), 7: np.float64(0.043243243243243246), 8: np.float64(0.22), 9: np.float64(0.9230769230769231), 10: np.float64(0.0392156862745098), 11: np.float64(0.16149068322981366), 12: np.float64(0.2754491017964072), 13: np.float64(0.05063291139240506), 14: np.float64(0.03524229074889868), 15: np.float64(0.6666666666666666), 16: np.float64(0.06451612903225806), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5423728813559322), 20: np.float64(0.4606741573033708), 21: np.float64(0.0), 22: np.float64(0.4520547945205479), 23: np.float64(0.8041237113402062), 24: np.float64(0.0), 25: np.float64(0.3225806451612903), 26: np.float64(0.6272189349112426), 27: np.float64(0.0), 28: np.float64(0.2608695652173913), 29: np.float64(0.7939698492462312), 30: np.float64(0.8484848484848485), 31: np.float64(0.4), 32: np.float64(0.5311475409836065), 33: np.float64(0.23076923076923078), 34: np.float64(0.16326530612244897), 35: np.float64(0.14893617021276595), 36: np.float64(0.46601941747572817), 37: np.float64(0.3516483516483517), 38: np.float64(0.17777777777777778), 39: np.float64(0.1), 40: np.float64(0.1095890410958904)}
Micro-average F1 score: 0.35964912280701755
Weighted-average F1 score: 0.3423317893662653
F1 score per class: {0: np.float64(0.4520547945205479), 1: np.float64(0.1796875), 2: np.float64(0.20588235294117646), 3: np.float64(0.3726235741444867), 4: np.float64(0.7425149700598802), 5: np.float64(0.5495750708215298), 6: np.float64(0.25806451612903225), 7: np.float64(0.045714285714285714), 8: np.float64(0.3132530120481928), 9: np.float64(0.47619047619047616), 10: np.float64(0.0761904761904762), 11: np.float64(0.176), 12: np.float64(0.29743589743589743), 13: np.float64(0.03773584905660377), 14: np.float64(0.03571428571428571), 15: np.float64(0.3870967741935484), 16: np.float64(0.44), 17: np.float64(0.16666666666666666), 18: np.float64(0.0625), 19: np.float64(0.4606413994169096), 20: np.float64(0.3979591836734694), 21: np.float64(0.03389830508474576), 22: np.float64(0.43023255813953487), 23: np.float64(0.6597938144329897), 24: np.float64(0.0), 25: np.float64(0.43243243243243246), 26: np.float64(0.6442307692307693), 27: np.float64(0.0), 28: np.float64(0.09876543209876543), 29: np.float64(0.8059701492537313), 30: np.float64(0.6938775510204082), 31: np.float64(0.06896551724137931), 32: np.float64(0.5030674846625767), 33: np.float64(0.1702127659574468), 34: np.float64(0.15748031496062992), 35: np.float64(0.2594594594594595), 36: np.float64(0.46875), 37: np.float64(0.10869565217391304), 38: np.float64(0.2222222222222222), 39: np.float64(0.09523809523809523), 40: np.float64(0.1360544217687075)}
Micro-average F1 score: 0.3406435088842644
Weighted-average F1 score: 0.32708557965500656
F1 score per class: {0: np.float64(0.46153846153846156), 1: np.float64(0.1700404858299595), 2: np.float64(0.2857142857142857), 3: np.float64(0.34965034965034963), 4: np.float64(0.7857142857142857), 5: np.float64(0.7384615384615385), 6: np.float64(0.25333333333333335), 7: np.float64(0.04419889502762431), 8: np.float64(0.2809917355371901), 9: np.float64(0.8620689655172413), 10: np.float64(0.0761904761904762), 11: np.float64(0.16417910447761194), 12: np.float64(0.28125), 13: np.float64(0.029850746268656716), 14: np.float64(0.03619909502262444), 15: np.float64(0.3870967741935484), 16: np.float64(0.3157894736842105), 17: np.float64(0.0), 18: np.float64(0.03389830508474576), 19: np.float64(0.49842271293375395), 20: np.float64(0.4307692307692308), 21: np.float64(0.0), 22: np.float64(0.4235294117647059), 23: np.float64(0.6363636363636364), 24: np.float64(0.0), 25: np.float64(0.463768115942029), 26: np.float64(0.67), 27: np.float64(0.0), 28: np.float64(0.12121212121212122), 29: np.float64(0.7939698492462312), 30: np.float64(0.8333333333333334), 31: np.float64(0.16666666666666666), 32: np.float64(0.5046153846153846), 33: np.float64(0.20512820512820512), 34: np.float64(0.14826498422712933), 35: np.float64(0.25), 36: np.float64(0.4935064935064935), 37: np.float64(0.13793103448275862), 38: np.float64(0.12698412698412698), 39: np.float64(0.08333333333333333), 40: np.float64(0.12658227848101267)}
Micro-average F1 score: 0.3455160744500846
Weighted-average F1 score: 0.3260436762510962

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.1188118811881188), 2: np.float64(0.0), 3: np.float64(0.514018691588785), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.05405405405405406), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.45993031358885017), 23: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.4878048780487805), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.23704663212435234
Weighted-average F1 score: 0.20187268402541475
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.14241486068111456), 2: np.float64(0.0), 3: np.float64(0.44545454545454544), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.047619047619047616), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.4444444444444444), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.47619047619047616), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.22013274336283187
Weighted-average F1 score: 0.19223151659758134
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.1320754716981132), 2: np.float64(0.0), 3: np.float64(0.4484304932735426), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.05405405405405406), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.4311377245508982), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.46534653465346537), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.22286042504307868
Weighted-average F1 score: 0.19553518997458566

F1 score per class: {0: np.float64(0.3950617283950617), 1: np.float64(0.0891089108910891), 2: np.float64(0.22641509433962265), 3: np.float64(0.2619047619047619), 4: np.float64(0.7142857142857143), 5: np.float64(0.6840148698884758), 6: np.float64(0.13953488372093023), 7: np.float64(0.021739130434782608), 8: np.float64(0.19130434782608696), 9: np.float64(0.8727272727272727), 10: np.float64(0.037037037037037035), 11: np.float64(0.14942528735632185), 12: np.float64(0.14241486068111456), 13: np.float64(0.025), 14: np.float64(0.026936026936026935), 15: np.float64(0.41379310344827586), 16: np.float64(0.06060606060606061), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.49382716049382713), 20: np.float64(0.211340206185567), 21: np.float64(0.0), 22: np.float64(0.3251231527093596), 23: np.float64(0.7027027027027027), 24: np.float64(0.0), 25: np.float64(0.3076923076923077), 26: np.float64(0.5380710659898477), 27: np.float64(0.0), 28: np.float64(0.17142857142857143), 29: np.float64(0.6583333333333333), 30: np.float64(0.8), 31: np.float64(0.2222222222222222), 32: np.float64(0.3741339491916859), 33: np.float64(0.17142857142857143), 34: np.float64(0.10568031704095113), 35: np.float64(0.11570247933884298), 36: np.float64(0.34285714285714286), 37: np.float64(0.2711864406779661), 38: np.float64(0.14814814814814814), 39: np.float64(0.07692307692307693), 40: np.float64(0.07476635514018691)}
Micro-average F1 score: 0.2544522396114409
Weighted-average F1 score: 0.23323466835438994
F1 score per class: {0: np.float64(0.3316582914572864), 1: np.float64(0.1), 2: np.float64(0.13861386138613863), 3: np.float64(0.23222748815165878), 4: np.float64(0.6966292134831461), 5: np.float64(0.33856893542757416), 6: np.float64(0.17699115044247787), 7: np.float64(0.023054755043227664), 8: np.float64(0.22033898305084745), 9: np.float64(0.37037037037037035), 10: np.float64(0.07079646017699115), 11: np.float64(0.171875), 12: np.float64(0.1686046511627907), 13: np.float64(0.018867924528301886), 14: np.float64(0.027777777777777776), 15: np.float64(0.3076923076923077), 16: np.float64(0.3013698630136986), 17: np.float64(0.15384615384615385), 18: np.float64(0.0392156862745098), 19: np.float64(0.4010152284263959), 20: np.float64(0.19117647058823528), 21: np.float64(0.03076923076923077), 22: np.float64(0.2977867203219316), 23: np.float64(0.463768115942029), 24: np.float64(0.0), 25: np.float64(0.41025641025641024), 26: np.float64(0.5275590551181102), 27: np.float64(0.0), 28: np.float64(0.05063291139240506), 29: np.float64(0.6454183266932271), 30: np.float64(0.5964912280701754), 31: np.float64(0.034482758620689655), 32: np.float64(0.36363636363636365), 33: np.float64(0.12121212121212122), 34: np.float64(0.09746588693957114), 35: np.float64(0.1797752808988764), 36: np.float64(0.29605263157894735), 37: np.float64(0.08849557522123894), 38: np.float64(0.14035087719298245), 39: np.float64(0.058823529411764705), 40: np.float64(0.09523809523809523)}
Micro-average F1 score: 0.230727529003578
Weighted-average F1 score: 0.21753188209374796
F1 score per class: {0: np.float64(0.3333333333333333), 1: np.float64(0.09395973154362416), 2: np.float64(0.18666666666666668), 3: np.float64(0.21739130434782608), 4: np.float64(0.7415730337078652), 5: np.float64(0.5303867403314917), 6: np.float64(0.17592592592592593), 7: np.float64(0.0221606648199446), 8: np.float64(0.22818791946308725), 9: np.float64(0.78125), 10: np.float64(0.06722689075630252), 11: np.float64(0.15492957746478872), 12: np.float64(0.15517241379310345), 13: np.float64(0.014705882352941176), 14: np.float64(0.028070175438596492), 15: np.float64(0.2727272727272727), 16: np.float64(0.26666666666666666), 17: np.float64(0.0), 18: np.float64(0.020833333333333332), 19: np.float64(0.4463276836158192), 20: np.float64(0.19399538106235567), 21: np.float64(0.0), 22: np.float64(0.2909090909090909), 23: np.float64(0.5045045045045045), 24: np.float64(0.0), 25: np.float64(0.4383561643835616), 26: np.float64(0.5800865800865801), 27: np.float64(0.0), 28: np.float64(0.07547169811320754), 29: np.float64(0.6422764227642277), 30: np.float64(0.7894736842105263), 31: np.float64(0.06896551724137931), 32: np.float64(0.36123348017621143), 33: np.float64(0.13333333333333333), 34: np.float64(0.09325396825396826), 35: np.float64(0.18461538461538463), 36: np.float64(0.3064516129032258), 37: np.float64(0.11320754716981132), 38: np.float64(0.08695652173913043), 39: np.float64(0.05), 40: np.float64(0.08830022075055188)}
Micro-average F1 score: 0.23724875101661438
Weighted-average F1 score: 0.21837626020887
cur_acc_wo_na:  ['0.7701', '0.5233', '0.4373', '0.6394', '0.4099', '0.4958', '0.3234', '0.3499']
his_acc_wo_na:  ['0.7701', '0.6800', '0.5671', '0.5737', '0.4987', '0.4888', '0.4234', '0.3596']
cur_acc des_wo_na:  ['0.7353', '0.5646', '0.4355', '0.5428', '0.4579', '0.5263', '0.3362', '0.3345']
his_acc des_wo_na:  ['0.7353', '0.6567', '0.5385', '0.5273', '0.4644', '0.4598', '0.4057', '0.3406']
cur_acc rrf_wo_na:  ['0.7514', '0.5604', '0.4676', '0.5603', '0.4342', '0.5178', '0.3664', '0.3371']
his_acc rrf_wo_na:  ['0.7514', '0.6705', '0.5607', '0.5358', '0.4684', '0.4739', '0.4095', '0.3455']
cur_acc_w_na:  ['0.6376', '0.4048', '0.3139', '0.4838', '0.3126', '0.3421', '0.2692', '0.2370']
his_acc_w_na:  ['0.6376', '0.5391', '0.4183', '0.4170', '0.3615', '0.3557', '0.3151', '0.2545']
cur_acc des_w_na:  ['0.6034', '0.4129', '0.2982', '0.3907', '0.3128', '0.3413', '0.2599', '0.2201']
his_acc des_w_na:  ['0.6034', '0.4937', '0.3677', '0.3619', '0.3136', '0.3089', '0.2845', '0.2307']
cur_acc rrf_w_na:  ['0.6178', '0.4085', '0.3223', '0.4099', '0.3036', '0.3442', '0.2857', '0.2229']
his_acc rrf_w_na:  ['0.6178', '0.5075', '0.3877', '0.3742', '0.3200', '0.3232', '0.2911', '0.2372']
--------Round  3
seed:  400
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 0 1 2 5 3 4 6]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 110.2881408CurrentTrain: epoch  0, batch     1 | loss: 200.4501703CurrentTrain: epoch  0, batch     2 | loss: 121.2643890CurrentTrain: epoch  0, batch     3 | loss: 102.2740993CurrentTrain: epoch  0, batch     4 | loss: 87.3742756CurrentTrain: epoch  0, batch     5 | loss: 89.3988367CurrentTrain: epoch  0, batch     6 | loss: 77.9242297CurrentTrain: epoch  0, batch     7 | loss: 119.6406817CurrentTrain: epoch  0, batch     8 | loss: 118.1666075CurrentTrain: epoch  0, batch     9 | loss: 119.2832441CurrentTrain: epoch  0, batch    10 | loss: 147.6955525CurrentTrain: epoch  0, batch    11 | loss: 118.9807344CurrentTrain: epoch  0, batch    12 | loss: 100.5061261CurrentTrain: epoch  0, batch    13 | loss: 147.0250235CurrentTrain: epoch  0, batch    14 | loss: 118.0496389CurrentTrain: epoch  0, batch    15 | loss: 87.0369627CurrentTrain: epoch  0, batch    16 | loss: 100.0643783CurrentTrain: epoch  0, batch    17 | loss: 86.5537442CurrentTrain: epoch  0, batch    18 | loss: 100.3460766CurrentTrain: epoch  0, batch    19 | loss: 118.1000583CurrentTrain: epoch  0, batch    20 | loss: 86.2426830CurrentTrain: epoch  0, batch    21 | loss: 145.6901120CurrentTrain: epoch  0, batch    22 | loss: 75.7429608CurrentTrain: epoch  0, batch    23 | loss: 99.2006028CurrentTrain: epoch  0, batch    24 | loss: 117.8581358CurrentTrain: epoch  0, batch    25 | loss: 98.9183290CurrentTrain: epoch  0, batch    26 | loss: 86.3062819CurrentTrain: epoch  0, batch    27 | loss: 85.8851825CurrentTrain: epoch  0, batch    28 | loss: 117.4298165CurrentTrain: epoch  0, batch    29 | loss: 98.6016425CurrentTrain: epoch  0, batch    30 | loss: 117.9629917CurrentTrain: epoch  0, batch    31 | loss: 75.5564439CurrentTrain: epoch  0, batch    32 | loss: 116.5358972CurrentTrain: epoch  0, batch    33 | loss: 117.8195853CurrentTrain: epoch  0, batch    34 | loss: 84.5616043CurrentTrain: epoch  0, batch    35 | loss: 144.8483801CurrentTrain: epoch  0, batch    36 | loss: 98.5846977CurrentTrain: epoch  0, batch    37 | loss: 98.1870545CurrentTrain: epoch  0, batch    38 | loss: 84.5961954CurrentTrain: epoch  0, batch    39 | loss: 97.6271461CurrentTrain: epoch  0, batch    40 | loss: 97.2902527CurrentTrain: epoch  0, batch    41 | loss: 97.0364292CurrentTrain: epoch  0, batch    42 | loss: 115.0473903CurrentTrain: epoch  0, batch    43 | loss: 145.0333101CurrentTrain: epoch  0, batch    44 | loss: 97.9342011CurrentTrain: epoch  0, batch    45 | loss: 117.1089596CurrentTrain: epoch  0, batch    46 | loss: 114.9091801CurrentTrain: epoch  0, batch    47 | loss: 95.2666876CurrentTrain: epoch  0, batch    48 | loss: 117.6410066CurrentTrain: epoch  0, batch    49 | loss: 96.7329349CurrentTrain: epoch  0, batch    50 | loss: 81.8785893CurrentTrain: epoch  0, batch    51 | loss: 97.9568146CurrentTrain: epoch  0, batch    52 | loss: 72.5353804CurrentTrain: epoch  0, batch    53 | loss: 84.4438073CurrentTrain: epoch  0, batch    54 | loss: 141.3781548CurrentTrain: epoch  0, batch    55 | loss: 83.7017649CurrentTrain: epoch  0, batch    56 | loss: 95.6652163CurrentTrain: epoch  0, batch    57 | loss: 115.6977992CurrentTrain: epoch  0, batch    58 | loss: 188.9622332CurrentTrain: epoch  0, batch    59 | loss: 142.0038656CurrentTrain: epoch  0, batch    60 | loss: 95.1924530CurrentTrain: epoch  0, batch    61 | loss: 92.8267099CurrentTrain: epoch  0, batch    62 | loss: 191.1139850CurrentTrain: epoch  0, batch    63 | loss: 114.0301618CurrentTrain: epoch  0, batch    64 | loss: 81.4071547CurrentTrain: epoch  0, batch    65 | loss: 80.8235405CurrentTrain: epoch  0, batch    66 | loss: 113.6217650CurrentTrain: epoch  0, batch    67 | loss: 112.6935092CurrentTrain: epoch  0, batch    68 | loss: 94.2902952CurrentTrain: epoch  0, batch    69 | loss: 140.8175390CurrentTrain: epoch  0, batch    70 | loss: 90.5743589CurrentTrain: epoch  0, batch    71 | loss: 69.6322559CurrentTrain: epoch  0, batch    72 | loss: 115.0130219CurrentTrain: epoch  0, batch    73 | loss: 92.9354824CurrentTrain: epoch  0, batch    74 | loss: 95.2651714CurrentTrain: epoch  0, batch    75 | loss: 96.8048269CurrentTrain: epoch  0, batch    76 | loss: 79.5999846CurrentTrain: epoch  0, batch    77 | loss: 77.1028388CurrentTrain: epoch  0, batch    78 | loss: 71.2210779CurrentTrain: epoch  0, batch    79 | loss: 95.0423412CurrentTrain: epoch  0, batch    80 | loss: 80.2679860CurrentTrain: epoch  0, batch    81 | loss: 79.0096110CurrentTrain: epoch  0, batch    82 | loss: 80.4991476CurrentTrain: epoch  0, batch    83 | loss: 67.8921696CurrentTrain: epoch  0, batch    84 | loss: 95.6147689CurrentTrain: epoch  0, batch    85 | loss: 109.1481121CurrentTrain: epoch  0, batch    86 | loss: 81.3408439CurrentTrain: epoch  0, batch    87 | loss: 94.9496809CurrentTrain: epoch  0, batch    88 | loss: 91.8759410CurrentTrain: epoch  0, batch    89 | loss: 137.2863546CurrentTrain: epoch  0, batch    90 | loss: 142.1620753CurrentTrain: epoch  0, batch    91 | loss: 111.7227129CurrentTrain: epoch  0, batch    92 | loss: 77.1848387CurrentTrain: epoch  0, batch    93 | loss: 79.8912701CurrentTrain: epoch  0, batch    94 | loss: 85.9951529CurrentTrain: epoch  0, batch    95 | loss: 95.1037907CurrentTrain: epoch  1, batch     0 | loss: 67.3470938CurrentTrain: epoch  1, batch     1 | loss: 79.8374586CurrentTrain: epoch  1, batch     2 | loss: 66.7043028CurrentTrain: epoch  1, batch     3 | loss: 108.8896333CurrentTrain: epoch  1, batch     4 | loss: 75.8090124CurrentTrain: epoch  1, batch     5 | loss: 88.5857043CurrentTrain: epoch  1, batch     6 | loss: 108.0534660CurrentTrain: epoch  1, batch     7 | loss: 88.8937974CurrentTrain: epoch  1, batch     8 | loss: 65.5824310CurrentTrain: epoch  1, batch     9 | loss: 78.3100373CurrentTrain: epoch  1, batch    10 | loss: 86.6833893CurrentTrain: epoch  1, batch    11 | loss: 140.5077296CurrentTrain: epoch  1, batch    12 | loss: 78.2267090CurrentTrain: epoch  1, batch    13 | loss: 109.4229663CurrentTrain: epoch  1, batch    14 | loss: 77.9245673CurrentTrain: epoch  1, batch    15 | loss: 92.0102850CurrentTrain: epoch  1, batch    16 | loss: 89.7786102CurrentTrain: epoch  1, batch    17 | loss: 89.8431166CurrentTrain: epoch  1, batch    18 | loss: 91.4495171CurrentTrain: epoch  1, batch    19 | loss: 109.4902861CurrentTrain: epoch  1, batch    20 | loss: 70.2339530CurrentTrain: epoch  1, batch    21 | loss: 74.6860394CurrentTrain: epoch  1, batch    22 | loss: 141.7593283CurrentTrain: epoch  1, batch    23 | loss: 137.1363016CurrentTrain: epoch  1, batch    24 | loss: 75.5580918CurrentTrain: epoch  1, batch    25 | loss: 79.2560308CurrentTrain: epoch  1, batch    26 | loss: 108.9155013CurrentTrain: epoch  1, batch    27 | loss: 75.4606246CurrentTrain: epoch  1, batch    28 | loss: 78.4653704CurrentTrain: epoch  1, batch    29 | loss: 134.9977741CurrentTrain: epoch  1, batch    30 | loss: 77.7971516CurrentTrain: epoch  1, batch    31 | loss: 76.5384433CurrentTrain: epoch  1, batch    32 | loss: 92.5620876CurrentTrain: epoch  1, batch    33 | loss: 74.3283734CurrentTrain: epoch  1, batch    34 | loss: 90.2472411CurrentTrain: epoch  1, batch    35 | loss: 136.3503626CurrentTrain: epoch  1, batch    36 | loss: 137.3309989CurrentTrain: epoch  1, batch    37 | loss: 191.1226642CurrentTrain: epoch  1, batch    38 | loss: 88.8599280CurrentTrain: epoch  1, batch    39 | loss: 77.9920791CurrentTrain: epoch  1, batch    40 | loss: 90.7710753CurrentTrain: epoch  1, batch    41 | loss: 78.9921602CurrentTrain: epoch  1, batch    42 | loss: 88.0238193CurrentTrain: epoch  1, batch    43 | loss: 67.3302859CurrentTrain: epoch  1, batch    44 | loss: 139.1379437CurrentTrain: epoch  1, batch    45 | loss: 108.1269595CurrentTrain: epoch  1, batch    46 | loss: 136.7635118CurrentTrain: epoch  1, batch    47 | loss: 75.7158388CurrentTrain: epoch  1, batch    48 | loss: 73.4613459CurrentTrain: epoch  1, batch    49 | loss: 107.7844189CurrentTrain: epoch  1, batch    50 | loss: 73.1814343CurrentTrain: epoch  1, batch    51 | loss: 77.9073457CurrentTrain: epoch  1, batch    52 | loss: 137.0305175CurrentTrain: epoch  1, batch    53 | loss: 90.7816508CurrentTrain: epoch  1, batch    54 | loss: 92.5695341CurrentTrain: epoch  1, batch    55 | loss: 133.8783275CurrentTrain: epoch  1, batch    56 | loss: 103.7683211CurrentTrain: epoch  1, batch    57 | loss: 66.9677075CurrentTrain: epoch  1, batch    58 | loss: 107.6198015CurrentTrain: epoch  1, batch    59 | loss: 83.0185232CurrentTrain: epoch  1, batch    60 | loss: 65.2875248CurrentTrain: epoch  1, batch    61 | loss: 68.0319157CurrentTrain: epoch  1, batch    62 | loss: 89.8734974CurrentTrain: epoch  1, batch    63 | loss: 76.1762534CurrentTrain: epoch  1, batch    64 | loss: 76.4050803CurrentTrain: epoch  1, batch    65 | loss: 92.2446486CurrentTrain: epoch  1, batch    66 | loss: 65.7394992CurrentTrain: epoch  1, batch    67 | loss: 108.3860113CurrentTrain: epoch  1, batch    68 | loss: 62.1752884CurrentTrain: epoch  1, batch    69 | loss: 110.5913501CurrentTrain: epoch  1, batch    70 | loss: 139.5524633CurrentTrain: epoch  1, batch    71 | loss: 69.8729583CurrentTrain: epoch  1, batch    72 | loss: 140.7264590CurrentTrain: epoch  1, batch    73 | loss: 138.9524942CurrentTrain: epoch  1, batch    74 | loss: 66.9300905CurrentTrain: epoch  1, batch    75 | loss: 66.5153131CurrentTrain: epoch  1, batch    76 | loss: 76.7268534CurrentTrain: epoch  1, batch    77 | loss: 79.0221042CurrentTrain: epoch  1, batch    78 | loss: 108.8937049CurrentTrain: epoch  1, batch    79 | loss: 87.2354609CurrentTrain: epoch  1, batch    80 | loss: 70.4878152CurrentTrain: epoch  1, batch    81 | loss: 134.5722371CurrentTrain: epoch  1, batch    82 | loss: 76.6700300CurrentTrain: epoch  1, batch    83 | loss: 104.4791788CurrentTrain: epoch  1, batch    84 | loss: 71.7802243CurrentTrain: epoch  1, batch    85 | loss: 88.0601097CurrentTrain: epoch  1, batch    86 | loss: 90.4341197CurrentTrain: epoch  1, batch    87 | loss: 87.7001208CurrentTrain: epoch  1, batch    88 | loss: 100.3308438CurrentTrain: epoch  1, batch    89 | loss: 85.7675293CurrentTrain: epoch  1, batch    90 | loss: 105.5244935CurrentTrain: epoch  1, batch    91 | loss: 91.2600042CurrentTrain: epoch  1, batch    92 | loss: 86.0501031CurrentTrain: epoch  1, batch    93 | loss: 104.6065491CurrentTrain: epoch  1, batch    94 | loss: 85.3752532CurrentTrain: epoch  1, batch    95 | loss: 62.1356864CurrentTrain: epoch  2, batch     0 | loss: 99.8206042CurrentTrain: epoch  2, batch     1 | loss: 75.1577209CurrentTrain: epoch  2, batch     2 | loss: 69.8664877CurrentTrain: epoch  2, batch     3 | loss: 61.3922028CurrentTrain: epoch  2, batch     4 | loss: 99.5570106CurrentTrain: epoch  2, batch     5 | loss: 107.4084437CurrentTrain: epoch  2, batch     6 | loss: 85.5250034CurrentTrain: epoch  2, batch     7 | loss: 73.0709277CurrentTrain: epoch  2, batch     8 | loss: 72.6035895CurrentTrain: epoch  2, batch     9 | loss: 104.1375735CurrentTrain: epoch  2, batch    10 | loss: 73.9223068CurrentTrain: epoch  2, batch    11 | loss: 89.2307178CurrentTrain: epoch  2, batch    12 | loss: 70.5373577CurrentTrain: epoch  2, batch    13 | loss: 73.4205940CurrentTrain: epoch  2, batch    14 | loss: 107.6448030CurrentTrain: epoch  2, batch    15 | loss: 65.2069696CurrentTrain: epoch  2, batch    16 | loss: 66.1408319CurrentTrain: epoch  2, batch    17 | loss: 178.6956212CurrentTrain: epoch  2, batch    18 | loss: 83.5637262CurrentTrain: epoch  2, batch    19 | loss: 109.4908037CurrentTrain: epoch  2, batch    20 | loss: 86.0793051CurrentTrain: epoch  2, batch    21 | loss: 98.7880407CurrentTrain: epoch  2, batch    22 | loss: 69.5916472CurrentTrain: epoch  2, batch    23 | loss: 73.1822916CurrentTrain: epoch  2, batch    24 | loss: 71.6663766CurrentTrain: epoch  2, batch    25 | loss: 74.8683138CurrentTrain: epoch  2, batch    26 | loss: 104.9514419CurrentTrain: epoch  2, batch    27 | loss: 63.0767415CurrentTrain: epoch  2, batch    28 | loss: 106.6815210CurrentTrain: epoch  2, batch    29 | loss: 72.0297744CurrentTrain: epoch  2, batch    30 | loss: 99.6855174CurrentTrain: epoch  2, batch    31 | loss: 107.8324029CurrentTrain: epoch  2, batch    32 | loss: 81.3094597CurrentTrain: epoch  2, batch    33 | loss: 74.4465009CurrentTrain: epoch  2, batch    34 | loss: 88.2061006CurrentTrain: epoch  2, batch    35 | loss: 89.6337770CurrentTrain: epoch  2, batch    36 | loss: 84.2000104CurrentTrain: epoch  2, batch    37 | loss: 134.6034163CurrentTrain: epoch  2, batch    38 | loss: 71.8367321CurrentTrain: epoch  2, batch    39 | loss: 103.8566828CurrentTrain: epoch  2, batch    40 | loss: 85.5933846CurrentTrain: epoch  2, batch    41 | loss: 75.6510973CurrentTrain: epoch  2, batch    42 | loss: 72.9652425CurrentTrain: epoch  2, batch    43 | loss: 71.2521994CurrentTrain: epoch  2, batch    44 | loss: 110.7026847CurrentTrain: epoch  2, batch    45 | loss: 85.0020410CurrentTrain: epoch  2, batch    46 | loss: 109.9812916CurrentTrain: epoch  2, batch    47 | loss: 108.6131659CurrentTrain: epoch  2, batch    48 | loss: 104.2882381CurrentTrain: epoch  2, batch    49 | loss: 106.6205828CurrentTrain: epoch  2, batch    50 | loss: 76.8229240CurrentTrain: epoch  2, batch    51 | loss: 74.9428521CurrentTrain: epoch  2, batch    52 | loss: 88.1307465CurrentTrain: epoch  2, batch    53 | loss: 83.3404736CurrentTrain: epoch  2, batch    54 | loss: 106.1359154CurrentTrain: epoch  2, batch    55 | loss: 86.3077037CurrentTrain: epoch  2, batch    56 | loss: 134.3071945CurrentTrain: epoch  2, batch    57 | loss: 105.8133341CurrentTrain: epoch  2, batch    58 | loss: 86.9456553CurrentTrain: epoch  2, batch    59 | loss: 87.8365567CurrentTrain: epoch  2, batch    60 | loss: 99.5620203CurrentTrain: epoch  2, batch    61 | loss: 122.7692772CurrentTrain: epoch  2, batch    62 | loss: 86.4241445CurrentTrain: epoch  2, batch    63 | loss: 87.5224998CurrentTrain: epoch  2, batch    64 | loss: 88.8789228CurrentTrain: epoch  2, batch    65 | loss: 88.1138519CurrentTrain: epoch  2, batch    66 | loss: 106.7203458CurrentTrain: epoch  2, batch    67 | loss: 104.6949623CurrentTrain: epoch  2, batch    68 | loss: 134.9671200CurrentTrain: epoch  2, batch    69 | loss: 107.3827331CurrentTrain: epoch  2, batch    70 | loss: 64.0235490CurrentTrain: epoch  2, batch    71 | loss: 100.0516880CurrentTrain: epoch  2, batch    72 | loss: 177.5665102CurrentTrain: epoch  2, batch    73 | loss: 88.3501990CurrentTrain: epoch  2, batch    74 | loss: 84.6362123CurrentTrain: epoch  2, batch    75 | loss: 72.4851251CurrentTrain: epoch  2, batch    76 | loss: 101.3492596CurrentTrain: epoch  2, batch    77 | loss: 82.6981898CurrentTrain: epoch  2, batch    78 | loss: 73.4210876CurrentTrain: epoch  2, batch    79 | loss: 106.4199782CurrentTrain: epoch  2, batch    80 | loss: 181.1571847CurrentTrain: epoch  2, batch    81 | loss: 86.4744897CurrentTrain: epoch  2, batch    82 | loss: 87.8923381CurrentTrain: epoch  2, batch    83 | loss: 59.4943287CurrentTrain: epoch  2, batch    84 | loss: 87.5630436CurrentTrain: epoch  2, batch    85 | loss: 61.2366736CurrentTrain: epoch  2, batch    86 | loss: 82.3743635CurrentTrain: epoch  2, batch    87 | loss: 99.9218039CurrentTrain: epoch  2, batch    88 | loss: 125.2189736CurrentTrain: epoch  2, batch    89 | loss: 135.1487757CurrentTrain: epoch  2, batch    90 | loss: 129.8421205CurrentTrain: epoch  2, batch    91 | loss: 107.3069842CurrentTrain: epoch  2, batch    92 | loss: 109.1053942CurrentTrain: epoch  2, batch    93 | loss: 110.4513240CurrentTrain: epoch  2, batch    94 | loss: 73.0728706CurrentTrain: epoch  2, batch    95 | loss: 72.7589407CurrentTrain: epoch  3, batch     0 | loss: 60.2951601CurrentTrain: epoch  3, batch     1 | loss: 63.6037508CurrentTrain: epoch  3, batch     2 | loss: 70.9321917CurrentTrain: epoch  3, batch     3 | loss: 86.7532652CurrentTrain: epoch  3, batch     4 | loss: 68.8715934CurrentTrain: epoch  3, batch     5 | loss: 83.8463893CurrentTrain: epoch  3, batch     6 | loss: 107.4754480CurrentTrain: epoch  3, batch     7 | loss: 81.9598768CurrentTrain: epoch  3, batch     8 | loss: 61.1659073CurrentTrain: epoch  3, batch     9 | loss: 108.4422801CurrentTrain: epoch  3, batch    10 | loss: 85.0396285CurrentTrain: epoch  3, batch    11 | loss: 97.1801435CurrentTrain: epoch  3, batch    12 | loss: 87.8670903CurrentTrain: epoch  3, batch    13 | loss: 108.1425281CurrentTrain: epoch  3, batch    14 | loss: 87.5932298CurrentTrain: epoch  3, batch    15 | loss: 105.3574605CurrentTrain: epoch  3, batch    16 | loss: 105.2341552CurrentTrain: epoch  3, batch    17 | loss: 73.5407187CurrentTrain: epoch  3, batch    18 | loss: 83.2249631CurrentTrain: epoch  3, batch    19 | loss: 85.8645361CurrentTrain: epoch  3, batch    20 | loss: 73.5972426CurrentTrain: epoch  3, batch    21 | loss: 68.1975097CurrentTrain: epoch  3, batch    22 | loss: 102.4389606CurrentTrain: epoch  3, batch    23 | loss: 176.7473745CurrentTrain: epoch  3, batch    24 | loss: 82.9495332CurrentTrain: epoch  3, batch    25 | loss: 105.5634788CurrentTrain: epoch  3, batch    26 | loss: 98.4554051CurrentTrain: epoch  3, batch    27 | loss: 131.8137455CurrentTrain: epoch  3, batch    28 | loss: 67.9228914CurrentTrain: epoch  3, batch    29 | loss: 102.3149783CurrentTrain: epoch  3, batch    30 | loss: 86.2960635CurrentTrain: epoch  3, batch    31 | loss: 67.9458921CurrentTrain: epoch  3, batch    32 | loss: 103.0308611CurrentTrain: epoch  3, batch    33 | loss: 84.9096920CurrentTrain: epoch  3, batch    34 | loss: 72.2355950CurrentTrain: epoch  3, batch    35 | loss: 63.3654255CurrentTrain: epoch  3, batch    36 | loss: 87.5901916CurrentTrain: epoch  3, batch    37 | loss: 67.5802335CurrentTrain: epoch  3, batch    38 | loss: 105.6188020CurrentTrain: epoch  3, batch    39 | loss: 84.0481945CurrentTrain: epoch  3, batch    40 | loss: 100.9695722CurrentTrain: epoch  3, batch    41 | loss: 82.4675525CurrentTrain: epoch  3, batch    42 | loss: 84.7248254CurrentTrain: epoch  3, batch    43 | loss: 84.4092278CurrentTrain: epoch  3, batch    44 | loss: 72.2682777CurrentTrain: epoch  3, batch    45 | loss: 84.3515803CurrentTrain: epoch  3, batch    46 | loss: 67.9915200CurrentTrain: epoch  3, batch    47 | loss: 80.8125850CurrentTrain: epoch  3, batch    48 | loss: 75.3690289CurrentTrain: epoch  3, batch    49 | loss: 105.5966302CurrentTrain: epoch  3, batch    50 | loss: 83.8172706CurrentTrain: epoch  3, batch    51 | loss: 85.5763926CurrentTrain: epoch  3, batch    52 | loss: 103.1504374CurrentTrain: epoch  3, batch    53 | loss: 61.0205574CurrentTrain: epoch  3, batch    54 | loss: 68.1387619CurrentTrain: epoch  3, batch    55 | loss: 81.4123653CurrentTrain: epoch  3, batch    56 | loss: 71.9804927CurrentTrain: epoch  3, batch    57 | loss: 104.5735432CurrentTrain: epoch  3, batch    58 | loss: 173.5809870CurrentTrain: epoch  3, batch    59 | loss: 81.8827015CurrentTrain: epoch  3, batch    60 | loss: 102.3049665CurrentTrain: epoch  3, batch    61 | loss: 100.3889472CurrentTrain: epoch  3, batch    62 | loss: 133.5634241CurrentTrain: epoch  3, batch    63 | loss: 86.6509692CurrentTrain: epoch  3, batch    64 | loss: 68.7895748CurrentTrain: epoch  3, batch    65 | loss: 73.2551705CurrentTrain: epoch  3, batch    66 | loss: 68.1622287CurrentTrain: epoch  3, batch    67 | loss: 130.9818381CurrentTrain: epoch  3, batch    68 | loss: 102.0809954CurrentTrain: epoch  3, batch    69 | loss: 107.6288421CurrentTrain: epoch  3, batch    70 | loss: 68.6759143CurrentTrain: epoch  3, batch    71 | loss: 73.5177644CurrentTrain: epoch  3, batch    72 | loss: 83.2881781CurrentTrain: epoch  3, batch    73 | loss: 100.7064647CurrentTrain: epoch  3, batch    74 | loss: 61.1726102CurrentTrain: epoch  3, batch    75 | loss: 72.5687624CurrentTrain: epoch  3, batch    76 | loss: 127.1635772CurrentTrain: epoch  3, batch    77 | loss: 70.2841971CurrentTrain: epoch  3, batch    78 | loss: 79.9965405CurrentTrain: epoch  3, batch    79 | loss: 83.4533006CurrentTrain: epoch  3, batch    80 | loss: 88.4302918CurrentTrain: epoch  3, batch    81 | loss: 73.7049236CurrentTrain: epoch  3, batch    82 | loss: 57.7173781CurrentTrain: epoch  3, batch    83 | loss: 85.3098386CurrentTrain: epoch  3, batch    84 | loss: 105.6622589CurrentTrain: epoch  3, batch    85 | loss: 79.6670037CurrentTrain: epoch  3, batch    86 | loss: 85.7945853CurrentTrain: epoch  3, batch    87 | loss: 89.4660767CurrentTrain: epoch  3, batch    88 | loss: 86.2971397CurrentTrain: epoch  3, batch    89 | loss: 131.0769604CurrentTrain: epoch  3, batch    90 | loss: 64.0047721CurrentTrain: epoch  3, batch    91 | loss: 103.9589453CurrentTrain: epoch  3, batch    92 | loss: 74.6849341CurrentTrain: epoch  3, batch    93 | loss: 67.0128090CurrentTrain: epoch  3, batch    94 | loss: 72.5356227CurrentTrain: epoch  3, batch    95 | loss: 74.5774253CurrentTrain: epoch  4, batch     0 | loss: 85.3915190CurrentTrain: epoch  4, batch     1 | loss: 86.3827584CurrentTrain: epoch  4, batch     2 | loss: 61.1597890CurrentTrain: epoch  4, batch     3 | loss: 133.3750995CurrentTrain: epoch  4, batch     4 | loss: 83.4598726CurrentTrain: epoch  4, batch     5 | loss: 83.0732702CurrentTrain: epoch  4, batch     6 | loss: 72.8736615CurrentTrain: epoch  4, batch     7 | loss: 67.4775942CurrentTrain: epoch  4, batch     8 | loss: 86.6387348CurrentTrain: epoch  4, batch     9 | loss: 64.7566888CurrentTrain: epoch  4, batch    10 | loss: 84.4783937CurrentTrain: epoch  4, batch    11 | loss: 82.4834087CurrentTrain: epoch  4, batch    12 | loss: 68.2952395CurrentTrain: epoch  4, batch    13 | loss: 123.3092816CurrentTrain: epoch  4, batch    14 | loss: 82.6516293CurrentTrain: epoch  4, batch    15 | loss: 76.1727922CurrentTrain: epoch  4, batch    16 | loss: 101.3259284CurrentTrain: epoch  4, batch    17 | loss: 84.6992536CurrentTrain: epoch  4, batch    18 | loss: 59.2695936CurrentTrain: epoch  4, batch    19 | loss: 69.4416825CurrentTrain: epoch  4, batch    20 | loss: 67.0706649CurrentTrain: epoch  4, batch    21 | loss: 57.5080267CurrentTrain: epoch  4, batch    22 | loss: 83.3395410CurrentTrain: epoch  4, batch    23 | loss: 92.2021112CurrentTrain: epoch  4, batch    24 | loss: 132.0250433CurrentTrain: epoch  4, batch    25 | loss: 70.4724885CurrentTrain: epoch  4, batch    26 | loss: 96.3112703CurrentTrain: epoch  4, batch    27 | loss: 78.9522842CurrentTrain: epoch  4, batch    28 | loss: 84.0614981CurrentTrain: epoch  4, batch    29 | loss: 128.2055931CurrentTrain: epoch  4, batch    30 | loss: 82.8752725CurrentTrain: epoch  4, batch    31 | loss: 101.3656254CurrentTrain: epoch  4, batch    32 | loss: 94.7450056CurrentTrain: epoch  4, batch    33 | loss: 101.4174501CurrentTrain: epoch  4, batch    34 | loss: 103.1654870CurrentTrain: epoch  4, batch    35 | loss: 82.4535132CurrentTrain: epoch  4, batch    36 | loss: 85.8403979CurrentTrain: epoch  4, batch    37 | loss: 81.3829968CurrentTrain: epoch  4, batch    38 | loss: 129.7256792CurrentTrain: epoch  4, batch    39 | loss: 87.0332511CurrentTrain: epoch  4, batch    40 | loss: 103.0872536CurrentTrain: epoch  4, batch    41 | loss: 84.8337180CurrentTrain: epoch  4, batch    42 | loss: 77.1610795CurrentTrain: epoch  4, batch    43 | loss: 129.7556220CurrentTrain: epoch  4, batch    44 | loss: 83.5245033CurrentTrain: epoch  4, batch    45 | loss: 101.3533607CurrentTrain: epoch  4, batch    46 | loss: 94.1800707CurrentTrain: epoch  4, batch    47 | loss: 70.7366050CurrentTrain: epoch  4, batch    48 | loss: 79.8613627CurrentTrain: epoch  4, batch    49 | loss: 82.5894654CurrentTrain: epoch  4, batch    50 | loss: 83.2888928CurrentTrain: epoch  4, batch    51 | loss: 101.9470282CurrentTrain: epoch  4, batch    52 | loss: 76.0166652CurrentTrain: epoch  4, batch    53 | loss: 71.0134321CurrentTrain: epoch  4, batch    54 | loss: 102.2585972CurrentTrain: epoch  4, batch    55 | loss: 80.1287908CurrentTrain: epoch  4, batch    56 | loss: 81.6006968CurrentTrain: epoch  4, batch    57 | loss: 86.0928811CurrentTrain: epoch  4, batch    58 | loss: 64.3260305CurrentTrain: epoch  4, batch    59 | loss: 80.6958022CurrentTrain: epoch  4, batch    60 | loss: 108.9394380CurrentTrain: epoch  4, batch    61 | loss: 70.7019075CurrentTrain: epoch  4, batch    62 | loss: 81.7963110CurrentTrain: epoch  4, batch    63 | loss: 84.6285103CurrentTrain: epoch  4, batch    64 | loss: 95.9675740CurrentTrain: epoch  4, batch    65 | loss: 70.2704404CurrentTrain: epoch  4, batch    66 | loss: 83.2136357CurrentTrain: epoch  4, batch    67 | loss: 79.0230983CurrentTrain: epoch  4, batch    68 | loss: 84.9597749CurrentTrain: epoch  4, batch    69 | loss: 88.5865784CurrentTrain: epoch  4, batch    70 | loss: 70.5231148CurrentTrain: epoch  4, batch    71 | loss: 97.6188157CurrentTrain: epoch  4, batch    72 | loss: 81.2871664CurrentTrain: epoch  4, batch    73 | loss: 72.2726357CurrentTrain: epoch  4, batch    74 | loss: 86.5696262CurrentTrain: epoch  4, batch    75 | loss: 67.2564219CurrentTrain: epoch  4, batch    76 | loss: 105.3525876CurrentTrain: epoch  4, batch    77 | loss: 70.2161611CurrentTrain: epoch  4, batch    78 | loss: 127.5180872CurrentTrain: epoch  4, batch    79 | loss: 71.8490382CurrentTrain: epoch  4, batch    80 | loss: 83.8645378CurrentTrain: epoch  4, batch    81 | loss: 77.4806463CurrentTrain: epoch  4, batch    82 | loss: 65.5774581CurrentTrain: epoch  4, batch    83 | loss: 81.5596010CurrentTrain: epoch  4, batch    84 | loss: 100.1039498CurrentTrain: epoch  4, batch    85 | loss: 67.8264197CurrentTrain: epoch  4, batch    86 | loss: 173.5641219CurrentTrain: epoch  4, batch    87 | loss: 102.0372516CurrentTrain: epoch  4, batch    88 | loss: 81.9587609CurrentTrain: epoch  4, batch    89 | loss: 70.3871296CurrentTrain: epoch  4, batch    90 | loss: 84.2891884CurrentTrain: epoch  4, batch    91 | loss: 69.6501263CurrentTrain: epoch  4, batch    92 | loss: 98.9243448CurrentTrain: epoch  4, batch    93 | loss: 79.9125088CurrentTrain: epoch  4, batch    94 | loss: 84.3513454CurrentTrain: epoch  4, batch    95 | loss: 85.2033400CurrentTrain: epoch  5, batch     0 | loss: 64.5870735CurrentTrain: epoch  5, batch     1 | loss: 80.0834629CurrentTrain: epoch  5, batch     2 | loss: 70.1382567CurrentTrain: epoch  5, batch     3 | loss: 82.3765388CurrentTrain: epoch  5, batch     4 | loss: 99.1046434CurrentTrain: epoch  5, batch     5 | loss: 167.1437934CurrentTrain: epoch  5, batch     6 | loss: 130.0944522CurrentTrain: epoch  5, batch     7 | loss: 96.0848614CurrentTrain: epoch  5, batch     8 | loss: 82.7317385CurrentTrain: epoch  5, batch     9 | loss: 170.7896318CurrentTrain: epoch  5, batch    10 | loss: 95.9882508CurrentTrain: epoch  5, batch    11 | loss: 64.9031936CurrentTrain: epoch  5, batch    12 | loss: 99.0208929CurrentTrain: epoch  5, batch    13 | loss: 79.9959585CurrentTrain: epoch  5, batch    14 | loss: 84.7670580CurrentTrain: epoch  5, batch    15 | loss: 79.6990762CurrentTrain: epoch  5, batch    16 | loss: 85.5517728CurrentTrain: epoch  5, batch    17 | loss: 84.3852429CurrentTrain: epoch  5, batch    18 | loss: 81.3687950CurrentTrain: epoch  5, batch    19 | loss: 76.4575266CurrentTrain: epoch  5, batch    20 | loss: 84.3721564CurrentTrain: epoch  5, batch    21 | loss: 101.8199774CurrentTrain: epoch  5, batch    22 | loss: 96.1619690CurrentTrain: epoch  5, batch    23 | loss: 81.1084455CurrentTrain: epoch  5, batch    24 | loss: 102.6126718CurrentTrain: epoch  5, batch    25 | loss: 57.8030352CurrentTrain: epoch  5, batch    26 | loss: 71.3746172CurrentTrain: epoch  5, batch    27 | loss: 82.2635222CurrentTrain: epoch  5, batch    28 | loss: 64.1695942CurrentTrain: epoch  5, batch    29 | loss: 66.2471245CurrentTrain: epoch  5, batch    30 | loss: 56.9367631CurrentTrain: epoch  5, batch    31 | loss: 67.0069011CurrentTrain: epoch  5, batch    32 | loss: 72.7955941CurrentTrain: epoch  5, batch    33 | loss: 81.9859021CurrentTrain: epoch  5, batch    34 | loss: 77.4022105CurrentTrain: epoch  5, batch    35 | loss: 80.0696689CurrentTrain: epoch  5, batch    36 | loss: 93.0760237CurrentTrain: epoch  5, batch    37 | loss: 99.2559162CurrentTrain: epoch  5, batch    38 | loss: 83.6504488CurrentTrain: epoch  5, batch    39 | loss: 69.0865496CurrentTrain: epoch  5, batch    40 | loss: 58.8764941CurrentTrain: epoch  5, batch    41 | loss: 121.8263882CurrentTrain: epoch  5, batch    42 | loss: 88.8541872CurrentTrain: epoch  5, batch    43 | loss: 81.6075193CurrentTrain: epoch  5, batch    44 | loss: 95.7517124CurrentTrain: epoch  5, batch    45 | loss: 99.5297480CurrentTrain: epoch  5, batch    46 | loss: 83.5434804CurrentTrain: epoch  5, batch    47 | loss: 55.9330379CurrentTrain: epoch  5, batch    48 | loss: 81.6498381CurrentTrain: epoch  5, batch    49 | loss: 96.8261708CurrentTrain: epoch  5, batch    50 | loss: 84.7683342CurrentTrain: epoch  5, batch    51 | loss: 84.8445512CurrentTrain: epoch  5, batch    52 | loss: 97.9809560CurrentTrain: epoch  5, batch    53 | loss: 126.7028322CurrentTrain: epoch  5, batch    54 | loss: 83.7133892CurrentTrain: epoch  5, batch    55 | loss: 81.1626857CurrentTrain: epoch  5, batch    56 | loss: 82.7176132CurrentTrain: epoch  5, batch    57 | loss: 69.0986531CurrentTrain: epoch  5, batch    58 | loss: 99.5199159CurrentTrain: epoch  5, batch    59 | loss: 129.1787995CurrentTrain: epoch  5, batch    60 | loss: 80.0136610CurrentTrain: epoch  5, batch    61 | loss: 90.2404780CurrentTrain: epoch  5, batch    62 | loss: 98.3325513CurrentTrain: epoch  5, batch    63 | loss: 70.4690251CurrentTrain: epoch  5, batch    64 | loss: 83.5242288CurrentTrain: epoch  5, batch    65 | loss: 78.6947369CurrentTrain: epoch  5, batch    66 | loss: 69.6295812CurrentTrain: epoch  5, batch    67 | loss: 81.2471394CurrentTrain: epoch  5, batch    68 | loss: 71.6623240CurrentTrain: epoch  5, batch    69 | loss: 79.0996112CurrentTrain: epoch  5, batch    70 | loss: 100.1518357CurrentTrain: epoch  5, batch    71 | loss: 82.8907717CurrentTrain: epoch  5, batch    72 | loss: 67.5050794CurrentTrain: epoch  5, batch    73 | loss: 98.9874990CurrentTrain: epoch  5, batch    74 | loss: 78.0099141CurrentTrain: epoch  5, batch    75 | loss: 123.7387190CurrentTrain: epoch  5, batch    76 | loss: 60.7463676CurrentTrain: epoch  5, batch    77 | loss: 123.5623355CurrentTrain: epoch  5, batch    78 | loss: 98.5901416CurrentTrain: epoch  5, batch    79 | loss: 81.1604019CurrentTrain: epoch  5, batch    80 | loss: 79.5608250CurrentTrain: epoch  5, batch    81 | loss: 85.0986605CurrentTrain: epoch  5, batch    82 | loss: 69.5412368CurrentTrain: epoch  5, batch    83 | loss: 96.9275420CurrentTrain: epoch  5, batch    84 | loss: 81.7938350CurrentTrain: epoch  5, batch    85 | loss: 67.2171671CurrentTrain: epoch  5, batch    86 | loss: 83.5646057CurrentTrain: epoch  5, batch    87 | loss: 97.2925157CurrentTrain: epoch  5, batch    88 | loss: 130.8481294CurrentTrain: epoch  5, batch    89 | loss: 65.3729365CurrentTrain: epoch  5, batch    90 | loss: 79.8682091CurrentTrain: epoch  5, batch    91 | loss: 68.6390588CurrentTrain: epoch  5, batch    92 | loss: 101.1843213CurrentTrain: epoch  5, batch    93 | loss: 57.1588118CurrentTrain: epoch  5, batch    94 | loss: 70.5102692CurrentTrain: epoch  5, batch    95 | loss: 84.3208637CurrentTrain: epoch  6, batch     0 | loss: 77.5771597CurrentTrain: epoch  6, batch     1 | loss: 82.0484083CurrentTrain: epoch  6, batch     2 | loss: 96.6747771CurrentTrain: epoch  6, batch     3 | loss: 68.1614335CurrentTrain: epoch  6, batch     4 | loss: 56.5327905CurrentTrain: epoch  6, batch     5 | loss: 76.8682663CurrentTrain: epoch  6, batch     6 | loss: 80.9046432CurrentTrain: epoch  6, batch     7 | loss: 78.5187999CurrentTrain: epoch  6, batch     8 | loss: 82.2041133CurrentTrain: epoch  6, batch     9 | loss: 98.6211274CurrentTrain: epoch  6, batch    10 | loss: 68.5051611CurrentTrain: epoch  6, batch    11 | loss: 60.2243531CurrentTrain: epoch  6, batch    12 | loss: 119.9380262CurrentTrain: epoch  6, batch    13 | loss: 81.3244632CurrentTrain: epoch  6, batch    14 | loss: 96.3108110CurrentTrain: epoch  6, batch    15 | loss: 70.1800112CurrentTrain: epoch  6, batch    16 | loss: 55.8145847CurrentTrain: epoch  6, batch    17 | loss: 79.2195444CurrentTrain: epoch  6, batch    18 | loss: 65.8565085CurrentTrain: epoch  6, batch    19 | loss: 97.1263112CurrentTrain: epoch  6, batch    20 | loss: 62.3936655CurrentTrain: epoch  6, batch    21 | loss: 78.3681409CurrentTrain: epoch  6, batch    22 | loss: 67.7861173CurrentTrain: epoch  6, batch    23 | loss: 57.8327137CurrentTrain: epoch  6, batch    24 | loss: 84.7572547CurrentTrain: epoch  6, batch    25 | loss: 58.6826496CurrentTrain: epoch  6, batch    26 | loss: 56.9198251CurrentTrain: epoch  6, batch    27 | loss: 80.5766271CurrentTrain: epoch  6, batch    28 | loss: 65.4459327CurrentTrain: epoch  6, batch    29 | loss: 94.3757484CurrentTrain: epoch  6, batch    30 | loss: 80.1169381CurrentTrain: epoch  6, batch    31 | loss: 66.9439492CurrentTrain: epoch  6, batch    32 | loss: 128.5280095CurrentTrain: epoch  6, batch    33 | loss: 77.5529908CurrentTrain: epoch  6, batch    34 | loss: 100.7178422CurrentTrain: epoch  6, batch    35 | loss: 58.0900357CurrentTrain: epoch  6, batch    36 | loss: 82.3346580CurrentTrain: epoch  6, batch    37 | loss: 61.0659122CurrentTrain: epoch  6, batch    38 | loss: 80.0357236CurrentTrain: epoch  6, batch    39 | loss: 97.9423125CurrentTrain: epoch  6, batch    40 | loss: 82.4381527CurrentTrain: epoch  6, batch    41 | loss: 79.8306892CurrentTrain: epoch  6, batch    42 | loss: 104.9529254CurrentTrain: epoch  6, batch    43 | loss: 79.3926649CurrentTrain: epoch  6, batch    44 | loss: 98.3831243CurrentTrain: epoch  6, batch    45 | loss: 123.3665412CurrentTrain: epoch  6, batch    46 | loss: 82.9554775CurrentTrain: epoch  6, batch    47 | loss: 173.1903308CurrentTrain: epoch  6, batch    48 | loss: 171.8275270CurrentTrain: epoch  6, batch    49 | loss: 173.4953340CurrentTrain: epoch  6, batch    50 | loss: 58.2049516CurrentTrain: epoch  6, batch    51 | loss: 82.8063292CurrentTrain: epoch  6, batch    52 | loss: 94.4160295CurrentTrain: epoch  6, batch    53 | loss: 99.0074826CurrentTrain: epoch  6, batch    54 | loss: 66.5912506CurrentTrain: epoch  6, batch    55 | loss: 59.0967991CurrentTrain: epoch  6, batch    56 | loss: 77.6224073CurrentTrain: epoch  6, batch    57 | loss: 83.0740842CurrentTrain: epoch  6, batch    58 | loss: 64.4496545CurrentTrain: epoch  6, batch    59 | loss: 100.5810263CurrentTrain: epoch  6, batch    60 | loss: 70.6088657CurrentTrain: epoch  6, batch    61 | loss: 79.6389341CurrentTrain: epoch  6, batch    62 | loss: 99.8016907CurrentTrain: epoch  6, batch    63 | loss: 57.2980766CurrentTrain: epoch  6, batch    64 | loss: 82.4126939CurrentTrain: epoch  6, batch    65 | loss: 56.1926013CurrentTrain: epoch  6, batch    66 | loss: 69.8815572CurrentTrain: epoch  6, batch    67 | loss: 68.3925726CurrentTrain: epoch  6, batch    68 | loss: 66.4845926CurrentTrain: epoch  6, batch    69 | loss: 62.7263168CurrentTrain: epoch  6, batch    70 | loss: 78.4690156CurrentTrain: epoch  6, batch    71 | loss: 81.8235506CurrentTrain: epoch  6, batch    72 | loss: 103.1819618CurrentTrain: epoch  6, batch    73 | loss: 54.9308588CurrentTrain: epoch  6, batch    74 | loss: 128.5959723CurrentTrain: epoch  6, batch    75 | loss: 67.6359958CurrentTrain: epoch  6, batch    76 | loss: 85.2121092CurrentTrain: epoch  6, batch    77 | loss: 98.3048465CurrentTrain: epoch  6, batch    78 | loss: 82.7245634CurrentTrain: epoch  6, batch    79 | loss: 79.5959504CurrentTrain: epoch  6, batch    80 | loss: 66.6485987CurrentTrain: epoch  6, batch    81 | loss: 103.8888635CurrentTrain: epoch  6, batch    82 | loss: 76.2727089CurrentTrain: epoch  6, batch    83 | loss: 177.2996572CurrentTrain: epoch  6, batch    84 | loss: 81.7595678CurrentTrain: epoch  6, batch    85 | loss: 81.2946532CurrentTrain: epoch  6, batch    86 | loss: 125.8520612CurrentTrain: epoch  6, batch    87 | loss: 80.0038659CurrentTrain: epoch  6, batch    88 | loss: 55.9854613CurrentTrain: epoch  6, batch    89 | loss: 69.2175482CurrentTrain: epoch  6, batch    90 | loss: 75.9584622CurrentTrain: epoch  6, batch    91 | loss: 97.5274813CurrentTrain: epoch  6, batch    92 | loss: 80.6766096CurrentTrain: epoch  6, batch    93 | loss: 98.7897467CurrentTrain: epoch  6, batch    94 | loss: 54.1561129CurrentTrain: epoch  6, batch    95 | loss: 82.2193854CurrentTrain: epoch  7, batch     0 | loss: 65.6556006CurrentTrain: epoch  7, batch     1 | loss: 55.4724732CurrentTrain: epoch  7, batch     2 | loss: 98.1676224CurrentTrain: epoch  7, batch     3 | loss: 95.3377515CurrentTrain: epoch  7, batch     4 | loss: 79.3135106CurrentTrain: epoch  7, batch     5 | loss: 77.2728600CurrentTrain: epoch  7, batch     6 | loss: 72.6053037CurrentTrain: epoch  7, batch     7 | loss: 96.4724678CurrentTrain: epoch  7, batch     8 | loss: 122.5177161CurrentTrain: epoch  7, batch     9 | loss: 79.9561230CurrentTrain: epoch  7, batch    10 | loss: 76.3327466CurrentTrain: epoch  7, batch    11 | loss: 97.1781315CurrentTrain: epoch  7, batch    12 | loss: 57.2860598CurrentTrain: epoch  7, batch    13 | loss: 80.2848280CurrentTrain: epoch  7, batch    14 | loss: 65.6442427CurrentTrain: epoch  7, batch    15 | loss: 81.0528075CurrentTrain: epoch  7, batch    16 | loss: 77.7741240CurrentTrain: epoch  7, batch    17 | loss: 99.5444479CurrentTrain: epoch  7, batch    18 | loss: 75.8889096CurrentTrain: epoch  7, batch    19 | loss: 93.9202004CurrentTrain: epoch  7, batch    20 | loss: 98.3823111CurrentTrain: epoch  7, batch    21 | loss: 126.5295260CurrentTrain: epoch  7, batch    22 | loss: 96.4063031CurrentTrain: epoch  7, batch    23 | loss: 69.1395395CurrentTrain: epoch  7, batch    24 | loss: 57.7883065CurrentTrain: epoch  7, batch    25 | loss: 84.8901937CurrentTrain: epoch  7, batch    26 | loss: 96.3081428CurrentTrain: epoch  7, batch    27 | loss: 98.5865061CurrentTrain: epoch  7, batch    28 | loss: 66.6749247CurrentTrain: epoch  7, batch    29 | loss: 99.5444926CurrentTrain: epoch  7, batch    30 | loss: 66.4065527CurrentTrain: epoch  7, batch    31 | loss: 57.5807997CurrentTrain: epoch  7, batch    32 | loss: 127.3595316CurrentTrain: epoch  7, batch    33 | loss: 64.1659678CurrentTrain: epoch  7, batch    34 | loss: 63.8217964CurrentTrain: epoch  7, batch    35 | loss: 124.0681618CurrentTrain: epoch  7, batch    36 | loss: 100.0660071CurrentTrain: epoch  7, batch    37 | loss: 59.2192426CurrentTrain: epoch  7, batch    38 | loss: 54.4451923CurrentTrain: epoch  7, batch    39 | loss: 94.5668337CurrentTrain: epoch  7, batch    40 | loss: 81.9084093CurrentTrain: epoch  7, batch    41 | loss: 66.9465169CurrentTrain: epoch  7, batch    42 | loss: 93.2290408CurrentTrain: epoch  7, batch    43 | loss: 100.4087464CurrentTrain: epoch  7, batch    44 | loss: 99.4752293CurrentTrain: epoch  7, batch    45 | loss: 64.8391233CurrentTrain: epoch  7, batch    46 | loss: 67.2011225CurrentTrain: epoch  7, batch    47 | loss: 99.0373347CurrentTrain: epoch  7, batch    48 | loss: 64.3872083CurrentTrain: epoch  7, batch    49 | loss: 68.7460740CurrentTrain: epoch  7, batch    50 | loss: 99.2795202CurrentTrain: epoch  7, batch    51 | loss: 101.7851185CurrentTrain: epoch  7, batch    52 | loss: 65.7001544CurrentTrain: epoch  7, batch    53 | loss: 124.7386496CurrentTrain: epoch  7, batch    54 | loss: 58.9280737CurrentTrain: epoch  7, batch    55 | loss: 55.8362497CurrentTrain: epoch  7, batch    56 | loss: 59.3466450CurrentTrain: epoch  7, batch    57 | loss: 79.9067988CurrentTrain: epoch  7, batch    58 | loss: 66.0363962CurrentTrain: epoch  7, batch    59 | loss: 80.6487483CurrentTrain: epoch  7, batch    60 | loss: 81.0841815CurrentTrain: epoch  7, batch    61 | loss: 78.0851470CurrentTrain: epoch  7, batch    62 | loss: 59.9201390CurrentTrain: epoch  7, batch    63 | loss: 79.6162604CurrentTrain: epoch  7, batch    64 | loss: 97.9405362CurrentTrain: epoch  7, batch    65 | loss: 97.1470399CurrentTrain: epoch  7, batch    66 | loss: 76.6034100CurrentTrain: epoch  7, batch    67 | loss: 92.1466533CurrentTrain: epoch  7, batch    68 | loss: 100.3813583CurrentTrain: epoch  7, batch    69 | loss: 98.4042604CurrentTrain: epoch  7, batch    70 | loss: 65.6046035CurrentTrain: epoch  7, batch    71 | loss: 99.2430117CurrentTrain: epoch  7, batch    72 | loss: 78.1257468CurrentTrain: epoch  7, batch    73 | loss: 79.4607202CurrentTrain: epoch  7, batch    74 | loss: 93.6987375CurrentTrain: epoch  7, batch    75 | loss: 68.8355813CurrentTrain: epoch  7, batch    76 | loss: 77.3043059CurrentTrain: epoch  7, batch    77 | loss: 97.7307247CurrentTrain: epoch  7, batch    78 | loss: 97.1919584CurrentTrain: epoch  7, batch    79 | loss: 83.4504540CurrentTrain: epoch  7, batch    80 | loss: 65.7101257CurrentTrain: epoch  7, batch    81 | loss: 82.1985493CurrentTrain: epoch  7, batch    82 | loss: 99.7943683CurrentTrain: epoch  7, batch    83 | loss: 64.8768173CurrentTrain: epoch  7, batch    84 | loss: 65.1126098CurrentTrain: epoch  7, batch    85 | loss: 98.7045088CurrentTrain: epoch  7, batch    86 | loss: 78.5244542CurrentTrain: epoch  7, batch    87 | loss: 97.5722039CurrentTrain: epoch  7, batch    88 | loss: 100.7800393CurrentTrain: epoch  7, batch    89 | loss: 93.3085399CurrentTrain: epoch  7, batch    90 | loss: 79.1755971CurrentTrain: epoch  7, batch    91 | loss: 99.8671110CurrentTrain: epoch  7, batch    92 | loss: 77.1925647CurrentTrain: epoch  7, batch    93 | loss: 79.8273904CurrentTrain: epoch  7, batch    94 | loss: 93.1683885CurrentTrain: epoch  7, batch    95 | loss: 62.6879073CurrentTrain: epoch  8, batch     0 | loss: 79.0196182CurrentTrain: epoch  8, batch     1 | loss: 67.8064471CurrentTrain: epoch  8, batch     2 | loss: 69.3255216CurrentTrain: epoch  8, batch     3 | loss: 125.0568370CurrentTrain: epoch  8, batch     4 | loss: 76.2190017CurrentTrain: epoch  8, batch     5 | loss: 75.3462899CurrentTrain: epoch  8, batch     6 | loss: 62.3139069CurrentTrain: epoch  8, batch     7 | loss: 55.9175999CurrentTrain: epoch  8, batch     8 | loss: 57.2770185CurrentTrain: epoch  8, batch     9 | loss: 67.7704389CurrentTrain: epoch  8, batch    10 | loss: 98.1038504CurrentTrain: epoch  8, batch    11 | loss: 66.3010995CurrentTrain: epoch  8, batch    12 | loss: 80.6143590CurrentTrain: epoch  8, batch    13 | loss: 80.0074269CurrentTrain: epoch  8, batch    14 | loss: 80.5800801CurrentTrain: epoch  8, batch    15 | loss: 118.4325576CurrentTrain: epoch  8, batch    16 | loss: 123.0657992CurrentTrain: epoch  8, batch    17 | loss: 60.1360650CurrentTrain: epoch  8, batch    18 | loss: 65.0490554CurrentTrain: epoch  8, batch    19 | loss: 54.3654077CurrentTrain: epoch  8, batch    20 | loss: 64.4238377CurrentTrain: epoch  8, batch    21 | loss: 94.3643292CurrentTrain: epoch  8, batch    22 | loss: 77.9376870CurrentTrain: epoch  8, batch    23 | loss: 94.7699145CurrentTrain: epoch  8, batch    24 | loss: 125.3449016CurrentTrain: epoch  8, batch    25 | loss: 63.4103445CurrentTrain: epoch  8, batch    26 | loss: 76.2293767CurrentTrain: epoch  8, batch    27 | loss: 51.7034083CurrentTrain: epoch  8, batch    28 | loss: 77.8381808CurrentTrain: epoch  8, batch    29 | loss: 65.2633155CurrentTrain: epoch  8, batch    30 | loss: 126.9889281CurrentTrain: epoch  8, batch    31 | loss: 93.9993437CurrentTrain: epoch  8, batch    32 | loss: 75.6983160CurrentTrain: epoch  8, batch    33 | loss: 79.2840619CurrentTrain: epoch  8, batch    34 | loss: 78.4697114CurrentTrain: epoch  8, batch    35 | loss: 63.3010269CurrentTrain: epoch  8, batch    36 | loss: 76.2771866CurrentTrain: epoch  8, batch    37 | loss: 68.2981276CurrentTrain: epoch  8, batch    38 | loss: 73.3370852CurrentTrain: epoch  8, batch    39 | loss: 101.8970321CurrentTrain: epoch  8, batch    40 | loss: 67.9187362CurrentTrain: epoch  8, batch    41 | loss: 118.8088106CurrentTrain: epoch  8, batch    42 | loss: 81.8167648CurrentTrain: epoch  8, batch    43 | loss: 57.5022979CurrentTrain: epoch  8, batch    44 | loss: 56.3676690CurrentTrain: epoch  8, batch    45 | loss: 82.7930486CurrentTrain: epoch  8, batch    46 | loss: 123.7560973CurrentTrain: epoch  8, batch    47 | loss: 100.5343344CurrentTrain: epoch  8, batch    48 | loss: 54.1387236CurrentTrain: epoch  8, batch    49 | loss: 66.8051647CurrentTrain: epoch  8, batch    50 | loss: 59.9676069CurrentTrain: epoch  8, batch    51 | loss: 66.6636376CurrentTrain: epoch  8, batch    52 | loss: 76.6895202CurrentTrain: epoch  8, batch    53 | loss: 64.3979527CurrentTrain: epoch  8, batch    54 | loss: 91.3495152CurrentTrain: epoch  8, batch    55 | loss: 264.2950016CurrentTrain: epoch  8, batch    56 | loss: 77.7687784CurrentTrain: epoch  8, batch    57 | loss: 115.9114838CurrentTrain: epoch  8, batch    58 | loss: 76.2008763CurrentTrain: epoch  8, batch    59 | loss: 64.8565375CurrentTrain: epoch  8, batch    60 | loss: 80.4878050CurrentTrain: epoch  8, batch    61 | loss: 65.2157065CurrentTrain: epoch  8, batch    62 | loss: 78.2083676CurrentTrain: epoch  8, batch    63 | loss: 95.6437523CurrentTrain: epoch  8, batch    64 | loss: 77.8296907CurrentTrain: epoch  8, batch    65 | loss: 123.0076704CurrentTrain: epoch  8, batch    66 | loss: 81.8711989CurrentTrain: epoch  8, batch    67 | loss: 75.9232280CurrentTrain: epoch  8, batch    68 | loss: 123.7729656CurrentTrain: epoch  8, batch    69 | loss: 59.9429539CurrentTrain: epoch  8, batch    70 | loss: 125.6040758CurrentTrain: epoch  8, batch    71 | loss: 77.8089161CurrentTrain: epoch  8, batch    72 | loss: 61.8100124CurrentTrain: epoch  8, batch    73 | loss: 92.4869609CurrentTrain: epoch  8, batch    74 | loss: 81.5267608CurrentTrain: epoch  8, batch    75 | loss: 95.9206140CurrentTrain: epoch  8, batch    76 | loss: 65.4267927CurrentTrain: epoch  8, batch    77 | loss: 97.4000195CurrentTrain: epoch  8, batch    78 | loss: 168.3262909CurrentTrain: epoch  8, batch    79 | loss: 75.1340469CurrentTrain: epoch  8, batch    80 | loss: 124.0499465CurrentTrain: epoch  8, batch    81 | loss: 73.3347601CurrentTrain: epoch  8, batch    82 | loss: 66.9865810CurrentTrain: epoch  8, batch    83 | loss: 73.9861456CurrentTrain: epoch  8, batch    84 | loss: 96.9878818CurrentTrain: epoch  8, batch    85 | loss: 78.3786010CurrentTrain: epoch  8, batch    86 | loss: 124.2146005CurrentTrain: epoch  8, batch    87 | loss: 76.8899223CurrentTrain: epoch  8, batch    88 | loss: 70.4012176CurrentTrain: epoch  8, batch    89 | loss: 81.4444192CurrentTrain: epoch  8, batch    90 | loss: 96.1873973CurrentTrain: epoch  8, batch    91 | loss: 80.2294884CurrentTrain: epoch  8, batch    92 | loss: 77.7721006CurrentTrain: epoch  8, batch    93 | loss: 97.7633419CurrentTrain: epoch  8, batch    94 | loss: 79.6747231CurrentTrain: epoch  8, batch    95 | loss: 53.5626082CurrentTrain: epoch  9, batch     0 | loss: 77.0852124CurrentTrain: epoch  9, batch     1 | loss: 80.4420003CurrentTrain: epoch  9, batch     2 | loss: 97.3459706CurrentTrain: epoch  9, batch     3 | loss: 123.0990540CurrentTrain: epoch  9, batch     4 | loss: 66.3191077CurrentTrain: epoch  9, batch     5 | loss: 63.4336205CurrentTrain: epoch  9, batch     6 | loss: 64.5620127CurrentTrain: epoch  9, batch     7 | loss: 56.2825677CurrentTrain: epoch  9, batch     8 | loss: 63.1625688CurrentTrain: epoch  9, batch     9 | loss: 94.9490831CurrentTrain: epoch  9, batch    10 | loss: 93.5627736CurrentTrain: epoch  9, batch    11 | loss: 55.5705061CurrentTrain: epoch  9, batch    12 | loss: 98.4532205CurrentTrain: epoch  9, batch    13 | loss: 62.2677691CurrentTrain: epoch  9, batch    14 | loss: 76.0326755CurrentTrain: epoch  9, batch    15 | loss: 169.0706320CurrentTrain: epoch  9, batch    16 | loss: 68.5475631CurrentTrain: epoch  9, batch    17 | loss: 74.4764930CurrentTrain: epoch  9, batch    18 | loss: 62.3414365CurrentTrain: epoch  9, batch    19 | loss: 164.4181167CurrentTrain: epoch  9, batch    20 | loss: 66.8208482CurrentTrain: epoch  9, batch    21 | loss: 94.4009671CurrentTrain: epoch  9, batch    22 | loss: 58.5197024CurrentTrain: epoch  9, batch    23 | loss: 89.8447599CurrentTrain: epoch  9, batch    24 | loss: 76.9073982CurrentTrain: epoch  9, batch    25 | loss: 80.8525094CurrentTrain: epoch  9, batch    26 | loss: 66.1544020CurrentTrain: epoch  9, batch    27 | loss: 123.9814630CurrentTrain: epoch  9, batch    28 | loss: 74.7425728CurrentTrain: epoch  9, batch    29 | loss: 93.4520631CurrentTrain: epoch  9, batch    30 | loss: 77.5086523CurrentTrain: epoch  9, batch    31 | loss: 61.4788184CurrentTrain: epoch  9, batch    32 | loss: 99.9228627CurrentTrain: epoch  9, batch    33 | loss: 99.9141718CurrentTrain: epoch  9, batch    34 | loss: 72.3897430CurrentTrain: epoch  9, batch    35 | loss: 124.5011666CurrentTrain: epoch  9, batch    36 | loss: 61.4645445CurrentTrain: epoch  9, batch    37 | loss: 79.2561912CurrentTrain: epoch  9, batch    38 | loss: 67.9091273CurrentTrain: epoch  9, batch    39 | loss: 76.9654372CurrentTrain: epoch  9, batch    40 | loss: 91.2950694CurrentTrain: epoch  9, batch    41 | loss: 59.3805095CurrentTrain: epoch  9, batch    42 | loss: 92.4105096CurrentTrain: epoch  9, batch    43 | loss: 94.3773472CurrentTrain: epoch  9, batch    44 | loss: 122.9062459CurrentTrain: epoch  9, batch    45 | loss: 74.6463004CurrentTrain: epoch  9, batch    46 | loss: 81.2232041CurrentTrain: epoch  9, batch    47 | loss: 99.1992929CurrentTrain: epoch  9, batch    48 | loss: 126.1435116CurrentTrain: epoch  9, batch    49 | loss: 75.5838743CurrentTrain: epoch  9, batch    50 | loss: 79.1468290CurrentTrain: epoch  9, batch    51 | loss: 57.0197061CurrentTrain: epoch  9, batch    52 | loss: 64.6093497CurrentTrain: epoch  9, batch    53 | loss: 67.6106404CurrentTrain: epoch  9, batch    54 | loss: 98.2121024CurrentTrain: epoch  9, batch    55 | loss: 57.6617724CurrentTrain: epoch  9, batch    56 | loss: 96.6613627CurrentTrain: epoch  9, batch    57 | loss: 62.1098901CurrentTrain: epoch  9, batch    58 | loss: 69.0216145CurrentTrain: epoch  9, batch    59 | loss: 90.1501823CurrentTrain: epoch  9, batch    60 | loss: 62.2961590CurrentTrain: epoch  9, batch    61 | loss: 75.2286801CurrentTrain: epoch  9, batch    62 | loss: 75.1537482CurrentTrain: epoch  9, batch    63 | loss: 74.7038702CurrentTrain: epoch  9, batch    64 | loss: 64.3997302CurrentTrain: epoch  9, batch    65 | loss: 53.7453494CurrentTrain: epoch  9, batch    66 | loss: 92.0887409CurrentTrain: epoch  9, batch    67 | loss: 75.5517476CurrentTrain: epoch  9, batch    68 | loss: 78.6214321CurrentTrain: epoch  9, batch    69 | loss: 77.0216831CurrentTrain: epoch  9, batch    70 | loss: 66.1161781CurrentTrain: epoch  9, batch    71 | loss: 124.7558934CurrentTrain: epoch  9, batch    72 | loss: 120.9707890CurrentTrain: epoch  9, batch    73 | loss: 95.8885162CurrentTrain: epoch  9, batch    74 | loss: 77.0217739CurrentTrain: epoch  9, batch    75 | loss: 90.0076520CurrentTrain: epoch  9, batch    76 | loss: 76.7846850CurrentTrain: epoch  9, batch    77 | loss: 57.9256089CurrentTrain: epoch  9, batch    78 | loss: 75.6440973CurrentTrain: epoch  9, batch    79 | loss: 67.9447523CurrentTrain: epoch  9, batch    80 | loss: 77.2173155CurrentTrain: epoch  9, batch    81 | loss: 65.1971056CurrentTrain: epoch  9, batch    82 | loss: 69.2767458CurrentTrain: epoch  9, batch    83 | loss: 75.9492562CurrentTrain: epoch  9, batch    84 | loss: 95.5158769CurrentTrain: epoch  9, batch    85 | loss: 101.7305398CurrentTrain: epoch  9, batch    86 | loss: 66.2817656CurrentTrain: epoch  9, batch    87 | loss: 64.8491549CurrentTrain: epoch  9, batch    88 | loss: 94.7519903CurrentTrain: epoch  9, batch    89 | loss: 78.2243146CurrentTrain: epoch  9, batch    90 | loss: 80.5225312CurrentTrain: epoch  9, batch    91 | loss: 64.5785940CurrentTrain: epoch  9, batch    92 | loss: 78.2174178CurrentTrain: epoch  9, batch    93 | loss: 78.6828375CurrentTrain: epoch  9, batch    94 | loss: 78.7596507CurrentTrain: epoch  9, batch    95 | loss: 81.9864184

F1 score per class: {32: np.float64(0.5863874345549738), 6: np.float64(0.8110599078341014), 19: np.float64(0.3888888888888889), 24: np.float64(0.73224043715847), 26: np.float64(0.9333333333333333), 29: np.float64(0.8557692307692307)}
Micro-average F1 score: 0.7728155339805826
Weighted-average F1 score: 0.7756268860058381
F1 score per class: {32: np.float64(0.6454545454545455), 6: np.float64(0.7876106194690266), 19: np.float64(0.2692307692307692), 24: np.float64(0.7351351351351352), 26: np.float64(0.9458128078817734), 29: np.float64(0.8269230769230769)}
Micro-average F1 score: 0.7623400365630713
Weighted-average F1 score: 0.7553128952560597
F1 score per class: {32: np.float64(0.6572769953051644), 6: np.float64(0.7892376681614349), 19: np.float64(0.30434782608695654), 24: np.float64(0.7391304347826086), 26: np.float64(0.9504950495049505), 29: np.float64(0.8325358851674641)}
Micro-average F1 score: 0.7725162488393686
Weighted-average F1 score: 0.7686120498001298

F1 score per class: {32: np.float64(0.5863874345549738), 6: np.float64(0.8110599078341014), 19: np.float64(0.3888888888888889), 24: np.float64(0.73224043715847), 26: np.float64(0.9333333333333333), 29: np.float64(0.8557692307692307)}
Micro-average F1 score: 0.7728155339805826
Weighted-average F1 score: 0.7756268860058381
F1 score per class: {32: np.float64(0.6454545454545455), 6: np.float64(0.7876106194690266), 19: np.float64(0.2692307692307692), 24: np.float64(0.7351351351351352), 26: np.float64(0.9458128078817734), 29: np.float64(0.8269230769230769)}
Micro-average F1 score: 0.7623400365630713
Weighted-average F1 score: 0.7553128952560597
F1 score per class: {32: np.float64(0.6572769953051644), 6: np.float64(0.7892376681614349), 19: np.float64(0.30434782608695654), 24: np.float64(0.7391304347826086), 26: np.float64(0.9504950495049505), 29: np.float64(0.8325358851674641)}
Micro-average F1 score: 0.7725162488393686
Weighted-average F1 score: 0.7686120498001298

F1 score per class: {32: np.float64(0.4426877470355731), 6: np.float64(0.7457627118644068), 19: np.float64(0.208955223880597), 24: np.float64(0.6767676767676768), 26: np.float64(0.8625592417061612), 29: np.float64(0.6793893129770993)}
Micro-average F1 score: 0.6487367563162184
Weighted-average F1 score: 0.6368436346051588
F1 score per class: {32: np.float64(0.44654088050314467), 6: np.float64(0.714859437751004), 19: np.float64(0.1414141414141414), 24: np.float64(0.6766169154228856), 26: np.float64(0.8571428571428571), 29: np.float64(0.6564885496183206)}
Micro-average F1 score: 0.6164079822616408
Weighted-average F1 score: 0.594358899893083
F1 score per class: {32: np.float64(0.45454545454545453), 6: np.float64(0.7154471544715447), 19: np.float64(0.16279069767441862), 24: np.float64(0.6834170854271356), 26: np.float64(0.8687782805429864), 29: np.float64(0.6615969581749049)}
Micro-average F1 score: 0.6288737717309146
Weighted-average F1 score: 0.6095543777958481

F1 score per class: {32: np.float64(0.4426877470355731), 6: np.float64(0.7457627118644068), 19: np.float64(0.208955223880597), 24: np.float64(0.6767676767676768), 26: np.float64(0.8625592417061612), 29: np.float64(0.6793893129770993)}
Micro-average F1 score: 0.6487367563162184
Weighted-average F1 score: 0.6368436346051588
F1 score per class: {32: np.float64(0.44654088050314467), 6: np.float64(0.714859437751004), 19: np.float64(0.1414141414141414), 24: np.float64(0.6766169154228856), 26: np.float64(0.8571428571428571), 29: np.float64(0.6564885496183206)}
Micro-average F1 score: 0.6164079822616408
Weighted-average F1 score: 0.594358899893083
F1 score per class: {32: np.float64(0.45454545454545453), 6: np.float64(0.7154471544715447), 19: np.float64(0.16279069767441862), 24: np.float64(0.6834170854271356), 26: np.float64(0.8687782805429864), 29: np.float64(0.6615969581749049)}
Micro-average F1 score: 0.6288737717309146
Weighted-average F1 score: 0.6095543777958481
cur_acc_wo_na:  ['0.7728']
his_acc_wo_na:  ['0.7728']
cur_acc des_wo_na:  ['0.7623']
his_acc des_wo_na:  ['0.7623']
cur_acc rrf_wo_na:  ['0.7725']
his_acc rrf_wo_na:  ['0.7725']
cur_acc_w_na:  ['0.6487']
his_acc_w_na:  ['0.6487']
cur_acc des_w_na:  ['0.6164']
his_acc des_w_na:  ['0.6164']
cur_acc rrf_w_na:  ['0.6289']
his_acc rrf_w_na:  ['0.6289']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 81.5856491CurrentTrain: epoch  0, batch     1 | loss: 147.2237665CurrentTrain: epoch  0, batch     2 | loss: 76.1059019CurrentTrain: epoch  0, batch     3 | loss: 11.6010411CurrentTrain: epoch  1, batch     0 | loss: 85.5341336CurrentTrain: epoch  1, batch     1 | loss: 84.2078159CurrentTrain: epoch  1, batch     2 | loss: 84.6676626CurrentTrain: epoch  1, batch     3 | loss: 13.4411455CurrentTrain: epoch  2, batch     0 | loss: 70.9922250CurrentTrain: epoch  2, batch     1 | loss: 80.6100231CurrentTrain: epoch  2, batch     2 | loss: 70.4745949CurrentTrain: epoch  2, batch     3 | loss: 10.2044115CurrentTrain: epoch  3, batch     0 | loss: 80.1995025CurrentTrain: epoch  3, batch     1 | loss: 84.9037006CurrentTrain: epoch  3, batch     2 | loss: 66.0714666CurrentTrain: epoch  3, batch     3 | loss: 20.9149594CurrentTrain: epoch  4, batch     0 | loss: 80.2535857CurrentTrain: epoch  4, batch     1 | loss: 77.7280495CurrentTrain: epoch  4, batch     2 | loss: 76.2046807CurrentTrain: epoch  4, batch     3 | loss: 17.3735488CurrentTrain: epoch  5, batch     0 | loss: 78.1320178CurrentTrain: epoch  5, batch     1 | loss: 64.6021605CurrentTrain: epoch  5, batch     2 | loss: 66.7335484CurrentTrain: epoch  5, batch     3 | loss: 10.1422781CurrentTrain: epoch  6, batch     0 | loss: 65.5435284CurrentTrain: epoch  6, batch     1 | loss: 62.8941432CurrentTrain: epoch  6, batch     2 | loss: 64.8385363CurrentTrain: epoch  6, batch     3 | loss: 16.9924250CurrentTrain: epoch  7, batch     0 | loss: 64.5547044CurrentTrain: epoch  7, batch     1 | loss: 74.3654634CurrentTrain: epoch  7, batch     2 | loss: 89.7813018CurrentTrain: epoch  7, batch     3 | loss: 18.9353800CurrentTrain: epoch  8, batch     0 | loss: 60.2014719CurrentTrain: epoch  8, batch     1 | loss: 119.0248850CurrentTrain: epoch  8, batch     2 | loss: 62.8725322CurrentTrain: epoch  8, batch     3 | loss: 9.1495264CurrentTrain: epoch  9, batch     0 | loss: 62.1465495CurrentTrain: epoch  9, batch     1 | loss: 61.8419775CurrentTrain: epoch  9, batch     2 | loss: 75.9243996CurrentTrain: epoch  9, batch     3 | loss: 5.3758349
MemoryTrain:  epoch  0, batch     0 | loss: 2.0649315MemoryTrain:  epoch  1, batch     0 | loss: 1.7857307MemoryTrain:  epoch  2, batch     0 | loss: 1.5710160MemoryTrain:  epoch  3, batch     0 | loss: 1.2446909MemoryTrain:  epoch  4, batch     0 | loss: 1.0677678MemoryTrain:  epoch  5, batch     0 | loss: 0.9280540MemoryTrain:  epoch  6, batch     0 | loss: 0.7073557MemoryTrain:  epoch  7, batch     0 | loss: 0.5827032MemoryTrain:  epoch  8, batch     0 | loss: 0.5149342MemoryTrain:  epoch  9, batch     0 | loss: 0.4559930

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6666666666666666), 7: np.float64(0.7741935483870968), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.5), 26: np.float64(0.0), 27: np.float64(0.5), 29: np.float64(0.0), 31: np.float64(0.14754098360655737)}
Micro-average F1 score: 0.2828282828282828
Weighted-average F1 score: 0.23499916679429644
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6666666666666666), 7: np.float64(0.684931506849315), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.5714285714285714), 26: np.float64(0.0), 27: np.float64(0.8), 29: np.float64(0.0), 31: np.float64(0.21978021978021978)}
Micro-average F1 score: 0.3205574912891986
Weighted-average F1 score: 0.2710105266760584
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.6666666666666666), 7: np.float64(0.746268656716418), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.47619047619047616), 26: np.float64(0.0), 27: np.float64(0.5), 29: np.float64(0.0), 31: np.float64(0.20618556701030927)}
Micro-average F1 score: 0.30985915492957744
Weighted-average F1 score: 0.2591328637933093

F1 score per class: {32: np.float64(0.42105263157894735), 6: np.float64(0.05), 7: np.float64(0.7741935483870968), 40: np.float64(0.6148409893992933), 9: np.float64(0.2962962962962963), 19: np.float64(0.6987951807228916), 24: np.float64(0.3448275862068966), 26: np.float64(0.93), 27: np.float64(0.2857142857142857), 29: np.float64(0.8269230769230769), 31: np.float64(0.06896551724137931)}
Micro-average F1 score: 0.5306930693069307
Weighted-average F1 score: 0.4749519866156842
F1 score per class: {32: np.float64(0.45751633986928103), 6: np.float64(0.06818181818181818), 7: np.float64(0.6329113924050633), 40: np.float64(0.5641025641025641), 9: np.float64(0.20833333333333334), 19: np.float64(0.723404255319149), 24: np.float64(0.375), 26: np.float64(0.9313725490196079), 27: np.float64(0.4), 29: np.float64(0.7960199004975125), 31: np.float64(0.13333333333333333)}
Micro-average F1 score: 0.5692832764505119
Weighted-average F1 score: 0.5419809929880927
F1 score per class: {32: np.float64(0.46153846153846156), 6: np.float64(0.06976744186046512), 7: np.float64(0.746268656716418), 40: np.float64(0.5686274509803921), 9: np.float64(0.2222222222222222), 19: np.float64(0.7351351351351352), 24: np.float64(0.30303030303030304), 26: np.float64(0.9405940594059405), 27: np.float64(0.25), 29: np.float64(0.7960199004975125), 31: np.float64(0.11627906976744186)}
Micro-average F1 score: 0.5702479338842975
Weighted-average F1 score: 0.5386711052155446

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.7272727272727273), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.45454545454545453), 26: np.float64(0.0), 27: np.float64(0.5), 29: np.float64(0.0), 31: np.float64(0.11920529801324503)}
Micro-average F1 score: 0.2420749279538905
Weighted-average F1 score: 0.2041882314030795
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.6024096385542169), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.5217391304347826), 26: np.float64(0.0), 27: np.float64(0.6666666666666666), 29: np.float64(0.0), 31: np.float64(0.20408163265306123)}
Micro-average F1 score: 0.2822085889570552
Weighted-average F1 score: 0.24454649220847496
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.6944444444444444), 40: np.float64(0.0), 9: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.4166666666666667), 26: np.float64(0.0), 27: np.float64(0.4), 29: np.float64(0.0), 31: np.float64(0.18181818181818182)}
Micro-average F1 score: 0.2724458204334365
Weighted-average F1 score: 0.2337997196848872

F1 score per class: {32: np.float64(0.3004694835680751), 6: np.float64(0.03), 7: np.float64(0.7272727272727273), 40: np.float64(0.5780730897009967), 9: np.float64(0.24242424242424243), 19: np.float64(0.651685393258427), 24: np.float64(0.25), 26: np.float64(0.8532110091743119), 27: np.float64(0.2), 29: np.float64(0.6417910447761194), 31: np.float64(0.05142857142857143)}
Micro-average F1 score: 0.42834310069259457
Weighted-average F1 score: 0.37823865688541114
F1 score per class: {32: np.float64(0.32710280373831774), 6: np.float64(0.041379310344827586), 7: np.float64(0.5263157894736842), 40: np.float64(0.5176470588235295), 9: np.float64(0.13157894736842105), 19: np.float64(0.6666666666666666), 24: np.float64(0.27906976744186046), 26: np.float64(0.8482142857142857), 27: np.float64(0.2857142857142857), 29: np.float64(0.6274509803921569), 31: np.float64(0.11494252873563218)}
Micro-average F1 score: 0.4674887892376682
Weighted-average F1 score: 0.44011880627919897
F1 score per class: {32: np.float64(0.3287671232876712), 6: np.float64(0.04054054054054054), 7: np.float64(0.6944444444444444), 40: np.float64(0.5240963855421686), 9: np.float64(0.14285714285714285), 19: np.float64(0.6868686868686869), 24: np.float64(0.21739130434782608), 26: np.float64(0.8597285067873304), 27: np.float64(0.18181818181818182), 29: np.float64(0.625), 31: np.float64(0.09523809523809523)}
Micro-average F1 score: 0.46806105144149235
Weighted-average F1 score: 0.43540750142953283
cur_acc_wo_na:  ['0.7728', '0.2828']
his_acc_wo_na:  ['0.7728', '0.5307']
cur_acc des_wo_na:  ['0.7623', '0.3206']
his_acc des_wo_na:  ['0.7623', '0.5693']
cur_acc rrf_wo_na:  ['0.7725', '0.3099']
his_acc rrf_wo_na:  ['0.7725', '0.5702']
cur_acc_w_na:  ['0.6487', '0.2421']
his_acc_w_na:  ['0.6487', '0.4283']
cur_acc des_w_na:  ['0.6164', '0.2822']
his_acc des_w_na:  ['0.6164', '0.4675']
cur_acc rrf_w_na:  ['0.6289', '0.2724']
his_acc rrf_w_na:  ['0.6289', '0.4681']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 102.7746472CurrentTrain: epoch  0, batch     1 | loss: 105.0296548CurrentTrain: epoch  0, batch     2 | loss: 89.9359197CurrentTrain: epoch  0, batch     3 | loss: 94.6708918CurrentTrain: epoch  1, batch     0 | loss: 82.7006263CurrentTrain: epoch  1, batch     1 | loss: 107.5189459CurrentTrain: epoch  1, batch     2 | loss: 78.6241322CurrentTrain: epoch  1, batch     3 | loss: 144.8749440CurrentTrain: epoch  2, batch     0 | loss: 92.7081550CurrentTrain: epoch  2, batch     1 | loss: 130.1218237CurrentTrain: epoch  2, batch     2 | loss: 87.5892218CurrentTrain: epoch  2, batch     3 | loss: 67.9415290CurrentTrain: epoch  3, batch     0 | loss: 72.1504992CurrentTrain: epoch  3, batch     1 | loss: 133.5849266CurrentTrain: epoch  3, batch     2 | loss: 72.7161493CurrentTrain: epoch  3, batch     3 | loss: 58.7663182CurrentTrain: epoch  4, batch     0 | loss: 84.3045051CurrentTrain: epoch  4, batch     1 | loss: 86.0771533CurrentTrain: epoch  4, batch     2 | loss: 70.1628848CurrentTrain: epoch  4, batch     3 | loss: 84.8848620CurrentTrain: epoch  5, batch     0 | loss: 83.1548058CurrentTrain: epoch  5, batch     1 | loss: 78.8296307CurrentTrain: epoch  5, batch     2 | loss: 84.0753760CurrentTrain: epoch  5, batch     3 | loss: 78.5492352CurrentTrain: epoch  6, batch     0 | loss: 82.4617330CurrentTrain: epoch  6, batch     1 | loss: 95.6940065CurrentTrain: epoch  6, batch     2 | loss: 96.6160919CurrentTrain: epoch  6, batch     3 | loss: 65.0513989CurrentTrain: epoch  7, batch     0 | loss: 67.8747400CurrentTrain: epoch  7, batch     1 | loss: 97.8754174CurrentTrain: epoch  7, batch     2 | loss: 82.6911467CurrentTrain: epoch  7, batch     3 | loss: 61.2291611CurrentTrain: epoch  8, batch     0 | loss: 64.5184940CurrentTrain: epoch  8, batch     1 | loss: 95.5438501CurrentTrain: epoch  8, batch     2 | loss: 100.8545556CurrentTrain: epoch  8, batch     3 | loss: 77.0844660CurrentTrain: epoch  9, batch     0 | loss: 75.8314949CurrentTrain: epoch  9, batch     1 | loss: 120.9989522CurrentTrain: epoch  9, batch     2 | loss: 95.7234626CurrentTrain: epoch  9, batch     3 | loss: 53.6819602
MemoryTrain:  epoch  0, batch     0 | loss: 1.5700641MemoryTrain:  epoch  1, batch     0 | loss: 1.3319463MemoryTrain:  epoch  2, batch     0 | loss: 1.1134876MemoryTrain:  epoch  3, batch     0 | loss: 0.8954843MemoryTrain:  epoch  4, batch     0 | loss: 0.7079513MemoryTrain:  epoch  5, batch     0 | loss: 0.6240854MemoryTrain:  epoch  6, batch     0 | loss: 0.5046951MemoryTrain:  epoch  7, batch     0 | loss: 0.4019918MemoryTrain:  epoch  8, batch     0 | loss: 0.3980838MemoryTrain:  epoch  9, batch     0 | loss: 0.3535652

F1 score per class: {0: np.float64(0.9), 32: np.float64(0.9368421052631579), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.1), 40: np.float64(0.0), 13: np.float64(0.42990654205607476), 19: np.float64(0.7710843373493976), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.6408450704225352
Weighted-average F1 score: 0.5372061000417362
F1 score per class: {0: np.float64(0.7346938775510204), 32: np.float64(0.9543147208121827), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.14285714285714285), 9: np.float64(0.0), 13: np.float64(0.5681818181818182), 19: np.float64(0.6585365853658537), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.6184873949579832
Weighted-average F1 score: 0.5229485676247381
F1 score per class: {0: np.float64(0.7912087912087912), 32: np.float64(0.9533678756476683), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.14285714285714285), 9: np.float64(0.0), 13: np.float64(0.5434782608695652), 19: np.float64(0.6585365853658537), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.6286701208981001
Weighted-average F1 score: 0.5316856708832047

F1 score per class: {32: np.float64(0.6153846153846154), 0: np.float64(0.9368421052631579), 4: np.float64(0.4782608695652174), 6: np.float64(0.07692307692307693), 7: np.float64(0.78125), 40: np.float64(0.047058823529411764), 9: np.float64(0.6234817813765182), 13: np.float64(0.19491525423728814), 19: np.float64(0.735632183908046), 21: np.float64(0.08695652173913043), 23: np.float64(0.7126436781609196), 24: np.float64(0.35714285714285715), 26: np.float64(0.9178743961352657), 27: np.float64(0.5), 29: np.float64(0.7510917030567685), 31: np.float64(0.2233502538071066)}
Micro-average F1 score: 0.5609302325581396
Weighted-average F1 score: 0.5063682042023446
F1 score per class: {32: np.float64(0.46153846153846156), 0: np.float64(0.9543147208121827), 4: np.float64(0.46511627906976744), 6: np.float64(0.08), 7: np.float64(0.6172839506172839), 40: np.float64(0.07407407407407407), 9: np.float64(0.55625), 13: np.float64(0.30120481927710846), 19: np.float64(0.6067415730337079), 21: np.float64(0.06896551724137931), 23: np.float64(0.6766169154228856), 24: np.float64(0.29411764705882354), 26: np.float64(0.8826291079812206), 27: np.float64(0.4444444444444444), 29: np.float64(0.7381974248927039), 31: np.float64(0.15384615384615385)}
Micro-average F1 score: 0.5533244087460955
Weighted-average F1 score: 0.5216136354327355
F1 score per class: {32: np.float64(0.5217391304347826), 0: np.float64(0.9533678756476683), 4: np.float64(0.49038461538461536), 6: np.float64(0.08823529411764706), 7: np.float64(0.7575757575757576), 40: np.float64(0.06666666666666667), 9: np.float64(0.6095890410958904), 13: np.float64(0.2702702702702703), 19: np.float64(0.6206896551724138), 21: np.float64(0.07142857142857142), 23: np.float64(0.6903553299492385), 24: np.float64(0.3448275862068966), 26: np.float64(0.892018779342723), 27: np.float64(0.2857142857142857), 29: np.float64(0.74235807860262), 31: np.float64(0.14130434782608695)}
Micro-average F1 score: 0.5659340659340659
Weighted-average F1 score: 0.5292172758027462

F1 score per class: {0: np.float64(0.8674698795180723), 32: np.float64(0.8855721393034826), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.043478260869565216), 40: np.float64(0.0), 13: np.float64(0.323943661971831), 19: np.float64(0.6808510638297872), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.4795783926218709
Weighted-average F1 score: 0.373073758259756
F1 score per class: {0: np.float64(0.6666666666666666), 32: np.float64(0.8909952606635071), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.06349206349206349), 9: np.float64(0.0), 13: np.float64(0.423728813559322), 19: np.float64(0.5806451612903226), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.4628930817610063
Weighted-average F1 score: 0.37128770634528374
F1 score per class: {0: np.float64(0.7272727272727273), 32: np.float64(0.8932038834951457), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.06153846153846154), 9: np.float64(0.0), 13: np.float64(0.4065040650406504), 19: np.float64(0.574468085106383), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0)}
Micro-average F1 score: 0.4702842377260982
Weighted-average F1 score: 0.37520072638527446

F1 score per class: {32: np.float64(0.48322147651006714), 0: np.float64(0.8811881188118812), 4: np.float64(0.31316725978647686), 6: np.float64(0.05217391304347826), 7: np.float64(0.7246376811594203), 40: np.float64(0.018604651162790697), 9: np.float64(0.5811320754716981), 13: np.float64(0.12534059945504086), 19: np.float64(0.64), 21: np.float64(0.07407407407407407), 23: np.float64(0.656084656084656), 24: np.float64(0.23809523809523808), 26: np.float64(0.8154506437768241), 27: np.float64(0.3333333333333333), 29: np.float64(0.5276073619631901), 31: np.float64(0.19130434782608696)}
Micro-average F1 score: 0.42826704545454547
Weighted-average F1 score: 0.37647343631260705
F1 score per class: {32: np.float64(0.3333333333333333), 0: np.float64(0.8867924528301887), 4: np.float64(0.2958579881656805), 6: np.float64(0.048), 7: np.float64(0.5154639175257731), 40: np.float64(0.030534351145038167), 9: np.float64(0.5), 13: np.float64(0.18796992481203006), 19: np.float64(0.5294117647058824), 21: np.float64(0.05555555555555555), 23: np.float64(0.6181818181818182), 24: np.float64(0.2), 26: np.float64(0.7673469387755102), 27: np.float64(0.26666666666666666), 29: np.float64(0.5227963525835866), 31: np.float64(0.12380952380952381)}
Micro-average F1 score: 0.4206241519674355
Weighted-average F1 score: 0.38717203074373213
F1 score per class: {32: np.float64(0.3829787234042553), 0: np.float64(0.8888888888888888), 4: np.float64(0.3157894736842105), 6: np.float64(0.05217391304347826), 7: np.float64(0.704225352112676), 40: np.float64(0.026845637583892617), 9: np.float64(0.5545171339563862), 13: np.float64(0.17301038062283736), 19: np.float64(0.5294117647058824), 21: np.float64(0.058823529411764705), 23: np.float64(0.6384976525821596), 24: np.float64(0.2222222222222222), 26: np.float64(0.7786885245901639), 27: np.float64(0.18181818181818182), 29: np.float64(0.5279503105590062), 31: np.float64(0.11304347826086956)}
Micro-average F1 score: 0.43156424581005587
Weighted-average F1 score: 0.39286662617084195
cur_acc_wo_na:  ['0.7728', '0.2828', '0.6408']
his_acc_wo_na:  ['0.7728', '0.5307', '0.5609']
cur_acc des_wo_na:  ['0.7623', '0.3206', '0.6185']
his_acc des_wo_na:  ['0.7623', '0.5693', '0.5533']
cur_acc rrf_wo_na:  ['0.7725', '0.3099', '0.6287']
his_acc rrf_wo_na:  ['0.7725', '0.5702', '0.5659']
cur_acc_w_na:  ['0.6487', '0.2421', '0.4796']
his_acc_w_na:  ['0.6487', '0.4283', '0.4283']
cur_acc des_w_na:  ['0.6164', '0.2822', '0.4629']
his_acc des_w_na:  ['0.6164', '0.4675', '0.4206']
cur_acc rrf_w_na:  ['0.6289', '0.2724', '0.4703']
his_acc rrf_w_na:  ['0.6289', '0.4681', '0.4316']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 112.7129392CurrentTrain: epoch  0, batch     1 | loss: 117.0825078CurrentTrain: epoch  0, batch     2 | loss: 144.2270550CurrentTrain: epoch  0, batch     3 | loss: 139.5631180CurrentTrain: epoch  0, batch     4 | loss: 52.0785346CurrentTrain: epoch  1, batch     0 | loss: 113.9225492CurrentTrain: epoch  1, batch     1 | loss: 134.5539963CurrentTrain: epoch  1, batch     2 | loss: 92.8099752CurrentTrain: epoch  1, batch     3 | loss: 86.8181786CurrentTrain: epoch  1, batch     4 | loss: 82.0560919CurrentTrain: epoch  2, batch     0 | loss: 135.4454473CurrentTrain: epoch  2, batch     1 | loss: 84.5203872CurrentTrain: epoch  2, batch     2 | loss: 85.9842319CurrentTrain: epoch  2, batch     3 | loss: 86.3636723CurrentTrain: epoch  2, batch     4 | loss: 64.3815660CurrentTrain: epoch  3, batch     0 | loss: 83.3545918CurrentTrain: epoch  3, batch     1 | loss: 81.1143107CurrentTrain: epoch  3, batch     2 | loss: 134.7109803CurrentTrain: epoch  3, batch     3 | loss: 80.3486725CurrentTrain: epoch  3, batch     4 | loss: 117.2543926CurrentTrain: epoch  4, batch     0 | loss: 128.1124941CurrentTrain: epoch  4, batch     1 | loss: 81.0576579CurrentTrain: epoch  4, batch     2 | loss: 98.2600977CurrentTrain: epoch  4, batch     3 | loss: 129.9208249CurrentTrain: epoch  4, batch     4 | loss: 62.1369118CurrentTrain: epoch  5, batch     0 | loss: 104.0747934CurrentTrain: epoch  5, batch     1 | loss: 96.5523365CurrentTrain: epoch  5, batch     2 | loss: 95.0591122CurrentTrain: epoch  5, batch     3 | loss: 99.2847565CurrentTrain: epoch  5, batch     4 | loss: 106.1529525CurrentTrain: epoch  6, batch     0 | loss: 78.0778987CurrentTrain: epoch  6, batch     1 | loss: 100.5426689CurrentTrain: epoch  6, batch     2 | loss: 124.6658304CurrentTrain: epoch  6, batch     3 | loss: 78.6596830CurrentTrain: epoch  6, batch     4 | loss: 60.8399524CurrentTrain: epoch  7, batch     0 | loss: 82.5764852CurrentTrain: epoch  7, batch     1 | loss: 65.8902763CurrentTrain: epoch  7, batch     2 | loss: 81.7691493CurrentTrain: epoch  7, batch     3 | loss: 80.9233475CurrentTrain: epoch  7, batch     4 | loss: 59.2360825CurrentTrain: epoch  8, batch     0 | loss: 123.5379194CurrentTrain: epoch  8, batch     1 | loss: 91.4563480CurrentTrain: epoch  8, batch     2 | loss: 79.6324452CurrentTrain: epoch  8, batch     3 | loss: 65.0771792CurrentTrain: epoch  8, batch     4 | loss: 107.0653438CurrentTrain: epoch  9, batch     0 | loss: 94.6549283CurrentTrain: epoch  9, batch     1 | loss: 167.0749853CurrentTrain: epoch  9, batch     2 | loss: 73.5420033CurrentTrain: epoch  9, batch     3 | loss: 93.7412294CurrentTrain: epoch  9, batch     4 | loss: 47.6980105
MemoryTrain:  epoch  0, batch     0 | loss: 1.0190907MemoryTrain:  epoch  1, batch     0 | loss: 0.8805809MemoryTrain:  epoch  2, batch     0 | loss: 0.6672761MemoryTrain:  epoch  3, batch     0 | loss: 0.5799651MemoryTrain:  epoch  4, batch     0 | loss: 0.4677956MemoryTrain:  epoch  5, batch     0 | loss: 0.4024448MemoryTrain:  epoch  6, batch     0 | loss: 0.3292734MemoryTrain:  epoch  7, batch     0 | loss: 0.2663941MemoryTrain:  epoch  8, batch     0 | loss: 0.2456737MemoryTrain:  epoch  9, batch     0 | loss: 0.2020081

F1 score per class: {0: np.float64(0.0), 32: np.float64(0.8679245283018868), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.4), 40: np.float64(0.0), 10: np.float64(0.7037037037037037), 13: np.float64(0.0), 16: np.float64(0.375), 17: np.float64(0.0), 18: np.float64(0.0), 23: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5736738703339882
Weighted-average F1 score: 0.5588902835137347
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.7364341085271318), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.4), 13: np.float64(0.0), 16: np.float64(0.6774193548387096), 17: np.float64(0.5), 18: np.float64(0.5365853658536586), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.5318471337579618
Weighted-average F1 score: 0.4990919033111936
F1 score per class: {0: np.float64(0.0), 32: np.float64(0.7630522088353414), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.3875968992248062), 10: np.float64(0.0), 9: np.float64(0.711864406779661), 13: np.float64(0.36363636363636365), 16: np.float64(0.5), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5498281786941581
Weighted-average F1 score: 0.5287791820845363

F1 score per class: {0: np.float64(0.660377358490566), 4: np.float64(0.8571428571428571), 5: np.float64(0.8518518518518519), 6: np.float64(0.49214659685863876), 7: np.float64(0.06896551724137931), 9: np.float64(0.7142857142857143), 10: np.float64(0.3586206896551724), 13: np.float64(0.12903225806451613), 16: np.float64(0.6229508196721312), 17: np.float64(0.0), 18: np.float64(0.36), 19: np.float64(0.6215139442231076), 21: np.float64(0.36363636363636365), 23: np.float64(0.7551020408163265), 24: np.float64(0.0), 26: np.float64(0.6707317073170732), 27: np.float64(0.32653061224489793), 29: np.float64(0.8811881188118812), 31: np.float64(0.0), 32: np.float64(0.7870370370370371), 40: np.float64(0.17592592592592593)}
Micro-average F1 score: 0.5901505901505901
Weighted-average F1 score: 0.5711079242247735
F1 score per class: {0: np.float64(0.5142857142857142), 4: np.float64(0.9430051813471503), 5: np.float64(0.6643356643356644), 6: np.float64(0.4607329842931937), 7: np.float64(0.0784313725490196), 9: np.float64(0.5617977528089888), 10: np.float64(0.36879432624113473), 13: np.float64(0.1111111111111111), 16: np.float64(0.5833333333333334), 17: np.float64(0.24), 18: np.float64(0.4583333333333333), 19: np.float64(0.5141065830721003), 21: np.float64(0.24489795918367346), 23: np.float64(0.6458333333333334), 24: np.float64(0.07692307692307693), 26: np.float64(0.680628272251309), 27: np.float64(0.3018867924528302), 29: np.float64(0.8571428571428571), 31: np.float64(0.2222222222222222), 32: np.float64(0.730593607305936), 40: np.float64(0.16326530612244897)}
Micro-average F1 score: 0.5424210152644657
Weighted-average F1 score: 0.521055690526461
F1 score per class: {0: np.float64(0.5950413223140496), 4: np.float64(0.93048128342246), 5: np.float64(0.7037037037037037), 6: np.float64(0.47368421052631576), 7: np.float64(0.07407407407407407), 9: np.float64(0.6578947368421053), 10: np.float64(0.3546099290780142), 13: np.float64(0.1), 16: np.float64(0.6176470588235294), 17: np.float64(0.2), 18: np.float64(0.4533333333333333), 19: np.float64(0.5765124555160143), 21: np.float64(0.24468085106382978), 23: np.float64(0.6736842105263158), 24: np.float64(0.08), 26: np.float64(0.6629213483146067), 27: np.float64(0.3076923076923077), 29: np.float64(0.875), 31: np.float64(0.2857142857142857), 32: np.float64(0.7511737089201878), 40: np.float64(0.14746543778801843)}
Micro-average F1 score: 0.5569620253164557
Weighted-average F1 score: 0.5332535852896125

F1 score per class: {32: np.float64(0.0), 0: np.float64(0.0), 4: np.float64(0.7479674796747967), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 40: np.float64(0.34210526315789475), 10: np.float64(0.0), 9: np.float64(0.4691358024691358), 13: np.float64(0.0), 16: np.float64(0.225), 17: np.float64(0.0), 18: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.42627737226277373
Weighted-average F1 score: 0.3926495150187207
F1 score per class: {0: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.5588235294117647), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.33121019108280253), 13: np.float64(0.0), 16: np.float64(0.44680851063829785), 17: np.float64(0.3), 18: np.float64(0.2953020134228188), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3595263724434876
Weighted-average F1 score: 0.33379203389701384
F1 score per class: {0: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.5792682926829268), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.32051282051282054), 13: np.float64(0.0), 16: np.float64(0.46153846153846156), 17: np.float64(0.21052631578947367), 18: np.float64(0.2833333333333333), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3755868544600939
Weighted-average F1 score: 0.35381539003269585

F1 score per class: {0: np.float64(0.5072463768115942), 4: np.float64(0.8064516129032258), 5: np.float64(0.7330677290836654), 6: np.float64(0.3333333333333333), 7: np.float64(0.045454545454545456), 9: np.float64(0.6578947368421053), 10: np.float64(0.2826086956521739), 13: np.float64(0.08), 16: np.float64(0.3838383838383838), 17: np.float64(0.0), 18: np.float64(0.21428571428571427), 19: np.float64(0.5672727272727273), 21: np.float64(0.23529411764705882), 23: np.float64(0.6666666666666666), 24: np.float64(0.0), 26: np.float64(0.6179775280898876), 27: np.float64(0.2077922077922078), 29: np.float64(0.7542372881355932), 31: np.float64(0.0), 32: np.float64(0.5862068965517241), 40: np.float64(0.1484375)}
Micro-average F1 score: 0.46774193548387094
Weighted-average F1 score: 0.44346731462736133
F1 score per class: {0: np.float64(0.375), 4: np.float64(0.875), 5: np.float64(0.46228710462287104), 6: np.float64(0.29931972789115646), 7: np.float64(0.04819277108433735), 9: np.float64(0.45454545454545453), 10: np.float64(0.27956989247311825), 13: np.float64(0.07692307692307693), 16: np.float64(0.3620689655172414), 17: np.float64(0.14285714285714285), 18: np.float64(0.24444444444444444), 19: np.float64(0.44565217391304346), 21: np.float64(0.15841584158415842), 23: np.float64(0.5585585585585585), 24: np.float64(0.0625), 26: np.float64(0.6132075471698113), 27: np.float64(0.18181818181818182), 29: np.float64(0.703125), 31: np.float64(0.15384615384615385), 32: np.float64(0.5594405594405595), 40: np.float64(0.13008130081300814)}
Micro-average F1 score: 0.40605899548232793
Weighted-average F1 score: 0.3844113131791555
F1 score per class: {0: np.float64(0.44171779141104295), 4: np.float64(0.8656716417910447), 5: np.float64(0.4909560723514212), 6: np.float64(0.3125), 7: np.float64(0.047058823529411764), 9: np.float64(0.6024096385542169), 10: np.float64(0.26737967914438504), 13: np.float64(0.07142857142857142), 16: np.float64(0.37168141592920356), 17: np.float64(0.11428571428571428), 18: np.float64(0.2518518518518518), 19: np.float64(0.4954128440366973), 21: np.float64(0.15753424657534246), 23: np.float64(0.5818181818181818), 24: np.float64(0.06666666666666667), 26: np.float64(0.6113989637305699), 27: np.float64(0.1839080459770115), 29: np.float64(0.7368421052631579), 31: np.float64(0.25), 32: np.float64(0.5734767025089605), 40: np.float64(0.11764705882352941)}
Micro-average F1 score: 0.42140845070422533
Weighted-average F1 score: 0.39728331958959984
cur_acc_wo_na:  ['0.7728', '0.2828', '0.6408', '0.5737']
his_acc_wo_na:  ['0.7728', '0.5307', '0.5609', '0.5902']
cur_acc des_wo_na:  ['0.7623', '0.3206', '0.6185', '0.5318']
his_acc des_wo_na:  ['0.7623', '0.5693', '0.5533', '0.5424']
cur_acc rrf_wo_na:  ['0.7725', '0.3099', '0.6287', '0.5498']
his_acc rrf_wo_na:  ['0.7725', '0.5702', '0.5659', '0.5570']
cur_acc_w_na:  ['0.6487', '0.2421', '0.4796', '0.4263']
his_acc_w_na:  ['0.6487', '0.4283', '0.4283', '0.4677']
cur_acc des_w_na:  ['0.6164', '0.2822', '0.4629', '0.3595']
his_acc des_w_na:  ['0.6164', '0.4675', '0.4206', '0.4061']
cur_acc rrf_w_na:  ['0.6289', '0.2724', '0.4703', '0.3756']
his_acc rrf_w_na:  ['0.6289', '0.4681', '0.4316', '0.4214']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 78.3903558CurrentTrain: epoch  0, batch     1 | loss: 100.2348730CurrentTrain: epoch  0, batch     2 | loss: 95.7162571CurrentTrain: epoch  0, batch     3 | loss: 61.8801042CurrentTrain: epoch  1, batch     0 | loss: 84.2579064CurrentTrain: epoch  1, batch     1 | loss: 91.0308415CurrentTrain: epoch  1, batch     2 | loss: 75.6100716CurrentTrain: epoch  1, batch     3 | loss: 50.2628811CurrentTrain: epoch  2, batch     0 | loss: 71.1756631CurrentTrain: epoch  2, batch     1 | loss: 68.8346605CurrentTrain: epoch  2, batch     2 | loss: 100.1691426CurrentTrain: epoch  2, batch     3 | loss: 120.9035397CurrentTrain: epoch  3, batch     0 | loss: 68.3782148CurrentTrain: epoch  3, batch     1 | loss: 79.3295634CurrentTrain: epoch  3, batch     2 | loss: 71.6876868CurrentTrain: epoch  3, batch     3 | loss: 89.4883142CurrentTrain: epoch  4, batch     0 | loss: 69.6183427CurrentTrain: epoch  4, batch     1 | loss: 82.8058756CurrentTrain: epoch  4, batch     2 | loss: 69.9773597CurrentTrain: epoch  4, batch     3 | loss: 44.3830878CurrentTrain: epoch  5, batch     0 | loss: 65.7207701CurrentTrain: epoch  5, batch     1 | loss: 82.5358722CurrentTrain: epoch  5, batch     2 | loss: 95.4716209CurrentTrain: epoch  5, batch     3 | loss: 52.6949401CurrentTrain: epoch  6, batch     0 | loss: 79.1255969CurrentTrain: epoch  6, batch     1 | loss: 78.8601554CurrentTrain: epoch  6, batch     2 | loss: 65.6724068CurrentTrain: epoch  6, batch     3 | loss: 65.6443556CurrentTrain: epoch  7, batch     0 | loss: 78.4683917CurrentTrain: epoch  7, batch     1 | loss: 96.1676452CurrentTrain: epoch  7, batch     2 | loss: 91.9177340CurrentTrain: epoch  7, batch     3 | loss: 49.8025910CurrentTrain: epoch  8, batch     0 | loss: 63.1507895CurrentTrain: epoch  8, batch     1 | loss: 79.6064131CurrentTrain: epoch  8, batch     2 | loss: 64.5514029CurrentTrain: epoch  8, batch     3 | loss: 64.6936651CurrentTrain: epoch  9, batch     0 | loss: 96.5396097CurrentTrain: epoch  9, batch     1 | loss: 62.0403022CurrentTrain: epoch  9, batch     2 | loss: 66.6771124CurrentTrain: epoch  9, batch     3 | loss: 59.2070260
MemoryTrain:  epoch  0, batch     0 | loss: 0.8191910MemoryTrain:  epoch  1, batch     0 | loss: 0.6984364MemoryTrain:  epoch  2, batch     0 | loss: 0.5914593MemoryTrain:  epoch  3, batch     0 | loss: 0.5113465MemoryTrain:  epoch  4, batch     0 | loss: 0.4384994MemoryTrain:  epoch  5, batch     0 | loss: 0.3501410MemoryTrain:  epoch  6, batch     0 | loss: 0.3088256MemoryTrain:  epoch  7, batch     0 | loss: 0.2526570MemoryTrain:  epoch  8, batch     0 | loss: 0.2246908MemoryTrain:  epoch  9, batch     0 | loss: 0.2049292

F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.6666666666666666), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.463768115942029), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6363636363636364), 37: np.float64(0.6607142857142857), 38: np.float64(0.13333333333333333), 40: np.float64(0.0)}
Micro-average F1 score: 0.4186046511627907
Weighted-average F1 score: 0.3204657439895716
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.6666666666666666), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.56), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6551724137931034), 37: np.float64(0.6846846846846847), 38: np.float64(0.4878048780487805), 40: np.float64(0.0)}
Micro-average F1 score: 0.44664031620553357
Weighted-average F1 score: 0.3346226969293053
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.7), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.56), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.6481481481481481), 37: np.float64(0.6608695652173913), 38: np.float64(0.45), 40: np.float64(0.0)}
Micro-average F1 score: 0.4517453798767967
Weighted-average F1 score: 0.344658288571332

F1 score per class: {0: np.float64(0.6666666666666666), 4: np.float64(0.8950276243093923), 5: np.float64(0.7315175097276264), 6: np.float64(0.48868778280542985), 7: np.float64(0.08), 9: np.float64(0.7142857142857143), 10: np.float64(0.38372093023255816), 13: np.float64(0.06557377049180328), 15: np.float64(0.28), 16: np.float64(0.6666666666666666), 17: np.float64(0.0), 18: np.float64(0.25925925925925924), 19: np.float64(0.5806451612903226), 21: np.float64(0.205607476635514), 23: np.float64(0.8275862068965517), 24: np.float64(0.08695652173913043), 25: np.float64(0.463768115942029), 26: np.float64(0.7231638418079096), 27: np.float64(0.2857142857142857), 29: np.float64(0.8679245283018868), 31: np.float64(0.0), 32: np.float64(0.723404255319149), 35: np.float64(0.38095238095238093), 37: np.float64(0.2835249042145594), 38: np.float64(0.12903225806451613), 40: np.float64(0.1945945945945946)}
Micro-average F1 score: 0.5272385723231058
Weighted-average F1 score: 0.5041721447524543
F1 score per class: {0: np.float64(0.5373134328358209), 4: np.float64(0.9479166666666666), 5: np.float64(0.6109324758842444), 6: np.float64(0.46808510638297873), 7: np.float64(0.08333333333333333), 9: np.float64(0.49019607843137253), 10: np.float64(0.5258215962441315), 13: np.float64(0.13333333333333333), 15: np.float64(0.4444444444444444), 16: np.float64(0.48), 17: np.float64(0.0), 18: np.float64(0.37383177570093457), 19: np.float64(0.4885057471264368), 21: np.float64(0.17857142857142858), 23: np.float64(0.6458333333333334), 24: np.float64(0.10810810810810811), 25: np.float64(0.56), 26: np.float64(0.6355140186915887), 27: np.float64(0.2962962962962963), 29: np.float64(0.8303571428571429), 31: np.float64(0.0), 32: np.float64(0.7258064516129032), 35: np.float64(0.3206751054852321), 37: np.float64(0.34234234234234234), 38: np.float64(0.43478260869565216), 40: np.float64(0.21897810218978103)}
Micro-average F1 score: 0.5092007690195002
Weighted-average F1 score: 0.4885613136927716
F1 score per class: {0: np.float64(0.6101694915254238), 4: np.float64(0.9473684210526315), 5: np.float64(0.6245847176079734), 6: np.float64(0.47413793103448276), 7: np.float64(0.08571428571428572), 9: np.float64(0.6756756756756757), 10: np.float64(0.5024154589371981), 13: np.float64(0.1111111111111111), 15: np.float64(0.4), 16: np.float64(0.6233766233766234), 17: np.float64(0.0), 18: np.float64(0.38961038961038963), 19: np.float64(0.5448717948717948), 21: np.float64(0.18604651162790697), 23: np.float64(0.6888888888888889), 24: np.float64(0.07407407407407407), 25: np.float64(0.5526315789473685), 26: np.float64(0.6666666666666666), 27: np.float64(0.3018867924528302), 29: np.float64(0.8378378378378378), 31: np.float64(0.0), 32: np.float64(0.7258064516129032), 35: np.float64(0.34146341463414637), 37: np.float64(0.2878787878787879), 38: np.float64(0.42857142857142855), 40: np.float64(0.1875)}
Micro-average F1 score: 0.5208690680388793
Weighted-average F1 score: 0.4978372237828667

F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.5), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.43243243243243246), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.5233644859813084), 37: np.float64(0.5323741007194245), 38: np.float64(0.13333333333333333), 40: np.float64(0.0)}
Micro-average F1 score: 0.3125
Weighted-average F1 score: 0.24038972093858127
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.5454545454545454), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5121951219512195), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.5170068027210885), 37: np.float64(0.5846153846153846), 38: np.float64(0.4444444444444444), 40: np.float64(0.0)}
Micro-average F1 score: 0.31301939058171746
Weighted-average F1 score: 0.23036966169644552
F1 score per class: {0: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.56), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 25: np.float64(0.5121951219512195), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.5147058823529411), 37: np.float64(0.5547445255474452), 38: np.float64(0.4186046511627907), 40: np.float64(0.0)}
Micro-average F1 score: 0.3235294117647059
Weighted-average F1 score: 0.24323643401488876

F1 score per class: {0: np.float64(0.544), 4: np.float64(0.8393782383419689), 5: np.float64(0.56797583081571), 6: np.float64(0.3103448275862069), 7: np.float64(0.047244094488188976), 9: np.float64(0.6578947368421053), 10: np.float64(0.27615062761506276), 13: np.float64(0.036036036036036036), 15: np.float64(0.14285714285714285), 16: np.float64(0.40350877192982454), 17: np.float64(0.0), 18: np.float64(0.16091954022988506), 19: np.float64(0.5), 21: np.float64(0.13580246913580246), 23: np.float64(0.7128712871287128), 24: np.float64(0.06896551724137931), 25: np.float64(0.43243243243243246), 26: np.float64(0.6464646464646465), 27: np.float64(0.16326530612244897), 29: np.float64(0.6917293233082706), 31: np.float64(0.0), 32: np.float64(0.5666666666666667), 35: np.float64(0.24034334763948498), 37: np.float64(0.15546218487394958), 38: np.float64(0.11764705882352941), 40: np.float64(0.16589861751152074)}
Micro-average F1 score: 0.38473840530043407
Weighted-average F1 score: 0.3567145194422847
F1 score per class: {0: np.float64(0.391304347826087), 4: np.float64(0.8792270531400966), 5: np.float64(0.3822937625754527), 6: np.float64(0.2972972972972973), 7: np.float64(0.045454545454545456), 9: np.float64(0.3787878787878788), 10: np.float64(0.3425076452599388), 13: np.float64(0.0851063829787234), 15: np.float64(0.3), 16: np.float64(0.2807017543859649), 17: np.float64(0.0), 18: np.float64(0.21164021164021163), 19: np.float64(0.4), 21: np.float64(0.11152416356877323), 23: np.float64(0.5210084033613446), 24: np.float64(0.07547169811320754), 25: np.float64(0.5060240963855421), 26: np.float64(0.5483870967741935), 27: np.float64(0.1568627450980392), 29: np.float64(0.6348122866894198), 31: np.float64(0.0), 32: np.float64(0.5389221556886228), 35: np.float64(0.1958762886597938), 37: np.float64(0.20596205962059622), 38: np.float64(0.3076923076923077), 40: np.float64(0.16666666666666666)}
Micro-average F1 score: 0.3536818008393743
Weighted-average F1 score: 0.33413550827867006
F1 score per class: {0: np.float64(0.44171779141104295), 4: np.float64(0.8910891089108911), 5: np.float64(0.42247191011235957), 6: np.float64(0.3005464480874317), 7: np.float64(0.048), 9: np.float64(0.6024096385542169), 10: np.float64(0.33548387096774196), 13: np.float64(0.06557377049180328), 15: np.float64(0.2545454545454545), 16: np.float64(0.35294117647058826), 17: np.float64(0.0), 18: np.float64(0.20833333333333334), 19: np.float64(0.4497354497354497), 21: np.float64(0.11594202898550725), 23: np.float64(0.5740740740740741), 24: np.float64(0.058823529411764705), 25: np.float64(0.5), 26: np.float64(0.5972850678733032), 27: np.float64(0.1568627450980392), 29: np.float64(0.6549295774647887), 31: np.float64(0.0), 32: np.float64(0.5405405405405406), 35: np.float64(0.2046783625730994), 37: np.float64(0.17194570135746606), 38: np.float64(0.34615384615384615), 40: np.float64(0.14634146341463414)}
Micro-average F1 score: 0.36689488521949254
Weighted-average F1 score: 0.343498243703016
cur_acc_wo_na:  ['0.7728', '0.2828', '0.6408', '0.5737', '0.4186']
his_acc_wo_na:  ['0.7728', '0.5307', '0.5609', '0.5902', '0.5272']
cur_acc des_wo_na:  ['0.7623', '0.3206', '0.6185', '0.5318', '0.4466']
his_acc des_wo_na:  ['0.7623', '0.5693', '0.5533', '0.5424', '0.5092']
cur_acc rrf_wo_na:  ['0.7725', '0.3099', '0.6287', '0.5498', '0.4517']
his_acc rrf_wo_na:  ['0.7725', '0.5702', '0.5659', '0.5570', '0.5209']
cur_acc_w_na:  ['0.6487', '0.2421', '0.4796', '0.4263', '0.3125']
his_acc_w_na:  ['0.6487', '0.4283', '0.4283', '0.4677', '0.3847']
cur_acc des_w_na:  ['0.6164', '0.2822', '0.4629', '0.3595', '0.3130']
his_acc des_w_na:  ['0.6164', '0.4675', '0.4206', '0.4061', '0.3537']
cur_acc rrf_w_na:  ['0.6289', '0.2724', '0.4703', '0.3756', '0.3235']
his_acc rrf_w_na:  ['0.6289', '0.4681', '0.4316', '0.4214', '0.3669']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 145.5505625CurrentTrain: epoch  0, batch     1 | loss: 82.1154668CurrentTrain: epoch  0, batch     2 | loss: 96.2212175CurrentTrain: epoch  0, batch     3 | loss: 111.5504341CurrentTrain: epoch  0, batch     4 | loss: 20.5413503CurrentTrain: epoch  1, batch     0 | loss: 133.8693731CurrentTrain: epoch  1, batch     1 | loss: 101.9660103CurrentTrain: epoch  1, batch     2 | loss: 77.6182882CurrentTrain: epoch  1, batch     3 | loss: 87.2232426CurrentTrain: epoch  1, batch     4 | loss: 26.6441921CurrentTrain: epoch  2, batch     0 | loss: 105.1383443CurrentTrain: epoch  2, batch     1 | loss: 82.5797981CurrentTrain: epoch  2, batch     2 | loss: 129.5689187CurrentTrain: epoch  2, batch     3 | loss: 71.2529866CurrentTrain: epoch  2, batch     4 | loss: 18.5332353CurrentTrain: epoch  3, batch     0 | loss: 82.1421142CurrentTrain: epoch  3, batch     1 | loss: 82.3129208CurrentTrain: epoch  3, batch     2 | loss: 101.4561969CurrentTrain: epoch  3, batch     3 | loss: 67.8809728CurrentTrain: epoch  3, batch     4 | loss: 39.5876524CurrentTrain: epoch  4, batch     0 | loss: 69.4159513CurrentTrain: epoch  4, batch     1 | loss: 98.1757580CurrentTrain: epoch  4, batch     2 | loss: 66.6985543CurrentTrain: epoch  4, batch     3 | loss: 97.9233995CurrentTrain: epoch  4, batch     4 | loss: 26.6787704CurrentTrain: epoch  5, batch     0 | loss: 84.4002840CurrentTrain: epoch  5, batch     1 | loss: 96.3902038CurrentTrain: epoch  5, batch     2 | loss: 77.5192617CurrentTrain: epoch  5, batch     3 | loss: 63.4425424CurrentTrain: epoch  5, batch     4 | loss: 40.8567733CurrentTrain: epoch  6, batch     0 | loss: 95.4856330CurrentTrain: epoch  6, batch     1 | loss: 95.8219506CurrentTrain: epoch  6, batch     2 | loss: 78.4947639CurrentTrain: epoch  6, batch     3 | loss: 77.0787686CurrentTrain: epoch  6, batch     4 | loss: 22.6917801CurrentTrain: epoch  7, batch     0 | loss: 66.6038306CurrentTrain: epoch  7, batch     1 | loss: 80.0324383CurrentTrain: epoch  7, batch     2 | loss: 77.7612491CurrentTrain: epoch  7, batch     3 | loss: 92.6998480CurrentTrain: epoch  7, batch     4 | loss: 23.2634651CurrentTrain: epoch  8, batch     0 | loss: 78.5196224CurrentTrain: epoch  8, batch     1 | loss: 79.0149708CurrentTrain: epoch  8, batch     2 | loss: 76.4741893CurrentTrain: epoch  8, batch     3 | loss: 63.0269109CurrentTrain: epoch  8, batch     4 | loss: 39.4412590CurrentTrain: epoch  9, batch     0 | loss: 74.9968784CurrentTrain: epoch  9, batch     1 | loss: 77.1361744CurrentTrain: epoch  9, batch     2 | loss: 92.3629753CurrentTrain: epoch  9, batch     3 | loss: 76.9020526CurrentTrain: epoch  9, batch     4 | loss: 38.8843972
MemoryTrain:  epoch  0, batch     0 | loss: 0.8654140MemoryTrain:  epoch  1, batch     0 | loss: 0.8263493MemoryTrain:  epoch  2, batch     0 | loss: 0.6268453MemoryTrain:  epoch  3, batch     0 | loss: 0.5216758MemoryTrain:  epoch  4, batch     0 | loss: 0.4965063MemoryTrain:  epoch  5, batch     0 | loss: 0.4087074MemoryTrain:  epoch  6, batch     0 | loss: 0.3605744MemoryTrain:  epoch  7, batch     0 | loss: 0.3089139MemoryTrain:  epoch  8, batch     0 | loss: 0.2789415MemoryTrain:  epoch  9, batch     0 | loss: 0.2342958

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.5384615384615384), 5: np.float64(0.0), 6: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.3442622950819672), 12: np.float64(0.5061728395061729), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 28: np.float64(0.48), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.21739130434782608), 40: np.float64(0.0)}
Micro-average F1 score: 0.3448275862068966
Weighted-average F1 score: 0.2749306203067191
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.45161290322580644), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.5037037037037037), 12: np.float64(0.5454545454545454), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.41379310344827586), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.15384615384615385), 40: np.float64(0.0)}
Micro-average F1 score: 0.3339191564147627
Weighted-average F1 score: 0.233142606909014
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.4375), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.5109489051094891), 12: np.float64(0.5595238095238095), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.48), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.18604651162790697), 40: np.float64(0.0)}
Micro-average F1 score: 0.3714821763602251
Weighted-average F1 score: 0.276120905207622

F1 score per class: {0: np.float64(0.6538461538461539), 2: np.float64(0.17721518987341772), 4: np.float64(0.7012987012987013), 5: np.float64(0.7654320987654321), 6: np.float64(0.43956043956043955), 7: np.float64(0.05714285714285714), 9: np.float64(0.6944444444444444), 10: np.float64(0.25396825396825395), 11: np.float64(0.1794871794871795), 12: np.float64(0.3037037037037037), 13: np.float64(0.06060606060606061), 15: np.float64(0.208955223880597), 16: np.float64(0.6376811594202898), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5931558935361216), 21: np.float64(0.3037974683544304), 23: np.float64(0.7415730337078652), 24: np.float64(0.09523809523809523), 25: np.float64(0.417910447761194), 26: np.float64(0.7058823529411765), 27: np.float64(0.26666666666666666), 28: np.float64(0.1518987341772152), 29: np.float64(0.8472906403940886), 31: np.float64(0.0), 32: np.float64(0.704), 35: np.float64(0.3333333333333333), 37: np.float64(0.2962962962962963), 38: np.float64(0.06060606060606061), 39: np.float64(0.07751937984496124), 40: np.float64(0.23333333333333334)}
Micro-average F1 score: 0.44763746891406464
Weighted-average F1 score: 0.42554252202848886
F1 score per class: {0: np.float64(0.43373493975903615), 2: np.float64(0.14), 4: np.float64(0.8117647058823529), 5: np.float64(0.5919003115264797), 6: np.float64(0.41964285714285715), 7: np.float64(0.06382978723404255), 9: np.float64(0.44642857142857145), 10: np.float64(0.3473053892215569), 11: np.float64(0.31627906976744186), 12: np.float64(0.3050847457627119), 13: np.float64(0.045454545454545456), 15: np.float64(0.36363636363636365), 16: np.float64(0.6753246753246753), 17: np.float64(0.0), 18: np.float64(0.061855670103092786), 19: np.float64(0.4913294797687861), 21: np.float64(0.21052631578947367), 23: np.float64(0.6530612244897959), 24: np.float64(0.058823529411764705), 25: np.float64(0.5789473684210527), 26: np.float64(0.6767676767676768), 27: np.float64(0.2727272727272727), 28: np.float64(0.1518987341772152), 29: np.float64(0.8140703517587939), 31: np.float64(0.0), 32: np.float64(0.6741573033707865), 35: np.float64(0.3261802575107296), 37: np.float64(0.2807017543859649), 38: np.float64(0.3137254901960784), 39: np.float64(0.06382978723404255), 40: np.float64(0.23357664233576642)}
Micro-average F1 score: 0.4288389513108614
Weighted-average F1 score: 0.40496889628861943
F1 score per class: {0: np.float64(0.5932203389830508), 2: np.float64(0.13725490196078433), 4: np.float64(0.7804878048780488), 5: np.float64(0.6529209621993127), 6: np.float64(0.42105263157894735), 7: np.float64(0.075), 9: np.float64(0.6666666666666666), 10: np.float64(0.3333333333333333), 11: np.float64(0.3167420814479638), 12: np.float64(0.31125827814569534), 13: np.float64(0.037037037037037035), 15: np.float64(0.2857142857142857), 16: np.float64(0.7058823529411765), 17: np.float64(0.0), 18: np.float64(0.05128205128205128), 19: np.float64(0.5704697986577181), 21: np.float64(0.22900763358778625), 23: np.float64(0.6222222222222222), 24: np.float64(0.08), 25: np.float64(0.5405405405405406), 26: np.float64(0.6808510638297872), 27: np.float64(0.2608695652173913), 28: np.float64(0.14814814814814814), 29: np.float64(0.8080808080808081), 31: np.float64(0.0), 32: np.float64(0.6742424242424242), 35: np.float64(0.35359116022099446), 37: np.float64(0.2882882882882883), 38: np.float64(0.13953488372093023), 39: np.float64(0.07017543859649122), 40: np.float64(0.19875776397515527)}
Micro-average F1 score: 0.4406187624750499
Weighted-average F1 score: 0.4161155633278123

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.28), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.28), 12: np.float64(0.42487046632124353), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.22641509433962265), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.11904761904761904), 40: np.float64(0.0)}
Micro-average F1 score: 0.23529411764705882
Weighted-average F1 score: 0.18844894999239045
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.23728813559322035), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.40963855421686746), 12: np.float64(0.47368421052631576), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.16666666666666666), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.1), 40: np.float64(0.0)}
Micro-average F1 score: 0.22144522144522144
Weighted-average F1 score: 0.15917755809485407
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.23333333333333334), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.41916167664670656), 12: np.float64(0.48205128205128206), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.18461538461538463), 29: np.float64(0.0), 32: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.11594202898550725), 40: np.float64(0.0)}
Micro-average F1 score: 0.24719101123595505
Weighted-average F1 score: 0.18506620750385128

F1 score per class: {0: np.float64(0.5230769230769231), 2: np.float64(0.09395973154362416), 4: np.float64(0.6625766871165644), 5: np.float64(0.6138613861386139), 6: np.float64(0.2898550724637681), 7: np.float64(0.032), 9: np.float64(0.6329113924050633), 10: np.float64(0.22377622377622378), 11: np.float64(0.12138728323699421), 12: np.float64(0.1524163568773234), 13: np.float64(0.03773584905660377), 15: np.float64(0.12173913043478261), 16: np.float64(0.4), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5454545454545454), 21: np.float64(0.20689655172413793), 23: np.float64(0.6470588235294118), 24: np.float64(0.07407407407407407), 25: np.float64(0.4), 26: np.float64(0.6382978723404256), 27: np.float64(0.1523809523809524), 28: np.float64(0.07741935483870968), 29: np.float64(0.6852589641434262), 31: np.float64(0.0), 32: np.float64(0.5415384615384615), 35: np.float64(0.2153846153846154), 37: np.float64(0.2376237623762376), 38: np.float64(0.058823529411764705), 39: np.float64(0.038910505836575876), 40: np.float64(0.20095693779904306)}
Micro-average F1 score: 0.3192118226600985
Weighted-average F1 score: 0.28951942002699627
F1 score per class: {0: np.float64(0.3025210084033613), 2: np.float64(0.08), 4: np.float64(0.7666666666666667), 5: np.float64(0.3784860557768924), 6: np.float64(0.2493368700265252), 7: np.float64(0.03428571428571429), 9: np.float64(0.3448275862068966), 10: np.float64(0.25892857142857145), 11: np.float64(0.21052631578947367), 12: np.float64(0.16574585635359115), 13: np.float64(0.03508771929824561), 15: np.float64(0.24), 16: np.float64(0.37681159420289856), 17: np.float64(0.0), 18: np.float64(0.047619047619047616), 19: np.float64(0.4156479217603912), 21: np.float64(0.1322314049586777), 23: np.float64(0.5079365079365079), 24: np.float64(0.043478260869565216), 25: np.float64(0.4731182795698925), 26: np.float64(0.5955555555555555), 27: np.float64(0.14754098360655737), 28: np.float64(0.06629834254143646), 29: np.float64(0.6612244897959184), 31: np.float64(0.0), 32: np.float64(0.47244094488188976), 35: np.float64(0.19895287958115182), 37: np.float64(0.2222222222222222), 38: np.float64(0.24615384615384617), 39: np.float64(0.03314917127071823), 40: np.float64(0.1839080459770115)}
Micro-average F1 score: 0.29125596184419716
Weighted-average F1 score: 0.2701879028009208
F1 score per class: {0: np.float64(0.4268292682926829), 2: np.float64(0.07446808510638298), 4: np.float64(0.7398843930635838), 5: np.float64(0.4470588235294118), 6: np.float64(0.24581005586592178), 7: np.float64(0.039735099337748346), 9: np.float64(0.5952380952380952), 10: np.float64(0.26), 11: np.float64(0.2153846153846154), 12: np.float64(0.16549295774647887), 13: np.float64(0.025974025974025976), 15: np.float64(0.18181818181818182), 16: np.float64(0.4067796610169492), 17: np.float64(0.0), 18: np.float64(0.03773584905660377), 19: np.float64(0.5074626865671642), 21: np.float64(0.14084507042253522), 23: np.float64(0.5384615384615384), 24: np.float64(0.06060606060606061), 25: np.float64(0.47619047619047616), 26: np.float64(0.6037735849056604), 27: np.float64(0.144), 28: np.float64(0.06349206349206349), 29: np.float64(0.6557377049180327), 31: np.float64(0.0), 32: np.float64(0.4930747922437673), 35: np.float64(0.22614840989399293), 37: np.float64(0.2222222222222222), 38: np.float64(0.12), 39: np.float64(0.038461538461538464), 40: np.float64(0.16)}
Micro-average F1 score: 0.30374957000344
Weighted-average F1 score: 0.2789449649495784
cur_acc_wo_na:  ['0.7728', '0.2828', '0.6408', '0.5737', '0.4186', '0.3448']
his_acc_wo_na:  ['0.7728', '0.5307', '0.5609', '0.5902', '0.5272', '0.4476']
cur_acc des_wo_na:  ['0.7623', '0.3206', '0.6185', '0.5318', '0.4466', '0.3339']
his_acc des_wo_na:  ['0.7623', '0.5693', '0.5533', '0.5424', '0.5092', '0.4288']
cur_acc rrf_wo_na:  ['0.7725', '0.3099', '0.6287', '0.5498', '0.4517', '0.3715']
his_acc rrf_wo_na:  ['0.7725', '0.5702', '0.5659', '0.5570', '0.5209', '0.4406']
cur_acc_w_na:  ['0.6487', '0.2421', '0.4796', '0.4263', '0.3125', '0.2353']
his_acc_w_na:  ['0.6487', '0.4283', '0.4283', '0.4677', '0.3847', '0.3192']
cur_acc des_w_na:  ['0.6164', '0.2822', '0.4629', '0.3595', '0.3130', '0.2214']
his_acc des_w_na:  ['0.6164', '0.4675', '0.4206', '0.4061', '0.3537', '0.2913']
cur_acc rrf_w_na:  ['0.6289', '0.2724', '0.4703', '0.3756', '0.3235', '0.2472']
his_acc rrf_w_na:  ['0.6289', '0.4681', '0.4316', '0.4214', '0.3669', '0.3037']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 90.9144917CurrentTrain: epoch  0, batch     1 | loss: 98.4118465CurrentTrain: epoch  0, batch     2 | loss: 196.0556955CurrentTrain: epoch  0, batch     3 | loss: 88.6886259CurrentTrain: epoch  0, batch     4 | loss: 81.3719750CurrentTrain: epoch  1, batch     0 | loss: 76.9559900CurrentTrain: epoch  1, batch     1 | loss: 99.5394551CurrentTrain: epoch  1, batch     2 | loss: 106.1255607CurrentTrain: epoch  1, batch     3 | loss: 107.2473041CurrentTrain: epoch  1, batch     4 | loss: 51.2859935CurrentTrain: epoch  2, batch     0 | loss: 107.2743401CurrentTrain: epoch  2, batch     1 | loss: 75.5081282CurrentTrain: epoch  2, batch     2 | loss: 71.4225853CurrentTrain: epoch  2, batch     3 | loss: 87.8926072CurrentTrain: epoch  2, batch     4 | loss: 61.2943758CurrentTrain: epoch  3, batch     0 | loss: 105.0317697CurrentTrain: epoch  3, batch     1 | loss: 85.4215993CurrentTrain: epoch  3, batch     2 | loss: 98.6748395CurrentTrain: epoch  3, batch     3 | loss: 100.2557338CurrentTrain: epoch  3, batch     4 | loss: 99.3475248CurrentTrain: epoch  4, batch     0 | loss: 100.1383739CurrentTrain: epoch  4, batch     1 | loss: 125.3121983CurrentTrain: epoch  4, batch     2 | loss: 82.2490282CurrentTrain: epoch  4, batch     3 | loss: 73.0690448CurrentTrain: epoch  4, batch     4 | loss: 55.4678505CurrentTrain: epoch  5, batch     0 | loss: 81.2321925CurrentTrain: epoch  5, batch     1 | loss: 79.7954802CurrentTrain: epoch  5, batch     2 | loss: 82.7805425CurrentTrain: epoch  5, batch     3 | loss: 124.2442223CurrentTrain: epoch  5, batch     4 | loss: 55.0534331CurrentTrain: epoch  6, batch     0 | loss: 79.8592377CurrentTrain: epoch  6, batch     1 | loss: 97.9577264CurrentTrain: epoch  6, batch     2 | loss: 168.7404945CurrentTrain: epoch  6, batch     3 | loss: 68.8652707CurrentTrain: epoch  6, batch     4 | loss: 49.3874946CurrentTrain: epoch  7, batch     0 | loss: 77.4754494CurrentTrain: epoch  7, batch     1 | loss: 97.1816732CurrentTrain: epoch  7, batch     2 | loss: 99.2758977CurrentTrain: epoch  7, batch     3 | loss: 80.4961729CurrentTrain: epoch  7, batch     4 | loss: 52.7528617CurrentTrain: epoch  8, batch     0 | loss: 94.8700130CurrentTrain: epoch  8, batch     1 | loss: 68.5486917CurrentTrain: epoch  8, batch     2 | loss: 95.7588370CurrentTrain: epoch  8, batch     3 | loss: 94.2201837CurrentTrain: epoch  8, batch     4 | loss: 67.2763393CurrentTrain: epoch  9, batch     0 | loss: 79.8114007CurrentTrain: epoch  9, batch     1 | loss: 79.3678211CurrentTrain: epoch  9, batch     2 | loss: 96.8700303CurrentTrain: epoch  9, batch     3 | loss: 76.9215757CurrentTrain: epoch  9, batch     4 | loss: 42.3507146
MemoryTrain:  epoch  0, batch     0 | loss: 1.1543688MemoryTrain:  epoch  1, batch     0 | loss: 1.0439601MemoryTrain:  epoch  2, batch     0 | loss: 0.8196938MemoryTrain:  epoch  3, batch     0 | loss: 0.6644105MemoryTrain:  epoch  4, batch     0 | loss: 0.5829165MemoryTrain:  epoch  5, batch     0 | loss: 0.4610547MemoryTrain:  epoch  6, batch     0 | loss: 0.3935639MemoryTrain:  epoch  7, batch     0 | loss: 0.3630941MemoryTrain:  epoch  8, batch     0 | loss: 0.3388975MemoryTrain:  epoch  9, batch     0 | loss: 0.2695957

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.28292682926829266), 2: np.float64(0.0), 3: np.float64(0.6024096385542169), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.19047619047619047), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5798319327731093), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.7226890756302521), 35: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.39096267190569745
Weighted-average F1 score: 0.3357229820803715
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.25510204081632654), 2: np.float64(0.0), 3: np.float64(0.5882352941176471), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.13333333333333333), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5655737704918032), 23: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.6956521739130435), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.32285471537807986
Weighted-average F1 score: 0.2607377731479259
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.25742574257425743), 2: np.float64(0.0), 3: np.float64(0.5824175824175825), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 14: np.float64(0.18556701030927836), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.5622489959839357), 23: np.float64(0.0), 24: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.7008547008547008), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3509700176366843
Weighted-average F1 score: 0.2941061476408515

F1 score per class: {0: np.float64(0.7341772151898734), 1: np.float64(0.20209059233449478), 2: np.float64(0.16470588235294117), 3: np.float64(0.3546099290780142), 4: np.float64(0.6301369863013698), 5: np.float64(0.7966101694915254), 6: np.float64(0.4293193717277487), 7: np.float64(0.0273972602739726), 9: np.float64(0.7575757575757576), 10: np.float64(0.2647058823529412), 11: np.float64(0.11267605633802817), 12: np.float64(0.2755905511811024), 13: np.float64(0.06666666666666667), 14: np.float64(0.12598425196850394), 15: np.float64(0.4), 16: np.float64(0.6666666666666666), 17: np.float64(0.0), 18: np.float64(0.03076923076923077), 19: np.float64(0.5572519083969466), 21: np.float64(0.0), 22: np.float64(0.5207547169811321), 23: np.float64(0.8), 24: np.float64(0.0), 25: np.float64(0.4117647058823529), 26: np.float64(0.7167630057803468), 27: np.float64(0.0), 28: np.float64(0.16279069767441862), 29: np.float64(0.801980198019802), 31: np.float64(0.0), 32: np.float64(0.5793650793650794), 34: np.float64(0.25146198830409355), 35: np.float64(0.17307692307692307), 37: np.float64(0.16216216216216217), 38: np.float64(0.14285714285714285), 39: np.float64(0.07017543859649122), 40: np.float64(0.2374429223744292)}
Micro-average F1 score: 0.3944621938232162
Weighted-average F1 score: 0.374919154111087
F1 score per class: {0: np.float64(0.48), 1: np.float64(0.18315018315018314), 2: np.float64(0.13861386138613863), 3: np.float64(0.37735849056603776), 4: np.float64(0.7215189873417721), 5: np.float64(0.6075949367088608), 6: np.float64(0.4018264840182648), 7: np.float64(0.04938271604938271), 9: np.float64(0.45454545454545453), 10: np.float64(0.32116788321167883), 11: np.float64(0.1206896551724138), 12: np.float64(0.2585034013605442), 13: np.float64(0.0425531914893617), 14: np.float64(0.09022556390977443), 15: np.float64(0.42857142857142855), 16: np.float64(0.7272727272727273), 17: np.float64(0.0), 18: np.float64(0.13986013986013987), 19: np.float64(0.48554913294797686), 21: np.float64(0.1694915254237288), 22: np.float64(0.47586206896551725), 23: np.float64(0.6796116504854369), 24: np.float64(0.0784313725490196), 25: np.float64(0.5454545454545454), 26: np.float64(0.6831683168316832), 27: np.float64(0.0), 28: np.float64(0.15555555555555556), 29: np.float64(0.79), 31: np.float64(0.0), 32: np.float64(0.5442622950819672), 34: np.float64(0.27303754266211605), 35: np.float64(0.1708542713567839), 37: np.float64(0.19298245614035087), 38: np.float64(0.26666666666666666), 39: np.float64(0.10526315789473684), 40: np.float64(0.2073170731707317)}
Micro-average F1 score: 0.37916118111717134
Weighted-average F1 score: 0.36272928802736415
F1 score per class: {0: np.float64(0.584070796460177), 1: np.float64(0.18118466898954705), 2: np.float64(0.14432989690721648), 3: np.float64(0.35451505016722407), 4: np.float64(0.6842105263157895), 5: np.float64(0.6785714285714286), 6: np.float64(0.4166666666666667), 7: np.float64(0.05555555555555555), 9: np.float64(0.6756756756756757), 10: np.float64(0.30434782608695654), 11: np.float64(0.109375), 12: np.float64(0.2608695652173913), 13: np.float64(0.04), 14: np.float64(0.11764705882352941), 15: np.float64(0.41379310344827586), 16: np.float64(0.7333333333333333), 17: np.float64(0.0), 18: np.float64(0.0970873786407767), 19: np.float64(0.5185185185185185), 21: np.float64(0.09523809523809523), 22: np.float64(0.46204620462046203), 23: np.float64(0.6595744680851063), 24: np.float64(0.0), 25: np.float64(0.5333333333333333), 26: np.float64(0.6907216494845361), 27: np.float64(0.0), 28: np.float64(0.14893617021276595), 29: np.float64(0.7839195979899497), 31: np.float64(0.0), 32: np.float64(0.5684931506849316), 34: np.float64(0.2554517133956386), 35: np.float64(0.15789473684210525), 37: np.float64(0.2), 38: np.float64(0.25), 39: np.float64(0.10309278350515463), 40: np.float64(0.18285714285714286)}
Micro-average F1 score: 0.38275458447132266
Weighted-average F1 score: 0.36558258031246227

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.16338028169014085), 2: np.float64(0.0), 3: np.float64(0.43859649122807015), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.14035087719298245), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.4946236559139785), 23: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.5512820512820513), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2604712041884817
Weighted-average F1 score: 0.22477782491734719
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.14326647564469913), 2: np.float64(0.0), 3: np.float64(0.46511627906976744), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.10714285714285714), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.46464646464646464), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.5555555555555556), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.21288515406162464
Weighted-average F1 score: 0.1746835513348496
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.14565826330532214), 2: np.float64(0.0), 3: np.float64(0.4435146443514644), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.14516129032258066), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.4560260586319218), 23: np.float64(0.0), 24: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.5540540540540541), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.2337052260716383
Weighted-average F1 score: 0.19863768878057395

F1 score per class: {0: np.float64(0.5576923076923077), 1: np.float64(0.11328125), 2: np.float64(0.1037037037037037), 3: np.float64(0.2188183807439825), 4: np.float64(0.5935483870967742), 5: np.float64(0.6372881355932203), 6: np.float64(0.2578616352201258), 7: np.float64(0.015037593984962405), 9: np.float64(0.6756756756756757), 10: np.float64(0.225), 11: np.float64(0.0898876404494382), 12: np.float64(0.13861386138613863), 13: np.float64(0.0380952380952381), 14: np.float64(0.07547169811320754), 15: np.float64(0.2608695652173913), 16: np.float64(0.47368421052631576), 17: np.float64(0.0), 18: np.float64(0.021052631578947368), 19: np.float64(0.49324324324324326), 21: np.float64(0.0), 22: np.float64(0.42073170731707316), 23: np.float64(0.6972477064220184), 24: np.float64(0.0), 25: np.float64(0.39436619718309857), 26: np.float64(0.6391752577319587), 27: np.float64(0.0), 28: np.float64(0.07526881720430108), 29: np.float64(0.6558704453441295), 31: np.float64(0.0), 32: np.float64(0.4397590361445783), 34: np.float64(0.14453781512605043), 35: np.float64(0.13953488372093023), 37: np.float64(0.1111111111111111), 38: np.float64(0.12244897959183673), 39: np.float64(0.03463203463203463), 40: np.float64(0.20155038759689922)}
Micro-average F1 score: 0.27283441367118444
Weighted-average F1 score: 0.24834458497345957
F1 score per class: {0: np.float64(0.3317972350230415), 1: np.float64(0.09940357852882704), 2: np.float64(0.0880503144654088), 3: np.float64(0.2518891687657431), 4: np.float64(0.6745562130177515), 5: np.float64(0.3685220729366603), 6: np.float64(0.24043715846994534), 7: np.float64(0.025477707006369428), 9: np.float64(0.32051282051282054), 10: np.float64(0.24858757062146894), 11: np.float64(0.0958904109589041), 12: np.float64(0.13595706618962433), 13: np.float64(0.027777777777777776), 14: np.float64(0.06666666666666667), 15: np.float64(0.3), 16: np.float64(0.44036697247706424), 17: np.float64(0.0), 18: np.float64(0.09302325581395349), 19: np.float64(0.42), 21: np.float64(0.12345679012345678), 22: np.float64(0.3520408163265306), 23: np.float64(0.5223880597014925), 24: np.float64(0.0547945205479452), 25: np.float64(0.4421052631578947), 26: np.float64(0.592274678111588), 27: np.float64(0.0), 28: np.float64(0.07407407407407407), 29: np.float64(0.6502057613168725), 31: np.float64(0.0), 32: np.float64(0.3824884792626728), 34: np.float64(0.16227180527383367), 35: np.float64(0.11371237458193979), 37: np.float64(0.13836477987421383), 38: np.float64(0.20253164556962025), 39: np.float64(0.05747126436781609), 40: np.float64(0.17)}
Micro-average F1 score: 0.2561626429479034
Weighted-average F1 score: 0.24026790612986018
F1 score per class: {0: np.float64(0.4258064516129032), 1: np.float64(0.1), 2: np.float64(0.0915032679738562), 3: np.float64(0.22795698924731184), 4: np.float64(0.6459627329192547), 5: np.float64(0.4408352668213457), 6: np.float64(0.24930747922437674), 7: np.float64(0.027777777777777776), 9: np.float64(0.5882352941176471), 10: np.float64(0.24705882352941178), 11: np.float64(0.08333333333333333), 12: np.float64(0.13588850174216027), 13: np.float64(0.02564102564102564), 14: np.float64(0.08294930875576037), 15: np.float64(0.2608695652173913), 16: np.float64(0.4943820224719101), 17: np.float64(0.0), 18: np.float64(0.06622516556291391), 19: np.float64(0.45652173913043476), 21: np.float64(0.0625), 22: np.float64(0.3491271820448878), 23: np.float64(0.5688073394495413), 24: np.float64(0.0), 25: np.float64(0.46511627906976744), 26: np.float64(0.6175115207373272), 27: np.float64(0.0), 28: np.float64(0.07106598984771574), 29: np.float64(0.6446280991735537), 31: np.float64(0.0), 32: np.float64(0.41919191919191917), 34: np.float64(0.14774774774774774), 35: np.float64(0.1085972850678733), 37: np.float64(0.1360544217687075), 38: np.float64(0.21212121212121213), 39: np.float64(0.05434782608695652), 40: np.float64(0.1523809523809524)}
Micro-average F1 score: 0.2613560676701745
Weighted-average F1 score: 0.24242911362082345
cur_acc_wo_na:  ['0.7728', '0.2828', '0.6408', '0.5737', '0.4186', '0.3448', '0.3910']
his_acc_wo_na:  ['0.7728', '0.5307', '0.5609', '0.5902', '0.5272', '0.4476', '0.3945']
cur_acc des_wo_na:  ['0.7623', '0.3206', '0.6185', '0.5318', '0.4466', '0.3339', '0.3229']
his_acc des_wo_na:  ['0.7623', '0.5693', '0.5533', '0.5424', '0.5092', '0.4288', '0.3792']
cur_acc rrf_wo_na:  ['0.7725', '0.3099', '0.6287', '0.5498', '0.4517', '0.3715', '0.3510']
his_acc rrf_wo_na:  ['0.7725', '0.5702', '0.5659', '0.5570', '0.5209', '0.4406', '0.3828']
cur_acc_w_na:  ['0.6487', '0.2421', '0.4796', '0.4263', '0.3125', '0.2353', '0.2605']
his_acc_w_na:  ['0.6487', '0.4283', '0.4283', '0.4677', '0.3847', '0.3192', '0.2728']
cur_acc des_w_na:  ['0.6164', '0.2822', '0.4629', '0.3595', '0.3130', '0.2214', '0.2129']
his_acc des_w_na:  ['0.6164', '0.4675', '0.4206', '0.4061', '0.3537', '0.2913', '0.2562']
cur_acc rrf_w_na:  ['0.6289', '0.2724', '0.4703', '0.3756', '0.3235', '0.2472', '0.2337']
his_acc rrf_w_na:  ['0.6289', '0.4681', '0.4316', '0.4214', '0.3669', '0.3037', '0.2614']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 95.3583785CurrentTrain: epoch  0, batch     1 | loss: 82.2701787CurrentTrain: epoch  0, batch     2 | loss: 82.3360497CurrentTrain: epoch  0, batch     3 | loss: 62.6264138CurrentTrain: epoch  1, batch     0 | loss: 85.9905430CurrentTrain: epoch  1, batch     1 | loss: 85.6192538CurrentTrain: epoch  1, batch     2 | loss: 107.5349530CurrentTrain: epoch  1, batch     3 | loss: 55.0614718CurrentTrain: epoch  2, batch     0 | loss: 87.6125684CurrentTrain: epoch  2, batch     1 | loss: 80.6575477CurrentTrain: epoch  2, batch     2 | loss: 102.2802173CurrentTrain: epoch  2, batch     3 | loss: 49.1533124CurrentTrain: epoch  3, batch     0 | loss: 66.4954262CurrentTrain: epoch  3, batch     1 | loss: 71.2338234CurrentTrain: epoch  3, batch     2 | loss: 131.9453091CurrentTrain: epoch  3, batch     3 | loss: 47.5357759CurrentTrain: epoch  4, batch     0 | loss: 85.1151895CurrentTrain: epoch  4, batch     1 | loss: 78.1337890CurrentTrain: epoch  4, batch     2 | loss: 64.3476304CurrentTrain: epoch  4, batch     3 | loss: 59.1730017CurrentTrain: epoch  5, batch     0 | loss: 76.7533932CurrentTrain: epoch  5, batch     1 | loss: 81.1835010CurrentTrain: epoch  5, batch     2 | loss: 62.1719125CurrentTrain: epoch  5, batch     3 | loss: 62.4507622CurrentTrain: epoch  6, batch     0 | loss: 64.2130214CurrentTrain: epoch  6, batch     1 | loss: 95.0221037CurrentTrain: epoch  6, batch     2 | loss: 65.9848670CurrentTrain: epoch  6, batch     3 | loss: 46.3446493CurrentTrain: epoch  7, batch     0 | loss: 61.0880631CurrentTrain: epoch  7, batch     1 | loss: 92.3058600CurrentTrain: epoch  7, batch     2 | loss: 94.6588476CurrentTrain: epoch  7, batch     3 | loss: 57.4813848CurrentTrain: epoch  8, batch     0 | loss: 77.1363100CurrentTrain: epoch  8, batch     1 | loss: 93.9949218CurrentTrain: epoch  8, batch     2 | loss: 60.3395175CurrentTrain: epoch  8, batch     3 | loss: 71.4484578CurrentTrain: epoch  9, batch     0 | loss: 76.2359434CurrentTrain: epoch  9, batch     1 | loss: 71.4592919CurrentTrain: epoch  9, batch     2 | loss: 71.7115782CurrentTrain: epoch  9, batch     3 | loss: 101.7453097
MemoryTrain:  epoch  0, batch     0 | loss: 0.7252198MemoryTrain:  epoch  1, batch     0 | loss: 0.6353868MemoryTrain:  epoch  2, batch     0 | loss: 0.4908368MemoryTrain:  epoch  3, batch     0 | loss: 0.3935856MemoryTrain:  epoch  4, batch     0 | loss: 0.3592131MemoryTrain:  epoch  5, batch     0 | loss: 0.2994066MemoryTrain:  epoch  6, batch     0 | loss: 0.2767570MemoryTrain:  epoch  7, batch     0 | loss: 0.2511930MemoryTrain:  epoch  8, batch     0 | loss: 0.2158225MemoryTrain:  epoch  9, batch     0 | loss: 0.1681263

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.5), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 20: np.float64(0.8598130841121495), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8648648648648649), 32: np.float64(0.0), 33: np.float64(0.5333333333333333), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.42696629213483145), 37: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4532803180914513
Weighted-average F1 score: 0.33305595249244835
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.6259541984732825), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.8440366972477065), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.9), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.42105263157894735), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.6386554621848739), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.4772727272727273
Weighted-average F1 score: 0.3476282826512153
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.6046511627906976), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.8468468468468469), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.9), 32: np.float64(0.0), 33: np.float64(0.5), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.616822429906542), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.48464163822525597
Weighted-average F1 score: 0.35488238228279434

F1 score per class: {0: np.float64(0.6055045871559633), 1: np.float64(0.19642857142857142), 2: np.float64(0.1686746987951807), 3: np.float64(0.4132231404958678), 4: np.float64(0.7421383647798742), 5: np.float64(0.7948717948717948), 6: np.float64(0.4186046511627907), 7: np.float64(0.029411764705882353), 8: np.float64(0.28292682926829266), 9: np.float64(0.7142857142857143), 10: np.float64(0.2517482517482518), 11: np.float64(0.08284023668639054), 12: np.float64(0.21105527638190955), 13: np.float64(0.08), 14: np.float64(0.07692307692307693), 15: np.float64(0.32432432432432434), 16: np.float64(0.6333333333333333), 17: np.float64(0.0), 18: np.float64(0.0625), 19: np.float64(0.5487364620938628), 20: np.float64(0.47668393782383417), 21: np.float64(0.0), 22: np.float64(0.543778801843318), 23: np.float64(0.7333333333333333), 24: np.float64(0.0), 25: np.float64(0.31746031746031744), 26: np.float64(0.6885245901639344), 27: np.float64(0.0), 28: np.float64(0.2857142857142857), 29: np.float64(0.7766990291262136), 30: np.float64(0.8648648648648649), 31: np.float64(0.2222222222222222), 32: np.float64(0.5567765567765568), 33: np.float64(0.22857142857142856), 34: np.float64(0.3409090909090909), 35: np.float64(0.13740458015267176), 36: np.float64(0.37254901960784315), 37: np.float64(0.2564102564102564), 38: np.float64(0.13333333333333333), 39: np.float64(0.19672131147540983), 40: np.float64(0.23931623931623933)}
Micro-average F1 score: 0.4003070427940894
Weighted-average F1 score: 0.3887094260579987
F1 score per class: {0: np.float64(0.33488372093023255), 1: np.float64(0.18181818181818182), 2: np.float64(0.10294117647058823), 3: np.float64(0.3378995433789954), 4: np.float64(0.7484662576687117), 5: np.float64(0.5429362880886427), 6: np.float64(0.33707865168539325), 7: np.float64(0.02631578947368421), 8: np.float64(0.26885245901639343), 9: np.float64(0.43859649122807015), 10: np.float64(0.2823529411764706), 11: np.float64(0.12030075187969924), 12: np.float64(0.21561338289962825), 13: np.float64(0.045454545454545456), 14: np.float64(0.1111111111111111), 15: np.float64(0.3076923076923077), 16: np.float64(0.7058823529411765), 17: np.float64(0.0), 18: np.float64(0.13186813186813187), 19: np.float64(0.4271356783919598), 20: np.float64(0.46), 21: np.float64(0.11267605633802817), 22: np.float64(0.43529411764705883), 23: np.float64(0.660377358490566), 24: np.float64(0.07692307692307693), 25: np.float64(0.4657534246575342), 26: np.float64(0.6540284360189573), 27: np.float64(0.0), 28: np.float64(0.2127659574468085), 29: np.float64(0.7850467289719626), 30: np.float64(0.5806451612903226), 31: np.float64(0.07142857142857142), 32: np.float64(0.512987012987013), 33: np.float64(0.1509433962264151), 34: np.float64(0.3205574912891986), 35: np.float64(0.19402985074626866), 36: np.float64(0.4662576687116564), 37: np.float64(0.22429906542056074), 38: np.float64(0.425531914893617), 39: np.float64(0.27450980392156865), 40: np.float64(0.25157232704402516)}
Micro-average F1 score: 0.3632935260842238
Weighted-average F1 score: 0.3499763435957901
F1 score per class: {0: np.float64(0.3954802259887006), 1: np.float64(0.18674698795180722), 2: np.float64(0.11382113821138211), 3: np.float64(0.31620553359683795), 4: np.float64(0.75), 5: np.float64(0.6405228758169934), 6: np.float64(0.3434343434343434), 7: np.float64(0.028169014084507043), 8: np.float64(0.30952380952380953), 9: np.float64(0.6756756756756757), 10: np.float64(0.3067484662576687), 11: np.float64(0.1032258064516129), 12: np.float64(0.2222222222222222), 13: np.float64(0.07692307692307693), 14: np.float64(0.1111111111111111), 15: np.float64(0.26666666666666666), 16: np.float64(0.71875), 17: np.float64(0.0), 18: np.float64(0.13157894736842105), 19: np.float64(0.47619047619047616), 20: np.float64(0.44549763033175355), 21: np.float64(0.1891891891891892), 22: np.float64(0.5171102661596958), 23: np.float64(0.6451612903225806), 24: np.float64(0.08333333333333333), 25: np.float64(0.4722222222222222), 26: np.float64(0.6502463054187192), 27: np.float64(0.0), 28: np.float64(0.24390243902439024), 29: np.float64(0.7924528301886793), 30: np.float64(0.6666666666666666), 31: np.float64(0.08695652173913043), 32: np.float64(0.5099337748344371), 33: np.float64(0.18867924528301888), 34: np.float64(0.3006535947712418), 35: np.float64(0.15053763440860216), 36: np.float64(0.4852941176470588), 37: np.float64(0.2222222222222222), 38: np.float64(0.21052631578947367), 39: np.float64(0.23333333333333334), 40: np.float64(0.2127659574468085)}
Micro-average F1 score: 0.3740268345204572
Weighted-average F1 score: 0.3582895057836547

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.4142857142857143), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.6258503401360545), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8205128205128205), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.42105263157894735), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.3584905660377358), 37: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3106267029972752
Weighted-average F1 score: 0.23213765184872293
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.5222929936305732), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.6258503401360545), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8372093023255814), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.3076923076923077), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.4779874213836478), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.30466321243523314
Weighted-average F1 score: 0.2276016174502104
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.52), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.6143790849673203), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 28: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.8571428571428571), 31: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.37037037037037035), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.45517241379310347), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.3141592920353982
Weighted-average F1 score: 0.23521896246899182

F1 score per class: {0: np.float64(0.44594594594594594), 1: np.float64(0.10909090909090909), 2: np.float64(0.1111111111111111), 3: np.float64(0.26246719160104987), 4: np.float64(0.7023809523809523), 5: np.float64(0.6220735785953178), 6: np.float64(0.24725274725274726), 7: np.float64(0.01652892561983471), 8: np.float64(0.16909620991253643), 9: np.float64(0.625), 10: np.float64(0.20809248554913296), 11: np.float64(0.0673076923076923), 12: np.float64(0.12209302325581395), 13: np.float64(0.04878048780487805), 14: np.float64(0.050505050505050504), 15: np.float64(0.22641509433962265), 16: np.float64(0.42696629213483145), 17: np.float64(0.0), 18: np.float64(0.046153846153846156), 19: np.float64(0.4735202492211838), 20: np.float64(0.2358974358974359), 21: np.float64(0.0), 22: np.float64(0.48360655737704916), 23: np.float64(0.6285714285714286), 24: np.float64(0.0), 25: np.float64(0.30303030303030304), 26: np.float64(0.6028708133971292), 27: np.float64(0.0), 28: np.float64(0.17391304347826086), 29: np.float64(0.622568093385214), 30: np.float64(0.7804878048780488), 31: np.float64(0.13333333333333333), 32: np.float64(0.40641711229946526), 33: np.float64(0.13793103448275862), 34: np.float64(0.18633540372670807), 35: np.float64(0.1016949152542373), 36: np.float64(0.24675324675324675), 37: np.float64(0.1834862385321101), 38: np.float64(0.125), 39: np.float64(0.0975609756097561), 40: np.float64(0.20363636363636364)}
Micro-average F1 score: 0.27798507462686567
Weighted-average F1 score: 0.2600325694697111
F1 score per class: {0: np.float64(0.23076923076923078), 1: np.float64(0.10071942446043165), 2: np.float64(0.06086956521739131), 3: np.float64(0.20612813370473537), 4: np.float64(0.7011494252873564), 5: np.float64(0.31511254019292606), 6: np.float64(0.20761245674740483), 7: np.float64(0.0136986301369863), 8: np.float64(0.15355805243445692), 9: np.float64(0.32051282051282054), 10: np.float64(0.20869565217391303), 11: np.float64(0.10256410256410256), 12: np.float64(0.11218568665377177), 13: np.float64(0.03278688524590164), 14: np.float64(0.08695652173913043), 15: np.float64(0.23529411764705882), 16: np.float64(0.41739130434782606), 17: np.float64(0.0), 18: np.float64(0.0898876404494382), 19: np.float64(0.3541666666666667), 20: np.float64(0.23469387755102042), 21: np.float64(0.08421052631578947), 22: np.float64(0.33109619686800895), 23: np.float64(0.49645390070921985), 24: np.float64(0.05063291139240506), 25: np.float64(0.4358974358974359), 26: np.float64(0.5542168674698795), 27: np.float64(0.0), 28: np.float64(0.0970873786407767), 29: np.float64(0.6176470588235294), 30: np.float64(0.4235294117647059), 31: np.float64(0.03773584905660377), 32: np.float64(0.37089201877934275), 33: np.float64(0.09090909090909091), 34: np.float64(0.188911704312115), 35: np.float64(0.1271393643031785), 36: np.float64(0.29457364341085274), 37: np.float64(0.15584415584415584), 38: np.float64(0.2777777777777778), 39: np.float64(0.14893617021276595), 40: np.float64(0.19900497512437812)}
Micro-average F1 score: 0.2402577158890159
Weighted-average F1 score: 0.22790615397584718
F1 score per class: {0: np.float64(0.26717557251908397), 1: np.float64(0.10316139767054909), 2: np.float64(0.06572769953051644), 3: np.float64(0.19464720194647203), 4: np.float64(0.7100591715976331), 5: np.float64(0.4188034188034188), 6: np.float64(0.2066869300911854), 7: np.float64(0.014814814814814815), 8: np.float64(0.18352941176470589), 9: np.float64(0.5681818181818182), 10: np.float64(0.22935779816513763), 11: np.float64(0.08648648648648649), 12: np.float64(0.11450381679389313), 13: np.float64(0.0547945205479452), 14: np.float64(0.07804878048780488), 15: np.float64(0.17647058823529413), 16: np.float64(0.44660194174757284), 17: np.float64(0.0), 18: np.float64(0.09009009009009009), 19: np.float64(0.40865384615384615), 20: np.float64(0.21962616822429906), 21: np.float64(0.12844036697247707), 22: np.float64(0.4146341463414634), 23: np.float64(0.5405405405405406), 24: np.float64(0.06557377049180328), 25: np.float64(0.4473684210526316), 26: np.float64(0.559322033898305), 27: np.float64(0.0), 28: np.float64(0.12048192771084337), 29: np.float64(0.6245353159851301), 30: np.float64(0.5070422535211268), 31: np.float64(0.05128205128205128), 32: np.float64(0.3710843373493976), 33: np.float64(0.11363636363636363), 34: np.float64(0.17794970986460348), 35: np.float64(0.1033210332103321), 36: np.float64(0.2894736842105263), 37: np.float64(0.16058394160583941), 38: np.float64(0.17391304347826086), 39: np.float64(0.11666666666666667), 40: np.float64(0.17094017094017094)}
Micro-average F1 score: 0.2505826212407058
Weighted-average F1 score: 0.23526807917531214
cur_acc_wo_na:  ['0.7728', '0.2828', '0.6408', '0.5737', '0.4186', '0.3448', '0.3910', '0.4533']
his_acc_wo_na:  ['0.7728', '0.5307', '0.5609', '0.5902', '0.5272', '0.4476', '0.3945', '0.4003']
cur_acc des_wo_na:  ['0.7623', '0.3206', '0.6185', '0.5318', '0.4466', '0.3339', '0.3229', '0.4773']
his_acc des_wo_na:  ['0.7623', '0.5693', '0.5533', '0.5424', '0.5092', '0.4288', '0.3792', '0.3633']
cur_acc rrf_wo_na:  ['0.7725', '0.3099', '0.6287', '0.5498', '0.4517', '0.3715', '0.3510', '0.4846']
his_acc rrf_wo_na:  ['0.7725', '0.5702', '0.5659', '0.5570', '0.5209', '0.4406', '0.3828', '0.3740']
cur_acc_w_na:  ['0.6487', '0.2421', '0.4796', '0.4263', '0.3125', '0.2353', '0.2605', '0.3106']
his_acc_w_na:  ['0.6487', '0.4283', '0.4283', '0.4677', '0.3847', '0.3192', '0.2728', '0.2780']
cur_acc des_w_na:  ['0.6164', '0.2822', '0.4629', '0.3595', '0.3130', '0.2214', '0.2129', '0.3047']
his_acc des_w_na:  ['0.6164', '0.4675', '0.4206', '0.4061', '0.3537', '0.2913', '0.2562', '0.2403']
cur_acc rrf_w_na:  ['0.6289', '0.2724', '0.4703', '0.3756', '0.3235', '0.2472', '0.2337', '0.3142']
his_acc rrf_w_na:  ['0.6289', '0.4681', '0.4316', '0.4214', '0.3669', '0.3037', '0.2614', '0.2506']
--------Round  4
seed:  500
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 5 6 4 2 1 3 0]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 128.2793996CurrentTrain: epoch  0, batch     1 | loss: 81.2739894CurrentTrain: epoch  0, batch     2 | loss: 123.0037855CurrentTrain: epoch  0, batch     3 | loss: 101.9660600CurrentTrain: epoch  0, batch     4 | loss: 101.4356778CurrentTrain: epoch  0, batch     5 | loss: 87.3018636CurrentTrain: epoch  0, batch     6 | loss: 118.9738277CurrentTrain: epoch  0, batch     7 | loss: 99.8740276CurrentTrain: epoch  0, batch     8 | loss: 146.8281385CurrentTrain: epoch  0, batch     9 | loss: 100.2788278CurrentTrain: epoch  0, batch    10 | loss: 118.1309823CurrentTrain: epoch  0, batch    11 | loss: 118.6467762CurrentTrain: epoch  0, batch    12 | loss: 100.3979412CurrentTrain: epoch  0, batch    13 | loss: 119.2788435CurrentTrain: epoch  0, batch    14 | loss: 99.8968966CurrentTrain: epoch  0, batch    15 | loss: 192.8905503CurrentTrain: epoch  0, batch    16 | loss: 119.0957843CurrentTrain: epoch  0, batch    17 | loss: 118.7640077CurrentTrain: epoch  0, batch    18 | loss: 117.7209256CurrentTrain: epoch  0, batch    19 | loss: 99.5949751CurrentTrain: epoch  0, batch    20 | loss: 86.7138715CurrentTrain: epoch  0, batch    21 | loss: 87.5965159CurrentTrain: epoch  0, batch    22 | loss: 99.0166024CurrentTrain: epoch  0, batch    23 | loss: 98.7207699CurrentTrain: epoch  0, batch    24 | loss: 85.5605155CurrentTrain: epoch  0, batch    25 | loss: 116.6559864CurrentTrain: epoch  0, batch    26 | loss: 98.2898751CurrentTrain: epoch  0, batch    27 | loss: 76.0110047CurrentTrain: epoch  0, batch    28 | loss: 117.6017444CurrentTrain: epoch  0, batch    29 | loss: 85.5206788CurrentTrain: epoch  0, batch    30 | loss: 117.4472373CurrentTrain: epoch  0, batch    31 | loss: 85.0785083CurrentTrain: epoch  0, batch    32 | loss: 75.2077010CurrentTrain: epoch  0, batch    33 | loss: 192.0368068CurrentTrain: epoch  0, batch    34 | loss: 84.1994244CurrentTrain: epoch  0, batch    35 | loss: 85.4524903CurrentTrain: epoch  0, batch    36 | loss: 117.4126905CurrentTrain: epoch  0, batch    37 | loss: 74.6573206CurrentTrain: epoch  0, batch    38 | loss: 96.6465419CurrentTrain: epoch  0, batch    39 | loss: 97.0284733CurrentTrain: epoch  0, batch    40 | loss: 97.1396713CurrentTrain: epoch  0, batch    41 | loss: 73.5307142CurrentTrain: epoch  0, batch    42 | loss: 190.5210964CurrentTrain: epoch  0, batch    43 | loss: 74.0887302CurrentTrain: epoch  0, batch    44 | loss: 114.4805100CurrentTrain: epoch  0, batch    45 | loss: 83.1138853CurrentTrain: epoch  0, batch    46 | loss: 96.8998645CurrentTrain: epoch  0, batch    47 | loss: 115.0444820CurrentTrain: epoch  0, batch    48 | loss: 83.0797361CurrentTrain: epoch  0, batch    49 | loss: 95.7589977CurrentTrain: epoch  0, batch    50 | loss: 94.5574482CurrentTrain: epoch  0, batch    51 | loss: 115.6963577CurrentTrain: epoch  0, batch    52 | loss: 83.1907747CurrentTrain: epoch  0, batch    53 | loss: 83.8346218CurrentTrain: epoch  0, batch    54 | loss: 96.9127421CurrentTrain: epoch  0, batch    55 | loss: 81.5910344CurrentTrain: epoch  0, batch    56 | loss: 81.4348046CurrentTrain: epoch  0, batch    57 | loss: 111.8013207CurrentTrain: epoch  0, batch    58 | loss: 112.9476915CurrentTrain: epoch  0, batch    59 | loss: 142.7209524CurrentTrain: epoch  0, batch    60 | loss: 94.3068525CurrentTrain: epoch  0, batch    61 | loss: 94.5386165CurrentTrain: epoch  0, batch    62 | loss: 93.1474474CurrentTrain: epoch  0, batch    63 | loss: 78.4581856CurrentTrain: epoch  0, batch    64 | loss: 95.1640112CurrentTrain: epoch  0, batch    65 | loss: 91.0178149CurrentTrain: epoch  0, batch    66 | loss: 80.1935737CurrentTrain: epoch  0, batch    67 | loss: 70.5178653CurrentTrain: epoch  0, batch    68 | loss: 78.2152578CurrentTrain: epoch  0, batch    69 | loss: 96.6756380CurrentTrain: epoch  0, batch    70 | loss: 113.5340980CurrentTrain: epoch  0, batch    71 | loss: 111.7688736CurrentTrain: epoch  0, batch    72 | loss: 76.4754176CurrentTrain: epoch  0, batch    73 | loss: 107.2961198CurrentTrain: epoch  0, batch    74 | loss: 75.2413355CurrentTrain: epoch  0, batch    75 | loss: 94.0633634CurrentTrain: epoch  0, batch    76 | loss: 141.5950906CurrentTrain: epoch  0, batch    77 | loss: 186.8627886CurrentTrain: epoch  0, batch    78 | loss: 79.9053487CurrentTrain: epoch  0, batch    79 | loss: 79.9142768CurrentTrain: epoch  0, batch    80 | loss: 138.3148778CurrentTrain: epoch  0, batch    81 | loss: 80.9683481CurrentTrain: epoch  0, batch    82 | loss: 142.6086587CurrentTrain: epoch  0, batch    83 | loss: 188.4803646CurrentTrain: epoch  0, batch    84 | loss: 82.5834033CurrentTrain: epoch  0, batch    85 | loss: 68.3636188CurrentTrain: epoch  0, batch    86 | loss: 89.7629179CurrentTrain: epoch  0, batch    87 | loss: 66.3248880CurrentTrain: epoch  0, batch    88 | loss: 113.4804551CurrentTrain: epoch  0, batch    89 | loss: 78.4120638CurrentTrain: epoch  0, batch    90 | loss: 91.4260653CurrentTrain: epoch  0, batch    91 | loss: 110.7093849CurrentTrain: epoch  0, batch    92 | loss: 94.3406952CurrentTrain: epoch  0, batch    93 | loss: 113.1283713CurrentTrain: epoch  0, batch    94 | loss: 87.2420037CurrentTrain: epoch  0, batch    95 | loss: 77.0341462CurrentTrain: epoch  1, batch     0 | loss: 81.0735648CurrentTrain: epoch  1, batch     1 | loss: 91.1906277CurrentTrain: epoch  1, batch     2 | loss: 68.8481272CurrentTrain: epoch  1, batch     3 | loss: 139.4923596CurrentTrain: epoch  1, batch     4 | loss: 111.1340827CurrentTrain: epoch  1, batch     5 | loss: 91.3228228CurrentTrain: epoch  1, batch     6 | loss: 138.4551725CurrentTrain: epoch  1, batch     7 | loss: 75.4479472CurrentTrain: epoch  1, batch     8 | loss: 89.8927784CurrentTrain: epoch  1, batch     9 | loss: 91.5588478CurrentTrain: epoch  1, batch    10 | loss: 87.9280383CurrentTrain: epoch  1, batch    11 | loss: 90.2637187CurrentTrain: epoch  1, batch    12 | loss: 184.7855560CurrentTrain: epoch  1, batch    13 | loss: 78.7005848CurrentTrain: epoch  1, batch    14 | loss: 73.7347199CurrentTrain: epoch  1, batch    15 | loss: 92.1894861CurrentTrain: epoch  1, batch    16 | loss: 66.2740938CurrentTrain: epoch  1, batch    17 | loss: 77.8361699CurrentTrain: epoch  1, batch    18 | loss: 62.6113176CurrentTrain: epoch  1, batch    19 | loss: 109.4812789CurrentTrain: epoch  1, batch    20 | loss: 85.1949729CurrentTrain: epoch  1, batch    21 | loss: 91.3261495CurrentTrain: epoch  1, batch    22 | loss: 74.0504072CurrentTrain: epoch  1, batch    23 | loss: 109.6904035CurrentTrain: epoch  1, batch    24 | loss: 92.8018196CurrentTrain: epoch  1, batch    25 | loss: 103.1961733CurrentTrain: epoch  1, batch    26 | loss: 101.0339405CurrentTrain: epoch  1, batch    27 | loss: 89.6128948CurrentTrain: epoch  1, batch    28 | loss: 91.0871427CurrentTrain: epoch  1, batch    29 | loss: 89.0153165CurrentTrain: epoch  1, batch    30 | loss: 88.5041342CurrentTrain: epoch  1, batch    31 | loss: 106.6659245CurrentTrain: epoch  1, batch    32 | loss: 75.8463385CurrentTrain: epoch  1, batch    33 | loss: 106.1430216CurrentTrain: epoch  1, batch    34 | loss: 88.1049702CurrentTrain: epoch  1, batch    35 | loss: 87.5825037CurrentTrain: epoch  1, batch    36 | loss: 77.6760454CurrentTrain: epoch  1, batch    37 | loss: 85.2230914CurrentTrain: epoch  1, batch    38 | loss: 66.9068938CurrentTrain: epoch  1, batch    39 | loss: 108.9125061CurrentTrain: epoch  1, batch    40 | loss: 106.8579627CurrentTrain: epoch  1, batch    41 | loss: 106.8094887CurrentTrain: epoch  1, batch    42 | loss: 89.5998079CurrentTrain: epoch  1, batch    43 | loss: 87.0454210CurrentTrain: epoch  1, batch    44 | loss: 90.2452318CurrentTrain: epoch  1, batch    45 | loss: 134.9430418CurrentTrain: epoch  1, batch    46 | loss: 83.1950194CurrentTrain: epoch  1, batch    47 | loss: 104.0289307CurrentTrain: epoch  1, batch    48 | loss: 108.6678223CurrentTrain: epoch  1, batch    49 | loss: 108.2402638CurrentTrain: epoch  1, batch    50 | loss: 78.1207033CurrentTrain: epoch  1, batch    51 | loss: 112.0911422CurrentTrain: epoch  1, batch    52 | loss: 86.3654064CurrentTrain: epoch  1, batch    53 | loss: 92.1609331CurrentTrain: epoch  1, batch    54 | loss: 139.8068063CurrentTrain: epoch  1, batch    55 | loss: 83.5342387CurrentTrain: epoch  1, batch    56 | loss: 70.2761941CurrentTrain: epoch  1, batch    57 | loss: 106.3731300CurrentTrain: epoch  1, batch    58 | loss: 88.0989318CurrentTrain: epoch  1, batch    59 | loss: 85.0934085CurrentTrain: epoch  1, batch    60 | loss: 71.2925465CurrentTrain: epoch  1, batch    61 | loss: 90.3571170CurrentTrain: epoch  1, batch    62 | loss: 104.2114767CurrentTrain: epoch  1, batch    63 | loss: 86.6157472CurrentTrain: epoch  1, batch    64 | loss: 86.4885584CurrentTrain: epoch  1, batch    65 | loss: 76.6995869CurrentTrain: epoch  1, batch    66 | loss: 89.5924768CurrentTrain: epoch  1, batch    67 | loss: 74.8201929CurrentTrain: epoch  1, batch    68 | loss: 76.1742300CurrentTrain: epoch  1, batch    69 | loss: 108.0726979CurrentTrain: epoch  1, batch    70 | loss: 105.6060971CurrentTrain: epoch  1, batch    71 | loss: 74.6096208CurrentTrain: epoch  1, batch    72 | loss: 182.8727646CurrentTrain: epoch  1, batch    73 | loss: 65.3283673CurrentTrain: epoch  1, batch    74 | loss: 75.7646763CurrentTrain: epoch  1, batch    75 | loss: 106.3668534CurrentTrain: epoch  1, batch    76 | loss: 107.0662706CurrentTrain: epoch  1, batch    77 | loss: 105.7303133CurrentTrain: epoch  1, batch    78 | loss: 104.1599188CurrentTrain: epoch  1, batch    79 | loss: 73.8111685CurrentTrain: epoch  1, batch    80 | loss: 92.1722456CurrentTrain: epoch  1, batch    81 | loss: 63.9720386CurrentTrain: epoch  1, batch    82 | loss: 77.7086196CurrentTrain: epoch  1, batch    83 | loss: 74.2514213CurrentTrain: epoch  1, batch    84 | loss: 84.5596568CurrentTrain: epoch  1, batch    85 | loss: 106.4338341CurrentTrain: epoch  1, batch    86 | loss: 92.9703762CurrentTrain: epoch  1, batch    87 | loss: 89.4400552CurrentTrain: epoch  1, batch    88 | loss: 108.6037848CurrentTrain: epoch  1, batch    89 | loss: 184.9038244CurrentTrain: epoch  1, batch    90 | loss: 87.3029025CurrentTrain: epoch  1, batch    91 | loss: 137.8006797CurrentTrain: epoch  1, batch    92 | loss: 108.8132919CurrentTrain: epoch  1, batch    93 | loss: 72.0526842CurrentTrain: epoch  1, batch    94 | loss: 103.7576460CurrentTrain: epoch  1, batch    95 | loss: 75.2853186CurrentTrain: epoch  2, batch     0 | loss: 105.5053086CurrentTrain: epoch  2, batch     1 | loss: 131.2262643CurrentTrain: epoch  2, batch     2 | loss: 88.2660253CurrentTrain: epoch  2, batch     3 | loss: 110.8716150CurrentTrain: epoch  2, batch     4 | loss: 87.4804460CurrentTrain: epoch  2, batch     5 | loss: 90.7803065CurrentTrain: epoch  2, batch     6 | loss: 85.9610319CurrentTrain: epoch  2, batch     7 | loss: 88.3004352CurrentTrain: epoch  2, batch     8 | loss: 86.7563686CurrentTrain: epoch  2, batch     9 | loss: 69.2157280CurrentTrain: epoch  2, batch    10 | loss: 103.4535850CurrentTrain: epoch  2, batch    11 | loss: 65.9709442CurrentTrain: epoch  2, batch    12 | loss: 134.9427475CurrentTrain: epoch  2, batch    13 | loss: 72.4967482CurrentTrain: epoch  2, batch    14 | loss: 72.2464311CurrentTrain: epoch  2, batch    15 | loss: 71.9732855CurrentTrain: epoch  2, batch    16 | loss: 104.5672588CurrentTrain: epoch  2, batch    17 | loss: 87.3683618CurrentTrain: epoch  2, batch    18 | loss: 107.2875029CurrentTrain: epoch  2, batch    19 | loss: 84.5507707CurrentTrain: epoch  2, batch    20 | loss: 104.5646696CurrentTrain: epoch  2, batch    21 | loss: 87.2613335CurrentTrain: epoch  2, batch    22 | loss: 137.8139814CurrentTrain: epoch  2, batch    23 | loss: 102.0577621CurrentTrain: epoch  2, batch    24 | loss: 88.7754139CurrentTrain: epoch  2, batch    25 | loss: 104.4741986CurrentTrain: epoch  2, batch    26 | loss: 106.4346801CurrentTrain: epoch  2, batch    27 | loss: 89.5957110CurrentTrain: epoch  2, batch    28 | loss: 91.4678380CurrentTrain: epoch  2, batch    29 | loss: 108.4844244CurrentTrain: epoch  2, batch    30 | loss: 73.6249072CurrentTrain: epoch  2, batch    31 | loss: 77.5719656CurrentTrain: epoch  2, batch    32 | loss: 86.0101569CurrentTrain: epoch  2, batch    33 | loss: 75.0718100CurrentTrain: epoch  2, batch    34 | loss: 88.9309347CurrentTrain: epoch  2, batch    35 | loss: 106.6003387CurrentTrain: epoch  2, batch    36 | loss: 84.8837213CurrentTrain: epoch  2, batch    37 | loss: 70.4753446CurrentTrain: epoch  2, batch    38 | loss: 64.3808195CurrentTrain: epoch  2, batch    39 | loss: 71.2351356CurrentTrain: epoch  2, batch    40 | loss: 84.8274847CurrentTrain: epoch  2, batch    41 | loss: 86.7158214CurrentTrain: epoch  2, batch    42 | loss: 85.8560315CurrentTrain: epoch  2, batch    43 | loss: 87.3751597CurrentTrain: epoch  2, batch    44 | loss: 88.7673709CurrentTrain: epoch  2, batch    45 | loss: 85.6794965CurrentTrain: epoch  2, batch    46 | loss: 84.0663085CurrentTrain: epoch  2, batch    47 | loss: 131.3225142CurrentTrain: epoch  2, batch    48 | loss: 133.1343573CurrentTrain: epoch  2, batch    49 | loss: 68.1002307CurrentTrain: epoch  2, batch    50 | loss: 63.1775526CurrentTrain: epoch  2, batch    51 | loss: 72.7101754CurrentTrain: epoch  2, batch    52 | loss: 73.2509302CurrentTrain: epoch  2, batch    53 | loss: 69.5091320CurrentTrain: epoch  2, batch    54 | loss: 82.7699066CurrentTrain: epoch  2, batch    55 | loss: 103.1724798CurrentTrain: epoch  2, batch    56 | loss: 71.9707130CurrentTrain: epoch  2, batch    57 | loss: 102.9371613CurrentTrain: epoch  2, batch    58 | loss: 132.2369036CurrentTrain: epoch  2, batch    59 | loss: 70.8019958CurrentTrain: epoch  2, batch    60 | loss: 88.2897670CurrentTrain: epoch  2, batch    61 | loss: 88.6337396CurrentTrain: epoch  2, batch    62 | loss: 71.1609187CurrentTrain: epoch  2, batch    63 | loss: 74.9526593CurrentTrain: epoch  2, batch    64 | loss: 79.7181344CurrentTrain: epoch  2, batch    65 | loss: 60.3069740CurrentTrain: epoch  2, batch    66 | loss: 102.3680803CurrentTrain: epoch  2, batch    67 | loss: 71.7940848CurrentTrain: epoch  2, batch    68 | loss: 88.5963678CurrentTrain: epoch  2, batch    69 | loss: 87.0547134CurrentTrain: epoch  2, batch    70 | loss: 90.2530801CurrentTrain: epoch  2, batch    71 | loss: 128.8149229CurrentTrain: epoch  2, batch    72 | loss: 60.3958457CurrentTrain: epoch  2, batch    73 | loss: 103.7763790CurrentTrain: epoch  2, batch    74 | loss: 61.1485771CurrentTrain: epoch  2, batch    75 | loss: 85.9929333CurrentTrain: epoch  2, batch    76 | loss: 68.9887010CurrentTrain: epoch  2, batch    77 | loss: 64.5169591CurrentTrain: epoch  2, batch    78 | loss: 132.8582491CurrentTrain: epoch  2, batch    79 | loss: 104.5853692CurrentTrain: epoch  2, batch    80 | loss: 63.1505676CurrentTrain: epoch  2, batch    81 | loss: 77.3892145CurrentTrain: epoch  2, batch    82 | loss: 63.2207898CurrentTrain: epoch  2, batch    83 | loss: 84.6431770CurrentTrain: epoch  2, batch    84 | loss: 104.5650017CurrentTrain: epoch  2, batch    85 | loss: 70.2566716CurrentTrain: epoch  2, batch    86 | loss: 65.4542496CurrentTrain: epoch  2, batch    87 | loss: 83.7270311CurrentTrain: epoch  2, batch    88 | loss: 137.1586345CurrentTrain: epoch  2, batch    89 | loss: 74.8282426CurrentTrain: epoch  2, batch    90 | loss: 105.8422608CurrentTrain: epoch  2, batch    91 | loss: 106.8743396CurrentTrain: epoch  2, batch    92 | loss: 83.4861899CurrentTrain: epoch  2, batch    93 | loss: 88.8152086CurrentTrain: epoch  2, batch    94 | loss: 106.1926269CurrentTrain: epoch  2, batch    95 | loss: 72.7433320CurrentTrain: epoch  3, batch     0 | loss: 102.6253640CurrentTrain: epoch  3, batch     1 | loss: 82.2597486CurrentTrain: epoch  3, batch     2 | loss: 84.6264471CurrentTrain: epoch  3, batch     3 | loss: 73.4187987CurrentTrain: epoch  3, batch     4 | loss: 71.9952819CurrentTrain: epoch  3, batch     5 | loss: 82.9145813CurrentTrain: epoch  3, batch     6 | loss: 85.8155225CurrentTrain: epoch  3, batch     7 | loss: 126.8345275CurrentTrain: epoch  3, batch     8 | loss: 60.2307945CurrentTrain: epoch  3, batch     9 | loss: 106.8665077CurrentTrain: epoch  3, batch    10 | loss: 77.3179263CurrentTrain: epoch  3, batch    11 | loss: 69.4896501CurrentTrain: epoch  3, batch    12 | loss: 125.3245036CurrentTrain: epoch  3, batch    13 | loss: 72.4493757CurrentTrain: epoch  3, batch    14 | loss: 175.0989979CurrentTrain: epoch  3, batch    15 | loss: 132.0576425CurrentTrain: epoch  3, batch    16 | loss: 99.6292281CurrentTrain: epoch  3, batch    17 | loss: 85.4542081CurrentTrain: epoch  3, batch    18 | loss: 69.2901176CurrentTrain: epoch  3, batch    19 | loss: 71.5658854CurrentTrain: epoch  3, batch    20 | loss: 125.7857746CurrentTrain: epoch  3, batch    21 | loss: 69.6962735CurrentTrain: epoch  3, batch    22 | loss: 71.1848648CurrentTrain: epoch  3, batch    23 | loss: 73.3545083CurrentTrain: epoch  3, batch    24 | loss: 84.5385619CurrentTrain: epoch  3, batch    25 | loss: 88.8487394CurrentTrain: epoch  3, batch    26 | loss: 64.8067597CurrentTrain: epoch  3, batch    27 | loss: 66.0511528CurrentTrain: epoch  3, batch    28 | loss: 86.4468183CurrentTrain: epoch  3, batch    29 | loss: 68.4757139CurrentTrain: epoch  3, batch    30 | loss: 73.8498267CurrentTrain: epoch  3, batch    31 | loss: 84.1122870CurrentTrain: epoch  3, batch    32 | loss: 86.3647537CurrentTrain: epoch  3, batch    33 | loss: 81.2704593CurrentTrain: epoch  3, batch    34 | loss: 84.9707447CurrentTrain: epoch  3, batch    35 | loss: 82.3701053CurrentTrain: epoch  3, batch    36 | loss: 80.7763956CurrentTrain: epoch  3, batch    37 | loss: 100.9952087CurrentTrain: epoch  3, batch    38 | loss: 111.6132770CurrentTrain: epoch  3, batch    39 | loss: 86.6510790CurrentTrain: epoch  3, batch    40 | loss: 62.8417919CurrentTrain: epoch  3, batch    41 | loss: 103.0891222CurrentTrain: epoch  3, batch    42 | loss: 89.1776098CurrentTrain: epoch  3, batch    43 | loss: 72.3770779CurrentTrain: epoch  3, batch    44 | loss: 86.3032774CurrentTrain: epoch  3, batch    45 | loss: 85.6849779CurrentTrain: epoch  3, batch    46 | loss: 73.4134788CurrentTrain: epoch  3, batch    47 | loss: 80.9911195CurrentTrain: epoch  3, batch    48 | loss: 66.1778919CurrentTrain: epoch  3, batch    49 | loss: 75.2252458CurrentTrain: epoch  3, batch    50 | loss: 70.5582867CurrentTrain: epoch  3, batch    51 | loss: 80.5702713CurrentTrain: epoch  3, batch    52 | loss: 86.5658599CurrentTrain: epoch  3, batch    53 | loss: 83.7560909CurrentTrain: epoch  3, batch    54 | loss: 72.6810516CurrentTrain: epoch  3, batch    55 | loss: 135.4019351CurrentTrain: epoch  3, batch    56 | loss: 81.7478441CurrentTrain: epoch  3, batch    57 | loss: 98.5708972CurrentTrain: epoch  3, batch    58 | loss: 60.9679864CurrentTrain: epoch  3, batch    59 | loss: 101.8583033CurrentTrain: epoch  3, batch    60 | loss: 84.5915793CurrentTrain: epoch  3, batch    61 | loss: 84.9558070CurrentTrain: epoch  3, batch    62 | loss: 182.0354460CurrentTrain: epoch  3, batch    63 | loss: 85.5883908CurrentTrain: epoch  3, batch    64 | loss: 83.8965379CurrentTrain: epoch  3, batch    65 | loss: 106.3321670CurrentTrain: epoch  3, batch    66 | loss: 77.5045042CurrentTrain: epoch  3, batch    67 | loss: 67.9953623CurrentTrain: epoch  3, batch    68 | loss: 71.9996546CurrentTrain: epoch  3, batch    69 | loss: 71.7523816CurrentTrain: epoch  3, batch    70 | loss: 57.4069389CurrentTrain: epoch  3, batch    71 | loss: 79.3837117CurrentTrain: epoch  3, batch    72 | loss: 78.1703692CurrentTrain: epoch  3, batch    73 | loss: 86.2231347CurrentTrain: epoch  3, batch    74 | loss: 107.4084319CurrentTrain: epoch  3, batch    75 | loss: 84.7521286CurrentTrain: epoch  3, batch    76 | loss: 87.1781695CurrentTrain: epoch  3, batch    77 | loss: 87.3530922CurrentTrain: epoch  3, batch    78 | loss: 72.9026043CurrentTrain: epoch  3, batch    79 | loss: 103.5157867CurrentTrain: epoch  3, batch    80 | loss: 71.2369977CurrentTrain: epoch  3, batch    81 | loss: 99.8925538CurrentTrain: epoch  3, batch    82 | loss: 101.8937892CurrentTrain: epoch  3, batch    83 | loss: 64.4751918CurrentTrain: epoch  3, batch    84 | loss: 88.6071819CurrentTrain: epoch  3, batch    85 | loss: 127.8111656CurrentTrain: epoch  3, batch    86 | loss: 71.6133501CurrentTrain: epoch  3, batch    87 | loss: 101.9874236CurrentTrain: epoch  3, batch    88 | loss: 105.1783989CurrentTrain: epoch  3, batch    89 | loss: 80.0016203CurrentTrain: epoch  3, batch    90 | loss: 82.1870899CurrentTrain: epoch  3, batch    91 | loss: 85.2300428CurrentTrain: epoch  3, batch    92 | loss: 102.9878927CurrentTrain: epoch  3, batch    93 | loss: 74.6841806CurrentTrain: epoch  3, batch    94 | loss: 68.9888585CurrentTrain: epoch  3, batch    95 | loss: 76.5275009CurrentTrain: epoch  4, batch     0 | loss: 81.5471173CurrentTrain: epoch  4, batch     1 | loss: 61.3528192CurrentTrain: epoch  4, batch     2 | loss: 66.6225637CurrentTrain: epoch  4, batch     3 | loss: 169.4083756CurrentTrain: epoch  4, batch     4 | loss: 97.6072987CurrentTrain: epoch  4, batch     5 | loss: 76.4084200CurrentTrain: epoch  4, batch     6 | loss: 72.5155517CurrentTrain: epoch  4, batch     7 | loss: 80.6695905CurrentTrain: epoch  4, batch     8 | loss: 97.8517090CurrentTrain: epoch  4, batch     9 | loss: 70.8258432CurrentTrain: epoch  4, batch    10 | loss: 102.0667598CurrentTrain: epoch  4, batch    11 | loss: 69.9334598CurrentTrain: epoch  4, batch    12 | loss: 83.7713083CurrentTrain: epoch  4, batch    13 | loss: 69.4212330CurrentTrain: epoch  4, batch    14 | loss: 99.9149828CurrentTrain: epoch  4, batch    15 | loss: 105.5540553CurrentTrain: epoch  4, batch    16 | loss: 132.9580277CurrentTrain: epoch  4, batch    17 | loss: 124.8468955CurrentTrain: epoch  4, batch    18 | loss: 83.5943028CurrentTrain: epoch  4, batch    19 | loss: 69.5406737CurrentTrain: epoch  4, batch    20 | loss: 68.2847290CurrentTrain: epoch  4, batch    21 | loss: 128.2056670CurrentTrain: epoch  4, batch    22 | loss: 103.0087894CurrentTrain: epoch  4, batch    23 | loss: 81.0854429CurrentTrain: epoch  4, batch    24 | loss: 99.9735637CurrentTrain: epoch  4, batch    25 | loss: 66.5909658CurrentTrain: epoch  4, batch    26 | loss: 85.7831468CurrentTrain: epoch  4, batch    27 | loss: 100.6157564CurrentTrain: epoch  4, batch    28 | loss: 125.6542060CurrentTrain: epoch  4, batch    29 | loss: 78.9633232CurrentTrain: epoch  4, batch    30 | loss: 83.6915239CurrentTrain: epoch  4, batch    31 | loss: 67.8751483CurrentTrain: epoch  4, batch    32 | loss: 86.1555172CurrentTrain: epoch  4, batch    33 | loss: 61.6490964CurrentTrain: epoch  4, batch    34 | loss: 102.8518609CurrentTrain: epoch  4, batch    35 | loss: 85.6571210CurrentTrain: epoch  4, batch    36 | loss: 105.7780940CurrentTrain: epoch  4, batch    37 | loss: 74.9924344CurrentTrain: epoch  4, batch    38 | loss: 84.7820761CurrentTrain: epoch  4, batch    39 | loss: 65.7451974CurrentTrain: epoch  4, batch    40 | loss: 71.5947439CurrentTrain: epoch  4, batch    41 | loss: 82.4795941CurrentTrain: epoch  4, batch    42 | loss: 61.3138312CurrentTrain: epoch  4, batch    43 | loss: 103.3110908CurrentTrain: epoch  4, batch    44 | loss: 80.6674322CurrentTrain: epoch  4, batch    45 | loss: 98.1395027CurrentTrain: epoch  4, batch    46 | loss: 85.8191604CurrentTrain: epoch  4, batch    47 | loss: 126.3699548CurrentTrain: epoch  4, batch    48 | loss: 99.6806423CurrentTrain: epoch  4, batch    49 | loss: 67.8726882CurrentTrain: epoch  4, batch    50 | loss: 85.4487028CurrentTrain: epoch  4, batch    51 | loss: 128.9225562CurrentTrain: epoch  4, batch    52 | loss: 74.4350266CurrentTrain: epoch  4, batch    53 | loss: 83.8347181CurrentTrain: epoch  4, batch    54 | loss: 101.8326705CurrentTrain: epoch  4, batch    55 | loss: 98.3247990CurrentTrain: epoch  4, batch    56 | loss: 77.9739361CurrentTrain: epoch  4, batch    57 | loss: 86.9473150CurrentTrain: epoch  4, batch    58 | loss: 84.1206721CurrentTrain: epoch  4, batch    59 | loss: 70.9481005CurrentTrain: epoch  4, batch    60 | loss: 82.5168192CurrentTrain: epoch  4, batch    61 | loss: 62.7027028CurrentTrain: epoch  4, batch    62 | loss: 65.6329278CurrentTrain: epoch  4, batch    63 | loss: 85.1359207CurrentTrain: epoch  4, batch    64 | loss: 101.1307039CurrentTrain: epoch  4, batch    65 | loss: 67.4969859CurrentTrain: epoch  4, batch    66 | loss: 102.4151801CurrentTrain: epoch  4, batch    67 | loss: 68.6529027CurrentTrain: epoch  4, batch    68 | loss: 85.7264906CurrentTrain: epoch  4, batch    69 | loss: 77.2806167CurrentTrain: epoch  4, batch    70 | loss: 60.2064448CurrentTrain: epoch  4, batch    71 | loss: 103.5070205CurrentTrain: epoch  4, batch    72 | loss: 176.5686522CurrentTrain: epoch  4, batch    73 | loss: 68.5169506CurrentTrain: epoch  4, batch    74 | loss: 101.7279473CurrentTrain: epoch  4, batch    75 | loss: 74.7324791CurrentTrain: epoch  4, batch    76 | loss: 59.6569190CurrentTrain: epoch  4, batch    77 | loss: 83.7740263CurrentTrain: epoch  4, batch    78 | loss: 63.5197958CurrentTrain: epoch  4, batch    79 | loss: 83.0824628CurrentTrain: epoch  4, batch    80 | loss: 127.9503608CurrentTrain: epoch  4, batch    81 | loss: 82.3948966CurrentTrain: epoch  4, batch    82 | loss: 71.3995361CurrentTrain: epoch  4, batch    83 | loss: 129.1856954CurrentTrain: epoch  4, batch    84 | loss: 78.2593868CurrentTrain: epoch  4, batch    85 | loss: 103.8625279CurrentTrain: epoch  4, batch    86 | loss: 102.6497781CurrentTrain: epoch  4, batch    87 | loss: 83.2499828CurrentTrain: epoch  4, batch    88 | loss: 81.4378725CurrentTrain: epoch  4, batch    89 | loss: 71.1776287CurrentTrain: epoch  4, batch    90 | loss: 70.8547351CurrentTrain: epoch  4, batch    91 | loss: 135.5756530CurrentTrain: epoch  4, batch    92 | loss: 70.5988777CurrentTrain: epoch  4, batch    93 | loss: 69.7187353CurrentTrain: epoch  4, batch    94 | loss: 102.8700359CurrentTrain: epoch  4, batch    95 | loss: 46.4007420CurrentTrain: epoch  5, batch     0 | loss: 78.9147148CurrentTrain: epoch  5, batch     1 | loss: 62.5212156CurrentTrain: epoch  5, batch     2 | loss: 67.1195952CurrentTrain: epoch  5, batch     3 | loss: 124.9439596CurrentTrain: epoch  5, batch     4 | loss: 94.3642246CurrentTrain: epoch  5, batch     5 | loss: 93.4751041CurrentTrain: epoch  5, batch     6 | loss: 100.0079325CurrentTrain: epoch  5, batch     7 | loss: 78.0477909CurrentTrain: epoch  5, batch     8 | loss: 56.4850409CurrentTrain: epoch  5, batch     9 | loss: 103.5660725CurrentTrain: epoch  5, batch    10 | loss: 128.3312497CurrentTrain: epoch  5, batch    11 | loss: 79.0085982CurrentTrain: epoch  5, batch    12 | loss: 98.1666794CurrentTrain: epoch  5, batch    13 | loss: 71.6080131CurrentTrain: epoch  5, batch    14 | loss: 78.6636867CurrentTrain: epoch  5, batch    15 | loss: 81.2790602CurrentTrain: epoch  5, batch    16 | loss: 80.2517562CurrentTrain: epoch  5, batch    17 | loss: 81.1448281CurrentTrain: epoch  5, batch    18 | loss: 85.3621383CurrentTrain: epoch  5, batch    19 | loss: 124.1107319CurrentTrain: epoch  5, batch    20 | loss: 79.3448212CurrentTrain: epoch  5, batch    21 | loss: 100.2009559CurrentTrain: epoch  5, batch    22 | loss: 79.0660327CurrentTrain: epoch  5, batch    23 | loss: 91.8155377CurrentTrain: epoch  5, batch    24 | loss: 101.9383368CurrentTrain: epoch  5, batch    25 | loss: 81.6016014CurrentTrain: epoch  5, batch    26 | loss: 67.5716553CurrentTrain: epoch  5, batch    27 | loss: 95.5263989CurrentTrain: epoch  5, batch    28 | loss: 101.8031626CurrentTrain: epoch  5, batch    29 | loss: 69.8177021CurrentTrain: epoch  5, batch    30 | loss: 105.7176755CurrentTrain: epoch  5, batch    31 | loss: 81.6434008CurrentTrain: epoch  5, batch    32 | loss: 69.1757809CurrentTrain: epoch  5, batch    33 | loss: 85.5105034CurrentTrain: epoch  5, batch    34 | loss: 79.4307230CurrentTrain: epoch  5, batch    35 | loss: 80.1874799CurrentTrain: epoch  5, batch    36 | loss: 68.7630576CurrentTrain: epoch  5, batch    37 | loss: 70.4309997CurrentTrain: epoch  5, batch    38 | loss: 100.9913230CurrentTrain: epoch  5, batch    39 | loss: 57.4819235CurrentTrain: epoch  5, batch    40 | loss: 81.1701020CurrentTrain: epoch  5, batch    41 | loss: 57.6228763CurrentTrain: epoch  5, batch    42 | loss: 71.7535573CurrentTrain: epoch  5, batch    43 | loss: 55.8782739CurrentTrain: epoch  5, batch    44 | loss: 58.6735924CurrentTrain: epoch  5, batch    45 | loss: 84.4044433CurrentTrain: epoch  5, batch    46 | loss: 99.6261915CurrentTrain: epoch  5, batch    47 | loss: 101.8642324CurrentTrain: epoch  5, batch    48 | loss: 124.0713501CurrentTrain: epoch  5, batch    49 | loss: 98.2256109CurrentTrain: epoch  5, batch    50 | loss: 81.9315584CurrentTrain: epoch  5, batch    51 | loss: 82.5040650CurrentTrain: epoch  5, batch    52 | loss: 125.8973062CurrentTrain: epoch  5, batch    53 | loss: 87.2943785CurrentTrain: epoch  5, batch    54 | loss: 65.5888712CurrentTrain: epoch  5, batch    55 | loss: 102.1871382CurrentTrain: epoch  5, batch    56 | loss: 59.5492651CurrentTrain: epoch  5, batch    57 | loss: 96.9565754CurrentTrain: epoch  5, batch    58 | loss: 127.4150651CurrentTrain: epoch  5, batch    59 | loss: 94.8014505CurrentTrain: epoch  5, batch    60 | loss: 67.2940798CurrentTrain: epoch  5, batch    61 | loss: 71.1428090CurrentTrain: epoch  5, batch    62 | loss: 85.0995036CurrentTrain: epoch  5, batch    63 | loss: 64.8929345CurrentTrain: epoch  5, batch    64 | loss: 88.1037585CurrentTrain: epoch  5, batch    65 | loss: 77.6873867CurrentTrain: epoch  5, batch    66 | loss: 83.1482536CurrentTrain: epoch  5, batch    67 | loss: 85.2464596CurrentTrain: epoch  5, batch    68 | loss: 100.3089320CurrentTrain: epoch  5, batch    69 | loss: 65.2826969CurrentTrain: epoch  5, batch    70 | loss: 79.2207656CurrentTrain: epoch  5, batch    71 | loss: 126.2693049CurrentTrain: epoch  5, batch    72 | loss: 56.5944166CurrentTrain: epoch  5, batch    73 | loss: 58.1905794CurrentTrain: epoch  5, batch    74 | loss: 72.7243798CurrentTrain: epoch  5, batch    75 | loss: 65.1424034CurrentTrain: epoch  5, batch    76 | loss: 71.2084532CurrentTrain: epoch  5, batch    77 | loss: 72.2542461CurrentTrain: epoch  5, batch    78 | loss: 57.7922709CurrentTrain: epoch  5, batch    79 | loss: 68.1275770CurrentTrain: epoch  5, batch    80 | loss: 79.2825988CurrentTrain: epoch  5, batch    81 | loss: 99.4083427CurrentTrain: epoch  5, batch    82 | loss: 76.4827277CurrentTrain: epoch  5, batch    83 | loss: 123.8593552CurrentTrain: epoch  5, batch    84 | loss: 54.8960649CurrentTrain: epoch  5, batch    85 | loss: 98.8108274CurrentTrain: epoch  5, batch    86 | loss: 86.1058663CurrentTrain: epoch  5, batch    87 | loss: 128.7788527CurrentTrain: epoch  5, batch    88 | loss: 68.0809322CurrentTrain: epoch  5, batch    89 | loss: 101.1111267CurrentTrain: epoch  5, batch    90 | loss: 130.1832351CurrentTrain: epoch  5, batch    91 | loss: 99.3904763CurrentTrain: epoch  5, batch    92 | loss: 79.7957608CurrentTrain: epoch  5, batch    93 | loss: 72.3327969CurrentTrain: epoch  5, batch    94 | loss: 57.8265949CurrentTrain: epoch  5, batch    95 | loss: 81.1903188CurrentTrain: epoch  6, batch     0 | loss: 79.8160074CurrentTrain: epoch  6, batch     1 | loss: 82.3515450CurrentTrain: epoch  6, batch     2 | loss: 79.2160506CurrentTrain: epoch  6, batch     3 | loss: 78.7332903CurrentTrain: epoch  6, batch     4 | loss: 102.1111706CurrentTrain: epoch  6, batch     5 | loss: 79.2769870CurrentTrain: epoch  6, batch     6 | loss: 74.0200225CurrentTrain: epoch  6, batch     7 | loss: 82.7531427CurrentTrain: epoch  6, batch     8 | loss: 64.7594032CurrentTrain: epoch  6, batch     9 | loss: 96.5723648CurrentTrain: epoch  6, batch    10 | loss: 65.9188904CurrentTrain: epoch  6, batch    11 | loss: 66.4273743CurrentTrain: epoch  6, batch    12 | loss: 65.5079492CurrentTrain: epoch  6, batch    13 | loss: 100.1069251CurrentTrain: epoch  6, batch    14 | loss: 69.4764118CurrentTrain: epoch  6, batch    15 | loss: 68.7789492CurrentTrain: epoch  6, batch    16 | loss: 88.9242538CurrentTrain: epoch  6, batch    17 | loss: 98.1603534CurrentTrain: epoch  6, batch    18 | loss: 65.6623583CurrentTrain: epoch  6, batch    19 | loss: 126.1237483CurrentTrain: epoch  6, batch    20 | loss: 67.7783676CurrentTrain: epoch  6, batch    21 | loss: 54.5983678CurrentTrain: epoch  6, batch    22 | loss: 67.3047103CurrentTrain: epoch  6, batch    23 | loss: 68.8851517CurrentTrain: epoch  6, batch    24 | loss: 76.6635298CurrentTrain: epoch  6, batch    25 | loss: 97.5144292CurrentTrain: epoch  6, batch    26 | loss: 93.2558743CurrentTrain: epoch  6, batch    27 | loss: 77.5023560CurrentTrain: epoch  6, batch    28 | loss: 98.1991235CurrentTrain: epoch  6, batch    29 | loss: 79.9955192CurrentTrain: epoch  6, batch    30 | loss: 81.7558443CurrentTrain: epoch  6, batch    31 | loss: 100.7085975CurrentTrain: epoch  6, batch    32 | loss: 98.7691946CurrentTrain: epoch  6, batch    33 | loss: 81.3512427CurrentTrain: epoch  6, batch    34 | loss: 98.3516821CurrentTrain: epoch  6, batch    35 | loss: 84.3102668CurrentTrain: epoch  6, batch    36 | loss: 119.1839268CurrentTrain: epoch  6, batch    37 | loss: 100.8670564CurrentTrain: epoch  6, batch    38 | loss: 95.3053965CurrentTrain: epoch  6, batch    39 | loss: 58.4327596CurrentTrain: epoch  6, batch    40 | loss: 77.2785867CurrentTrain: epoch  6, batch    41 | loss: 79.7474406CurrentTrain: epoch  6, batch    42 | loss: 77.3082359CurrentTrain: epoch  6, batch    43 | loss: 121.4289347CurrentTrain: epoch  6, batch    44 | loss: 126.8366505CurrentTrain: epoch  6, batch    45 | loss: 97.9178983CurrentTrain: epoch  6, batch    46 | loss: 92.2898453CurrentTrain: epoch  6, batch    47 | loss: 65.2418391CurrentTrain: epoch  6, batch    48 | loss: 100.6369995CurrentTrain: epoch  6, batch    49 | loss: 97.6799514CurrentTrain: epoch  6, batch    50 | loss: 64.6479838CurrentTrain: epoch  6, batch    51 | loss: 83.7537392CurrentTrain: epoch  6, batch    52 | loss: 68.6117303CurrentTrain: epoch  6, batch    53 | loss: 84.9791365CurrentTrain: epoch  6, batch    54 | loss: 100.6596120CurrentTrain: epoch  6, batch    55 | loss: 82.0744685CurrentTrain: epoch  6, batch    56 | loss: 95.0438593CurrentTrain: epoch  6, batch    57 | loss: 96.8934598CurrentTrain: epoch  6, batch    58 | loss: 99.0089171CurrentTrain: epoch  6, batch    59 | loss: 64.7680753CurrentTrain: epoch  6, batch    60 | loss: 78.7693371CurrentTrain: epoch  6, batch    61 | loss: 126.5691187CurrentTrain: epoch  6, batch    62 | loss: 83.1616907CurrentTrain: epoch  6, batch    63 | loss: 66.5665477CurrentTrain: epoch  6, batch    64 | loss: 57.0014256CurrentTrain: epoch  6, batch    65 | loss: 68.2160557CurrentTrain: epoch  6, batch    66 | loss: 98.6333957CurrentTrain: epoch  6, batch    67 | loss: 81.8295662CurrentTrain: epoch  6, batch    68 | loss: 77.2368355CurrentTrain: epoch  6, batch    69 | loss: 60.8285302CurrentTrain: epoch  6, batch    70 | loss: 81.3195856CurrentTrain: epoch  6, batch    71 | loss: 97.9222841CurrentTrain: epoch  6, batch    72 | loss: 99.0758125CurrentTrain: epoch  6, batch    73 | loss: 101.0107908CurrentTrain: epoch  6, batch    74 | loss: 69.3368154CurrentTrain: epoch  6, batch    75 | loss: 71.5078956CurrentTrain: epoch  6, batch    76 | loss: 60.0365665CurrentTrain: epoch  6, batch    77 | loss: 99.1836080CurrentTrain: epoch  6, batch    78 | loss: 78.6396878CurrentTrain: epoch  6, batch    79 | loss: 58.5379594CurrentTrain: epoch  6, batch    80 | loss: 84.7664219CurrentTrain: epoch  6, batch    81 | loss: 100.7746664CurrentTrain: epoch  6, batch    82 | loss: 72.0356634CurrentTrain: epoch  6, batch    83 | loss: 97.4932786CurrentTrain: epoch  6, batch    84 | loss: 82.8857129CurrentTrain: epoch  6, batch    85 | loss: 63.2484785CurrentTrain: epoch  6, batch    86 | loss: 85.0099767CurrentTrain: epoch  6, batch    87 | loss: 94.9924936CurrentTrain: epoch  6, batch    88 | loss: 96.1499071CurrentTrain: epoch  6, batch    89 | loss: 103.7374921CurrentTrain: epoch  6, batch    90 | loss: 101.4495716CurrentTrain: epoch  6, batch    91 | loss: 101.9616660CurrentTrain: epoch  6, batch    92 | loss: 78.6882586CurrentTrain: epoch  6, batch    93 | loss: 79.1669753CurrentTrain: epoch  6, batch    94 | loss: 80.6407823CurrentTrain: epoch  6, batch    95 | loss: 69.3070462CurrentTrain: epoch  7, batch     0 | loss: 63.8996459CurrentTrain: epoch  7, batch     1 | loss: 122.2657243CurrentTrain: epoch  7, batch     2 | loss: 96.9456581CurrentTrain: epoch  7, batch     3 | loss: 68.0974155CurrentTrain: epoch  7, batch     4 | loss: 79.5064367CurrentTrain: epoch  7, batch     5 | loss: 101.5004391CurrentTrain: epoch  7, batch     6 | loss: 74.6887929CurrentTrain: epoch  7, batch     7 | loss: 54.1617973CurrentTrain: epoch  7, batch     8 | loss: 67.4149642CurrentTrain: epoch  7, batch     9 | loss: 67.9871293CurrentTrain: epoch  7, batch    10 | loss: 101.4377450CurrentTrain: epoch  7, batch    11 | loss: 78.7657012CurrentTrain: epoch  7, batch    12 | loss: 96.5611296CurrentTrain: epoch  7, batch    13 | loss: 76.6370118CurrentTrain: epoch  7, batch    14 | loss: 94.5838971CurrentTrain: epoch  7, batch    15 | loss: 69.0929761CurrentTrain: epoch  7, batch    16 | loss: 91.8990163CurrentTrain: epoch  7, batch    17 | loss: 94.4837046CurrentTrain: epoch  7, batch    18 | loss: 67.0374202CurrentTrain: epoch  7, batch    19 | loss: 66.6063609CurrentTrain: epoch  7, batch    20 | loss: 63.6362096CurrentTrain: epoch  7, batch    21 | loss: 123.2762541CurrentTrain: epoch  7, batch    22 | loss: 64.5692942CurrentTrain: epoch  7, batch    23 | loss: 69.1883460CurrentTrain: epoch  7, batch    24 | loss: 65.8908451CurrentTrain: epoch  7, batch    25 | loss: 69.6738964CurrentTrain: epoch  7, batch    26 | loss: 99.6542784CurrentTrain: epoch  7, batch    27 | loss: 96.1656898CurrentTrain: epoch  7, batch    28 | loss: 77.9700601CurrentTrain: epoch  7, batch    29 | loss: 99.0934606CurrentTrain: epoch  7, batch    30 | loss: 81.4235532CurrentTrain: epoch  7, batch    31 | loss: 67.2577037CurrentTrain: epoch  7, batch    32 | loss: 78.2582105CurrentTrain: epoch  7, batch    33 | loss: 97.3405177CurrentTrain: epoch  7, batch    34 | loss: 76.0928504CurrentTrain: epoch  7, batch    35 | loss: 80.6934414CurrentTrain: epoch  7, batch    36 | loss: 73.2592039CurrentTrain: epoch  7, batch    37 | loss: 122.4302780CurrentTrain: epoch  7, batch    38 | loss: 80.9049439CurrentTrain: epoch  7, batch    39 | loss: 65.1886110CurrentTrain: epoch  7, batch    40 | loss: 63.9785636CurrentTrain: epoch  7, batch    41 | loss: 82.9204602CurrentTrain: epoch  7, batch    42 | loss: 121.6833548CurrentTrain: epoch  7, batch    43 | loss: 76.7430341CurrentTrain: epoch  7, batch    44 | loss: 65.6671967CurrentTrain: epoch  7, batch    45 | loss: 99.1523116CurrentTrain: epoch  7, batch    46 | loss: 81.7099448CurrentTrain: epoch  7, batch    47 | loss: 64.9159596CurrentTrain: epoch  7, batch    48 | loss: 95.4778619CurrentTrain: epoch  7, batch    49 | loss: 100.0458460CurrentTrain: epoch  7, batch    50 | loss: 69.1360045CurrentTrain: epoch  7, batch    51 | loss: 94.8971685CurrentTrain: epoch  7, batch    52 | loss: 116.4061712CurrentTrain: epoch  7, batch    53 | loss: 64.6997982CurrentTrain: epoch  7, batch    54 | loss: 67.1679418CurrentTrain: epoch  7, batch    55 | loss: 66.5134826CurrentTrain: epoch  7, batch    56 | loss: 61.6820586CurrentTrain: epoch  7, batch    57 | loss: 125.7475815CurrentTrain: epoch  7, batch    58 | loss: 60.8132093CurrentTrain: epoch  7, batch    59 | loss: 65.0525934CurrentTrain: epoch  7, batch    60 | loss: 76.0371686CurrentTrain: epoch  7, batch    61 | loss: 98.9321194CurrentTrain: epoch  7, batch    62 | loss: 68.4518981CurrentTrain: epoch  7, batch    63 | loss: 128.7614162CurrentTrain: epoch  7, batch    64 | loss: 65.7304885CurrentTrain: epoch  7, batch    65 | loss: 84.1369629CurrentTrain: epoch  7, batch    66 | loss: 127.3578245CurrentTrain: epoch  7, batch    67 | loss: 81.1143879CurrentTrain: epoch  7, batch    68 | loss: 122.5836216CurrentTrain: epoch  7, batch    69 | loss: 102.1882423CurrentTrain: epoch  7, batch    70 | loss: 94.5432898CurrentTrain: epoch  7, batch    71 | loss: 82.2847979CurrentTrain: epoch  7, batch    72 | loss: 77.2359678CurrentTrain: epoch  7, batch    73 | loss: 69.5642911CurrentTrain: epoch  7, batch    74 | loss: 122.1016089CurrentTrain: epoch  7, batch    75 | loss: 97.7084216CurrentTrain: epoch  7, batch    76 | loss: 78.6459509CurrentTrain: epoch  7, batch    77 | loss: 54.7695217CurrentTrain: epoch  7, batch    78 | loss: 71.6891591CurrentTrain: epoch  7, batch    79 | loss: 80.4813788CurrentTrain: epoch  7, batch    80 | loss: 68.9827672CurrentTrain: epoch  7, batch    81 | loss: 100.8204767CurrentTrain: epoch  7, batch    82 | loss: 71.1480942CurrentTrain: epoch  7, batch    83 | loss: 95.3494220CurrentTrain: epoch  7, batch    84 | loss: 82.0019509CurrentTrain: epoch  7, batch    85 | loss: 122.5512935CurrentTrain: epoch  7, batch    86 | loss: 79.0636762CurrentTrain: epoch  7, batch    87 | loss: 58.3127074CurrentTrain: epoch  7, batch    88 | loss: 60.9171685CurrentTrain: epoch  7, batch    89 | loss: 69.6144564CurrentTrain: epoch  7, batch    90 | loss: 77.6271448CurrentTrain: epoch  7, batch    91 | loss: 98.9757952CurrentTrain: epoch  7, batch    92 | loss: 65.9089662CurrentTrain: epoch  7, batch    93 | loss: 119.1402957CurrentTrain: epoch  7, batch    94 | loss: 75.9667714CurrentTrain: epoch  7, batch    95 | loss: 78.3874392CurrentTrain: epoch  8, batch     0 | loss: 68.6220311CurrentTrain: epoch  8, batch     1 | loss: 125.2321211CurrentTrain: epoch  8, batch     2 | loss: 64.5420413CurrentTrain: epoch  8, batch     3 | loss: 54.7461261CurrentTrain: epoch  8, batch     4 | loss: 97.1627620CurrentTrain: epoch  8, batch     5 | loss: 96.1706085CurrentTrain: epoch  8, batch     6 | loss: 93.2698032CurrentTrain: epoch  8, batch     7 | loss: 65.9402676CurrentTrain: epoch  8, batch     8 | loss: 79.0137598CurrentTrain: epoch  8, batch     9 | loss: 55.6890081CurrentTrain: epoch  8, batch    10 | loss: 76.0307083CurrentTrain: epoch  8, batch    11 | loss: 78.3129183CurrentTrain: epoch  8, batch    12 | loss: 80.3991096CurrentTrain: epoch  8, batch    13 | loss: 53.8181205CurrentTrain: epoch  8, batch    14 | loss: 121.2530543CurrentTrain: epoch  8, batch    15 | loss: 66.6793166CurrentTrain: epoch  8, batch    16 | loss: 100.8976011CurrentTrain: epoch  8, batch    17 | loss: 91.6131489CurrentTrain: epoch  8, batch    18 | loss: 64.9875031CurrentTrain: epoch  8, batch    19 | loss: 95.1831741CurrentTrain: epoch  8, batch    20 | loss: 79.6603585CurrentTrain: epoch  8, batch    21 | loss: 97.5838128CurrentTrain: epoch  8, batch    22 | loss: 167.0407113CurrentTrain: epoch  8, batch    23 | loss: 78.6016983CurrentTrain: epoch  8, batch    24 | loss: 82.2622729CurrentTrain: epoch  8, batch    25 | loss: 118.7123328CurrentTrain: epoch  8, batch    26 | loss: 79.5263510CurrentTrain: epoch  8, batch    27 | loss: 82.4932189CurrentTrain: epoch  8, batch    28 | loss: 81.4057992CurrentTrain: epoch  8, batch    29 | loss: 66.7705275CurrentTrain: epoch  8, batch    30 | loss: 78.0072926CurrentTrain: epoch  8, batch    31 | loss: 122.0994743CurrentTrain: epoch  8, batch    32 | loss: 75.6386005CurrentTrain: epoch  8, batch    33 | loss: 74.3486739CurrentTrain: epoch  8, batch    34 | loss: 62.0227375CurrentTrain: epoch  8, batch    35 | loss: 76.8466358CurrentTrain: epoch  8, batch    36 | loss: 76.1232301CurrentTrain: epoch  8, batch    37 | loss: 123.9542612CurrentTrain: epoch  8, batch    38 | loss: 98.4929232CurrentTrain: epoch  8, batch    39 | loss: 123.2403537CurrentTrain: epoch  8, batch    40 | loss: 55.3255000CurrentTrain: epoch  8, batch    41 | loss: 91.6170127CurrentTrain: epoch  8, batch    42 | loss: 97.9289378CurrentTrain: epoch  8, batch    43 | loss: 73.3304660CurrentTrain: epoch  8, batch    44 | loss: 56.5475424CurrentTrain: epoch  8, batch    45 | loss: 55.9697628CurrentTrain: epoch  8, batch    46 | loss: 81.6892438CurrentTrain: epoch  8, batch    47 | loss: 75.2355787CurrentTrain: epoch  8, batch    48 | loss: 83.0636365CurrentTrain: epoch  8, batch    49 | loss: 77.2075728CurrentTrain: epoch  8, batch    50 | loss: 78.1482820CurrentTrain: epoch  8, batch    51 | loss: 78.5001991CurrentTrain: epoch  8, batch    52 | loss: 74.9361765CurrentTrain: epoch  8, batch    53 | loss: 74.5379578CurrentTrain: epoch  8, batch    54 | loss: 122.1352678CurrentTrain: epoch  8, batch    55 | loss: 100.5449911CurrentTrain: epoch  8, batch    56 | loss: 59.0011772CurrentTrain: epoch  8, batch    57 | loss: 97.4776519CurrentTrain: epoch  8, batch    58 | loss: 76.2741290CurrentTrain: epoch  8, batch    59 | loss: 122.2836411CurrentTrain: epoch  8, batch    60 | loss: 66.7820315CurrentTrain: epoch  8, batch    61 | loss: 74.6374021CurrentTrain: epoch  8, batch    62 | loss: 167.9293267CurrentTrain: epoch  8, batch    63 | loss: 65.3590618CurrentTrain: epoch  8, batch    64 | loss: 78.6630488CurrentTrain: epoch  8, batch    65 | loss: 68.7359981CurrentTrain: epoch  8, batch    66 | loss: 73.8982093CurrentTrain: epoch  8, batch    67 | loss: 95.2315759CurrentTrain: epoch  8, batch    68 | loss: 97.6550222CurrentTrain: epoch  8, batch    69 | loss: 64.6025024CurrentTrain: epoch  8, batch    70 | loss: 68.1465535CurrentTrain: epoch  8, batch    71 | loss: 77.8078353CurrentTrain: epoch  8, batch    72 | loss: 77.8830911CurrentTrain: epoch  8, batch    73 | loss: 121.4446464CurrentTrain: epoch  8, batch    74 | loss: 76.1128951CurrentTrain: epoch  8, batch    75 | loss: 64.8833295CurrentTrain: epoch  8, batch    76 | loss: 96.1052550CurrentTrain: epoch  8, batch    77 | loss: 64.2229726CurrentTrain: epoch  8, batch    78 | loss: 95.2745752CurrentTrain: epoch  8, batch    79 | loss: 60.2747288CurrentTrain: epoch  8, batch    80 | loss: 94.0291947CurrentTrain: epoch  8, batch    81 | loss: 79.9954783CurrentTrain: epoch  8, batch    82 | loss: 62.3979350CurrentTrain: epoch  8, batch    83 | loss: 68.2571003CurrentTrain: epoch  8, batch    84 | loss: 78.4217184CurrentTrain: epoch  8, batch    85 | loss: 80.1473018CurrentTrain: epoch  8, batch    86 | loss: 95.7181011CurrentTrain: epoch  8, batch    87 | loss: 56.0991948CurrentTrain: epoch  8, batch    88 | loss: 162.7149842CurrentTrain: epoch  8, batch    89 | loss: 62.6946627CurrentTrain: epoch  8, batch    90 | loss: 97.7701881CurrentTrain: epoch  8, batch    91 | loss: 64.1260970CurrentTrain: epoch  8, batch    92 | loss: 62.8520335CurrentTrain: epoch  8, batch    93 | loss: 68.7392675CurrentTrain: epoch  8, batch    94 | loss: 61.1164223CurrentTrain: epoch  8, batch    95 | loss: 82.3569164CurrentTrain: epoch  9, batch     0 | loss: 76.6744163CurrentTrain: epoch  9, batch     1 | loss: 63.0698692CurrentTrain: epoch  9, batch     2 | loss: 120.9665263CurrentTrain: epoch  9, batch     3 | loss: 78.9230135CurrentTrain: epoch  9, batch     4 | loss: 73.6393817CurrentTrain: epoch  9, batch     5 | loss: 81.4872025CurrentTrain: epoch  9, batch     6 | loss: 65.5298702CurrentTrain: epoch  9, batch     7 | loss: 66.6392570CurrentTrain: epoch  9, batch     8 | loss: 75.8406078CurrentTrain: epoch  9, batch     9 | loss: 78.7234592CurrentTrain: epoch  9, batch    10 | loss: 76.3710258CurrentTrain: epoch  9, batch    11 | loss: 76.9078505CurrentTrain: epoch  9, batch    12 | loss: 96.0124067CurrentTrain: epoch  9, batch    13 | loss: 77.0146759CurrentTrain: epoch  9, batch    14 | loss: 79.4089018CurrentTrain: epoch  9, batch    15 | loss: 63.2813936CurrentTrain: epoch  9, batch    16 | loss: 78.8418448CurrentTrain: epoch  9, batch    17 | loss: 76.4602368CurrentTrain: epoch  9, batch    18 | loss: 125.6701723CurrentTrain: epoch  9, batch    19 | loss: 61.4020483CurrentTrain: epoch  9, batch    20 | loss: 95.8792946CurrentTrain: epoch  9, batch    21 | loss: 117.4965701CurrentTrain: epoch  9, batch    22 | loss: 93.2690118CurrentTrain: epoch  9, batch    23 | loss: 77.2734658CurrentTrain: epoch  9, batch    24 | loss: 95.8258769CurrentTrain: epoch  9, batch    25 | loss: 61.1005647CurrentTrain: epoch  9, batch    26 | loss: 67.5912819CurrentTrain: epoch  9, batch    27 | loss: 76.1486638CurrentTrain: epoch  9, batch    28 | loss: 117.8267004CurrentTrain: epoch  9, batch    29 | loss: 54.2724498CurrentTrain: epoch  9, batch    30 | loss: 78.1616090CurrentTrain: epoch  9, batch    31 | loss: 95.9354171CurrentTrain: epoch  9, batch    32 | loss: 73.5161460CurrentTrain: epoch  9, batch    33 | loss: 77.5490649CurrentTrain: epoch  9, batch    34 | loss: 124.1013326CurrentTrain: epoch  9, batch    35 | loss: 68.0179536CurrentTrain: epoch  9, batch    36 | loss: 73.0807582CurrentTrain: epoch  9, batch    37 | loss: 98.2854803CurrentTrain: epoch  9, batch    38 | loss: 92.8067754CurrentTrain: epoch  9, batch    39 | loss: 79.7853003CurrentTrain: epoch  9, batch    40 | loss: 55.2313534CurrentTrain: epoch  9, batch    41 | loss: 94.5442978CurrentTrain: epoch  9, batch    42 | loss: 67.3556489CurrentTrain: epoch  9, batch    43 | loss: 74.1722503CurrentTrain: epoch  9, batch    44 | loss: 64.2647002CurrentTrain: epoch  9, batch    45 | loss: 94.1441300CurrentTrain: epoch  9, batch    46 | loss: 78.4099122CurrentTrain: epoch  9, batch    47 | loss: 96.5889936CurrentTrain: epoch  9, batch    48 | loss: 79.4660422CurrentTrain: epoch  9, batch    49 | loss: 78.5642929CurrentTrain: epoch  9, batch    50 | loss: 61.9810234CurrentTrain: epoch  9, batch    51 | loss: 68.2198483CurrentTrain: epoch  9, batch    52 | loss: 100.0977287CurrentTrain: epoch  9, batch    53 | loss: 77.8786489CurrentTrain: epoch  9, batch    54 | loss: 95.5986882CurrentTrain: epoch  9, batch    55 | loss: 75.4635848CurrentTrain: epoch  9, batch    56 | loss: 75.4633913CurrentTrain: epoch  9, batch    57 | loss: 58.0734061CurrentTrain: epoch  9, batch    58 | loss: 61.8930520CurrentTrain: epoch  9, batch    59 | loss: 124.8395034CurrentTrain: epoch  9, batch    60 | loss: 98.1901522CurrentTrain: epoch  9, batch    61 | loss: 80.2811891CurrentTrain: epoch  9, batch    62 | loss: 67.3466060CurrentTrain: epoch  9, batch    63 | loss: 119.5530969CurrentTrain: epoch  9, batch    64 | loss: 75.4914179CurrentTrain: epoch  9, batch    65 | loss: 80.1050216CurrentTrain: epoch  9, batch    66 | loss: 64.0425802CurrentTrain: epoch  9, batch    67 | loss: 92.6774696CurrentTrain: epoch  9, batch    68 | loss: 71.4954729CurrentTrain: epoch  9, batch    69 | loss: 66.0182459CurrentTrain: epoch  9, batch    70 | loss: 65.4420344CurrentTrain: epoch  9, batch    71 | loss: 68.2315312CurrentTrain: epoch  9, batch    72 | loss: 93.3240685CurrentTrain: epoch  9, batch    73 | loss: 74.1833564CurrentTrain: epoch  9, batch    74 | loss: 76.8785745CurrentTrain: epoch  9, batch    75 | loss: 65.9854590CurrentTrain: epoch  9, batch    76 | loss: 98.2130592CurrentTrain: epoch  9, batch    77 | loss: 78.8365503CurrentTrain: epoch  9, batch    78 | loss: 55.6731131CurrentTrain: epoch  9, batch    79 | loss: 124.5603071CurrentTrain: epoch  9, batch    80 | loss: 78.3316982CurrentTrain: epoch  9, batch    81 | loss: 75.6554476CurrentTrain: epoch  9, batch    82 | loss: 95.1879048CurrentTrain: epoch  9, batch    83 | loss: 63.8447503CurrentTrain: epoch  9, batch    84 | loss: 76.6679869CurrentTrain: epoch  9, batch    85 | loss: 58.1877022CurrentTrain: epoch  9, batch    86 | loss: 76.7101623CurrentTrain: epoch  9, batch    87 | loss: 95.4548988CurrentTrain: epoch  9, batch    88 | loss: 76.7211865CurrentTrain: epoch  9, batch    89 | loss: 74.0574215CurrentTrain: epoch  9, batch    90 | loss: 64.9418457CurrentTrain: epoch  9, batch    91 | loss: 92.4715025CurrentTrain: epoch  9, batch    92 | loss: 74.0694399CurrentTrain: epoch  9, batch    93 | loss: 67.6907165CurrentTrain: epoch  9, batch    94 | loss: 166.9772221CurrentTrain: epoch  9, batch    95 | loss: 68.3880849

F1 score per class: {32: np.float64(0.5164835164835165), 6: np.float64(0.8169014084507042), 19: np.float64(0.34285714285714286), 24: np.float64(0.7333333333333333), 26: np.float64(0.9278350515463918), 29: np.float64(0.8186046511627907)}
Micro-average F1 score: 0.7536800785083415
Weighted-average F1 score: 0.7595065375866223
F1 score per class: {32: np.float64(0.6610878661087866), 6: np.float64(0.8), 19: np.float64(0.2222222222222222), 24: np.float64(0.7243243243243244), 26: np.float64(0.9387755102040817), 29: np.float64(0.8246445497630331)}
Micro-average F1 score: 0.7542448614834674
Weighted-average F1 score: 0.7406269134109441
F1 score per class: {32: np.float64(0.6810344827586207), 6: np.float64(0.8090909090909091), 19: np.float64(0.2978723404255319), 24: np.float64(0.7252747252747253), 26: np.float64(0.9387755102040817), 29: np.float64(0.8207547169811321)}
Micro-average F1 score: 0.7713498622589532
Weighted-average F1 score: 0.7655783948185527

F1 score per class: {32: np.float64(0.5164835164835165), 6: np.float64(0.8169014084507042), 19: np.float64(0.34285714285714286), 24: np.float64(0.7333333333333333), 26: np.float64(0.9278350515463918), 29: np.float64(0.8186046511627907)}
Micro-average F1 score: 0.7536800785083415
Weighted-average F1 score: 0.7595065375866223
F1 score per class: {32: np.float64(0.6610878661087866), 6: np.float64(0.8), 19: np.float64(0.2222222222222222), 24: np.float64(0.7243243243243244), 26: np.float64(0.9387755102040817), 29: np.float64(0.8246445497630331)}
Micro-average F1 score: 0.7542448614834674
Weighted-average F1 score: 0.7406269134109441
F1 score per class: {32: np.float64(0.6810344827586207), 6: np.float64(0.8090909090909091), 19: np.float64(0.2978723404255319), 24: np.float64(0.7252747252747253), 26: np.float64(0.9387755102040817), 29: np.float64(0.8207547169811321)}
Micro-average F1 score: 0.7713498622589532
Weighted-average F1 score: 0.7655783948185527

F1 score per class: {32: np.float64(0.38524590163934425), 6: np.float64(0.7631578947368421), 19: np.float64(0.21428571428571427), 24: np.float64(0.6804123711340206), 26: np.float64(0.8530805687203792), 29: np.float64(0.6567164179104478)}
Micro-average F1 score: 0.6394671107410491
Weighted-average F1 score: 0.6299876160011036
F1 score per class: {32: np.float64(0.4540229885057471), 6: np.float64(0.7346938775510204), 19: np.float64(0.1320754716981132), 24: np.float64(0.6504854368932039), 26: np.float64(0.8518518518518519), 29: np.float64(0.6666666666666666)}
Micro-average F1 score: 0.6107091172214182
Weighted-average F1 score: 0.5854751844474363
F1 score per class: {32: np.float64(0.4688427299703264), 6: np.float64(0.7416666666666667), 19: np.float64(0.17073170731707318), 24: np.float64(0.6534653465346535), 26: np.float64(0.8518518518518519), 29: np.float64(0.6615969581749049)}
Micro-average F1 score: 0.6268656716417911
Weighted-average F1 score: 0.6072803819324238

F1 score per class: {32: np.float64(0.38524590163934425), 6: np.float64(0.7631578947368421), 19: np.float64(0.21428571428571427), 24: np.float64(0.6804123711340206), 26: np.float64(0.8530805687203792), 29: np.float64(0.6567164179104478)}
Micro-average F1 score: 0.6394671107410491
Weighted-average F1 score: 0.6299876160011036
F1 score per class: {32: np.float64(0.4540229885057471), 6: np.float64(0.7346938775510204), 19: np.float64(0.1320754716981132), 24: np.float64(0.6504854368932039), 26: np.float64(0.8518518518518519), 29: np.float64(0.6666666666666666)}
Micro-average F1 score: 0.6107091172214182
Weighted-average F1 score: 0.5854751844474363
F1 score per class: {32: np.float64(0.4688427299703264), 6: np.float64(0.7416666666666667), 19: np.float64(0.17073170731707318), 24: np.float64(0.6534653465346535), 26: np.float64(0.8518518518518519), 29: np.float64(0.6615969581749049)}
Micro-average F1 score: 0.6268656716417911
Weighted-average F1 score: 0.6072803819324238
cur_acc_wo_na:  ['0.7537']
his_acc_wo_na:  ['0.7537']
cur_acc des_wo_na:  ['0.7542']
his_acc des_wo_na:  ['0.7542']
cur_acc rrf_wo_na:  ['0.7713']
his_acc rrf_wo_na:  ['0.7713']
cur_acc_w_na:  ['0.6395']
his_acc_w_na:  ['0.6395']
cur_acc des_w_na:  ['0.6107']
his_acc des_w_na:  ['0.6107']
cur_acc rrf_w_na:  ['0.6269']
his_acc rrf_w_na:  ['0.6269']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death'])
CurrentTrain: epoch  0, batch     0 | loss: 96.1377924CurrentTrain: epoch  0, batch     1 | loss: 91.2608493CurrentTrain: epoch  0, batch     2 | loss: 140.7091708CurrentTrain: epoch  0, batch     3 | loss: 54.4329748CurrentTrain: epoch  1, batch     0 | loss: 75.8775830CurrentTrain: epoch  1, batch     1 | loss: 88.9074404CurrentTrain: epoch  1, batch     2 | loss: 103.0935945CurrentTrain: epoch  1, batch     3 | loss: 72.6858421CurrentTrain: epoch  2, batch     0 | loss: 106.6970963CurrentTrain: epoch  2, batch     1 | loss: 83.0138244CurrentTrain: epoch  2, batch     2 | loss: 84.1703514CurrentTrain: epoch  2, batch     3 | loss: 86.7460191CurrentTrain: epoch  3, batch     0 | loss: 81.0300429CurrentTrain: epoch  3, batch     1 | loss: 71.7236826CurrentTrain: epoch  3, batch     2 | loss: 100.6635471CurrentTrain: epoch  3, batch     3 | loss: 85.9346906CurrentTrain: epoch  4, batch     0 | loss: 98.0107733CurrentTrain: epoch  4, batch     1 | loss: 68.8105515CurrentTrain: epoch  4, batch     2 | loss: 69.1052956CurrentTrain: epoch  4, batch     3 | loss: 57.1098473CurrentTrain: epoch  5, batch     0 | loss: 80.5371717CurrentTrain: epoch  5, batch     1 | loss: 71.1816066CurrentTrain: epoch  5, batch     2 | loss: 65.2620510CurrentTrain: epoch  5, batch     3 | loss: 53.5879560CurrentTrain: epoch  6, batch     0 | loss: 78.3736504CurrentTrain: epoch  6, batch     1 | loss: 75.6217940CurrentTrain: epoch  6, batch     2 | loss: 65.1289754CurrentTrain: epoch  6, batch     3 | loss: 85.7942381CurrentTrain: epoch  7, batch     0 | loss: 98.2321465CurrentTrain: epoch  7, batch     1 | loss: 64.4482132CurrentTrain: epoch  7, batch     2 | loss: 77.0842204CurrentTrain: epoch  7, batch     3 | loss: 81.7299266CurrentTrain: epoch  8, batch     0 | loss: 64.5818706CurrentTrain: epoch  8, batch     1 | loss: 77.6451266CurrentTrain: epoch  8, batch     2 | loss: 78.1638626CurrentTrain: epoch  8, batch     3 | loss: 63.3757739CurrentTrain: epoch  9, batch     0 | loss: 64.1794231CurrentTrain: epoch  9, batch     1 | loss: 76.2882536CurrentTrain: epoch  9, batch     2 | loss: 79.5819562CurrentTrain: epoch  9, batch     3 | loss: 43.0458171
MemoryTrain:  epoch  0, batch     0 | loss: 1.9981433MemoryTrain:  epoch  1, batch     0 | loss: 1.8176339MemoryTrain:  epoch  2, batch     0 | loss: 1.4716190MemoryTrain:  epoch  3, batch     0 | loss: 1.1290907MemoryTrain:  epoch  4, batch     0 | loss: 0.9517163MemoryTrain:  epoch  5, batch     0 | loss: 0.7589357MemoryTrain:  epoch  6, batch     0 | loss: 0.6630964MemoryTrain:  epoch  7, batch     0 | loss: 0.4916141MemoryTrain:  epoch  8, batch     0 | loss: 0.3958242MemoryTrain:  epoch  9, batch     0 | loss: 0.3483084

F1 score per class: {32: np.float64(0.0), 35: np.float64(0.8421052631578947), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.463768115942029), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.6744186046511628), 25: np.float64(0.5154639175257731), 26: np.float64(0.3684210526315789)}
Micro-average F1 score: 0.5059523809523809
Weighted-average F1 score: 0.45795579242218987
F1 score per class: {32: np.float64(0.0), 35: np.float64(0.7368421052631579), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.7659574468085106), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.8037383177570093), 26: np.float64(0.5436893203883495), 29: np.float64(0.5588235294117647)}
Micro-average F1 score: 0.6100917431192661
Weighted-average F1 score: 0.551245614727183
F1 score per class: {32: np.float64(0.0), 35: np.float64(0.7619047619047619), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.7441860465116279), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.7924528301886793), 26: np.float64(0.5384615384615384), 29: np.float64(0.5283018867924528)}
Micro-average F1 score: 0.6048780487804878
Weighted-average F1 score: 0.5462585573437517

F1 score per class: {32: np.float64(0.6237623762376238), 35: np.float64(0.6956521739130435), 37: np.float64(0.8018867924528302), 6: np.float64(0.18181818181818182), 38: np.float64(0.463768115942029), 15: np.float64(0.7251461988304093), 19: np.float64(0.8936170212765957), 24: np.float64(0.7980769230769231), 25: np.float64(0.5321100917431193), 26: np.float64(0.43478260869565216), 29: np.float64(0.3684210526315789)}
Micro-average F1 score: 0.6798245614035088
Weighted-average F1 score: 0.6900855425229525
F1 score per class: {32: np.float64(0.6774193548387096), 35: np.float64(0.5833333333333334), 37: np.float64(0.7678571428571429), 6: np.float64(0.3333333333333333), 38: np.float64(0.7659574468085106), 15: np.float64(0.7052631578947368), 19: np.float64(0.91), 24: np.float64(0.8252427184466019), 25: np.float64(0.5584415584415584), 26: np.float64(0.4628099173553719), 29: np.float64(0.4470588235294118)}
Micro-average F1 score: 0.6924034869240349
Weighted-average F1 score: 0.679810462737587
F1 score per class: {32: np.float64(0.6612903225806451), 35: np.float64(0.5925925925925926), 37: np.float64(0.7747747747747747), 6: np.float64(0.32558139534883723), 38: np.float64(0.7441860465116279), 15: np.float64(0.7344632768361582), 19: np.float64(0.9025641025641026), 24: np.float64(0.8173076923076923), 25: np.float64(0.5753424657534246), 26: np.float64(0.4409448818897638), 29: np.float64(0.45901639344262296)}
Micro-average F1 score: 0.6974025974025974
Weighted-average F1 score: 0.6891891595001817

F1 score per class: {32: np.float64(0.0), 35: np.float64(0.6666666666666666), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.4266666666666667), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.5918367346938775), 26: np.float64(0.5), 29: np.float64(0.2916666666666667)}
Micro-average F1 score: 0.4218362282878412
Weighted-average F1 score: 0.36037785411194184
F1 score per class: {32: np.float64(0.0), 35: np.float64(0.5833333333333334), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.6728971962616822), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.688), 26: np.float64(0.5045045045045045), 29: np.float64(0.3838383838383838)}
Micro-average F1 score: 0.4767025089605735
Weighted-average F1 score: 0.4175637743510201
F1 score per class: {32: np.float64(0.0), 35: np.float64(0.64), 37: np.float64(0.0), 38: np.float64(0.0), 6: np.float64(0.6666666666666666), 15: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.6829268292682927), 26: np.float64(0.5), 29: np.float64(0.36363636363636365)}
Micro-average F1 score: 0.4806201550387597
Weighted-average F1 score: 0.4188007836788325

F1 score per class: {32: np.float64(0.4359861591695502), 35: np.float64(0.5161290322580645), 37: np.float64(0.7391304347826086), 6: np.float64(0.12), 38: np.float64(0.4266666666666667), 15: np.float64(0.6595744680851063), 19: np.float64(0.8), 24: np.float64(0.6459143968871596), 25: np.float64(0.41134751773049644), 26: np.float64(0.3333333333333333), 29: np.float64(0.25925925925925924)}
Micro-average F1 score: 0.5552238805970149
Weighted-average F1 score: 0.5483195757895353
F1 score per class: {32: np.float64(0.4540540540540541), 35: np.float64(0.45161290322580644), 37: np.float64(0.7020408163265306), 6: np.float64(0.16129032258064516), 38: np.float64(0.6728971962616822), 15: np.float64(0.6203703703703703), 19: np.float64(0.7711864406779662), 24: np.float64(0.6640625), 25: np.float64(0.3944954128440367), 26: np.float64(0.358974358974359), 29: np.float64(0.24358974358974358)}
Micro-average F1 score: 0.5257683215130023
Weighted-average F1 score: 0.5013899229217553
F1 score per class: {32: np.float64(0.44808743169398907), 35: np.float64(0.45714285714285713), 37: np.float64(0.7107438016528925), 6: np.float64(0.17721518987341772), 38: np.float64(0.6666666666666666), 15: np.float64(0.6598984771573604), 19: np.float64(0.7822222222222223), 24: np.float64(0.6563706563706564), 25: np.float64(0.42), 26: np.float64(0.3373493975903614), 29: np.float64(0.25925925925925924)}
Micro-average F1 score: 0.5443487075519513
Weighted-average F1 score: 0.5238592897287003
cur_acc_wo_na:  ['0.7537', '0.5060']
his_acc_wo_na:  ['0.7537', '0.6798']
cur_acc des_wo_na:  ['0.7542', '0.6101']
his_acc des_wo_na:  ['0.7542', '0.6924']
cur_acc rrf_wo_na:  ['0.7713', '0.6049']
his_acc rrf_wo_na:  ['0.7713', '0.6974']
cur_acc_w_na:  ['0.6395', '0.4218']
his_acc_w_na:  ['0.6395', '0.5552']
cur_acc des_w_na:  ['0.6107', '0.4767']
his_acc des_w_na:  ['0.6107', '0.5258']
cur_acc rrf_w_na:  ['0.6269', '0.4806']
his_acc rrf_w_na:  ['0.6269', '0.5443']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse'])
CurrentTrain: epoch  0, batch     0 | loss: 123.1286363CurrentTrain: epoch  0, batch     1 | loss: 87.2461947CurrentTrain: epoch  0, batch     2 | loss: 81.7568969CurrentTrain: epoch  0, batch     3 | loss: 51.2920095CurrentTrain: epoch  1, batch     0 | loss: 81.3807031CurrentTrain: epoch  1, batch     1 | loss: 74.5655163CurrentTrain: epoch  1, batch     2 | loss: 86.3575405CurrentTrain: epoch  1, batch     3 | loss: 82.6623731CurrentTrain: epoch  2, batch     0 | loss: 81.8949867CurrentTrain: epoch  2, batch     1 | loss: 85.3109580CurrentTrain: epoch  2, batch     2 | loss: 86.2126874CurrentTrain: epoch  2, batch     3 | loss: 50.8404657CurrentTrain: epoch  3, batch     0 | loss: 103.4476450CurrentTrain: epoch  3, batch     1 | loss: 84.7256704CurrentTrain: epoch  3, batch     2 | loss: 80.2249864CurrentTrain: epoch  3, batch     3 | loss: 58.4267764CurrentTrain: epoch  4, batch     0 | loss: 81.4132372CurrentTrain: epoch  4, batch     1 | loss: 100.1209300CurrentTrain: epoch  4, batch     2 | loss: 81.0220992CurrentTrain: epoch  4, batch     3 | loss: 56.3634751CurrentTrain: epoch  5, batch     0 | loss: 64.6452037CurrentTrain: epoch  5, batch     1 | loss: 82.2466010CurrentTrain: epoch  5, batch     2 | loss: 77.3237045CurrentTrain: epoch  5, batch     3 | loss: 50.6115012CurrentTrain: epoch  6, batch     0 | loss: 78.1630966CurrentTrain: epoch  6, batch     1 | loss: 67.1999056CurrentTrain: epoch  6, batch     2 | loss: 78.7604021CurrentTrain: epoch  6, batch     3 | loss: 56.6027584CurrentTrain: epoch  7, batch     0 | loss: 80.6474769CurrentTrain: epoch  7, batch     1 | loss: 73.8898148CurrentTrain: epoch  7, batch     2 | loss: 65.5175345CurrentTrain: epoch  7, batch     3 | loss: 71.7269272CurrentTrain: epoch  8, batch     0 | loss: 93.1710718CurrentTrain: epoch  8, batch     1 | loss: 93.0834166CurrentTrain: epoch  8, batch     2 | loss: 74.3769891CurrentTrain: epoch  8, batch     3 | loss: 54.3377281CurrentTrain: epoch  9, batch     0 | loss: 76.8657648CurrentTrain: epoch  9, batch     1 | loss: 97.7006775CurrentTrain: epoch  9, batch     2 | loss: 60.6945158CurrentTrain: epoch  9, batch     3 | loss: 45.8277579
MemoryTrain:  epoch  0, batch     0 | loss: 0.9249538MemoryTrain:  epoch  1, batch     0 | loss: 0.9314719MemoryTrain:  epoch  2, batch     0 | loss: 0.7397375MemoryTrain:  epoch  3, batch     0 | loss: 0.5499259MemoryTrain:  epoch  4, batch     0 | loss: 0.4671666MemoryTrain:  epoch  5, batch     0 | loss: 0.4037559MemoryTrain:  epoch  6, batch     0 | loss: 0.3168355MemoryTrain:  epoch  7, batch     0 | loss: 0.2790368MemoryTrain:  epoch  8, batch     0 | loss: 0.2457136MemoryTrain:  epoch  9, batch     0 | loss: 0.2039806

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.4715447154471545), 35: np.float64(0.0), 36: np.float64(0.5333333333333333), 37: np.float64(0.0), 6: np.float64(0.0), 38: np.float64(0.9142857142857143), 8: np.float64(0.0), 15: np.float64(0.42857142857142855), 20: np.float64(0.0), 26: np.float64(0.5319148936170213), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.4856396866840731
Weighted-average F1 score: 0.40666303147593946
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.5882352941176471), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.6352941176470588), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.8292682926829268), 20: np.float64(0.0), 24: np.float64(0.47058823529411764), 25: np.float64(0.0), 26: np.float64(0.736), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.5673469387755102
Weighted-average F1 score: 0.4885656010591448
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.609271523178808), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.6097560975609756), 6: np.float64(0.0), 8: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.8292682926829268), 24: np.float64(0.0), 25: np.float64(0.5), 26: np.float64(0.0), 29: np.float64(0.6833333333333333), 30: np.float64(0.0)}
Micro-average F1 score: 0.5659574468085107
Weighted-average F1 score: 0.49107146357007647

F1 score per class: {32: np.float64(0.600896860986547), 33: np.float64(0.41134751773049644), 35: np.float64(0.6666666666666666), 36: np.float64(0.801980198019802), 37: np.float64(0.45977011494252873), 6: np.float64(0.14285714285714285), 38: np.float64(0.3384615384615385), 8: np.float64(0.7142857142857143), 15: np.float64(0.8704663212435233), 19: np.float64(0.9142857142857143), 20: np.float64(0.8113207547169812), 24: np.float64(0.4), 25: np.float64(0.5858585858585859), 26: np.float64(0.45454545454545453), 29: np.float64(0.2535211267605634), 30: np.float64(0.12903225806451613)}
Micro-average F1 score: 0.6251455180442375
Weighted-average F1 score: 0.66229921538011
F1 score per class: {32: np.float64(0.6582278481012658), 33: np.float64(0.43478260869565216), 35: np.float64(0.56), 36: np.float64(0.7577092511013216), 37: np.float64(0.4778761061946903), 6: np.float64(0.29411764705882354), 38: np.float64(0.5176470588235295), 8: np.float64(0.6633165829145728), 15: np.float64(0.9073170731707317), 19: np.float64(0.5), 20: np.float64(0.8055555555555556), 24: np.float64(0.34782608695652173), 25: np.float64(0.6133333333333333), 26: np.float64(0.5542168674698795), 29: np.float64(0.32323232323232326), 30: np.float64(0.42857142857142855)}
Micro-average F1 score: 0.6187793427230047
Weighted-average F1 score: 0.6164191216673208
F1 score per class: {32: np.float64(0.6554621848739496), 33: np.float64(0.4742268041237113), 35: np.float64(0.5714285714285714), 36: np.float64(0.7644444444444445), 37: np.float64(0.45871559633027525), 6: np.float64(0.3333333333333333), 38: np.float64(0.44155844155844154), 8: np.float64(0.6910994764397905), 15: np.float64(0.9064039408866995), 19: np.float64(0.576271186440678), 20: np.float64(0.8), 24: np.float64(0.4), 25: np.float64(0.656934306569343), 26: np.float64(0.543046357615894), 29: np.float64(0.3146067415730337), 30: np.float64(0.2857142857142857)}
Micro-average F1 score: 0.6324110671936759
Weighted-average F1 score: 0.6413690791898427

F1 score per class: {32: np.float64(0.0), 33: np.float64(0.43283582089552236), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.46511627906976744), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.8648648648648649), 15: np.float64(0.0), 19: np.float64(0.42857142857142855), 20: np.float64(0.0), 26: np.float64(0.44642857142857145), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.3866943866943867
Weighted-average F1 score: 0.3008520623067655
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.45685279187817257), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.5346534653465347), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.7555555555555555), 20: np.float64(0.0), 24: np.float64(0.47058823529411764), 25: np.float64(0.0), 26: np.float64(0.5859872611464968), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.40702781844802344
Weighted-average F1 score: 0.34052312245507854
F1 score per class: {32: np.float64(0.0), 33: np.float64(0.48677248677248675), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.5102040816326531), 6: np.float64(0.0), 38: np.float64(0.0), 8: np.float64(0.0), 15: np.float64(0.0), 19: np.float64(0.7906976744186046), 20: np.float64(0.0), 24: np.float64(0.5), 25: np.float64(0.0), 26: np.float64(0.5466666666666666), 29: np.float64(0.0), 30: np.float64(0.0)}
Micro-average F1 score: 0.415625
Weighted-average F1 score: 0.3482081964530851

F1 score per class: {32: np.float64(0.4036144578313253), 33: np.float64(0.35365853658536583), 35: np.float64(0.45714285714285713), 36: np.float64(0.7397260273972602), 37: np.float64(0.3053435114503817), 6: np.float64(0.11764705882352941), 38: np.float64(0.3235294117647059), 8: np.float64(0.6310679611650486), 15: np.float64(0.7850467289719626), 19: np.float64(0.8421052631578947), 20: np.float64(0.6346863468634686), 24: np.float64(0.3333333333333333), 25: np.float64(0.4461538461538462), 26: np.float64(0.37037037037037035), 29: np.float64(0.23376623376623376), 30: np.float64(0.09302325581395349)}
Micro-average F1 score: 0.5078014184397163
Weighted-average F1 score: 0.5171182568237077
F1 score per class: {32: np.float64(0.43575418994413406), 33: np.float64(0.2830188679245283), 35: np.float64(0.42424242424242425), 36: np.float64(0.6825396825396826), 37: np.float64(0.32142857142857145), 6: np.float64(0.16), 38: np.float64(0.46808510638297873), 8: np.float64(0.5714285714285714), 15: np.float64(0.768595041322314), 19: np.float64(0.4), 20: np.float64(0.6236559139784946), 24: np.float64(0.25806451612903225), 25: np.float64(0.42201834862385323), 26: np.float64(0.42790697674418604), 29: np.float64(0.24806201550387597), 30: np.float64(0.28125)}
Micro-average F1 score: 0.4637579169598874
Weighted-average F1 score: 0.45195344201518334
F1 score per class: {32: np.float64(0.430939226519337), 33: np.float64(0.3262411347517731), 35: np.float64(0.4), 36: np.float64(0.6907630522088354), 37: np.float64(0.3067484662576687), 6: np.float64(0.1927710843373494), 38: np.float64(0.40476190476190477), 8: np.float64(0.6082949308755761), 15: np.float64(0.7666666666666667), 19: np.float64(0.4722222222222222), 20: np.float64(0.624113475177305), 24: np.float64(0.2962962962962963), 25: np.float64(0.4712041884816754), 26: np.float64(0.41836734693877553), 29: np.float64(0.2641509433962264), 30: np.float64(0.18181818181818182)}
Micro-average F1 score: 0.48320120800302
Weighted-average F1 score: 0.4776925906474633
cur_acc_wo_na:  ['0.7537', '0.5060', '0.4856']
his_acc_wo_na:  ['0.7537', '0.6798', '0.6251']
cur_acc des_wo_na:  ['0.7542', '0.6101', '0.5673']
his_acc des_wo_na:  ['0.7542', '0.6924', '0.6188']
cur_acc rrf_wo_na:  ['0.7713', '0.6049', '0.5660']
his_acc rrf_wo_na:  ['0.7713', '0.6974', '0.6324']
cur_acc_w_na:  ['0.6395', '0.4218', '0.3867']
his_acc_w_na:  ['0.6395', '0.5552', '0.5078']
cur_acc des_w_na:  ['0.6107', '0.4767', '0.4070']
his_acc des_w_na:  ['0.6107', '0.5258', '0.4638']
cur_acc rrf_w_na:  ['0.6269', '0.4806', '0.4156']
his_acc rrf_w_na:  ['0.6269', '0.5443', '0.4832']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings'])
CurrentTrain: epoch  0, batch     0 | loss: 101.0437011CurrentTrain: epoch  0, batch     1 | loss: 141.5474884CurrentTrain: epoch  0, batch     2 | loss: 93.1697262CurrentTrain: epoch  0, batch     3 | loss: 83.9968099CurrentTrain: epoch  0, batch     4 | loss: 66.5300530CurrentTrain: epoch  1, batch     0 | loss: 75.1136840CurrentTrain: epoch  1, batch     1 | loss: 108.3884385CurrentTrain: epoch  1, batch     2 | loss: 91.0889571CurrentTrain: epoch  1, batch     3 | loss: 74.7774111CurrentTrain: epoch  1, batch     4 | loss: 110.1784376CurrentTrain: epoch  2, batch     0 | loss: 107.6127381CurrentTrain: epoch  2, batch     1 | loss: 76.7128084CurrentTrain: epoch  2, batch     2 | loss: 85.3254516CurrentTrain: epoch  2, batch     3 | loss: 86.4195885CurrentTrain: epoch  2, batch     4 | loss: 46.9156307CurrentTrain: epoch  3, batch     0 | loss: 131.0269477CurrentTrain: epoch  3, batch     1 | loss: 98.4710015CurrentTrain: epoch  3, batch     2 | loss: 82.0221882CurrentTrain: epoch  3, batch     3 | loss: 85.3656114CurrentTrain: epoch  3, batch     4 | loss: 56.7679892CurrentTrain: epoch  4, batch     0 | loss: 86.4803980CurrentTrain: epoch  4, batch     1 | loss: 83.5393323CurrentTrain: epoch  4, batch     2 | loss: 79.2739047CurrentTrain: epoch  4, batch     3 | loss: 98.9979081CurrentTrain: epoch  4, batch     4 | loss: 54.9277920CurrentTrain: epoch  5, batch     0 | loss: 67.1611739CurrentTrain: epoch  5, batch     1 | loss: 81.2485312CurrentTrain: epoch  5, batch     2 | loss: 123.4515909CurrentTrain: epoch  5, batch     3 | loss: 103.5025566CurrentTrain: epoch  5, batch     4 | loss: 68.8636570CurrentTrain: epoch  6, batch     0 | loss: 70.9971170CurrentTrain: epoch  6, batch     1 | loss: 81.1182020CurrentTrain: epoch  6, batch     2 | loss: 95.6097241CurrentTrain: epoch  6, batch     3 | loss: 79.3652197CurrentTrain: epoch  6, batch     4 | loss: 68.8995812CurrentTrain: epoch  7, batch     0 | loss: 78.0952698CurrentTrain: epoch  7, batch     1 | loss: 95.4390063CurrentTrain: epoch  7, batch     2 | loss: 80.8819496CurrentTrain: epoch  7, batch     3 | loss: 98.6616949CurrentTrain: epoch  7, batch     4 | loss: 36.8552494CurrentTrain: epoch  8, batch     0 | loss: 80.8674174CurrentTrain: epoch  8, batch     1 | loss: 65.7734379CurrentTrain: epoch  8, batch     2 | loss: 66.3289079CurrentTrain: epoch  8, batch     3 | loss: 96.2490153CurrentTrain: epoch  8, batch     4 | loss: 68.5433341CurrentTrain: epoch  9, batch     0 | loss: 123.1341563CurrentTrain: epoch  9, batch     1 | loss: 93.4654066CurrentTrain: epoch  9, batch     2 | loss: 96.3370099CurrentTrain: epoch  9, batch     3 | loss: 65.3259637CurrentTrain: epoch  9, batch     4 | loss: 51.5008269
MemoryTrain:  epoch  0, batch     0 | loss: 1.5005261MemoryTrain:  epoch  1, batch     0 | loss: 1.1422894MemoryTrain:  epoch  2, batch     0 | loss: 1.0420478MemoryTrain:  epoch  3, batch     0 | loss: 0.9077749MemoryTrain:  epoch  4, batch     0 | loss: 0.6617860MemoryTrain:  epoch  5, batch     0 | loss: 0.5511993MemoryTrain:  epoch  6, batch     0 | loss: 0.5605467MemoryTrain:  epoch  7, batch     0 | loss: 0.3957600MemoryTrain:  epoch  8, batch     0 | loss: 0.3595681MemoryTrain:  epoch  9, batch     0 | loss: 0.2900316

F1 score per class: {32: np.float64(0.2122905027932961), 1: np.float64(0.7468354430379747), 34: np.float64(0.0), 3: np.float64(0.0), 35: np.float64(0.08602150537634409), 37: np.float64(0.0), 6: np.float64(0.5478260869565217), 8: np.float64(0.0), 14: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.6260869565217392), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.39911797133406834
Weighted-average F1 score: 0.34905671437996433
F1 score per class: {1: np.float64(0.2111111111111111), 3: np.float64(0.6049382716049383), 6: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.043478260869565216), 19: np.float64(0.0), 22: np.float64(0.5339366515837104), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.6885245901639344), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0)}
Micro-average F1 score: 0.3273073263558516
Weighted-average F1 score: 0.2699830551528329
F1 score per class: {32: np.float64(0.2111111111111111), 1: np.float64(0.6626506024096386), 34: np.float64(0.0), 3: np.float64(0.0), 35: np.float64(0.045454545454545456), 37: np.float64(0.0), 33: np.float64(0.5321888412017167), 6: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.6885245901639344), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.3555992141453831
Weighted-average F1 score: 0.3029153234313346

F1 score per class: {1: np.float64(0.1645021645021645), 3: np.float64(0.5315315315315315), 6: np.float64(0.5898617511520737), 8: np.float64(0.3971631205673759), 14: np.float64(0.07547169811320754), 15: np.float64(0.6956521739130435), 19: np.float64(0.6728110599078341), 20: np.float64(0.37681159420289856), 22: np.float64(0.48091603053435117), 24: np.float64(0.08695652173913043), 25: np.float64(0.3880597014925373), 26: np.float64(0.7058823529411765), 29: np.float64(0.8613861386138614), 30: np.float64(0.8823529411764706), 32: np.float64(0.6097560975609756), 33: np.float64(0.375), 34: np.float64(0.3), 35: np.float64(0.07894736842105263), 36: np.float64(0.5054945054945055), 37: np.float64(0.15789473684210525), 38: np.float64(0.13333333333333333)}
Micro-average F1 score: 0.4762247838616715
Weighted-average F1 score: 0.47554360875454393
F1 score per class: {1: np.float64(0.16740088105726872), 3: np.float64(0.4224137931034483), 6: np.float64(0.6135458167330677), 8: np.float64(0.45933014354066987), 14: np.float64(0.03260869565217391), 15: np.float64(0.6), 19: np.float64(0.6264150943396226), 20: np.float64(0.4672897196261682), 22: np.float64(0.46825396825396826), 24: np.float64(0.09523809523809523), 25: np.float64(0.5365853658536586), 26: np.float64(0.6633663366336634), 29: np.float64(0.8532110091743119), 30: np.float64(0.7058823529411765), 32: np.float64(0.5783132530120482), 33: np.float64(0.2857142857142857), 34: np.float64(0.37668161434977576), 35: np.float64(0.2727272727272727), 36: np.float64(0.6114649681528662), 37: np.float64(0.19298245614035087), 38: np.float64(0.42857142857142855)}
Micro-average F1 score: 0.47062386432465175
Weighted-average F1 score: 0.4561927303210716
F1 score per class: {1: np.float64(0.1630901287553648), 3: np.float64(0.46218487394957986), 6: np.float64(0.6024096385542169), 8: np.float64(0.4819277108433735), 14: np.float64(0.03409090909090909), 15: np.float64(0.631578947368421), 19: np.float64(0.6482213438735178), 20: np.float64(0.43478260869565216), 22: np.float64(0.46441947565543074), 24: np.float64(0.06896551724137931), 25: np.float64(0.5), 26: np.float64(0.6910994764397905), 29: np.float64(0.8599033816425121), 30: np.float64(0.8947368421052632), 32: np.float64(0.5806451612903226), 33: np.float64(0.3157894736842105), 34: np.float64(0.3088235294117647), 35: np.float64(0.203125), 36: np.float64(0.591304347826087), 37: np.float64(0.16279069767441862), 38: np.float64(0.3902439024390244)}
Micro-average F1 score: 0.46639057024530106
Weighted-average F1 score: 0.44882508392000137

F1 score per class: {32: np.float64(0.1130952380952381), 1: np.float64(0.6082474226804123), 34: np.float64(0.0), 3: np.float64(0.0), 35: np.float64(0.07079646017699115), 37: np.float64(0.0), 6: np.float64(0.4452296819787986), 33: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.0), 19: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.5), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.2830336200156372
Weighted-average F1 score: 0.24651193604184019
F1 score per class: {1: np.float64(0.1148036253776435), 3: np.float64(0.4666666666666667), 6: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.034482758620689655), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.43223443223443225), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.525), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.22279792746113988
Weighted-average F1 score: 0.18854754334620405
F1 score per class: {1: np.float64(0.11377245508982035), 3: np.float64(0.5092592592592593), 6: np.float64(0.0), 8: np.float64(0.0), 14: np.float64(0.03636363636363636), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.4290657439446367), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.5185185185185185), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.24509140148950576
Weighted-average F1 score: 0.213011564681888

F1 score per class: {1: np.float64(0.08315098468271334), 3: np.float64(0.3881578947368421), 6: np.float64(0.3742690058479532), 8: np.float64(0.345679012345679), 14: np.float64(0.058823529411764705), 15: np.float64(0.5161290322580645), 19: np.float64(0.6058091286307054), 20: np.float64(0.27956989247311825), 22: np.float64(0.36103151862464183), 24: np.float64(0.08), 25: np.float64(0.37681159420289856), 26: np.float64(0.6255924170616114), 29: np.float64(0.7280334728033473), 30: np.float64(0.8333333333333334), 32: np.float64(0.46153846153846156), 33: np.float64(0.3157894736842105), 34: np.float64(0.2188449848024316), 35: np.float64(0.06451612903225806), 36: np.float64(0.42592592592592593), 37: np.float64(0.1518987341772152), 38: np.float64(0.09090909090909091)}
Micro-average F1 score: 0.3580715059588299
Weighted-average F1 score: 0.3432852766239355
F1 score per class: {1: np.float64(0.08755760368663594), 3: np.float64(0.29080118694362017), 6: np.float64(0.3888888888888889), 8: np.float64(0.3106796116504854), 14: np.float64(0.025), 15: np.float64(0.46153846153846156), 19: np.float64(0.5478547854785478), 20: np.float64(0.28735632183908044), 22: np.float64(0.34911242603550297), 24: np.float64(0.07017543859649122), 25: np.float64(0.4835164835164835), 26: np.float64(0.575107296137339), 29: np.float64(0.6992481203007519), 30: np.float64(0.6206896551724138), 32: np.float64(0.43243243243243246), 33: np.float64(0.2222222222222222), 34: np.float64(0.25149700598802394), 35: np.float64(0.17872340425531916), 36: np.float64(0.4444444444444444), 37: np.float64(0.16176470588235295), 38: np.float64(0.2465753424657534)}
Micro-average F1 score: 0.33665511265164644
Weighted-average F1 score: 0.32219548043655977
F1 score per class: {1: np.float64(0.08501118568232663), 3: np.float64(0.3151862464183381), 6: np.float64(0.3826530612244898), 8: np.float64(0.3463203463203463), 14: np.float64(0.026200873362445413), 15: np.float64(0.48), 19: np.float64(0.5714285714285714), 20: np.float64(0.2857142857142857), 22: np.float64(0.34349030470914127), 24: np.float64(0.06060606060606061), 25: np.float64(0.46153846153846156), 26: np.float64(0.6055045871559633), 29: np.float64(0.7091633466135459), 30: np.float64(0.85), 32: np.float64(0.43373493975903615), 33: np.float64(0.2727272727272727), 34: np.float64(0.21374045801526717), 35: np.float64(0.14054054054054055), 36: np.float64(0.4503311258278146), 37: np.float64(0.14285714285714285), 38: np.float64(0.2222222222222222)}
Micro-average F1 score: 0.3377941855099216
Weighted-average F1 score: 0.31970801511279356
cur_acc_wo_na:  ['0.7537', '0.5060', '0.4856', '0.3991']
his_acc_wo_na:  ['0.7537', '0.6798', '0.6251', '0.4762']
cur_acc des_wo_na:  ['0.7542', '0.6101', '0.5673', '0.3273']
his_acc des_wo_na:  ['0.7542', '0.6924', '0.6188', '0.4706']
cur_acc rrf_wo_na:  ['0.7713', '0.6049', '0.5660', '0.3556']
his_acc rrf_wo_na:  ['0.7713', '0.6974', '0.6324', '0.4664']
cur_acc_w_na:  ['0.6395', '0.4218', '0.3867', '0.2830']
his_acc_w_na:  ['0.6395', '0.5552', '0.5078', '0.3581']
cur_acc des_w_na:  ['0.6107', '0.4767', '0.4070', '0.2228']
his_acc des_w_na:  ['0.6107', '0.5258', '0.4638', '0.3367']
cur_acc rrf_w_na:  ['0.6269', '0.4806', '0.4156', '0.2451']
his_acc rrf_w_na:  ['0.6269', '0.5443', '0.4832', '0.3378']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 149.1570310CurrentTrain: epoch  0, batch     1 | loss: 97.4348433CurrentTrain: epoch  0, batch     2 | loss: 88.4251483CurrentTrain: epoch  0, batch     3 | loss: 92.4681348CurrentTrain: epoch  0, batch     4 | loss: 122.0682405CurrentTrain: epoch  1, batch     0 | loss: 92.3690529CurrentTrain: epoch  1, batch     1 | loss: 107.8366159CurrentTrain: epoch  1, batch     2 | loss: 94.5026583CurrentTrain: epoch  1, batch     3 | loss: 101.4740002CurrentTrain: epoch  1, batch     4 | loss: 64.8079577CurrentTrain: epoch  2, batch     0 | loss: 90.1723374CurrentTrain: epoch  2, batch     1 | loss: 68.5918781CurrentTrain: epoch  2, batch     2 | loss: 106.0504596CurrentTrain: epoch  2, batch     3 | loss: 101.1492304CurrentTrain: epoch  2, batch     4 | loss: 116.3949075CurrentTrain: epoch  3, batch     0 | loss: 71.4900385CurrentTrain: epoch  3, batch     1 | loss: 97.5590081CurrentTrain: epoch  3, batch     2 | loss: 128.6863767CurrentTrain: epoch  3, batch     3 | loss: 87.2689538CurrentTrain: epoch  3, batch     4 | loss: 80.2750660CurrentTrain: epoch  4, batch     0 | loss: 82.2130248CurrentTrain: epoch  4, batch     1 | loss: 96.8398147CurrentTrain: epoch  4, batch     2 | loss: 123.5430054CurrentTrain: epoch  4, batch     3 | loss: 85.7913690CurrentTrain: epoch  4, batch     4 | loss: 51.9151914CurrentTrain: epoch  5, batch     0 | loss: 126.8648403CurrentTrain: epoch  5, batch     1 | loss: 83.9319576CurrentTrain: epoch  5, batch     2 | loss: 67.9775125CurrentTrain: epoch  5, batch     3 | loss: 99.1487124CurrentTrain: epoch  5, batch     4 | loss: 49.4818166CurrentTrain: epoch  6, batch     0 | loss: 83.7052585CurrentTrain: epoch  6, batch     1 | loss: 77.5913428CurrentTrain: epoch  6, batch     2 | loss: 83.2740098CurrentTrain: epoch  6, batch     3 | loss: 79.0572889CurrentTrain: epoch  6, batch     4 | loss: 63.9452037CurrentTrain: epoch  7, batch     0 | loss: 124.7092745CurrentTrain: epoch  7, batch     1 | loss: 98.1257040CurrentTrain: epoch  7, batch     2 | loss: 77.0171308CurrentTrain: epoch  7, batch     3 | loss: 79.4427969CurrentTrain: epoch  7, batch     4 | loss: 60.4848300CurrentTrain: epoch  8, batch     0 | loss: 96.0287656CurrentTrain: epoch  8, batch     1 | loss: 67.2022440CurrentTrain: epoch  8, batch     2 | loss: 123.6724259CurrentTrain: epoch  8, batch     3 | loss: 79.6560290CurrentTrain: epoch  8, batch     4 | loss: 40.2796635CurrentTrain: epoch  9, batch     0 | loss: 64.7812202CurrentTrain: epoch  9, batch     1 | loss: 95.1900532CurrentTrain: epoch  9, batch     2 | loss: 74.3815758CurrentTrain: epoch  9, batch     3 | loss: 95.8010399CurrentTrain: epoch  9, batch     4 | loss: 107.8847052
MemoryTrain:  epoch  0, batch     0 | loss: 1.0602161MemoryTrain:  epoch  1, batch     0 | loss: 0.8878800MemoryTrain:  epoch  2, batch     0 | loss: 0.6106005MemoryTrain:  epoch  3, batch     0 | loss: 0.5349857MemoryTrain:  epoch  4, batch     0 | loss: 0.4317814MemoryTrain:  epoch  5, batch     0 | loss: 0.3593312MemoryTrain:  epoch  6, batch     0 | loss: 0.3220480MemoryTrain:  epoch  7, batch     0 | loss: 0.2628993MemoryTrain:  epoch  8, batch     0 | loss: 0.2324502MemoryTrain:  epoch  9, batch     0 | loss: 0.2247808

F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.8888888888888888), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.3140495867768595), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.7868852459016393), 17: np.float64(0.0), 18: np.float64(0.13636363636363635), 22: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0)}
Micro-average F1 score: 0.47157190635451507
Weighted-average F1 score: 0.4132116164935448
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.7538461538461538), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.46808510638297873), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.696969696969697), 17: np.float64(0.0), 18: np.float64(0.16494845360824742), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.4180645161290323
Weighted-average F1 score: 0.3502899604899613
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.8032786885245902), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.45714285714285713), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.696969696969697), 17: np.float64(0.0), 18: np.float64(0.1568627450980392), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.44291609353507566
Weighted-average F1 score: 0.3752657050011905

F1 score per class: {1: np.float64(0.19383259911894274), 3: np.float64(0.3111111111111111), 5: np.float64(0.7330677290836654), 6: np.float64(0.4928909952606635), 8: np.float64(0.13186813186813187), 10: np.float64(0.2360248447204969), 14: np.float64(0.058823529411764705), 15: np.float64(0.6666666666666666), 16: np.float64(0.6486486486486487), 17: np.float64(0.0), 18: np.float64(0.08888888888888889), 19: np.float64(0.6637931034482759), 20: np.float64(0.4594594594594595), 22: np.float64(0.5168539325842697), 24: np.float64(0.10526315789473684), 25: np.float64(0.36363636363636365), 26: np.float64(0.6701570680628273), 29: np.float64(0.8442211055276382), 30: np.float64(0.9142857142857143), 32: np.float64(0.6), 33: np.float64(0.375), 34: np.float64(0.2413793103448276), 35: np.float64(0.08571428571428572), 36: np.float64(0.08695652173913043), 37: np.float64(0.17142857142857143), 38: np.float64(0.0)}
Micro-average F1 score: 0.4340758579169175
Weighted-average F1 score: 0.44936268205629326
F1 score per class: {1: np.float64(0.1623931623931624), 3: np.float64(0.4166666666666667), 5: np.float64(0.5490196078431373), 6: np.float64(0.5163636363636364), 8: np.float64(0.40816326530612246), 10: np.float64(0.34375), 14: np.float64(0.05813953488372093), 15: np.float64(0.6), 16: np.float64(0.5679012345679012), 17: np.float64(0.0), 18: np.float64(0.1095890410958904), 19: np.float64(0.6064981949458483), 20: np.float64(0.47058823529411764), 22: np.float64(0.4797297297297297), 24: np.float64(0.05714285714285714), 25: np.float64(0.46511627906976744), 26: np.float64(0.6448598130841121), 29: np.float64(0.8440366972477065), 30: np.float64(0.6181818181818182), 32: np.float64(0.5608856088560885), 33: np.float64(0.375), 34: np.float64(0.26198083067092653), 35: np.float64(0.27586206896551724), 36: np.float64(0.5511811023622047), 37: np.float64(0.1732283464566929), 38: np.float64(0.35555555555555557)}
Micro-average F1 score: 0.43411226210551673
Weighted-average F1 score: 0.4224299150566598
F1 score per class: {1: np.float64(0.15702479338842976), 3: np.float64(0.43617021276595747), 5: np.float64(0.6012269938650306), 6: np.float64(0.525096525096525), 8: np.float64(0.36065573770491804), 10: np.float64(0.32160804020100503), 14: np.float64(0.075), 15: np.float64(0.5714285714285714), 16: np.float64(0.5542168674698795), 17: np.float64(0.0), 18: np.float64(0.1038961038961039), 19: np.float64(0.631578947368421), 20: np.float64(0.5057471264367817), 22: np.float64(0.4931506849315068), 24: np.float64(0.07407407407407407), 25: np.float64(0.43243243243243246), 26: np.float64(0.6568627450980392), 29: np.float64(0.8653846153846154), 30: np.float64(0.7555555555555555), 32: np.float64(0.562962962962963), 33: np.float64(0.375), 34: np.float64(0.26548672566371684), 35: np.float64(0.21052631578947367), 36: np.float64(0.41379310344827586), 37: np.float64(0.17777777777777778), 38: np.float64(0.18181818181818182)}
Micro-average F1 score: 0.43657666836474784
Weighted-average F1 score: 0.4274384747610363

F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.7330677290836654), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.2923076923076923), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.4897959183673469), 17: np.float64(0.0), 18: np.float64(0.11538461538461539), 20: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.3357142857142857
Weighted-average F1 score: 0.28457331478832104
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.5764705882352941), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.4370860927152318), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.44660194174757284), 17: np.float64(0.0), 18: np.float64(0.13333333333333333), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 24: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.2817391304347826
Weighted-average F1 score: 0.23376766626909254
F1 score per class: {1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.6222222222222222), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.42105263157894735), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.4339622641509434), 17: np.float64(0.0), 18: np.float64(0.12698412698412698), 19: np.float64(0.0), 20: np.float64(0.0), 22: np.float64(0.0), 25: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.3026315789473684
Weighted-average F1 score: 0.25375029695043405

F1 score per class: {1: np.float64(0.09799554565701558), 3: np.float64(0.23863636363636365), 5: np.float64(0.5492537313432836), 6: np.float64(0.30678466076696165), 8: np.float64(0.12244897959183673), 10: np.float64(0.19689119170984457), 14: np.float64(0.04918032786885246), 15: np.float64(0.47058823529411764), 16: np.float64(0.37209302325581395), 17: np.float64(0.0), 18: np.float64(0.06451612903225806), 19: np.float64(0.5789473684210527), 20: np.float64(0.29310344827586204), 22: np.float64(0.40707964601769914), 24: np.float64(0.10526315789473684), 25: np.float64(0.34782608695652173), 26: np.float64(0.5818181818181818), 29: np.float64(0.7058823529411765), 30: np.float64(0.8648648648648649), 32: np.float64(0.45348837209302323), 33: np.float64(0.3), 34: np.float64(0.15317286652078774), 35: np.float64(0.07058823529411765), 36: np.float64(0.0821917808219178), 37: np.float64(0.16901408450704225), 38: np.float64(0.0)}
Micro-average F1 score: 0.32115812917594655
Weighted-average F1 score: 0.31692927897832407
F1 score per class: {1: np.float64(0.08370044052863436), 3: np.float64(0.3065134099616858), 5: np.float64(0.35443037974683544), 6: np.float64(0.30869565217391304), 8: np.float64(0.30456852791878175), 10: np.float64(0.26294820717131473), 14: np.float64(0.043859649122807015), 15: np.float64(0.375), 16: np.float64(0.323943661971831), 17: np.float64(0.0), 18: np.float64(0.08290155440414508), 19: np.float64(0.49851632047477745), 20: np.float64(0.2702702702702703), 22: np.float64(0.3558897243107769), 24: np.float64(0.043478260869565216), 25: np.float64(0.41237113402061853), 26: np.float64(0.5369649805447471), 29: np.float64(0.647887323943662), 30: np.float64(0.5151515151515151), 32: np.float64(0.4141689373297003), 33: np.float64(0.2222222222222222), 34: np.float64(0.15678776290630975), 35: np.float64(0.1941747572815534), 36: np.float64(0.4046242774566474), 37: np.float64(0.1301775147928994), 38: np.float64(0.2222222222222222)}
Micro-average F1 score: 0.30003330003330003
Weighted-average F1 score: 0.28915726201405956
F1 score per class: {1: np.float64(0.08137044967880086), 3: np.float64(0.3178294573643411), 5: np.float64(0.38811881188118813), 6: np.float64(0.32), 8: np.float64(0.2857142857142857), 10: np.float64(0.25196850393700787), 14: np.float64(0.056074766355140186), 15: np.float64(0.375), 16: np.float64(0.304635761589404), 17: np.float64(0.0), 18: np.float64(0.07407407407407407), 19: np.float64(0.5266457680250783), 20: np.float64(0.30344827586206896), 22: np.float64(0.366412213740458), 24: np.float64(0.06451612903225806), 25: np.float64(0.4), 26: np.float64(0.5606694560669456), 29: np.float64(0.694980694980695), 30: np.float64(0.7083333333333334), 32: np.float64(0.418732782369146), 33: np.float64(0.21428571428571427), 34: np.float64(0.15734265734265734), 35: np.float64(0.15286624203821655), 36: np.float64(0.3333333333333333), 37: np.float64(0.1553398058252427), 38: np.float64(0.1111111111111111)}
Micro-average F1 score: 0.3051450952465729
Weighted-average F1 score: 0.2925669609676079
cur_acc_wo_na:  ['0.7537', '0.5060', '0.4856', '0.3991', '0.4716']
his_acc_wo_na:  ['0.7537', '0.6798', '0.6251', '0.4762', '0.4341']
cur_acc des_wo_na:  ['0.7542', '0.6101', '0.5673', '0.3273', '0.4181']
his_acc des_wo_na:  ['0.7542', '0.6924', '0.6188', '0.4706', '0.4341']
cur_acc rrf_wo_na:  ['0.7713', '0.6049', '0.5660', '0.3556', '0.4429']
his_acc rrf_wo_na:  ['0.7713', '0.6974', '0.6324', '0.4664', '0.4366']
cur_acc_w_na:  ['0.6395', '0.4218', '0.3867', '0.2830', '0.3357']
his_acc_w_na:  ['0.6395', '0.5552', '0.5078', '0.3581', '0.3212']
cur_acc des_w_na:  ['0.6107', '0.4767', '0.4070', '0.2228', '0.2817']
his_acc des_w_na:  ['0.6107', '0.5258', '0.4638', '0.3367', '0.3000']
cur_acc rrf_w_na:  ['0.6269', '0.4806', '0.4156', '0.2451', '0.3026']
his_acc rrf_w_na:  ['0.6269', '0.5443', '0.4832', '0.3378', '0.3051']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 110.3246725CurrentTrain: epoch  0, batch     1 | loss: 144.3598839CurrentTrain: epoch  0, batch     2 | loss: 114.2790437CurrentTrain: epoch  0, batch     3 | loss: 97.1595729CurrentTrain: epoch  1, batch     0 | loss: 146.4126263CurrentTrain: epoch  1, batch     1 | loss: 79.4463872CurrentTrain: epoch  1, batch     2 | loss: 104.7057259CurrentTrain: epoch  1, batch     3 | loss: 74.0087336CurrentTrain: epoch  2, batch     0 | loss: 105.4889500CurrentTrain: epoch  2, batch     1 | loss: 76.7217087CurrentTrain: epoch  2, batch     2 | loss: 102.2189642CurrentTrain: epoch  2, batch     3 | loss: 60.3722606CurrentTrain: epoch  3, batch     0 | loss: 71.8842841CurrentTrain: epoch  3, batch     1 | loss: 87.4146028CurrentTrain: epoch  3, batch     2 | loss: 72.8113344CurrentTrain: epoch  3, batch     3 | loss: 70.7136854CurrentTrain: epoch  4, batch     0 | loss: 85.5423455CurrentTrain: epoch  4, batch     1 | loss: 85.3249114CurrentTrain: epoch  4, batch     2 | loss: 85.3359332CurrentTrain: epoch  4, batch     3 | loss: 61.8019903CurrentTrain: epoch  5, batch     0 | loss: 98.8056354CurrentTrain: epoch  5, batch     1 | loss: 86.2887214CurrentTrain: epoch  5, batch     2 | loss: 123.1760661CurrentTrain: epoch  5, batch     3 | loss: 61.3292203CurrentTrain: epoch  6, batch     0 | loss: 85.4628190CurrentTrain: epoch  6, batch     1 | loss: 99.2544672CurrentTrain: epoch  6, batch     2 | loss: 97.7879493CurrentTrain: epoch  6, batch     3 | loss: 51.1297540CurrentTrain: epoch  7, batch     0 | loss: 64.5959759CurrentTrain: epoch  7, batch     1 | loss: 94.6859048CurrentTrain: epoch  7, batch     2 | loss: 98.5369770CurrentTrain: epoch  7, batch     3 | loss: 83.4291789CurrentTrain: epoch  8, batch     0 | loss: 75.2336148CurrentTrain: epoch  8, batch     1 | loss: 77.7121255CurrentTrain: epoch  8, batch     2 | loss: 70.3265214CurrentTrain: epoch  8, batch     3 | loss: 99.2251167CurrentTrain: epoch  9, batch     0 | loss: 65.5042648CurrentTrain: epoch  9, batch     1 | loss: 66.7330806CurrentTrain: epoch  9, batch     2 | loss: 95.0573285CurrentTrain: epoch  9, batch     3 | loss: 78.0881731
MemoryTrain:  epoch  0, batch     0 | loss: 0.8837081MemoryTrain:  epoch  1, batch     0 | loss: 0.7573382MemoryTrain:  epoch  2, batch     0 | loss: 0.5941277MemoryTrain:  epoch  3, batch     0 | loss: 0.5060895MemoryTrain:  epoch  4, batch     0 | loss: 0.4061710MemoryTrain:  epoch  5, batch     0 | loss: 0.3783014MemoryTrain:  epoch  6, batch     0 | loss: 0.3067427MemoryTrain:  epoch  7, batch     0 | loss: 0.2421424MemoryTrain:  epoch  8, batch     0 | loss: 0.2196935MemoryTrain:  epoch  9, batch     0 | loss: 0.1971649

F1 score per class: {0: np.float64(0.8493150684931506), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.9247311827956989), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.26666666666666666), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.6538461538461539), 22: np.float64(0.0), 23: np.float64(0.7865168539325843), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0)}
Micro-average F1 score: 0.7066115702479339
Weighted-average F1 score: 0.6042930604120755
F1 score per class: {0: np.float64(0.7741935483870968), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8934010152284264), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.4444444444444444), 14: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.6557377049180327), 22: np.float64(0.0), 23: np.float64(0.6588235294117647), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.5958904109589042
Weighted-average F1 score: 0.48488994568626537
F1 score per class: {0: np.float64(0.8235294117647058), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.925531914893617), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.3076923076923077), 14: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.6349206349206349), 22: np.float64(0.0), 23: np.float64(0.6666666666666666), 26: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.6254545454545455
Weighted-average F1 score: 0.5103693506697261

F1 score per class: {0: np.float64(0.6262626262626263), 1: np.float64(0.1641025641025641), 3: np.float64(0.5402298850574713), 4: np.float64(0.9247311827956989), 5: np.float64(0.7450980392156863), 6: np.float64(0.5), 8: np.float64(0.14285714285714285), 10: np.float64(0.2485207100591716), 13: np.float64(0.0547945205479452), 14: np.float64(0.02666666666666667), 15: np.float64(0.6666666666666666), 16: np.float64(0.6285714285714286), 17: np.float64(0.16666666666666666), 18: np.float64(0.12903225806451613), 19: np.float64(0.6883720930232559), 20: np.float64(0.4358974358974359), 21: np.float64(0.21794871794871795), 22: np.float64(0.53), 23: np.float64(0.660377358490566), 24: np.float64(0.0), 25: np.float64(0.36363636363636365), 26: np.float64(0.6739130434782609), 29: np.float64(0.7979274611398963), 30: np.float64(0.9444444444444444), 32: np.float64(0.5808823529411765), 33: np.float64(0.4), 34: np.float64(0.22712933753943218), 35: np.float64(0.1927710843373494), 36: np.float64(0.08571428571428572), 37: np.float64(0.15151515151515152), 38: np.float64(0.0)}
Micro-average F1 score: 0.46743095362167797
Weighted-average F1 score: 0.47116157138929
F1 score per class: {0: np.float64(0.3891891891891892), 1: np.float64(0.18274111675126903), 3: np.float64(0.44635193133047213), 4: np.float64(0.8934010152284264), 5: np.float64(0.5616045845272206), 6: np.float64(0.5294117647058824), 8: np.float64(0.39759036144578314), 10: np.float64(0.30939226519337015), 13: np.float64(0.0851063829787234), 14: np.float64(0.04), 15: np.float64(0.631578947368421), 16: np.float64(0.5974025974025974), 17: np.float64(0.25), 18: np.float64(0.12612612612612611), 19: np.float64(0.6693227091633466), 20: np.float64(0.5360824742268041), 21: np.float64(0.2094240837696335), 22: np.float64(0.4326530612244898), 23: np.float64(0.5833333333333334), 24: np.float64(0.0), 25: np.float64(0.47619047619047616), 26: np.float64(0.6139534883720931), 29: np.float64(0.821917808219178), 30: np.float64(0.7083333333333334), 32: np.float64(0.5284280936454849), 33: np.float64(0.4), 34: np.float64(0.2711864406779661), 35: np.float64(0.302158273381295), 36: np.float64(0.5641025641025641), 37: np.float64(0.20618556701030927), 38: np.float64(0.37735849056603776)}
Micro-average F1 score: 0.45775862068965517
Weighted-average F1 score: 0.4443052950113938
F1 score per class: {0: np.float64(0.49295774647887325), 1: np.float64(0.17391304347826086), 3: np.float64(0.4473684210526316), 4: np.float64(0.925531914893617), 5: np.float64(0.6302250803858521), 6: np.float64(0.5207547169811321), 8: np.float64(0.265625), 10: np.float64(0.32085561497326204), 13: np.float64(0.05714285714285714), 14: np.float64(0.047244094488188976), 15: np.float64(0.6666666666666666), 16: np.float64(0.5974025974025974), 17: np.float64(0.21428571428571427), 18: np.float64(0.125), 19: np.float64(0.6720647773279352), 20: np.float64(0.5652173913043478), 21: np.float64(0.1932367149758454), 22: np.float64(0.47058823529411764), 23: np.float64(0.5656565656565656), 24: np.float64(0.0), 25: np.float64(0.4444444444444444), 26: np.float64(0.6341463414634146), 29: np.float64(0.8516746411483254), 30: np.float64(0.7906976744186046), 32: np.float64(0.5302013422818792), 33: np.float64(0.375), 34: np.float64(0.25384615384615383), 35: np.float64(0.256), 36: np.float64(0.38095238095238093), 37: np.float64(0.16666666666666666), 38: np.float64(0.16666666666666666)}
Micro-average F1 score: 0.4555176336746303
Weighted-average F1 score: 0.44350067468457377

F1 score per class: {0: np.float64(0.8378378378378378), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8911917098445595), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.15384615384615385), 15: np.float64(0.0), 16: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.4473684210526316), 22: np.float64(0.0), 23: np.float64(0.6862745098039216), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0)}
Micro-average F1 score: 0.5402843601895735
Weighted-average F1 score: 0.4237004242927297
F1 score per class: {0: np.float64(0.6792452830188679), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8585365853658536), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.25), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.4819277108433735), 22: np.float64(0.0), 23: np.float64(0.5714285714285714), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.44274809160305345
Weighted-average F1 score: 0.3426985231421008
F1 score per class: {0: np.float64(0.7692307692307693), 1: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.8877551020408163), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.18181818181818182), 14: np.float64(0.0), 15: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.45977011494252873), 22: np.float64(0.0), 23: np.float64(0.5773195876288659), 26: np.float64(0.0), 29: np.float64(0.0), 30: np.float64(0.0), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0)}
Micro-average F1 score: 0.4673913043478261
Weighted-average F1 score: 0.35749412062696495

F1 score per class: {0: np.float64(0.46616541353383456), 1: np.float64(0.08443271767810026), 3: np.float64(0.4017094017094017), 4: np.float64(0.8730964467005076), 5: np.float64(0.5352112676056338), 6: np.float64(0.30569948186528495), 8: np.float64(0.1308411214953271), 10: np.float64(0.20192307692307693), 13: np.float64(0.02702702702702703), 14: np.float64(0.024691358024691357), 15: np.float64(0.4444444444444444), 16: np.float64(0.4074074074074074), 17: np.float64(0.07547169811320754), 18: np.float64(0.09090909090909091), 19: np.float64(0.6297872340425532), 20: np.float64(0.2905982905982906), 21: np.float64(0.1349206349206349), 22: np.float64(0.47533632286995514), 23: np.float64(0.5384615384615384), 24: np.float64(0.0), 25: np.float64(0.34782608695652173), 26: np.float64(0.5876777251184834), 29: np.float64(0.6844444444444444), 30: np.float64(0.8717948717948718), 32: np.float64(0.42245989304812837), 33: np.float64(0.4), 34: np.float64(0.140625), 35: np.float64(0.14035087719298245), 36: np.float64(0.08333333333333333), 37: np.float64(0.14705882352941177), 38: np.float64(0.0)}
Micro-average F1 score: 0.3440076701821668
Weighted-average F1 score: 0.32752773015625697
F1 score per class: {0: np.float64(0.2465753424657534), 1: np.float64(0.09375), 3: np.float64(0.3023255813953488), 4: np.float64(0.8421052631578947), 5: np.float64(0.36981132075471695), 6: np.float64(0.3130434782608696), 8: np.float64(0.2693877551020408), 10: np.float64(0.21455938697318008), 13: np.float64(0.047058823529411764), 14: np.float64(0.032432432432432434), 15: np.float64(0.5), 16: np.float64(0.368), 17: np.float64(0.12307692307692308), 18: np.float64(0.08974358974358974), 19: np.float64(0.5544554455445545), 20: np.float64(0.3151515151515151), 21: np.float64(0.13377926421404682), 22: np.float64(0.334384858044164), 23: np.float64(0.45528455284552843), 24: np.float64(0.0), 25: np.float64(0.43010752688172044), 26: np.float64(0.5217391304347826), 29: np.float64(0.6428571428571429), 30: np.float64(0.6071428571428571), 32: np.float64(0.38349514563106796), 33: np.float64(0.3), 34: np.float64(0.1596009975062344), 35: np.float64(0.2), 36: np.float64(0.4342105263157895), 37: np.float64(0.1652892561983471), 38: np.float64(0.23529411764705882)}
Micro-average F1 score: 0.3180116783949693
Weighted-average F1 score: 0.30263284669258866
F1 score per class: {0: np.float64(0.3349282296650718), 1: np.float64(0.09), 3: np.float64(0.30177514792899407), 4: np.float64(0.8656716417910447), 5: np.float64(0.41350210970464135), 6: np.float64(0.3094170403587444), 8: np.float64(0.2), 10: np.float64(0.2222222222222222), 13: np.float64(0.03076923076923077), 14: np.float64(0.039735099337748346), 15: np.float64(0.5217391304347826), 16: np.float64(0.35658914728682173), 17: np.float64(0.10714285714285714), 18: np.float64(0.0880503144654088), 19: np.float64(0.5551839464882943), 20: np.float64(0.3333333333333333), 21: np.float64(0.1238390092879257), 22: np.float64(0.3701067615658363), 23: np.float64(0.4444444444444444), 24: np.float64(0.0), 25: np.float64(0.42105263157894735), 26: np.float64(0.5462184873949579), 29: np.float64(0.689922480620155), 30: np.float64(0.7083333333333334), 32: np.float64(0.38256658595641646), 33: np.float64(0.3157894736842105), 34: np.float64(0.1506849315068493), 35: np.float64(0.17777777777777778), 36: np.float64(0.3018867924528302), 37: np.float64(0.14634146341463414), 38: np.float64(0.11538461538461539)}
Micro-average F1 score: 0.31919642857142855
Weighted-average F1 score: 0.3023916026270091
cur_acc_wo_na:  ['0.7537', '0.5060', '0.4856', '0.3991', '0.4716', '0.7066']
his_acc_wo_na:  ['0.7537', '0.6798', '0.6251', '0.4762', '0.4341', '0.4674']
cur_acc des_wo_na:  ['0.7542', '0.6101', '0.5673', '0.3273', '0.4181', '0.5959']
his_acc des_wo_na:  ['0.7542', '0.6924', '0.6188', '0.4706', '0.4341', '0.4578']
cur_acc rrf_wo_na:  ['0.7713', '0.6049', '0.5660', '0.3556', '0.4429', '0.6255']
his_acc rrf_wo_na:  ['0.7713', '0.6974', '0.6324', '0.4664', '0.4366', '0.4555']
cur_acc_w_na:  ['0.6395', '0.4218', '0.3867', '0.2830', '0.3357', '0.5403']
his_acc_w_na:  ['0.6395', '0.5552', '0.5078', '0.3581', '0.3212', '0.3440']
cur_acc des_w_na:  ['0.6107', '0.4767', '0.4070', '0.2228', '0.2817', '0.4427']
his_acc des_w_na:  ['0.6107', '0.5258', '0.4638', '0.3367', '0.3000', '0.3180']
cur_acc rrf_w_na:  ['0.6269', '0.4806', '0.4156', '0.2451', '0.3026', '0.4674']
his_acc rrf_w_na:  ['0.6269', '0.5443', '0.4832', '0.3378', '0.3051', '0.3192']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death'])
CurrentTrain: epoch  0, batch     0 | loss: 89.5039355CurrentTrain: epoch  0, batch     1 | loss: 122.2184168CurrentTrain: epoch  0, batch     2 | loss: 111.1456546CurrentTrain: epoch  0, batch     3 | loss: 116.7831348CurrentTrain: epoch  0, batch     4 | loss: 28.9397043CurrentTrain: epoch  1, batch     0 | loss: 94.6910595CurrentTrain: epoch  1, batch     1 | loss: 132.3536915CurrentTrain: epoch  1, batch     2 | loss: 73.5256747CurrentTrain: epoch  1, batch     3 | loss: 181.1273573CurrentTrain: epoch  1, batch     4 | loss: 30.5113799CurrentTrain: epoch  2, batch     0 | loss: 107.8616400CurrentTrain: epoch  2, batch     1 | loss: 103.7979613CurrentTrain: epoch  2, batch     2 | loss: 98.8786090CurrentTrain: epoch  2, batch     3 | loss: 85.6161483CurrentTrain: epoch  2, batch     4 | loss: 15.2214574CurrentTrain: epoch  3, batch     0 | loss: 85.5254819CurrentTrain: epoch  3, batch     1 | loss: 84.8414899CurrentTrain: epoch  3, batch     2 | loss: 81.4827227CurrentTrain: epoch  3, batch     3 | loss: 81.2780896CurrentTrain: epoch  3, batch     4 | loss: 27.2153478CurrentTrain: epoch  4, batch     0 | loss: 68.6961511CurrentTrain: epoch  4, batch     1 | loss: 65.0689834CurrentTrain: epoch  4, batch     2 | loss: 86.2587406CurrentTrain: epoch  4, batch     3 | loss: 82.7624057CurrentTrain: epoch  4, batch     4 | loss: 44.3334312CurrentTrain: epoch  5, batch     0 | loss: 67.8629598CurrentTrain: epoch  5, batch     1 | loss: 123.7691806CurrentTrain: epoch  5, batch     2 | loss: 82.1863532CurrentTrain: epoch  5, batch     3 | loss: 78.9534892CurrentTrain: epoch  5, batch     4 | loss: 26.1642011CurrentTrain: epoch  6, batch     0 | loss: 79.5464110CurrentTrain: epoch  6, batch     1 | loss: 67.3189528CurrentTrain: epoch  6, batch     2 | loss: 76.2418993CurrentTrain: epoch  6, batch     3 | loss: 98.5933888CurrentTrain: epoch  6, batch     4 | loss: 41.1671019CurrentTrain: epoch  7, batch     0 | loss: 78.9165181CurrentTrain: epoch  7, batch     1 | loss: 68.1056074CurrentTrain: epoch  7, batch     2 | loss: 78.5505513CurrentTrain: epoch  7, batch     3 | loss: 77.8459461CurrentTrain: epoch  7, batch     4 | loss: 12.3908892CurrentTrain: epoch  8, batch     0 | loss: 65.3772595CurrentTrain: epoch  8, batch     1 | loss: 93.9448197CurrentTrain: epoch  8, batch     2 | loss: 80.6449788CurrentTrain: epoch  8, batch     3 | loss: 64.3871865CurrentTrain: epoch  8, batch     4 | loss: 24.9156567CurrentTrain: epoch  9, batch     0 | loss: 78.5171046CurrentTrain: epoch  9, batch     1 | loss: 91.6539053CurrentTrain: epoch  9, batch     2 | loss: 78.5021655CurrentTrain: epoch  9, batch     3 | loss: 75.3913173CurrentTrain: epoch  9, batch     4 | loss: 24.8396451
MemoryTrain:  epoch  0, batch     0 | loss: 0.8650422MemoryTrain:  epoch  1, batch     0 | loss: 0.7784175MemoryTrain:  epoch  2, batch     0 | loss: 0.6593520MemoryTrain:  epoch  3, batch     0 | loss: 0.5922891MemoryTrain:  epoch  4, batch     0 | loss: 0.4931059MemoryTrain:  epoch  5, batch     0 | loss: 0.4433930MemoryTrain:  epoch  6, batch     0 | loss: 0.3613387MemoryTrain:  epoch  7, batch     0 | loss: 0.3597184MemoryTrain:  epoch  8, batch     0 | loss: 0.3026149MemoryTrain:  epoch  9, batch     0 | loss: 0.2643888

F1 score per class: {0: np.float64(0.0), 2: np.float64(0.5833333333333334), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.31666666666666665), 12: np.float64(0.6075949367088608), 13: np.float64(0.0), 14: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 28: np.float64(0.46153846153846156), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.1111111111111111)}
Micro-average F1 score: 0.3951219512195122
Weighted-average F1 score: 0.32919359379363355
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.4827586206896552), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.3875968992248062), 12: np.float64(0.6629834254143646), 13: np.float64(0.0), 14: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 28: np.float64(0.5), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.4)}
Micro-average F1 score: 0.3562610229276896
Weighted-average F1 score: 0.25186293890969447
F1 score per class: {0: np.float64(0.0), 2: np.float64(0.5384615384615384), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.3875968992248062), 12: np.float64(0.6629213483146067), 13: np.float64(0.0), 14: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 28: np.float64(0.4), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.32)}
Micro-average F1 score: 0.38747553816046965
Weighted-average F1 score: 0.2913465212006936

F1 score per class: {0: np.float64(0.6966292134831461), 1: np.float64(0.17486338797814208), 2: np.float64(0.32558139534883723), 3: np.float64(0.32558139534883723), 4: np.float64(0.88268156424581), 5: np.float64(0.7929515418502202), 6: np.float64(0.5172413793103449), 8: np.float64(0.13793103448275862), 10: np.float64(0.25333333333333335), 11: np.float64(0.1386861313868613), 12: np.float64(0.34408602150537637), 13: np.float64(0.041666666666666664), 14: np.float64(0.02564102564102564), 15: np.float64(0.631578947368421), 16: np.float64(0.5079365079365079), 17: np.float64(0.0), 18: np.float64(0.0425531914893617), 19: np.float64(0.6899563318777293), 20: np.float64(0.29850746268656714), 21: np.float64(0.22429906542056074), 22: np.float64(0.5240641711229946), 23: np.float64(0.6666666666666666), 24: np.float64(0.0), 25: np.float64(0.36363636363636365), 26: np.float64(0.6588235294117647), 28: np.float64(0.11650485436893204), 29: np.float64(0.7553191489361702), 30: np.float64(0.9444444444444444), 32: np.float64(0.5745454545454546), 33: np.float64(0.375), 34: np.float64(0.24347826086956523), 35: np.float64(0.21621621621621623), 36: np.float64(0.11428571428571428), 37: np.float64(0.15384615384615385), 38: np.float64(0.23255813953488372), 39: np.float64(0.0425531914893617)}
Micro-average F1 score: 0.4296476306196841
Weighted-average F1 score: 0.4331672712354399
F1 score per class: {0: np.float64(0.36363636363636365), 1: np.float64(0.19148936170212766), 2: np.float64(0.1728395061728395), 3: np.float64(0.4581497797356828), 4: np.float64(0.8556701030927835), 5: np.float64(0.6139240506329114), 6: np.float64(0.5015290519877675), 8: np.float64(0.4225352112676056), 10: np.float64(0.3282051282051282), 11: np.float64(0.176056338028169), 12: np.float64(0.3076923076923077), 13: np.float64(0.03636363636363636), 14: np.float64(0.04316546762589928), 15: np.float64(0.631578947368421), 16: np.float64(0.6197183098591549), 17: np.float64(0.0), 18: np.float64(0.09302325581395349), 19: np.float64(0.6148148148148148), 20: np.float64(0.4835164835164835), 21: np.float64(0.17573221757322174), 22: np.float64(0.4019607843137255), 23: np.float64(0.6796116504854369), 24: np.float64(0.09090909090909091), 25: np.float64(0.5063291139240507), 26: np.float64(0.6598984771573604), 28: np.float64(0.21052631578947367), 29: np.float64(0.7881773399014779), 30: np.float64(0.6545454545454545), 32: np.float64(0.5191740412979351), 33: np.float64(0.3333333333333333), 34: np.float64(0.2602739726027397), 35: np.float64(0.25757575757575757), 36: np.float64(0.4175824175824176), 37: np.float64(0.18947368421052632), 38: np.float64(0.36666666666666664), 39: np.float64(0.13157894736842105)}
Micro-average F1 score: 0.41530855154733565
Weighted-average F1 score: 0.3994279668314677
F1 score per class: {0: np.float64(0.5299145299145299), 1: np.float64(0.18556701030927836), 2: np.float64(0.2222222222222222), 3: np.float64(0.4372093023255814), 4: np.float64(0.8901098901098901), 5: np.float64(0.714828897338403), 6: np.float64(0.5409252669039146), 8: np.float64(0.3064516129032258), 10: np.float64(0.31521739130434784), 11: np.float64(0.16778523489932887), 12: np.float64(0.3268698060941828), 13: np.float64(0.03389830508474576), 14: np.float64(0.046511627906976744), 15: np.float64(0.631578947368421), 16: np.float64(0.6027397260273972), 17: np.float64(0.0), 18: np.float64(0.05194805194805195), 19: np.float64(0.6459143968871596), 20: np.float64(0.525), 21: np.float64(0.20512820512820512), 22: np.float64(0.4563106796116505), 23: np.float64(0.7), 24: np.float64(0.1), 25: np.float64(0.5), 26: np.float64(0.6559139784946236), 28: np.float64(0.09302325581395349), 29: np.float64(0.797979797979798), 30: np.float64(0.8372093023255814), 32: np.float64(0.5566343042071198), 33: np.float64(0.3333333333333333), 34: np.float64(0.23943661971830985), 35: np.float64(0.1834862385321101), 36: np.float64(0.21052631578947367), 37: np.float64(0.16666666666666666), 38: np.float64(0.3728813559322034), 39: np.float64(0.1038961038961039)}
Micro-average F1 score: 0.42408376963350786
Weighted-average F1 score: 0.40814810039840066

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.35), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.2638888888888889), 12: np.float64(0.518918918918919), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.22641509433962265), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.08333333333333333)}
Micro-average F1 score: 0.2807625649913345
Weighted-average F1 score: 0.22558072196788337
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.2916666666666667), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.3184713375796178), 12: np.float64(0.5309734513274337), 13: np.float64(0.0), 14: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.2222222222222222), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.2702702702702703)}
Micro-average F1 score: 0.23059360730593606
Weighted-average F1 score: 0.17152300699952616
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.32558139534883723), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 8: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.3125), 12: np.float64(0.5291479820627802), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 23: np.float64(0.0), 26: np.float64(0.0), 28: np.float64(0.17391304347826086), 29: np.float64(0.0), 32: np.float64(0.0), 33: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 38: np.float64(0.0), 39: np.float64(0.21621621621621623)}
Micro-average F1 score: 0.2544987146529563
Weighted-average F1 score: 0.1972032877651687

F1 score per class: {0: np.float64(0.5210084033613446), 1: np.float64(0.08648648648648649), 2: np.float64(0.175), 3: np.float64(0.2625), 4: np.float64(0.8315789473684211), 5: np.float64(0.6405693950177936), 6: np.float64(0.29925187032418954), 8: np.float64(0.12903225806451613), 10: np.float64(0.2111111111111111), 11: np.float64(0.09268292682926829), 12: np.float64(0.14014598540145987), 13: np.float64(0.023529411764705882), 14: np.float64(0.022988505747126436), 15: np.float64(0.6), 16: np.float64(0.32), 17: np.float64(0.0), 18: np.float64(0.03333333333333333), 19: np.float64(0.6245059288537549), 20: np.float64(0.19801980198019803), 21: np.float64(0.12972972972972974), 22: np.float64(0.4803921568627451), 23: np.float64(0.5765765765765766), 24: np.float64(0.0), 25: np.float64(0.34782608695652173), 26: np.float64(0.5863874345549738), 28: np.float64(0.06153846153846154), 29: np.float64(0.6311111111111111), 30: np.float64(0.8717948717948718), 32: np.float64(0.42473118279569894), 33: np.float64(0.35294117647058826), 34: np.float64(0.2014388489208633), 35: np.float64(0.1702127659574468), 36: np.float64(0.10526315789473684), 37: np.float64(0.14705882352941177), 38: np.float64(0.15873015873015872), 39: np.float64(0.030303030303030304)}
Micro-average F1 score: 0.30315500685871055
Weighted-average F1 score: 0.28154176540650105
F1 score per class: {0: np.float64(0.24324324324324326), 1: np.float64(0.09473684210526316), 2: np.float64(0.09523809523809523), 3: np.float64(0.3365695792880259), 4: np.float64(0.7867298578199052), 5: np.float64(0.4190064794816415), 6: np.float64(0.2867132867132867), 8: np.float64(0.28938906752411575), 10: np.float64(0.23357664233576642), 11: np.float64(0.117096018735363), 12: np.float64(0.12972972972972974), 13: np.float64(0.0196078431372549), 14: np.float64(0.03529411764705882), 15: np.float64(0.5), 16: np.float64(0.4036697247706422), 17: np.float64(0.0), 18: np.float64(0.06504065040650407), 19: np.float64(0.532051282051282), 20: np.float64(0.2543352601156069), 21: np.float64(0.11413043478260869), 22: np.float64(0.3293172690763052), 23: np.float64(0.5263157894736842), 24: np.float64(0.08695652173913043), 25: np.float64(0.47619047619047616), 26: np.float64(0.5652173913043478), 28: np.float64(0.09302325581395349), 29: np.float64(0.642570281124498), 30: np.float64(0.5454545454545454), 32: np.float64(0.37209302325581395), 33: np.float64(0.24), 34: np.float64(0.16666666666666666), 35: np.float64(0.17801047120418848), 36: np.float64(0.31932773109243695), 37: np.float64(0.1565217391304348), 38: np.float64(0.24175824175824176), 39: np.float64(0.07142857142857142)}
Micro-average F1 score: 0.27544328394461987
Weighted-average F1 score: 0.25739834108622855
F1 score per class: {0: np.float64(0.3522727272727273), 1: np.float64(0.09350649350649351), 2: np.float64(0.12962962962962962), 3: np.float64(0.3197278911564626), 4: np.float64(0.8307692307692308), 5: np.float64(0.4986737400530504), 6: np.float64(0.30522088353413657), 8: np.float64(0.25165562913907286), 10: np.float64(0.22924901185770752), 11: np.float64(0.111358574610245), 12: np.float64(0.133032694475761), 13: np.float64(0.018867924528301886), 14: np.float64(0.038461538461538464), 15: np.float64(0.5), 16: np.float64(0.3826086956521739), 17: np.float64(0.0), 18: np.float64(0.034782608695652174), 19: np.float64(0.5608108108108109), 20: np.float64(0.2896551724137931), 21: np.float64(0.12779552715654952), 22: np.float64(0.37751004016064255), 23: np.float64(0.5303030303030303), 24: np.float64(0.09523809523809523), 25: np.float64(0.475), 26: np.float64(0.5754716981132075), 28: np.float64(0.04597701149425287), 29: np.float64(0.6556016597510373), 30: np.float64(0.7058823529411765), 32: np.float64(0.40375586854460094), 33: np.float64(0.2727272727272727), 34: np.float64(0.17), 35: np.float64(0.1388888888888889), 36: np.float64(0.18181818181818182), 37: np.float64(0.1518987341772152), 38: np.float64(0.23655913978494625), 39: np.float64(0.06299212598425197)}
Micro-average F1 score: 0.28417217649440024
Weighted-average F1 score: 0.2630494022308521
cur_acc_wo_na:  ['0.7537', '0.5060', '0.4856', '0.3991', '0.4716', '0.7066', '0.3951']
his_acc_wo_na:  ['0.7537', '0.6798', '0.6251', '0.4762', '0.4341', '0.4674', '0.4296']
cur_acc des_wo_na:  ['0.7542', '0.6101', '0.5673', '0.3273', '0.4181', '0.5959', '0.3563']
his_acc des_wo_na:  ['0.7542', '0.6924', '0.6188', '0.4706', '0.4341', '0.4578', '0.4153']
cur_acc rrf_wo_na:  ['0.7713', '0.6049', '0.5660', '0.3556', '0.4429', '0.6255', '0.3875']
his_acc rrf_wo_na:  ['0.7713', '0.6974', '0.6324', '0.4664', '0.4366', '0.4555', '0.4241']
cur_acc_w_na:  ['0.6395', '0.4218', '0.3867', '0.2830', '0.3357', '0.5403', '0.2808']
his_acc_w_na:  ['0.6395', '0.5552', '0.5078', '0.3581', '0.3212', '0.3440', '0.3032']
cur_acc des_w_na:  ['0.6107', '0.4767', '0.4070', '0.2228', '0.2817', '0.4427', '0.2306']
his_acc des_w_na:  ['0.6107', '0.5258', '0.4638', '0.3367', '0.3000', '0.3180', '0.2754']
cur_acc rrf_w_na:  ['0.6269', '0.4806', '0.4156', '0.2451', '0.3026', '0.4674', '0.2545']
his_acc rrf_w_na:  ['0.6269', '0.5443', '0.4832', '0.3378', '0.3051', '0.3192', '0.2842']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death', 'person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse', 'organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion', 'person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 82.1880624CurrentTrain: epoch  0, batch     1 | loss: 98.9167008CurrentTrain: epoch  0, batch     2 | loss: 83.7166911CurrentTrain: epoch  0, batch     3 | loss: 25.8030454CurrentTrain: epoch  1, batch     0 | loss: 105.9002700CurrentTrain: epoch  1, batch     1 | loss: 73.9784347CurrentTrain: epoch  1, batch     2 | loss: 87.9737604CurrentTrain: epoch  1, batch     3 | loss: 14.2642751CurrentTrain: epoch  2, batch     0 | loss: 78.4194505CurrentTrain: epoch  2, batch     1 | loss: 70.0217063CurrentTrain: epoch  2, batch     2 | loss: 107.8892965CurrentTrain: epoch  2, batch     3 | loss: 6.1326995CurrentTrain: epoch  3, batch     0 | loss: 62.5278010CurrentTrain: epoch  3, batch     1 | loss: 96.4203078CurrentTrain: epoch  3, batch     2 | loss: 86.4075922CurrentTrain: epoch  3, batch     3 | loss: 17.7965051CurrentTrain: epoch  4, batch     0 | loss: 78.1714421CurrentTrain: epoch  4, batch     1 | loss: 69.5548786CurrentTrain: epoch  4, batch     2 | loss: 76.0596500CurrentTrain: epoch  4, batch     3 | loss: 16.6408918CurrentTrain: epoch  5, batch     0 | loss: 73.3740921CurrentTrain: epoch  5, batch     1 | loss: 80.0763586CurrentTrain: epoch  5, batch     2 | loss: 68.3299825CurrentTrain: epoch  5, batch     3 | loss: 7.4337800CurrentTrain: epoch  6, batch     0 | loss: 64.6242828CurrentTrain: epoch  6, batch     1 | loss: 78.7004543CurrentTrain: epoch  6, batch     2 | loss: 73.7007537CurrentTrain: epoch  6, batch     3 | loss: 11.8680009CurrentTrain: epoch  7, batch     0 | loss: 64.6622919CurrentTrain: epoch  7, batch     1 | loss: 61.6725685CurrentTrain: epoch  7, batch     2 | loss: 77.2329136CurrentTrain: epoch  7, batch     3 | loss: 9.2667936CurrentTrain: epoch  8, batch     0 | loss: 75.5029614CurrentTrain: epoch  8, batch     1 | loss: 63.2814736CurrentTrain: epoch  8, batch     2 | loss: 73.5883639CurrentTrain: epoch  8, batch     3 | loss: 4.1057666CurrentTrain: epoch  9, batch     0 | loss: 63.2148494CurrentTrain: epoch  9, batch     1 | loss: 72.6860710CurrentTrain: epoch  9, batch     2 | loss: 74.0737226CurrentTrain: epoch  9, batch     3 | loss: 9.3673855
MemoryTrain:  epoch  0, batch     0 | loss: 0.8094425MemoryTrain:  epoch  1, batch     0 | loss: 0.7043016MemoryTrain:  epoch  2, batch     0 | loss: 0.5112130MemoryTrain:  epoch  3, batch     0 | loss: 0.4217978MemoryTrain:  epoch  4, batch     0 | loss: 0.3669649MemoryTrain:  epoch  5, batch     0 | loss: 0.3069729MemoryTrain:  epoch  6, batch     0 | loss: 0.2996965MemoryTrain:  epoch  7, batch     0 | loss: 0.3016345MemoryTrain:  epoch  8, batch     0 | loss: 0.2318989MemoryTrain:  epoch  9, batch     0 | loss: 0.2414928

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 3: np.float64(0.0), 7: np.float64(0.6), 9: np.float64(0.819672131147541), 10: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.4), 31: np.float64(0.2), 34: np.float64(0.0), 40: np.float64(0.35555555555555557)}
Micro-average F1 score: 0.3515151515151515
Weighted-average F1 score: 0.2866238278351211
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7272727272727273), 9: np.float64(0.6493506493506493), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.4), 30: np.float64(0.0), 31: np.float64(0.16666666666666666), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.4715447154471545)}
Micro-average F1 score: 0.3506849315068493
Weighted-average F1 score: 0.27841492229792686
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 3: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.7272727272727273), 9: np.float64(0.7575757575757576), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.4), 30: np.float64(0.0), 31: np.float64(0.18181818181818182), 32: np.float64(0.0), 34: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.4603174603174603)}
Micro-average F1 score: 0.3646723646723647
Weighted-average F1 score: 0.2860820379807722

F1 score per class: {0: np.float64(0.3711340206185567), 1: np.float64(0.14184397163120568), 2: np.float64(0.2545454545454545), 3: np.float64(0.3333333333333333), 4: np.float64(0.88268156424581), 5: np.float64(0.7175572519083969), 6: np.float64(0.325), 7: np.float64(0.0425531914893617), 8: np.float64(0.25263157894736843), 9: np.float64(0.78125), 10: np.float64(0.21768707482993196), 11: np.float64(0.1519756838905775), 12: np.float64(0.34210526315789475), 13: np.float64(0.0196078431372549), 14: np.float64(0.041666666666666664), 15: np.float64(0.6), 16: np.float64(0.53125), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5671641791044776), 20: np.float64(0.5365853658536586), 21: np.float64(0.21238938053097345), 22: np.float64(0.5482233502538071), 23: np.float64(0.7254901960784313), 24: np.float64(0.0), 25: np.float64(0.4657534246575342), 26: np.float64(0.5548387096774193), 27: np.float64(0.16129032258064516), 28: np.float64(0.14457831325301204), 29: np.float64(0.7262569832402235), 30: np.float64(0.8823529411764706), 31: np.float64(0.07407407407407407), 32: np.float64(0.6086956521739131), 33: np.float64(0.375), 34: np.float64(0.21428571428571427), 35: np.float64(0.09230769230769231), 36: np.float64(0.058823529411764705), 37: np.float64(0.14925373134328357), 38: np.float64(0.25), 39: np.float64(0.11764705882352941), 40: np.float64(0.12467532467532468)}
Micro-average F1 score: 0.36303243454474404
Weighted-average F1 score: 0.33904418815794246
F1 score per class: {0: np.float64(0.2723735408560311), 1: np.float64(0.16049382716049382), 2: np.float64(0.17777777777777778), 3: np.float64(0.48360655737704916), 4: np.float64(0.8105263157894737), 5: np.float64(0.5384615384615384), 6: np.float64(0.3516483516483517), 7: np.float64(0.043478260869565216), 8: np.float64(0.35), 9: np.float64(0.3184713375796178), 10: np.float64(0.26666666666666666), 11: np.float64(0.16733067729083664), 12: np.float64(0.3), 13: np.float64(0.02127659574468085), 14: np.float64(0.05084745762711865), 15: np.float64(0.6), 16: np.float64(0.5974025974025974), 17: np.float64(0.0), 18: np.float64(0.19540229885057472), 19: np.float64(0.5079365079365079), 20: np.float64(0.46296296296296297), 21: np.float64(0.2122905027932961), 22: np.float64(0.48), 23: np.float64(0.6060606060606061), 24: np.float64(0.1), 25: np.float64(0.5714285714285714), 26: np.float64(0.6178010471204188), 27: np.float64(0.14084507042253522), 28: np.float64(0.2222222222222222), 29: np.float64(0.743455497382199), 30: np.float64(0.7391304347826086), 31: np.float64(0.0425531914893617), 32: np.float64(0.5146579804560261), 33: np.float64(0.3333333333333333), 34: np.float64(0.2288135593220339), 35: np.float64(0.25225225225225223), 36: np.float64(0.3617021276595745), 37: np.float64(0.1782178217821782), 38: np.float64(0.3055555555555556), 39: np.float64(0.16901408450704225), 40: np.float64(0.21561338289962825)}
Micro-average F1 score: 0.36064505619807785
Weighted-average F1 score: 0.33804407528072766
F1 score per class: {0: np.float64(0.27906976744186046), 1: np.float64(0.15950920245398773), 2: np.float64(0.1917808219178082), 3: np.float64(0.5181818181818182), 4: np.float64(0.8603351955307262), 5: np.float64(0.6178343949044586), 6: np.float64(0.38857142857142857), 7: np.float64(0.046511627906976744), 8: np.float64(0.34285714285714286), 9: np.float64(0.6756756756756757), 10: np.float64(0.26993865030674846), 11: np.float64(0.16370106761565836), 12: np.float64(0.3086816720257235), 13: np.float64(0.021052631578947368), 14: np.float64(0.04838709677419355), 15: np.float64(0.6), 16: np.float64(0.6216216216216216), 17: np.float64(0.0), 18: np.float64(0.20134228187919462), 19: np.float64(0.541095890410959), 20: np.float64(0.5106382978723404), 21: np.float64(0.21468926553672316), 22: np.float64(0.5252525252525253), 23: np.float64(0.6947368421052632), 24: np.float64(0.10526315789473684), 25: np.float64(0.5569620253164557), 26: np.float64(0.6483516483516484), 27: np.float64(0.13157894736842105), 28: np.float64(0.15), 29: np.float64(0.7486631016042781), 30: np.float64(0.8421052631578947), 31: np.float64(0.06060606060606061), 32: np.float64(0.5555555555555556), 33: np.float64(0.3333333333333333), 34: np.float64(0.23478260869565218), 35: np.float64(0.2247191011235955), 36: np.float64(0.24691358024691357), 37: np.float64(0.175), 38: np.float64(0.2647058823529412), 39: np.float64(0.2), 40: np.float64(0.19141914191419143)}
Micro-average F1 score: 0.37571552471812664
Weighted-average F1 score: 0.34806322592547057

F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.5), 9: np.float64(0.7575757575757576), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.35714285714285715), 31: np.float64(0.16666666666666666), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 40: np.float64(0.32)}
Micro-average F1 score: 0.27294117647058824
Weighted-average F1 score: 0.21564900265864895
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6153846153846154), 9: np.float64(0.5319148936170213), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.37037037037037035), 28: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.125), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 36: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.4084507042253521)}
Micro-average F1 score: 0.2565130260521042
Weighted-average F1 score: 0.20325669347245612
F1 score per class: {0: np.float64(0.0), 1: np.float64(0.0), 3: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.6153846153846154), 9: np.float64(0.6666666666666666), 10: np.float64(0.0), 11: np.float64(0.0), 12: np.float64(0.0), 13: np.float64(0.0), 14: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.35714285714285715), 28: np.float64(0.0), 30: np.float64(0.0), 31: np.float64(0.13333333333333333), 32: np.float64(0.0), 34: np.float64(0.0), 35: np.float64(0.0), 37: np.float64(0.0), 40: np.float64(0.3945578231292517)}
Micro-average F1 score: 0.270042194092827
Weighted-average F1 score: 0.21069524390952962

F1 score per class: {0: np.float64(0.2535211267605634), 1: np.float64(0.0706713780918728), 2: np.float64(0.14), 3: np.float64(0.25806451612903225), 4: np.float64(0.8315789473684211), 5: np.float64(0.49604221635883905), 6: np.float64(0.19696969696969696), 7: np.float64(0.024896265560165973), 8: np.float64(0.22429906542056074), 9: np.float64(0.6944444444444444), 10: np.float64(0.17582417582417584), 11: np.float64(0.0984251968503937), 12: np.float64(0.14168937329700274), 13: np.float64(0.010582010582010581), 14: np.float64(0.03636363636363636), 15: np.float64(0.5217391304347826), 16: np.float64(0.33663366336633666), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.5371024734982333), 20: np.float64(0.2953020134228188), 21: np.float64(0.1276595744680851), 22: np.float64(0.4909090909090909), 23: np.float64(0.578125), 24: np.float64(0.0), 25: np.float64(0.4358974358974359), 26: np.float64(0.4942528735632184), 27: np.float64(0.12048192771084337), 28: np.float64(0.07792207792207792), 29: np.float64(0.6403940886699507), 30: np.float64(0.8108108108108109), 31: np.float64(0.038461538461538464), 32: np.float64(0.456973293768546), 33: np.float64(0.375), 34: np.float64(0.1411764705882353), 35: np.float64(0.07317073170731707), 36: np.float64(0.056338028169014086), 37: np.float64(0.14285714285714285), 38: np.float64(0.15384615384615385), 39: np.float64(0.07058823529411765), 40: np.float64(0.08921933085501858)}
Micro-average F1 score: 0.2508437964088025
Weighted-average F1 score: 0.22471021154485382
F1 score per class: {0: np.float64(0.171990171990172), 1: np.float64(0.08099688473520249), 2: np.float64(0.10062893081761007), 3: np.float64(0.3323943661971831), 4: np.float64(0.7549019607843137), 5: np.float64(0.31561996779388085), 6: np.float64(0.23880597014925373), 7: np.float64(0.021798365122615803), 8: np.float64(0.25), 9: np.float64(0.22727272727272727), 10: np.float64(0.19909502262443438), 11: np.float64(0.12804878048780488), 12: np.float64(0.13464235624123422), 13: np.float64(0.011299435028248588), 14: np.float64(0.04411764705882353), 15: np.float64(0.48), 16: np.float64(0.38016528925619836), 17: np.float64(0.0), 18: np.float64(0.11038961038961038), 19: np.float64(0.4456824512534819), 20: np.float64(0.24271844660194175), 21: np.float64(0.13523131672597866), 22: np.float64(0.4), 23: np.float64(0.46153846153846156), 24: np.float64(0.1), 25: np.float64(0.5), 26: np.float64(0.5315315315315315), 27: np.float64(0.09090909090909091), 28: np.float64(0.09259259259259259), 29: np.float64(0.6173913043478261), 30: np.float64(0.6666666666666666), 31: np.float64(0.022988505747126436), 32: np.float64(0.3648960739030023), 33: np.float64(0.24), 34: np.float64(0.1443850267379679), 35: np.float64(0.18181818181818182), 36: np.float64(0.288135593220339), 37: np.float64(0.15254237288135594), 38: np.float64(0.18803418803418803), 39: np.float64(0.0916030534351145), 40: np.float64(0.15064935064935064)}
Micro-average F1 score: 0.2388864911523522
Weighted-average F1 score: 0.2195346864138104
F1 score per class: {0: np.float64(0.1791044776119403), 1: np.float64(0.07926829268292683), 2: np.float64(0.109375), 3: np.float64(0.3713355048859935), 4: np.float64(0.8105263157894737), 5: np.float64(0.37524177949709864), 6: np.float64(0.2677165354330709), 7: np.float64(0.023323615160349854), 8: np.float64(0.28402366863905326), 9: np.float64(0.5617977528089888), 10: np.float64(0.2009132420091324), 11: np.float64(0.11794871794871795), 12: np.float64(0.13445378151260504), 13: np.float64(0.011235955056179775), 14: np.float64(0.041666666666666664), 15: np.float64(0.48), 16: np.float64(0.39655172413793105), 17: np.float64(0.0), 18: np.float64(0.11583011583011583), 19: np.float64(0.49842271293375395), 20: np.float64(0.26229508196721313), 21: np.float64(0.1347517730496454), 22: np.float64(0.4425531914893617), 23: np.float64(0.5196850393700787), 24: np.float64(0.10526315789473684), 25: np.float64(0.5057471264367817), 26: np.float64(0.5728155339805825), 27: np.float64(0.08771929824561403), 28: np.float64(0.06936416184971098), 29: np.float64(0.6278026905829597), 30: np.float64(0.7804878048780488), 31: np.float64(0.03125), 32: np.float64(0.39603960396039606), 33: np.float64(0.24), 34: np.float64(0.14958448753462603), 35: np.float64(0.16393442622950818), 36: np.float64(0.21052631578947367), 37: np.float64(0.16091954022988506), 38: np.float64(0.16822429906542055), 39: np.float64(0.11428571428571428), 40: np.float64(0.13488372093023257)}
Micro-average F1 score: 0.25168487102021847
Weighted-average F1 score: 0.22736971312407667
cur_acc_wo_na:  ['0.7537', '0.5060', '0.4856', '0.3991', '0.4716', '0.7066', '0.3951', '0.3515']
his_acc_wo_na:  ['0.7537', '0.6798', '0.6251', '0.4762', '0.4341', '0.4674', '0.4296', '0.3630']
cur_acc des_wo_na:  ['0.7542', '0.6101', '0.5673', '0.3273', '0.4181', '0.5959', '0.3563', '0.3507']
his_acc des_wo_na:  ['0.7542', '0.6924', '0.6188', '0.4706', '0.4341', '0.4578', '0.4153', '0.3606']
cur_acc rrf_wo_na:  ['0.7713', '0.6049', '0.5660', '0.3556', '0.4429', '0.6255', '0.3875', '0.3647']
his_acc rrf_wo_na:  ['0.7713', '0.6974', '0.6324', '0.4664', '0.4366', '0.4555', '0.4241', '0.3757']
cur_acc_w_na:  ['0.6395', '0.4218', '0.3867', '0.2830', '0.3357', '0.5403', '0.2808', '0.2729']
his_acc_w_na:  ['0.6395', '0.5552', '0.5078', '0.3581', '0.3212', '0.3440', '0.3032', '0.2508']
cur_acc des_w_na:  ['0.6107', '0.4767', '0.4070', '0.2228', '0.2817', '0.4427', '0.2306', '0.2565']
his_acc des_w_na:  ['0.6107', '0.5258', '0.4638', '0.3367', '0.3000', '0.3180', '0.2754', '0.2389']
cur_acc rrf_w_na:  ['0.6269', '0.4806', '0.4156', '0.2451', '0.3026', '0.4674', '0.2545', '0.2700']
his_acc rrf_w_na:  ['0.6269', '0.5443', '0.4832', '0.3378', '0.3051', '0.3192', '0.2842', '0.2517']
--------Round  5
seed:  600
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/na_test.pkl
Task_order: [7 2 0 1 6 3 4 5]
prepared data!
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA'])
CurrentTrain: epoch  0, batch     0 | loss: 107.7399305CurrentTrain: epoch  0, batch     1 | loss: 80.3521851CurrentTrain: epoch  0, batch     2 | loss: 120.6657427CurrentTrain: epoch  0, batch     3 | loss: 87.8241885CurrentTrain: epoch  0, batch     4 | loss: 88.2358685CurrentTrain: epoch  0, batch     5 | loss: 119.4870369CurrentTrain: epoch  0, batch     6 | loss: 101.8900403CurrentTrain: epoch  0, batch     7 | loss: 100.0227523CurrentTrain: epoch  0, batch     8 | loss: 87.0959973CurrentTrain: epoch  0, batch     9 | loss: 100.0186048CurrentTrain: epoch  0, batch    10 | loss: 100.8094918CurrentTrain: epoch  0, batch    11 | loss: 118.6382577CurrentTrain: epoch  0, batch    12 | loss: 85.9250197CurrentTrain: epoch  0, batch    13 | loss: 85.8721943CurrentTrain: epoch  0, batch    14 | loss: 99.6701368CurrentTrain: epoch  0, batch    15 | loss: 86.5548363CurrentTrain: epoch  0, batch    16 | loss: 99.0838293CurrentTrain: epoch  0, batch    17 | loss: 100.1568036CurrentTrain: epoch  0, batch    18 | loss: 99.0885641CurrentTrain: epoch  0, batch    19 | loss: 86.5140872CurrentTrain: epoch  0, batch    20 | loss: 145.7076317CurrentTrain: epoch  0, batch    21 | loss: 118.2789423CurrentTrain: epoch  0, batch    22 | loss: 117.8829607CurrentTrain: epoch  0, batch    23 | loss: 117.7564403CurrentTrain: epoch  0, batch    24 | loss: 75.8552457CurrentTrain: epoch  0, batch    25 | loss: 99.2940818CurrentTrain: epoch  0, batch    26 | loss: 192.1647922CurrentTrain: epoch  0, batch    27 | loss: 98.5118017CurrentTrain: epoch  0, batch    28 | loss: 191.3899518CurrentTrain: epoch  0, batch    29 | loss: 146.0405277CurrentTrain: epoch  0, batch    30 | loss: 117.6497264CurrentTrain: epoch  0, batch    31 | loss: 84.5627753CurrentTrain: epoch  0, batch    32 | loss: 116.4176695CurrentTrain: epoch  0, batch    33 | loss: 117.5680892CurrentTrain: epoch  0, batch    34 | loss: 117.1437643CurrentTrain: epoch  0, batch    35 | loss: 145.9902626CurrentTrain: epoch  0, batch    36 | loss: 96.3530027CurrentTrain: epoch  0, batch    37 | loss: 96.7827315CurrentTrain: epoch  0, batch    38 | loss: 82.4411970CurrentTrain: epoch  0, batch    39 | loss: 98.5105697CurrentTrain: epoch  0, batch    40 | loss: 85.1999159CurrentTrain: epoch  0, batch    41 | loss: 84.6710375CurrentTrain: epoch  0, batch    42 | loss: 83.8284292CurrentTrain: epoch  0, batch    43 | loss: 115.4694087CurrentTrain: epoch  0, batch    44 | loss: 96.7710797CurrentTrain: epoch  0, batch    45 | loss: 96.4200165CurrentTrain: epoch  0, batch    46 | loss: 94.5189011CurrentTrain: epoch  0, batch    47 | loss: 93.6190574CurrentTrain: epoch  0, batch    48 | loss: 82.4217379CurrentTrain: epoch  0, batch    49 | loss: 117.4278264CurrentTrain: epoch  0, batch    50 | loss: 95.9953319CurrentTrain: epoch  0, batch    51 | loss: 83.3414474CurrentTrain: epoch  0, batch    52 | loss: 81.3582294CurrentTrain: epoch  0, batch    53 | loss: 97.3713800CurrentTrain: epoch  0, batch    54 | loss: 95.3674124CurrentTrain: epoch  0, batch    55 | loss: 80.7408844CurrentTrain: epoch  0, batch    56 | loss: 112.2505890CurrentTrain: epoch  0, batch    57 | loss: 140.8134050CurrentTrain: epoch  0, batch    58 | loss: 93.7424954CurrentTrain: epoch  0, batch    59 | loss: 95.5566191CurrentTrain: epoch  0, batch    60 | loss: 142.8132290CurrentTrain: epoch  0, batch    61 | loss: 93.9287278CurrentTrain: epoch  0, batch    62 | loss: 94.4328866CurrentTrain: epoch  0, batch    63 | loss: 94.5264143CurrentTrain: epoch  0, batch    64 | loss: 80.4066224CurrentTrain: epoch  0, batch    65 | loss: 81.2292151CurrentTrain: epoch  0, batch    66 | loss: 92.8414918CurrentTrain: epoch  0, batch    67 | loss: 79.3789326CurrentTrain: epoch  0, batch    68 | loss: 93.7796223CurrentTrain: epoch  0, batch    69 | loss: 77.0579135CurrentTrain: epoch  0, batch    70 | loss: 112.9060439CurrentTrain: epoch  0, batch    71 | loss: 81.1330879CurrentTrain: epoch  0, batch    72 | loss: 91.2970369CurrentTrain: epoch  0, batch    73 | loss: 92.4245242CurrentTrain: epoch  0, batch    74 | loss: 78.9623620CurrentTrain: epoch  0, batch    75 | loss: 77.3993016CurrentTrain: epoch  0, batch    76 | loss: 95.8485036CurrentTrain: epoch  0, batch    77 | loss: 91.9610585CurrentTrain: epoch  0, batch    78 | loss: 140.4747957CurrentTrain: epoch  0, batch    79 | loss: 77.5472433CurrentTrain: epoch  0, batch    80 | loss: 78.7798972CurrentTrain: epoch  0, batch    81 | loss: 112.3363999CurrentTrain: epoch  0, batch    82 | loss: 111.8831277CurrentTrain: epoch  0, batch    83 | loss: 107.2146111CurrentTrain: epoch  0, batch    84 | loss: 95.1205187CurrentTrain: epoch  0, batch    85 | loss: 128.5221174CurrentTrain: epoch  0, batch    86 | loss: 95.6911951CurrentTrain: epoch  0, batch    87 | loss: 92.7426194CurrentTrain: epoch  0, batch    88 | loss: 91.5714424CurrentTrain: epoch  0, batch    89 | loss: 111.9106833CurrentTrain: epoch  0, batch    90 | loss: 78.6799393CurrentTrain: epoch  0, batch    91 | loss: 109.6217122CurrentTrain: epoch  0, batch    92 | loss: 91.4363546CurrentTrain: epoch  0, batch    93 | loss: 91.5562197CurrentTrain: epoch  0, batch    94 | loss: 113.6627444CurrentTrain: epoch  0, batch    95 | loss: 87.9685941CurrentTrain: epoch  1, batch     0 | loss: 88.6119987CurrentTrain: epoch  1, batch     1 | loss: 92.2422160CurrentTrain: epoch  1, batch     2 | loss: 78.6126953CurrentTrain: epoch  1, batch     3 | loss: 110.1551907CurrentTrain: epoch  1, batch     4 | loss: 91.8703241CurrentTrain: epoch  1, batch     5 | loss: 111.1027079CurrentTrain: epoch  1, batch     6 | loss: 68.7262605CurrentTrain: epoch  1, batch     7 | loss: 88.2298779CurrentTrain: epoch  1, batch     8 | loss: 87.7168722CurrentTrain: epoch  1, batch     9 | loss: 92.3083880CurrentTrain: epoch  1, batch    10 | loss: 89.2949333CurrentTrain: epoch  1, batch    11 | loss: 91.2682563CurrentTrain: epoch  1, batch    12 | loss: 87.5008553CurrentTrain: epoch  1, batch    13 | loss: 90.8302427CurrentTrain: epoch  1, batch    14 | loss: 108.5526499CurrentTrain: epoch  1, batch    15 | loss: 77.1058028CurrentTrain: epoch  1, batch    16 | loss: 67.3735470CurrentTrain: epoch  1, batch    17 | loss: 67.9352669CurrentTrain: epoch  1, batch    18 | loss: 104.7390381CurrentTrain: epoch  1, batch    19 | loss: 89.1915733CurrentTrain: epoch  1, batch    20 | loss: 93.2581224CurrentTrain: epoch  1, batch    21 | loss: 78.7324449CurrentTrain: epoch  1, batch    22 | loss: 79.0328086CurrentTrain: epoch  1, batch    23 | loss: 87.6894862CurrentTrain: epoch  1, batch    24 | loss: 107.4245620CurrentTrain: epoch  1, batch    25 | loss: 89.4756629CurrentTrain: epoch  1, batch    26 | loss: 76.6576754CurrentTrain: epoch  1, batch    27 | loss: 90.8257330CurrentTrain: epoch  1, batch    28 | loss: 104.5459631CurrentTrain: epoch  1, batch    29 | loss: 111.2373999CurrentTrain: epoch  1, batch    30 | loss: 90.9480172CurrentTrain: epoch  1, batch    31 | loss: 75.1853895CurrentTrain: epoch  1, batch    32 | loss: 109.9228636CurrentTrain: epoch  1, batch    33 | loss: 137.3276059CurrentTrain: epoch  1, batch    34 | loss: 86.6663542CurrentTrain: epoch  1, batch    35 | loss: 88.4926089CurrentTrain: epoch  1, batch    36 | loss: 75.7619499CurrentTrain: epoch  1, batch    37 | loss: 63.4268021CurrentTrain: epoch  1, batch    38 | loss: 89.2537186CurrentTrain: epoch  1, batch    39 | loss: 104.4672631CurrentTrain: epoch  1, batch    40 | loss: 85.2625466CurrentTrain: epoch  1, batch    41 | loss: 72.7622715CurrentTrain: epoch  1, batch    42 | loss: 89.5505622CurrentTrain: epoch  1, batch    43 | loss: 73.4497475CurrentTrain: epoch  1, batch    44 | loss: 84.0849438CurrentTrain: epoch  1, batch    45 | loss: 88.2980239CurrentTrain: epoch  1, batch    46 | loss: 106.6245812CurrentTrain: epoch  1, batch    47 | loss: 134.4494927CurrentTrain: epoch  1, batch    48 | loss: 85.3972570CurrentTrain: epoch  1, batch    49 | loss: 140.8548246CurrentTrain: epoch  1, batch    50 | loss: 109.5266677CurrentTrain: epoch  1, batch    51 | loss: 72.9440344CurrentTrain: epoch  1, batch    52 | loss: 134.0987092CurrentTrain: epoch  1, batch    53 | loss: 64.9199697CurrentTrain: epoch  1, batch    54 | loss: 90.5870409CurrentTrain: epoch  1, batch    55 | loss: 89.2516197CurrentTrain: epoch  1, batch    56 | loss: 183.6867003CurrentTrain: epoch  1, batch    57 | loss: 62.8238606CurrentTrain: epoch  1, batch    58 | loss: 177.9456719CurrentTrain: epoch  1, batch    59 | loss: 109.9232387CurrentTrain: epoch  1, batch    60 | loss: 71.6604381CurrentTrain: epoch  1, batch    61 | loss: 89.9620104CurrentTrain: epoch  1, batch    62 | loss: 87.6297264CurrentTrain: epoch  1, batch    63 | loss: 75.0422544CurrentTrain: epoch  1, batch    64 | loss: 102.3336583CurrentTrain: epoch  1, batch    65 | loss: 87.9732871CurrentTrain: epoch  1, batch    66 | loss: 89.5789775CurrentTrain: epoch  1, batch    67 | loss: 89.5091818CurrentTrain: epoch  1, batch    68 | loss: 107.5698643CurrentTrain: epoch  1, batch    69 | loss: 90.0807227CurrentTrain: epoch  1, batch    70 | loss: 89.4967353CurrentTrain: epoch  1, batch    71 | loss: 73.2165428CurrentTrain: epoch  1, batch    72 | loss: 122.3229553CurrentTrain: epoch  1, batch    73 | loss: 60.3355769CurrentTrain: epoch  1, batch    74 | loss: 103.5177913CurrentTrain: epoch  1, batch    75 | loss: 76.9684243CurrentTrain: epoch  1, batch    76 | loss: 141.8368601CurrentTrain: epoch  1, batch    77 | loss: 88.0164643CurrentTrain: epoch  1, batch    78 | loss: 88.6902054CurrentTrain: epoch  1, batch    79 | loss: 91.4284647CurrentTrain: epoch  1, batch    80 | loss: 92.8524682CurrentTrain: epoch  1, batch    81 | loss: 92.8351182CurrentTrain: epoch  1, batch    82 | loss: 106.3382992CurrentTrain: epoch  1, batch    83 | loss: 94.3481427CurrentTrain: epoch  1, batch    84 | loss: 105.4383248CurrentTrain: epoch  1, batch    85 | loss: 107.6184879CurrentTrain: epoch  1, batch    86 | loss: 84.5816221CurrentTrain: epoch  1, batch    87 | loss: 83.5904313CurrentTrain: epoch  1, batch    88 | loss: 66.6310051CurrentTrain: epoch  1, batch    89 | loss: 109.3712546CurrentTrain: epoch  1, batch    90 | loss: 73.3811485CurrentTrain: epoch  1, batch    91 | loss: 134.1000380CurrentTrain: epoch  1, batch    92 | loss: 74.6707155CurrentTrain: epoch  1, batch    93 | loss: 107.4136671CurrentTrain: epoch  1, batch    94 | loss: 88.4708469CurrentTrain: epoch  1, batch    95 | loss: 150.5361668CurrentTrain: epoch  2, batch     0 | loss: 75.9562066CurrentTrain: epoch  2, batch     1 | loss: 85.6210973CurrentTrain: epoch  2, batch     2 | loss: 84.4113731CurrentTrain: epoch  2, batch     3 | loss: 104.8498609CurrentTrain: epoch  2, batch     4 | loss: 91.0022940CurrentTrain: epoch  2, batch     5 | loss: 66.6140342CurrentTrain: epoch  2, batch     6 | loss: 64.0537431CurrentTrain: epoch  2, batch     7 | loss: 73.3611940CurrentTrain: epoch  2, batch     8 | loss: 104.9755062CurrentTrain: epoch  2, batch     9 | loss: 136.3138863CurrentTrain: epoch  2, batch    10 | loss: 74.6422788CurrentTrain: epoch  2, batch    11 | loss: 181.5115847CurrentTrain: epoch  2, batch    12 | loss: 107.5380897CurrentTrain: epoch  2, batch    13 | loss: 66.8303565CurrentTrain: epoch  2, batch    14 | loss: 131.1410743CurrentTrain: epoch  2, batch    15 | loss: 83.5859240CurrentTrain: epoch  2, batch    16 | loss: 84.5734892CurrentTrain: epoch  2, batch    17 | loss: 82.2586858CurrentTrain: epoch  2, batch    18 | loss: 72.0376825CurrentTrain: epoch  2, batch    19 | loss: 101.1758818CurrentTrain: epoch  2, batch    20 | loss: 73.7868031CurrentTrain: epoch  2, batch    21 | loss: 107.0018681CurrentTrain: epoch  2, batch    22 | loss: 63.7298638CurrentTrain: epoch  2, batch    23 | loss: 73.8599383CurrentTrain: epoch  2, batch    24 | loss: 72.0213860CurrentTrain: epoch  2, batch    25 | loss: 130.5191572CurrentTrain: epoch  2, batch    26 | loss: 110.2728701CurrentTrain: epoch  2, batch    27 | loss: 133.9383031CurrentTrain: epoch  2, batch    28 | loss: 88.1414818CurrentTrain: epoch  2, batch    29 | loss: 106.3137231CurrentTrain: epoch  2, batch    30 | loss: 90.1290890CurrentTrain: epoch  2, batch    31 | loss: 103.5654991CurrentTrain: epoch  2, batch    32 | loss: 86.0274347CurrentTrain: epoch  2, batch    33 | loss: 70.5493143CurrentTrain: epoch  2, batch    34 | loss: 89.7477413CurrentTrain: epoch  2, batch    35 | loss: 88.3641983CurrentTrain: epoch  2, batch    36 | loss: 69.7442566CurrentTrain: epoch  2, batch    37 | loss: 102.7046579CurrentTrain: epoch  2, batch    38 | loss: 84.2365393CurrentTrain: epoch  2, batch    39 | loss: 75.4144311CurrentTrain: epoch  2, batch    40 | loss: 89.1967465CurrentTrain: epoch  2, batch    41 | loss: 75.1774140CurrentTrain: epoch  2, batch    42 | loss: 102.7186482CurrentTrain: epoch  2, batch    43 | loss: 129.1156000CurrentTrain: epoch  2, batch    44 | loss: 72.8869877CurrentTrain: epoch  2, batch    45 | loss: 83.8792043CurrentTrain: epoch  2, batch    46 | loss: 63.9436733CurrentTrain: epoch  2, batch    47 | loss: 100.9314243CurrentTrain: epoch  2, batch    48 | loss: 86.7955402CurrentTrain: epoch  2, batch    49 | loss: 87.4756155CurrentTrain: epoch  2, batch    50 | loss: 86.6338423CurrentTrain: epoch  2, batch    51 | loss: 106.8566890CurrentTrain: epoch  2, batch    52 | loss: 74.8131616CurrentTrain: epoch  2, batch    53 | loss: 129.5122720CurrentTrain: epoch  2, batch    54 | loss: 61.1409039CurrentTrain: epoch  2, batch    55 | loss: 70.6132125CurrentTrain: epoch  2, batch    56 | loss: 100.4563878CurrentTrain: epoch  2, batch    57 | loss: 86.3179693CurrentTrain: epoch  2, batch    58 | loss: 108.5831304CurrentTrain: epoch  2, batch    59 | loss: 75.1050363CurrentTrain: epoch  2, batch    60 | loss: 133.2760051CurrentTrain: epoch  2, batch    61 | loss: 82.7437264CurrentTrain: epoch  2, batch    62 | loss: 83.5785137CurrentTrain: epoch  2, batch    63 | loss: 71.8268071CurrentTrain: epoch  2, batch    64 | loss: 71.6438616CurrentTrain: epoch  2, batch    65 | loss: 83.7742664CurrentTrain: epoch  2, batch    66 | loss: 73.2888687CurrentTrain: epoch  2, batch    67 | loss: 81.9553287CurrentTrain: epoch  2, batch    68 | loss: 86.8056333CurrentTrain: epoch  2, batch    69 | loss: 103.7106992CurrentTrain: epoch  2, batch    70 | loss: 104.1153118CurrentTrain: epoch  2, batch    71 | loss: 65.6301081CurrentTrain: epoch  2, batch    72 | loss: 72.7440601CurrentTrain: epoch  2, batch    73 | loss: 82.7662471CurrentTrain: epoch  2, batch    74 | loss: 86.0856604CurrentTrain: epoch  2, batch    75 | loss: 74.5143726CurrentTrain: epoch  2, batch    76 | loss: 88.7894138CurrentTrain: epoch  2, batch    77 | loss: 127.7440456CurrentTrain: epoch  2, batch    78 | loss: 101.0477844CurrentTrain: epoch  2, batch    79 | loss: 103.5703698CurrentTrain: epoch  2, batch    80 | loss: 63.1249990CurrentTrain: epoch  2, batch    81 | loss: 88.4632145CurrentTrain: epoch  2, batch    82 | loss: 66.2926948CurrentTrain: epoch  2, batch    83 | loss: 83.3882556CurrentTrain: epoch  2, batch    84 | loss: 74.9567008CurrentTrain: epoch  2, batch    85 | loss: 95.2191025CurrentTrain: epoch  2, batch    86 | loss: 103.4199496CurrentTrain: epoch  2, batch    87 | loss: 102.0968346CurrentTrain: epoch  2, batch    88 | loss: 134.3483009CurrentTrain: epoch  2, batch    89 | loss: 73.6161790CurrentTrain: epoch  2, batch    90 | loss: 89.1737327CurrentTrain: epoch  2, batch    91 | loss: 83.7826483CurrentTrain: epoch  2, batch    92 | loss: 85.0972566CurrentTrain: epoch  2, batch    93 | loss: 87.3924426CurrentTrain: epoch  2, batch    94 | loss: 72.3740099CurrentTrain: epoch  2, batch    95 | loss: 86.5233530CurrentTrain: epoch  3, batch     0 | loss: 82.1930296CurrentTrain: epoch  3, batch     1 | loss: 85.1211439CurrentTrain: epoch  3, batch     2 | loss: 98.2511768CurrentTrain: epoch  3, batch     3 | loss: 87.1592574CurrentTrain: epoch  3, batch     4 | loss: 108.4615819CurrentTrain: epoch  3, batch     5 | loss: 61.1906724CurrentTrain: epoch  3, batch     6 | loss: 70.4355010CurrentTrain: epoch  3, batch     7 | loss: 71.5651634CurrentTrain: epoch  3, batch     8 | loss: 126.0873708CurrentTrain: epoch  3, batch     9 | loss: 101.4175669CurrentTrain: epoch  3, batch    10 | loss: 106.5402777CurrentTrain: epoch  3, batch    11 | loss: 103.9413850CurrentTrain: epoch  3, batch    12 | loss: 72.2010796CurrentTrain: epoch  3, batch    13 | loss: 101.7464319CurrentTrain: epoch  3, batch    14 | loss: 102.0236238CurrentTrain: epoch  3, batch    15 | loss: 68.2927541CurrentTrain: epoch  3, batch    16 | loss: 79.1131839CurrentTrain: epoch  3, batch    17 | loss: 81.8276827CurrentTrain: epoch  3, batch    18 | loss: 100.3119077CurrentTrain: epoch  3, batch    19 | loss: 103.3601285CurrentTrain: epoch  3, batch    20 | loss: 73.8788795CurrentTrain: epoch  3, batch    21 | loss: 65.2493896CurrentTrain: epoch  3, batch    22 | loss: 66.4260015CurrentTrain: epoch  3, batch    23 | loss: 124.8585301CurrentTrain: epoch  3, batch    24 | loss: 86.6479444CurrentTrain: epoch  3, batch    25 | loss: 74.0008666CurrentTrain: epoch  3, batch    26 | loss: 103.2122003CurrentTrain: epoch  3, batch    27 | loss: 103.8916517CurrentTrain: epoch  3, batch    28 | loss: 60.0141887CurrentTrain: epoch  3, batch    29 | loss: 69.0015917CurrentTrain: epoch  3, batch    30 | loss: 86.0797701CurrentTrain: epoch  3, batch    31 | loss: 98.3342042CurrentTrain: epoch  3, batch    32 | loss: 101.3529011CurrentTrain: epoch  3, batch    33 | loss: 69.3660540CurrentTrain: epoch  3, batch    34 | loss: 85.0878937CurrentTrain: epoch  3, batch    35 | loss: 56.7285456CurrentTrain: epoch  3, batch    36 | loss: 69.7745844CurrentTrain: epoch  3, batch    37 | loss: 136.3455143CurrentTrain: epoch  3, batch    38 | loss: 81.6804501CurrentTrain: epoch  3, batch    39 | loss: 74.4608064CurrentTrain: epoch  3, batch    40 | loss: 87.3214310CurrentTrain: epoch  3, batch    41 | loss: 86.2417137CurrentTrain: epoch  3, batch    42 | loss: 62.8551401CurrentTrain: epoch  3, batch    43 | loss: 87.9712562CurrentTrain: epoch  3, batch    44 | loss: 97.3297226CurrentTrain: epoch  3, batch    45 | loss: 103.2463767CurrentTrain: epoch  3, batch    46 | loss: 100.3684301CurrentTrain: epoch  3, batch    47 | loss: 61.0131991CurrentTrain: epoch  3, batch    48 | loss: 73.8468507CurrentTrain: epoch  3, batch    49 | loss: 73.2232358CurrentTrain: epoch  3, batch    50 | loss: 68.3585629CurrentTrain: epoch  3, batch    51 | loss: 98.7926603CurrentTrain: epoch  3, batch    52 | loss: 70.6155839CurrentTrain: epoch  3, batch    53 | loss: 86.2205124CurrentTrain: epoch  3, batch    54 | loss: 81.8443640CurrentTrain: epoch  3, batch    55 | loss: 102.4390850CurrentTrain: epoch  3, batch    56 | loss: 84.2727092CurrentTrain: epoch  3, batch    57 | loss: 132.8900419CurrentTrain: epoch  3, batch    58 | loss: 130.7593396CurrentTrain: epoch  3, batch    59 | loss: 129.0255597CurrentTrain: epoch  3, batch    60 | loss: 82.4419742CurrentTrain: epoch  3, batch    61 | loss: 81.1283899CurrentTrain: epoch  3, batch    62 | loss: 101.8260553CurrentTrain: epoch  3, batch    63 | loss: 133.1228499CurrentTrain: epoch  3, batch    64 | loss: 61.5749660CurrentTrain: epoch  3, batch    65 | loss: 73.3388482CurrentTrain: epoch  3, batch    66 | loss: 128.1170735CurrentTrain: epoch  3, batch    67 | loss: 87.2166508CurrentTrain: epoch  3, batch    68 | loss: 58.0017377CurrentTrain: epoch  3, batch    69 | loss: 103.5260688CurrentTrain: epoch  3, batch    70 | loss: 87.2580456CurrentTrain: epoch  3, batch    71 | loss: 69.5541089CurrentTrain: epoch  3, batch    72 | loss: 71.9350071CurrentTrain: epoch  3, batch    73 | loss: 83.8107451CurrentTrain: epoch  3, batch    74 | loss: 88.5634433CurrentTrain: epoch  3, batch    75 | loss: 71.5509789CurrentTrain: epoch  3, batch    76 | loss: 73.3955553CurrentTrain: epoch  3, batch    77 | loss: 71.7578811CurrentTrain: epoch  3, batch    78 | loss: 70.9072144CurrentTrain: epoch  3, batch    79 | loss: 109.3578890CurrentTrain: epoch  3, batch    80 | loss: 86.8892304CurrentTrain: epoch  3, batch    81 | loss: 79.5238061CurrentTrain: epoch  3, batch    82 | loss: 106.5757524CurrentTrain: epoch  3, batch    83 | loss: 102.3453089CurrentTrain: epoch  3, batch    84 | loss: 103.4912598CurrentTrain: epoch  3, batch    85 | loss: 104.7837689CurrentTrain: epoch  3, batch    86 | loss: 99.3521854CurrentTrain: epoch  3, batch    87 | loss: 104.7255758CurrentTrain: epoch  3, batch    88 | loss: 99.7102399CurrentTrain: epoch  3, batch    89 | loss: 60.1803908CurrentTrain: epoch  3, batch    90 | loss: 136.2979860CurrentTrain: epoch  3, batch    91 | loss: 102.6200241CurrentTrain: epoch  3, batch    92 | loss: 88.1535323CurrentTrain: epoch  3, batch    93 | loss: 83.8514395CurrentTrain: epoch  3, batch    94 | loss: 88.3978248CurrentTrain: epoch  3, batch    95 | loss: 70.4965478CurrentTrain: epoch  4, batch     0 | loss: 81.5972883CurrentTrain: epoch  4, batch     1 | loss: 70.3755689CurrentTrain: epoch  4, batch     2 | loss: 69.9727348CurrentTrain: epoch  4, batch     3 | loss: 128.5274451CurrentTrain: epoch  4, batch     4 | loss: 61.1821128CurrentTrain: epoch  4, batch     5 | loss: 73.6110376CurrentTrain: epoch  4, batch     6 | loss: 82.2957942CurrentTrain: epoch  4, batch     7 | loss: 83.9893698CurrentTrain: epoch  4, batch     8 | loss: 125.2496158CurrentTrain: epoch  4, batch     9 | loss: 69.8417021CurrentTrain: epoch  4, batch    10 | loss: 171.1941238CurrentTrain: epoch  4, batch    11 | loss: 127.9524766CurrentTrain: epoch  4, batch    12 | loss: 99.6229357CurrentTrain: epoch  4, batch    13 | loss: 103.1433200CurrentTrain: epoch  4, batch    14 | loss: 83.8623628CurrentTrain: epoch  4, batch    15 | loss: 65.4876147CurrentTrain: epoch  4, batch    16 | loss: 100.4653519CurrentTrain: epoch  4, batch    17 | loss: 70.2724064CurrentTrain: epoch  4, batch    18 | loss: 84.8056870CurrentTrain: epoch  4, batch    19 | loss: 67.3377488CurrentTrain: epoch  4, batch    20 | loss: 84.6009858CurrentTrain: epoch  4, batch    21 | loss: 80.8096223CurrentTrain: epoch  4, batch    22 | loss: 70.7950514CurrentTrain: epoch  4, batch    23 | loss: 100.6629688CurrentTrain: epoch  4, batch    24 | loss: 82.2333522CurrentTrain: epoch  4, batch    25 | loss: 99.3635908CurrentTrain: epoch  4, batch    26 | loss: 103.8308693CurrentTrain: epoch  4, batch    27 | loss: 67.8705600CurrentTrain: epoch  4, batch    28 | loss: 79.9861390CurrentTrain: epoch  4, batch    29 | loss: 100.2729792CurrentTrain: epoch  4, batch    30 | loss: 84.2919358CurrentTrain: epoch  4, batch    31 | loss: 81.1193550CurrentTrain: epoch  4, batch    32 | loss: 82.2897808CurrentTrain: epoch  4, batch    33 | loss: 99.1928580CurrentTrain: epoch  4, batch    34 | loss: 69.2664259CurrentTrain: epoch  4, batch    35 | loss: 132.1669251CurrentTrain: epoch  4, batch    36 | loss: 125.0176146CurrentTrain: epoch  4, batch    37 | loss: 106.0443382CurrentTrain: epoch  4, batch    38 | loss: 84.0872652CurrentTrain: epoch  4, batch    39 | loss: 103.5964613CurrentTrain: epoch  4, batch    40 | loss: 71.8668172CurrentTrain: epoch  4, batch    41 | loss: 69.7674263CurrentTrain: epoch  4, batch    42 | loss: 71.1688989CurrentTrain: epoch  4, batch    43 | loss: 84.6504955CurrentTrain: epoch  4, batch    44 | loss: 85.8086407CurrentTrain: epoch  4, batch    45 | loss: 58.4872683CurrentTrain: epoch  4, batch    46 | loss: 126.6549068CurrentTrain: epoch  4, batch    47 | loss: 81.7546965CurrentTrain: epoch  4, batch    48 | loss: 99.1308522CurrentTrain: epoch  4, batch    49 | loss: 81.7120546CurrentTrain: epoch  4, batch    50 | loss: 84.7521349CurrentTrain: epoch  4, batch    51 | loss: 101.7523225CurrentTrain: epoch  4, batch    52 | loss: 68.6767995CurrentTrain: epoch  4, batch    53 | loss: 84.9492760CurrentTrain: epoch  4, batch    54 | loss: 57.4630926CurrentTrain: epoch  4, batch    55 | loss: 63.8238872CurrentTrain: epoch  4, batch    56 | loss: 128.7486476CurrentTrain: epoch  4, batch    57 | loss: 95.6779711CurrentTrain: epoch  4, batch    58 | loss: 57.2483595CurrentTrain: epoch  4, batch    59 | loss: 73.8719299CurrentTrain: epoch  4, batch    60 | loss: 102.3507163CurrentTrain: epoch  4, batch    61 | loss: 70.0710725CurrentTrain: epoch  4, batch    62 | loss: 84.7379758CurrentTrain: epoch  4, batch    63 | loss: 98.7070835CurrentTrain: epoch  4, batch    64 | loss: 102.3043790CurrentTrain: epoch  4, batch    65 | loss: 97.6762288CurrentTrain: epoch  4, batch    66 | loss: 82.0373893CurrentTrain: epoch  4, batch    67 | loss: 80.5313913CurrentTrain: epoch  4, batch    68 | loss: 85.7269810CurrentTrain: epoch  4, batch    69 | loss: 88.1114381CurrentTrain: epoch  4, batch    70 | loss: 81.0495559CurrentTrain: epoch  4, batch    71 | loss: 70.3524294CurrentTrain: epoch  4, batch    72 | loss: 84.2601605CurrentTrain: epoch  4, batch    73 | loss: 70.0038230CurrentTrain: epoch  4, batch    74 | loss: 83.6752042CurrentTrain: epoch  4, batch    75 | loss: 61.3571013CurrentTrain: epoch  4, batch    76 | loss: 81.7921259CurrentTrain: epoch  4, batch    77 | loss: 103.5003803CurrentTrain: epoch  4, batch    78 | loss: 69.1611520CurrentTrain: epoch  4, batch    79 | loss: 99.4163289CurrentTrain: epoch  4, batch    80 | loss: 83.7909951CurrentTrain: epoch  4, batch    81 | loss: 88.0145009CurrentTrain: epoch  4, batch    82 | loss: 102.1145784CurrentTrain: epoch  4, batch    83 | loss: 81.0153259CurrentTrain: epoch  4, batch    84 | loss: 80.5781338CurrentTrain: epoch  4, batch    85 | loss: 70.5195984CurrentTrain: epoch  4, batch    86 | loss: 167.0639227CurrentTrain: epoch  4, batch    87 | loss: 73.3824438CurrentTrain: epoch  4, batch    88 | loss: 130.8057591CurrentTrain: epoch  4, batch    89 | loss: 71.3334645CurrentTrain: epoch  4, batch    90 | loss: 78.3674316CurrentTrain: epoch  4, batch    91 | loss: 70.2408284CurrentTrain: epoch  4, batch    92 | loss: 79.5924214CurrentTrain: epoch  4, batch    93 | loss: 135.1077831CurrentTrain: epoch  4, batch    94 | loss: 68.7128507CurrentTrain: epoch  4, batch    95 | loss: 69.6391270CurrentTrain: epoch  5, batch     0 | loss: 101.6466985CurrentTrain: epoch  5, batch     1 | loss: 60.6399158CurrentTrain: epoch  5, batch     2 | loss: 67.5808898CurrentTrain: epoch  5, batch     3 | loss: 83.1612345CurrentTrain: epoch  5, batch     4 | loss: 69.3709937CurrentTrain: epoch  5, batch     5 | loss: 103.2590419CurrentTrain: epoch  5, batch     6 | loss: 82.3177322CurrentTrain: epoch  5, batch     7 | loss: 79.1859064CurrentTrain: epoch  5, batch     8 | loss: 58.9940413CurrentTrain: epoch  5, batch     9 | loss: 96.7926876CurrentTrain: epoch  5, batch    10 | loss: 82.8213698CurrentTrain: epoch  5, batch    11 | loss: 101.9637613CurrentTrain: epoch  5, batch    12 | loss: 97.8918273CurrentTrain: epoch  5, batch    13 | loss: 83.2630256CurrentTrain: epoch  5, batch    14 | loss: 68.6134426CurrentTrain: epoch  5, batch    15 | loss: 104.2157812CurrentTrain: epoch  5, batch    16 | loss: 81.8653127CurrentTrain: epoch  5, batch    17 | loss: 80.1266106CurrentTrain: epoch  5, batch    18 | loss: 165.1528780CurrentTrain: epoch  5, batch    19 | loss: 79.5007696CurrentTrain: epoch  5, batch    20 | loss: 83.5931003CurrentTrain: epoch  5, batch    21 | loss: 97.3098215CurrentTrain: epoch  5, batch    22 | loss: 82.5217239CurrentTrain: epoch  5, batch    23 | loss: 78.1342332CurrentTrain: epoch  5, batch    24 | loss: 59.0036321CurrentTrain: epoch  5, batch    25 | loss: 100.2153601CurrentTrain: epoch  5, batch    26 | loss: 86.2592008CurrentTrain: epoch  5, batch    27 | loss: 60.3624477CurrentTrain: epoch  5, batch    28 | loss: 65.3832372CurrentTrain: epoch  5, batch    29 | loss: 99.6074831CurrentTrain: epoch  5, batch    30 | loss: 79.0072712CurrentTrain: epoch  5, batch    31 | loss: 66.4259724CurrentTrain: epoch  5, batch    32 | loss: 96.2272952CurrentTrain: epoch  5, batch    33 | loss: 85.0454619CurrentTrain: epoch  5, batch    34 | loss: 69.9359103CurrentTrain: epoch  5, batch    35 | loss: 63.2821400CurrentTrain: epoch  5, batch    36 | loss: 67.6904663CurrentTrain: epoch  5, batch    37 | loss: 83.6664504CurrentTrain: epoch  5, batch    38 | loss: 62.7793914CurrentTrain: epoch  5, batch    39 | loss: 66.9497675CurrentTrain: epoch  5, batch    40 | loss: 68.2794238CurrentTrain: epoch  5, batch    41 | loss: 80.4503309CurrentTrain: epoch  5, batch    42 | loss: 102.5989489CurrentTrain: epoch  5, batch    43 | loss: 102.7165476CurrentTrain: epoch  5, batch    44 | loss: 122.6230499CurrentTrain: epoch  5, batch    45 | loss: 71.2343484CurrentTrain: epoch  5, batch    46 | loss: 97.5812363CurrentTrain: epoch  5, batch    47 | loss: 59.5374975CurrentTrain: epoch  5, batch    48 | loss: 85.4208150CurrentTrain: epoch  5, batch    49 | loss: 100.7209664CurrentTrain: epoch  5, batch    50 | loss: 81.2686871CurrentTrain: epoch  5, batch    51 | loss: 68.7634983CurrentTrain: epoch  5, batch    52 | loss: 99.8116799CurrentTrain: epoch  5, batch    53 | loss: 63.7767996CurrentTrain: epoch  5, batch    54 | loss: 128.3502748CurrentTrain: epoch  5, batch    55 | loss: 97.4816001CurrentTrain: epoch  5, batch    56 | loss: 71.1170603CurrentTrain: epoch  5, batch    57 | loss: 84.2507763CurrentTrain: epoch  5, batch    58 | loss: 98.2281052CurrentTrain: epoch  5, batch    59 | loss: 71.7155328CurrentTrain: epoch  5, batch    60 | loss: 84.3316238CurrentTrain: epoch  5, batch    61 | loss: 80.5114484CurrentTrain: epoch  5, batch    62 | loss: 69.5818623CurrentTrain: epoch  5, batch    63 | loss: 98.6656447CurrentTrain: epoch  5, batch    64 | loss: 80.3989433CurrentTrain: epoch  5, batch    65 | loss: 81.9968201CurrentTrain: epoch  5, batch    66 | loss: 65.0768840CurrentTrain: epoch  5, batch    67 | loss: 93.9146896CurrentTrain: epoch  5, batch    68 | loss: 99.0884138CurrentTrain: epoch  5, batch    69 | loss: 62.2374931CurrentTrain: epoch  5, batch    70 | loss: 100.7451638CurrentTrain: epoch  5, batch    71 | loss: 58.4929980CurrentTrain: epoch  5, batch    72 | loss: 84.6055237CurrentTrain: epoch  5, batch    73 | loss: 56.1250710CurrentTrain: epoch  5, batch    74 | loss: 82.0759937CurrentTrain: epoch  5, batch    75 | loss: 65.1451007CurrentTrain: epoch  5, batch    76 | loss: 125.6654986CurrentTrain: epoch  5, batch    77 | loss: 82.5018276CurrentTrain: epoch  5, batch    78 | loss: 104.2282618CurrentTrain: epoch  5, batch    79 | loss: 81.4759372CurrentTrain: epoch  5, batch    80 | loss: 100.4474337CurrentTrain: epoch  5, batch    81 | loss: 101.0247829CurrentTrain: epoch  5, batch    82 | loss: 86.2706828CurrentTrain: epoch  5, batch    83 | loss: 171.6929446CurrentTrain: epoch  5, batch    84 | loss: 59.9020734CurrentTrain: epoch  5, batch    85 | loss: 66.5232104CurrentTrain: epoch  5, batch    86 | loss: 178.1804920CurrentTrain: epoch  5, batch    87 | loss: 86.1143525CurrentTrain: epoch  5, batch    88 | loss: 121.8935724CurrentTrain: epoch  5, batch    89 | loss: 66.5571052CurrentTrain: epoch  5, batch    90 | loss: 72.8247356CurrentTrain: epoch  5, batch    91 | loss: 128.6128918CurrentTrain: epoch  5, batch    92 | loss: 67.1212819CurrentTrain: epoch  5, batch    93 | loss: 100.7404510CurrentTrain: epoch  5, batch    94 | loss: 95.8062060CurrentTrain: epoch  5, batch    95 | loss: 109.9271347CurrentTrain: epoch  6, batch     0 | loss: 70.0633781CurrentTrain: epoch  6, batch     1 | loss: 99.3071098CurrentTrain: epoch  6, batch     2 | loss: 77.9916599CurrentTrain: epoch  6, batch     3 | loss: 69.8726784CurrentTrain: epoch  6, batch     4 | loss: 80.7082211CurrentTrain: epoch  6, batch     5 | loss: 96.3048819CurrentTrain: epoch  6, batch     6 | loss: 99.5768839CurrentTrain: epoch  6, batch     7 | loss: 122.6671431CurrentTrain: epoch  6, batch     8 | loss: 65.2738069CurrentTrain: epoch  6, batch     9 | loss: 53.0357354CurrentTrain: epoch  6, batch    10 | loss: 93.8561897CurrentTrain: epoch  6, batch    11 | loss: 80.3558897CurrentTrain: epoch  6, batch    12 | loss: 95.7963381CurrentTrain: epoch  6, batch    13 | loss: 96.2228428CurrentTrain: epoch  6, batch    14 | loss: 57.4529611CurrentTrain: epoch  6, batch    15 | loss: 80.2228679CurrentTrain: epoch  6, batch    16 | loss: 56.5675193CurrentTrain: epoch  6, batch    17 | loss: 68.4903185CurrentTrain: epoch  6, batch    18 | loss: 95.7653237CurrentTrain: epoch  6, batch    19 | loss: 78.5094837CurrentTrain: epoch  6, batch    20 | loss: 57.3317673CurrentTrain: epoch  6, batch    21 | loss: 75.3501699CurrentTrain: epoch  6, batch    22 | loss: 80.6102936CurrentTrain: epoch  6, batch    23 | loss: 98.2693921CurrentTrain: epoch  6, batch    24 | loss: 97.8257673CurrentTrain: epoch  6, batch    25 | loss: 95.5884284CurrentTrain: epoch  6, batch    26 | loss: 77.3982812CurrentTrain: epoch  6, batch    27 | loss: 95.7009154CurrentTrain: epoch  6, batch    28 | loss: 80.9059950CurrentTrain: epoch  6, batch    29 | loss: 68.6134367CurrentTrain: epoch  6, batch    30 | loss: 99.5925908CurrentTrain: epoch  6, batch    31 | loss: 71.1979501CurrentTrain: epoch  6, batch    32 | loss: 58.2980598CurrentTrain: epoch  6, batch    33 | loss: 64.0995508CurrentTrain: epoch  6, batch    34 | loss: 96.9053695CurrentTrain: epoch  6, batch    35 | loss: 65.3014905CurrentTrain: epoch  6, batch    36 | loss: 85.2138917CurrentTrain: epoch  6, batch    37 | loss: 59.5189842CurrentTrain: epoch  6, batch    38 | loss: 98.1024102CurrentTrain: epoch  6, batch    39 | loss: 81.8597278CurrentTrain: epoch  6, batch    40 | loss: 81.3721079CurrentTrain: epoch  6, batch    41 | loss: 130.4864596CurrentTrain: epoch  6, batch    42 | loss: 122.6286934CurrentTrain: epoch  6, batch    43 | loss: 61.1917518CurrentTrain: epoch  6, batch    44 | loss: 84.5790129CurrentTrain: epoch  6, batch    45 | loss: 98.6046187CurrentTrain: epoch  6, batch    46 | loss: 78.5623943CurrentTrain: epoch  6, batch    47 | loss: 100.8777373CurrentTrain: epoch  6, batch    48 | loss: 83.7283719CurrentTrain: epoch  6, batch    49 | loss: 95.9665588CurrentTrain: epoch  6, batch    50 | loss: 125.0871062CurrentTrain: epoch  6, batch    51 | loss: 78.7440285CurrentTrain: epoch  6, batch    52 | loss: 104.5531756CurrentTrain: epoch  6, batch    53 | loss: 98.0397481CurrentTrain: epoch  6, batch    54 | loss: 99.9118507CurrentTrain: epoch  6, batch    55 | loss: 97.4073287CurrentTrain: epoch  6, batch    56 | loss: 100.9486153CurrentTrain: epoch  6, batch    57 | loss: 166.8416816CurrentTrain: epoch  6, batch    58 | loss: 79.8433356CurrentTrain: epoch  6, batch    59 | loss: 71.6783165CurrentTrain: epoch  6, batch    60 | loss: 122.3333931CurrentTrain: epoch  6, batch    61 | loss: 80.1500621CurrentTrain: epoch  6, batch    62 | loss: 98.2288283CurrentTrain: epoch  6, batch    63 | loss: 69.1169162CurrentTrain: epoch  6, batch    64 | loss: 78.0135101CurrentTrain: epoch  6, batch    65 | loss: 70.2347552CurrentTrain: epoch  6, batch    66 | loss: 67.6025270CurrentTrain: epoch  6, batch    67 | loss: 69.7049565CurrentTrain: epoch  6, batch    68 | loss: 82.1703251CurrentTrain: epoch  6, batch    69 | loss: 76.0411514CurrentTrain: epoch  6, batch    70 | loss: 67.4521239CurrentTrain: epoch  6, batch    71 | loss: 63.1807053CurrentTrain: epoch  6, batch    72 | loss: 107.0595451CurrentTrain: epoch  6, batch    73 | loss: 101.2519906CurrentTrain: epoch  6, batch    74 | loss: 58.8968265CurrentTrain: epoch  6, batch    75 | loss: 97.1301496CurrentTrain: epoch  6, batch    76 | loss: 79.6351808CurrentTrain: epoch  6, batch    77 | loss: 76.4010480CurrentTrain: epoch  6, batch    78 | loss: 77.0172851CurrentTrain: epoch  6, batch    79 | loss: 70.0407535CurrentTrain: epoch  6, batch    80 | loss: 80.4500112CurrentTrain: epoch  6, batch    81 | loss: 97.8130178CurrentTrain: epoch  6, batch    82 | loss: 98.8391098CurrentTrain: epoch  6, batch    83 | loss: 54.2538951CurrentTrain: epoch  6, batch    84 | loss: 69.0252150CurrentTrain: epoch  6, batch    85 | loss: 96.6909266CurrentTrain: epoch  6, batch    86 | loss: 64.9596825CurrentTrain: epoch  6, batch    87 | loss: 66.7836422CurrentTrain: epoch  6, batch    88 | loss: 81.5823650CurrentTrain: epoch  6, batch    89 | loss: 78.0245435CurrentTrain: epoch  6, batch    90 | loss: 96.7706316CurrentTrain: epoch  6, batch    91 | loss: 80.2894693CurrentTrain: epoch  6, batch    92 | loss: 67.1152496CurrentTrain: epoch  6, batch    93 | loss: 100.0680933CurrentTrain: epoch  6, batch    94 | loss: 97.7541933CurrentTrain: epoch  6, batch    95 | loss: 81.6929982CurrentTrain: epoch  7, batch     0 | loss: 78.2848642CurrentTrain: epoch  7, batch     1 | loss: 67.0160345CurrentTrain: epoch  7, batch     2 | loss: 123.9648482CurrentTrain: epoch  7, batch     3 | loss: 82.0219747CurrentTrain: epoch  7, batch     4 | loss: 81.6999325CurrentTrain: epoch  7, batch     5 | loss: 76.4446709CurrentTrain: epoch  7, batch     6 | loss: 75.5867572CurrentTrain: epoch  7, batch     7 | loss: 65.3878480CurrentTrain: epoch  7, batch     8 | loss: 68.2092746CurrentTrain: epoch  7, batch     9 | loss: 77.8094212CurrentTrain: epoch  7, batch    10 | loss: 123.4429711CurrentTrain: epoch  7, batch    11 | loss: 83.7317436CurrentTrain: epoch  7, batch    12 | loss: 96.6905065CurrentTrain: epoch  7, batch    13 | loss: 96.7073300CurrentTrain: epoch  7, batch    14 | loss: 56.7044948CurrentTrain: epoch  7, batch    15 | loss: 68.2382985CurrentTrain: epoch  7, batch    16 | loss: 123.6548691CurrentTrain: epoch  7, batch    17 | loss: 82.1940944CurrentTrain: epoch  7, batch    18 | loss: 95.4669556CurrentTrain: epoch  7, batch    19 | loss: 76.3023107CurrentTrain: epoch  7, batch    20 | loss: 96.7590957CurrentTrain: epoch  7, batch    21 | loss: 75.8783577CurrentTrain: epoch  7, batch    22 | loss: 79.4034830CurrentTrain: epoch  7, batch    23 | loss: 81.0677304CurrentTrain: epoch  7, batch    24 | loss: 80.2292999CurrentTrain: epoch  7, batch    25 | loss: 65.3218869CurrentTrain: epoch  7, batch    26 | loss: 76.5404669CurrentTrain: epoch  7, batch    27 | loss: 79.6750090CurrentTrain: epoch  7, batch    28 | loss: 77.4539665CurrentTrain: epoch  7, batch    29 | loss: 58.4349991CurrentTrain: epoch  7, batch    30 | loss: 79.4188945CurrentTrain: epoch  7, batch    31 | loss: 123.8227103CurrentTrain: epoch  7, batch    32 | loss: 80.2426223CurrentTrain: epoch  7, batch    33 | loss: 101.5237795CurrentTrain: epoch  7, batch    34 | loss: 91.1895319CurrentTrain: epoch  7, batch    35 | loss: 95.9374602CurrentTrain: epoch  7, batch    36 | loss: 64.8070103CurrentTrain: epoch  7, batch    37 | loss: 78.7279119CurrentTrain: epoch  7, batch    38 | loss: 92.8549416CurrentTrain: epoch  7, batch    39 | loss: 81.5734941CurrentTrain: epoch  7, batch    40 | loss: 120.2008802CurrentTrain: epoch  7, batch    41 | loss: 100.6759503CurrentTrain: epoch  7, batch    42 | loss: 101.1887078CurrentTrain: epoch  7, batch    43 | loss: 81.6454360CurrentTrain: epoch  7, batch    44 | loss: 69.8659207CurrentTrain: epoch  7, batch    45 | loss: 75.5873696CurrentTrain: epoch  7, batch    46 | loss: 56.6803803CurrentTrain: epoch  7, batch    47 | loss: 69.7592692CurrentTrain: epoch  7, batch    48 | loss: 67.0059355CurrentTrain: epoch  7, batch    49 | loss: 68.1972260CurrentTrain: epoch  7, batch    50 | loss: 77.9101469CurrentTrain: epoch  7, batch    51 | loss: 96.4999411CurrentTrain: epoch  7, batch    52 | loss: 66.9148047CurrentTrain: epoch  7, batch    53 | loss: 76.4499373CurrentTrain: epoch  7, batch    54 | loss: 99.4175295CurrentTrain: epoch  7, batch    55 | loss: 66.2840589CurrentTrain: epoch  7, batch    56 | loss: 67.2423417CurrentTrain: epoch  7, batch    57 | loss: 64.5393868CurrentTrain: epoch  7, batch    58 | loss: 54.8138453CurrentTrain: epoch  7, batch    59 | loss: 127.4770714CurrentTrain: epoch  7, batch    60 | loss: 62.7917015CurrentTrain: epoch  7, batch    61 | loss: 68.6992532CurrentTrain: epoch  7, batch    62 | loss: 78.5676053CurrentTrain: epoch  7, batch    63 | loss: 121.0610629CurrentTrain: epoch  7, batch    64 | loss: 123.4691401CurrentTrain: epoch  7, batch    65 | loss: 99.9153246CurrentTrain: epoch  7, batch    66 | loss: 100.0676078CurrentTrain: epoch  7, batch    67 | loss: 64.6148652CurrentTrain: epoch  7, batch    68 | loss: 66.1866317CurrentTrain: epoch  7, batch    69 | loss: 97.1699493CurrentTrain: epoch  7, batch    70 | loss: 100.7811589CurrentTrain: epoch  7, batch    71 | loss: 78.6722730CurrentTrain: epoch  7, batch    72 | loss: 58.5379306CurrentTrain: epoch  7, batch    73 | loss: 79.7915748CurrentTrain: epoch  7, batch    74 | loss: 127.5332134CurrentTrain: epoch  7, batch    75 | loss: 94.5166905CurrentTrain: epoch  7, batch    76 | loss: 95.4227296CurrentTrain: epoch  7, batch    77 | loss: 129.1488901CurrentTrain: epoch  7, batch    78 | loss: 66.2631373CurrentTrain: epoch  7, batch    79 | loss: 123.4132636CurrentTrain: epoch  7, batch    80 | loss: 80.7829222CurrentTrain: epoch  7, batch    81 | loss: 65.9220309CurrentTrain: epoch  7, batch    82 | loss: 93.6388921CurrentTrain: epoch  7, batch    83 | loss: 67.3418800CurrentTrain: epoch  7, batch    84 | loss: 80.0997836CurrentTrain: epoch  7, batch    85 | loss: 67.5585487CurrentTrain: epoch  7, batch    86 | loss: 70.1121317CurrentTrain: epoch  7, batch    87 | loss: 99.8232513CurrentTrain: epoch  7, batch    88 | loss: 99.8824137CurrentTrain: epoch  7, batch    89 | loss: 75.4573330CurrentTrain: epoch  7, batch    90 | loss: 93.6674796CurrentTrain: epoch  7, batch    91 | loss: 75.8149087CurrentTrain: epoch  7, batch    92 | loss: 63.2236535CurrentTrain: epoch  7, batch    93 | loss: 127.9001018CurrentTrain: epoch  7, batch    94 | loss: 66.9759777CurrentTrain: epoch  7, batch    95 | loss: 79.8303501CurrentTrain: epoch  8, batch     0 | loss: 52.3223581CurrentTrain: epoch  8, batch     1 | loss: 125.6876183CurrentTrain: epoch  8, batch     2 | loss: 79.6562996CurrentTrain: epoch  8, batch     3 | loss: 90.6448001CurrentTrain: epoch  8, batch     4 | loss: 77.6139446CurrentTrain: epoch  8, batch     5 | loss: 65.2667675CurrentTrain: epoch  8, batch     6 | loss: 98.6898205CurrentTrain: epoch  8, batch     7 | loss: 78.4282672CurrentTrain: epoch  8, batch     8 | loss: 77.1324844CurrentTrain: epoch  8, batch     9 | loss: 118.6118879CurrentTrain: epoch  8, batch    10 | loss: 94.6387860CurrentTrain: epoch  8, batch    11 | loss: 97.7969811CurrentTrain: epoch  8, batch    12 | loss: 52.0525462CurrentTrain: epoch  8, batch    13 | loss: 57.1222694CurrentTrain: epoch  8, batch    14 | loss: 57.6821472CurrentTrain: epoch  8, batch    15 | loss: 79.0136007CurrentTrain: epoch  8, batch    16 | loss: 77.9631087CurrentTrain: epoch  8, batch    17 | loss: 62.0515565CurrentTrain: epoch  8, batch    18 | loss: 57.7131877CurrentTrain: epoch  8, batch    19 | loss: 68.0147184CurrentTrain: epoch  8, batch    20 | loss: 64.0027755CurrentTrain: epoch  8, batch    21 | loss: 79.8725172CurrentTrain: epoch  8, batch    22 | loss: 76.3958083CurrentTrain: epoch  8, batch    23 | loss: 55.3309417CurrentTrain: epoch  8, batch    24 | loss: 94.0039171CurrentTrain: epoch  8, batch    25 | loss: 100.8792324CurrentTrain: epoch  8, batch    26 | loss: 80.3453245CurrentTrain: epoch  8, batch    27 | loss: 92.3550436CurrentTrain: epoch  8, batch    28 | loss: 97.1343220CurrentTrain: epoch  8, batch    29 | loss: 94.9332002CurrentTrain: epoch  8, batch    30 | loss: 56.8910899CurrentTrain: epoch  8, batch    31 | loss: 67.9420463CurrentTrain: epoch  8, batch    32 | loss: 61.5106527CurrentTrain: epoch  8, batch    33 | loss: 67.6433633CurrentTrain: epoch  8, batch    34 | loss: 67.0233327CurrentTrain: epoch  8, batch    35 | loss: 68.2157819CurrentTrain: epoch  8, batch    36 | loss: 65.8117672CurrentTrain: epoch  8, batch    37 | loss: 56.8922305CurrentTrain: epoch  8, batch    38 | loss: 65.4607534CurrentTrain: epoch  8, batch    39 | loss: 94.8505740CurrentTrain: epoch  8, batch    40 | loss: 82.1930332CurrentTrain: epoch  8, batch    41 | loss: 79.1525901CurrentTrain: epoch  8, batch    42 | loss: 59.1244787CurrentTrain: epoch  8, batch    43 | loss: 67.6229694CurrentTrain: epoch  8, batch    44 | loss: 77.0256132CurrentTrain: epoch  8, batch    45 | loss: 67.8838951CurrentTrain: epoch  8, batch    46 | loss: 62.5105309CurrentTrain: epoch  8, batch    47 | loss: 90.6631757CurrentTrain: epoch  8, batch    48 | loss: 64.9041583CurrentTrain: epoch  8, batch    49 | loss: 96.4232525CurrentTrain: epoch  8, batch    50 | loss: 77.7439493CurrentTrain: epoch  8, batch    51 | loss: 68.6929967CurrentTrain: epoch  8, batch    52 | loss: 67.4774525CurrentTrain: epoch  8, batch    53 | loss: 72.7563344CurrentTrain: epoch  8, batch    54 | loss: 94.9693726CurrentTrain: epoch  8, batch    55 | loss: 78.8130091CurrentTrain: epoch  8, batch    56 | loss: 120.2364568CurrentTrain: epoch  8, batch    57 | loss: 125.5094106CurrentTrain: epoch  8, batch    58 | loss: 75.7694060CurrentTrain: epoch  8, batch    59 | loss: 64.9902204CurrentTrain: epoch  8, batch    60 | loss: 101.3449083CurrentTrain: epoch  8, batch    61 | loss: 98.7217521CurrentTrain: epoch  8, batch    62 | loss: 79.6437791CurrentTrain: epoch  8, batch    63 | loss: 95.3034525CurrentTrain: epoch  8, batch    64 | loss: 95.7948677CurrentTrain: epoch  8, batch    65 | loss: 75.7711285CurrentTrain: epoch  8, batch    66 | loss: 66.7166294CurrentTrain: epoch  8, batch    67 | loss: 79.6537768CurrentTrain: epoch  8, batch    68 | loss: 68.2075993CurrentTrain: epoch  8, batch    69 | loss: 78.1119582CurrentTrain: epoch  8, batch    70 | loss: 95.1943979CurrentTrain: epoch  8, batch    71 | loss: 69.0947626CurrentTrain: epoch  8, batch    72 | loss: 66.1535588CurrentTrain: epoch  8, batch    73 | loss: 127.0141359CurrentTrain: epoch  8, batch    74 | loss: 122.9369567CurrentTrain: epoch  8, batch    75 | loss: 95.3061808CurrentTrain: epoch  8, batch    76 | loss: 96.2672249CurrentTrain: epoch  8, batch    77 | loss: 119.8296666CurrentTrain: epoch  8, batch    78 | loss: 92.7631486CurrentTrain: epoch  8, batch    79 | loss: 72.2465826CurrentTrain: epoch  8, batch    80 | loss: 62.4109117CurrentTrain: epoch  8, batch    81 | loss: 99.6769085CurrentTrain: epoch  8, batch    82 | loss: 122.5093888CurrentTrain: epoch  8, batch    83 | loss: 95.4778766CurrentTrain: epoch  8, batch    84 | loss: 80.5529701CurrentTrain: epoch  8, batch    85 | loss: 125.8181114CurrentTrain: epoch  8, batch    86 | loss: 79.3751336CurrentTrain: epoch  8, batch    87 | loss: 66.2189803CurrentTrain: epoch  8, batch    88 | loss: 123.3476951CurrentTrain: epoch  8, batch    89 | loss: 69.9548497CurrentTrain: epoch  8, batch    90 | loss: 78.5381353CurrentTrain: epoch  8, batch    91 | loss: 65.9870058CurrentTrain: epoch  8, batch    92 | loss: 77.0238528CurrentTrain: epoch  8, batch    93 | loss: 63.0866211CurrentTrain: epoch  8, batch    94 | loss: 77.9249468CurrentTrain: epoch  8, batch    95 | loss: 82.0561085CurrentTrain: epoch  9, batch     0 | loss: 79.1955352CurrentTrain: epoch  9, batch     1 | loss: 67.7559669CurrentTrain: epoch  9, batch     2 | loss: 64.0907812CurrentTrain: epoch  9, batch     3 | loss: 80.7198464CurrentTrain: epoch  9, batch     4 | loss: 80.3067779CurrentTrain: epoch  9, batch     5 | loss: 94.3857196CurrentTrain: epoch  9, batch     6 | loss: 75.8551021CurrentTrain: epoch  9, batch     7 | loss: 55.7566435CurrentTrain: epoch  9, batch     8 | loss: 74.9361966CurrentTrain: epoch  9, batch     9 | loss: 96.4626662CurrentTrain: epoch  9, batch    10 | loss: 66.6818720CurrentTrain: epoch  9, batch    11 | loss: 54.8493113CurrentTrain: epoch  9, batch    12 | loss: 78.5753332CurrentTrain: epoch  9, batch    13 | loss: 92.4469233CurrentTrain: epoch  9, batch    14 | loss: 63.0104397CurrentTrain: epoch  9, batch    15 | loss: 93.4896257CurrentTrain: epoch  9, batch    16 | loss: 79.4947182CurrentTrain: epoch  9, batch    17 | loss: 73.6278357CurrentTrain: epoch  9, batch    18 | loss: 80.1731692CurrentTrain: epoch  9, batch    19 | loss: 76.6404649CurrentTrain: epoch  9, batch    20 | loss: 91.3966337CurrentTrain: epoch  9, batch    21 | loss: 65.2406130CurrentTrain: epoch  9, batch    22 | loss: 71.7368140CurrentTrain: epoch  9, batch    23 | loss: 79.9688969CurrentTrain: epoch  9, batch    24 | loss: 64.8401155CurrentTrain: epoch  9, batch    25 | loss: 99.2785040CurrentTrain: epoch  9, batch    26 | loss: 64.9725758CurrentTrain: epoch  9, batch    27 | loss: 76.0415299CurrentTrain: epoch  9, batch    28 | loss: 75.6928883CurrentTrain: epoch  9, batch    29 | loss: 73.3061167CurrentTrain: epoch  9, batch    30 | loss: 76.1447435CurrentTrain: epoch  9, batch    31 | loss: 72.0474676CurrentTrain: epoch  9, batch    32 | loss: 67.6610352CurrentTrain: epoch  9, batch    33 | loss: 76.8835093CurrentTrain: epoch  9, batch    34 | loss: 76.6210081CurrentTrain: epoch  9, batch    35 | loss: 77.4620994CurrentTrain: epoch  9, batch    36 | loss: 97.3105184CurrentTrain: epoch  9, batch    37 | loss: 170.4352508CurrentTrain: epoch  9, batch    38 | loss: 93.8627790CurrentTrain: epoch  9, batch    39 | loss: 78.4298421CurrentTrain: epoch  9, batch    40 | loss: 63.7533658CurrentTrain: epoch  9, batch    41 | loss: 79.9702175CurrentTrain: epoch  9, batch    42 | loss: 66.0076777CurrentTrain: epoch  9, batch    43 | loss: 78.9507756CurrentTrain: epoch  9, batch    44 | loss: 63.2450049CurrentTrain: epoch  9, batch    45 | loss: 94.6768424CurrentTrain: epoch  9, batch    46 | loss: 78.2006650CurrentTrain: epoch  9, batch    47 | loss: 64.1279566CurrentTrain: epoch  9, batch    48 | loss: 78.2455330CurrentTrain: epoch  9, batch    49 | loss: 69.1902548CurrentTrain: epoch  9, batch    50 | loss: 63.7860040CurrentTrain: epoch  9, batch    51 | loss: 77.8611215CurrentTrain: epoch  9, batch    52 | loss: 66.5117093CurrentTrain: epoch  9, batch    53 | loss: 126.9273684CurrentTrain: epoch  9, batch    54 | loss: 64.5873237CurrentTrain: epoch  9, batch    55 | loss: 121.2114525CurrentTrain: epoch  9, batch    56 | loss: 95.6119043CurrentTrain: epoch  9, batch    57 | loss: 77.0636055CurrentTrain: epoch  9, batch    58 | loss: 94.8815969CurrentTrain: epoch  9, batch    59 | loss: 90.9149813CurrentTrain: epoch  9, batch    60 | loss: 78.7266360CurrentTrain: epoch  9, batch    61 | loss: 85.1022347CurrentTrain: epoch  9, batch    62 | loss: 64.6014593CurrentTrain: epoch  9, batch    63 | loss: 74.5978070CurrentTrain: epoch  9, batch    64 | loss: 126.3222442CurrentTrain: epoch  9, batch    65 | loss: 95.2724629CurrentTrain: epoch  9, batch    66 | loss: 80.6103877CurrentTrain: epoch  9, batch    67 | loss: 93.7443014CurrentTrain: epoch  9, batch    68 | loss: 124.9811464CurrentTrain: epoch  9, batch    69 | loss: 95.0641461CurrentTrain: epoch  9, batch    70 | loss: 75.1669083CurrentTrain: epoch  9, batch    71 | loss: 69.4608113CurrentTrain: epoch  9, batch    72 | loss: 53.5594524CurrentTrain: epoch  9, batch    73 | loss: 66.6171568CurrentTrain: epoch  9, batch    74 | loss: 73.9460413CurrentTrain: epoch  9, batch    75 | loss: 81.0029227CurrentTrain: epoch  9, batch    76 | loss: 65.1609335CurrentTrain: epoch  9, batch    77 | loss: 121.5611929CurrentTrain: epoch  9, batch    78 | loss: 91.6752637CurrentTrain: epoch  9, batch    79 | loss: 53.1342903CurrentTrain: epoch  9, batch    80 | loss: 56.8626741CurrentTrain: epoch  9, batch    81 | loss: 58.3528226CurrentTrain: epoch  9, batch    82 | loss: 65.9192647CurrentTrain: epoch  9, batch    83 | loss: 64.3807276CurrentTrain: epoch  9, batch    84 | loss: 83.6169742CurrentTrain: epoch  9, batch    85 | loss: 70.4219731CurrentTrain: epoch  9, batch    86 | loss: 55.5246378CurrentTrain: epoch  9, batch    87 | loss: 77.0412740CurrentTrain: epoch  9, batch    88 | loss: 92.0695707CurrentTrain: epoch  9, batch    89 | loss: 65.3087433CurrentTrain: epoch  9, batch    90 | loss: 75.8517267CurrentTrain: epoch  9, batch    91 | loss: 66.8315674CurrentTrain: epoch  9, batch    92 | loss: 126.1920141CurrentTrain: epoch  9, batch    93 | loss: 78.7966763CurrentTrain: epoch  9, batch    94 | loss: 75.0252076CurrentTrain: epoch  9, batch    95 | loss: 102.2272532

F1 score per class: {32: np.float64(0.6082474226804123), 6: np.float64(0.7959183673469388), 19: np.float64(0.35294117647058826), 24: np.float64(0.73224043715847), 26: np.float64(0.9052631578947369), 29: np.float64(0.8585858585858586)}
Micro-average F1 score: 0.7658291457286432
Weighted-average F1 score: 0.7665021686727207
F1 score per class: {32: np.float64(0.6548672566371682), 6: np.float64(0.7924528301886793), 19: np.float64(0.25), 24: np.float64(0.7243243243243244), 26: np.float64(0.9292929292929293), 29: np.float64(0.84)}
Micro-average F1 score: 0.7614593077642656
Weighted-average F1 score: 0.7539133683406352
F1 score per class: {32: np.float64(0.6636771300448431), 6: np.float64(0.8118811881188119), 19: np.float64(0.3), 24: np.float64(0.7243243243243244), 26: np.float64(0.934010152284264), 29: np.float64(0.845771144278607)}
Micro-average F1 score: 0.7748091603053435
Weighted-average F1 score: 0.7710068039526699

F1 score per class: {32: np.float64(0.6082474226804123), 6: np.float64(0.7959183673469388), 19: np.float64(0.35294117647058826), 24: np.float64(0.73224043715847), 26: np.float64(0.9052631578947369), 29: np.float64(0.8585858585858586)}
Micro-average F1 score: 0.7658291457286432
Weighted-average F1 score: 0.7665021686727207
F1 score per class: {32: np.float64(0.6548672566371682), 6: np.float64(0.7924528301886793), 19: np.float64(0.25), 24: np.float64(0.7243243243243244), 26: np.float64(0.9292929292929293), 29: np.float64(0.84)}
Micro-average F1 score: 0.7614593077642656
Weighted-average F1 score: 0.7539133683406352
F1 score per class: {32: np.float64(0.6636771300448431), 6: np.float64(0.8118811881188119), 19: np.float64(0.3), 24: np.float64(0.7243243243243244), 26: np.float64(0.934010152284264), 29: np.float64(0.845771144278607)}
Micro-average F1 score: 0.7748091603053435
Weighted-average F1 score: 0.7710068039526699

F1 score per class: {32: np.float64(0.44696969696969696), 6: np.float64(0.7572815533980582), 19: np.float64(0.23529411764705882), 24: np.float64(0.6802030456852792), 26: np.float64(0.8269230769230769), 29: np.float64(0.6882591093117408)}
Micro-average F1 score: 0.649616368286445
Weighted-average F1 score: 0.6378642101581186
F1 score per class: {32: np.float64(0.4484848484848485), 6: np.float64(0.7466666666666667), 19: np.float64(0.1518987341772152), 24: np.float64(0.6600985221674877), 26: np.float64(0.8440366972477065), 29: np.float64(0.6774193548387096)}
Micro-average F1 score: 0.624712202609363
Weighted-average F1 score: 0.603306004897157
F1 score per class: {32: np.float64(0.4582043343653251), 6: np.float64(0.7663551401869159), 19: np.float64(0.1791044776119403), 24: np.float64(0.6600985221674877), 26: np.float64(0.8558139534883721), 29: np.float64(0.6827309236947792)}
Micro-average F1 score: 0.6388670338316287
Weighted-average F1 score: 0.6194632563249629

F1 score per class: {32: np.float64(0.44696969696969696), 6: np.float64(0.7572815533980582), 19: np.float64(0.23529411764705882), 24: np.float64(0.6802030456852792), 26: np.float64(0.8269230769230769), 29: np.float64(0.6882591093117408)}
Micro-average F1 score: 0.649616368286445
Weighted-average F1 score: 0.6378642101581186
F1 score per class: {32: np.float64(0.4484848484848485), 6: np.float64(0.7466666666666667), 19: np.float64(0.1518987341772152), 24: np.float64(0.6600985221674877), 26: np.float64(0.8440366972477065), 29: np.float64(0.6774193548387096)}
Micro-average F1 score: 0.624712202609363
Weighted-average F1 score: 0.603306004897157
F1 score per class: {32: np.float64(0.4582043343653251), 6: np.float64(0.7663551401869159), 19: np.float64(0.1791044776119403), 24: np.float64(0.6600985221674877), 26: np.float64(0.8558139534883721), 29: np.float64(0.6827309236947792)}
Micro-average F1 score: 0.6388670338316287
Weighted-average F1 score: 0.6194632563249629
cur_acc_wo_na:  ['0.7658']
his_acc_wo_na:  ['0.7658']
cur_acc des_wo_na:  ['0.7615']
his_acc des_wo_na:  ['0.7615']
cur_acc rrf_wo_na:  ['0.7748']
his_acc rrf_wo_na:  ['0.7748']
cur_acc_w_na:  ['0.6496']
his_acc_w_na:  ['0.6496']
cur_acc des_w_na:  ['0.6247']
his_acc des_w_na:  ['0.6247']
cur_acc rrf_w_na:  ['0.6389']
his_acc rrf_w_na:  ['0.6389']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges'])
CurrentTrain: epoch  0, batch     0 | loss: 84.1187746CurrentTrain: epoch  0, batch     1 | loss: 155.4864415CurrentTrain: epoch  0, batch     2 | loss: 115.1973817CurrentTrain: epoch  0, batch     3 | loss: 90.4052751CurrentTrain: epoch  0, batch     4 | loss: 120.7215841CurrentTrain: epoch  1, batch     0 | loss: 90.2168543CurrentTrain: epoch  1, batch     1 | loss: 107.7694380CurrentTrain: epoch  1, batch     2 | loss: 77.7229923CurrentTrain: epoch  1, batch     3 | loss: 108.8679114CurrentTrain: epoch  1, batch     4 | loss: 60.1994564CurrentTrain: epoch  2, batch     0 | loss: 84.8199456CurrentTrain: epoch  2, batch     1 | loss: 128.3904736CurrentTrain: epoch  2, batch     2 | loss: 109.3640310CurrentTrain: epoch  2, batch     3 | loss: 89.8836246CurrentTrain: epoch  2, batch     4 | loss: 66.6885502CurrentTrain: epoch  3, batch     0 | loss: 105.2832549CurrentTrain: epoch  3, batch     1 | loss: 84.3319154CurrentTrain: epoch  3, batch     2 | loss: 103.3891809CurrentTrain: epoch  3, batch     3 | loss: 100.9787633CurrentTrain: epoch  3, batch     4 | loss: 82.1932481CurrentTrain: epoch  4, batch     0 | loss: 101.1148902CurrentTrain: epoch  4, batch     1 | loss: 70.0553535CurrentTrain: epoch  4, batch     2 | loss: 129.2360264CurrentTrain: epoch  4, batch     3 | loss: 68.5963234CurrentTrain: epoch  4, batch     4 | loss: 82.6849130CurrentTrain: epoch  5, batch     0 | loss: 68.4286175CurrentTrain: epoch  5, batch     1 | loss: 102.9889934CurrentTrain: epoch  5, batch     2 | loss: 101.4249497CurrentTrain: epoch  5, batch     3 | loss: 125.7464232CurrentTrain: epoch  5, batch     4 | loss: 59.1205881CurrentTrain: epoch  6, batch     0 | loss: 81.4312658CurrentTrain: epoch  6, batch     1 | loss: 68.8922307CurrentTrain: epoch  6, batch     2 | loss: 123.1281201CurrentTrain: epoch  6, batch     3 | loss: 80.5337422CurrentTrain: epoch  6, batch     4 | loss: 108.8816496CurrentTrain: epoch  7, batch     0 | loss: 98.9686111CurrentTrain: epoch  7, batch     1 | loss: 95.7464581CurrentTrain: epoch  7, batch     2 | loss: 125.6286216CurrentTrain: epoch  7, batch     3 | loss: 63.3511948CurrentTrain: epoch  7, batch     4 | loss: 74.1780486CurrentTrain: epoch  8, batch     0 | loss: 67.4021566CurrentTrain: epoch  8, batch     1 | loss: 96.7352549CurrentTrain: epoch  8, batch     2 | loss: 80.3183978CurrentTrain: epoch  8, batch     3 | loss: 80.8850567CurrentTrain: epoch  8, batch     4 | loss: 57.4096853CurrentTrain: epoch  9, batch     0 | loss: 80.2882840CurrentTrain: epoch  9, batch     1 | loss: 95.0223674CurrentTrain: epoch  9, batch     2 | loss: 75.3539949CurrentTrain: epoch  9, batch     3 | loss: 80.0912213CurrentTrain: epoch  9, batch     4 | loss: 58.7355762
MemoryTrain:  epoch  0, batch     0 | loss: 1.6916785MemoryTrain:  epoch  1, batch     0 | loss: 1.4442899MemoryTrain:  epoch  2, batch     0 | loss: 1.1443263MemoryTrain:  epoch  3, batch     0 | loss: 0.9665151MemoryTrain:  epoch  4, batch     0 | loss: 0.7481971MemoryTrain:  epoch  5, batch     0 | loss: 0.6128880MemoryTrain:  epoch  6, batch     0 | loss: 0.6926918MemoryTrain:  epoch  7, batch     0 | loss: 0.4093149MemoryTrain:  epoch  8, batch     0 | loss: 0.4163215MemoryTrain:  epoch  9, batch     0 | loss: 0.3461495

F1 score per class: {32: np.float64(0.8910891089108911), 5: np.float64(0.0), 6: np.float64(0.21428571428571427), 10: np.float64(0.6382978723404256), 16: np.float64(0.0), 17: np.float64(0.14634146341463414), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.5429864253393665
Weighted-average F1 score: 0.6319213696613568
F1 score per class: {32: np.float64(0.7883817427385892), 5: np.float64(0.0), 6: np.float64(0.5616438356164384), 10: np.float64(0.6551724137931034), 16: np.float64(0.0), 17: np.float64(0.59375), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.6214285714285714
Weighted-average F1 score: 0.6034278864461413
F1 score per class: {32: np.float64(0.8157894736842105), 5: np.float64(0.0), 6: np.float64(0.5714285714285714), 10: np.float64(0.6545454545454545), 16: np.float64(0.0), 17: np.float64(0.5423728813559322), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.6294227188081937
Weighted-average F1 score: 0.6113947710428684

F1 score per class: {32: np.float64(0.8910891089108911), 5: np.float64(0.518918918918919), 6: np.float64(0.21238938053097345), 10: np.float64(0.625), 16: np.float64(0.0), 17: np.float64(0.13953488372093023), 18: np.float64(0.7904761904761904), 19: np.float64(0.4117647058823529), 24: np.float64(0.7303370786516854), 26: np.float64(0.8923076923076924), 29: np.float64(0.8217821782178217)}
Micro-average F1 score: 0.6702923181509177
Weighted-average F1 score: 0.6926815211152524
F1 score per class: {32: np.float64(0.7480314960629921), 5: np.float64(0.6017699115044248), 6: np.float64(0.5222929936305732), 10: np.float64(0.5846153846153846), 16: np.float64(0.0), 17: np.float64(0.5205479452054794), 18: np.float64(0.7574468085106383), 19: np.float64(0.36), 24: np.float64(0.7311827956989247), 26: np.float64(0.9207920792079208), 29: np.float64(0.8173076923076923)}
Micro-average F1 score: 0.6967895362663495
Weighted-average F1 score: 0.6968906382844808
F1 score per class: {32: np.float64(0.775), 5: np.float64(0.5781990521327014), 6: np.float64(0.525), 10: np.float64(0.6), 16: np.float64(0.0), 17: np.float64(0.5), 18: np.float64(0.7892376681614349), 19: np.float64(0.4090909090909091), 24: np.float64(0.7472527472527473), 26: np.float64(0.9207920792079208), 29: np.float64(0.8133971291866029)}
Micro-average F1 score: 0.7022058823529411
Weighted-average F1 score: 0.7007738616255643

F1 score per class: {32: np.float64(0.7692307692307693), 5: np.float64(0.0), 6: np.float64(0.21052631578947367), 10: np.float64(0.46153846153846156), 16: np.float64(0.0), 17: np.float64(0.10714285714285714), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.42628774422735344
Weighted-average F1 score: 0.4328008778311364
F1 score per class: {32: np.float64(0.5974842767295597), 5: np.float64(0.0), 6: np.float64(0.4632768361581921), 10: np.float64(0.4470588235294118), 16: np.float64(0.0), 17: np.float64(0.36538461538461536), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.4371859296482412
Weighted-average F1 score: 0.4134478716079071
F1 score per class: {32: np.float64(0.6179401993355482), 5: np.float64(0.0), 6: np.float64(0.4745762711864407), 10: np.float64(0.43902439024390244), 16: np.float64(0.0), 17: np.float64(0.38095238095238093), 18: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.0), 26: np.float64(0.0), 29: np.float64(0.0)}
Micro-average F1 score: 0.4512683578104139
Weighted-average F1 score: 0.42596698339375466

F1 score per class: {32: np.float64(0.7692307692307693), 5: np.float64(0.35555555555555557), 6: np.float64(0.2033898305084746), 10: np.float64(0.4411764705882353), 16: np.float64(0.0), 17: np.float64(0.1), 18: np.float64(0.7312775330396476), 19: np.float64(0.2641509433962264), 24: np.float64(0.6666666666666666), 26: np.float64(0.7837837837837838), 29: np.float64(0.6535433070866141)}
Micro-average F1 score: 0.5441501103752759
Weighted-average F1 score: 0.5382762714283592
F1 score per class: {32: np.float64(0.5444126074498568), 5: np.float64(0.38636363636363635), 6: np.float64(0.39805825242718446), 10: np.float64(0.36893203883495146), 16: np.float64(0.0), 17: np.float64(0.3064516129032258), 18: np.float64(0.6846153846153846), 19: np.float64(0.18556701030927836), 24: np.float64(0.6445497630331753), 26: np.float64(0.7717842323651453), 29: np.float64(0.6463878326996197)}
Micro-average F1 score: 0.5211204979991108
Weighted-average F1 score: 0.5076535753103538
F1 score per class: {32: np.float64(0.5653495440729484), 5: np.float64(0.37888198757763975), 6: np.float64(0.39436619718309857), 10: np.float64(0.37894736842105264), 16: np.float64(0.0), 17: np.float64(0.32989690721649484), 18: np.float64(0.7183673469387755), 19: np.float64(0.21951219512195122), 24: np.float64(0.6732673267326733), 26: np.float64(0.788135593220339), 29: np.float64(0.6415094339622641)}
Micro-average F1 score: 0.5330232558139535
Weighted-average F1 score: 0.5180578398963046
cur_acc_wo_na:  ['0.7658', '0.5430']
his_acc_wo_na:  ['0.7658', '0.6703']
cur_acc des_wo_na:  ['0.7615', '0.6214']
his_acc des_wo_na:  ['0.7615', '0.6968']
cur_acc rrf_wo_na:  ['0.7748', '0.6294']
his_acc rrf_wo_na:  ['0.7748', '0.7022']
cur_acc_w_na:  ['0.6496', '0.4263']
his_acc_w_na:  ['0.6496', '0.5442']
cur_acc des_w_na:  ['0.6247', '0.4372']
his_acc des_w_na:  ['0.6247', '0.5211']
cur_acc rrf_w_na:  ['0.6389', '0.4513']
his_acc rrf_w_na:  ['0.6389', '0.5330']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by'])
CurrentTrain: epoch  0, batch     0 | loss: 98.0706500CurrentTrain: epoch  0, batch     1 | loss: 80.5244821CurrentTrain: epoch  0, batch     2 | loss: 80.8274765CurrentTrain: epoch  0, batch     3 | loss: 9.7961234CurrentTrain: epoch  1, batch     0 | loss: 77.6270637CurrentTrain: epoch  1, batch     1 | loss: 75.3700656CurrentTrain: epoch  1, batch     2 | loss: 72.8760314CurrentTrain: epoch  1, batch     3 | loss: 20.5586845CurrentTrain: epoch  2, batch     0 | loss: 65.5422873CurrentTrain: epoch  2, batch     1 | loss: 84.4947778CurrentTrain: epoch  2, batch     2 | loss: 99.3104092CurrentTrain: epoch  2, batch     3 | loss: 19.9360058CurrentTrain: epoch  3, batch     0 | loss: 67.5366953CurrentTrain: epoch  3, batch     1 | loss: 71.0379823CurrentTrain: epoch  3, batch     2 | loss: 79.5271262CurrentTrain: epoch  3, batch     3 | loss: 10.8027219CurrentTrain: epoch  4, batch     0 | loss: 65.7380784CurrentTrain: epoch  4, batch     1 | loss: 67.9552385CurrentTrain: epoch  4, batch     2 | loss: 68.2570242CurrentTrain: epoch  4, batch     3 | loss: 19.3884470CurrentTrain: epoch  5, batch     0 | loss: 64.1255706CurrentTrain: epoch  5, batch     1 | loss: 64.1363488CurrentTrain: epoch  5, batch     2 | loss: 68.0755207CurrentTrain: epoch  5, batch     3 | loss: 18.4719038CurrentTrain: epoch  6, batch     0 | loss: 65.6590577CurrentTrain: epoch  6, batch     1 | loss: 61.4475179CurrentTrain: epoch  6, batch     2 | loss: 65.9651193CurrentTrain: epoch  6, batch     3 | loss: 19.7108659CurrentTrain: epoch  7, batch     0 | loss: 59.7677619CurrentTrain: epoch  7, batch     1 | loss: 73.0777684CurrentTrain: epoch  7, batch     2 | loss: 95.7136759CurrentTrain: epoch  7, batch     3 | loss: 41.8824470CurrentTrain: epoch  8, batch     0 | loss: 62.8431188CurrentTrain: epoch  8, batch     1 | loss: 63.0222446CurrentTrain: epoch  8, batch     2 | loss: 62.4367178CurrentTrain: epoch  8, batch     3 | loss: 18.0335457CurrentTrain: epoch  9, batch     0 | loss: 75.4947133CurrentTrain: epoch  9, batch     1 | loss: 71.8470478CurrentTrain: epoch  9, batch     2 | loss: 72.4839567CurrentTrain: epoch  9, batch     3 | loss: 9.3392367
MemoryTrain:  epoch  0, batch     0 | loss: 1.0410468MemoryTrain:  epoch  1, batch     0 | loss: 0.8600148MemoryTrain:  epoch  2, batch     0 | loss: 0.6969266MemoryTrain:  epoch  3, batch     0 | loss: 0.5997531MemoryTrain:  epoch  4, batch     0 | loss: 0.4217217MemoryTrain:  epoch  5, batch     0 | loss: 0.3622083MemoryTrain:  epoch  6, batch     0 | loss: 0.3016422MemoryTrain:  epoch  7, batch     0 | loss: 0.2554786MemoryTrain:  epoch  8, batch     0 | loss: 0.2383514MemoryTrain:  epoch  9, batch     0 | loss: 0.1850851

F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5714285714285714), 7: np.float64(0.8421052631578947), 40: np.float64(0.0), 9: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.13333333333333333), 26: np.float64(0.0), 27: np.float64(0.5), 29: np.float64(0.0), 31: np.float64(0.3230769230769231)}
Micro-average F1 score: 0.362962962962963
Weighted-average F1 score: 0.311189462808896
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5714285714285714), 7: np.float64(0.6666666666666666), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.2222222222222222), 26: np.float64(0.0), 27: np.float64(0.25), 29: np.float64(0.0), 31: np.float64(0.32)}
Micro-average F1 score: 0.33003300330033003
Weighted-average F1 score: 0.28920970857478795
F1 score per class: {32: np.float64(0.0), 6: np.float64(0.5714285714285714), 7: np.float64(0.7936507936507936), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.2222222222222222), 26: np.float64(0.0), 27: np.float64(0.4), 29: np.float64(0.0), 31: np.float64(0.3125)}
Micro-average F1 score: 0.34965034965034963
Weighted-average F1 score: 0.2998200442967885

F1 score per class: {32: np.float64(0.8625592417061612), 5: np.float64(0.3088235294117647), 6: np.float64(0.037037037037037035), 7: np.float64(0.8421052631578947), 40: np.float64(0.18181818181818182), 9: np.float64(0.6086956521739131), 10: np.float64(0.0), 16: np.float64(0.045454545454545456), 17: np.float64(0.6329113924050633), 18: np.float64(0.2727272727272727), 19: np.float64(0.7134502923976608), 24: np.float64(0.10526315789473684), 26: np.float64(0.8131868131868132), 27: np.float64(0.3333333333333333), 29: np.float64(0.8042328042328042), 31: np.float64(0.15849056603773584)}
Micro-average F1 score: 0.5208333333333334
Weighted-average F1 score: 0.5006087637454955
F1 score per class: {32: np.float64(0.643598615916955), 5: np.float64(0.41916167664670656), 6: np.float64(0.04938271604938271), 7: np.float64(0.6578947368421053), 40: np.float64(0.475), 10: np.float64(0.5151515151515151), 9: np.float64(0.0), 16: np.float64(0.3492063492063492), 17: np.float64(0.6204081632653061), 18: np.float64(0.23529411764705882), 19: np.float64(0.7333333333333333), 24: np.float64(0.17391304347826086), 26: np.float64(0.875), 27: np.float64(0.13333333333333333), 29: np.float64(0.8282828282828283), 31: np.float64(0.17467248908296942)}
Micro-average F1 score: 0.547244094488189
Weighted-average F1 score: 0.5232683465613808
F1 score per class: {32: np.float64(0.7022900763358778), 5: np.float64(0.4166666666666667), 6: np.float64(0.04878048780487805), 7: np.float64(0.7936507936507936), 40: np.float64(0.425531914893617), 10: np.float64(0.5357142857142857), 9: np.float64(0.0), 16: np.float64(0.13043478260869565), 17: np.float64(0.6255144032921811), 18: np.float64(0.2), 19: np.float64(0.7344632768361582), 24: np.float64(0.16666666666666666), 26: np.float64(0.8631578947368421), 27: np.float64(0.2222222222222222), 29: np.float64(0.8282828282828283), 31: np.float64(0.16666666666666666)}
Micro-average F1 score: 0.5472279260780287
Weighted-average F1 score: 0.5260466450473491

F1 score per class: {32: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.7741935483870968), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 19: np.float64(0.125), 26: np.float64(0.0), 27: np.float64(0.4), 29: np.float64(0.0), 31: np.float64(0.2709677419354839)}
Micro-average F1 score: 0.31210191082802546
Weighted-average F1 score: 0.27260080645161294
F1 score per class: {32: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.5813953488372093), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.21052631578947367), 26: np.float64(0.0), 27: np.float64(0.18181818181818182), 29: np.float64(0.0), 31: np.float64(0.26666666666666666)}
Micro-average F1 score: 0.2717391304347826
Weighted-average F1 score: 0.2407476737322823
F1 score per class: {32: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.5), 7: np.float64(0.7352941176470589), 40: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 16: np.float64(0.0), 17: np.float64(0.0), 19: np.float64(0.0), 24: np.float64(0.21052631578947367), 26: np.float64(0.0), 27: np.float64(0.2857142857142857), 29: np.float64(0.0), 31: np.float64(0.2597402597402597)}
Micro-average F1 score: 0.29239766081871343
Weighted-average F1 score: 0.2518058973778381

F1 score per class: {32: np.float64(0.6594202898550725), 5: np.float64(0.22105263157894736), 6: np.float64(0.02197802197802198), 7: np.float64(0.7741935483870968), 40: np.float64(0.17543859649122806), 10: np.float64(0.4057971014492754), 9: np.float64(0.0), 16: np.float64(0.04), 17: np.float64(0.6024096385542169), 18: np.float64(0.25), 19: np.float64(0.6559139784946236), 24: np.float64(0.09090909090909091), 26: np.float64(0.729064039408867), 27: np.float64(0.25), 29: np.float64(0.6696035242290749), 31: np.float64(0.12209302325581395)}
Micro-average F1 score: 0.4209127159946832
Weighted-average F1 score: 0.39313028240485587
F1 score per class: {32: np.float64(0.4325581395348837), 5: np.float64(0.2892561983471074), 6: np.float64(0.029411764705882353), 7: np.float64(0.5376344086021505), 40: np.float64(0.39378238341968913), 10: np.float64(0.3008849557522124), 9: np.float64(0.0), 16: np.float64(0.24719101123595505), 17: np.float64(0.5801526717557252), 18: np.float64(0.16), 19: np.float64(0.66), 24: np.float64(0.13793103448275862), 26: np.float64(0.7601809954751131), 27: np.float64(0.1), 29: np.float64(0.6804979253112033), 31: np.float64(0.136986301369863)}
Micro-average F1 score: 0.41962264150943396
Weighted-average F1 score: 0.3937260775767619
F1 score per class: {32: np.float64(0.4804177545691906), 5: np.float64(0.29535864978902954), 6: np.float64(0.027972027972027972), 7: np.float64(0.7246376811594203), 40: np.float64(0.36585365853658536), 10: np.float64(0.3225806451612903), 9: np.float64(0.0), 16: np.float64(0.10714285714285714), 17: np.float64(0.5868725868725869), 18: np.float64(0.15), 19: np.float64(0.6770833333333334), 24: np.float64(0.13793103448275862), 26: np.float64(0.7592592592592593), 27: np.float64(0.15384615384615385), 29: np.float64(0.6721311475409836), 31: np.float64(0.13071895424836602)}
Micro-average F1 score: 0.42828445158698275
Weighted-average F1 score: 0.40227105088293275
cur_acc_wo_na:  ['0.7658', '0.5430', '0.3630']
his_acc_wo_na:  ['0.7658', '0.6703', '0.5208']
cur_acc des_wo_na:  ['0.7615', '0.6214', '0.3300']
his_acc des_wo_na:  ['0.7615', '0.6968', '0.5472']
cur_acc rrf_wo_na:  ['0.7748', '0.6294', '0.3497']
his_acc rrf_wo_na:  ['0.7748', '0.7022', '0.5472']
cur_acc_w_na:  ['0.6496', '0.4263', '0.3121']
his_acc_w_na:  ['0.6496', '0.5442', '0.4209']
cur_acc des_w_na:  ['0.6247', '0.4372', '0.2717']
his_acc des_w_na:  ['0.6247', '0.5211', '0.4196']
cur_acc rrf_w_na:  ['0.6389', '0.4513', '0.2924']
his_acc rrf_w_na:  ['0.6389', '0.5330', '0.4283']
seen_des: dict_keys(['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters', 'unknown', 'NA', 'person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges', 'person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by', 'organization founded', 'person age', 'person city of birth', 'organization members', 'person religion'])
CurrentTrain: epoch  0, batch     0 | loss: 102.3886380CurrentTrain: epoch  0, batch     1 | loss: 97.1527512CurrentTrain: epoch  0, batch     2 | loss: 117.6173273CurrentTrain: epoch  0, batch     3 | loss: 96.1296043CurrentTrain: epoch  1, batch     0 | loss: 77.7509475CurrentTrain: epoch  1, batch     1 | loss: 74.2601957CurrentTrain: epoch  1, batch     2 | loss: 97.9449416CurrentTrain: epoch  1, batch     3 | loss: 91.5417950CurrentTrain: epoch  2, batch     0 | loss: 87.2342511CurrentTrain: epoch  2, batch     1 | loss: 71.6885992CurrentTrain: epoch  2, batch     2 | loss: 108.9074455CurrentTrain: epoch  2, batch     3 | loss: 72.3591588CurrentTrain: epoch  3, batch     0 | loss: 101.5823622CurrentTrain: epoch  3, batch     1 | loss: 87.2611984CurrentTrain: epoch  3, batch     2 | loss: 85.7097702CurrentTrain: epoch  3, batch     3 | loss: 81.4295854CurrentTrain: epoch  4, batch     0 | loss: 98.9556417CurrentTrain: epoch  4, batch     1 | loss: 101.3212310CurrentTrain: epoch  4, batch     2 | loss: 88.1602793CurrentTrain: epoch  4, batch     3 | loss: 54.4822597CurrentTrain: epoch  5, batch     0 | loss: 99.3282277CurrentTrain: epoch  5, batch     1 | loss: 78.4526692CurrentTrain: epoch  5, batch     2 | loss: 103.2069513CurrentTrain: epoch  5, batch     3 | loss: 64.5978709CurrentTrain: epoch  6, batch     0 | loss: 81.5204621CurrentTrain: epoch  6, batch     1 | loss: 77.8093193CurrentTrain: epoch  6, batch     2 | loss: 82.6408626CurrentTrain: epoch  6, batch     3 | loss: 78.4486189CurrentTrain: epoch  7, batch     0 | loss: 77.0908847CurrentTrain: epoch  7, batch     1 | loss: 97.3264633CurrentTrain: epoch  7, batch     2 | loss: 81.0352899CurrentTrain: epoch  7, batch     3 | loss: 65.8854649CurrentTrain: epoch  8, batch     0 | loss: 82.6609989CurrentTrain: epoch  8, batch     1 | loss: 77.1683071CurrentTrain: epoch  8, batch     2 | loss: 76.9710138CurrentTrain: epoch  8, batch     3 | loss: 55.0209974CurrentTrain: epoch  9, batch     0 | loss: 74.8200263CurrentTrain: epoch  9, batch     1 | loss: 65.2304119CurrentTrain: epoch  9, batch     2 | loss: 98.0104039CurrentTrain: epoch  9, batch     3 | loss: 79.1195089
MemoryTrain:  epoch  0, batch     0 | loss: 0.9903797MemoryTrain:  epoch  1, batch     0 | loss: 0.8452603MemoryTrain:  epoch  2, batch     0 | loss: 0.7169216MemoryTrain:  epoch  3, batch     0 | loss: 0.5667800MemoryTrain:  epoch  4, batch     0 | loss: 0.4588247MemoryTrain:  epoch  5, batch     0 | loss: 0.4112181MemoryTrain:  epoch  6, batch     0 | loss: 0.3599585MemoryTrain:  epoch  7, batch     0 | loss: 0.3092123MemoryTrain:  epoch  8, batch     0 | loss: 0.2892418MemoryTrain:  epoch  9, batch     0 | loss: 0.2546161

F1 score per class: {0: np.float64(0.9014084507042254), 4: np.float64(0.9583333333333334), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.17391304347826086), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.27586206896551724), 23: np.float64(0.8), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.6882591093117408
Weighted-average F1 score: 0.5977856373550656
F1 score per class: {0: np.float64(0.813953488372093), 4: np.float64(0.9603960396039604), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.17391304347826086), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.4358974358974359), 23: np.float64(0.7058823529411765), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.6241379310344828
Weighted-average F1 score: 0.5230146129205261
F1 score per class: {0: np.float64(0.8533333333333334), 4: np.float64(0.9746192893401016), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 10: np.float64(0.0), 13: np.float64(0.16666666666666666), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 21: np.float64(0.43037974683544306), 23: np.float64(0.7142857142857143), 24: np.float64(0.0), 26: np.float64(0.0), 27: np.float64(0.0), 29: np.float64(0.0), 31: np.float64(0.0), 32: np.float64(0.0), 40: np.float64(0.0)}
Micro-average F1 score: 0.6555555555555556
Weighted-average F1 score: 0.553806886487487
